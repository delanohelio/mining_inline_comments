{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYzMjIyNDA1", "number": 4239, "reviewThreads": {"totalCount": 55, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQwMDozOTozOFrODYWxAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQwODo0ODowNVrODg-8tg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2ODY1NDExOnYy", "diffSide": "RIGHT", "path": "dist-material/application.yml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQwMDozOTozOFrOFeK2vg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQwMDozOTozOFrOFeK2vg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE3OTQ1NA==", "bodyText": "This should not be changed in PR.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r367179454", "createdAt": "2020-01-16T00:39:38Z", "author": {"login": "wu-sheng"}, "path": "dist-material/application.yml", "diffHunk": "@@ -120,11 +120,11 @@ storage:\n #    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n #    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n #    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n-  h2:\n-    driver: ${SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource}\n-    url: ${SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db}\n-    user: ${SW_STORAGE_H2_USER:sa}\n-    metadataQueryMaxSize: ${SW_STORAGE_H2_QUERY_MAX_SIZE:5000}\n+#  h2:\n+#    driver: ${SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource}\n+#    url: ${SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db}\n+#    user: ${SW_STORAGE_H2_USER:sa}\n+#    metadataQueryMaxSize: ${SW_STORAGE_H2_QUERY_MAX_SIZE:5000}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "484e078399f90e2b11d9bc16a83c76bbc1d4921b"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2ODY1NTUyOnYy", "diffSide": "RIGHT", "path": "dist-material/application.yml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQwMDo0MDoyNlrOFeK3mw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQwMDo0MDoyNlrOFeK3mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE3OTY3NQ==", "bodyText": "You should support to set metadata DB type. Otherwise, you have to link to single one DB implementation.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r367179675", "createdAt": "2020-01-16T00:40:26Z", "author": {"login": "wu-sheng"}, "path": "dist-material/application.yml", "diffHunk": "@@ -135,6 +135,16 @@ storage:\n #      dataSource.prepStmtCacheSqlLimit: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n #      dataSource.useServerPrepStmts: ${SW_DATA_SOURCE_USE_SERVER_PREP_STMTS:true}\n #    metadataQueryMaxSize: ${SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000}\n+  influx:\n+    myDriver: ${SW_STORAGE_MY_DRIVER:org.h2.jdbcx.JdbcDataSource}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "484e078399f90e2b11d9bc16a83c76bbc1d4921b"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MjM1NjY4OnYy", "diffSide": "RIGHT", "path": "oap-server/server-bootstrap/src/main/resources/application.yml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwNDowMDo0OFrOFeuTBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwNDowMDo0OFrOFeuTBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc2MDEzNQ==", "bodyText": "myUrl: ${SW_STORAGE_MY_URL:org.h2.jdbcx.JdbcDataSource}\n    myDriver: ${SW_STORAGE_MY_DRIVER:jdbc:h2:mem:skywalking-oap-db}\n\n--->\n    myUrl: ${SW_STORAGE_MY_URL:jdbc:h2:mem:skywalking-oap-db}\n    myDriver: ${SW_STORAGE_MY_DRIVER:org.h2.jdbcx.JdbcDataSource}", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r367760135", "createdAt": "2020-01-17T04:00:48Z", "author": {"login": "JaredTan95"}, "path": "oap-server/server-bootstrap/src/main/resources/application.yml", "diffHunk": "@@ -98,28 +98,37 @@ storage:\n #    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n #    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n #    advanced: ${SW_STORAGE_ES_ADVANCED:\"\"}\n-  elasticsearch7:\n-    nameSpace: ${SW_NAMESPACE:\"\"}\n-    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n-    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n-    #trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n-    #trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n-    user: ${SW_ES_USER:\"\"}\n-    password: ${SW_ES_PASSWORD:\"\"}\n-    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n-    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n-    # Those data TTL settings will override the same settings in core module.\n-    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n-    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n-    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n-    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n-    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n-    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n-    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n-    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n-    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n-    advanced: ${SW_STORAGE_ES_ADVANCED:\"\"}\n+  influx:\n+    myUrl: ${SW_STORAGE_MY_URL:org.h2.jdbcx.JdbcDataSource}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "484e078399f90e2b11d9bc16a83c76bbc1d4921b"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NTYyMDI5OnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/InfluxStorageDAO.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQwMDo0NjowOFrOFfMogQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQwODoxNjozNFrOFfNsjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI1NzE1Mw==", "bodyText": "INoneStreamDAO is used for web interactive job, such as @mrproliu 's profiling task. Basically, this should have little data. Is the influxDB suitable for this?", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r368257153", "createdAt": "2020-01-19T00:46:08Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/InfluxStorageDAO.java", "diffHunk": "@@ -53,6 +53,6 @@ public IRecordDAO newRecordDao(StorageBuilder<Record> storageBuilder) {\n \n     @Override\n     public INoneStreamDAO newNoneStreamDao(StorageBuilder<NoneStream> storageBuilder) {\n-        return new NoneStreamDAO();\n+        return new NoneStreamDAO(influxClient, storageBuilder);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e654eda3d9e30e5af385e0bf320f3865e0f89626"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI2MzA1Ng==", "bodyText": "That sounds the relationship database better.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r368263056", "createdAt": "2020-01-19T03:33:13Z", "author": {"login": "dmsolr"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/InfluxStorageDAO.java", "diffHunk": "@@ -53,6 +53,6 @@ public IRecordDAO newRecordDao(StorageBuilder<Record> storageBuilder) {\n \n     @Override\n     public INoneStreamDAO newNoneStreamDao(StorageBuilder<NoneStream> storageBuilder) {\n-        return new NoneStreamDAO();\n+        return new NoneStreamDAO(influxClient, storageBuilder);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI1NzE1Mw=="}, "originalCommit": {"oid": "e654eda3d9e30e5af385e0bf320f3865e0f89626"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI3NDU3NA==", "bodyText": "There would be much data, just easy to query should be enough. Anyway, based on your decision.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r368274574", "createdAt": "2020-01-19T08:16:34Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/InfluxStorageDAO.java", "diffHunk": "@@ -53,6 +53,6 @@ public IRecordDAO newRecordDao(StorageBuilder<Record> storageBuilder) {\n \n     @Override\n     public INoneStreamDAO newNoneStreamDao(StorageBuilder<NoneStream> storageBuilder) {\n-        return new NoneStreamDAO();\n+        return new NoneStreamDAO(influxClient, storageBuilder);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI1NzE1Mw=="}, "originalCommit": {"oid": "e654eda3d9e30e5af385e0bf320f3865e0f89626"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMjEzNjY4OnYy", "diffSide": "RIGHT", "path": "dist-material/release-docs/NOTICE", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwMTozOTo1NVrOFkkxTA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwMTozOTo1NVrOFkkxTA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg5NTUwMA==", "bodyText": "As MIT license you don't need to update NOTICE. NOTICE is for Apache 2.0 only. Please remove this part.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r373895500", "createdAt": "2020-02-03T01:39:55Z", "author": {"login": "wu-sheng"}, "path": "dist-material/release-docs/NOTICE", "diffHunk": "@@ -905,4 +905,31 @@ be obtained at:\n   * HOMEPAGE:\n     * https://github.com/catapult-project/catapult\n \n+------\n+\n+===========================================================================", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8d36fccc74f4ea46b1e61ef0821da595b289084e"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMjU1NjY3OnYy", "diffSide": "RIGHT", "path": "oap-server/server-bootstrap/src/main/resources/application.yml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNzo1MDo0MlrOFkoonw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNzo1MDo0MlrOFkoonw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzk1ODgxNQ==", "bodyText": "If these are using the as same unit as the core module, you shouldn't add them. You could use the core's.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r373958815", "createdAt": "2020-02-03T07:50:42Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-bootstrap/src/main/resources/application.yml", "diffHunk": "@@ -146,6 +146,11 @@ storage:\n #    password: ${SW_STORAGE_PASSWORD:}\n #    database: ${SW_STORAGE_DATABASE:skywalking}\n #    metadataQueryMaxSize: ${SW_STORAGE_H2_QUERY_MAX_SIZE:5000}\n+#    recordDataTTL: ${SW_STORAGE_RECORD_DATA_TTL:7} # keeps 7 days\n+#    minuteMetricsDataTTL: ${SW_STORAGE_MINUTE_METRICS_DATA_TTL:64800} # Unit is minute, keeps 45 days\n+#    hourMetricsDataTTL: ${SW_STORAGE_HOUR_METRICS_DATA_TTL:1080} # Unit is hour, keeps 45 days\n+#    dayMetricsDataTTL: ${SW_STORAGE_DAY_METRICS_DATA_TTL:45} # Unit is day, keeps 45 days\n+#    monthMetricsDataTTL: ${SW_STORAGE_MONTH_METRICS_DATA_TTL:18} # Unit is month, keeps 18 months", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9128aec8aff64b68c151a710f36728fa6a1dccbf"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNjY0NjY0OnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMDo0NDoyOFrOFlPmOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMjoyMDoyN1rOFlSFyw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDU5NzE3OQ==", "bodyText": "I don't really recommend to use this kind of codes to get the current class just for logging, java.lang.invoke.MethodHandles#lookup creates new object for every call, which I don't think is necessary, and if you are trying to avoid \"copy-and-paste\" mistakes, why not just use the @Slf4j annotation of Lombok, WDYT @wu-sheng", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r374597179", "createdAt": "2020-02-04T10:44:28Z", "author": {"login": "kezhenxu94"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb;\n+\n+import java.io.IOException;\n+import java.lang.invoke.MethodHandles;\n+import java.util.List;\n+import okhttp3.OkHttpClient;\n+import org.apache.skywalking.oap.server.core.analysis.Downsampling;\n+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;\n+import org.apache.skywalking.oap.server.library.client.Client;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.BatchPoints;\n+import org.influxdb.dto.Point;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.time.TimeInterval;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.ti;\n+\n+public class InfluxClient implements Client {\n+    private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f06435eb514cf47cc90741c475502b28b31aab03"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDYzODAyNw==", "bodyText": "Agree. @slf4j good enough for me.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r374638027", "createdAt": "2020-02-04T12:20:27Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb;\n+\n+import java.io.IOException;\n+import java.lang.invoke.MethodHandles;\n+import java.util.List;\n+import okhttp3.OkHttpClient;\n+import org.apache.skywalking.oap.server.core.analysis.Downsampling;\n+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;\n+import org.apache.skywalking.oap.server.library.client.Client;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.BatchPoints;\n+import org.influxdb.dto.Point;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.time.TimeInterval;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.ti;\n+\n+public class InfluxClient implements Client {\n+    private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDU5NzE3OQ=="}, "originalCommit": {"oid": "f06435eb514cf47cc90741c475502b28b31aab03"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNjY1ODE3OnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/pom.xml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMDo0ODowNFrOFlPtNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMDo0ODowNFrOFlPtNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDU5ODk2Nw==", "bodyText": "why does influx plugin depend on ElasticSearch plugin", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r374598967", "createdAt": "2020-02-04T10:48:04Z", "author": {"login": "kezhenxu94"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/pom.xml", "diffHunk": "@@ -0,0 +1,50 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specrm ific language governing permissions and\n+  ~ limitations under the License.\n+  ~\n+  -->\n+\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <parent>\n+        <artifactId>server-storage-plugin</artifactId>\n+        <groupId>org.apache.skywalking</groupId>\n+        <version>7.0.0-SNAPSHOT</version>\n+    </parent>\n+    <modelVersion>4.0.0</modelVersion>\n+\n+    <artifactId>storage-influxdb-plugin</artifactId>\n+    <packaging>jar</packaging>\n+\n+    <dependencies>\n+        <dependency>\n+            <groupId>org.apache.skywalking</groupId>\n+            <artifactId>storage-elasticsearch-plugin</artifactId>\n+            <version>${project.version}</version>\n+        </dependency>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f06435eb514cf47cc90741c475502b28b31aab03"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNjY3Njc2OnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/query/AggregationQuery.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMDo1NDoxMFrOFlP4og==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMDo1NDoxMFrOFlP4og==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDYwMTg5MA==", "bodyText": "As private methods cannot be meaningfully overridden, declaring them final is redundant.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r374601890", "createdAt": "2020-02-04T10:54:10Z", "author": {"login": "kezhenxu94"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/query/AggregationQuery.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.query;\n+\n+import com.google.common.collect.Lists;\n+import org.apache.skywalking.oap.server.core.analysis.Downsampling;\n+import org.apache.skywalking.oap.server.core.analysis.metrics.Metrics;\n+import org.apache.skywalking.oap.server.core.query.entity.Order;\n+import org.apache.skywalking.oap.server.core.query.entity.TopNEntity;\n+import org.apache.skywalking.oap.server.core.register.EndpointInventory;\n+import org.apache.skywalking.oap.server.core.register.ServiceInstanceInventory;\n+import org.apache.skywalking.oap.server.core.storage.model.ModelName;\n+import org.apache.skywalking.oap.server.core.storage.query.IAggregationQueryDAO;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.SelectQueryImpl;\n+import org.influxdb.querybuilder.SelectSubQueryImpl;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.lang.invoke.MethodHandles;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.List;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.*;\n+\n+public class AggregationQuery implements IAggregationQueryDAO {\n+    private static final Logger LOG = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+    private final InfluxClient client;\n+\n+    public AggregationQuery(InfluxClient client) {\n+        this.client = client;\n+    }\n+\n+    @Override\n+    public List<TopNEntity> getServiceTopN(String indName, String valueCName, int topN, Downsampling downsampling,\n+                                           long startTB, long endTB, Order order) throws IOException {\n+        return getTopNEntity(downsampling, indName, subQuery(indName, valueCName, startTB, endTB), order, topN);\n+    }\n+\n+    @Override\n+    public List<TopNEntity> getAllServiceInstanceTopN(String indName, String valueCName, int topN, Downsampling downsampling,\n+                                                      long startTB, long endTB, Order order) throws IOException {\n+        return getTopNEntity(downsampling, indName, subQuery(indName, valueCName, startTB, endTB), order, topN);\n+    }\n+\n+    @Override\n+    public List<TopNEntity> getServiceInstanceTopN(int serviceId, String indName, String valueCName, int topN, Downsampling downsampling,\n+                                                   long startTB, long endTB, Order order) throws IOException {\n+        return getTopNEntity(downsampling, indName, subQuery(ServiceInstanceInventory.SERVICE_ID, serviceId, indName, valueCName, startTB, endTB), order, topN);\n+    }\n+\n+    @Override\n+    public List<TopNEntity> getAllEndpointTopN(String indName, String valueCName, int topN, Downsampling downsampling,\n+                                               long startTB, long endTB, Order order) throws IOException {\n+        return getTopNEntity(downsampling, indName, subQuery(indName, valueCName, startTB, endTB), order, topN);\n+    }\n+\n+    @Override\n+    public List<TopNEntity> getEndpointTopN(int serviceId, String indName, String valueCName, int topN, Downsampling downsampling,\n+                                            long startTB, long endTB, Order order) throws IOException {\n+        return getTopNEntity(downsampling, indName, subQuery(EndpointInventory.SERVICE_ID, serviceId, indName, valueCName, startTB, endTB), order, topN);\n+    }\n+\n+    private final List<TopNEntity> getTopNEntity(Downsampling downsampling, String name, SelectSubQueryImpl<SelectQueryImpl> subQuery, Order order, int topN) throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f06435eb514cf47cc90741c475502b28b31aab03"}, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNjczNDU5OnYy", "diffSide": "RIGHT", "path": "test/e2e/e2e-influxdb/src/docker/rc.d/rc0-prepare.sh", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMToxNDozNFrOFlQcfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMToxNDozNFrOFlQcfQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDYxMTA2OQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Modify application.yml to set MySQL as storage provider.\n          \n          \n            \n            # Modify application.yml to set InfluxDB as storage provider.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r374611069", "createdAt": "2020-02-04T11:14:34Z", "author": {"login": "kezhenxu94"}, "path": "test/e2e/e2e-influxdb/src/docker/rc.d/rc0-prepare.sh", "diffHunk": "@@ -0,0 +1,21 @@\n+#!/usr/bin/env bash\n+# Licensed to the SkyAPM under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+echo \"InfluxDB with H2 database is storage provider...\"\n+\n+# Modify application.yml to set MySQL as storage provider.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f06435eb514cf47cc90741c475502b28b31aab03"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNjczNjA2OnYy", "diffSide": "RIGHT", "path": "test/e2e/e2e-influxdb/src/main/java/org/apache/skywalking/e2e/sample/client/SampleClientApplication.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMToxNTowN1rOFlQdYA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMToxNTowN1rOFlQdYA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDYxMTI5Ng==", "bodyText": "remove the @authors please", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r374611296", "createdAt": "2020-02-04T11:15:07Z", "author": {"login": "kezhenxu94"}, "path": "test/e2e/e2e-influxdb/src/main/java/org/apache/skywalking/e2e/sample/client/SampleClientApplication.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.e2e.sample.client;\n+\n+import org.springframework.boot.SpringApplication;\n+import org.springframework.boot.autoconfigure.SpringBootApplication;\n+import org.springframework.data.jpa.repository.config.EnableJpaRepositories;\n+\n+/**\n+ * @author kezhenxu94\n+ */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f06435eb514cf47cc90741c475502b28b31aab03"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNjc0NDA2OnYy", "diffSide": "RIGHT", "path": "oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/storage/model/Model.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMToxODowNlrOFlQiWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMToxODowNlrOFlQiWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDYxMjU3MQ==", "bodyText": "why add unused method", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r374612571", "createdAt": "2020-02-04T11:18:06Z", "author": {"login": "kezhenxu94"}, "path": "oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/storage/model/Model.java", "diffHunk": "@@ -44,5 +48,11 @@ public Model(String name, List<ModelColumn> columns, boolean capableOfTimeSeries\n         this.scopeId = scopeId;\n         this.name = ModelName.build(downsampling, name);\n         this.record = record;\n+        this.storageColumns = Maps.newTreeMap();\n+        columns.forEach(column -> { storageColumns.put(column.getColumnName().getStorageName(), column); });\n+    }\n+\n+    public ModelColumn getColumnByStorageCName(String storageCName) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f06435eb514cf47cc90741c475502b28b31aab03"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNjc4NDMxOnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/pom.xml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMTozMzo1N1rOFlQ7ew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMTozMzo1N1rOFlQ7ew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDYxOTAwMw==", "bodyText": "make it a property", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r374619003", "createdAt": "2020-02-04T11:33:57Z", "author": {"login": "kezhenxu94"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/pom.xml", "diffHunk": "@@ -0,0 +1,50 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specrm ific language governing permissions and\n+  ~ limitations under the License.\n+  ~\n+  -->\n+\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <parent>\n+        <artifactId>server-storage-plugin</artifactId>\n+        <groupId>org.apache.skywalking</groupId>\n+        <version>7.0.0-SNAPSHOT</version>\n+    </parent>\n+    <modelVersion>4.0.0</modelVersion>\n+\n+    <artifactId>storage-influxdb-plugin</artifactId>\n+    <packaging>jar</packaging>\n+\n+    <dependencies>\n+        <dependency>\n+            <groupId>org.apache.skywalking</groupId>\n+            <artifactId>storage-elasticsearch-plugin</artifactId>\n+            <version>${project.version}</version>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>org.apache.skywalking</groupId>\n+            <artifactId>storage-jdbc-hikaricp-plugin</artifactId>\n+            <version>${project.version}</version>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>org.influxdb</groupId>\n+            <artifactId>influxdb-java</artifactId>\n+            <version>2.15</version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f06435eb514cf47cc90741c475502b28b31aab03"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNjc4ODQwOnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMTozNTozOVrOFlQ-CQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMTozNTozOVrOFlQ-CQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDYxOTY1Nw==", "bodyText": "use System.lineSeparator() instead of hardcoded \\r\\n", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r374619657", "createdAt": "2020-02-04T11:35:39Z", "author": {"login": "kezhenxu94"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb;\n+\n+import java.io.IOException;\n+import java.lang.invoke.MethodHandles;\n+import java.util.List;\n+import okhttp3.OkHttpClient;\n+import org.apache.skywalking.oap.server.core.analysis.Downsampling;\n+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;\n+import org.apache.skywalking.oap.server.library.client.Client;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.BatchPoints;\n+import org.influxdb.dto.Point;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.time.TimeInterval;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.ti;\n+\n+public class InfluxClient implements Client {\n+    private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+    private InfluxStorageConfig config;\n+    private InfluxDB influx;\n+\n+    public static final String TIME = \"time\";\n+    public static final String TAG_ENTITY_ID = \"entity_id\";\n+    private final String database;\n+\n+    public InfluxClient(InfluxStorageConfig config) {\n+        this.config = config;\n+        this.database = config.getDatabase();\n+    }\n+\n+    public final String getDatabase() {\n+        return database;\n+    }\n+\n+    @Override\n+    public void connect() {\n+        influx = InfluxDBFactory.connect(config.getUrl(), config.getUser(), config.getPassword(),\n+            new OkHttpClient.Builder(), InfluxDB.ResponseFormat.MSGPACK);\n+        influx.query(new Query(\"CREATE DATABASE \" + database));\n+\n+        influx.setDatabase(database);\n+        influx.enableBatch();\n+    }\n+\n+    public InfluxDB getInflux() {\n+        return influx;\n+    }\n+\n+    public List<QueryResult.Result> query(Query query) throws IOException {\n+        if (logger.isDebugEnabled()) {\n+            logger.debug(\"SQL Statement: {}\", query.getCommand());\n+        }\n+\n+        try {\n+            QueryResult result = getInflux().query(query);\n+            if (result.hasError()) {\n+                throw new IOException(result.getError());\n+            }\n+            return result.getResults();\n+        } catch (Exception e) {\n+            throw new IOException(e.getMessage() + \"\\r\\nSQL Statement: \" + query.getCommand(), e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f06435eb514cf47cc90741c475502b28b31aab03"}, "originalPosition": 84}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNjgxMjExOnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/MetricsDAO.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMTo0NTowMFrOFlRMsg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMTo0NTowMFrOFlRMsg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDYyMzQxMA==", "bodyText": "Raw use of parameterized class WhereQueryImpl", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r374623410", "createdAt": "2020-02-04T11:45:00Z", "author": {"login": "kezhenxu94"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/MetricsDAO.java", "diffHunk": "@@ -0,0 +1,95 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.base;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.skywalking.oap.server.core.analysis.metrics.Metrics;\n+import org.apache.skywalking.oap.server.core.storage.IMetricsDAO;\n+import org.apache.skywalking.oap.server.core.storage.StorageBuilder;\n+import org.apache.skywalking.oap.server.core.storage.model.Model;\n+import org.apache.skywalking.oap.server.core.storage.model.ModelColumn;\n+import org.apache.skywalking.oap.server.core.storage.type.StorageDataType;\n+import org.apache.skywalking.oap.server.library.client.request.InsertRequest;\n+import org.apache.skywalking.oap.server.library.client.request.UpdateRequest;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.WhereQueryImpl;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.contains;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.select;\n+\n+public class MetricsDAO implements IMetricsDAO {\n+    private final StorageBuilder<Metrics> storageBuilder;\n+    private final InfluxClient client;\n+\n+    public MetricsDAO(InfluxClient client, StorageBuilder<Metrics> storageBuilder) {\n+        this.client = client;\n+        this.storageBuilder = storageBuilder;\n+    }\n+\n+    @Override\n+    public List<Metrics> multiGet(Model model, List<String> ids) throws IOException {\n+        WhereQueryImpl query = select(\"*::field\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f06435eb514cf47cc90741c475502b28b31aab03"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNjkyNDc2OnYy", "diffSide": "RIGHT", "path": "tools/dependencies/known-oap-backend-dependencies-es7.txt", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMjoyNzozM1rOFlSRwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxNToyNjowMFrOFlYQbw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDY0MTA4OQ==", "bodyText": "All these dependencies licenses should be checked and LICENSE file should be updated(NOTICE should be update if the license is Apache 2.0 and there is a NOTICE existing).", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r374641089", "createdAt": "2020-02-04T12:27:33Z", "author": {"login": "wu-sheng"}, "path": "tools/dependencies/known-oap-backend-dependencies-es7.txt", "diffHunk": "@@ -159,3 +159,8 @@ sundr-core-0.9.2.jar\n swagger-annotations-1.5.12.jar\n t-digest-3.2.jar\n zookeeper-3.4.10.jar\n+converter-moshi-2.5.0.jar\n+influxdb-java-2.15.jar\n+logging-interceptor-3.13.1.jar\n+moshi-1.5.0.jar\n+msgpack-core-0.8.16.jar", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f06435eb514cf47cc90741c475502b28b31aab03"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDcwODUwNQ==", "bodyText": "I am confusing about this. So, I need to take some time to know it.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r374708505", "createdAt": "2020-02-04T14:40:07Z", "author": {"login": "dmsolr"}, "path": "tools/dependencies/known-oap-backend-dependencies-es7.txt", "diffHunk": "@@ -159,3 +159,8 @@ sundr-core-0.9.2.jar\n swagger-annotations-1.5.12.jar\n t-digest-3.2.jar\n zookeeper-3.4.10.jar\n+converter-moshi-2.5.0.jar\n+influxdb-java-2.15.jar\n+logging-interceptor-3.13.1.jar\n+moshi-1.5.0.jar\n+msgpack-core-0.8.16.jar", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDY0MTA4OQ=="}, "originalCommit": {"oid": "f06435eb514cf47cc90741c475502b28b31aab03"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDczOTA1NQ==", "bodyText": "Confused what parts? All new dependency should be added into the LICENSE, like you do for influxdb-java. You need to find the licenses for all other jars.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r374739055", "createdAt": "2020-02-04T15:26:00Z", "author": {"login": "wu-sheng"}, "path": "tools/dependencies/known-oap-backend-dependencies-es7.txt", "diffHunk": "@@ -159,3 +159,8 @@ sundr-core-0.9.2.jar\n swagger-annotations-1.5.12.jar\n t-digest-3.2.jar\n zookeeper-3.4.10.jar\n+converter-moshi-2.5.0.jar\n+influxdb-java-2.15.jar\n+logging-interceptor-3.13.1.jar\n+moshi-1.5.0.jar\n+msgpack-core-0.8.16.jar", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDY0MTA4OQ=="}, "originalCommit": {"oid": "f06435eb514cf47cc90741c475502b28b31aab03"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNjkzMTM5OnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxTTLCalculatorProvider.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMjoyOTo1OVrOFlSV0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxNDo0MDoyN1rOFlWZ3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDY0MjEyOA==", "bodyText": "There is GeneralStorageTTL existing, the influxdb implementation should be as same as that one, since it also uses the core configuration.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r374642128", "createdAt": "2020-02-04T12:29:59Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxTTLCalculatorProvider.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb;\n+\n+import org.apache.skywalking.oap.server.core.DataTTLConfig;\n+import org.apache.skywalking.oap.server.core.analysis.Downsampling;\n+import org.apache.skywalking.oap.server.library.module.ModuleDefineHolder;\n+import org.joda.time.DateTime;\n+\n+public class InfluxTTLCalculatorProvider {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f06435eb514cf47cc90741c475502b28b31aab03"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDcwODcwMQ==", "bodyText": "got it.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r374708701", "createdAt": "2020-02-04T14:40:27Z", "author": {"login": "dmsolr"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxTTLCalculatorProvider.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb;\n+\n+import org.apache.skywalking.oap.server.core.DataTTLConfig;\n+import org.apache.skywalking.oap.server.core.analysis.Downsampling;\n+import org.apache.skywalking.oap.server.library.module.ModuleDefineHolder;\n+import org.joda.time.DateTime;\n+\n+public class InfluxTTLCalculatorProvider {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDY0MjEyOA=="}, "originalCommit": {"oid": "f06435eb514cf47cc90741c475502b28b31aab03"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNzAwODc1OnYy", "diffSide": "RIGHT", "path": "oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/metrics/Metrics.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMjo1NTozMVrOFlTC4A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMjo1Njo1N1rOFlTFYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDY1MzY2NA==", "bodyText": "This class should not change and not relate to this PR, please revert.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r374653664", "createdAt": "2020-02-04T12:55:31Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/metrics/Metrics.java", "diffHunk": "@@ -32,8 +35,13 @@\n     public static final String TIME_BUCKET = \"time_bucket\";\n     public static final String ENTITY_ID = \"entity_id\";\n \n-    @Getter @Setter @Column(columnName = TIME_BUCKET) private long timeBucket;\n-    @Getter @Setter private long survivalTime = 0L;\n+    @Getter\n+    @Setter\n+    @Column(columnName = TIME_BUCKET)\n+    private long timeBucket;\n+    @Getter\n+    @Setter\n+    private long survivalTime = 0L;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f06435eb514cf47cc90741c475502b28b31aab03"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDY1NDMwNQ==", "bodyText": "Including all following changes of this class.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r374654305", "createdAt": "2020-02-04T12:56:57Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/metrics/Metrics.java", "diffHunk": "@@ -32,8 +35,13 @@\n     public static final String TIME_BUCKET = \"time_bucket\";\n     public static final String ENTITY_ID = \"entity_id\";\n \n-    @Getter @Setter @Column(columnName = TIME_BUCKET) private long timeBucket;\n-    @Getter @Setter private long survivalTime = 0L;\n+    @Getter\n+    @Setter\n+    @Column(columnName = TIME_BUCKET)\n+    private long timeBucket;\n+    @Getter\n+    @Setter\n+    private long survivalTime = 0L;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDY1MzY2NA=="}, "originalCommit": {"oid": "f06435eb514cf47cc90741c475502b28b31aab03"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNzAxNDg4OnYy", "diffSide": "RIGHT", "path": "oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/storage/model/Model.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMjo1Nzo0MVrOFlTGnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMjo1Nzo0MVrOFlTGnA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDY1NDYyMA==", "bodyText": "This should not be added.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r374654620", "createdAt": "2020-02-04T12:57:41Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/storage/model/Model.java", "diffHunk": "@@ -35,6 +38,7 @@\n     private final List<ModelColumn> columns;\n     private final int scopeId;\n     private final boolean record;\n+    private final TreeMap<String, ModelColumn> storageColumns;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f06435eb514cf47cc90741c475502b28b31aab03"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNzAxNjUzOnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/BatchDAO.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMjo1ODoxNFrOFlTHlQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMjo1ODoxNFrOFlTHlQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDY1NDg2OQ==", "bodyText": "This file format seems not right.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r374654869", "createdAt": "2020-02-04T12:58:14Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/BatchDAO.java", "diffHunk": "@@ -0,0 +1,107 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.base;\n+\n+import org.apache.skywalking.apm.commons.datacarrier.DataCarrier;\n+import org.apache.skywalking.apm.commons.datacarrier.consumer.BulkConsumePool;\n+import org.apache.skywalking.apm.commons.datacarrier.consumer.ConsumerPoolFactory;\n+import org.apache.skywalking.apm.commons.datacarrier.consumer.IConsumer;\n+import org.apache.skywalking.oap.server.core.UnexpectedException;\n+import org.apache.skywalking.oap.server.core.storage.IBatchDAO;\n+import org.apache.skywalking.oap.server.library.client.request.InsertRequest;\n+import org.apache.skywalking.oap.server.library.client.request.PrepareRequest;\n+import org.apache.skywalking.oap.server.library.util.CollectionUtils;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.influxdb.dto.BatchPoints;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.List;\n+\n+public class  BatchDAO implements IBatchDAO {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f06435eb514cf47cc90741c475502b28b31aab03"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNzA0MzQxOnYy", "diffSide": "RIGHT", "path": "oap-server/server-bootstrap/src/main/resources/application.yml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMzowNzo1NlrOFlTX1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxMzowNzo1NlrOFlTX1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDY1OTAyOA==", "bodyText": "This shouldn't be changed. If start in IDE, we keep in ES", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r374659028", "createdAt": "2020-02-04T13:07:56Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-bootstrap/src/main/resources/application.yml", "diffHunk": "@@ -98,33 +98,33 @@ storage:\n #    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n #    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n #    advanced: ${SW_STORAGE_ES_ADVANCED:\"\"}\n-  elasticsearch7:\n-    nameSpace: ${SW_NAMESPACE:\"\"}\n-    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n-    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n-    #trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n-    #trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n-    user: ${SW_ES_USER:\"\"}\n-    password: ${SW_ES_PASSWORD:\"\"}\n-    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n-    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n-    # Those data TTL settings will override the same settings in core module.\n-    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n-    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n-    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n-    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n-    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n-    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n-    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n-    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n-    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n-    advanced: ${SW_STORAGE_ES_ADVANCED:\"\"}\n-#  h2:\n-#    driver: ${SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource}\n-#    url: ${SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db}\n-#    user: ${SW_STORAGE_H2_USER:sa}\n-#    metadataQueryMaxSize: ${SW_STORAGE_H2_QUERY_MAX_SIZE:5000}\n+#  elasticsearch7:\n+#    nameSpace: ${SW_NAMESPACE:\"\"}\n+#    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n+#    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n+#    #trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n+#    #trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n+#    user: ${SW_ES_USER:\"\"}\n+#    password: ${SW_ES_PASSWORD:\"\"}\n+#    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n+#    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n+#    # Those data TTL settings will override the same settings in core module.\n+#    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n+#    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n+#    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n+#    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n+#    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n+#    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n+#    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n+#    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n+#    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n+#    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n+#    advanced: ${SW_STORAGE_ES_ADVANCED:\"\"}\n+  h2:\n+    driver: ${SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource}\n+    url: ${SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db}\n+    user: ${SW_STORAGE_H2_USER:sa}\n+    metadataQueryMaxSize: ${SW_STORAGE_H2_QUERY_MAX_SIZE:5000}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f06435eb514cf47cc90741c475502b28b31aab03"}, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxOTY1NDM3OnYy", "diffSide": "RIGHT", "path": "oap-server/server-bootstrap/src/main/resources/application.yml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwNTo1OTozNFrOFlslaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwNTo1OTozNFrOFlslaQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTA3MjEwNQ==", "bodyText": "These formats are still changed.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r375072105", "createdAt": "2020-02-05T05:59:34Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-bootstrap/src/main/resources/application.yml", "diffHunk": "@@ -75,29 +75,29 @@ core:\n     enableDatabaseSession: ${SW_CORE_ENABLE_DATABASE_SESSION:true}\n     topNReportPeriod: ${SW_CORE_TOPN_REPORT_PERIOD:10} # top_n record worker report cycle, unit is minute\n storage:\n-#  elasticsearch:\n-#    nameSpace: ${SW_NAMESPACE:\"\"}\n-#    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n-#    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n-#    #trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n-#    #trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n-#    user: ${SW_ES_USER:\"\"}\n-#    password: ${SW_ES_PASSWORD:\"\"}\n-#    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n-#    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n-#    # Those data TTL settings will override the same settings in core module.\n-#    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n-#    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n-#    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-#    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n-#    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n-#    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n-#    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n-#    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n-#    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n-#    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n-#    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n-#    advanced: ${SW_STORAGE_ES_ADVANCED:\"\"}\n+  #  elasticsearch:\n+  #    nameSpace: ${SW_NAMESPACE:\"\"}\n+  #    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n+  #    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n+  #    #trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n+  #    #trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n+  #    user: ${SW_ES_USER:\"\"}\n+  #    password: ${SW_ES_PASSWORD:\"\"}\n+  #    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n+  #    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n+  #    # Those data TTL settings will override the same settings in core module.\n+  #    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n+  #    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n+  #    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n+  #    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n+  #    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n+  #    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n+  #    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n+  #    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n+  #    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n+  #    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n+  #    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n+  #    advanced: ${SW_STORAGE_ES_ADVANCED:\"\"}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58587c88ce1e34be64ff2b418afda02bc1cfa5ca"}, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxOTk1MTEwOnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwODozNDo0MVrOFlvYJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwODozNDo0MVrOFlvYJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTExNzg2MQ==", "bodyText": "Empty comment?", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r375117861", "createdAt": "2020-02-05T08:34:41Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb;\n+\n+import java.io.IOException;\n+import java.lang.invoke.MethodHandles;\n+import java.util.List;\n+import okhttp3.OkHttpClient;\n+import org.apache.skywalking.oap.server.core.analysis.Downsampling;\n+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;\n+import org.apache.skywalking.oap.server.library.client.Client;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.BatchPoints;\n+import org.influxdb.dto.Point;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.time.TimeInterval;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.ti;\n+\n+/**\n+ *", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "748dce814b1567ec1d1d5878de91b2891e7a75b7"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxOTk1NjExOnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "isResolved": true, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwODozNjozNVrOFlvbOA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QwODoxMTowMlrOFm1Ezg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTExODY0OA==", "bodyText": "What does this #get(0) represent?", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r375118648", "createdAt": "2020-02-05T08:36:35Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb;\n+\n+import java.io.IOException;\n+import java.lang.invoke.MethodHandles;\n+import java.util.List;\n+import okhttp3.OkHttpClient;\n+import org.apache.skywalking.oap.server.core.analysis.Downsampling;\n+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;\n+import org.apache.skywalking.oap.server.library.client.Client;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.BatchPoints;\n+import org.influxdb.dto.Point;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.time.TimeInterval;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.ti;\n+\n+/**\n+ *\n+ */\n+public class InfluxClient implements Client {\n+    private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+    private InfluxStorageConfig config;\n+    private InfluxDB influx;\n+\n+    /**\n+     * A constant, the name of time field in Time-series database.\n+     */\n+    public static final String TIME = \"time\";\n+    /**\n+     * A constant, the name of tag.\n+     */\n+    public static final String TAG_ENTITY_ID = \"entity_id\";\n+\n+    private final String database;\n+\n+    public InfluxClient(InfluxStorageConfig config) {\n+        this.config = config;\n+        this.database = config.getDatabase();\n+    }\n+\n+    public final String getDatabase() {\n+        return database;\n+    }\n+\n+    @Override\n+    public void connect() {\n+        influx = InfluxDBFactory.connect(config.getUrl(), config.getUser(), config.getPassword(),\n+            new OkHttpClient.Builder(), InfluxDB.ResponseFormat.MSGPACK);\n+        influx.query(new Query(\"CREATE DATABASE \" + database));\n+\n+        influx.setDatabase(database);\n+        influx.enableBatch();\n+    }\n+\n+    /**\n+     * To get a connection of InfluxDB\n+     *\n+     * @return InfluxDB's connection\n+     */\n+    public InfluxDB getInflux() {\n+        return influx;\n+    }\n+\n+    /**\n+     * Request with a {@link Query} to InfluxDB and return a set of {@link QueryResult.Result}s.\n+     *\n+     * @param query\n+     * @return a set of Result.\n+     * @throws IOException\n+     */\n+    public List<QueryResult.Result> query(Query query) throws IOException {\n+        if (logger.isDebugEnabled()) {\n+            logger.debug(\"SQL Statement: {}\", query.getCommand());\n+        }\n+\n+        try {\n+            QueryResult result = getInflux().query(query);\n+            if (result.hasError()) {\n+                throw new IOException(result.getError());\n+            }\n+            return result.getResults();\n+        } catch (Exception e) {\n+            throw new IOException(e.getMessage() + System.lineSeparator() + \"SQL Statement: \" + query.getCommand(), e);\n+        }\n+    }\n+\n+    /**\n+     * Request with one statement to InfluxDB and return a set of {@link QueryResult.Series}s.\n+     *\n+     * @param query\n+     * @return a set of Series\n+     * @throws IOException\n+     */\n+    public List<QueryResult.Series> queryForSeries(Query query) throws IOException {\n+        return query(query).get(0).getSeries();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "748dce814b1567ec1d1d5878de91b2891e7a75b7"}, "originalPosition": 118}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTEyODY4OQ==", "bodyText": "InfluxDB support user to send a request with multi statements. This is for a single statement in a request(query).\nSo, #get(0) means get the first result of the query.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r375128689", "createdAt": "2020-02-05T08:58:53Z", "author": {"login": "dmsolr"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb;\n+\n+import java.io.IOException;\n+import java.lang.invoke.MethodHandles;\n+import java.util.List;\n+import okhttp3.OkHttpClient;\n+import org.apache.skywalking.oap.server.core.analysis.Downsampling;\n+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;\n+import org.apache.skywalking.oap.server.library.client.Client;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.BatchPoints;\n+import org.influxdb.dto.Point;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.time.TimeInterval;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.ti;\n+\n+/**\n+ *\n+ */\n+public class InfluxClient implements Client {\n+    private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+    private InfluxStorageConfig config;\n+    private InfluxDB influx;\n+\n+    /**\n+     * A constant, the name of time field in Time-series database.\n+     */\n+    public static final String TIME = \"time\";\n+    /**\n+     * A constant, the name of tag.\n+     */\n+    public static final String TAG_ENTITY_ID = \"entity_id\";\n+\n+    private final String database;\n+\n+    public InfluxClient(InfluxStorageConfig config) {\n+        this.config = config;\n+        this.database = config.getDatabase();\n+    }\n+\n+    public final String getDatabase() {\n+        return database;\n+    }\n+\n+    @Override\n+    public void connect() {\n+        influx = InfluxDBFactory.connect(config.getUrl(), config.getUser(), config.getPassword(),\n+            new OkHttpClient.Builder(), InfluxDB.ResponseFormat.MSGPACK);\n+        influx.query(new Query(\"CREATE DATABASE \" + database));\n+\n+        influx.setDatabase(database);\n+        influx.enableBatch();\n+    }\n+\n+    /**\n+     * To get a connection of InfluxDB\n+     *\n+     * @return InfluxDB's connection\n+     */\n+    public InfluxDB getInflux() {\n+        return influx;\n+    }\n+\n+    /**\n+     * Request with a {@link Query} to InfluxDB and return a set of {@link QueryResult.Result}s.\n+     *\n+     * @param query\n+     * @return a set of Result.\n+     * @throws IOException\n+     */\n+    public List<QueryResult.Result> query(Query query) throws IOException {\n+        if (logger.isDebugEnabled()) {\n+            logger.debug(\"SQL Statement: {}\", query.getCommand());\n+        }\n+\n+        try {\n+            QueryResult result = getInflux().query(query);\n+            if (result.hasError()) {\n+                throw new IOException(result.getError());\n+            }\n+            return result.getResults();\n+        } catch (Exception e) {\n+            throw new IOException(e.getMessage() + System.lineSeparator() + \"SQL Statement: \" + query.getCommand(), e);\n+        }\n+    }\n+\n+    /**\n+     * Request with one statement to InfluxDB and return a set of {@link QueryResult.Series}s.\n+     *\n+     * @param query\n+     * @return a set of Series\n+     * @throws IOException\n+     */\n+    public List<QueryResult.Series> queryForSeries(Query query) throws IOException {\n+        return query(query).get(0).getSeries();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTExODY0OA=="}, "originalCommit": {"oid": "748dce814b1567ec1d1d5878de91b2891e7a75b7"}, "originalPosition": 118}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTEzMTE2Ng==", "bodyText": "Do we use multiple statements? I think #get(0) should be included #query(return series). If we have multiple stat case, we should have a different API.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r375131166", "createdAt": "2020-02-05T09:04:20Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb;\n+\n+import java.io.IOException;\n+import java.lang.invoke.MethodHandles;\n+import java.util.List;\n+import okhttp3.OkHttpClient;\n+import org.apache.skywalking.oap.server.core.analysis.Downsampling;\n+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;\n+import org.apache.skywalking.oap.server.library.client.Client;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.BatchPoints;\n+import org.influxdb.dto.Point;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.time.TimeInterval;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.ti;\n+\n+/**\n+ *\n+ */\n+public class InfluxClient implements Client {\n+    private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+    private InfluxStorageConfig config;\n+    private InfluxDB influx;\n+\n+    /**\n+     * A constant, the name of time field in Time-series database.\n+     */\n+    public static final String TIME = \"time\";\n+    /**\n+     * A constant, the name of tag.\n+     */\n+    public static final String TAG_ENTITY_ID = \"entity_id\";\n+\n+    private final String database;\n+\n+    public InfluxClient(InfluxStorageConfig config) {\n+        this.config = config;\n+        this.database = config.getDatabase();\n+    }\n+\n+    public final String getDatabase() {\n+        return database;\n+    }\n+\n+    @Override\n+    public void connect() {\n+        influx = InfluxDBFactory.connect(config.getUrl(), config.getUser(), config.getPassword(),\n+            new OkHttpClient.Builder(), InfluxDB.ResponseFormat.MSGPACK);\n+        influx.query(new Query(\"CREATE DATABASE \" + database));\n+\n+        influx.setDatabase(database);\n+        influx.enableBatch();\n+    }\n+\n+    /**\n+     * To get a connection of InfluxDB\n+     *\n+     * @return InfluxDB's connection\n+     */\n+    public InfluxDB getInflux() {\n+        return influx;\n+    }\n+\n+    /**\n+     * Request with a {@link Query} to InfluxDB and return a set of {@link QueryResult.Result}s.\n+     *\n+     * @param query\n+     * @return a set of Result.\n+     * @throws IOException\n+     */\n+    public List<QueryResult.Result> query(Query query) throws IOException {\n+        if (logger.isDebugEnabled()) {\n+            logger.debug(\"SQL Statement: {}\", query.getCommand());\n+        }\n+\n+        try {\n+            QueryResult result = getInflux().query(query);\n+            if (result.hasError()) {\n+                throw new IOException(result.getError());\n+            }\n+            return result.getResults();\n+        } catch (Exception e) {\n+            throw new IOException(e.getMessage() + System.lineSeparator() + \"SQL Statement: \" + query.getCommand(), e);\n+        }\n+    }\n+\n+    /**\n+     * Request with one statement to InfluxDB and return a set of {@link QueryResult.Series}s.\n+     *\n+     * @param query\n+     * @return a set of Series\n+     * @throws IOException\n+     */\n+    public List<QueryResult.Series> queryForSeries(Query query) throws IOException {\n+        return query(query).get(0).getSeries();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTExODY0OA=="}, "originalCommit": {"oid": "748dce814b1567ec1d1d5878de91b2891e7a75b7"}, "originalPosition": 118}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTE5MDk4Mw==", "bodyText": "Yes.\nIn ITraceQueryDAO#queryBasicTraces(...), we have 2 statements in a request. The one gets the number of traces, and another recalls all trace data.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r375190983", "createdAt": "2020-02-05T11:03:04Z", "author": {"login": "dmsolr"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb;\n+\n+import java.io.IOException;\n+import java.lang.invoke.MethodHandles;\n+import java.util.List;\n+import okhttp3.OkHttpClient;\n+import org.apache.skywalking.oap.server.core.analysis.Downsampling;\n+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;\n+import org.apache.skywalking.oap.server.library.client.Client;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.BatchPoints;\n+import org.influxdb.dto.Point;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.time.TimeInterval;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.ti;\n+\n+/**\n+ *\n+ */\n+public class InfluxClient implements Client {\n+    private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+    private InfluxStorageConfig config;\n+    private InfluxDB influx;\n+\n+    /**\n+     * A constant, the name of time field in Time-series database.\n+     */\n+    public static final String TIME = \"time\";\n+    /**\n+     * A constant, the name of tag.\n+     */\n+    public static final String TAG_ENTITY_ID = \"entity_id\";\n+\n+    private final String database;\n+\n+    public InfluxClient(InfluxStorageConfig config) {\n+        this.config = config;\n+        this.database = config.getDatabase();\n+    }\n+\n+    public final String getDatabase() {\n+        return database;\n+    }\n+\n+    @Override\n+    public void connect() {\n+        influx = InfluxDBFactory.connect(config.getUrl(), config.getUser(), config.getPassword(),\n+            new OkHttpClient.Builder(), InfluxDB.ResponseFormat.MSGPACK);\n+        influx.query(new Query(\"CREATE DATABASE \" + database));\n+\n+        influx.setDatabase(database);\n+        influx.enableBatch();\n+    }\n+\n+    /**\n+     * To get a connection of InfluxDB\n+     *\n+     * @return InfluxDB's connection\n+     */\n+    public InfluxDB getInflux() {\n+        return influx;\n+    }\n+\n+    /**\n+     * Request with a {@link Query} to InfluxDB and return a set of {@link QueryResult.Result}s.\n+     *\n+     * @param query\n+     * @return a set of Result.\n+     * @throws IOException\n+     */\n+    public List<QueryResult.Result> query(Query query) throws IOException {\n+        if (logger.isDebugEnabled()) {\n+            logger.debug(\"SQL Statement: {}\", query.getCommand());\n+        }\n+\n+        try {\n+            QueryResult result = getInflux().query(query);\n+            if (result.hasError()) {\n+                throw new IOException(result.getError());\n+            }\n+            return result.getResults();\n+        } catch (Exception e) {\n+            throw new IOException(e.getMessage() + System.lineSeparator() + \"SQL Statement: \" + query.getCommand(), e);\n+        }\n+    }\n+\n+    /**\n+     * Request with one statement to InfluxDB and return a set of {@link QueryResult.Series}s.\n+     *\n+     * @param query\n+     * @return a set of Series\n+     * @throws IOException\n+     */\n+    public List<QueryResult.Series> queryForSeries(Query query) throws IOException {\n+        return query(query).get(0).getSeries();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTExODY0OA=="}, "originalCommit": {"oid": "748dce814b1567ec1d1d5878de91b2891e7a75b7"}, "originalPosition": 118}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTIyOTcyOQ==", "bodyText": "Could we add a #singleStatementQuery method for most cases?", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r375229729", "createdAt": "2020-02-05T12:35:32Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb;\n+\n+import java.io.IOException;\n+import java.lang.invoke.MethodHandles;\n+import java.util.List;\n+import okhttp3.OkHttpClient;\n+import org.apache.skywalking.oap.server.core.analysis.Downsampling;\n+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;\n+import org.apache.skywalking.oap.server.library.client.Client;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.BatchPoints;\n+import org.influxdb.dto.Point;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.time.TimeInterval;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.ti;\n+\n+/**\n+ *\n+ */\n+public class InfluxClient implements Client {\n+    private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+    private InfluxStorageConfig config;\n+    private InfluxDB influx;\n+\n+    /**\n+     * A constant, the name of time field in Time-series database.\n+     */\n+    public static final String TIME = \"time\";\n+    /**\n+     * A constant, the name of tag.\n+     */\n+    public static final String TAG_ENTITY_ID = \"entity_id\";\n+\n+    private final String database;\n+\n+    public InfluxClient(InfluxStorageConfig config) {\n+        this.config = config;\n+        this.database = config.getDatabase();\n+    }\n+\n+    public final String getDatabase() {\n+        return database;\n+    }\n+\n+    @Override\n+    public void connect() {\n+        influx = InfluxDBFactory.connect(config.getUrl(), config.getUser(), config.getPassword(),\n+            new OkHttpClient.Builder(), InfluxDB.ResponseFormat.MSGPACK);\n+        influx.query(new Query(\"CREATE DATABASE \" + database));\n+\n+        influx.setDatabase(database);\n+        influx.enableBatch();\n+    }\n+\n+    /**\n+     * To get a connection of InfluxDB\n+     *\n+     * @return InfluxDB's connection\n+     */\n+    public InfluxDB getInflux() {\n+        return influx;\n+    }\n+\n+    /**\n+     * Request with a {@link Query} to InfluxDB and return a set of {@link QueryResult.Result}s.\n+     *\n+     * @param query\n+     * @return a set of Result.\n+     * @throws IOException\n+     */\n+    public List<QueryResult.Result> query(Query query) throws IOException {\n+        if (logger.isDebugEnabled()) {\n+            logger.debug(\"SQL Statement: {}\", query.getCommand());\n+        }\n+\n+        try {\n+            QueryResult result = getInflux().query(query);\n+            if (result.hasError()) {\n+                throw new IOException(result.getError());\n+            }\n+            return result.getResults();\n+        } catch (Exception e) {\n+            throw new IOException(e.getMessage() + System.lineSeparator() + \"SQL Statement: \" + query.getCommand(), e);\n+        }\n+    }\n+\n+    /**\n+     * Request with one statement to InfluxDB and return a set of {@link QueryResult.Series}s.\n+     *\n+     * @param query\n+     * @return a set of Series\n+     * @throws IOException\n+     */\n+    public List<QueryResult.Series> queryForSeries(Query query) throws IOException {\n+        return query(query).get(0).getSeries();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTExODY0OA=="}, "originalCommit": {"oid": "748dce814b1567ec1d1d5878de91b2891e7a75b7"}, "originalPosition": 118}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjI1OTc5MA==", "bodyText": "Sorry, I make a mistake. This method works for single statement. InfluxClient#query() is for multi-statements", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r376259790", "createdAt": "2020-02-07T08:11:02Z", "author": {"login": "dmsolr"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb;\n+\n+import java.io.IOException;\n+import java.lang.invoke.MethodHandles;\n+import java.util.List;\n+import okhttp3.OkHttpClient;\n+import org.apache.skywalking.oap.server.core.analysis.Downsampling;\n+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;\n+import org.apache.skywalking.oap.server.library.client.Client;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.BatchPoints;\n+import org.influxdb.dto.Point;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.time.TimeInterval;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.ti;\n+\n+/**\n+ *\n+ */\n+public class InfluxClient implements Client {\n+    private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+    private InfluxStorageConfig config;\n+    private InfluxDB influx;\n+\n+    /**\n+     * A constant, the name of time field in Time-series database.\n+     */\n+    public static final String TIME = \"time\";\n+    /**\n+     * A constant, the name of tag.\n+     */\n+    public static final String TAG_ENTITY_ID = \"entity_id\";\n+\n+    private final String database;\n+\n+    public InfluxClient(InfluxStorageConfig config) {\n+        this.config = config;\n+        this.database = config.getDatabase();\n+    }\n+\n+    public final String getDatabase() {\n+        return database;\n+    }\n+\n+    @Override\n+    public void connect() {\n+        influx = InfluxDBFactory.connect(config.getUrl(), config.getUser(), config.getPassword(),\n+            new OkHttpClient.Builder(), InfluxDB.ResponseFormat.MSGPACK);\n+        influx.query(new Query(\"CREATE DATABASE \" + database));\n+\n+        influx.setDatabase(database);\n+        influx.enableBatch();\n+    }\n+\n+    /**\n+     * To get a connection of InfluxDB\n+     *\n+     * @return InfluxDB's connection\n+     */\n+    public InfluxDB getInflux() {\n+        return influx;\n+    }\n+\n+    /**\n+     * Request with a {@link Query} to InfluxDB and return a set of {@link QueryResult.Result}s.\n+     *\n+     * @param query\n+     * @return a set of Result.\n+     * @throws IOException\n+     */\n+    public List<QueryResult.Result> query(Query query) throws IOException {\n+        if (logger.isDebugEnabled()) {\n+            logger.debug(\"SQL Statement: {}\", query.getCommand());\n+        }\n+\n+        try {\n+            QueryResult result = getInflux().query(query);\n+            if (result.hasError()) {\n+                throw new IOException(result.getError());\n+            }\n+            return result.getResults();\n+        } catch (Exception e) {\n+            throw new IOException(e.getMessage() + System.lineSeparator() + \"SQL Statement: \" + query.getCommand(), e);\n+        }\n+    }\n+\n+    /**\n+     * Request with one statement to InfluxDB and return a set of {@link QueryResult.Series}s.\n+     *\n+     * @param query\n+     * @return a set of Series\n+     * @throws IOException\n+     */\n+    public List<QueryResult.Series> queryForSeries(Query query) throws IOException {\n+        return query(query).get(0).getSeries();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTExODY0OA=="}, "originalCommit": {"oid": "748dce814b1567ec1d1d5878de91b2891e7a75b7"}, "originalPosition": 118}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxOTk2Mzc3OnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwODozOToyN1rOFlvgAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwODo1OToxOVrOFlwDQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTExOTg3Mg==", "bodyText": "Don't see anyone uses this. Please confirm. And queryForDelete is not a good idea. For time-series data, it is better to delete by time bucket only.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r375119872", "createdAt": "2020-02-05T08:39:27Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb;\n+\n+import java.io.IOException;\n+import java.lang.invoke.MethodHandles;\n+import java.util.List;\n+import okhttp3.OkHttpClient;\n+import org.apache.skywalking.oap.server.core.analysis.Downsampling;\n+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;\n+import org.apache.skywalking.oap.server.library.client.Client;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.BatchPoints;\n+import org.influxdb.dto.Point;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.time.TimeInterval;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.ti;\n+\n+/**\n+ *\n+ */\n+public class InfluxClient implements Client {\n+    private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+    private InfluxStorageConfig config;\n+    private InfluxDB influx;\n+\n+    /**\n+     * A constant, the name of time field in Time-series database.\n+     */\n+    public static final String TIME = \"time\";\n+    /**\n+     * A constant, the name of tag.\n+     */\n+    public static final String TAG_ENTITY_ID = \"entity_id\";\n+\n+    private final String database;\n+\n+    public InfluxClient(InfluxStorageConfig config) {\n+        this.config = config;\n+        this.database = config.getDatabase();\n+    }\n+\n+    public final String getDatabase() {\n+        return database;\n+    }\n+\n+    @Override\n+    public void connect() {\n+        influx = InfluxDBFactory.connect(config.getUrl(), config.getUser(), config.getPassword(),\n+            new OkHttpClient.Builder(), InfluxDB.ResponseFormat.MSGPACK);\n+        influx.query(new Query(\"CREATE DATABASE \" + database));\n+\n+        influx.setDatabase(database);\n+        influx.enableBatch();\n+    }\n+\n+    /**\n+     * To get a connection of InfluxDB\n+     *\n+     * @return InfluxDB's connection\n+     */\n+    public InfluxDB getInflux() {\n+        return influx;\n+    }\n+\n+    /**\n+     * Request with a {@link Query} to InfluxDB and return a set of {@link QueryResult.Result}s.\n+     *\n+     * @param query\n+     * @return a set of Result.\n+     * @throws IOException\n+     */\n+    public List<QueryResult.Result> query(Query query) throws IOException {\n+        if (logger.isDebugEnabled()) {\n+            logger.debug(\"SQL Statement: {}\", query.getCommand());\n+        }\n+\n+        try {\n+            QueryResult result = getInflux().query(query);\n+            if (result.hasError()) {\n+                throw new IOException(result.getError());\n+            }\n+            return result.getResults();\n+        } catch (Exception e) {\n+            throw new IOException(e.getMessage() + System.lineSeparator() + \"SQL Statement: \" + query.getCommand(), e);\n+        }\n+    }\n+\n+    /**\n+     * Request with one statement to InfluxDB and return a set of {@link QueryResult.Series}s.\n+     *\n+     * @param query\n+     * @return a set of Series\n+     * @throws IOException\n+     */\n+    public List<QueryResult.Series> queryForSeries(Query query) throws IOException {\n+        return query(query).get(0).getSeries();\n+    }\n+\n+    /**\n+     * Data management, to drop a time-series by measurement and time-series name specified. If an exception isn't\n+     * thrown, it means execution success.\n+     *\n+     * @param measurement\n+     * @param timeBucket\n+     * @throws IOException\n+     */\n+    public void dropSeries(String measurement, long timeBucket) throws IOException {\n+        Query query = new Query(\"DROP SERIES FROM \" + measurement + \" WHERE time_bucket='\" + timeBucket + \"'\");\n+        QueryResult result = getInflux().query(query);\n+\n+        if (result.hasError()) {\n+            throw new IOException(\"Statement: \" + query.getCommand() + \", ErrorMsg: \" + result.getError());\n+        }\n+    }\n+\n+    /**\n+     * Data management, to delete data by a statement. If an exception isn't thrown, it means execution success.\n+     *\n+     * @param statement\n+     * @throws IOException\n+     */\n+    public void queryForDelete(String statement) throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "748dce814b1567ec1d1d5878de91b2891e7a75b7"}, "originalPosition": 144}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTEyODg5OA==", "bodyText": "Yes, I will remove", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r375128898", "createdAt": "2020-02-05T08:59:19Z", "author": {"login": "dmsolr"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb;\n+\n+import java.io.IOException;\n+import java.lang.invoke.MethodHandles;\n+import java.util.List;\n+import okhttp3.OkHttpClient;\n+import org.apache.skywalking.oap.server.core.analysis.Downsampling;\n+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;\n+import org.apache.skywalking.oap.server.library.client.Client;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.BatchPoints;\n+import org.influxdb.dto.Point;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.time.TimeInterval;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.ti;\n+\n+/**\n+ *\n+ */\n+public class InfluxClient implements Client {\n+    private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+    private InfluxStorageConfig config;\n+    private InfluxDB influx;\n+\n+    /**\n+     * A constant, the name of time field in Time-series database.\n+     */\n+    public static final String TIME = \"time\";\n+    /**\n+     * A constant, the name of tag.\n+     */\n+    public static final String TAG_ENTITY_ID = \"entity_id\";\n+\n+    private final String database;\n+\n+    public InfluxClient(InfluxStorageConfig config) {\n+        this.config = config;\n+        this.database = config.getDatabase();\n+    }\n+\n+    public final String getDatabase() {\n+        return database;\n+    }\n+\n+    @Override\n+    public void connect() {\n+        influx = InfluxDBFactory.connect(config.getUrl(), config.getUser(), config.getPassword(),\n+            new OkHttpClient.Builder(), InfluxDB.ResponseFormat.MSGPACK);\n+        influx.query(new Query(\"CREATE DATABASE \" + database));\n+\n+        influx.setDatabase(database);\n+        influx.enableBatch();\n+    }\n+\n+    /**\n+     * To get a connection of InfluxDB\n+     *\n+     * @return InfluxDB's connection\n+     */\n+    public InfluxDB getInflux() {\n+        return influx;\n+    }\n+\n+    /**\n+     * Request with a {@link Query} to InfluxDB and return a set of {@link QueryResult.Result}s.\n+     *\n+     * @param query\n+     * @return a set of Result.\n+     * @throws IOException\n+     */\n+    public List<QueryResult.Result> query(Query query) throws IOException {\n+        if (logger.isDebugEnabled()) {\n+            logger.debug(\"SQL Statement: {}\", query.getCommand());\n+        }\n+\n+        try {\n+            QueryResult result = getInflux().query(query);\n+            if (result.hasError()) {\n+                throw new IOException(result.getError());\n+            }\n+            return result.getResults();\n+        } catch (Exception e) {\n+            throw new IOException(e.getMessage() + System.lineSeparator() + \"SQL Statement: \" + query.getCommand(), e);\n+        }\n+    }\n+\n+    /**\n+     * Request with one statement to InfluxDB and return a set of {@link QueryResult.Series}s.\n+     *\n+     * @param query\n+     * @return a set of Series\n+     * @throws IOException\n+     */\n+    public List<QueryResult.Series> queryForSeries(Query query) throws IOException {\n+        return query(query).get(0).getSeries();\n+    }\n+\n+    /**\n+     * Data management, to drop a time-series by measurement and time-series name specified. If an exception isn't\n+     * thrown, it means execution success.\n+     *\n+     * @param measurement\n+     * @param timeBucket\n+     * @throws IOException\n+     */\n+    public void dropSeries(String measurement, long timeBucket) throws IOException {\n+        Query query = new Query(\"DROP SERIES FROM \" + measurement + \" WHERE time_bucket='\" + timeBucket + \"'\");\n+        QueryResult result = getInflux().query(query);\n+\n+        if (result.hasError()) {\n+            throw new IOException(\"Statement: \" + query.getCommand() + \", ErrorMsg: \" + result.getError());\n+        }\n+    }\n+\n+    /**\n+     * Data management, to delete data by a statement. If an exception isn't thrown, it means execution success.\n+     *\n+     * @param statement\n+     * @throws IOException\n+     */\n+    public void queryForDelete(String statement) throws IOException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTExOTg3Mg=="}, "originalCommit": {"oid": "748dce814b1567ec1d1d5878de91b2891e7a75b7"}, "originalPosition": 144}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxOTk2NTgzOnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxStorageConfig.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwODo0MDoxNlrOFlvhWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwODo0MDoxNlrOFlvhWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTEyMDIxNg==", "bodyText": "Comments are required.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r375120216", "createdAt": "2020-02-05T08:40:16Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxStorageConfig.java", "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb;\n+\n+import lombok.Getter;\n+import lombok.Setter;\n+import org.apache.skywalking.oap.server.library.module.ModuleConfig;\n+\n+@Setter\n+@Getter\n+public class InfluxStorageConfig extends ModuleConfig {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "748dce814b1567ec1d1d5878de91b2891e7a75b7"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxOTk3MjgyOnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/BatchDAO.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwODo0Mjo1MlrOFlvlnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QwODoyMjozM1rOFm1VrQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTEyMTMwOA==", "bodyText": "Is this a blocking write? Meaning, the data is queryable when this method finished.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r375121308", "createdAt": "2020-02-05T08:42:52Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/BatchDAO.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.base;\n+\n+import java.util.List;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.skywalking.apm.commons.datacarrier.DataCarrier;\n+import org.apache.skywalking.apm.commons.datacarrier.consumer.BulkConsumePool;\n+import org.apache.skywalking.apm.commons.datacarrier.consumer.ConsumerPoolFactory;\n+import org.apache.skywalking.apm.commons.datacarrier.consumer.IConsumer;\n+import org.apache.skywalking.oap.server.core.UnexpectedException;\n+import org.apache.skywalking.oap.server.core.storage.IBatchDAO;\n+import org.apache.skywalking.oap.server.library.client.request.InsertRequest;\n+import org.apache.skywalking.oap.server.library.client.request.PrepareRequest;\n+import org.apache.skywalking.oap.server.library.util.CollectionUtils;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.influxdb.dto.BatchPoints;\n+\n+@Slf4j\n+public class BatchDAO implements IBatchDAO {\n+    private final DataCarrier<PrepareRequest> dataCarrier;\n+    private final InfluxClient client;\n+\n+    public BatchDAO(InfluxClient client) {\n+        this.client = client;\n+\n+        String name = \"INFLUX_ASYNC_BATCH_PERSISTENT\";\n+        BulkConsumePool.Creator creator = new BulkConsumePool.Creator(name, 1, 20L);\n+\n+        try {\n+            ConsumerPoolFactory.INSTANCE.createIfAbsent(name, creator);\n+        } catch (Exception e) {\n+            throw new UnexpectedException(e.getMessage(), e);\n+        }\n+\n+        this.dataCarrier = new DataCarrier(1, 10000);\n+        this.dataCarrier.consume(ConsumerPoolFactory.INSTANCE.get(name), new InfluxBatchConsumer(this));\n+    }\n+\n+    @Override\n+    public void asynchronous(InsertRequest insertRequest) {\n+        dataCarrier.produce(insertRequest);\n+    }\n+\n+    @Override\n+    public void synchronous(List<PrepareRequest> prepareRequests) {\n+        if (CollectionUtils.isEmpty(prepareRequests)) {\n+            return;\n+        }\n+\n+        if (log.isDebugEnabled()) {\n+            log.debug(\"batch sql statements execute, data size: {}\", prepareRequests.size());\n+        }\n+\n+        final BatchPoints.Builder builder = BatchPoints.builder();\n+        prepareRequests.forEach(e -> {\n+            builder.point(((InfluxInsertRequest)e).getPoint());\n+        });\n+\n+        client.write(builder.build());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "748dce814b1567ec1d1d5878de91b2891e7a75b7"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjI2NDEwOQ==", "bodyText": "The data is non-blocking write. They are queryable after the method executed.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r376264109", "createdAt": "2020-02-07T08:22:33Z", "author": {"login": "dmsolr"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/BatchDAO.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.base;\n+\n+import java.util.List;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.skywalking.apm.commons.datacarrier.DataCarrier;\n+import org.apache.skywalking.apm.commons.datacarrier.consumer.BulkConsumePool;\n+import org.apache.skywalking.apm.commons.datacarrier.consumer.ConsumerPoolFactory;\n+import org.apache.skywalking.apm.commons.datacarrier.consumer.IConsumer;\n+import org.apache.skywalking.oap.server.core.UnexpectedException;\n+import org.apache.skywalking.oap.server.core.storage.IBatchDAO;\n+import org.apache.skywalking.oap.server.library.client.request.InsertRequest;\n+import org.apache.skywalking.oap.server.library.client.request.PrepareRequest;\n+import org.apache.skywalking.oap.server.library.util.CollectionUtils;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.influxdb.dto.BatchPoints;\n+\n+@Slf4j\n+public class BatchDAO implements IBatchDAO {\n+    private final DataCarrier<PrepareRequest> dataCarrier;\n+    private final InfluxClient client;\n+\n+    public BatchDAO(InfluxClient client) {\n+        this.client = client;\n+\n+        String name = \"INFLUX_ASYNC_BATCH_PERSISTENT\";\n+        BulkConsumePool.Creator creator = new BulkConsumePool.Creator(name, 1, 20L);\n+\n+        try {\n+            ConsumerPoolFactory.INSTANCE.createIfAbsent(name, creator);\n+        } catch (Exception e) {\n+            throw new UnexpectedException(e.getMessage(), e);\n+        }\n+\n+        this.dataCarrier = new DataCarrier(1, 10000);\n+        this.dataCarrier.consume(ConsumerPoolFactory.INSTANCE.get(name), new InfluxBatchConsumer(this));\n+    }\n+\n+    @Override\n+    public void asynchronous(InsertRequest insertRequest) {\n+        dataCarrier.produce(insertRequest);\n+    }\n+\n+    @Override\n+    public void synchronous(List<PrepareRequest> prepareRequests) {\n+        if (CollectionUtils.isEmpty(prepareRequests)) {\n+            return;\n+        }\n+\n+        if (log.isDebugEnabled()) {\n+            log.debug(\"batch sql statements execute, data size: {}\", prepareRequests.size());\n+        }\n+\n+        final BatchPoints.Builder builder = BatchPoints.builder();\n+        prepareRequests.forEach(e -> {\n+            builder.point(((InfluxInsertRequest)e).getPoint());\n+        });\n+\n+        client.write(builder.build());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTEyMTMwOA=="}, "originalCommit": {"oid": "748dce814b1567ec1d1d5878de91b2891e7a75b7"}, "originalPosition": 76}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxOTk3NzU4OnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/BatchDAO.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwODo0NDozMVrOFlvoaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QwODo1NDoyNVrOFm2GnA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTEyMjAyNQ==", "bodyText": "Doesn't InfluxDB have an async write mode? I remember time serious DB is good at writing.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r375122025", "createdAt": "2020-02-05T08:44:31Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/BatchDAO.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.base;\n+\n+import java.util.List;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.skywalking.apm.commons.datacarrier.DataCarrier;\n+import org.apache.skywalking.apm.commons.datacarrier.consumer.BulkConsumePool;\n+import org.apache.skywalking.apm.commons.datacarrier.consumer.ConsumerPoolFactory;\n+import org.apache.skywalking.apm.commons.datacarrier.consumer.IConsumer;\n+import org.apache.skywalking.oap.server.core.UnexpectedException;\n+import org.apache.skywalking.oap.server.core.storage.IBatchDAO;\n+import org.apache.skywalking.oap.server.library.client.request.InsertRequest;\n+import org.apache.skywalking.oap.server.library.client.request.PrepareRequest;\n+import org.apache.skywalking.oap.server.library.util.CollectionUtils;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.influxdb.dto.BatchPoints;\n+\n+@Slf4j\n+public class BatchDAO implements IBatchDAO {\n+    private final DataCarrier<PrepareRequest> dataCarrier;\n+    private final InfluxClient client;\n+\n+    public BatchDAO(InfluxClient client) {\n+        this.client = client;\n+\n+        String name = \"INFLUX_ASYNC_BATCH_PERSISTENT\";\n+        BulkConsumePool.Creator creator = new BulkConsumePool.Creator(name, 1, 20L);\n+\n+        try {\n+            ConsumerPoolFactory.INSTANCE.createIfAbsent(name, creator);\n+        } catch (Exception e) {\n+            throw new UnexpectedException(e.getMessage(), e);\n+        }\n+\n+        this.dataCarrier = new DataCarrier(1, 10000);\n+        this.dataCarrier.consume(ConsumerPoolFactory.INSTANCE.get(name), new InfluxBatchConsumer(this));\n+    }\n+\n+    @Override\n+    public void asynchronous(InsertRequest insertRequest) {\n+        dataCarrier.produce(insertRequest);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "748dce814b1567ec1d1d5878de91b2891e7a75b7"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjI2MzQwOQ==", "bodyText": "Yes, it does. I will fix.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r376263409", "createdAt": "2020-02-07T08:20:42Z", "author": {"login": "dmsolr"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/BatchDAO.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.base;\n+\n+import java.util.List;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.skywalking.apm.commons.datacarrier.DataCarrier;\n+import org.apache.skywalking.apm.commons.datacarrier.consumer.BulkConsumePool;\n+import org.apache.skywalking.apm.commons.datacarrier.consumer.ConsumerPoolFactory;\n+import org.apache.skywalking.apm.commons.datacarrier.consumer.IConsumer;\n+import org.apache.skywalking.oap.server.core.UnexpectedException;\n+import org.apache.skywalking.oap.server.core.storage.IBatchDAO;\n+import org.apache.skywalking.oap.server.library.client.request.InsertRequest;\n+import org.apache.skywalking.oap.server.library.client.request.PrepareRequest;\n+import org.apache.skywalking.oap.server.library.util.CollectionUtils;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.influxdb.dto.BatchPoints;\n+\n+@Slf4j\n+public class BatchDAO implements IBatchDAO {\n+    private final DataCarrier<PrepareRequest> dataCarrier;\n+    private final InfluxClient client;\n+\n+    public BatchDAO(InfluxClient client) {\n+        this.client = client;\n+\n+        String name = \"INFLUX_ASYNC_BATCH_PERSISTENT\";\n+        BulkConsumePool.Creator creator = new BulkConsumePool.Creator(name, 1, 20L);\n+\n+        try {\n+            ConsumerPoolFactory.INSTANCE.createIfAbsent(name, creator);\n+        } catch (Exception e) {\n+            throw new UnexpectedException(e.getMessage(), e);\n+        }\n+\n+        this.dataCarrier = new DataCarrier(1, 10000);\n+        this.dataCarrier.consume(ConsumerPoolFactory.INSTANCE.get(name), new InfluxBatchConsumer(this));\n+    }\n+\n+    @Override\n+    public void asynchronous(InsertRequest insertRequest) {\n+        dataCarrier.produce(insertRequest);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTEyMjAyNQ=="}, "originalCommit": {"oid": "748dce814b1567ec1d1d5878de91b2891e7a75b7"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjI3NjYzNg==", "bodyText": "Then you should not require datacarrier? Right?", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r376276636", "createdAt": "2020-02-07T08:54:25Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/BatchDAO.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.base;\n+\n+import java.util.List;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.skywalking.apm.commons.datacarrier.DataCarrier;\n+import org.apache.skywalking.apm.commons.datacarrier.consumer.BulkConsumePool;\n+import org.apache.skywalking.apm.commons.datacarrier.consumer.ConsumerPoolFactory;\n+import org.apache.skywalking.apm.commons.datacarrier.consumer.IConsumer;\n+import org.apache.skywalking.oap.server.core.UnexpectedException;\n+import org.apache.skywalking.oap.server.core.storage.IBatchDAO;\n+import org.apache.skywalking.oap.server.library.client.request.InsertRequest;\n+import org.apache.skywalking.oap.server.library.client.request.PrepareRequest;\n+import org.apache.skywalking.oap.server.library.util.CollectionUtils;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.influxdb.dto.BatchPoints;\n+\n+@Slf4j\n+public class BatchDAO implements IBatchDAO {\n+    private final DataCarrier<PrepareRequest> dataCarrier;\n+    private final InfluxClient client;\n+\n+    public BatchDAO(InfluxClient client) {\n+        this.client = client;\n+\n+        String name = \"INFLUX_ASYNC_BATCH_PERSISTENT\";\n+        BulkConsumePool.Creator creator = new BulkConsumePool.Creator(name, 1, 20L);\n+\n+        try {\n+            ConsumerPoolFactory.INSTANCE.createIfAbsent(name, creator);\n+        } catch (Exception e) {\n+            throw new UnexpectedException(e.getMessage(), e);\n+        }\n+\n+        this.dataCarrier = new DataCarrier(1, 10000);\n+        this.dataCarrier.consume(ConsumerPoolFactory.INSTANCE.get(name), new InfluxBatchConsumer(this));\n+    }\n+\n+    @Override\n+    public void asynchronous(InsertRequest insertRequest) {\n+        dataCarrier.produce(insertRequest);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTEyMjAyNQ=="}, "originalCommit": {"oid": "748dce814b1567ec1d1d5878de91b2891e7a75b7"}, "originalPosition": 58}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxOTk4MDQ1OnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwODo0NToyNlrOFlvqHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwODo0NToyNlrOFlvqHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTEyMjQ2Mw==", "bodyText": "=?", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r375122463", "createdAt": "2020-02-05T08:45:26Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb;\n+\n+import java.io.IOException;\n+import java.lang.invoke.MethodHandles;\n+import java.util.List;\n+import okhttp3.OkHttpClient;\n+import org.apache.skywalking.oap.server.core.analysis.Downsampling;\n+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;\n+import org.apache.skywalking.oap.server.library.client.Client;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.BatchPoints;\n+import org.influxdb.dto.Point;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.time.TimeInterval;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.ti;\n+\n+/**\n+ *\n+ */\n+public class InfluxClient implements Client {\n+    private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+    private InfluxStorageConfig config;\n+    private InfluxDB influx;\n+\n+    /**\n+     * A constant, the name of time field in Time-series database.\n+     */\n+    public static final String TIME = \"time\";\n+    /**\n+     * A constant, the name of tag.\n+     */\n+    public static final String TAG_ENTITY_ID = \"entity_id\";\n+\n+    private final String database;\n+\n+    public InfluxClient(InfluxStorageConfig config) {\n+        this.config = config;\n+        this.database = config.getDatabase();\n+    }\n+\n+    public final String getDatabase() {\n+        return database;\n+    }\n+\n+    @Override\n+    public void connect() {\n+        influx = InfluxDBFactory.connect(config.getUrl(), config.getUser(), config.getPassword(),\n+            new OkHttpClient.Builder(), InfluxDB.ResponseFormat.MSGPACK);\n+        influx.query(new Query(\"CREATE DATABASE \" + database));\n+\n+        influx.setDatabase(database);\n+        influx.enableBatch();\n+    }\n+\n+    /**\n+     * To get a connection of InfluxDB\n+     *\n+     * @return InfluxDB's connection\n+     */\n+    public InfluxDB getInflux() {\n+        return influx;\n+    }\n+\n+    /**\n+     * Request with a {@link Query} to InfluxDB and return a set of {@link QueryResult.Result}s.\n+     *\n+     * @param query\n+     * @return a set of Result.\n+     * @throws IOException\n+     */\n+    public List<QueryResult.Result> query(Query query) throws IOException {\n+        if (logger.isDebugEnabled()) {\n+            logger.debug(\"SQL Statement: {}\", query.getCommand());\n+        }\n+\n+        try {\n+            QueryResult result = getInflux().query(query);\n+            if (result.hasError()) {\n+                throw new IOException(result.getError());\n+            }\n+            return result.getResults();\n+        } catch (Exception e) {\n+            throw new IOException(e.getMessage() + System.lineSeparator() + \"SQL Statement: \" + query.getCommand(), e);\n+        }\n+    }\n+\n+    /**\n+     * Request with one statement to InfluxDB and return a set of {@link QueryResult.Series}s.\n+     *\n+     * @param query\n+     * @return a set of Series\n+     * @throws IOException\n+     */\n+    public List<QueryResult.Series> queryForSeries(Query query) throws IOException {\n+        return query(query).get(0).getSeries();\n+    }\n+\n+    /**\n+     * Data management, to drop a time-series by measurement and time-series name specified. If an exception isn't\n+     * thrown, it means execution success.\n+     *\n+     * @param measurement\n+     * @param timeBucket\n+     * @throws IOException\n+     */\n+    public void dropSeries(String measurement, long timeBucket) throws IOException {\n+        Query query = new Query(\"DROP SERIES FROM \" + measurement + \" WHERE time_bucket='\" + timeBucket + \"'\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "748dce814b1567ec1d1d5878de91b2891e7a75b7"}, "originalPosition": 130}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxOTk4MzMxOnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/MetricsDAO.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwODo0NjoyNVrOFlvrzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwODo0NjoyNVrOFlvrzg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTEyMjg5NA==", "bodyText": "Another #get(0). What does this mean?", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r375122894", "createdAt": "2020-02-05T08:46:25Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/MetricsDAO.java", "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.base;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.skywalking.oap.server.core.analysis.metrics.Metrics;\n+import org.apache.skywalking.oap.server.core.storage.IMetricsDAO;\n+import org.apache.skywalking.oap.server.core.storage.StorageBuilder;\n+import org.apache.skywalking.oap.server.core.storage.model.Model;\n+import org.apache.skywalking.oap.server.core.storage.model.ModelColumn;\n+import org.apache.skywalking.oap.server.core.storage.type.StorageDataType;\n+import org.apache.skywalking.oap.server.library.client.request.InsertRequest;\n+import org.apache.skywalking.oap.server.library.client.request.UpdateRequest;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.SelectQueryImpl;\n+import org.influxdb.querybuilder.WhereQueryImpl;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.contains;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.select;\n+\n+public class MetricsDAO implements IMetricsDAO {\n+    private final StorageBuilder<Metrics> storageBuilder;\n+    private final InfluxClient client;\n+\n+    public MetricsDAO(InfluxClient client, StorageBuilder<Metrics> storageBuilder) {\n+        this.client = client;\n+        this.storageBuilder = storageBuilder;\n+    }\n+\n+    @Override\n+    public List<Metrics> multiGet(Model model, List<String> ids) throws IOException {\n+        WhereQueryImpl<SelectQueryImpl> query = select(\"*::field\")\n+            .from(client.getDatabase(), model.getName())\n+            .where(contains(\"id\", Joiner.on(\"|\").join(ids)));\n+        List<QueryResult.Series> series = client.queryForSeries(query);\n+        if (series == null || series.isEmpty()) {\n+            return Collections.emptyList();\n+        }\n+\n+        final List<Metrics> metrics = Lists.newArrayList();\n+        List<String> columns = series.get(0).getColumns();\n+        Map<String, String> storageAndColumnNames = Maps.newHashMap();\n+        for (ModelColumn column : model.getColumns()) {\n+            storageAndColumnNames.put(column.getColumnName().getName(), column.getColumnName().getStorageName());\n+        }\n+\n+        series.get(0).getValues().forEach(values -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "748dce814b1567ec1d1d5878de91b2891e7a75b7"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyOTk3NjMyOnYy", "diffSide": "RIGHT", "path": "docs/en/setup/backend/backend-storage.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQwNTo0NzozN1rOFnPVHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQwNTo0NzozN1rOFnPVHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY4OTk1MQ==", "bodyText": "likes -> like.\nwe need to configure InfluxDB's properties and H2/MySQL -> `We need to configure properties of InfluxDB and Metabase.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r376689951", "createdAt": "2020-02-08T05:47:37Z", "author": {"login": "wu-sheng"}, "path": "docs/en/setup/backend/backend-storage.md", "diffHunk": "@@ -226,6 +227,27 @@ storage:\n All connection related settings including link url, username and password are in `application.yml`. \n These settings can refer to the configuration of *MySQL* above.\n \n+## InfluxDB\n+InfluxDB as storage since SkyWalking 7.0. It depends on `H2/MySQL` storage-plugin to store `metadata` likes `Inventory` and `ProfileTask`. So, when we set `InfluxDB` as storage provider, we need to configure `InfluxDB`'s properties and `H2/MySQL`.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb1b87538d949f3a2b87e2e14836f931312ee1b7"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyOTk3NjY2OnYy", "diffSide": "RIGHT", "path": "docs/en/setup/backend/backend-storage.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQwNTo0ODoyNFrOFnPVRQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQwNTo0ODoyNFrOFnPVRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY4OTk4OQ==", "bodyText": "Please provide type options.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r376689989", "createdAt": "2020-02-08T05:48:24Z", "author": {"login": "wu-sheng"}, "path": "docs/en/setup/backend/backend-storage.md", "diffHunk": "@@ -226,6 +227,27 @@ storage:\n All connection related settings including link url, username and password are in `application.yml`. \n These settings can refer to the configuration of *MySQL* above.\n \n+## InfluxDB\n+InfluxDB as storage since SkyWalking 7.0. It depends on `H2/MySQL` storage-plugin to store `metadata` likes `Inventory` and `ProfileTask`. So, when we set `InfluxDB` as storage provider, we need to configure `InfluxDB`'s properties and `H2/MySQL`.\n+\n+```yaml\n+storage\n+  influx:\n+    # Metadata storage provider configuration\n+    metabaseType: ${SW_STORAGE_METABASE_TYPE:H2}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb1b87538d949f3a2b87e2e14836f931312ee1b7"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMzMDE0OTI2OnYy", "diffSide": "RIGHT", "path": "test/e2e/e2e-ttl/e2e-ttl-influxdb/src/main/proto/common/CLR.proto", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQxNDowMDoxNVrOFnQp4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQxNDowMDoxNVrOFnQp4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcxMTY0OQ==", "bodyText": "All these protos should be removed, please follow this, #4329 (comment)", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r376711649", "createdAt": "2020-02-08T14:00:15Z", "author": {"login": "wu-sheng"}, "path": "test/e2e/e2e-ttl/e2e-ttl-influxdb/src/main/proto/common/CLR.proto", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+syntax = \"proto3\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2bd17170a147a1c53822eb11057d667937826392"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMzMDQyMjIzOnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOVQwMTowMjo0M1rOFnSwvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOVQwMTowMjo0M1rOFnSwvw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njc0NjE3NQ==", "bodyText": "I think this should be private to avoid misuse", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r376746175", "createdAt": "2020-02-09T01:02:43Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import lombok.extern.slf4j.Slf4j;\n+import okhttp3.OkHttpClient;\n+import org.apache.skywalking.oap.server.core.analysis.Downsampling;\n+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;\n+import org.apache.skywalking.oap.server.library.client.Client;\n+import org.apache.skywalking.oap.server.library.util.CollectionUtils;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.BatchPoints;\n+import org.influxdb.dto.Point;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.time.TimeInterval;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.ti;\n+\n+/**\n+ * InfluxDB connection maintainer, provides base data write/query API.\n+ */\n+@Slf4j\n+public class InfluxClient implements Client {\n+    private InfluxStorageConfig config;\n+    private InfluxDB influx;\n+\n+    /**\n+     * A constant, the name of time field in Time-series database.\n+     */\n+    public static final String TIME = \"time\";\n+    /**\n+     * A constant, the name of tag.\n+     */\n+    public static final String TAG_ENTITY_ID = \"entity_id\";\n+\n+    private final String database;\n+\n+    public InfluxClient(InfluxStorageConfig config) {\n+        this.config = config;\n+        this.database = config.getDatabase();\n+    }\n+\n+    public final String getDatabase() {\n+        return database;\n+    }\n+\n+    @Override\n+    public void connect() {\n+        influx = InfluxDBFactory.connect(config.getUrl(), config.getUser(), config.getPassword(),\n+            new OkHttpClient.Builder(), InfluxDB.ResponseFormat.MSGPACK);\n+        influx.query(new Query(\"CREATE DATABASE \" + database));\n+\n+        influx.enableBatch(config.getActions(), config.getDuration(), TimeUnit.MILLISECONDS);\n+        influx.setDatabase(database);\n+    }\n+\n+    /**\n+     * To get a connection of InfluxDB.\n+     *\n+     * @return InfluxDB's connection\n+     */\n+    public InfluxDB getInflux() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "12414c80e1819ccdd6d774bede6d9d33fe6af457"}, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMzODU5MDY3OnYy", "diffSide": "RIGHT", "path": ".github/workflows/e2e.yaml", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMlQwMjowMzozMVrOFofjag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMlQwMjo0OToxOVrOFogM4g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODAwNDMzMA==", "bodyText": "What do you mean N_TTL?", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r378004330", "createdAt": "2020-02-12T02:03:31Z", "author": {"login": "wu-sheng"}, "path": ".github/workflows/e2e.yaml", "diffHunk": "@@ -39,19 +39,21 @@ jobs:\n           ./mvnw --batch-mode -Dcheckstyle.skip -Drat.skip -T2 -Dmaven.compile.fork -Dmaven.compiler.maxmem=3072 -DskipTests clean install\n           ./mvnw --batch-mode -f test/e2e/pom.xml -pl e2e-base clean install\n       - name: Single Node Tests(JDK8)\n-        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-single-service\n+        run: export E2E_VERSION=jdk8-1.4 && bash -x test/e2e/run.sh e2e-single-service\n+      - name: Single Node Tests(InfluxDB/JDK8)\n+        run: export E2E_VERSION=jdk8-1.4 && bash -x test/e2e/run.sh e2e-influxdb\n       - name: Single Node Tests(MySQL/JDK8)\n-        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-mysql\n+        run: export E2E_VERSION=jdk8-1.4 && bash -x test/e2e/run.sh e2e-mysql\n       - name: Single Node Tests(JDK9)\n-        run: export E2E_VERSION=jdk9-1.3 && bash -x test/e2e/run.sh e2e-single-service\n+        run: export E2E_VERSION=jdk9-1.4 && bash -x test/e2e/run.sh e2e-single-service\n       - name: Single Node Tests(JDK11)\n-        run: export E2E_VERSION=jdk11-1.3 && bash -x test/e2e/run.sh e2e-single-service\n+        run: export E2E_VERSION=jdk11-1.4 && bash -x test/e2e/run.sh e2e-single-service\n       - name: Single Node Tests(JDK12)\n-        run: export E2E_VERSION=jdk12-1.3 && bash -x test/e2e/run.sh e2e-single-service\n+        run: export E2E_VERSION=jdk12-1.4 && bash -x test/e2e/run.sh e2e-single-service\n       - name: Agent Reboot Tests(JDK8)\n-        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-agent-reboot\n+        run: export E2E_VERSION=jdk8-1.4 && bash -x test/e2e/run.sh e2e-agent-reboot\n \n-  Cluster:\n+  Cluster_N_TTL:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c06a1dca76b9cd931cb41f3e0183b53e264e174"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODAwOTA4MQ==", "bodyText": "What do you mean N_TTL?\n\nPossibly N == And, we don't need to save 2 letters to cause confusion, no?", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r378009081", "createdAt": "2020-02-12T02:23:48Z", "author": {"login": "kezhenxu94"}, "path": ".github/workflows/e2e.yaml", "diffHunk": "@@ -39,19 +39,21 @@ jobs:\n           ./mvnw --batch-mode -Dcheckstyle.skip -Drat.skip -T2 -Dmaven.compile.fork -Dmaven.compiler.maxmem=3072 -DskipTests clean install\n           ./mvnw --batch-mode -f test/e2e/pom.xml -pl e2e-base clean install\n       - name: Single Node Tests(JDK8)\n-        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-single-service\n+        run: export E2E_VERSION=jdk8-1.4 && bash -x test/e2e/run.sh e2e-single-service\n+      - name: Single Node Tests(InfluxDB/JDK8)\n+        run: export E2E_VERSION=jdk8-1.4 && bash -x test/e2e/run.sh e2e-influxdb\n       - name: Single Node Tests(MySQL/JDK8)\n-        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-mysql\n+        run: export E2E_VERSION=jdk8-1.4 && bash -x test/e2e/run.sh e2e-mysql\n       - name: Single Node Tests(JDK9)\n-        run: export E2E_VERSION=jdk9-1.3 && bash -x test/e2e/run.sh e2e-single-service\n+        run: export E2E_VERSION=jdk9-1.4 && bash -x test/e2e/run.sh e2e-single-service\n       - name: Single Node Tests(JDK11)\n-        run: export E2E_VERSION=jdk11-1.3 && bash -x test/e2e/run.sh e2e-single-service\n+        run: export E2E_VERSION=jdk11-1.4 && bash -x test/e2e/run.sh e2e-single-service\n       - name: Single Node Tests(JDK12)\n-        run: export E2E_VERSION=jdk12-1.3 && bash -x test/e2e/run.sh e2e-single-service\n+        run: export E2E_VERSION=jdk12-1.4 && bash -x test/e2e/run.sh e2e-single-service\n       - name: Agent Reboot Tests(JDK8)\n-        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-agent-reboot\n+        run: export E2E_VERSION=jdk8-1.4 && bash -x test/e2e/run.sh e2e-agent-reboot\n \n-  Cluster:\n+  Cluster_N_TTL:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODAwNDMzMA=="}, "originalCommit": {"oid": "4c06a1dca76b9cd931cb41f3e0183b53e264e174"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODAwOTkyMg==", "bodyText": "Three things\n\nN represent AND is not a common case. + and & are better\nThis name should not be changed randomly, Cluster is a required test, without this check(named as cluster), we can't merge PR unless we request the INFRA change the settings.\nIf you want the test group names more clear, moving the TTL out of the cluster test group makes sense to me. But notice, it will take more time as it requires to compile the project again.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r378009922", "createdAt": "2020-02-12T02:27:24Z", "author": {"login": "wu-sheng"}, "path": ".github/workflows/e2e.yaml", "diffHunk": "@@ -39,19 +39,21 @@ jobs:\n           ./mvnw --batch-mode -Dcheckstyle.skip -Drat.skip -T2 -Dmaven.compile.fork -Dmaven.compiler.maxmem=3072 -DskipTests clean install\n           ./mvnw --batch-mode -f test/e2e/pom.xml -pl e2e-base clean install\n       - name: Single Node Tests(JDK8)\n-        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-single-service\n+        run: export E2E_VERSION=jdk8-1.4 && bash -x test/e2e/run.sh e2e-single-service\n+      - name: Single Node Tests(InfluxDB/JDK8)\n+        run: export E2E_VERSION=jdk8-1.4 && bash -x test/e2e/run.sh e2e-influxdb\n       - name: Single Node Tests(MySQL/JDK8)\n-        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-mysql\n+        run: export E2E_VERSION=jdk8-1.4 && bash -x test/e2e/run.sh e2e-mysql\n       - name: Single Node Tests(JDK9)\n-        run: export E2E_VERSION=jdk9-1.3 && bash -x test/e2e/run.sh e2e-single-service\n+        run: export E2E_VERSION=jdk9-1.4 && bash -x test/e2e/run.sh e2e-single-service\n       - name: Single Node Tests(JDK11)\n-        run: export E2E_VERSION=jdk11-1.3 && bash -x test/e2e/run.sh e2e-single-service\n+        run: export E2E_VERSION=jdk11-1.4 && bash -x test/e2e/run.sh e2e-single-service\n       - name: Single Node Tests(JDK12)\n-        run: export E2E_VERSION=jdk12-1.3 && bash -x test/e2e/run.sh e2e-single-service\n+        run: export E2E_VERSION=jdk12-1.4 && bash -x test/e2e/run.sh e2e-single-service\n       - name: Agent Reboot Tests(JDK8)\n-        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-agent-reboot\n+        run: export E2E_VERSION=jdk8-1.4 && bash -x test/e2e/run.sh e2e-agent-reboot\n \n-  Cluster:\n+  Cluster_N_TTL:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODAwNDMzMA=="}, "originalCommit": {"oid": "4c06a1dca76b9cd931cb41f3e0183b53e264e174"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODAxNDk0Ng==", "bodyText": "Yes. I will revert it.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r378014946", "createdAt": "2020-02-12T02:49:19Z", "author": {"login": "dmsolr"}, "path": ".github/workflows/e2e.yaml", "diffHunk": "@@ -39,19 +39,21 @@ jobs:\n           ./mvnw --batch-mode -Dcheckstyle.skip -Drat.skip -T2 -Dmaven.compile.fork -Dmaven.compiler.maxmem=3072 -DskipTests clean install\n           ./mvnw --batch-mode -f test/e2e/pom.xml -pl e2e-base clean install\n       - name: Single Node Tests(JDK8)\n-        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-single-service\n+        run: export E2E_VERSION=jdk8-1.4 && bash -x test/e2e/run.sh e2e-single-service\n+      - name: Single Node Tests(InfluxDB/JDK8)\n+        run: export E2E_VERSION=jdk8-1.4 && bash -x test/e2e/run.sh e2e-influxdb\n       - name: Single Node Tests(MySQL/JDK8)\n-        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-mysql\n+        run: export E2E_VERSION=jdk8-1.4 && bash -x test/e2e/run.sh e2e-mysql\n       - name: Single Node Tests(JDK9)\n-        run: export E2E_VERSION=jdk9-1.3 && bash -x test/e2e/run.sh e2e-single-service\n+        run: export E2E_VERSION=jdk9-1.4 && bash -x test/e2e/run.sh e2e-single-service\n       - name: Single Node Tests(JDK11)\n-        run: export E2E_VERSION=jdk11-1.3 && bash -x test/e2e/run.sh e2e-single-service\n+        run: export E2E_VERSION=jdk11-1.4 && bash -x test/e2e/run.sh e2e-single-service\n       - name: Single Node Tests(JDK12)\n-        run: export E2E_VERSION=jdk12-1.3 && bash -x test/e2e/run.sh e2e-single-service\n+        run: export E2E_VERSION=jdk12-1.4 && bash -x test/e2e/run.sh e2e-single-service\n       - name: Agent Reboot Tests(JDK8)\n-        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-agent-reboot\n+        run: export E2E_VERSION=jdk8-1.4 && bash -x test/e2e/run.sh e2e-agent-reboot\n \n-  Cluster:\n+  Cluster_N_TTL:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODAwNDMzMA=="}, "originalCommit": {"oid": "4c06a1dca76b9cd931cb41f3e0183b53e264e174"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMzODY0NDgzOnYy", "diffSide": "RIGHT", "path": ".github/workflows/e2e.yaml", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMlQwMjozOTozNFrOFogDoQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMlQwMjo0OToyMlrOFogM7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODAxMjU3Nw==", "bodyText": "Upgrade to 1.5 please, based on, #4343 (comment)", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r378012577", "createdAt": "2020-02-12T02:39:34Z", "author": {"login": "wu-sheng"}, "path": ".github/workflows/e2e.yaml", "diffHunk": "@@ -39,19 +39,21 @@ jobs:\n           ./mvnw --batch-mode -Dcheckstyle.skip -Drat.skip -T2 -Dmaven.compile.fork -Dmaven.compiler.maxmem=3072 -DskipTests clean install\n           ./mvnw --batch-mode -f test/e2e/pom.xml -pl e2e-base clean install\n       - name: Single Node Tests(JDK8)\n-        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-single-service\n+        run: export E2E_VERSION=jdk8-1.4 && bash -x test/e2e/run.sh e2e-single-service", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c06a1dca76b9cd931cb41f3e0183b53e264e174"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODAxNDk1OA==", "bodyText": "Got it.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r378014958", "createdAt": "2020-02-12T02:49:22Z", "author": {"login": "dmsolr"}, "path": ".github/workflows/e2e.yaml", "diffHunk": "@@ -39,19 +39,21 @@ jobs:\n           ./mvnw --batch-mode -Dcheckstyle.skip -Drat.skip -T2 -Dmaven.compile.fork -Dmaven.compiler.maxmem=3072 -DskipTests clean install\n           ./mvnw --batch-mode -f test/e2e/pom.xml -pl e2e-base clean install\n       - name: Single Node Tests(JDK8)\n-        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-single-service\n+        run: export E2E_VERSION=jdk8-1.4 && bash -x test/e2e/run.sh e2e-single-service", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODAxMjU3Nw=="}, "originalCommit": {"oid": "4c06a1dca76b9cd931cb41f3e0183b53e264e174"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM0Mzk1NzUyOnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QxMzowNTozMlrOFpS-4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwMjoxNzoxMVrOFppzqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODg0Njk0Nw==", "bodyText": "From here, all comments about @param and @return are either empty and meaningless. Could you fix this?", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r378846947", "createdAt": "2020-02-13T13:05:32Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "diffHunk": "@@ -0,0 +1,210 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import lombok.extern.slf4j.Slf4j;\n+import okhttp3.OkHttpClient;\n+import org.apache.skywalking.oap.server.core.analysis.Downsampling;\n+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;\n+import org.apache.skywalking.oap.server.library.client.Client;\n+import org.apache.skywalking.oap.server.library.util.CollectionUtils;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.BatchPoints;\n+import org.influxdb.dto.Point;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.time.TimeInterval;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.ti;\n+\n+/**\n+ * InfluxDB connection maintainer, provides base data write/query API.\n+ */\n+@Slf4j\n+public class InfluxClient implements Client {\n+    private InfluxStorageConfig config;\n+    private InfluxDB influx;\n+\n+    /**\n+     * A constant, the name of time field in Time-series database.\n+     */\n+    public static final String TIME = \"time\";\n+    /**\n+     * A constant, the name of tag.\n+     */\n+    public static final String TAG_ENTITY_ID = \"entity_id\";\n+\n+    private final String database;\n+\n+    public InfluxClient(InfluxStorageConfig config) {\n+        this.config = config;\n+        this.database = config.getDatabase();\n+    }\n+\n+    public final String getDatabase() {\n+        return database;\n+    }\n+\n+    @Override\n+    public void connect() {\n+        influx = InfluxDBFactory.connect(config.getUrl(), config.getUser(), config.getPassword(),\n+                                         new OkHttpClient.Builder().readTimeout(3, TimeUnit.MINUTES)\n+                                                                   .writeTimeout(3, TimeUnit.MINUTES),\n+                                         InfluxDB.ResponseFormat.MSGPACK\n+        );\n+        influx.query(new Query(\"CREATE DATABASE \" + database));\n+\n+        influx.enableBatch(config.getActions(), config.getDuration(), TimeUnit.MILLISECONDS);\n+        influx.setDatabase(database);\n+    }\n+\n+    /**\n+     * To get a connection of InfluxDB.\n+     *\n+     * @return InfluxDB's connection\n+     */\n+    private InfluxDB getInflux() {\n+        return influx;\n+    }\n+\n+    /**\n+     * Execute a query against InfluxDB and return a set of {@link QueryResult.Result}s. Normally, InfluxDB supports\n+     * combining multiple statements into one query, so that we do get multi-results.\n+     *\n+     * @param query Query\n+     * @return a set of {@link QueryResult.Result}s.\n+     * @throws IOException if there is an error on the InfluxDB server or communication error.\n+     */\n+    public List<QueryResult.Result> query(Query query) throws IOException {\n+        if (log.isDebugEnabled()) {\n+            log.debug(\"SQL Statement: {}\", query.getCommand());\n+        }\n+\n+        try {\n+            QueryResult result = getInflux().query(query);\n+            if (result.hasError()) {\n+                throw new IOException(result.getError());\n+            }\n+            return result.getResults();\n+        } catch (Exception e) {\n+            throw new IOException(e.getMessage() + System.lineSeparator() + \"SQL Statement: \" + query.getCommand(), e);\n+        }\n+    }\n+\n+    /**\n+     * Execute a query against InfluxDB with a single statement.\n+     *\n+     * @param query Query\n+     * @return a set of {@link QueryResult.Series}s\n+     * @throws IOException if there is an error on the InfluxDB server or communication error\n+     */\n+    public List<QueryResult.Series> queryForSeries(Query query) throws IOException {\n+        List<QueryResult.Result> results = query(query);\n+\n+        if (CollectionUtils.isEmpty(results)) {\n+            return null;\n+        }\n+        return results.get(0).getSeries();\n+    }\n+\n+    /**\n+     * Execute a query against InfluxDB with a single statement but return a single {@link QueryResult.Series}.\n+     *\n+     * @param query Query\n+     * @return {@link QueryResult.Series}\n+     * @throws IOException if there is an error on the InfluxDB server or communication error\n+     */\n+    public QueryResult.Series queryForSingleSeries(Query query) throws IOException {\n+        List<QueryResult.Series> series = queryForSeries(query);\n+        if (CollectionUtils.isEmpty(series)) {\n+            return null;\n+        }\n+        return series.get(0);\n+    }\n+\n+    /**\n+     * Data management, to drop a time-series by measurement and time-series name specified. If an exception isn't\n+     * thrown, it means execution success. Notice, drop series don't support to drop series by range\n+     *\n+     * @param measurement String\n+     * @param timeBucket  long\n+     * @throws IOException if there is an error on the InfluxDB server or communication error\n+     */\n+    public void dropSeries(String measurement, long timeBucket) throws IOException {\n+        Query query = new Query(\"DROP SERIES FROM \" + measurement + \" WHERE time_bucket='\" + timeBucket + \"'\");\n+        QueryResult result = getInflux().query(query);\n+\n+        if (result.hasError()) {\n+            throw new IOException(\"Statement: \" + query.getCommand() + \", ErrorMsg: \" + result.getError());\n+        }\n+    }\n+\n+    public void deleteByQuery(String measurement, long timestamp) throws IOException {\n+        this.query(new Query(\"delete from \" + measurement + \" where time < \" + timestamp + \"ms\"));\n+    }\n+\n+    /**\n+     * Write a {@link Point} into InfluxDB. Note that, the {@link Point} is written into buffer of InfluxDB Client and\n+     * wait for buffer flushing.\n+     *\n+     * @param point Point", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3838428d5feb0027fc6d06bcc2b178ca347b5bf"}, "originalPosition": 170}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTIyMDkwNw==", "bodyText": "@dmsolr you should put the description after the parameter name and return name, NOT the type of the parameter and return object, they're meaningless, and will cheat the JavaDoc compiler, if they are already self-documented, simply remove the JavaDoc.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r379220907", "createdAt": "2020-02-14T02:17:11Z", "author": {"login": "kezhenxu94"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "diffHunk": "@@ -0,0 +1,210 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import lombok.extern.slf4j.Slf4j;\n+import okhttp3.OkHttpClient;\n+import org.apache.skywalking.oap.server.core.analysis.Downsampling;\n+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;\n+import org.apache.skywalking.oap.server.library.client.Client;\n+import org.apache.skywalking.oap.server.library.util.CollectionUtils;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.BatchPoints;\n+import org.influxdb.dto.Point;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.time.TimeInterval;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.ti;\n+\n+/**\n+ * InfluxDB connection maintainer, provides base data write/query API.\n+ */\n+@Slf4j\n+public class InfluxClient implements Client {\n+    private InfluxStorageConfig config;\n+    private InfluxDB influx;\n+\n+    /**\n+     * A constant, the name of time field in Time-series database.\n+     */\n+    public static final String TIME = \"time\";\n+    /**\n+     * A constant, the name of tag.\n+     */\n+    public static final String TAG_ENTITY_ID = \"entity_id\";\n+\n+    private final String database;\n+\n+    public InfluxClient(InfluxStorageConfig config) {\n+        this.config = config;\n+        this.database = config.getDatabase();\n+    }\n+\n+    public final String getDatabase() {\n+        return database;\n+    }\n+\n+    @Override\n+    public void connect() {\n+        influx = InfluxDBFactory.connect(config.getUrl(), config.getUser(), config.getPassword(),\n+                                         new OkHttpClient.Builder().readTimeout(3, TimeUnit.MINUTES)\n+                                                                   .writeTimeout(3, TimeUnit.MINUTES),\n+                                         InfluxDB.ResponseFormat.MSGPACK\n+        );\n+        influx.query(new Query(\"CREATE DATABASE \" + database));\n+\n+        influx.enableBatch(config.getActions(), config.getDuration(), TimeUnit.MILLISECONDS);\n+        influx.setDatabase(database);\n+    }\n+\n+    /**\n+     * To get a connection of InfluxDB.\n+     *\n+     * @return InfluxDB's connection\n+     */\n+    private InfluxDB getInflux() {\n+        return influx;\n+    }\n+\n+    /**\n+     * Execute a query against InfluxDB and return a set of {@link QueryResult.Result}s. Normally, InfluxDB supports\n+     * combining multiple statements into one query, so that we do get multi-results.\n+     *\n+     * @param query Query\n+     * @return a set of {@link QueryResult.Result}s.\n+     * @throws IOException if there is an error on the InfluxDB server or communication error.\n+     */\n+    public List<QueryResult.Result> query(Query query) throws IOException {\n+        if (log.isDebugEnabled()) {\n+            log.debug(\"SQL Statement: {}\", query.getCommand());\n+        }\n+\n+        try {\n+            QueryResult result = getInflux().query(query);\n+            if (result.hasError()) {\n+                throw new IOException(result.getError());\n+            }\n+            return result.getResults();\n+        } catch (Exception e) {\n+            throw new IOException(e.getMessage() + System.lineSeparator() + \"SQL Statement: \" + query.getCommand(), e);\n+        }\n+    }\n+\n+    /**\n+     * Execute a query against InfluxDB with a single statement.\n+     *\n+     * @param query Query\n+     * @return a set of {@link QueryResult.Series}s\n+     * @throws IOException if there is an error on the InfluxDB server or communication error\n+     */\n+    public List<QueryResult.Series> queryForSeries(Query query) throws IOException {\n+        List<QueryResult.Result> results = query(query);\n+\n+        if (CollectionUtils.isEmpty(results)) {\n+            return null;\n+        }\n+        return results.get(0).getSeries();\n+    }\n+\n+    /**\n+     * Execute a query against InfluxDB with a single statement but return a single {@link QueryResult.Series}.\n+     *\n+     * @param query Query\n+     * @return {@link QueryResult.Series}\n+     * @throws IOException if there is an error on the InfluxDB server or communication error\n+     */\n+    public QueryResult.Series queryForSingleSeries(Query query) throws IOException {\n+        List<QueryResult.Series> series = queryForSeries(query);\n+        if (CollectionUtils.isEmpty(series)) {\n+            return null;\n+        }\n+        return series.get(0);\n+    }\n+\n+    /**\n+     * Data management, to drop a time-series by measurement and time-series name specified. If an exception isn't\n+     * thrown, it means execution success. Notice, drop series don't support to drop series by range\n+     *\n+     * @param measurement String\n+     * @param timeBucket  long\n+     * @throws IOException if there is an error on the InfluxDB server or communication error\n+     */\n+    public void dropSeries(String measurement, long timeBucket) throws IOException {\n+        Query query = new Query(\"DROP SERIES FROM \" + measurement + \" WHERE time_bucket='\" + timeBucket + \"'\");\n+        QueryResult result = getInflux().query(query);\n+\n+        if (result.hasError()) {\n+            throw new IOException(\"Statement: \" + query.getCommand() + \", ErrorMsg: \" + result.getError());\n+        }\n+    }\n+\n+    public void deleteByQuery(String measurement, long timestamp) throws IOException {\n+        this.query(new Query(\"delete from \" + measurement + \" where time < \" + timestamp + \"ms\"));\n+    }\n+\n+    /**\n+     * Write a {@link Point} into InfluxDB. Note that, the {@link Point} is written into buffer of InfluxDB Client and\n+     * wait for buffer flushing.\n+     *\n+     * @param point Point", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODg0Njk0Nw=="}, "originalCommit": {"oid": "c3838428d5feb0027fc6d06bcc2b178ca347b5bf"}, "originalPosition": 170}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM0Mzk3OTM5OnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/PointBuilder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QxMzoxMjo0OFrOFpTMYA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QxMzoxMjo0OFrOFpTMYA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODg1MDQwMA==", "bodyText": "Could you explain this class a little more? I am a little confused. All existing entities have the shared prepareBatchInsert and prepareBatchUpdate logic without explicit entity name required. Using the literal string name here is highly unstable. These names could be changed in any PR, and new entity could be added.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r378850400", "createdAt": "2020-02-13T13:12:48Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/PointBuilder.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.base;\n+\n+import com.google.common.collect.Maps;\n+import java.io.IOException;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.skywalking.apm.commons.datacarrier.common.AtomicRangeInteger;\n+import org.apache.skywalking.oap.server.core.alarm.AlarmRecord;\n+import org.apache.skywalking.oap.server.core.analysis.manual.segment.SegmentRecord;\n+import org.apache.skywalking.oap.server.core.analysis.metrics.Metrics;\n+import org.apache.skywalking.oap.server.core.analysis.record.Record;\n+import org.apache.skywalking.oap.server.core.analysis.topn.TopN;\n+import org.apache.skywalking.oap.server.core.profile.ProfileTaskLogRecord;\n+import org.apache.skywalking.oap.server.core.profile.ProfileThreadSnapshotRecord;\n+import org.apache.skywalking.oap.server.core.storage.StorageData;\n+import org.apache.skywalking.oap.server.core.storage.model.ColumnName;\n+import org.apache.skywalking.oap.server.core.storage.model.Model;\n+import org.apache.skywalking.oap.server.core.storage.model.ModelColumn;\n+import org.apache.skywalking.oap.server.core.storage.type.StorageDataType;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.influxdb.dto.Point;\n+\n+import static org.apache.skywalking.oap.server.core.analysis.TimeBucket.getTimestamp;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.ALARM;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.DATABASE_SLOW_STATEMENT;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.HTTP_ACCESS_LOG;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.PROFILE_TASK_LOG;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.PROFILE_TASK_SEGMENT_SNAPSHOT;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.SEGMENT;\n+\n+/**\n+ * A helper help to build a InfluxDB Point from StorageData.\n+ */\n+public class PointBuilder {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3838428d5feb0027fc6d06bcc2b178ca347b5bf"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1MDQ1NTQ4OnYy", "diffSide": "RIGHT", "path": "docker/oap-es7/docker-entrypoint.sh", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNVQxMjoxNzoxM1rOFqO3_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNVQxMjoxNzoxM1rOFqO3_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTgyODIyMQ==", "bodyText": "Should escape the $ character", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r379828221", "createdAt": "2020-02-15T12:17:13Z", "author": {"login": "kezhenxu94"}, "path": "docker/oap-es7/docker-entrypoint.sh", "diffHunk": "@@ -149,6 +149,37 @@ storage:\n EOT\n }\n \n+generateStorageInfluxDB() {\n+    cat <<EOT >> ${var_application_file}\n+storage:\n+  influx:\n+    # Metadata storage provider configuration\n+    metabaseType: ${SW_STORAGE_METABASE_TYPE:H2} # There are 2 options as Metabase provider, H2 or MySQL.\n+    h2Props:\n+      dataSourceClassName: ${SW_STORAGE_METABASE_DRIVER:org.h2.jdbcx.JdbcDataSource}\n+      dataSource.url: ${SW_STORAGE_METABASE_URL:jdbc:h2:mem:skywalking-oap-db}\n+      dataSource.user: ${SW_STORAGE_METABASE_USER:sa}\n+      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:}\n+    mysqlProps:\n+      jdbcUrl: ${SW_STORAGE_METABASE_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n+      dataSource.user: ${SW_STORAGE_METABASE_USER:root}\n+      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:root@1234}\n+      dataSource.cachePrepStmts: ${SW_STORAGE_METABASE_CACHE_PREP_STMTS:true}\n+      dataSource.prepStmtCacheSize: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_SIZE:250}\n+      dataSource.prepStmtCacheSqlLimit: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n+      dataSource.useServerPrepStmts: ${SW_STORAGE_METABASE_USE_SERVER_PREP_STMTS:true}\n+    metadataQueryMaxSize: ${SW_STORAGE_METABASE_QUERY_MAX_SIZE:5000}\n+    # InfluxDB configuration\n+    url: ${SW_STORAGE_INFLUXDB_URL:http://localhost:8086}\n+    user: ${SW_STORAGE_INFLUXDB_USER:root}\n+    password: ${SW_STORAGE_INFLUXDB_PASSWORD:}\n+    database: ${SW_STORAGE_INFLUXDB_DATABASE:skywalking}\n+    actions: ${SW_STORAGE_INFLUXDB_ACTIONS:1000} # the number of actions to collect\n+    duration: ${SW_STORAGE_INFLUXDB_DURATION:1000} # the time to wait at most (milliseconds)\n+    fetchTaskLogMaxSize: ${SW_STORAGE_INFLUXDB_FETCH_TASK_LOG_MAX_SIZE:5000} # the max number of fetch task log in a request", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e6105b7f01c414b97618106f21e52b760b0e828d"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1MDQ1NTkxOnYy", "diffSide": "RIGHT", "path": "docker/oap/docker-entrypoint.sh", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNVQxMjoxODoxOVrOFqO4PA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNVQxMjoxODoxOVrOFqO4PA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTgyODI4NA==", "bodyText": "Should escape the $ character", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r379828284", "createdAt": "2020-02-15T12:18:19Z", "author": {"login": "kezhenxu94"}, "path": "docker/oap/docker-entrypoint.sh", "diffHunk": "@@ -150,6 +150,37 @@ storage:\n EOT\n }\n \n+generateStorageInfluxDB() {\n+    cat <<EOT >> ${var_application_file}\n+storage:\n+  influx:\n+    # Metadata storage provider configuration\n+    metabaseType: ${SW_STORAGE_METABASE_TYPE:H2} # There are 2 options as Metabase provider, H2 or MySQL.\n+    h2Props:\n+      dataSourceClassName: ${SW_STORAGE_METABASE_DRIVER:org.h2.jdbcx.JdbcDataSource}\n+      dataSource.url: ${SW_STORAGE_METABASE_URL:jdbc:h2:mem:skywalking-oap-db}\n+      dataSource.user: ${SW_STORAGE_METABASE_USER:sa}\n+      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:}\n+    mysqlProps:\n+      jdbcUrl: ${SW_STORAGE_METABASE_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n+      dataSource.user: ${SW_STORAGE_METABASE_USER:root}\n+      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:root@1234}\n+      dataSource.cachePrepStmts: ${SW_STORAGE_METABASE_CACHE_PREP_STMTS:true}\n+      dataSource.prepStmtCacheSize: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_SIZE:250}\n+      dataSource.prepStmtCacheSqlLimit: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n+      dataSource.useServerPrepStmts: ${SW_STORAGE_METABASE_USE_SERVER_PREP_STMTS:true}\n+    metadataQueryMaxSize: ${SW_STORAGE_METABASE_QUERY_MAX_SIZE:5000}\n+    # InfluxDB configuration\n+    url: ${SW_STORAGE_INFLUXDB_URL:http://localhost:8086}\n+    user: ${SW_STORAGE_INFLUXDB_USER:root}\n+    password: ${SW_STORAGE_INFLUXDB_PASSWORD:}\n+    database: ${SW_STORAGE_INFLUXDB_DATABASE:skywalking}\n+    actions: ${SW_STORAGE_INFLUXDB_ACTIONS:1000} # the number of actions to collect\n+    duration: ${SW_STORAGE_INFLUXDB_DURATION:1000} # the time to wait at most (milliseconds)\n+    fetchTaskLogMaxSize: ${SW_STORAGE_INFLUXDB_FETCH_TASK_LOG_MAX_SIZE:5000} # the max number of fetch task log in a request", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e6105b7f01c414b97618106f21e52b760b0e828d"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1MDQ1OTQ2OnYy", "diffSide": "RIGHT", "path": "oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/TimeBucket.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNVQxMjoyODoyMlrOFqO6EA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNVQxMjoyODoyMlrOFqO6EA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTgyODc1Mg==", "bodyText": "mush -> must be", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r379828752", "createdAt": "2020-02-15T12:28:22Z", "author": {"login": "kezhenxu94"}, "path": "oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/TimeBucket.java", "diffHunk": "@@ -32,10 +32,119 @@ public static long getRecordTimeBucket(long time) {\n         return getTimeBucket(time, Downsampling.Second);\n     }\n \n+    /**\n+     * Record time bucket format in Minute Unit.\n+     *\n+     * @param time Timestamp\n+     * @return time in minute format.\n+     */\n     public static long getMinuteTimeBucket(long time) {\n         return getTimeBucket(time, Downsampling.Minute);\n     }\n \n+    /**\n+     * Convert TimeBucket to Timestamp in millisecond.\n+     *\n+     * @param timeBucket long\n+     * @return timestamp in millisecond unit\n+     */\n+    public static long getTimestamp(long timeBucket) {\n+        if (isSecondBucket(timeBucket)) {\n+            return getTimestamp(timeBucket, Downsampling.Second);\n+        } else if (isMinuteBucket(timeBucket)) {\n+            return getTimestamp(timeBucket, Downsampling.Minute);\n+        } else if (isHourBucket(timeBucket)) {\n+            return getTimestamp(timeBucket, Downsampling.Hour);\n+        } else if (isDayBucket(timeBucket)) {\n+            return getTimestamp(timeBucket, Downsampling.Day);\n+        } else if (isMonthBucket(timeBucket)) {\n+            return getTimestamp(timeBucket, Downsampling.Month);\n+        } else {\n+            throw new UnexpectedException(\"Unknown downsampling value.\");\n+        }\n+    }\n+\n+    /**\n+     * The format of timeBucket in minute Unit is \"yyyyMMddHHmmss\", so which means the TimeBucket mush between", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6e4375d038cd56498cd7f09365d6002136a3fd44"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1MDQ4NzI0OnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/query/ProfileThreadSnapshotQuery.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNVQxMzo0MzoyMFrOFqPHtg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNlQwNjo1Njo0NlrOFqSCEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTgzMjI0Ng==", "bodyText": "better to use org.apache.skywalking.apm.agent.core.base64.Base64 for consistence, and the default charset here is different from other places", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r379832246", "createdAt": "2020-02-15T13:43:20Z", "author": {"login": "kezhenxu94"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/query/ProfileThreadSnapshotQuery.java", "diffHunk": "@@ -0,0 +1,165 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.query;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.collect.Lists;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Base64;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import org.apache.skywalking.apm.util.StringUtil;\n+import org.apache.skywalking.oap.server.core.analysis.manual.segment.SegmentRecord;\n+import org.apache.skywalking.oap.server.core.profile.ProfileThreadSnapshotRecord;\n+import org.apache.skywalking.oap.server.core.query.entity.BasicTrace;\n+import org.apache.skywalking.oap.server.core.storage.profile.IProfileThreadSnapshotQueryDAO;\n+import org.apache.skywalking.oap.server.library.util.BooleanUtils;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.WhereQueryImpl;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.contains;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.eq;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.gte;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.lte;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.select;\n+\n+public class ProfileThreadSnapshotQuery implements IProfileThreadSnapshotQueryDAO {\n+    private final InfluxClient client;\n+\n+    public ProfileThreadSnapshotQuery(InfluxClient client) {\n+        this.client = client;\n+    }\n+\n+    @Override\n+    public List<BasicTrace> queryProfiledSegments(String taskId) throws IOException {\n+        WhereQueryImpl query = select(ProfileThreadSnapshotRecord.SEGMENT_ID)\n+            .from(client.getDatabase(), ProfileThreadSnapshotRecord.INDEX_NAME)\n+            .where()\n+            .and(eq(ProfileThreadSnapshotRecord.TASK_ID, taskId))\n+            .and(eq(ProfileThreadSnapshotRecord.SEQUENCE, 0));\n+\n+        final LinkedList<String> segments = new LinkedList<>();\n+        QueryResult.Series series = client.queryForSingleSeries(query);\n+        if (series == null) {\n+            return Collections.emptyList();\n+        }\n+        series.getValues().forEach(values -> {\n+            segments.add((String) values.get(1));\n+        });\n+\n+        if (segments.isEmpty()) {\n+            return Collections.emptyList();\n+        }\n+\n+        query = select()\n+            .function(\"bottom\", SegmentRecord.START_TIME, segments.size())\n+            .column(SegmentRecord.SEGMENT_ID)\n+            .column(SegmentRecord.START_TIME)\n+            .column(SegmentRecord.ENDPOINT_NAME)\n+            .column(SegmentRecord.LATENCY)\n+            .column(SegmentRecord.IS_ERROR)\n+            .column(SegmentRecord.TRACE_ID)\n+            .from(client.getDatabase(), SegmentRecord.INDEX_NAME)\n+            .where()\n+            .and(contains(SegmentRecord.SEGMENT_ID, Joiner.on(\"|\").join(segments)));\n+\n+        ArrayList<BasicTrace> result = Lists.newArrayListWithCapacity(segments.size());\n+        client.queryForSingleSeries(query)\n+              .getValues()\n+              .stream()\n+              .sorted((a, b) -> Long.compare(((Number) b.get(1)).longValue(), ((Number) a.get(1)).longValue()))\n+              .forEach(values -> {\n+                  BasicTrace basicTrace = new BasicTrace();\n+\n+                  basicTrace.setSegmentId((String) values.get(2));\n+                  basicTrace.setStart(String.valueOf(values.get(3)));\n+                  basicTrace.getEndpointNames().add((String) values.get(4));\n+                  basicTrace.setDuration((int) values.get(5));\n+                  basicTrace.setError(BooleanUtils.valueToBoolean((int) values.get(6)));\n+                  String traceIds = (String) values.get(7);\n+                  basicTrace.getTraceIds().add(traceIds);\n+\n+                  result.add(basicTrace);\n+              });\n+\n+        return result;\n+    }\n+\n+    @Override\n+    public int queryMinSequence(String segmentId, long start, long end) throws IOException {\n+        return querySequenceWithAgg(\"min\", segmentId, start, end);\n+    }\n+\n+    @Override\n+    public int queryMaxSequence(String segmentId, long start, long end) throws IOException {\n+        return querySequenceWithAgg(\"max\", segmentId, start, end);\n+    }\n+\n+    @Override\n+    public List<ProfileThreadSnapshotRecord> queryRecords(String segmentId, int minSequence,\n+                                                          int maxSequence) throws IOException {\n+        WhereQueryImpl query = select(\n+            ProfileThreadSnapshotRecord.TASK_ID,\n+            ProfileThreadSnapshotRecord.SEGMENT_ID,\n+            ProfileThreadSnapshotRecord.DUMP_TIME,\n+            ProfileThreadSnapshotRecord.SEQUENCE,\n+            ProfileThreadSnapshotRecord.STACK_BINARY\n+        )\n+            .from(client.getDatabase(), ProfileThreadSnapshotRecord.INDEX_NAME)\n+            .where(eq(ProfileThreadSnapshotRecord.SEGMENT_ID, segmentId))\n+            .and(gte(ProfileThreadSnapshotRecord.SEQUENCE, minSequence))\n+            .and(lte(ProfileThreadSnapshotRecord.SEQUENCE, maxSequence));\n+\n+        ArrayList<ProfileThreadSnapshotRecord> result = new ArrayList<>(maxSequence - minSequence);\n+        client.queryForSingleSeries(query).getValues().forEach(values -> {\n+            ProfileThreadSnapshotRecord record = new ProfileThreadSnapshotRecord();\n+\n+            record.setTaskId((String) values.get(1));\n+            record.setSegmentId((String) values.get(2));\n+            record.setDumpTime(((Number) values.get(3)).longValue());\n+            record.setSequence((int) values.get(4));\n+            String dataBinaryBase64 = String.valueOf(values.get(5));\n+            if (StringUtil.isNotEmpty(dataBinaryBase64)) {\n+                record.setStackBinary(Base64.getDecoder().decode(dataBinaryBase64));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6e4375d038cd56498cd7f09365d6002136a3fd44"}, "originalPosition": 142}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTg3OTk1Mg==", "bodyText": "This class is included in skywaking-agent-core module. We don't import it.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r379879952", "createdAt": "2020-02-16T06:56:46Z", "author": {"login": "dmsolr"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/query/ProfileThreadSnapshotQuery.java", "diffHunk": "@@ -0,0 +1,165 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.query;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.collect.Lists;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Base64;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import org.apache.skywalking.apm.util.StringUtil;\n+import org.apache.skywalking.oap.server.core.analysis.manual.segment.SegmentRecord;\n+import org.apache.skywalking.oap.server.core.profile.ProfileThreadSnapshotRecord;\n+import org.apache.skywalking.oap.server.core.query.entity.BasicTrace;\n+import org.apache.skywalking.oap.server.core.storage.profile.IProfileThreadSnapshotQueryDAO;\n+import org.apache.skywalking.oap.server.library.util.BooleanUtils;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.WhereQueryImpl;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.contains;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.eq;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.gte;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.lte;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.select;\n+\n+public class ProfileThreadSnapshotQuery implements IProfileThreadSnapshotQueryDAO {\n+    private final InfluxClient client;\n+\n+    public ProfileThreadSnapshotQuery(InfluxClient client) {\n+        this.client = client;\n+    }\n+\n+    @Override\n+    public List<BasicTrace> queryProfiledSegments(String taskId) throws IOException {\n+        WhereQueryImpl query = select(ProfileThreadSnapshotRecord.SEGMENT_ID)\n+            .from(client.getDatabase(), ProfileThreadSnapshotRecord.INDEX_NAME)\n+            .where()\n+            .and(eq(ProfileThreadSnapshotRecord.TASK_ID, taskId))\n+            .and(eq(ProfileThreadSnapshotRecord.SEQUENCE, 0));\n+\n+        final LinkedList<String> segments = new LinkedList<>();\n+        QueryResult.Series series = client.queryForSingleSeries(query);\n+        if (series == null) {\n+            return Collections.emptyList();\n+        }\n+        series.getValues().forEach(values -> {\n+            segments.add((String) values.get(1));\n+        });\n+\n+        if (segments.isEmpty()) {\n+            return Collections.emptyList();\n+        }\n+\n+        query = select()\n+            .function(\"bottom\", SegmentRecord.START_TIME, segments.size())\n+            .column(SegmentRecord.SEGMENT_ID)\n+            .column(SegmentRecord.START_TIME)\n+            .column(SegmentRecord.ENDPOINT_NAME)\n+            .column(SegmentRecord.LATENCY)\n+            .column(SegmentRecord.IS_ERROR)\n+            .column(SegmentRecord.TRACE_ID)\n+            .from(client.getDatabase(), SegmentRecord.INDEX_NAME)\n+            .where()\n+            .and(contains(SegmentRecord.SEGMENT_ID, Joiner.on(\"|\").join(segments)));\n+\n+        ArrayList<BasicTrace> result = Lists.newArrayListWithCapacity(segments.size());\n+        client.queryForSingleSeries(query)\n+              .getValues()\n+              .stream()\n+              .sorted((a, b) -> Long.compare(((Number) b.get(1)).longValue(), ((Number) a.get(1)).longValue()))\n+              .forEach(values -> {\n+                  BasicTrace basicTrace = new BasicTrace();\n+\n+                  basicTrace.setSegmentId((String) values.get(2));\n+                  basicTrace.setStart(String.valueOf(values.get(3)));\n+                  basicTrace.getEndpointNames().add((String) values.get(4));\n+                  basicTrace.setDuration((int) values.get(5));\n+                  basicTrace.setError(BooleanUtils.valueToBoolean((int) values.get(6)));\n+                  String traceIds = (String) values.get(7);\n+                  basicTrace.getTraceIds().add(traceIds);\n+\n+                  result.add(basicTrace);\n+              });\n+\n+        return result;\n+    }\n+\n+    @Override\n+    public int queryMinSequence(String segmentId, long start, long end) throws IOException {\n+        return querySequenceWithAgg(\"min\", segmentId, start, end);\n+    }\n+\n+    @Override\n+    public int queryMaxSequence(String segmentId, long start, long end) throws IOException {\n+        return querySequenceWithAgg(\"max\", segmentId, start, end);\n+    }\n+\n+    @Override\n+    public List<ProfileThreadSnapshotRecord> queryRecords(String segmentId, int minSequence,\n+                                                          int maxSequence) throws IOException {\n+        WhereQueryImpl query = select(\n+            ProfileThreadSnapshotRecord.TASK_ID,\n+            ProfileThreadSnapshotRecord.SEGMENT_ID,\n+            ProfileThreadSnapshotRecord.DUMP_TIME,\n+            ProfileThreadSnapshotRecord.SEQUENCE,\n+            ProfileThreadSnapshotRecord.STACK_BINARY\n+        )\n+            .from(client.getDatabase(), ProfileThreadSnapshotRecord.INDEX_NAME)\n+            .where(eq(ProfileThreadSnapshotRecord.SEGMENT_ID, segmentId))\n+            .and(gte(ProfileThreadSnapshotRecord.SEQUENCE, minSequence))\n+            .and(lte(ProfileThreadSnapshotRecord.SEQUENCE, maxSequence));\n+\n+        ArrayList<ProfileThreadSnapshotRecord> result = new ArrayList<>(maxSequence - minSequence);\n+        client.queryForSingleSeries(query).getValues().forEach(values -> {\n+            ProfileThreadSnapshotRecord record = new ProfileThreadSnapshotRecord();\n+\n+            record.setTaskId((String) values.get(1));\n+            record.setSegmentId((String) values.get(2));\n+            record.setDumpTime(((Number) values.get(3)).longValue());\n+            record.setSequence((int) values.get(4));\n+            String dataBinaryBase64 = String.valueOf(values.get(5));\n+            if (StringUtil.isNotEmpty(dataBinaryBase64)) {\n+                record.setStackBinary(Base64.getDecoder().decode(dataBinaryBase64));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTgzMjI0Ng=="}, "originalCommit": {"oid": "6e4375d038cd56498cd7f09365d6002136a3fd44"}, "originalPosition": 142}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1MDQ5MDg5OnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/query/TraceQuery.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNVQxMzo1MjoyOVrOFqPJlQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNlQwNjo0NDozM1rOFqR_8g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTgzMjcyNQ==", "bodyText": "is there any particular reason why you paginate here instead of paginating in InfluxDB server side (using the .limit)?\nwhy do you sort them again in a different order (SEGMENT_ID?) when you already have top by QueryOrder in line 74 - 80\n\nhope I did not miss any context", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r379832725", "createdAt": "2020-02-15T13:52:29Z", "author": {"login": "kezhenxu94"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/query/TraceQuery.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.query;\n+\n+import com.google.common.collect.Lists;\n+import java.io.IOException;\n+import java.util.Base64;\n+import java.util.Collections;\n+import java.util.List;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.skywalking.oap.server.core.analysis.manual.segment.SegmentRecord;\n+import org.apache.skywalking.oap.server.core.query.entity.BasicTrace;\n+import org.apache.skywalking.oap.server.core.query.entity.QueryOrder;\n+import org.apache.skywalking.oap.server.core.query.entity.Span;\n+import org.apache.skywalking.oap.server.core.query.entity.TraceBrief;\n+import org.apache.skywalking.oap.server.core.query.entity.TraceState;\n+import org.apache.skywalking.oap.server.core.storage.query.ITraceQueryDAO;\n+import org.apache.skywalking.oap.server.library.util.BooleanUtils;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.base.RecordDAO;\n+import org.elasticsearch.common.Strings;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.SelectQueryImpl;\n+import org.influxdb.querybuilder.WhereQueryImpl;\n+import org.influxdb.querybuilder.clauses.Clause;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.eq;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.gte;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.lte;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.regex;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.select;\n+\n+@Slf4j\n+public class TraceQuery implements ITraceQueryDAO {\n+    private final InfluxClient client;\n+\n+    public TraceQuery(InfluxClient client) {\n+        this.client = client;\n+    }\n+\n+    @Override\n+    public TraceBrief queryBasicTraces(long startSecondTB,\n+                                       long endSecondTB,\n+                                       long minDuration,\n+                                       long maxDuration,\n+                                       String endpointName,\n+                                       int serviceId,\n+                                       int serviceInstanceId,\n+                                       int endpointId,\n+                                       String traceId,\n+                                       int limit,\n+                                       int from,\n+                                       TraceState traceState,\n+                                       QueryOrder queryOrder)\n+        throws IOException {\n+\n+        String orderBy = SegmentRecord.START_TIME;\n+        if (queryOrder == QueryOrder.BY_DURATION) {\n+            orderBy = SegmentRecord.LATENCY;\n+        }\n+\n+        WhereQueryImpl<SelectQueryImpl> recallQuery = select()\n+            .function(\"top\", orderBy, limit + from)\n+            .column(SegmentRecord.SEGMENT_ID)\n+            .column(SegmentRecord.START_TIME)\n+            .column(SegmentRecord.ENDPOINT_NAME)\n+            .column(SegmentRecord.LATENCY)\n+            .column(SegmentRecord.IS_ERROR)\n+            .column(SegmentRecord.TRACE_ID)\n+            .from(client.getDatabase(), SegmentRecord.INDEX_NAME)\n+            .where();\n+\n+        if (startSecondTB != 0 && endSecondTB != 0) {\n+            recallQuery.and(gte(SegmentRecord.TIME_BUCKET, startSecondTB))\n+                       .and(lte(SegmentRecord.TIME_BUCKET, endSecondTB));\n+        }\n+        if (minDuration != 0) {\n+            recallQuery.and(gte(SegmentRecord.LATENCY, minDuration));\n+        }\n+        if (maxDuration != 0) {\n+            recallQuery.and(lte(SegmentRecord.LATENCY, maxDuration));\n+        }\n+        if (!Strings.isNullOrEmpty(endpointName)) {\n+            recallQuery.and(regex(SegmentRecord.ENDPOINT_NAME, \"/\" + endpointName.replaceAll(\"/\", \"\\\\\\\\/\") + \"/\"));\n+        }\n+        if (serviceId != 0) {\n+            recallQuery.and(eq(RecordDAO.TAG_SERVICE_ID, String.valueOf(serviceId)));\n+        }\n+        if (serviceInstanceId != 0) {\n+            recallQuery.and(eq(SegmentRecord.SERVICE_INSTANCE_ID, serviceInstanceId));\n+        }\n+        if (endpointId != 0) {\n+            recallQuery.and(eq(SegmentRecord.ENDPOINT_ID, endpointId));\n+        }\n+        if (!Strings.isNullOrEmpty(traceId)) {\n+            recallQuery.and(eq(SegmentRecord.TRACE_ID, traceId));\n+        }\n+        switch (traceState) {\n+            case ERROR:\n+                recallQuery.and(eq(SegmentRecord.IS_ERROR, BooleanUtils.TRUE));\n+                break;\n+            case SUCCESS:\n+                recallQuery.and(eq(SegmentRecord.IS_ERROR, BooleanUtils.FALSE));\n+                break;\n+        }\n+\n+        WhereQueryImpl<SelectQueryImpl> countQuery = select()\n+            .count(SegmentRecord.ENDPOINT_ID)\n+            .from(client.getDatabase(), SegmentRecord.INDEX_NAME)\n+            .where();\n+        for (Clause clause : recallQuery.getClauses()) {\n+            countQuery.where(clause);\n+        }\n+        Query query = new Query(countQuery.getCommand() + recallQuery.getCommand());\n+\n+        List<QueryResult.Result> results = client.query(query);\n+        if (log.isDebugEnabled()) {\n+            log.debug(\"SQL: {} result set: {}\", query.getCommand(), results);\n+        }\n+        if (results.size() != 2) {\n+            throw new IOException(\"Expecting to get 2 Results, but it is \" + results.size());\n+        }\n+        List<QueryResult.Series> counter = results.get(0).getSeries();\n+        List<QueryResult.Series> result = results.get(1).getSeries();\n+        if (result == null || result.isEmpty()) {\n+            return new TraceBrief();\n+        }\n+\n+        TraceBrief traceBrief = new TraceBrief();\n+        traceBrief.setTotal(((Number) counter.get(0).getValues().get(0).get(1)).intValue());\n+\n+        result.get(0).getValues().stream().sorted((a, b) -> {\n+            return Long.compare(((Number) b.get(1)).longValue(), ((Number) a.get(1)).longValue());\n+        }).skip(from).forEach(values -> {\n+            BasicTrace basicTrace = new BasicTrace();\n+\n+            basicTrace.setSegmentId((String) values.get(2));\n+            basicTrace.setStart(String.valueOf((long) values.get(3)));\n+            basicTrace.getEndpointNames().add((String) values.get(4));\n+            basicTrace.setDuration((int) values.get(5));\n+            basicTrace.setError(BooleanUtils.valueToBoolean((int) values.get(6)));\n+            basicTrace.getTraceIds().add((String) values.get(7));\n+\n+            traceBrief.getTraces().add(basicTrace);\n+        });", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6e4375d038cd56498cd7f09365d6002136a3fd44"}, "originalPosition": 162}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTg2MzcxMg==", "bodyText": "It took me a lot of time to get it clearly. It is a bad story.\n\ntop/bottom cannot work with limit.\nI think top/bottom collects data by PriorityQueue. And it does not re-sort them in the result set. So we get the dataset unorder. Anyway, we always get the un-ordered result set in reality.\n\nI mean, the function top works after limit, if limit enabled.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r379863712", "createdAt": "2020-02-15T23:57:33Z", "author": {"login": "dmsolr"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/query/TraceQuery.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.query;\n+\n+import com.google.common.collect.Lists;\n+import java.io.IOException;\n+import java.util.Base64;\n+import java.util.Collections;\n+import java.util.List;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.skywalking.oap.server.core.analysis.manual.segment.SegmentRecord;\n+import org.apache.skywalking.oap.server.core.query.entity.BasicTrace;\n+import org.apache.skywalking.oap.server.core.query.entity.QueryOrder;\n+import org.apache.skywalking.oap.server.core.query.entity.Span;\n+import org.apache.skywalking.oap.server.core.query.entity.TraceBrief;\n+import org.apache.skywalking.oap.server.core.query.entity.TraceState;\n+import org.apache.skywalking.oap.server.core.storage.query.ITraceQueryDAO;\n+import org.apache.skywalking.oap.server.library.util.BooleanUtils;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.base.RecordDAO;\n+import org.elasticsearch.common.Strings;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.SelectQueryImpl;\n+import org.influxdb.querybuilder.WhereQueryImpl;\n+import org.influxdb.querybuilder.clauses.Clause;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.eq;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.gte;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.lte;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.regex;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.select;\n+\n+@Slf4j\n+public class TraceQuery implements ITraceQueryDAO {\n+    private final InfluxClient client;\n+\n+    public TraceQuery(InfluxClient client) {\n+        this.client = client;\n+    }\n+\n+    @Override\n+    public TraceBrief queryBasicTraces(long startSecondTB,\n+                                       long endSecondTB,\n+                                       long minDuration,\n+                                       long maxDuration,\n+                                       String endpointName,\n+                                       int serviceId,\n+                                       int serviceInstanceId,\n+                                       int endpointId,\n+                                       String traceId,\n+                                       int limit,\n+                                       int from,\n+                                       TraceState traceState,\n+                                       QueryOrder queryOrder)\n+        throws IOException {\n+\n+        String orderBy = SegmentRecord.START_TIME;\n+        if (queryOrder == QueryOrder.BY_DURATION) {\n+            orderBy = SegmentRecord.LATENCY;\n+        }\n+\n+        WhereQueryImpl<SelectQueryImpl> recallQuery = select()\n+            .function(\"top\", orderBy, limit + from)\n+            .column(SegmentRecord.SEGMENT_ID)\n+            .column(SegmentRecord.START_TIME)\n+            .column(SegmentRecord.ENDPOINT_NAME)\n+            .column(SegmentRecord.LATENCY)\n+            .column(SegmentRecord.IS_ERROR)\n+            .column(SegmentRecord.TRACE_ID)\n+            .from(client.getDatabase(), SegmentRecord.INDEX_NAME)\n+            .where();\n+\n+        if (startSecondTB != 0 && endSecondTB != 0) {\n+            recallQuery.and(gte(SegmentRecord.TIME_BUCKET, startSecondTB))\n+                       .and(lte(SegmentRecord.TIME_BUCKET, endSecondTB));\n+        }\n+        if (minDuration != 0) {\n+            recallQuery.and(gte(SegmentRecord.LATENCY, minDuration));\n+        }\n+        if (maxDuration != 0) {\n+            recallQuery.and(lte(SegmentRecord.LATENCY, maxDuration));\n+        }\n+        if (!Strings.isNullOrEmpty(endpointName)) {\n+            recallQuery.and(regex(SegmentRecord.ENDPOINT_NAME, \"/\" + endpointName.replaceAll(\"/\", \"\\\\\\\\/\") + \"/\"));\n+        }\n+        if (serviceId != 0) {\n+            recallQuery.and(eq(RecordDAO.TAG_SERVICE_ID, String.valueOf(serviceId)));\n+        }\n+        if (serviceInstanceId != 0) {\n+            recallQuery.and(eq(SegmentRecord.SERVICE_INSTANCE_ID, serviceInstanceId));\n+        }\n+        if (endpointId != 0) {\n+            recallQuery.and(eq(SegmentRecord.ENDPOINT_ID, endpointId));\n+        }\n+        if (!Strings.isNullOrEmpty(traceId)) {\n+            recallQuery.and(eq(SegmentRecord.TRACE_ID, traceId));\n+        }\n+        switch (traceState) {\n+            case ERROR:\n+                recallQuery.and(eq(SegmentRecord.IS_ERROR, BooleanUtils.TRUE));\n+                break;\n+            case SUCCESS:\n+                recallQuery.and(eq(SegmentRecord.IS_ERROR, BooleanUtils.FALSE));\n+                break;\n+        }\n+\n+        WhereQueryImpl<SelectQueryImpl> countQuery = select()\n+            .count(SegmentRecord.ENDPOINT_ID)\n+            .from(client.getDatabase(), SegmentRecord.INDEX_NAME)\n+            .where();\n+        for (Clause clause : recallQuery.getClauses()) {\n+            countQuery.where(clause);\n+        }\n+        Query query = new Query(countQuery.getCommand() + recallQuery.getCommand());\n+\n+        List<QueryResult.Result> results = client.query(query);\n+        if (log.isDebugEnabled()) {\n+            log.debug(\"SQL: {} result set: {}\", query.getCommand(), results);\n+        }\n+        if (results.size() != 2) {\n+            throw new IOException(\"Expecting to get 2 Results, but it is \" + results.size());\n+        }\n+        List<QueryResult.Series> counter = results.get(0).getSeries();\n+        List<QueryResult.Series> result = results.get(1).getSeries();\n+        if (result == null || result.isEmpty()) {\n+            return new TraceBrief();\n+        }\n+\n+        TraceBrief traceBrief = new TraceBrief();\n+        traceBrief.setTotal(((Number) counter.get(0).getValues().get(0).get(1)).intValue());\n+\n+        result.get(0).getValues().stream().sorted((a, b) -> {\n+            return Long.compare(((Number) b.get(1)).longValue(), ((Number) a.get(1)).longValue());\n+        }).skip(from).forEach(values -> {\n+            BasicTrace basicTrace = new BasicTrace();\n+\n+            basicTrace.setSegmentId((String) values.get(2));\n+            basicTrace.setStart(String.valueOf((long) values.get(3)));\n+            basicTrace.getEndpointNames().add((String) values.get(4));\n+            basicTrace.setDuration((int) values.get(5));\n+            basicTrace.setError(BooleanUtils.valueToBoolean((int) values.get(6)));\n+            basicTrace.getTraceIds().add((String) values.get(7));\n+\n+            traceBrief.getTraces().add(basicTrace);\n+        });", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTgzMjcyNQ=="}, "originalCommit": {"oid": "6e4375d038cd56498cd7f09365d6002136a3fd44"}, "originalPosition": 162}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTg2NzAzMg==", "bodyText": "Resolved\nThe question is more about why you sort them in a different order without taking care of the given orderBy", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r379867032", "createdAt": "2020-02-16T01:05:08Z", "author": {"login": "kezhenxu94"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/query/TraceQuery.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.query;\n+\n+import com.google.common.collect.Lists;\n+import java.io.IOException;\n+import java.util.Base64;\n+import java.util.Collections;\n+import java.util.List;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.skywalking.oap.server.core.analysis.manual.segment.SegmentRecord;\n+import org.apache.skywalking.oap.server.core.query.entity.BasicTrace;\n+import org.apache.skywalking.oap.server.core.query.entity.QueryOrder;\n+import org.apache.skywalking.oap.server.core.query.entity.Span;\n+import org.apache.skywalking.oap.server.core.query.entity.TraceBrief;\n+import org.apache.skywalking.oap.server.core.query.entity.TraceState;\n+import org.apache.skywalking.oap.server.core.storage.query.ITraceQueryDAO;\n+import org.apache.skywalking.oap.server.library.util.BooleanUtils;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.base.RecordDAO;\n+import org.elasticsearch.common.Strings;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.SelectQueryImpl;\n+import org.influxdb.querybuilder.WhereQueryImpl;\n+import org.influxdb.querybuilder.clauses.Clause;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.eq;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.gte;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.lte;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.regex;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.select;\n+\n+@Slf4j\n+public class TraceQuery implements ITraceQueryDAO {\n+    private final InfluxClient client;\n+\n+    public TraceQuery(InfluxClient client) {\n+        this.client = client;\n+    }\n+\n+    @Override\n+    public TraceBrief queryBasicTraces(long startSecondTB,\n+                                       long endSecondTB,\n+                                       long minDuration,\n+                                       long maxDuration,\n+                                       String endpointName,\n+                                       int serviceId,\n+                                       int serviceInstanceId,\n+                                       int endpointId,\n+                                       String traceId,\n+                                       int limit,\n+                                       int from,\n+                                       TraceState traceState,\n+                                       QueryOrder queryOrder)\n+        throws IOException {\n+\n+        String orderBy = SegmentRecord.START_TIME;\n+        if (queryOrder == QueryOrder.BY_DURATION) {\n+            orderBy = SegmentRecord.LATENCY;\n+        }\n+\n+        WhereQueryImpl<SelectQueryImpl> recallQuery = select()\n+            .function(\"top\", orderBy, limit + from)\n+            .column(SegmentRecord.SEGMENT_ID)\n+            .column(SegmentRecord.START_TIME)\n+            .column(SegmentRecord.ENDPOINT_NAME)\n+            .column(SegmentRecord.LATENCY)\n+            .column(SegmentRecord.IS_ERROR)\n+            .column(SegmentRecord.TRACE_ID)\n+            .from(client.getDatabase(), SegmentRecord.INDEX_NAME)\n+            .where();\n+\n+        if (startSecondTB != 0 && endSecondTB != 0) {\n+            recallQuery.and(gte(SegmentRecord.TIME_BUCKET, startSecondTB))\n+                       .and(lte(SegmentRecord.TIME_BUCKET, endSecondTB));\n+        }\n+        if (minDuration != 0) {\n+            recallQuery.and(gte(SegmentRecord.LATENCY, minDuration));\n+        }\n+        if (maxDuration != 0) {\n+            recallQuery.and(lte(SegmentRecord.LATENCY, maxDuration));\n+        }\n+        if (!Strings.isNullOrEmpty(endpointName)) {\n+            recallQuery.and(regex(SegmentRecord.ENDPOINT_NAME, \"/\" + endpointName.replaceAll(\"/\", \"\\\\\\\\/\") + \"/\"));\n+        }\n+        if (serviceId != 0) {\n+            recallQuery.and(eq(RecordDAO.TAG_SERVICE_ID, String.valueOf(serviceId)));\n+        }\n+        if (serviceInstanceId != 0) {\n+            recallQuery.and(eq(SegmentRecord.SERVICE_INSTANCE_ID, serviceInstanceId));\n+        }\n+        if (endpointId != 0) {\n+            recallQuery.and(eq(SegmentRecord.ENDPOINT_ID, endpointId));\n+        }\n+        if (!Strings.isNullOrEmpty(traceId)) {\n+            recallQuery.and(eq(SegmentRecord.TRACE_ID, traceId));\n+        }\n+        switch (traceState) {\n+            case ERROR:\n+                recallQuery.and(eq(SegmentRecord.IS_ERROR, BooleanUtils.TRUE));\n+                break;\n+            case SUCCESS:\n+                recallQuery.and(eq(SegmentRecord.IS_ERROR, BooleanUtils.FALSE));\n+                break;\n+        }\n+\n+        WhereQueryImpl<SelectQueryImpl> countQuery = select()\n+            .count(SegmentRecord.ENDPOINT_ID)\n+            .from(client.getDatabase(), SegmentRecord.INDEX_NAME)\n+            .where();\n+        for (Clause clause : recallQuery.getClauses()) {\n+            countQuery.where(clause);\n+        }\n+        Query query = new Query(countQuery.getCommand() + recallQuery.getCommand());\n+\n+        List<QueryResult.Result> results = client.query(query);\n+        if (log.isDebugEnabled()) {\n+            log.debug(\"SQL: {} result set: {}\", query.getCommand(), results);\n+        }\n+        if (results.size() != 2) {\n+            throw new IOException(\"Expecting to get 2 Results, but it is \" + results.size());\n+        }\n+        List<QueryResult.Series> counter = results.get(0).getSeries();\n+        List<QueryResult.Series> result = results.get(1).getSeries();\n+        if (result == null || result.isEmpty()) {\n+            return new TraceBrief();\n+        }\n+\n+        TraceBrief traceBrief = new TraceBrief();\n+        traceBrief.setTotal(((Number) counter.get(0).getValues().get(0).get(1)).intValue());\n+\n+        result.get(0).getValues().stream().sorted((a, b) -> {\n+            return Long.compare(((Number) b.get(1)).longValue(), ((Number) a.get(1)).longValue());\n+        }).skip(from).forEach(values -> {\n+            BasicTrace basicTrace = new BasicTrace();\n+\n+            basicTrace.setSegmentId((String) values.get(2));\n+            basicTrace.setStart(String.valueOf((long) values.get(3)));\n+            basicTrace.getEndpointNames().add((String) values.get(4));\n+            basicTrace.setDuration((int) values.get(5));\n+            basicTrace.setError(BooleanUtils.valueToBoolean((int) values.get(6)));\n+            basicTrace.getTraceIds().add((String) values.get(7));\n+\n+            traceBrief.getTraces().add(basicTrace);\n+        });", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTgzMjcyNQ=="}, "originalCommit": {"oid": "6e4375d038cd56498cd7f09365d6002136a3fd44"}, "originalPosition": 162}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTg2NzEyOQ==", "bodyText": "And there may be performance issue when paging deeply", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r379867129", "createdAt": "2020-02-16T01:07:43Z", "author": {"login": "kezhenxu94"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/query/TraceQuery.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.query;\n+\n+import com.google.common.collect.Lists;\n+import java.io.IOException;\n+import java.util.Base64;\n+import java.util.Collections;\n+import java.util.List;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.skywalking.oap.server.core.analysis.manual.segment.SegmentRecord;\n+import org.apache.skywalking.oap.server.core.query.entity.BasicTrace;\n+import org.apache.skywalking.oap.server.core.query.entity.QueryOrder;\n+import org.apache.skywalking.oap.server.core.query.entity.Span;\n+import org.apache.skywalking.oap.server.core.query.entity.TraceBrief;\n+import org.apache.skywalking.oap.server.core.query.entity.TraceState;\n+import org.apache.skywalking.oap.server.core.storage.query.ITraceQueryDAO;\n+import org.apache.skywalking.oap.server.library.util.BooleanUtils;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.base.RecordDAO;\n+import org.elasticsearch.common.Strings;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.SelectQueryImpl;\n+import org.influxdb.querybuilder.WhereQueryImpl;\n+import org.influxdb.querybuilder.clauses.Clause;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.eq;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.gte;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.lte;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.regex;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.select;\n+\n+@Slf4j\n+public class TraceQuery implements ITraceQueryDAO {\n+    private final InfluxClient client;\n+\n+    public TraceQuery(InfluxClient client) {\n+        this.client = client;\n+    }\n+\n+    @Override\n+    public TraceBrief queryBasicTraces(long startSecondTB,\n+                                       long endSecondTB,\n+                                       long minDuration,\n+                                       long maxDuration,\n+                                       String endpointName,\n+                                       int serviceId,\n+                                       int serviceInstanceId,\n+                                       int endpointId,\n+                                       String traceId,\n+                                       int limit,\n+                                       int from,\n+                                       TraceState traceState,\n+                                       QueryOrder queryOrder)\n+        throws IOException {\n+\n+        String orderBy = SegmentRecord.START_TIME;\n+        if (queryOrder == QueryOrder.BY_DURATION) {\n+            orderBy = SegmentRecord.LATENCY;\n+        }\n+\n+        WhereQueryImpl<SelectQueryImpl> recallQuery = select()\n+            .function(\"top\", orderBy, limit + from)\n+            .column(SegmentRecord.SEGMENT_ID)\n+            .column(SegmentRecord.START_TIME)\n+            .column(SegmentRecord.ENDPOINT_NAME)\n+            .column(SegmentRecord.LATENCY)\n+            .column(SegmentRecord.IS_ERROR)\n+            .column(SegmentRecord.TRACE_ID)\n+            .from(client.getDatabase(), SegmentRecord.INDEX_NAME)\n+            .where();\n+\n+        if (startSecondTB != 0 && endSecondTB != 0) {\n+            recallQuery.and(gte(SegmentRecord.TIME_BUCKET, startSecondTB))\n+                       .and(lte(SegmentRecord.TIME_BUCKET, endSecondTB));\n+        }\n+        if (minDuration != 0) {\n+            recallQuery.and(gte(SegmentRecord.LATENCY, minDuration));\n+        }\n+        if (maxDuration != 0) {\n+            recallQuery.and(lte(SegmentRecord.LATENCY, maxDuration));\n+        }\n+        if (!Strings.isNullOrEmpty(endpointName)) {\n+            recallQuery.and(regex(SegmentRecord.ENDPOINT_NAME, \"/\" + endpointName.replaceAll(\"/\", \"\\\\\\\\/\") + \"/\"));\n+        }\n+        if (serviceId != 0) {\n+            recallQuery.and(eq(RecordDAO.TAG_SERVICE_ID, String.valueOf(serviceId)));\n+        }\n+        if (serviceInstanceId != 0) {\n+            recallQuery.and(eq(SegmentRecord.SERVICE_INSTANCE_ID, serviceInstanceId));\n+        }\n+        if (endpointId != 0) {\n+            recallQuery.and(eq(SegmentRecord.ENDPOINT_ID, endpointId));\n+        }\n+        if (!Strings.isNullOrEmpty(traceId)) {\n+            recallQuery.and(eq(SegmentRecord.TRACE_ID, traceId));\n+        }\n+        switch (traceState) {\n+            case ERROR:\n+                recallQuery.and(eq(SegmentRecord.IS_ERROR, BooleanUtils.TRUE));\n+                break;\n+            case SUCCESS:\n+                recallQuery.and(eq(SegmentRecord.IS_ERROR, BooleanUtils.FALSE));\n+                break;\n+        }\n+\n+        WhereQueryImpl<SelectQueryImpl> countQuery = select()\n+            .count(SegmentRecord.ENDPOINT_ID)\n+            .from(client.getDatabase(), SegmentRecord.INDEX_NAME)\n+            .where();\n+        for (Clause clause : recallQuery.getClauses()) {\n+            countQuery.where(clause);\n+        }\n+        Query query = new Query(countQuery.getCommand() + recallQuery.getCommand());\n+\n+        List<QueryResult.Result> results = client.query(query);\n+        if (log.isDebugEnabled()) {\n+            log.debug(\"SQL: {} result set: {}\", query.getCommand(), results);\n+        }\n+        if (results.size() != 2) {\n+            throw new IOException(\"Expecting to get 2 Results, but it is \" + results.size());\n+        }\n+        List<QueryResult.Series> counter = results.get(0).getSeries();\n+        List<QueryResult.Series> result = results.get(1).getSeries();\n+        if (result == null || result.isEmpty()) {\n+            return new TraceBrief();\n+        }\n+\n+        TraceBrief traceBrief = new TraceBrief();\n+        traceBrief.setTotal(((Number) counter.get(0).getValues().get(0).get(1)).intValue());\n+\n+        result.get(0).getValues().stream().sorted((a, b) -> {\n+            return Long.compare(((Number) b.get(1)).longValue(), ((Number) a.get(1)).longValue());\n+        }).skip(from).forEach(values -> {\n+            BasicTrace basicTrace = new BasicTrace();\n+\n+            basicTrace.setSegmentId((String) values.get(2));\n+            basicTrace.setStart(String.valueOf((long) values.get(3)));\n+            basicTrace.getEndpointNames().add((String) values.get(4));\n+            basicTrace.setDuration((int) values.get(5));\n+            basicTrace.setError(BooleanUtils.valueToBoolean((int) values.get(6)));\n+            basicTrace.getTraceIds().add((String) values.get(7));\n+\n+            traceBrief.getTraces().add(basicTrace);\n+        });", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTgzMjcyNQ=="}, "originalCommit": {"oid": "6e4375d038cd56498cd7f09365d6002136a3fd44"}, "originalPosition": 162}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTg3OTQxMA==", "bodyText": "I got it. InfluxDB only ORDER BY time supported at this time. As far as I know, most of TSDB have the same issue.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r379879410", "createdAt": "2020-02-16T06:44:33Z", "author": {"login": "dmsolr"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/query/TraceQuery.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.query;\n+\n+import com.google.common.collect.Lists;\n+import java.io.IOException;\n+import java.util.Base64;\n+import java.util.Collections;\n+import java.util.List;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.skywalking.oap.server.core.analysis.manual.segment.SegmentRecord;\n+import org.apache.skywalking.oap.server.core.query.entity.BasicTrace;\n+import org.apache.skywalking.oap.server.core.query.entity.QueryOrder;\n+import org.apache.skywalking.oap.server.core.query.entity.Span;\n+import org.apache.skywalking.oap.server.core.query.entity.TraceBrief;\n+import org.apache.skywalking.oap.server.core.query.entity.TraceState;\n+import org.apache.skywalking.oap.server.core.storage.query.ITraceQueryDAO;\n+import org.apache.skywalking.oap.server.library.util.BooleanUtils;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.base.RecordDAO;\n+import org.elasticsearch.common.Strings;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.SelectQueryImpl;\n+import org.influxdb.querybuilder.WhereQueryImpl;\n+import org.influxdb.querybuilder.clauses.Clause;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.eq;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.gte;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.lte;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.regex;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.select;\n+\n+@Slf4j\n+public class TraceQuery implements ITraceQueryDAO {\n+    private final InfluxClient client;\n+\n+    public TraceQuery(InfluxClient client) {\n+        this.client = client;\n+    }\n+\n+    @Override\n+    public TraceBrief queryBasicTraces(long startSecondTB,\n+                                       long endSecondTB,\n+                                       long minDuration,\n+                                       long maxDuration,\n+                                       String endpointName,\n+                                       int serviceId,\n+                                       int serviceInstanceId,\n+                                       int endpointId,\n+                                       String traceId,\n+                                       int limit,\n+                                       int from,\n+                                       TraceState traceState,\n+                                       QueryOrder queryOrder)\n+        throws IOException {\n+\n+        String orderBy = SegmentRecord.START_TIME;\n+        if (queryOrder == QueryOrder.BY_DURATION) {\n+            orderBy = SegmentRecord.LATENCY;\n+        }\n+\n+        WhereQueryImpl<SelectQueryImpl> recallQuery = select()\n+            .function(\"top\", orderBy, limit + from)\n+            .column(SegmentRecord.SEGMENT_ID)\n+            .column(SegmentRecord.START_TIME)\n+            .column(SegmentRecord.ENDPOINT_NAME)\n+            .column(SegmentRecord.LATENCY)\n+            .column(SegmentRecord.IS_ERROR)\n+            .column(SegmentRecord.TRACE_ID)\n+            .from(client.getDatabase(), SegmentRecord.INDEX_NAME)\n+            .where();\n+\n+        if (startSecondTB != 0 && endSecondTB != 0) {\n+            recallQuery.and(gte(SegmentRecord.TIME_BUCKET, startSecondTB))\n+                       .and(lte(SegmentRecord.TIME_BUCKET, endSecondTB));\n+        }\n+        if (minDuration != 0) {\n+            recallQuery.and(gte(SegmentRecord.LATENCY, minDuration));\n+        }\n+        if (maxDuration != 0) {\n+            recallQuery.and(lte(SegmentRecord.LATENCY, maxDuration));\n+        }\n+        if (!Strings.isNullOrEmpty(endpointName)) {\n+            recallQuery.and(regex(SegmentRecord.ENDPOINT_NAME, \"/\" + endpointName.replaceAll(\"/\", \"\\\\\\\\/\") + \"/\"));\n+        }\n+        if (serviceId != 0) {\n+            recallQuery.and(eq(RecordDAO.TAG_SERVICE_ID, String.valueOf(serviceId)));\n+        }\n+        if (serviceInstanceId != 0) {\n+            recallQuery.and(eq(SegmentRecord.SERVICE_INSTANCE_ID, serviceInstanceId));\n+        }\n+        if (endpointId != 0) {\n+            recallQuery.and(eq(SegmentRecord.ENDPOINT_ID, endpointId));\n+        }\n+        if (!Strings.isNullOrEmpty(traceId)) {\n+            recallQuery.and(eq(SegmentRecord.TRACE_ID, traceId));\n+        }\n+        switch (traceState) {\n+            case ERROR:\n+                recallQuery.and(eq(SegmentRecord.IS_ERROR, BooleanUtils.TRUE));\n+                break;\n+            case SUCCESS:\n+                recallQuery.and(eq(SegmentRecord.IS_ERROR, BooleanUtils.FALSE));\n+                break;\n+        }\n+\n+        WhereQueryImpl<SelectQueryImpl> countQuery = select()\n+            .count(SegmentRecord.ENDPOINT_ID)\n+            .from(client.getDatabase(), SegmentRecord.INDEX_NAME)\n+            .where();\n+        for (Clause clause : recallQuery.getClauses()) {\n+            countQuery.where(clause);\n+        }\n+        Query query = new Query(countQuery.getCommand() + recallQuery.getCommand());\n+\n+        List<QueryResult.Result> results = client.query(query);\n+        if (log.isDebugEnabled()) {\n+            log.debug(\"SQL: {} result set: {}\", query.getCommand(), results);\n+        }\n+        if (results.size() != 2) {\n+            throw new IOException(\"Expecting to get 2 Results, but it is \" + results.size());\n+        }\n+        List<QueryResult.Series> counter = results.get(0).getSeries();\n+        List<QueryResult.Series> result = results.get(1).getSeries();\n+        if (result == null || result.isEmpty()) {\n+            return new TraceBrief();\n+        }\n+\n+        TraceBrief traceBrief = new TraceBrief();\n+        traceBrief.setTotal(((Number) counter.get(0).getValues().get(0).get(1)).intValue());\n+\n+        result.get(0).getValues().stream().sorted((a, b) -> {\n+            return Long.compare(((Number) b.get(1)).longValue(), ((Number) a.get(1)).longValue());\n+        }).skip(from).forEach(values -> {\n+            BasicTrace basicTrace = new BasicTrace();\n+\n+            basicTrace.setSegmentId((String) values.get(2));\n+            basicTrace.setStart(String.valueOf((long) values.get(3)));\n+            basicTrace.getEndpointNames().add((String) values.get(4));\n+            basicTrace.setDuration((int) values.get(5));\n+            basicTrace.setError(BooleanUtils.valueToBoolean((int) values.get(6)));\n+            basicTrace.getTraceIds().add((String) values.get(7));\n+\n+            traceBrief.getTraces().add(basicTrace);\n+        });", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTgzMjcyNQ=="}, "originalCommit": {"oid": "6e4375d038cd56498cd7f09365d6002136a3fd44"}, "originalPosition": 162}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1MDQ5MTg5OnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/query/TraceQuery.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNVQxMzo1NDo1NFrOFqPKJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNlQwMToxNzo0MlrOFqRRdw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTgzMjg3MQ==", "bodyText": "All the WhereQueryImpl may be replaced by  org.influxdb.dto.Query?", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r379832871", "createdAt": "2020-02-15T13:54:54Z", "author": {"login": "kezhenxu94"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/query/TraceQuery.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.query;\n+\n+import com.google.common.collect.Lists;\n+import java.io.IOException;\n+import java.util.Base64;\n+import java.util.Collections;\n+import java.util.List;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.skywalking.oap.server.core.analysis.manual.segment.SegmentRecord;\n+import org.apache.skywalking.oap.server.core.query.entity.BasicTrace;\n+import org.apache.skywalking.oap.server.core.query.entity.QueryOrder;\n+import org.apache.skywalking.oap.server.core.query.entity.Span;\n+import org.apache.skywalking.oap.server.core.query.entity.TraceBrief;\n+import org.apache.skywalking.oap.server.core.query.entity.TraceState;\n+import org.apache.skywalking.oap.server.core.storage.query.ITraceQueryDAO;\n+import org.apache.skywalking.oap.server.library.util.BooleanUtils;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.base.RecordDAO;\n+import org.elasticsearch.common.Strings;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.SelectQueryImpl;\n+import org.influxdb.querybuilder.WhereQueryImpl;\n+import org.influxdb.querybuilder.clauses.Clause;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.eq;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.gte;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.lte;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.regex;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.select;\n+\n+@Slf4j\n+public class TraceQuery implements ITraceQueryDAO {\n+    private final InfluxClient client;\n+\n+    public TraceQuery(InfluxClient client) {\n+        this.client = client;\n+    }\n+\n+    @Override\n+    public TraceBrief queryBasicTraces(long startSecondTB,\n+                                       long endSecondTB,\n+                                       long minDuration,\n+                                       long maxDuration,\n+                                       String endpointName,\n+                                       int serviceId,\n+                                       int serviceInstanceId,\n+                                       int endpointId,\n+                                       String traceId,\n+                                       int limit,\n+                                       int from,\n+                                       TraceState traceState,\n+                                       QueryOrder queryOrder)\n+        throws IOException {\n+\n+        String orderBy = SegmentRecord.START_TIME;\n+        if (queryOrder == QueryOrder.BY_DURATION) {\n+            orderBy = SegmentRecord.LATENCY;\n+        }\n+\n+        WhereQueryImpl<SelectQueryImpl> recallQuery = select()\n+            .function(\"top\", orderBy, limit + from)\n+            .column(SegmentRecord.SEGMENT_ID)\n+            .column(SegmentRecord.START_TIME)\n+            .column(SegmentRecord.ENDPOINT_NAME)\n+            .column(SegmentRecord.LATENCY)\n+            .column(SegmentRecord.IS_ERROR)\n+            .column(SegmentRecord.TRACE_ID)\n+            .from(client.getDatabase(), SegmentRecord.INDEX_NAME)\n+            .where();\n+\n+        if (startSecondTB != 0 && endSecondTB != 0) {\n+            recallQuery.and(gte(SegmentRecord.TIME_BUCKET, startSecondTB))\n+                       .and(lte(SegmentRecord.TIME_BUCKET, endSecondTB));\n+        }\n+        if (minDuration != 0) {\n+            recallQuery.and(gte(SegmentRecord.LATENCY, minDuration));\n+        }\n+        if (maxDuration != 0) {\n+            recallQuery.and(lte(SegmentRecord.LATENCY, maxDuration));\n+        }\n+        if (!Strings.isNullOrEmpty(endpointName)) {\n+            recallQuery.and(regex(SegmentRecord.ENDPOINT_NAME, \"/\" + endpointName.replaceAll(\"/\", \"\\\\\\\\/\") + \"/\"));\n+        }\n+        if (serviceId != 0) {\n+            recallQuery.and(eq(RecordDAO.TAG_SERVICE_ID, String.valueOf(serviceId)));\n+        }\n+        if (serviceInstanceId != 0) {\n+            recallQuery.and(eq(SegmentRecord.SERVICE_INSTANCE_ID, serviceInstanceId));\n+        }\n+        if (endpointId != 0) {\n+            recallQuery.and(eq(SegmentRecord.ENDPOINT_ID, endpointId));\n+        }\n+        if (!Strings.isNullOrEmpty(traceId)) {\n+            recallQuery.and(eq(SegmentRecord.TRACE_ID, traceId));\n+        }\n+        switch (traceState) {\n+            case ERROR:\n+                recallQuery.and(eq(SegmentRecord.IS_ERROR, BooleanUtils.TRUE));\n+                break;\n+            case SUCCESS:\n+                recallQuery.and(eq(SegmentRecord.IS_ERROR, BooleanUtils.FALSE));\n+                break;\n+        }\n+\n+        WhereQueryImpl<SelectQueryImpl> countQuery = select()\n+            .count(SegmentRecord.ENDPOINT_ID)\n+            .from(client.getDatabase(), SegmentRecord.INDEX_NAME)\n+            .where();\n+        for (Clause clause : recallQuery.getClauses()) {\n+            countQuery.where(clause);\n+        }\n+        Query query = new Query(countQuery.getCommand() + recallQuery.getCommand());\n+\n+        List<QueryResult.Result> results = client.query(query);\n+        if (log.isDebugEnabled()) {\n+            log.debug(\"SQL: {} result set: {}\", query.getCommand(), results);\n+        }\n+        if (results.size() != 2) {\n+            throw new IOException(\"Expecting to get 2 Results, but it is \" + results.size());\n+        }\n+        List<QueryResult.Series> counter = results.get(0).getSeries();\n+        List<QueryResult.Series> result = results.get(1).getSeries();\n+        if (result == null || result.isEmpty()) {\n+            return new TraceBrief();\n+        }\n+\n+        TraceBrief traceBrief = new TraceBrief();\n+        traceBrief.setTotal(((Number) counter.get(0).getValues().get(0).get(1)).intValue());\n+\n+        result.get(0).getValues().stream().sorted((a, b) -> {\n+            return Long.compare(((Number) b.get(1)).longValue(), ((Number) a.get(1)).longValue());\n+        }).skip(from).forEach(values -> {\n+            BasicTrace basicTrace = new BasicTrace();\n+\n+            basicTrace.setSegmentId((String) values.get(2));\n+            basicTrace.setStart(String.valueOf((long) values.get(3)));\n+            basicTrace.getEndpointNames().add((String) values.get(4));\n+            basicTrace.setDuration((int) values.get(5));\n+            basicTrace.setError(BooleanUtils.valueToBoolean((int) values.get(6)));\n+            basicTrace.getTraceIds().add((String) values.get(7));\n+\n+            traceBrief.getTraces().add(basicTrace);\n+        });\n+        return traceBrief;\n+    }\n+\n+    @Override\n+    public List<SegmentRecord> queryByTraceId(String traceId) throws IOException {\n+        WhereQueryImpl query = select().column(SegmentRecord.SEGMENT_ID)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6e4375d038cd56498cd7f09365d6002136a3fd44"}, "originalPosition": 168}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTg2MzYwNg==", "bodyText": "Could you explain more? WhereQueryImpl is harmless and easy to append clauses.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r379863606", "createdAt": "2020-02-15T23:55:05Z", "author": {"login": "dmsolr"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/query/TraceQuery.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.query;\n+\n+import com.google.common.collect.Lists;\n+import java.io.IOException;\n+import java.util.Base64;\n+import java.util.Collections;\n+import java.util.List;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.skywalking.oap.server.core.analysis.manual.segment.SegmentRecord;\n+import org.apache.skywalking.oap.server.core.query.entity.BasicTrace;\n+import org.apache.skywalking.oap.server.core.query.entity.QueryOrder;\n+import org.apache.skywalking.oap.server.core.query.entity.Span;\n+import org.apache.skywalking.oap.server.core.query.entity.TraceBrief;\n+import org.apache.skywalking.oap.server.core.query.entity.TraceState;\n+import org.apache.skywalking.oap.server.core.storage.query.ITraceQueryDAO;\n+import org.apache.skywalking.oap.server.library.util.BooleanUtils;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.base.RecordDAO;\n+import org.elasticsearch.common.Strings;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.SelectQueryImpl;\n+import org.influxdb.querybuilder.WhereQueryImpl;\n+import org.influxdb.querybuilder.clauses.Clause;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.eq;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.gte;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.lte;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.regex;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.select;\n+\n+@Slf4j\n+public class TraceQuery implements ITraceQueryDAO {\n+    private final InfluxClient client;\n+\n+    public TraceQuery(InfluxClient client) {\n+        this.client = client;\n+    }\n+\n+    @Override\n+    public TraceBrief queryBasicTraces(long startSecondTB,\n+                                       long endSecondTB,\n+                                       long minDuration,\n+                                       long maxDuration,\n+                                       String endpointName,\n+                                       int serviceId,\n+                                       int serviceInstanceId,\n+                                       int endpointId,\n+                                       String traceId,\n+                                       int limit,\n+                                       int from,\n+                                       TraceState traceState,\n+                                       QueryOrder queryOrder)\n+        throws IOException {\n+\n+        String orderBy = SegmentRecord.START_TIME;\n+        if (queryOrder == QueryOrder.BY_DURATION) {\n+            orderBy = SegmentRecord.LATENCY;\n+        }\n+\n+        WhereQueryImpl<SelectQueryImpl> recallQuery = select()\n+            .function(\"top\", orderBy, limit + from)\n+            .column(SegmentRecord.SEGMENT_ID)\n+            .column(SegmentRecord.START_TIME)\n+            .column(SegmentRecord.ENDPOINT_NAME)\n+            .column(SegmentRecord.LATENCY)\n+            .column(SegmentRecord.IS_ERROR)\n+            .column(SegmentRecord.TRACE_ID)\n+            .from(client.getDatabase(), SegmentRecord.INDEX_NAME)\n+            .where();\n+\n+        if (startSecondTB != 0 && endSecondTB != 0) {\n+            recallQuery.and(gte(SegmentRecord.TIME_BUCKET, startSecondTB))\n+                       .and(lte(SegmentRecord.TIME_BUCKET, endSecondTB));\n+        }\n+        if (minDuration != 0) {\n+            recallQuery.and(gte(SegmentRecord.LATENCY, minDuration));\n+        }\n+        if (maxDuration != 0) {\n+            recallQuery.and(lte(SegmentRecord.LATENCY, maxDuration));\n+        }\n+        if (!Strings.isNullOrEmpty(endpointName)) {\n+            recallQuery.and(regex(SegmentRecord.ENDPOINT_NAME, \"/\" + endpointName.replaceAll(\"/\", \"\\\\\\\\/\") + \"/\"));\n+        }\n+        if (serviceId != 0) {\n+            recallQuery.and(eq(RecordDAO.TAG_SERVICE_ID, String.valueOf(serviceId)));\n+        }\n+        if (serviceInstanceId != 0) {\n+            recallQuery.and(eq(SegmentRecord.SERVICE_INSTANCE_ID, serviceInstanceId));\n+        }\n+        if (endpointId != 0) {\n+            recallQuery.and(eq(SegmentRecord.ENDPOINT_ID, endpointId));\n+        }\n+        if (!Strings.isNullOrEmpty(traceId)) {\n+            recallQuery.and(eq(SegmentRecord.TRACE_ID, traceId));\n+        }\n+        switch (traceState) {\n+            case ERROR:\n+                recallQuery.and(eq(SegmentRecord.IS_ERROR, BooleanUtils.TRUE));\n+                break;\n+            case SUCCESS:\n+                recallQuery.and(eq(SegmentRecord.IS_ERROR, BooleanUtils.FALSE));\n+                break;\n+        }\n+\n+        WhereQueryImpl<SelectQueryImpl> countQuery = select()\n+            .count(SegmentRecord.ENDPOINT_ID)\n+            .from(client.getDatabase(), SegmentRecord.INDEX_NAME)\n+            .where();\n+        for (Clause clause : recallQuery.getClauses()) {\n+            countQuery.where(clause);\n+        }\n+        Query query = new Query(countQuery.getCommand() + recallQuery.getCommand());\n+\n+        List<QueryResult.Result> results = client.query(query);\n+        if (log.isDebugEnabled()) {\n+            log.debug(\"SQL: {} result set: {}\", query.getCommand(), results);\n+        }\n+        if (results.size() != 2) {\n+            throw new IOException(\"Expecting to get 2 Results, but it is \" + results.size());\n+        }\n+        List<QueryResult.Series> counter = results.get(0).getSeries();\n+        List<QueryResult.Series> result = results.get(1).getSeries();\n+        if (result == null || result.isEmpty()) {\n+            return new TraceBrief();\n+        }\n+\n+        TraceBrief traceBrief = new TraceBrief();\n+        traceBrief.setTotal(((Number) counter.get(0).getValues().get(0).get(1)).intValue());\n+\n+        result.get(0).getValues().stream().sorted((a, b) -> {\n+            return Long.compare(((Number) b.get(1)).longValue(), ((Number) a.get(1)).longValue());\n+        }).skip(from).forEach(values -> {\n+            BasicTrace basicTrace = new BasicTrace();\n+\n+            basicTrace.setSegmentId((String) values.get(2));\n+            basicTrace.setStart(String.valueOf((long) values.get(3)));\n+            basicTrace.getEndpointNames().add((String) values.get(4));\n+            basicTrace.setDuration((int) values.get(5));\n+            basicTrace.setError(BooleanUtils.valueToBoolean((int) values.get(6)));\n+            basicTrace.getTraceIds().add((String) values.get(7));\n+\n+            traceBrief.getTraces().add(basicTrace);\n+        });\n+        return traceBrief;\n+    }\n+\n+    @Override\n+    public List<SegmentRecord> queryByTraceId(String traceId) throws IOException {\n+        WhereQueryImpl query = select().column(SegmentRecord.SEGMENT_ID)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTgzMjg3MQ=="}, "originalCommit": {"oid": "6e4375d038cd56498cd7f09365d6002136a3fd44"}, "originalPosition": 168}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTg2NzUxMQ==", "bodyText": "Could you explain more? WhereQueryImpl is harmless and easy to append clauses.\n\n\nProgram to interface not Impl\nWhereQueryImpl is generic-typed, but you simply ignored them, causing many warnings\n\nAnyway, just ignore if you don\u2019t care the warnings", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r379867511", "createdAt": "2020-02-16T01:17:42Z", "author": {"login": "kezhenxu94"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/query/TraceQuery.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.query;\n+\n+import com.google.common.collect.Lists;\n+import java.io.IOException;\n+import java.util.Base64;\n+import java.util.Collections;\n+import java.util.List;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.skywalking.oap.server.core.analysis.manual.segment.SegmentRecord;\n+import org.apache.skywalking.oap.server.core.query.entity.BasicTrace;\n+import org.apache.skywalking.oap.server.core.query.entity.QueryOrder;\n+import org.apache.skywalking.oap.server.core.query.entity.Span;\n+import org.apache.skywalking.oap.server.core.query.entity.TraceBrief;\n+import org.apache.skywalking.oap.server.core.query.entity.TraceState;\n+import org.apache.skywalking.oap.server.core.storage.query.ITraceQueryDAO;\n+import org.apache.skywalking.oap.server.library.util.BooleanUtils;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.base.RecordDAO;\n+import org.elasticsearch.common.Strings;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.SelectQueryImpl;\n+import org.influxdb.querybuilder.WhereQueryImpl;\n+import org.influxdb.querybuilder.clauses.Clause;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.eq;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.gte;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.lte;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.regex;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.select;\n+\n+@Slf4j\n+public class TraceQuery implements ITraceQueryDAO {\n+    private final InfluxClient client;\n+\n+    public TraceQuery(InfluxClient client) {\n+        this.client = client;\n+    }\n+\n+    @Override\n+    public TraceBrief queryBasicTraces(long startSecondTB,\n+                                       long endSecondTB,\n+                                       long minDuration,\n+                                       long maxDuration,\n+                                       String endpointName,\n+                                       int serviceId,\n+                                       int serviceInstanceId,\n+                                       int endpointId,\n+                                       String traceId,\n+                                       int limit,\n+                                       int from,\n+                                       TraceState traceState,\n+                                       QueryOrder queryOrder)\n+        throws IOException {\n+\n+        String orderBy = SegmentRecord.START_TIME;\n+        if (queryOrder == QueryOrder.BY_DURATION) {\n+            orderBy = SegmentRecord.LATENCY;\n+        }\n+\n+        WhereQueryImpl<SelectQueryImpl> recallQuery = select()\n+            .function(\"top\", orderBy, limit + from)\n+            .column(SegmentRecord.SEGMENT_ID)\n+            .column(SegmentRecord.START_TIME)\n+            .column(SegmentRecord.ENDPOINT_NAME)\n+            .column(SegmentRecord.LATENCY)\n+            .column(SegmentRecord.IS_ERROR)\n+            .column(SegmentRecord.TRACE_ID)\n+            .from(client.getDatabase(), SegmentRecord.INDEX_NAME)\n+            .where();\n+\n+        if (startSecondTB != 0 && endSecondTB != 0) {\n+            recallQuery.and(gte(SegmentRecord.TIME_BUCKET, startSecondTB))\n+                       .and(lte(SegmentRecord.TIME_BUCKET, endSecondTB));\n+        }\n+        if (minDuration != 0) {\n+            recallQuery.and(gte(SegmentRecord.LATENCY, minDuration));\n+        }\n+        if (maxDuration != 0) {\n+            recallQuery.and(lte(SegmentRecord.LATENCY, maxDuration));\n+        }\n+        if (!Strings.isNullOrEmpty(endpointName)) {\n+            recallQuery.and(regex(SegmentRecord.ENDPOINT_NAME, \"/\" + endpointName.replaceAll(\"/\", \"\\\\\\\\/\") + \"/\"));\n+        }\n+        if (serviceId != 0) {\n+            recallQuery.and(eq(RecordDAO.TAG_SERVICE_ID, String.valueOf(serviceId)));\n+        }\n+        if (serviceInstanceId != 0) {\n+            recallQuery.and(eq(SegmentRecord.SERVICE_INSTANCE_ID, serviceInstanceId));\n+        }\n+        if (endpointId != 0) {\n+            recallQuery.and(eq(SegmentRecord.ENDPOINT_ID, endpointId));\n+        }\n+        if (!Strings.isNullOrEmpty(traceId)) {\n+            recallQuery.and(eq(SegmentRecord.TRACE_ID, traceId));\n+        }\n+        switch (traceState) {\n+            case ERROR:\n+                recallQuery.and(eq(SegmentRecord.IS_ERROR, BooleanUtils.TRUE));\n+                break;\n+            case SUCCESS:\n+                recallQuery.and(eq(SegmentRecord.IS_ERROR, BooleanUtils.FALSE));\n+                break;\n+        }\n+\n+        WhereQueryImpl<SelectQueryImpl> countQuery = select()\n+            .count(SegmentRecord.ENDPOINT_ID)\n+            .from(client.getDatabase(), SegmentRecord.INDEX_NAME)\n+            .where();\n+        for (Clause clause : recallQuery.getClauses()) {\n+            countQuery.where(clause);\n+        }\n+        Query query = new Query(countQuery.getCommand() + recallQuery.getCommand());\n+\n+        List<QueryResult.Result> results = client.query(query);\n+        if (log.isDebugEnabled()) {\n+            log.debug(\"SQL: {} result set: {}\", query.getCommand(), results);\n+        }\n+        if (results.size() != 2) {\n+            throw new IOException(\"Expecting to get 2 Results, but it is \" + results.size());\n+        }\n+        List<QueryResult.Series> counter = results.get(0).getSeries();\n+        List<QueryResult.Series> result = results.get(1).getSeries();\n+        if (result == null || result.isEmpty()) {\n+            return new TraceBrief();\n+        }\n+\n+        TraceBrief traceBrief = new TraceBrief();\n+        traceBrief.setTotal(((Number) counter.get(0).getValues().get(0).get(1)).intValue());\n+\n+        result.get(0).getValues().stream().sorted((a, b) -> {\n+            return Long.compare(((Number) b.get(1)).longValue(), ((Number) a.get(1)).longValue());\n+        }).skip(from).forEach(values -> {\n+            BasicTrace basicTrace = new BasicTrace();\n+\n+            basicTrace.setSegmentId((String) values.get(2));\n+            basicTrace.setStart(String.valueOf((long) values.get(3)));\n+            basicTrace.getEndpointNames().add((String) values.get(4));\n+            basicTrace.setDuration((int) values.get(5));\n+            basicTrace.setError(BooleanUtils.valueToBoolean((int) values.get(6)));\n+            basicTrace.getTraceIds().add((String) values.get(7));\n+\n+            traceBrief.getTraces().add(basicTrace);\n+        });\n+        return traceBrief;\n+    }\n+\n+    @Override\n+    public List<SegmentRecord> queryByTraceId(String traceId) throws IOException {\n+        WhereQueryImpl query = select().column(SegmentRecord.SEGMENT_ID)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTgzMjg3MQ=="}, "originalCommit": {"oid": "6e4375d038cd56498cd7f09365d6002136a3fd44"}, "originalPosition": 168}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1MDQ5MzczOnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/MetricsDAO.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNVQxMzo1OToxNlrOFqPLFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNVQyMzo1NTo1N1rOFqRCZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTgzMzExMQ==", "bodyText": "did not find related documentation, but will .raw(\"*::field\") be more efficient?", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r379833111", "createdAt": "2020-02-15T13:59:16Z", "author": {"login": "kezhenxu94"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/MetricsDAO.java", "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.base;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;\n+import org.apache.skywalking.oap.server.core.analysis.metrics.Metrics;\n+import org.apache.skywalking.oap.server.core.storage.IMetricsDAO;\n+import org.apache.skywalking.oap.server.core.storage.StorageBuilder;\n+import org.apache.skywalking.oap.server.core.storage.model.Model;\n+import org.apache.skywalking.oap.server.core.storage.model.ModelColumn;\n+import org.apache.skywalking.oap.server.core.storage.type.StorageDataType;\n+import org.apache.skywalking.oap.server.library.client.request.InsertRequest;\n+import org.apache.skywalking.oap.server.library.client.request.UpdateRequest;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.SelectQueryImpl;\n+import org.influxdb.querybuilder.WhereQueryImpl;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.contains;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.select;\n+\n+public class MetricsDAO implements IMetricsDAO {\n+    public static final String TAG_ENTITY_ID = \"_entity_id\";\n+\n+    private final StorageBuilder<Metrics> storageBuilder;\n+    private final InfluxClient client;\n+\n+    public MetricsDAO(InfluxClient client, StorageBuilder<Metrics> storageBuilder) {\n+        this.client = client;\n+        this.storageBuilder = storageBuilder;\n+    }\n+\n+    @Override\n+    public List<Metrics> multiGet(Model model, List<String> ids) throws IOException {\n+        WhereQueryImpl<SelectQueryImpl> query = select()\n+            .regex(\"*::field\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6e4375d038cd56498cd7f09365d6002136a3fd44"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTg2MzY1Mg==", "bodyText": "They are different in name only.\nIf you think raw is more appropiate, I will fix them.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r379863652", "createdAt": "2020-02-15T23:55:57Z", "author": {"login": "dmsolr"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/MetricsDAO.java", "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.base;\n+\n+import com.google.common.base.Joiner;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;\n+import org.apache.skywalking.oap.server.core.analysis.metrics.Metrics;\n+import org.apache.skywalking.oap.server.core.storage.IMetricsDAO;\n+import org.apache.skywalking.oap.server.core.storage.StorageBuilder;\n+import org.apache.skywalking.oap.server.core.storage.model.Model;\n+import org.apache.skywalking.oap.server.core.storage.model.ModelColumn;\n+import org.apache.skywalking.oap.server.core.storage.type.StorageDataType;\n+import org.apache.skywalking.oap.server.library.client.request.InsertRequest;\n+import org.apache.skywalking.oap.server.library.client.request.UpdateRequest;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.SelectQueryImpl;\n+import org.influxdb.querybuilder.WhereQueryImpl;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.contains;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.select;\n+\n+public class MetricsDAO implements IMetricsDAO {\n+    public static final String TAG_ENTITY_ID = \"_entity_id\";\n+\n+    private final StorageBuilder<Metrics> storageBuilder;\n+    private final InfluxClient client;\n+\n+    public MetricsDAO(InfluxClient client, StorageBuilder<Metrics> storageBuilder) {\n+        this.client = client;\n+        this.storageBuilder = storageBuilder;\n+    }\n+\n+    @Override\n+    public List<Metrics> multiGet(Model model, List<String> ids) throws IOException {\n+        WhereQueryImpl<SelectQueryImpl> query = select()\n+            .regex(\"*::field\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTgzMzExMQ=="}, "originalCommit": {"oid": "6e4375d038cd56498cd7f09365d6002136a3fd44"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1MDQ5NjkwOnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/query/LogQuery.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNVQxNDowNjo0NFrOFqPMvg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNVQxNDowNjo0NFrOFqPMvg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTgzMzUzNA==", "bodyText": "why do you need this? seems the limit doesn't include the offset", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r379833534", "createdAt": "2020-02-15T14:06:44Z", "author": {"login": "kezhenxu94"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/query/LogQuery.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.query;\n+\n+import com.google.common.collect.Maps;\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.skywalking.oap.server.core.Const;\n+import org.apache.skywalking.oap.server.core.analysis.manual.log.AbstractLogRecord;\n+import org.apache.skywalking.oap.server.core.query.entity.ContentType;\n+import org.apache.skywalking.oap.server.core.query.entity.Log;\n+import org.apache.skywalking.oap.server.core.query.entity.LogState;\n+import org.apache.skywalking.oap.server.core.query.entity.Logs;\n+import org.apache.skywalking.oap.server.core.query.entity.Pagination;\n+import org.apache.skywalking.oap.server.core.storage.query.ILogQueryDAO;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.base.RecordDAO;\n+import org.elasticsearch.common.Strings;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.SelectQueryImpl;\n+import org.influxdb.querybuilder.WhereQueryImpl;\n+import org.influxdb.querybuilder.clauses.ConjunctionClause;\n+\n+import static org.apache.skywalking.oap.server.core.analysis.manual.log.AbstractLogRecord.CONTENT;\n+import static org.apache.skywalking.oap.server.core.analysis.manual.log.AbstractLogRecord.CONTENT_TYPE;\n+import static org.apache.skywalking.oap.server.core.analysis.manual.log.AbstractLogRecord.ENDPOINT_ID;\n+import static org.apache.skywalking.oap.server.core.analysis.manual.log.AbstractLogRecord.IS_ERROR;\n+import static org.apache.skywalking.oap.server.core.analysis.manual.log.AbstractLogRecord.SERVICE_ID;\n+import static org.apache.skywalking.oap.server.core.analysis.manual.log.AbstractLogRecord.SERVICE_INSTANCE_ID;\n+import static org.apache.skywalking.oap.server.core.analysis.manual.log.AbstractLogRecord.STATUS_CODE;\n+import static org.apache.skywalking.oap.server.core.analysis.manual.log.AbstractLogRecord.TIMESTAMP;\n+import static org.apache.skywalking.oap.server.core.analysis.manual.log.AbstractLogRecord.TRACE_ID;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.eq;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.gte;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.lte;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.select;\n+\n+@Slf4j\n+public class LogQuery implements ILogQueryDAO {\n+    private final InfluxClient client;\n+\n+    public LogQuery(InfluxClient client) {\n+        this.client = client;\n+    }\n+\n+    @Override\n+    public Logs queryLogs(String metricName, int serviceId, int serviceInstanceId, int endpointId, String traceId,\n+                          LogState state, String stateCode, Pagination paging, int from, int limit,\n+                          long startTB, long endTB) throws IOException {\n+        WhereQueryImpl<SelectQueryImpl> recallQuery = select().regex(\"*::field\")\n+            .from(client.getDatabase(), metricName)\n+            .where();\n+        if (serviceId != Const.NONE) {\n+            recallQuery.and(eq(RecordDAO.TAG_SERVICE_ID, String.valueOf(serviceId)));\n+        }\n+        if (serviceInstanceId != Const.NONE) {\n+            recallQuery.and(eq(SERVICE_INSTANCE_ID, serviceInstanceId));\n+        }\n+        if (endpointId != Const.NONE) {\n+            recallQuery.and(eq(ENDPOINT_ID, endpointId));\n+        }\n+        if (!Strings.isNullOrEmpty(traceId)) {\n+            recallQuery.and(eq(TRACE_ID, traceId));\n+        }\n+        switch (state) {\n+            case ERROR: {\n+                recallQuery.and(eq(IS_ERROR, true));\n+                break;\n+            }\n+            case SUCCESS: {\n+                recallQuery.and(eq(IS_ERROR, false));\n+                break;\n+            }\n+        }\n+        if (!Strings.isNullOrEmpty(stateCode)) {\n+            recallQuery.and(eq(STATUS_CODE, stateCode));\n+        }\n+        recallQuery.and(gte(AbstractLogRecord.TIME_BUCKET, startTB))\n+                   .and(lte(AbstractLogRecord.TIME_BUCKET, endTB));\n+\n+        if (from > Const.NONE) {\n+            limit += from;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6e4375d038cd56498cd7f09365d6002136a3fd44"}, "originalPosition": 101}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1MTAxOTcxOnYy", "diffSide": "RIGHT", "path": ".github/workflows/e2e.yaml", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNlQxMjo0MDowMlrOFqTRgg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNlQxMzoyODo1OFrOFqTdmw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTkwMDI5MA==", "bodyText": "Why this doesn't have --storage=elasticsearch? What is the default? Or what happens if no --storage=?\nI expect a fail when missing this parameter.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r379900290", "createdAt": "2020-02-16T12:40:02Z", "author": {"login": "wu-sheng"}, "path": ".github/workflows/e2e.yaml", "diffHunk": "@@ -71,15 +73,19 @@ jobs:\n           ./mvnw --batch-mode -Dcheckstyle.skip -Drat.skip -T2 -Dmaven.compile.fork -Dmaven.compiler.maxmem=3072 -DskipTests clean install\n           ./mvnw --batch-mode -f test/e2e/pom.xml -pl e2e-base clean install\n       - name: Cluster Tests (ES6/ZK/JDK8)\n-        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-cluster/e2e-cluster-test-runner\n+        run: export E2E_VERSION=jdk8-1.5 && bash -x test/e2e/run.sh e2e-cluster/e2e-cluster-test-runner --storage=elasticsearch\n+      - name: Cluster Tests (InfluxDB/ZK/JDK8)\n+        run: export E2E_VERSION=jdk8-1.5 && bash -x test/e2e/run.sh e2e-cluster/e2e-cluster-test-runner --storage=influxdb\n       - name: Cluster With Gateway Tests (ES6/ZK/JDK8)\n-        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-cluster-with-gateway/e2e-cluster-with-gateway-test-runner\n+        run: export E2E_VERSION=jdk8-1.5 && bash -x test/e2e/run.sh e2e-cluster-with-gateway/e2e-cluster-with-gateway-test-runner", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13698b55ed1e501475fa4069d0fcadd133b581c5"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTkwMjIzMw==", "bodyText": "Why this doesn't have --storage=elasticsearch? What is the default? Or what happens if no --storage=?\n\nNot every e2e case is aware of the parameter --storage, e2e-cluster-with-gateway is one of them, the parameter is introduced recently and only e2e-cluster and e2e-profile are refactored then, IIRC", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r379902233", "createdAt": "2020-02-16T13:10:32Z", "author": {"login": "kezhenxu94"}, "path": ".github/workflows/e2e.yaml", "diffHunk": "@@ -71,15 +73,19 @@ jobs:\n           ./mvnw --batch-mode -Dcheckstyle.skip -Drat.skip -T2 -Dmaven.compile.fork -Dmaven.compiler.maxmem=3072 -DskipTests clean install\n           ./mvnw --batch-mode -f test/e2e/pom.xml -pl e2e-base clean install\n       - name: Cluster Tests (ES6/ZK/JDK8)\n-        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-cluster/e2e-cluster-test-runner\n+        run: export E2E_VERSION=jdk8-1.5 && bash -x test/e2e/run.sh e2e-cluster/e2e-cluster-test-runner --storage=elasticsearch\n+      - name: Cluster Tests (InfluxDB/ZK/JDK8)\n+        run: export E2E_VERSION=jdk8-1.5 && bash -x test/e2e/run.sh e2e-cluster/e2e-cluster-test-runner --storage=influxdb\n       - name: Cluster With Gateway Tests (ES6/ZK/JDK8)\n-        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-cluster-with-gateway/e2e-cluster-with-gateway-test-runner\n+        run: export E2E_VERSION=jdk8-1.5 && bash -x test/e2e/run.sh e2e-cluster-with-gateway/e2e-cluster-with-gateway-test-runner", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTkwMDI5MA=="}, "originalCommit": {"oid": "13698b55ed1e501475fa4069d0fcadd133b581c5"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTkwMjg3MQ==", "bodyText": "Not add e2e-cluster-with-gateway test yet. Do we need it?\nBy the way, you are right, @kezhenxu94 .\n(I am trying to add more testcases into e2e-ttl-influxdb, so I have not refactored it)", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r379902871", "createdAt": "2020-02-16T13:20:58Z", "author": {"login": "dmsolr"}, "path": ".github/workflows/e2e.yaml", "diffHunk": "@@ -71,15 +73,19 @@ jobs:\n           ./mvnw --batch-mode -Dcheckstyle.skip -Drat.skip -T2 -Dmaven.compile.fork -Dmaven.compiler.maxmem=3072 -DskipTests clean install\n           ./mvnw --batch-mode -f test/e2e/pom.xml -pl e2e-base clean install\n       - name: Cluster Tests (ES6/ZK/JDK8)\n-        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-cluster/e2e-cluster-test-runner\n+        run: export E2E_VERSION=jdk8-1.5 && bash -x test/e2e/run.sh e2e-cluster/e2e-cluster-test-runner --storage=elasticsearch\n+      - name: Cluster Tests (InfluxDB/ZK/JDK8)\n+        run: export E2E_VERSION=jdk8-1.5 && bash -x test/e2e/run.sh e2e-cluster/e2e-cluster-test-runner --storage=influxdb\n       - name: Cluster With Gateway Tests (ES6/ZK/JDK8)\n-        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-cluster-with-gateway/e2e-cluster-with-gateway-test-runner\n+        run: export E2E_VERSION=jdk8-1.5 && bash -x test/e2e/run.sh e2e-cluster-with-gateway/e2e-cluster-with-gateway-test-runner", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTkwMDI5MA=="}, "originalCommit": {"oid": "13698b55ed1e501475fa4069d0fcadd133b581c5"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTkwMzM4Nw==", "bodyText": "I am OK with keeping the current status.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r379903387", "createdAt": "2020-02-16T13:28:58Z", "author": {"login": "wu-sheng"}, "path": ".github/workflows/e2e.yaml", "diffHunk": "@@ -71,15 +73,19 @@ jobs:\n           ./mvnw --batch-mode -Dcheckstyle.skip -Drat.skip -T2 -Dmaven.compile.fork -Dmaven.compiler.maxmem=3072 -DskipTests clean install\n           ./mvnw --batch-mode -f test/e2e/pom.xml -pl e2e-base clean install\n       - name: Cluster Tests (ES6/ZK/JDK8)\n-        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-cluster/e2e-cluster-test-runner\n+        run: export E2E_VERSION=jdk8-1.5 && bash -x test/e2e/run.sh e2e-cluster/e2e-cluster-test-runner --storage=elasticsearch\n+      - name: Cluster Tests (InfluxDB/ZK/JDK8)\n+        run: export E2E_VERSION=jdk8-1.5 && bash -x test/e2e/run.sh e2e-cluster/e2e-cluster-test-runner --storage=influxdb\n       - name: Cluster With Gateway Tests (ES6/ZK/JDK8)\n-        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-cluster-with-gateway/e2e-cluster-with-gateway-test-runner\n+        run: export E2E_VERSION=jdk8-1.5 && bash -x test/e2e/run.sh e2e-cluster-with-gateway/e2e-cluster-with-gateway-test-runner", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTkwMDI5MA=="}, "originalCommit": {"oid": "13698b55ed1e501475fa4069d0fcadd133b581c5"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1MTk5MTM1OnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/installer/MetaTableDefine.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xN1QwODozMjo0NVrOFqb2sw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQwMzo1Mzo0OFrOFq0cHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDA0MDg4Mw==", "bodyText": "There is another missing here, PROFILE_TASK_LOG. Could you check why this is missed but still tests passed? Does InfluxDB have the profile e2e?", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r380040883", "createdAt": "2020-02-17T08:32:45Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/installer/MetaTableDefine.java", "diffHunk": "@@ -0,0 +1,55 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.installer;\n+\n+import org.apache.skywalking.oap.server.core.storage.model.Model;\n+import org.apache.skywalking.oap.server.storage.plugin.jdbc.TableMetaInfo;\n+\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.ENDPOINT_INVENTORY;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.NETWORK_ADDRESS;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.PROFILE_TASK;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.PROFILE_TASK_SEGMENT_SNAPSHOT;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.SERVICE_INSTANCE_INVENTORY;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.SERVICE_INVENTORY;\n+\n+/**\n+ * Here defines which table is stored in metadata database(H2/MySQL).\n+ */\n+public class MetaTableDefine {\n+\n+    /**\n+     * Test a {@link Model} is stored in H2/MySQL or not.\n+     *\n+     * @param model Model\n+     * @return true if the {@link Model} is stored in H2/MySQL\n+     */\n+    public static boolean contains(Model model) {\n+        switch (model.getScopeId()) {\n+            case SERVICE_INVENTORY:\n+            case SERVICE_INSTANCE_INVENTORY:\n+            case NETWORK_ADDRESS:\n+            case ENDPOINT_INVENTORY:\n+            case PROFILE_TASK:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a4e13a6f18019cb17f0092a696dcfc3631a15565"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDA0OTk0NA==", "bodyText": "profile_task_log is not metadata. It is stored on InfluxDB.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r380049944", "createdAt": "2020-02-17T08:53:12Z", "author": {"login": "dmsolr"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/installer/MetaTableDefine.java", "diffHunk": "@@ -0,0 +1,55 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.installer;\n+\n+import org.apache.skywalking.oap.server.core.storage.model.Model;\n+import org.apache.skywalking.oap.server.storage.plugin.jdbc.TableMetaInfo;\n+\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.ENDPOINT_INVENTORY;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.NETWORK_ADDRESS;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.PROFILE_TASK;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.PROFILE_TASK_SEGMENT_SNAPSHOT;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.SERVICE_INSTANCE_INVENTORY;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.SERVICE_INVENTORY;\n+\n+/**\n+ * Here defines which table is stored in metadata database(H2/MySQL).\n+ */\n+public class MetaTableDefine {\n+\n+    /**\n+     * Test a {@link Model} is stored in H2/MySQL or not.\n+     *\n+     * @param model Model\n+     * @return true if the {@link Model} is stored in H2/MySQL\n+     */\n+    public static boolean contains(Model model) {\n+        switch (model.getScopeId()) {\n+            case SERVICE_INVENTORY:\n+            case SERVICE_INSTANCE_INVENTORY:\n+            case NETWORK_ADDRESS:\n+            case ENDPOINT_INVENTORY:\n+            case PROFILE_TASK:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDA0MDg4Mw=="}, "originalCommit": {"oid": "a4e13a6f18019cb17f0092a696dcfc3631a15565"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDA1NDI0NA==", "bodyText": "What is the principle? Could you add some comments and guidelines about this?", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r380054244", "createdAt": "2020-02-17T09:01:29Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/installer/MetaTableDefine.java", "diffHunk": "@@ -0,0 +1,55 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.installer;\n+\n+import org.apache.skywalking.oap.server.core.storage.model.Model;\n+import org.apache.skywalking.oap.server.storage.plugin.jdbc.TableMetaInfo;\n+\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.ENDPOINT_INVENTORY;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.NETWORK_ADDRESS;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.PROFILE_TASK;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.PROFILE_TASK_SEGMENT_SNAPSHOT;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.SERVICE_INSTANCE_INVENTORY;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.SERVICE_INVENTORY;\n+\n+/**\n+ * Here defines which table is stored in metadata database(H2/MySQL).\n+ */\n+public class MetaTableDefine {\n+\n+    /**\n+     * Test a {@link Model} is stored in H2/MySQL or not.\n+     *\n+     * @param model Model\n+     * @return true if the {@link Model} is stored in H2/MySQL\n+     */\n+    public static boolean contains(Model model) {\n+        switch (model.getScopeId()) {\n+            case SERVICE_INVENTORY:\n+            case SERVICE_INSTANCE_INVENTORY:\n+            case NETWORK_ADDRESS:\n+            case ENDPOINT_INVENTORY:\n+            case PROFILE_TASK:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDA0MDg4Mw=="}, "originalCommit": {"oid": "a4e13a6f18019cb17f0092a696dcfc3631a15565"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDQ0MzU4OA==", "bodyText": "Use model#capableOfTimeSeries == true check. If YES, then it is a metadata table.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r380443588", "createdAt": "2020-02-18T03:53:18Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/installer/MetaTableDefine.java", "diffHunk": "@@ -0,0 +1,55 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.installer;\n+\n+import org.apache.skywalking.oap.server.core.storage.model.Model;\n+import org.apache.skywalking.oap.server.storage.plugin.jdbc.TableMetaInfo;\n+\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.ENDPOINT_INVENTORY;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.NETWORK_ADDRESS;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.PROFILE_TASK;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.PROFILE_TASK_SEGMENT_SNAPSHOT;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.SERVICE_INSTANCE_INVENTORY;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.SERVICE_INVENTORY;\n+\n+/**\n+ * Here defines which table is stored in metadata database(H2/MySQL).\n+ */\n+public class MetaTableDefine {\n+\n+    /**\n+     * Test a {@link Model} is stored in H2/MySQL or not.\n+     *\n+     * @param model Model\n+     * @return true if the {@link Model} is stored in H2/MySQL\n+     */\n+    public static boolean contains(Model model) {\n+        switch (model.getScopeId()) {\n+            case SERVICE_INVENTORY:\n+            case SERVICE_INSTANCE_INVENTORY:\n+            case NETWORK_ADDRESS:\n+            case ENDPOINT_INVENTORY:\n+            case PROFILE_TASK:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDA0MDg4Mw=="}, "originalCommit": {"oid": "a4e13a6f18019cb17f0092a696dcfc3631a15565"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDQ0MzY3OA==", "bodyText": "And PROFILE_TASK is not a metadata entity", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r380443678", "createdAt": "2020-02-18T03:53:48Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/installer/MetaTableDefine.java", "diffHunk": "@@ -0,0 +1,55 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.installer;\n+\n+import org.apache.skywalking.oap.server.core.storage.model.Model;\n+import org.apache.skywalking.oap.server.storage.plugin.jdbc.TableMetaInfo;\n+\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.ENDPOINT_INVENTORY;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.NETWORK_ADDRESS;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.PROFILE_TASK;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.PROFILE_TASK_SEGMENT_SNAPSHOT;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.SERVICE_INSTANCE_INVENTORY;\n+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.SERVICE_INVENTORY;\n+\n+/**\n+ * Here defines which table is stored in metadata database(H2/MySQL).\n+ */\n+public class MetaTableDefine {\n+\n+    /**\n+     * Test a {@link Model} is stored in H2/MySQL or not.\n+     *\n+     * @param model Model\n+     * @return true if the {@link Model} is stored in H2/MySQL\n+     */\n+    public static boolean contains(Model model) {\n+        switch (model.getScopeId()) {\n+            case SERVICE_INVENTORY:\n+            case SERVICE_INSTANCE_INVENTORY:\n+            case NETWORK_ADDRESS:\n+            case ENDPOINT_INVENTORY:\n+            case PROFILE_TASK:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDA0MDg4Mw=="}, "originalCommit": {"oid": "a4e13a6f18019cb17f0092a696dcfc3631a15565"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1MjAxMzk5OnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/query/AggregationQuery.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xN1QwODo0MDo1NlrOFqcENQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xN1QwODo0MDo1NlrOFqcENQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDA0NDM0MQ==", "bodyText": "As you mentioned last time, the result is unordered. Could you add the comments some places to ease the readers?", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r380044341", "createdAt": "2020-02-17T08:40:56Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/query/AggregationQuery.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.query;\n+\n+import com.google.common.collect.Lists;\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.List;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.skywalking.oap.server.core.analysis.Downsampling;\n+import org.apache.skywalking.oap.server.core.query.entity.Order;\n+import org.apache.skywalking.oap.server.core.query.entity.TopNEntity;\n+import org.apache.skywalking.oap.server.core.register.EndpointInventory;\n+import org.apache.skywalking.oap.server.core.register.ServiceInstanceInventory;\n+import org.apache.skywalking.oap.server.core.storage.model.ModelName;\n+import org.apache.skywalking.oap.server.core.storage.query.IAggregationQueryDAO;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.base.MetricsDAO;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.SelectQueryImpl;\n+import org.influxdb.querybuilder.SelectSubQueryImpl;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.eq;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.gte;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.lte;\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.select;\n+\n+@Slf4j\n+public class AggregationQuery implements IAggregationQueryDAO {\n+    private InfluxClient client;\n+\n+    public AggregationQuery(InfluxClient client) {\n+        this.client = client;\n+    }\n+\n+    @Override\n+    public List<TopNEntity> getServiceTopN(String indName, String valueCName, int topN, Downsampling downsampling,\n+                                           long startTB, long endTB, Order order) throws IOException {\n+        return getTopNEntity(downsampling, indName, subQuery(indName, valueCName, startTB, endTB), order, topN);\n+    }\n+\n+    @Override\n+    public List<TopNEntity> getAllServiceInstanceTopN(String indName, String valueCName, int topN,\n+                                                      Downsampling downsampling,\n+                                                      long startTB, long endTB, Order order) throws IOException {\n+        return getTopNEntity(downsampling, indName, subQuery(indName, valueCName, startTB, endTB), order, topN);\n+    }\n+\n+    @Override\n+    public List<TopNEntity> getServiceInstanceTopN(int serviceId, String indName, String valueCName, int topN,\n+                                                   Downsampling downsampling,\n+                                                   long startTB, long endTB, Order order) throws IOException {\n+        return getTopNEntity(\n+            downsampling, indName,\n+            subQuery(ServiceInstanceInventory.SERVICE_ID, serviceId, indName, valueCName, startTB, endTB), order, topN\n+        );\n+    }\n+\n+    @Override\n+    public List<TopNEntity> getAllEndpointTopN(String indName, String valueCName, int topN, Downsampling downsampling,\n+                                               long startTB, long endTB, Order order) throws IOException {\n+        return getTopNEntity(downsampling, indName, subQuery(indName, valueCName, startTB, endTB), order, topN);\n+    }\n+\n+    @Override\n+    public List<TopNEntity> getEndpointTopN(int serviceId, String indName, String valueCName, int topN,\n+                                            Downsampling downsampling,\n+                                            long startTB, long endTB, Order order) throws IOException {\n+        return getTopNEntity(\n+            downsampling, indName,\n+            subQuery(EndpointInventory.SERVICE_ID, serviceId, indName, valueCName, startTB, endTB), order, topN\n+        );\n+    }\n+\n+    private List<TopNEntity> getTopNEntity(Downsampling downsampling,\n+                                           String name,\n+                                           SelectSubQueryImpl<SelectQueryImpl> subQuery,\n+                                           Order order,\n+                                           int topN) throws IOException {\n+        String measurement = ModelName.build(downsampling, name);\n+        Comparator<TopNEntity> comparator = DESCENDING;\n+        String functionName = \"top\";\n+        if (order == Order.ASC) {\n+            functionName = \"bottom\";\n+            comparator = ASCENDING;\n+        }\n+\n+        SelectQueryImpl query = select().function(functionName, \"mean\", topN).as(\"value\")\n+                                        .column(MetricsDAO.TAG_ENTITY_ID)\n+                                        .from(client.getDatabase(), measurement);\n+        query.setSubQuery(subQuery);\n+\n+        List<QueryResult.Series> series = client.queryForSeries(query);\n+        if (log.isDebugEnabled()) {\n+            log.debug(\"SQL: {} result set: {}\", query.getCommand(), series);\n+        }\n+        if (series == null || series.isEmpty()) {\n+            return Collections.emptyList();\n+        }\n+\n+        List<List<Object>> dataset = series.get(0).getValues();\n+        List<TopNEntity> entities = Lists.newArrayListWithCapacity(dataset.size());\n+        dataset.forEach(values -> {\n+            final TopNEntity entity = new TopNEntity();\n+            entity.setId((String) values.get(2));\n+            entity.setValue(((Double) values.get(1)).longValue());\n+            entities.add(entity);\n+        });\n+        Collections.sort(entities, comparator);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a4e13a6f18019cb17f0092a696dcfc3631a15565"}, "originalPosition": 126}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1MjAyMDkxOnYy", "diffSide": "RIGHT", "path": "test/e2e/e2e-ttl/e2e-ttl-influxdb/src/test/java/org/apache/skywalking/e2e/StorageTTLITCase.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xN1QwODo0MzoyMFrOFqcIJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xN1QwOTo0NTo1OVrOFqeD8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDA0NTM0OQ==", "bodyText": "remove this, and those in other files", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r380045349", "createdAt": "2020-02-17T08:43:20Z", "author": {"login": "kezhenxu94"}, "path": "test/e2e/e2e-ttl/e2e-ttl-influxdb/src/test/java/org/apache/skywalking/e2e/StorageTTLITCase.java", "diffHunk": "@@ -0,0 +1,285 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.skywalking.e2e;\n+\n+import io.grpc.ManagedChannel;\n+import io.grpc.ManagedChannelBuilder;\n+import io.grpc.internal.DnsNameResolverProvider;\n+import io.grpc.netty.NettyChannelBuilder;\n+import io.grpc.stub.StreamObserver;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.skywalking.apm.network.common.DetectPoint;\n+import org.apache.skywalking.apm.network.servicemesh.MeshProbeDownstream;\n+import org.apache.skywalking.apm.network.servicemesh.Protocol;\n+import org.apache.skywalking.apm.network.servicemesh.ServiceMeshMetric;\n+import org.apache.skywalking.apm.network.servicemesh.ServiceMeshMetricServiceGrpc;\n+import org.apache.skywalking.e2e.metrics.AllOfMetricsMatcher;\n+import org.apache.skywalking.e2e.metrics.AtLeastOneOfMetricsMatcher;\n+import org.apache.skywalking.e2e.metrics.Metrics;\n+import org.apache.skywalking.e2e.metrics.MetricsQuery;\n+import org.apache.skywalking.e2e.metrics.MetricsValueMatcher;\n+import org.apache.skywalking.e2e.service.Service;\n+import org.apache.skywalking.e2e.service.ServicesQuery;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+\n+import static org.apache.skywalking.e2e.metrics.MetricsQuery.SERVICE_RESP_TIME;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+/**\n+ * @author kezhenxu94\n+ */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a4e13a6f18019cb17f0092a696dcfc3631a15565"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDA0NjE1Nw==", "bodyText": "Why isn't this detected by CI process?", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r380046157", "createdAt": "2020-02-17T08:45:03Z", "author": {"login": "wu-sheng"}, "path": "test/e2e/e2e-ttl/e2e-ttl-influxdb/src/test/java/org/apache/skywalking/e2e/StorageTTLITCase.java", "diffHunk": "@@ -0,0 +1,285 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.skywalking.e2e;\n+\n+import io.grpc.ManagedChannel;\n+import io.grpc.ManagedChannelBuilder;\n+import io.grpc.internal.DnsNameResolverProvider;\n+import io.grpc.netty.NettyChannelBuilder;\n+import io.grpc.stub.StreamObserver;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.skywalking.apm.network.common.DetectPoint;\n+import org.apache.skywalking.apm.network.servicemesh.MeshProbeDownstream;\n+import org.apache.skywalking.apm.network.servicemesh.Protocol;\n+import org.apache.skywalking.apm.network.servicemesh.ServiceMeshMetric;\n+import org.apache.skywalking.apm.network.servicemesh.ServiceMeshMetricServiceGrpc;\n+import org.apache.skywalking.e2e.metrics.AllOfMetricsMatcher;\n+import org.apache.skywalking.e2e.metrics.AtLeastOneOfMetricsMatcher;\n+import org.apache.skywalking.e2e.metrics.Metrics;\n+import org.apache.skywalking.e2e.metrics.MetricsQuery;\n+import org.apache.skywalking.e2e.metrics.MetricsValueMatcher;\n+import org.apache.skywalking.e2e.service.Service;\n+import org.apache.skywalking.e2e.service.ServicesQuery;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+\n+import static org.apache.skywalking.e2e.metrics.MetricsQuery.SERVICE_RESP_TIME;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+/**\n+ * @author kezhenxu94\n+ */", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDA0NTM0OQ=="}, "originalCommit": {"oid": "a4e13a6f18019cb17f0092a696dcfc3631a15565"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDA0ODA0NQ==", "bodyText": "Why isn't this detected by CI process?\n\nCI belongs to the root module and its submodules, e2e and plugin tests are neither of them, maybe set up the same Checkstyle plugin in e2e and plugin tests?", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r380048045", "createdAt": "2020-02-17T08:49:12Z", "author": {"login": "kezhenxu94"}, "path": "test/e2e/e2e-ttl/e2e-ttl-influxdb/src/test/java/org/apache/skywalking/e2e/StorageTTLITCase.java", "diffHunk": "@@ -0,0 +1,285 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.skywalking.e2e;\n+\n+import io.grpc.ManagedChannel;\n+import io.grpc.ManagedChannelBuilder;\n+import io.grpc.internal.DnsNameResolverProvider;\n+import io.grpc.netty.NettyChannelBuilder;\n+import io.grpc.stub.StreamObserver;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.skywalking.apm.network.common.DetectPoint;\n+import org.apache.skywalking.apm.network.servicemesh.MeshProbeDownstream;\n+import org.apache.skywalking.apm.network.servicemesh.Protocol;\n+import org.apache.skywalking.apm.network.servicemesh.ServiceMeshMetric;\n+import org.apache.skywalking.apm.network.servicemesh.ServiceMeshMetricServiceGrpc;\n+import org.apache.skywalking.e2e.metrics.AllOfMetricsMatcher;\n+import org.apache.skywalking.e2e.metrics.AtLeastOneOfMetricsMatcher;\n+import org.apache.skywalking.e2e.metrics.Metrics;\n+import org.apache.skywalking.e2e.metrics.MetricsQuery;\n+import org.apache.skywalking.e2e.metrics.MetricsValueMatcher;\n+import org.apache.skywalking.e2e.service.Service;\n+import org.apache.skywalking.e2e.service.ServicesQuery;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+\n+import static org.apache.skywalking.e2e.metrics.MetricsQuery.SERVICE_RESP_TIME;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+/**\n+ * @author kezhenxu94\n+ */", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDA0NTM0OQ=="}, "originalCommit": {"oid": "a4e13a6f18019cb17f0092a696dcfc3631a15565"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDA1MjAxMA==", "bodyText": "We don't check ./test directory.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r380052010", "createdAt": "2020-02-17T08:56:59Z", "author": {"login": "dmsolr"}, "path": "test/e2e/e2e-ttl/e2e-ttl-influxdb/src/test/java/org/apache/skywalking/e2e/StorageTTLITCase.java", "diffHunk": "@@ -0,0 +1,285 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.skywalking.e2e;\n+\n+import io.grpc.ManagedChannel;\n+import io.grpc.ManagedChannelBuilder;\n+import io.grpc.internal.DnsNameResolverProvider;\n+import io.grpc.netty.NettyChannelBuilder;\n+import io.grpc.stub.StreamObserver;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.skywalking.apm.network.common.DetectPoint;\n+import org.apache.skywalking.apm.network.servicemesh.MeshProbeDownstream;\n+import org.apache.skywalking.apm.network.servicemesh.Protocol;\n+import org.apache.skywalking.apm.network.servicemesh.ServiceMeshMetric;\n+import org.apache.skywalking.apm.network.servicemesh.ServiceMeshMetricServiceGrpc;\n+import org.apache.skywalking.e2e.metrics.AllOfMetricsMatcher;\n+import org.apache.skywalking.e2e.metrics.AtLeastOneOfMetricsMatcher;\n+import org.apache.skywalking.e2e.metrics.Metrics;\n+import org.apache.skywalking.e2e.metrics.MetricsQuery;\n+import org.apache.skywalking.e2e.metrics.MetricsValueMatcher;\n+import org.apache.skywalking.e2e.service.Service;\n+import org.apache.skywalking.e2e.service.ServicesQuery;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+\n+import static org.apache.skywalking.e2e.metrics.MetricsQuery.SERVICE_RESP_TIME;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+/**\n+ * @author kezhenxu94\n+ */", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDA0NTM0OQ=="}, "originalCommit": {"oid": "a4e13a6f18019cb17f0092a696dcfc3631a15565"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDA3NzA0Mw==", "bodyText": "I think we should do that. Creating an issue to track this?", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r380077043", "createdAt": "2020-02-17T09:45:59Z", "author": {"login": "wu-sheng"}, "path": "test/e2e/e2e-ttl/e2e-ttl-influxdb/src/test/java/org/apache/skywalking/e2e/StorageTTLITCase.java", "diffHunk": "@@ -0,0 +1,285 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.skywalking.e2e;\n+\n+import io.grpc.ManagedChannel;\n+import io.grpc.ManagedChannelBuilder;\n+import io.grpc.internal.DnsNameResolverProvider;\n+import io.grpc.netty.NettyChannelBuilder;\n+import io.grpc.stub.StreamObserver;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.skywalking.apm.network.common.DetectPoint;\n+import org.apache.skywalking.apm.network.servicemesh.MeshProbeDownstream;\n+import org.apache.skywalking.apm.network.servicemesh.Protocol;\n+import org.apache.skywalking.apm.network.servicemesh.ServiceMeshMetric;\n+import org.apache.skywalking.apm.network.servicemesh.ServiceMeshMetricServiceGrpc;\n+import org.apache.skywalking.e2e.metrics.AllOfMetricsMatcher;\n+import org.apache.skywalking.e2e.metrics.AtLeastOneOfMetricsMatcher;\n+import org.apache.skywalking.e2e.metrics.Metrics;\n+import org.apache.skywalking.e2e.metrics.MetricsQuery;\n+import org.apache.skywalking.e2e.metrics.MetricsValueMatcher;\n+import org.apache.skywalking.e2e.service.Service;\n+import org.apache.skywalking.e2e.service.ServicesQuery;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+\n+import static org.apache.skywalking.e2e.metrics.MetricsQuery.SERVICE_RESP_TIME;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+/**\n+ * @author kezhenxu94\n+ */", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDA0NTM0OQ=="}, "originalCommit": {"oid": "a4e13a6f18019cb17f0092a696dcfc3631a15565"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1NTA1NDI0OnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/query/ProfileTaskQuery.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQwODowNDoxM1rOFq4c8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQwODowNDoxM1rOFq4c8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDUwOTQyNw==", "bodyText": "Check ModelInstaller#overrideColumnName, you could replace the name in the storage implementation. That is a more elegant way.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r380509427", "createdAt": "2020-02-18T08:04:13Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/query/ProfileTaskQuery.java", "diffHunk": "@@ -95,7 +96,7 @@ public ProfileTask getById(final String id) throws IOException {\n         WhereQueryImpl query = select(\"ID\", ProfileTaskRecord.SERVICE_ID,\n                                       ProfileTaskRecord.ENDPOINT_NAME, ProfileTaskRecord.START_TIME,\n                                       ProfileTaskRecord.CREATE_TIME,\n-                                      ProfileTaskRecord.DURATION,\n+                                      \"\\\"\" + ProfileTaskRecord.DURATION + \"\\\"\", // scape, the 'duration' is identifier", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5609a5d5578a65758540d5ad9be53a2ee214907b"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1ODY3NTk0OnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQwNTowNTowMFrOFrbNoA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQwNzo1ODowNFrOFreHvg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTA3ODk0NA==", "bodyText": "recommend add a null value to judge here\uff0csubsequence queries are based on the available influx", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r381078944", "createdAt": "2020-02-19T05:05:00Z", "author": null, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "diffHunk": "@@ -0,0 +1,191 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import lombok.extern.slf4j.Slf4j;\n+import okhttp3.OkHttpClient;\n+import org.apache.skywalking.oap.server.core.analysis.Downsampling;\n+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;\n+import org.apache.skywalking.oap.server.library.client.Client;\n+import org.apache.skywalking.oap.server.library.util.CollectionUtils;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.BatchPoints;\n+import org.influxdb.dto.Point;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.time.TimeInterval;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.ti;\n+\n+/**\n+ * InfluxDB connection maintainer, provides base data write/query API.\n+ */\n+@Slf4j\n+public class InfluxClient implements Client {\n+    private InfluxStorageConfig config;\n+    private InfluxDB influx;\n+\n+    /**\n+     * A constant, the name of time field in Time-series database.\n+     */\n+    public static final String TIME = \"time\";\n+    /**\n+     * A constant, the name of tag of time_bucket.\n+     */\n+    public static final String TAG_TIME_BUCKET = \"_time_bucket\";\n+\n+    private final String database;\n+\n+    public InfluxClient(InfluxStorageConfig config) {\n+        this.config = config;\n+        this.database = config.getDatabase();\n+    }\n+\n+    public final String getDatabase() {\n+        return database;\n+    }\n+\n+    @Override\n+    public void connect() {\n+        influx = InfluxDBFactory.connect(config.getUrl(), config.getUser(), config.getPassword(),\n+                                         new OkHttpClient.Builder().readTimeout(3, TimeUnit.MINUTES)\n+                                                                   .writeTimeout(3, TimeUnit.MINUTES),\n+                                         InfluxDB.ResponseFormat.MSGPACK\n+        );\n+        influx.query(new Query(\"CREATE DATABASE \" + database));\n+\n+        influx.enableBatch(config.getActions(), config.getDuration(), TimeUnit.MILLISECONDS);\n+        influx.setDatabase(database);\n+    }\n+\n+    /**\n+     * To get a connection of InfluxDB.\n+     *\n+     * @return InfluxDB's connection\n+     */\n+    private InfluxDB getInflux() {\n+        return influx;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9121be6a56988bb3d606b4239268e953b16f19c6"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTEyNjU5MA==", "bodyText": "I don't think so. OAP crashes and exits, when Influx initializes failed.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r381126590", "createdAt": "2020-02-19T07:58:04Z", "author": {"login": "dmsolr"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "diffHunk": "@@ -0,0 +1,191 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import lombok.extern.slf4j.Slf4j;\n+import okhttp3.OkHttpClient;\n+import org.apache.skywalking.oap.server.core.analysis.Downsampling;\n+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;\n+import org.apache.skywalking.oap.server.library.client.Client;\n+import org.apache.skywalking.oap.server.library.util.CollectionUtils;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.BatchPoints;\n+import org.influxdb.dto.Point;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.time.TimeInterval;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.ti;\n+\n+/**\n+ * InfluxDB connection maintainer, provides base data write/query API.\n+ */\n+@Slf4j\n+public class InfluxClient implements Client {\n+    private InfluxStorageConfig config;\n+    private InfluxDB influx;\n+\n+    /**\n+     * A constant, the name of time field in Time-series database.\n+     */\n+    public static final String TIME = \"time\";\n+    /**\n+     * A constant, the name of tag of time_bucket.\n+     */\n+    public static final String TAG_TIME_BUCKET = \"_time_bucket\";\n+\n+    private final String database;\n+\n+    public InfluxClient(InfluxStorageConfig config) {\n+        this.config = config;\n+        this.database = config.getDatabase();\n+    }\n+\n+    public final String getDatabase() {\n+        return database;\n+    }\n+\n+    @Override\n+    public void connect() {\n+        influx = InfluxDBFactory.connect(config.getUrl(), config.getUser(), config.getPassword(),\n+                                         new OkHttpClient.Builder().readTimeout(3, TimeUnit.MINUTES)\n+                                                                   .writeTimeout(3, TimeUnit.MINUTES),\n+                                         InfluxDB.ResponseFormat.MSGPACK\n+        );\n+        influx.query(new Query(\"CREATE DATABASE \" + database));\n+\n+        influx.enableBatch(config.getActions(), config.getDuration(), TimeUnit.MILLISECONDS);\n+        influx.setDatabase(database);\n+    }\n+\n+    /**\n+     * To get a connection of InfluxDB.\n+     *\n+     * @return InfluxDB's connection\n+     */\n+    private InfluxDB getInflux() {\n+        return influx;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTA3ODk0NA=="}, "originalCommit": {"oid": "9121be6a56988bb3d606b4239268e953b16f19c6"}, "originalPosition": 87}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1ODY4Mzk5OnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQwNToxMTowOFrOFrbSaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQwNToxMTowOFrOFrbSaQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTA4MDE2OQ==", "bodyText": "change method name deleteBefore or else better\uff1f", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r381080169", "createdAt": "2020-02-19T05:11:08Z", "author": null, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java", "diffHunk": "@@ -0,0 +1,191 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import lombok.extern.slf4j.Slf4j;\n+import okhttp3.OkHttpClient;\n+import org.apache.skywalking.oap.server.core.analysis.Downsampling;\n+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;\n+import org.apache.skywalking.oap.server.library.client.Client;\n+import org.apache.skywalking.oap.server.library.util.CollectionUtils;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.BatchPoints;\n+import org.influxdb.dto.Point;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.querybuilder.time.TimeInterval;\n+\n+import static org.influxdb.querybuilder.BuiltQuery.QueryBuilder.ti;\n+\n+/**\n+ * InfluxDB connection maintainer, provides base data write/query API.\n+ */\n+@Slf4j\n+public class InfluxClient implements Client {\n+    private InfluxStorageConfig config;\n+    private InfluxDB influx;\n+\n+    /**\n+     * A constant, the name of time field in Time-series database.\n+     */\n+    public static final String TIME = \"time\";\n+    /**\n+     * A constant, the name of tag of time_bucket.\n+     */\n+    public static final String TAG_TIME_BUCKET = \"_time_bucket\";\n+\n+    private final String database;\n+\n+    public InfluxClient(InfluxStorageConfig config) {\n+        this.config = config;\n+        this.database = config.getDatabase();\n+    }\n+\n+    public final String getDatabase() {\n+        return database;\n+    }\n+\n+    @Override\n+    public void connect() {\n+        influx = InfluxDBFactory.connect(config.getUrl(), config.getUser(), config.getPassword(),\n+                                         new OkHttpClient.Builder().readTimeout(3, TimeUnit.MINUTES)\n+                                                                   .writeTimeout(3, TimeUnit.MINUTES),\n+                                         InfluxDB.ResponseFormat.MSGPACK\n+        );\n+        influx.query(new Query(\"CREATE DATABASE \" + database));\n+\n+        influx.enableBatch(config.getActions(), config.getDuration(), TimeUnit.MILLISECONDS);\n+        influx.setDatabase(database);\n+    }\n+\n+    /**\n+     * To get a connection of InfluxDB.\n+     *\n+     * @return InfluxDB's connection\n+     */\n+    private InfluxDB getInflux() {\n+        return influx;\n+    }\n+\n+    /**\n+     * Execute a query against InfluxDB and return a set of {@link QueryResult.Result}s. Normally, InfluxDB supports\n+     * combining multiple statements into one query, so that we do get multi-results.\n+     *\n+     * @throws IOException if there is an error on the InfluxDB server or communication error.\n+     */\n+    public List<QueryResult.Result> query(Query query) throws IOException {\n+        if (log.isDebugEnabled()) {\n+            log.debug(\"SQL Statement: {}\", query.getCommand());\n+        }\n+\n+        try {\n+            QueryResult result = getInflux().query(query);\n+            if (result.hasError()) {\n+                throw new IOException(result.getError());\n+            }\n+            return result.getResults();\n+        } catch (Exception e) {\n+            throw new IOException(e.getMessage() + System.lineSeparator() + \"SQL Statement: \" + query.getCommand(), e);\n+        }\n+    }\n+\n+    /**\n+     * Execute a query against InfluxDB with a single statement.\n+     *\n+     * @throws IOException if there is an error on the InfluxDB server or communication error\n+     */\n+    public List<QueryResult.Series> queryForSeries(Query query) throws IOException {\n+        List<QueryResult.Result> results = query(query);\n+\n+        if (CollectionUtils.isEmpty(results)) {\n+            return null;\n+        }\n+        return results.get(0).getSeries();\n+    }\n+\n+    /**\n+     * Execute a query against InfluxDB with a single statement but return a single {@link QueryResult.Series}.\n+     *\n+     * @throws IOException if there is an error on the InfluxDB server or communication error\n+     */\n+    public QueryResult.Series queryForSingleSeries(Query query) throws IOException {\n+        List<QueryResult.Series> series = queryForSeries(query);\n+        if (CollectionUtils.isEmpty(series)) {\n+            return null;\n+        }\n+        return series.get(0);\n+    }\n+\n+    /**\n+     * Data management, to drop a time-series by measurement and time-series name specified. If an exception isn't\n+     * thrown, it means execution success. Notice, drop series don't support to drop series by range\n+     *\n+     * @throws IOException if there is an error on the InfluxDB server or communication error\n+     */\n+    public void dropSeries(String measurement, long timeBucket) throws IOException {\n+        Query query = new Query(\"DROP SERIES FROM \" + measurement + \" WHERE time_bucket='\" + timeBucket + \"'\");\n+        QueryResult result = getInflux().query(query);\n+\n+        if (result.hasError()) {\n+            throw new IOException(\"Statement: \" + query.getCommand() + \", ErrorMsg: \" + result.getError());\n+        }\n+    }\n+\n+    public void deleteByQuery(String measurement, long timestamp) throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9121be6a56988bb3d606b4239268e953b16f19c6"}, "originalPosition": 154}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1ODcwNjI4OnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/HistoryDeleteDAO.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQwNToyNTo1NVrOFrbf_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQwNzo1NDoxNlrOFreB0w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTA4MzY0NQ==", "bodyText": "+1 can be deleted\uff1f delete is <", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r381083645", "createdAt": "2020-02-19T05:25:55Z", "author": null, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/HistoryDeleteDAO.java", "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.base;\n+\n+import java.io.IOException;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.skywalking.oap.server.core.CoreModule;\n+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;\n+import org.apache.skywalking.oap.server.core.config.ConfigService;\n+import org.apache.skywalking.oap.server.core.storage.IHistoryDeleteDAO;\n+import org.apache.skywalking.oap.server.core.storage.model.Model;\n+import org.apache.skywalking.oap.server.core.storage.ttl.StorageTTL;\n+import org.apache.skywalking.oap.server.core.storage.ttl.TTLCalculator;\n+import org.apache.skywalking.oap.server.library.module.ModuleDefineHolder;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.joda.time.DateTime;\n+\n+@Slf4j\n+public class HistoryDeleteDAO implements IHistoryDeleteDAO {\n+    private final ModuleDefineHolder moduleDefineHolder;\n+    private final InfluxClient client;\n+    private final StorageTTL storageTTL;\n+\n+    public HistoryDeleteDAO(ModuleDefineHolder moduleDefineHolder, InfluxClient client, StorageTTL storageTTL) {\n+        this.moduleDefineHolder = moduleDefineHolder;\n+        this.storageTTL = storageTTL;\n+        this.client = client;\n+    }\n+\n+    @Override\n+    public void deleteHistory(Model model, String timeBucketColumnName) throws IOException {\n+        if (log.isDebugEnabled()) {\n+            log.debug(\"TTL execution log, model: {}\", model.getName());\n+        }\n+        try {\n+            ConfigService configService = moduleDefineHolder.find(CoreModule.NAME)\n+                                                            .provider()\n+                                                            .getService(ConfigService.class);\n+\n+            TTLCalculator ttlCalculator;\n+            if (model.isRecord()) {\n+                ttlCalculator = storageTTL.recordCalculator();\n+            } else {\n+                ttlCalculator = storageTTL.metricsCalculator(model.getDownsampling());\n+            }\n+\n+            client.deleteByQuery(\n+                model.getName(),\n+                TimeBucket.getTimestamp(ttlCalculator.timeBefore(DateTime.now(), configService.getDataTTLConfig()) + 1)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9121be6a56988bb3d606b4239268e953b16f19c6"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTEyNTA3NQ==", "bodyText": "The condition, we delete the history data, is less than and equal.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r381125075", "createdAt": "2020-02-19T07:54:16Z", "author": {"login": "dmsolr"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/HistoryDeleteDAO.java", "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.base;\n+\n+import java.io.IOException;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.skywalking.oap.server.core.CoreModule;\n+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;\n+import org.apache.skywalking.oap.server.core.config.ConfigService;\n+import org.apache.skywalking.oap.server.core.storage.IHistoryDeleteDAO;\n+import org.apache.skywalking.oap.server.core.storage.model.Model;\n+import org.apache.skywalking.oap.server.core.storage.ttl.StorageTTL;\n+import org.apache.skywalking.oap.server.core.storage.ttl.TTLCalculator;\n+import org.apache.skywalking.oap.server.library.module.ModuleDefineHolder;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.joda.time.DateTime;\n+\n+@Slf4j\n+public class HistoryDeleteDAO implements IHistoryDeleteDAO {\n+    private final ModuleDefineHolder moduleDefineHolder;\n+    private final InfluxClient client;\n+    private final StorageTTL storageTTL;\n+\n+    public HistoryDeleteDAO(ModuleDefineHolder moduleDefineHolder, InfluxClient client, StorageTTL storageTTL) {\n+        this.moduleDefineHolder = moduleDefineHolder;\n+        this.storageTTL = storageTTL;\n+        this.client = client;\n+    }\n+\n+    @Override\n+    public void deleteHistory(Model model, String timeBucketColumnName) throws IOException {\n+        if (log.isDebugEnabled()) {\n+            log.debug(\"TTL execution log, model: {}\", model.getName());\n+        }\n+        try {\n+            ConfigService configService = moduleDefineHolder.find(CoreModule.NAME)\n+                                                            .provider()\n+                                                            .getService(ConfigService.class);\n+\n+            TTLCalculator ttlCalculator;\n+            if (model.isRecord()) {\n+                ttlCalculator = storageTTL.recordCalculator();\n+            } else {\n+                ttlCalculator = storageTTL.metricsCalculator(model.getDownsampling());\n+            }\n+\n+            client.deleteByQuery(\n+                model.getName(),\n+                TimeBucket.getTimestamp(ttlCalculator.timeBefore(DateTime.now(), configService.getDataTTLConfig()) + 1)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTA4MzY0NQ=="}, "originalCommit": {"oid": "9121be6a56988bb3d606b4239268e953b16f19c6"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1OTEyMzc0OnYy", "diffSide": "RIGHT", "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/NoneStreamDAO.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQwODo0ODowNlrOFrfcUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQwOTozNjozM1rOFrhBRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTE0ODI0Mw==", "bodyText": "why this have Nanosecond? or millisecond?", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r381148243", "createdAt": "2020-02-19T08:48:06Z", "author": null, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/NoneStreamDAO.java", "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.base;\n+\n+import java.io.IOException;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.skywalking.apm.commons.datacarrier.common.AtomicRangeInteger;\n+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;\n+import org.apache.skywalking.oap.server.core.analysis.config.NoneStream;\n+import org.apache.skywalking.oap.server.core.profile.ProfileTaskRecord;\n+import org.apache.skywalking.oap.server.core.storage.INoneStreamDAO;\n+import org.apache.skywalking.oap.server.core.storage.StorageBuilder;\n+import org.apache.skywalking.oap.server.core.storage.model.Model;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.influxdb.dto.Point;\n+\n+public class NoneStreamDAO implements INoneStreamDAO {\n+    public static final String TAG_SERVICE_ID = \"_service_id\";\n+    private static final int PADDING_SIZE = 1_000_000;\n+    private static final AtomicRangeInteger SUFFIX = new AtomicRangeInteger(0, PADDING_SIZE);\n+\n+    private InfluxClient client;\n+    private StorageBuilder<NoneStream> storageBuilder;\n+\n+    public NoneStreamDAO(InfluxClient client, StorageBuilder<NoneStream> storageBuilder) {\n+        this.client = client;\n+        this.storageBuilder = storageBuilder;\n+    }\n+\n+    @Override\n+    public void insert(final Model model, final NoneStream noneStream) throws IOException {\n+        final long timestamp = TimeBucket.getTimestamp(\n+            noneStream.getTimeBucket(), model.getDownsampling()) * PADDING_SIZE + SUFFIX.getAndIncrement();\n+\n+        Point point = new InfluxInsertRequest(model, noneStream, storageBuilder)\n+            .time(timestamp, TimeUnit.NANOSECONDS)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9121be6a56988bb3d606b4239268e953b16f19c6"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTE3NDA4NA==", "bodyText": "All data in influxdb is nanosecond.", "url": "https://github.com/apache/skywalking/pull/4239#discussion_r381174084", "createdAt": "2020-02-19T09:36:33Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/base/NoneStreamDAO.java", "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.skywalking.oap.server.storage.plugin.influxdb.base;\n+\n+import java.io.IOException;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.skywalking.apm.commons.datacarrier.common.AtomicRangeInteger;\n+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;\n+import org.apache.skywalking.oap.server.core.analysis.config.NoneStream;\n+import org.apache.skywalking.oap.server.core.profile.ProfileTaskRecord;\n+import org.apache.skywalking.oap.server.core.storage.INoneStreamDAO;\n+import org.apache.skywalking.oap.server.core.storage.StorageBuilder;\n+import org.apache.skywalking.oap.server.core.storage.model.Model;\n+import org.apache.skywalking.oap.server.storage.plugin.influxdb.InfluxClient;\n+import org.influxdb.dto.Point;\n+\n+public class NoneStreamDAO implements INoneStreamDAO {\n+    public static final String TAG_SERVICE_ID = \"_service_id\";\n+    private static final int PADDING_SIZE = 1_000_000;\n+    private static final AtomicRangeInteger SUFFIX = new AtomicRangeInteger(0, PADDING_SIZE);\n+\n+    private InfluxClient client;\n+    private StorageBuilder<NoneStream> storageBuilder;\n+\n+    public NoneStreamDAO(InfluxClient client, StorageBuilder<NoneStream> storageBuilder) {\n+        this.client = client;\n+        this.storageBuilder = storageBuilder;\n+    }\n+\n+    @Override\n+    public void insert(final Model model, final NoneStream noneStream) throws IOException {\n+        final long timestamp = TimeBucket.getTimestamp(\n+            noneStream.getTimeBucket(), model.getDownsampling()) * PADDING_SIZE + SUFFIX.getAndIncrement();\n+\n+        Point point = new InfluxInsertRequest(model, noneStream, storageBuilder)\n+            .time(timestamp, TimeUnit.NANOSECONDS)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTE0ODI0Mw=="}, "originalCommit": {"oid": "9121be6a56988bb3d606b4239268e953b16f19c6"}, "originalPosition": 52}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4527, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}