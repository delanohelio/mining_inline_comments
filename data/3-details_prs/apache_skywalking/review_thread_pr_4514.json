{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg4NTQ1Nzg2", "number": 4514, "reviewThreads": {"totalCount": 18, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwMzozNjowMlrODoFxFA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQxMjo0Njo1MlrODoHP_A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMzY0MTE2OnYy", "diffSide": "RIGHT", "path": "docker/oap-es7/docker-entrypoint.sh", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwMzozNjowMlrOF2cvEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwNToyMTowM1rOF2dAQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYzODIyNg==", "bodyText": "@hanahmily please review these, the original logic operators are &&, but according to the error message, I think they should be ||, if I'm wrong, please correct me", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392638226", "createdAt": "2020-03-15T03:36:02Z", "author": {"login": "kezhenxu94"}, "path": "docker/oap-es7/docker-entrypoint.sh", "diffHunk": "@@ -294,202 +33,51 @@ validateVariables() {\n     fi\n }\n \n-generateApplicationYaml() {\n-    # validate\n-    [[ -z \"$SW_CLUSTER\" ]] && [[ -z \"$SW_STORAGE\" ]] && [[ -z \"$SW_CONFIGURATION\" ]] \\\n-        && [[ -z \"$SW_TELEMETRY\" ]] \\\n-        && { echo \"Error: please specify \\\"SW_CLUSTER\\\" \\\"SW_STORAGE\\\" \\\"SW_CONFIGURATION\\\" \\\"SW_TELEMETRY\\\"\"; exit 1; }\n-\n-    validateVariables \"SW_CLUSTER\" \"$SW_CLUSTER\" \"standalone zookeeper kubernetes consul etcd nacos\"\n-\n-    validateVariables \"SW_STORAGE\" \"$SW_STORAGE\" \"elasticsearch h2 mysql influxdb\"\n-\n-    validateVariables \"SW_CONFIGURATION\" \"$SW_CONFIGURATION\" \"none apollo nacos zookeeper\"\n-\n-    validateVariables \"SW_TELEMETRY\" \"$SW_TELEMETRY\" \"none prometheus so11y\"\n+echo \"[Entrypoint] Apache SkyWalking Docker Image\"\n \n-    echo \"# Generated by 'docker-entrypoint.sh'\" > ${var_application_file}\n-    #generate cluster\n-    case ${SW_CLUSTER} in\n-    standalone) generateClusterStandalone;;\n-    zookeeper) generateClusterZookeeper;;\n-    kubernetes) generateClusterK8s;;\n-    consul) generateClusterConsul;;\n-    etcd) generateClusterEtcd;;\n-    nacos) generateClusterNacos;;\n-    esac\n+# validate\n+[[ -z \"$SW_CLUSTER\" ]] || [[ -z \"$SW_STORAGE\" ]] || [[ -z \"$SW_CONFIGURATION\" ]] \\\n+    || [[ -z \"$SW_TELEMETRY\" ]] \\\n+    && { echo \"Error: please specify \\\"SW_CLUSTER\\\" \\\"SW_STORAGE\\\" \\\"SW_CONFIGURATION\\\" \\\"SW_TELEMETRY\\\"\"; exit 1; }", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 300}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY0MjYyNg==", "bodyText": "I think we should remove this assertation, leave it to oap config value checker.", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392642626", "createdAt": "2020-03-15T05:21:03Z", "author": {"login": "hanahmily"}, "path": "docker/oap-es7/docker-entrypoint.sh", "diffHunk": "@@ -294,202 +33,51 @@ validateVariables() {\n     fi\n }\n \n-generateApplicationYaml() {\n-    # validate\n-    [[ -z \"$SW_CLUSTER\" ]] && [[ -z \"$SW_STORAGE\" ]] && [[ -z \"$SW_CONFIGURATION\" ]] \\\n-        && [[ -z \"$SW_TELEMETRY\" ]] \\\n-        && { echo \"Error: please specify \\\"SW_CLUSTER\\\" \\\"SW_STORAGE\\\" \\\"SW_CONFIGURATION\\\" \\\"SW_TELEMETRY\\\"\"; exit 1; }\n-\n-    validateVariables \"SW_CLUSTER\" \"$SW_CLUSTER\" \"standalone zookeeper kubernetes consul etcd nacos\"\n-\n-    validateVariables \"SW_STORAGE\" \"$SW_STORAGE\" \"elasticsearch h2 mysql influxdb\"\n-\n-    validateVariables \"SW_CONFIGURATION\" \"$SW_CONFIGURATION\" \"none apollo nacos zookeeper\"\n-\n-    validateVariables \"SW_TELEMETRY\" \"$SW_TELEMETRY\" \"none prometheus so11y\"\n+echo \"[Entrypoint] Apache SkyWalking Docker Image\"\n \n-    echo \"# Generated by 'docker-entrypoint.sh'\" > ${var_application_file}\n-    #generate cluster\n-    case ${SW_CLUSTER} in\n-    standalone) generateClusterStandalone;;\n-    zookeeper) generateClusterZookeeper;;\n-    kubernetes) generateClusterK8s;;\n-    consul) generateClusterConsul;;\n-    etcd) generateClusterEtcd;;\n-    nacos) generateClusterNacos;;\n-    esac\n+# validate\n+[[ -z \"$SW_CLUSTER\" ]] || [[ -z \"$SW_STORAGE\" ]] || [[ -z \"$SW_CONFIGURATION\" ]] \\\n+    || [[ -z \"$SW_TELEMETRY\" ]] \\\n+    && { echo \"Error: please specify \\\"SW_CLUSTER\\\" \\\"SW_STORAGE\\\" \\\"SW_CONFIGURATION\\\" \\\"SW_TELEMETRY\\\"\"; exit 1; }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYzODIyNg=="}, "originalCommit": null, "originalPosition": 300}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMzY0OTY3OnYy", "diffSide": "RIGHT", "path": "oap-server/server-bootstrap/src/main/java/org/apache/skywalking/oap/server/starter/config/ApplicationConfigLoader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwMzo1OTo1M1rOF2czEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwNDoxMDo0MVrOF2c0oA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYzOTI1MA==", "bodyText": "I think you need to add a check and error for selected provider not found, when you give a value to selector, but no suitable provider definition here.", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392639250", "createdAt": "2020-03-15T03:59:53Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-bootstrap/src/main/java/org/apache/skywalking/oap/server/starter/config/ApplicationConfigLoader.java", "diffHunk": "@@ -105,6 +107,19 @@ private void overrideConfigBySystemEnv(ApplicationConfiguration configuration) {\n         }\n     }\n \n+    private void selectConfig(final Map<String, Object> configuration) {\n+        if (configuration.size() <= 1) {\n+            return;\n+        }\n+        if (configuration.containsKey(\"selector\")) {\n+            final String selector = (String) configuration.get(\"selector\");\n+            final String resolvedSelector = PropertyPlaceholderHelper.INSTANCE.replacePlaceholders(\n+                selector, System.getProperties()\n+            );\n+            configuration.entrySet().removeIf(e -> !resolvedSelector.equals(e.getKey()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYzOTY0OA==", "bodyText": "I think you need to add a check and error for selected provider not found, when you give a value to selector, but no suitable provider definition here.\n\nYes, thanks for pointing out, just found that and fixed", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392639648", "createdAt": "2020-03-15T04:10:41Z", "author": {"login": "kezhenxu94"}, "path": "oap-server/server-bootstrap/src/main/java/org/apache/skywalking/oap/server/starter/config/ApplicationConfigLoader.java", "diffHunk": "@@ -105,6 +107,19 @@ private void overrideConfigBySystemEnv(ApplicationConfiguration configuration) {\n         }\n     }\n \n+    private void selectConfig(final Map<String, Object> configuration) {\n+        if (configuration.size() <= 1) {\n+            return;\n+        }\n+        if (configuration.containsKey(\"selector\")) {\n+            final String selector = (String) configuration.get(\"selector\");\n+            final String resolvedSelector = PropertyPlaceholderHelper.INSTANCE.replacePlaceholders(\n+                selector, System.getProperties()\n+            );\n+            configuration.entrySet().removeIf(e -> !resolvedSelector.equals(e.getKey()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYzOTI1MA=="}, "originalCommit": null, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMzY3NjY0OnYy", "diffSide": "RIGHT", "path": "docker/oap-es7/docker-entrypoint.sh", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwNToyMToxNlrOF2dASA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwNToyMToxNlrOF2dASA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY0MjYzMg==", "bodyText": "remove it.", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392642632", "createdAt": "2020-03-15T05:21:16Z", "author": {"login": "hanahmily"}, "path": "docker/oap-es7/docker-entrypoint.sh", "diffHunk": "@@ -294,202 +33,51 @@ validateVariables() {\n     fi\n }\n \n-generateApplicationYaml() {\n-    # validate\n-    [[ -z \"$SW_CLUSTER\" ]] && [[ -z \"$SW_STORAGE\" ]] && [[ -z \"$SW_CONFIGURATION\" ]] \\\n-        && [[ -z \"$SW_TELEMETRY\" ]] \\\n-        && { echo \"Error: please specify \\\"SW_CLUSTER\\\" \\\"SW_STORAGE\\\" \\\"SW_CONFIGURATION\\\" \\\"SW_TELEMETRY\\\"\"; exit 1; }\n-\n-    validateVariables \"SW_CLUSTER\" \"$SW_CLUSTER\" \"standalone zookeeper kubernetes consul etcd nacos\"\n-\n-    validateVariables \"SW_STORAGE\" \"$SW_STORAGE\" \"elasticsearch h2 mysql influxdb\"\n-\n-    validateVariables \"SW_CONFIGURATION\" \"$SW_CONFIGURATION\" \"none apollo nacos zookeeper\"\n-\n-    validateVariables \"SW_TELEMETRY\" \"$SW_TELEMETRY\" \"none prometheus so11y\"\n+echo \"[Entrypoint] Apache SkyWalking Docker Image\"\n \n-    echo \"# Generated by 'docker-entrypoint.sh'\" > ${var_application_file}\n-    #generate cluster\n-    case ${SW_CLUSTER} in\n-    standalone) generateClusterStandalone;;\n-    zookeeper) generateClusterZookeeper;;\n-    kubernetes) generateClusterK8s;;\n-    consul) generateClusterConsul;;\n-    etcd) generateClusterEtcd;;\n-    nacos) generateClusterNacos;;\n-    esac\n+# validate\n+[[ -z \"$SW_CLUSTER\" ]] || [[ -z \"$SW_STORAGE\" ]] || [[ -z \"$SW_CONFIGURATION\" ]] \\\n+    || [[ -z \"$SW_TELEMETRY\" ]] \\\n+    && { echo \"Error: please specify \\\"SW_CLUSTER\\\" \\\"SW_STORAGE\\\" \\\"SW_CONFIGURATION\\\" \\\"SW_TELEMETRY\\\"\"; exit 1; }\n \n-    #generate core\n-    cat <<EOT >> ${var_application_file}\n-core:\n-  default:\n-    # Mixed: Receive agent data, Level 1 aggregate, Level 2 aggregate\n-    # Receiver: Receive agent data, Level 1 aggregate\n-    # Aggregator: Level 2 aggregate\n-    role: \\${SW_CORE_ROLE:Mixed} # Mixed/Receiver/Aggregator\n-    restHost: \\${SW_CORE_REST_HOST:0.0.0.0}\n-    restPort: \\${SW_CORE_REST_PORT:12800}\n-    restContextPath: \\${SW_CORE_REST_CONTEXT_PATH:/}\n-    gRPCHost: \\${SW_CORE_GRPC_HOST:0.0.0.0}\n-    gRPCPort: \\${SW_CORE_GRPC_PORT:11800}\n-    gRPCSslEnabled: \\${SW_CORE_GRPC_SSL_ENABLED:false}\n-    gRPCSslKeyPath: \\${SW_CORE_GRPC_SSL_KEY_PATH:\"\"}\n-    gRPCSslCertChainPath: \\${SW_CORE_GRPC_SSL_CERT_CHAIN_PATH:\"\"}\n-    gRPCSslTrustedCAPath: \\${SW_CORE_GRPC_SSL_TRUSTED_CA_PATH:\"\"}\n-    downsampling:\n-    - Hour\n-    - Day\n-    - Month\n-    # Set a timeout on metrics data. After the timeout has expired, the metrics data will automatically be deleted.\n-    enableDataKeeperExecutor: \\${SW_CORE_ENABLE_DATA_KEEPER_EXECUTOR:true} # Turn it off then automatically metrics data delete will be close.\n-    dataKeeperExecutePeriod: \\${SW_CORE_DATA_KEEPER_EXECUTE_PERIOD:5} # How often the data keeper executor runs periodically, unit is minute\n-    recordDataTTL: \\${SW_CORE_RECORD_DATA_TTL:90} # Unit is minute\n-    minuteMetricsDataTTL: \\${SW_CORE_MINUTE_METRIC_DATA_TTL:90} # Unit is minute\n-    hourMetricsDataTTL: \\${SW_CORE_HOUR_METRIC_DATA_TTL:36} # Unit is hour\n-    dayMetricsDataTTL: \\${SW_CORE_DAY_METRIC_DATA_TTL:45} # Unit is day\n-    monthMetricsDataTTL: \\${SW_CORE_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-    # Cache metric data for 1 minute to reduce database queries, and if the OAP cluster changes within that minute,\n-    # the metrics may not be accurate within that minute.\n-    enableDatabaseSession: \\${SW_CORE_ENABLE_DATABASE_SESSION:true}\n-    topNReportPeriod: \\${SW_CORE_TOPN_REPORT_PERIOD:10}\n-EOT\n+validateVariables \"SW_CLUSTER\" \"$SW_CLUSTER\" \"standalone zookeeper kubernetes consul etcd nacos\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 336}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMzY3Njg2OnYy", "diffSide": "RIGHT", "path": "docker/oap-es7/docker-entrypoint.sh", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwNToyMToyOVrOF2dAXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwNToyMToyOVrOF2dAXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY0MjY1NQ==", "bodyText": "the same, remove it.", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392642655", "createdAt": "2020-03-15T05:21:29Z", "author": {"login": "hanahmily"}, "path": "docker/oap-es7/docker-entrypoint.sh", "diffHunk": "@@ -294,202 +33,51 @@ validateVariables() {\n     fi\n }\n \n-generateApplicationYaml() {\n-    # validate\n-    [[ -z \"$SW_CLUSTER\" ]] && [[ -z \"$SW_STORAGE\" ]] && [[ -z \"$SW_CONFIGURATION\" ]] \\\n-        && [[ -z \"$SW_TELEMETRY\" ]] \\\n-        && { echo \"Error: please specify \\\"SW_CLUSTER\\\" \\\"SW_STORAGE\\\" \\\"SW_CONFIGURATION\\\" \\\"SW_TELEMETRY\\\"\"; exit 1; }\n-\n-    validateVariables \"SW_CLUSTER\" \"$SW_CLUSTER\" \"standalone zookeeper kubernetes consul etcd nacos\"\n-\n-    validateVariables \"SW_STORAGE\" \"$SW_STORAGE\" \"elasticsearch h2 mysql influxdb\"\n-\n-    validateVariables \"SW_CONFIGURATION\" \"$SW_CONFIGURATION\" \"none apollo nacos zookeeper\"\n-\n-    validateVariables \"SW_TELEMETRY\" \"$SW_TELEMETRY\" \"none prometheus so11y\"\n+echo \"[Entrypoint] Apache SkyWalking Docker Image\"\n \n-    echo \"# Generated by 'docker-entrypoint.sh'\" > ${var_application_file}\n-    #generate cluster\n-    case ${SW_CLUSTER} in\n-    standalone) generateClusterStandalone;;\n-    zookeeper) generateClusterZookeeper;;\n-    kubernetes) generateClusterK8s;;\n-    consul) generateClusterConsul;;\n-    etcd) generateClusterEtcd;;\n-    nacos) generateClusterNacos;;\n-    esac\n+# validate\n+[[ -z \"$SW_CLUSTER\" ]] || [[ -z \"$SW_STORAGE\" ]] || [[ -z \"$SW_CONFIGURATION\" ]] \\\n+    || [[ -z \"$SW_TELEMETRY\" ]] \\\n+    && { echo \"Error: please specify \\\"SW_CLUSTER\\\" \\\"SW_STORAGE\\\" \\\"SW_CONFIGURATION\\\" \\\"SW_TELEMETRY\\\"\"; exit 1; }\n \n-    #generate core\n-    cat <<EOT >> ${var_application_file}\n-core:\n-  default:\n-    # Mixed: Receive agent data, Level 1 aggregate, Level 2 aggregate\n-    # Receiver: Receive agent data, Level 1 aggregate\n-    # Aggregator: Level 2 aggregate\n-    role: \\${SW_CORE_ROLE:Mixed} # Mixed/Receiver/Aggregator\n-    restHost: \\${SW_CORE_REST_HOST:0.0.0.0}\n-    restPort: \\${SW_CORE_REST_PORT:12800}\n-    restContextPath: \\${SW_CORE_REST_CONTEXT_PATH:/}\n-    gRPCHost: \\${SW_CORE_GRPC_HOST:0.0.0.0}\n-    gRPCPort: \\${SW_CORE_GRPC_PORT:11800}\n-    gRPCSslEnabled: \\${SW_CORE_GRPC_SSL_ENABLED:false}\n-    gRPCSslKeyPath: \\${SW_CORE_GRPC_SSL_KEY_PATH:\"\"}\n-    gRPCSslCertChainPath: \\${SW_CORE_GRPC_SSL_CERT_CHAIN_PATH:\"\"}\n-    gRPCSslTrustedCAPath: \\${SW_CORE_GRPC_SSL_TRUSTED_CA_PATH:\"\"}\n-    downsampling:\n-    - Hour\n-    - Day\n-    - Month\n-    # Set a timeout on metrics data. After the timeout has expired, the metrics data will automatically be deleted.\n-    enableDataKeeperExecutor: \\${SW_CORE_ENABLE_DATA_KEEPER_EXECUTOR:true} # Turn it off then automatically metrics data delete will be close.\n-    dataKeeperExecutePeriod: \\${SW_CORE_DATA_KEEPER_EXECUTE_PERIOD:5} # How often the data keeper executor runs periodically, unit is minute\n-    recordDataTTL: \\${SW_CORE_RECORD_DATA_TTL:90} # Unit is minute\n-    minuteMetricsDataTTL: \\${SW_CORE_MINUTE_METRIC_DATA_TTL:90} # Unit is minute\n-    hourMetricsDataTTL: \\${SW_CORE_HOUR_METRIC_DATA_TTL:36} # Unit is hour\n-    dayMetricsDataTTL: \\${SW_CORE_DAY_METRIC_DATA_TTL:45} # Unit is day\n-    monthMetricsDataTTL: \\${SW_CORE_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-    # Cache metric data for 1 minute to reduce database queries, and if the OAP cluster changes within that minute,\n-    # the metrics may not be accurate within that minute.\n-    enableDatabaseSession: \\${SW_CORE_ENABLE_DATABASE_SESSION:true}\n-    topNReportPeriod: \\${SW_CORE_TOPN_REPORT_PERIOD:10}\n-EOT\n+validateVariables \"SW_CLUSTER\" \"$SW_CLUSTER\" \"standalone zookeeper kubernetes consul etcd nacos\"\n \n-    # generate storage\n-    case ${SW_STORAGE} in\n-    elasticsearch) generateStorageElastisearch;;\n-    h2) generateStorageH2;;\n-    mysql) generateStorageMySQL;;\n-    influxdb) generateStorageInfluxDB;;\n-    esac\n+validateVariables \"SW_STORAGE\" \"$SW_STORAGE\" \"elasticsearch h2 mysql influxdb\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 345}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMzY3Njg5OnYy", "diffSide": "RIGHT", "path": "docker/oap-es7/docker-entrypoint.sh", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwNToyMTo0NVrOF2dAYw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwNToyMTo0NVrOF2dAYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY0MjY1OQ==", "bodyText": "same as above, remove this line.", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392642659", "createdAt": "2020-03-15T05:21:45Z", "author": {"login": "hanahmily"}, "path": "docker/oap-es7/docker-entrypoint.sh", "diffHunk": "@@ -294,202 +33,51 @@ validateVariables() {\n     fi\n }\n \n-generateApplicationYaml() {\n-    # validate\n-    [[ -z \"$SW_CLUSTER\" ]] && [[ -z \"$SW_STORAGE\" ]] && [[ -z \"$SW_CONFIGURATION\" ]] \\\n-        && [[ -z \"$SW_TELEMETRY\" ]] \\\n-        && { echo \"Error: please specify \\\"SW_CLUSTER\\\" \\\"SW_STORAGE\\\" \\\"SW_CONFIGURATION\\\" \\\"SW_TELEMETRY\\\"\"; exit 1; }\n-\n-    validateVariables \"SW_CLUSTER\" \"$SW_CLUSTER\" \"standalone zookeeper kubernetes consul etcd nacos\"\n-\n-    validateVariables \"SW_STORAGE\" \"$SW_STORAGE\" \"elasticsearch h2 mysql influxdb\"\n-\n-    validateVariables \"SW_CONFIGURATION\" \"$SW_CONFIGURATION\" \"none apollo nacos zookeeper\"\n-\n-    validateVariables \"SW_TELEMETRY\" \"$SW_TELEMETRY\" \"none prometheus so11y\"\n+echo \"[Entrypoint] Apache SkyWalking Docker Image\"\n \n-    echo \"# Generated by 'docker-entrypoint.sh'\" > ${var_application_file}\n-    #generate cluster\n-    case ${SW_CLUSTER} in\n-    standalone) generateClusterStandalone;;\n-    zookeeper) generateClusterZookeeper;;\n-    kubernetes) generateClusterK8s;;\n-    consul) generateClusterConsul;;\n-    etcd) generateClusterEtcd;;\n-    nacos) generateClusterNacos;;\n-    esac\n+# validate\n+[[ -z \"$SW_CLUSTER\" ]] || [[ -z \"$SW_STORAGE\" ]] || [[ -z \"$SW_CONFIGURATION\" ]] \\\n+    || [[ -z \"$SW_TELEMETRY\" ]] \\\n+    && { echo \"Error: please specify \\\"SW_CLUSTER\\\" \\\"SW_STORAGE\\\" \\\"SW_CONFIGURATION\\\" \\\"SW_TELEMETRY\\\"\"; exit 1; }\n \n-    #generate core\n-    cat <<EOT >> ${var_application_file}\n-core:\n-  default:\n-    # Mixed: Receive agent data, Level 1 aggregate, Level 2 aggregate\n-    # Receiver: Receive agent data, Level 1 aggregate\n-    # Aggregator: Level 2 aggregate\n-    role: \\${SW_CORE_ROLE:Mixed} # Mixed/Receiver/Aggregator\n-    restHost: \\${SW_CORE_REST_HOST:0.0.0.0}\n-    restPort: \\${SW_CORE_REST_PORT:12800}\n-    restContextPath: \\${SW_CORE_REST_CONTEXT_PATH:/}\n-    gRPCHost: \\${SW_CORE_GRPC_HOST:0.0.0.0}\n-    gRPCPort: \\${SW_CORE_GRPC_PORT:11800}\n-    gRPCSslEnabled: \\${SW_CORE_GRPC_SSL_ENABLED:false}\n-    gRPCSslKeyPath: \\${SW_CORE_GRPC_SSL_KEY_PATH:\"\"}\n-    gRPCSslCertChainPath: \\${SW_CORE_GRPC_SSL_CERT_CHAIN_PATH:\"\"}\n-    gRPCSslTrustedCAPath: \\${SW_CORE_GRPC_SSL_TRUSTED_CA_PATH:\"\"}\n-    downsampling:\n-    - Hour\n-    - Day\n-    - Month\n-    # Set a timeout on metrics data. After the timeout has expired, the metrics data will automatically be deleted.\n-    enableDataKeeperExecutor: \\${SW_CORE_ENABLE_DATA_KEEPER_EXECUTOR:true} # Turn it off then automatically metrics data delete will be close.\n-    dataKeeperExecutePeriod: \\${SW_CORE_DATA_KEEPER_EXECUTE_PERIOD:5} # How often the data keeper executor runs periodically, unit is minute\n-    recordDataTTL: \\${SW_CORE_RECORD_DATA_TTL:90} # Unit is minute\n-    minuteMetricsDataTTL: \\${SW_CORE_MINUTE_METRIC_DATA_TTL:90} # Unit is minute\n-    hourMetricsDataTTL: \\${SW_CORE_HOUR_METRIC_DATA_TTL:36} # Unit is hour\n-    dayMetricsDataTTL: \\${SW_CORE_DAY_METRIC_DATA_TTL:45} # Unit is day\n-    monthMetricsDataTTL: \\${SW_CORE_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-    # Cache metric data for 1 minute to reduce database queries, and if the OAP cluster changes within that minute,\n-    # the metrics may not be accurate within that minute.\n-    enableDatabaseSession: \\${SW_CORE_ENABLE_DATABASE_SESSION:true}\n-    topNReportPeriod: \\${SW_CORE_TOPN_REPORT_PERIOD:10}\n-EOT\n+validateVariables \"SW_CLUSTER\" \"$SW_CLUSTER\" \"standalone zookeeper kubernetes consul etcd nacos\"\n \n-    # generate storage\n-    case ${SW_STORAGE} in\n-    elasticsearch) generateStorageElastisearch;;\n-    h2) generateStorageH2;;\n-    mysql) generateStorageMySQL;;\n-    influxdb) generateStorageInfluxDB;;\n-    esac\n+validateVariables \"SW_STORAGE\" \"$SW_STORAGE\" \"elasticsearch h2 mysql influxdb\"\n \n-    cat <<EOT >> ${var_application_file}\n-receiver-sharing-server:\n-  default:\n-   restHost: \\${SW_RECEIVER_SHARING_REST_HOST:0.0.0.0}\n-   restPort: \\${SW_RECEIVER_SHARING_REST_PORT:0}\n-   restContextPath: \\${SW_RECEIVER_SHARING_REST_CONTEXT_PATH:/}\n-   gRPCHost: \\${SW_RECEIVER_SHARING_GRPC_HOST:0.0.0.0}\n-   gRPCPort: \\${SW_RECEIVER_SHARING_GRPC_PORT:0}\n-   maxConcurrentCallsPerConnection: \\${SW_RECEIVER_SHARING_MAX_CONCURRENT_CALL:0}\n-   maxMessageSize: \\${SW_RECEIVER_SHARING_MAX_MESSAGE_SIZE:0}\n-   gRPCThreadPoolSize: \\${SW_RECEIVER_SHARING_GRPC_THREAD_POOL_SIZE:0}\n-   gRPCThreadPoolQueueSize: \\${SW_RECEIVER_SHARING_GRPC_THREAD_POOL_QUEUE_SIZE:0}\n-   authentication: \\${SW_AUTHENTICATION:\"\"}\n-   gRPCSslEnabled: \\${SW_RECEIVER_SHARING_GRPC_SSL_ENABLED:false}\n-   gRPCSslKeyPath: \\${SW_RECEIVER_SHARING_GRPC_SSL_KEY_PATH:\"\"}\n-   gRPCSslCertChainPath: \\${SW_RECEIVER_SHARING_GRPC_SSL_CERT_CHAIN_PATH:\"\"}\n-receiver-register:\n-  default:\n-receiver-trace:\n-  default:\n-    bufferPath: \\${SW_RECEIVER_BUFFER_PATH:../trace-buffer/}  # Path to trace buffer files, suggest to use absolute path\n-    bufferOffsetMaxFileSize: \\${SW_RECEIVER_BUFFER_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n-    bufferDataMaxFileSize: \\${SW_RECEIVER_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n-    bufferFileCleanWhenRestart: \\${SW_RECEIVER_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n-    sampleRate: \\${SW_TRACE_SAMPLE_RATE:10000} # The sample rate precision is 1/10000. 10000 means 100% sample in default.\n-    slowDBAccessThreshold: \\${SW_SLOW_DB_THRESHOLD:default:200,mongodb:100} # The slow database access thresholds. Unit ms.\n-receiver-jvm:\n-  default:\n-receiver-clr:\n-  default:\n-service-mesh:\n-  default:\n-    bufferPath: \\${SW_SERVICE_MESH_BUFFER_PATH:../mesh-buffer/}  # Path to trace buffer files, suggest to use absolute path\n-    bufferOffsetMaxFileSize: \\${SW_SERVICE_MESH_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n-    bufferDataMaxFileSize: \\${SW_SERVICE_MESH_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n-    bufferFileCleanWhenRestart: \\${SW_SERVICE_MESH_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n-istio-telemetry:\n-  default:\n-query:\n-  graphql:\n-    path: \\${SW_QUERY_GRAPHQL_PATH:/graphql}\n-alarm:\n-  default:\n-EOT\n-    # generate telemetry\n-    case ${SW_TELEMETRY} in\n-    none) generateTelemetryNone;;\n-    prometheus) generateTelemetryPrometheus;;\n-    so11y) generateTelemetrySo11y;;\n-    esac\n+validateVariables \"SW_CONFIGURATION\" \"$SW_CONFIGURATION\" \"none apollo nacos zookeeper\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 397}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMzY3Njk3OnYy", "diffSide": "RIGHT", "path": "docker/oap-es7/docker-entrypoint.sh", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwNToyMTo1OFrOF2dAbg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwNToyMTo1OFrOF2dAbg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY0MjY3MA==", "bodyText": "remove it.", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392642670", "createdAt": "2020-03-15T05:21:58Z", "author": {"login": "hanahmily"}, "path": "docker/oap-es7/docker-entrypoint.sh", "diffHunk": "@@ -294,202 +33,51 @@ validateVariables() {\n     fi\n }\n \n-generateApplicationYaml() {\n-    # validate\n-    [[ -z \"$SW_CLUSTER\" ]] && [[ -z \"$SW_STORAGE\" ]] && [[ -z \"$SW_CONFIGURATION\" ]] \\\n-        && [[ -z \"$SW_TELEMETRY\" ]] \\\n-        && { echo \"Error: please specify \\\"SW_CLUSTER\\\" \\\"SW_STORAGE\\\" \\\"SW_CONFIGURATION\\\" \\\"SW_TELEMETRY\\\"\"; exit 1; }\n-\n-    validateVariables \"SW_CLUSTER\" \"$SW_CLUSTER\" \"standalone zookeeper kubernetes consul etcd nacos\"\n-\n-    validateVariables \"SW_STORAGE\" \"$SW_STORAGE\" \"elasticsearch h2 mysql influxdb\"\n-\n-    validateVariables \"SW_CONFIGURATION\" \"$SW_CONFIGURATION\" \"none apollo nacos zookeeper\"\n-\n-    validateVariables \"SW_TELEMETRY\" \"$SW_TELEMETRY\" \"none prometheus so11y\"\n+echo \"[Entrypoint] Apache SkyWalking Docker Image\"\n \n-    echo \"# Generated by 'docker-entrypoint.sh'\" > ${var_application_file}\n-    #generate cluster\n-    case ${SW_CLUSTER} in\n-    standalone) generateClusterStandalone;;\n-    zookeeper) generateClusterZookeeper;;\n-    kubernetes) generateClusterK8s;;\n-    consul) generateClusterConsul;;\n-    etcd) generateClusterEtcd;;\n-    nacos) generateClusterNacos;;\n-    esac\n+# validate\n+[[ -z \"$SW_CLUSTER\" ]] || [[ -z \"$SW_STORAGE\" ]] || [[ -z \"$SW_CONFIGURATION\" ]] \\\n+    || [[ -z \"$SW_TELEMETRY\" ]] \\\n+    && { echo \"Error: please specify \\\"SW_CLUSTER\\\" \\\"SW_STORAGE\\\" \\\"SW_CONFIGURATION\\\" \\\"SW_TELEMETRY\\\"\"; exit 1; }\n \n-    #generate core\n-    cat <<EOT >> ${var_application_file}\n-core:\n-  default:\n-    # Mixed: Receive agent data, Level 1 aggregate, Level 2 aggregate\n-    # Receiver: Receive agent data, Level 1 aggregate\n-    # Aggregator: Level 2 aggregate\n-    role: \\${SW_CORE_ROLE:Mixed} # Mixed/Receiver/Aggregator\n-    restHost: \\${SW_CORE_REST_HOST:0.0.0.0}\n-    restPort: \\${SW_CORE_REST_PORT:12800}\n-    restContextPath: \\${SW_CORE_REST_CONTEXT_PATH:/}\n-    gRPCHost: \\${SW_CORE_GRPC_HOST:0.0.0.0}\n-    gRPCPort: \\${SW_CORE_GRPC_PORT:11800}\n-    gRPCSslEnabled: \\${SW_CORE_GRPC_SSL_ENABLED:false}\n-    gRPCSslKeyPath: \\${SW_CORE_GRPC_SSL_KEY_PATH:\"\"}\n-    gRPCSslCertChainPath: \\${SW_CORE_GRPC_SSL_CERT_CHAIN_PATH:\"\"}\n-    gRPCSslTrustedCAPath: \\${SW_CORE_GRPC_SSL_TRUSTED_CA_PATH:\"\"}\n-    downsampling:\n-    - Hour\n-    - Day\n-    - Month\n-    # Set a timeout on metrics data. After the timeout has expired, the metrics data will automatically be deleted.\n-    enableDataKeeperExecutor: \\${SW_CORE_ENABLE_DATA_KEEPER_EXECUTOR:true} # Turn it off then automatically metrics data delete will be close.\n-    dataKeeperExecutePeriod: \\${SW_CORE_DATA_KEEPER_EXECUTE_PERIOD:5} # How often the data keeper executor runs periodically, unit is minute\n-    recordDataTTL: \\${SW_CORE_RECORD_DATA_TTL:90} # Unit is minute\n-    minuteMetricsDataTTL: \\${SW_CORE_MINUTE_METRIC_DATA_TTL:90} # Unit is minute\n-    hourMetricsDataTTL: \\${SW_CORE_HOUR_METRIC_DATA_TTL:36} # Unit is hour\n-    dayMetricsDataTTL: \\${SW_CORE_DAY_METRIC_DATA_TTL:45} # Unit is day\n-    monthMetricsDataTTL: \\${SW_CORE_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-    # Cache metric data for 1 minute to reduce database queries, and if the OAP cluster changes within that minute,\n-    # the metrics may not be accurate within that minute.\n-    enableDatabaseSession: \\${SW_CORE_ENABLE_DATABASE_SESSION:true}\n-    topNReportPeriod: \\${SW_CORE_TOPN_REPORT_PERIOD:10}\n-EOT\n+validateVariables \"SW_CLUSTER\" \"$SW_CLUSTER\" \"standalone zookeeper kubernetes consul etcd nacos\"\n \n-    # generate storage\n-    case ${SW_STORAGE} in\n-    elasticsearch) generateStorageElastisearch;;\n-    h2) generateStorageH2;;\n-    mysql) generateStorageMySQL;;\n-    influxdb) generateStorageInfluxDB;;\n-    esac\n+validateVariables \"SW_STORAGE\" \"$SW_STORAGE\" \"elasticsearch h2 mysql influxdb\"\n \n-    cat <<EOT >> ${var_application_file}\n-receiver-sharing-server:\n-  default:\n-   restHost: \\${SW_RECEIVER_SHARING_REST_HOST:0.0.0.0}\n-   restPort: \\${SW_RECEIVER_SHARING_REST_PORT:0}\n-   restContextPath: \\${SW_RECEIVER_SHARING_REST_CONTEXT_PATH:/}\n-   gRPCHost: \\${SW_RECEIVER_SHARING_GRPC_HOST:0.0.0.0}\n-   gRPCPort: \\${SW_RECEIVER_SHARING_GRPC_PORT:0}\n-   maxConcurrentCallsPerConnection: \\${SW_RECEIVER_SHARING_MAX_CONCURRENT_CALL:0}\n-   maxMessageSize: \\${SW_RECEIVER_SHARING_MAX_MESSAGE_SIZE:0}\n-   gRPCThreadPoolSize: \\${SW_RECEIVER_SHARING_GRPC_THREAD_POOL_SIZE:0}\n-   gRPCThreadPoolQueueSize: \\${SW_RECEIVER_SHARING_GRPC_THREAD_POOL_QUEUE_SIZE:0}\n-   authentication: \\${SW_AUTHENTICATION:\"\"}\n-   gRPCSslEnabled: \\${SW_RECEIVER_SHARING_GRPC_SSL_ENABLED:false}\n-   gRPCSslKeyPath: \\${SW_RECEIVER_SHARING_GRPC_SSL_KEY_PATH:\"\"}\n-   gRPCSslCertChainPath: \\${SW_RECEIVER_SHARING_GRPC_SSL_CERT_CHAIN_PATH:\"\"}\n-receiver-register:\n-  default:\n-receiver-trace:\n-  default:\n-    bufferPath: \\${SW_RECEIVER_BUFFER_PATH:../trace-buffer/}  # Path to trace buffer files, suggest to use absolute path\n-    bufferOffsetMaxFileSize: \\${SW_RECEIVER_BUFFER_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n-    bufferDataMaxFileSize: \\${SW_RECEIVER_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n-    bufferFileCleanWhenRestart: \\${SW_RECEIVER_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n-    sampleRate: \\${SW_TRACE_SAMPLE_RATE:10000} # The sample rate precision is 1/10000. 10000 means 100% sample in default.\n-    slowDBAccessThreshold: \\${SW_SLOW_DB_THRESHOLD:default:200,mongodb:100} # The slow database access thresholds. Unit ms.\n-receiver-jvm:\n-  default:\n-receiver-clr:\n-  default:\n-service-mesh:\n-  default:\n-    bufferPath: \\${SW_SERVICE_MESH_BUFFER_PATH:../mesh-buffer/}  # Path to trace buffer files, suggest to use absolute path\n-    bufferOffsetMaxFileSize: \\${SW_SERVICE_MESH_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n-    bufferDataMaxFileSize: \\${SW_SERVICE_MESH_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n-    bufferFileCleanWhenRestart: \\${SW_SERVICE_MESH_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n-istio-telemetry:\n-  default:\n-query:\n-  graphql:\n-    path: \\${SW_QUERY_GRAPHQL_PATH:/graphql}\n-alarm:\n-  default:\n-EOT\n-    # generate telemetry\n-    case ${SW_TELEMETRY} in\n-    none) generateTelemetryNone;;\n-    prometheus) generateTelemetryPrometheus;;\n-    so11y) generateTelemetrySo11y;;\n-    esac\n+validateVariables \"SW_CONFIGURATION\" \"$SW_CONFIGURATION\" \"none apollo nacos zookeeper\"\n \n-    # generate configuration\n-    case ${SW_CONFIGURATION} in\n-    none) generateConfigurationNone;;\n-    apollo) generateConfigurationApollo;;\n-    nacos) generateConfigurationNacos;;\n-    zookeeper) generateConfigurationZookeeper;;\n-    consul) generateConfigurationConsul;;\n-    grpc) generateConfigurationGRPC;;\n-    esac\n+validateVariables \"SW_TELEMETRY\" \"$SW_TELEMETRY\" \"none prometheus so11y\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 408}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMzY4MjA4OnYy", "diffSide": "RIGHT", "path": "docker/oap-es7/docker-entrypoint.sh", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwNTozNjowN1rOF2dCxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwNTozNjowN1rOF2dCxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY0MzI2OA==", "bodyText": "I suggest removing these codes. I should provide some \"backwards\" compbility, just like \"SW_STORAGE\", but keeping it only add complex and confusing variables convertion.", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392643268", "createdAt": "2020-03-15T05:36:07Z", "author": {"login": "hanahmily"}, "path": "docker/oap-es7/docker-entrypoint.sh", "diffHunk": "@@ -294,202 +33,51 @@ validateVariables() {\n     fi\n }\n \n-generateApplicationYaml() {\n-    # validate\n-    [[ -z \"$SW_CLUSTER\" ]] && [[ -z \"$SW_STORAGE\" ]] && [[ -z \"$SW_CONFIGURATION\" ]] \\\n-        && [[ -z \"$SW_TELEMETRY\" ]] \\\n-        && { echo \"Error: please specify \\\"SW_CLUSTER\\\" \\\"SW_STORAGE\\\" \\\"SW_CONFIGURATION\\\" \\\"SW_TELEMETRY\\\"\"; exit 1; }\n-\n-    validateVariables \"SW_CLUSTER\" \"$SW_CLUSTER\" \"standalone zookeeper kubernetes consul etcd nacos\"\n-\n-    validateVariables \"SW_STORAGE\" \"$SW_STORAGE\" \"elasticsearch h2 mysql influxdb\"\n-\n-    validateVariables \"SW_CONFIGURATION\" \"$SW_CONFIGURATION\" \"none apollo nacos zookeeper\"\n-\n-    validateVariables \"SW_TELEMETRY\" \"$SW_TELEMETRY\" \"none prometheus so11y\"\n+echo \"[Entrypoint] Apache SkyWalking Docker Image\"\n \n-    echo \"# Generated by 'docker-entrypoint.sh'\" > ${var_application_file}\n-    #generate cluster\n-    case ${SW_CLUSTER} in\n-    standalone) generateClusterStandalone;;\n-    zookeeper) generateClusterZookeeper;;\n-    kubernetes) generateClusterK8s;;\n-    consul) generateClusterConsul;;\n-    etcd) generateClusterEtcd;;\n-    nacos) generateClusterNacos;;\n-    esac\n+# validate\n+[[ -z \"$SW_CLUSTER\" ]] || [[ -z \"$SW_STORAGE\" ]] || [[ -z \"$SW_CONFIGURATION\" ]] \\\n+    || [[ -z \"$SW_TELEMETRY\" ]] \\\n+    && { echo \"Error: please specify \\\"SW_CLUSTER\\\" \\\"SW_STORAGE\\\" \\\"SW_CONFIGURATION\\\" \\\"SW_TELEMETRY\\\"\"; exit 1; }\n \n-    #generate core\n-    cat <<EOT >> ${var_application_file}\n-core:\n-  default:\n-    # Mixed: Receive agent data, Level 1 aggregate, Level 2 aggregate\n-    # Receiver: Receive agent data, Level 1 aggregate\n-    # Aggregator: Level 2 aggregate\n-    role: \\${SW_CORE_ROLE:Mixed} # Mixed/Receiver/Aggregator\n-    restHost: \\${SW_CORE_REST_HOST:0.0.0.0}\n-    restPort: \\${SW_CORE_REST_PORT:12800}\n-    restContextPath: \\${SW_CORE_REST_CONTEXT_PATH:/}\n-    gRPCHost: \\${SW_CORE_GRPC_HOST:0.0.0.0}\n-    gRPCPort: \\${SW_CORE_GRPC_PORT:11800}\n-    gRPCSslEnabled: \\${SW_CORE_GRPC_SSL_ENABLED:false}\n-    gRPCSslKeyPath: \\${SW_CORE_GRPC_SSL_KEY_PATH:\"\"}\n-    gRPCSslCertChainPath: \\${SW_CORE_GRPC_SSL_CERT_CHAIN_PATH:\"\"}\n-    gRPCSslTrustedCAPath: \\${SW_CORE_GRPC_SSL_TRUSTED_CA_PATH:\"\"}\n-    downsampling:\n-    - Hour\n-    - Day\n-    - Month\n-    # Set a timeout on metrics data. After the timeout has expired, the metrics data will automatically be deleted.\n-    enableDataKeeperExecutor: \\${SW_CORE_ENABLE_DATA_KEEPER_EXECUTOR:true} # Turn it off then automatically metrics data delete will be close.\n-    dataKeeperExecutePeriod: \\${SW_CORE_DATA_KEEPER_EXECUTE_PERIOD:5} # How often the data keeper executor runs periodically, unit is minute\n-    recordDataTTL: \\${SW_CORE_RECORD_DATA_TTL:90} # Unit is minute\n-    minuteMetricsDataTTL: \\${SW_CORE_MINUTE_METRIC_DATA_TTL:90} # Unit is minute\n-    hourMetricsDataTTL: \\${SW_CORE_HOUR_METRIC_DATA_TTL:36} # Unit is hour\n-    dayMetricsDataTTL: \\${SW_CORE_DAY_METRIC_DATA_TTL:45} # Unit is day\n-    monthMetricsDataTTL: \\${SW_CORE_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-    # Cache metric data for 1 minute to reduce database queries, and if the OAP cluster changes within that minute,\n-    # the metrics may not be accurate within that minute.\n-    enableDatabaseSession: \\${SW_CORE_ENABLE_DATABASE_SESSION:true}\n-    topNReportPeriod: \\${SW_CORE_TOPN_REPORT_PERIOD:10}\n-EOT\n+validateVariables \"SW_CLUSTER\" \"$SW_CLUSTER\" \"standalone zookeeper kubernetes consul etcd nacos\"\n \n-    # generate storage\n-    case ${SW_STORAGE} in\n-    elasticsearch) generateStorageElastisearch;;\n-    h2) generateStorageH2;;\n-    mysql) generateStorageMySQL;;\n-    influxdb) generateStorageInfluxDB;;\n-    esac\n+validateVariables \"SW_STORAGE\" \"$SW_STORAGE\" \"elasticsearch h2 mysql influxdb\"\n \n-    cat <<EOT >> ${var_application_file}\n-receiver-sharing-server:\n-  default:\n-   restHost: \\${SW_RECEIVER_SHARING_REST_HOST:0.0.0.0}\n-   restPort: \\${SW_RECEIVER_SHARING_REST_PORT:0}\n-   restContextPath: \\${SW_RECEIVER_SHARING_REST_CONTEXT_PATH:/}\n-   gRPCHost: \\${SW_RECEIVER_SHARING_GRPC_HOST:0.0.0.0}\n-   gRPCPort: \\${SW_RECEIVER_SHARING_GRPC_PORT:0}\n-   maxConcurrentCallsPerConnection: \\${SW_RECEIVER_SHARING_MAX_CONCURRENT_CALL:0}\n-   maxMessageSize: \\${SW_RECEIVER_SHARING_MAX_MESSAGE_SIZE:0}\n-   gRPCThreadPoolSize: \\${SW_RECEIVER_SHARING_GRPC_THREAD_POOL_SIZE:0}\n-   gRPCThreadPoolQueueSize: \\${SW_RECEIVER_SHARING_GRPC_THREAD_POOL_QUEUE_SIZE:0}\n-   authentication: \\${SW_AUTHENTICATION:\"\"}\n-   gRPCSslEnabled: \\${SW_RECEIVER_SHARING_GRPC_SSL_ENABLED:false}\n-   gRPCSslKeyPath: \\${SW_RECEIVER_SHARING_GRPC_SSL_KEY_PATH:\"\"}\n-   gRPCSslCertChainPath: \\${SW_RECEIVER_SHARING_GRPC_SSL_CERT_CHAIN_PATH:\"\"}\n-receiver-register:\n-  default:\n-receiver-trace:\n-  default:\n-    bufferPath: \\${SW_RECEIVER_BUFFER_PATH:../trace-buffer/}  # Path to trace buffer files, suggest to use absolute path\n-    bufferOffsetMaxFileSize: \\${SW_RECEIVER_BUFFER_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n-    bufferDataMaxFileSize: \\${SW_RECEIVER_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n-    bufferFileCleanWhenRestart: \\${SW_RECEIVER_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n-    sampleRate: \\${SW_TRACE_SAMPLE_RATE:10000} # The sample rate precision is 1/10000. 10000 means 100% sample in default.\n-    slowDBAccessThreshold: \\${SW_SLOW_DB_THRESHOLD:default:200,mongodb:100} # The slow database access thresholds. Unit ms.\n-receiver-jvm:\n-  default:\n-receiver-clr:\n-  default:\n-service-mesh:\n-  default:\n-    bufferPath: \\${SW_SERVICE_MESH_BUFFER_PATH:../mesh-buffer/}  # Path to trace buffer files, suggest to use absolute path\n-    bufferOffsetMaxFileSize: \\${SW_SERVICE_MESH_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n-    bufferDataMaxFileSize: \\${SW_SERVICE_MESH_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n-    bufferFileCleanWhenRestart: \\${SW_SERVICE_MESH_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n-istio-telemetry:\n-  default:\n-query:\n-  graphql:\n-    path: \\${SW_QUERY_GRAPHQL_PATH:/graphql}\n-alarm:\n-  default:\n-EOT\n-    # generate telemetry\n-    case ${SW_TELEMETRY} in\n-    none) generateTelemetryNone;;\n-    prometheus) generateTelemetryPrometheus;;\n-    so11y) generateTelemetrySo11y;;\n-    esac\n+validateVariables \"SW_CONFIGURATION\" \"$SW_CONFIGURATION\" \"none apollo nacos zookeeper\"\n \n-    # generate configuration\n-    case ${SW_CONFIGURATION} in\n-    none) generateConfigurationNone;;\n-    apollo) generateConfigurationApollo;;\n-    nacos) generateConfigurationNacos;;\n-    zookeeper) generateConfigurationZookeeper;;\n-    consul) generateConfigurationConsul;;\n-    grpc) generateConfigurationGRPC;;\n-    esac\n+validateVariables \"SW_TELEMETRY\" \"$SW_TELEMETRY\" \"none prometheus so11y\"\n \n-    cat <<EOT >> ${var_application_file}\n-envoy-metric:\n-  default:\n-EOT\n-    if [[ \"$SW_ENVOY_ALS_ENABLED\" = \"true\" ]]; then\n-        cat <<EOT >> ${var_application_file}\n-    alsHTTPAnalysis: \\${SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS:k8s-mesh}\n-EOT\n-    fi\n-\n-    if [[ \"$SW_RECEIVER_ZIPKIN_ENABLED\" = \"true\" ]]; then\n-        cat <<EOT >> ${var_application_file}\n-receiver_zipkin:\n-  default:\n-    host: \\${SW_RECEIVER_ZIPKIN_HOST:0.0.0.0}\n-    port: \\${SW_RECEIVER_ZIPKIN_PORT:9411}\n-    contextPath: \\${SW_RECEIVER_ZIPKIN_CONTEXT_PATH:/}\n-EOT\n-    fi\n+if [[ \"$SW_ENVOY_ALS_ENABLED\" = \"true\" ]]; then\n+    export SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS=k8s-mesh\n+    echo \"Set SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS to ${SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS}\"\n+fi", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 432}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMzY4MjUzOnYy", "diffSide": "RIGHT", "path": "docker/oap-es7/docker-entrypoint.sh", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwNTozNzowMVrOF2dC9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwNTozNzowMVrOF2dC9Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY0MzMxNw==", "bodyText": "same as above.", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392643317", "createdAt": "2020-03-15T05:37:01Z", "author": {"login": "hanahmily"}, "path": "docker/oap-es7/docker-entrypoint.sh", "diffHunk": "@@ -294,202 +33,51 @@ validateVariables() {\n     fi\n }\n \n-generateApplicationYaml() {\n-    # validate\n-    [[ -z \"$SW_CLUSTER\" ]] && [[ -z \"$SW_STORAGE\" ]] && [[ -z \"$SW_CONFIGURATION\" ]] \\\n-        && [[ -z \"$SW_TELEMETRY\" ]] \\\n-        && { echo \"Error: please specify \\\"SW_CLUSTER\\\" \\\"SW_STORAGE\\\" \\\"SW_CONFIGURATION\\\" \\\"SW_TELEMETRY\\\"\"; exit 1; }\n-\n-    validateVariables \"SW_CLUSTER\" \"$SW_CLUSTER\" \"standalone zookeeper kubernetes consul etcd nacos\"\n-\n-    validateVariables \"SW_STORAGE\" \"$SW_STORAGE\" \"elasticsearch h2 mysql influxdb\"\n-\n-    validateVariables \"SW_CONFIGURATION\" \"$SW_CONFIGURATION\" \"none apollo nacos zookeeper\"\n-\n-    validateVariables \"SW_TELEMETRY\" \"$SW_TELEMETRY\" \"none prometheus so11y\"\n+echo \"[Entrypoint] Apache SkyWalking Docker Image\"\n \n-    echo \"# Generated by 'docker-entrypoint.sh'\" > ${var_application_file}\n-    #generate cluster\n-    case ${SW_CLUSTER} in\n-    standalone) generateClusterStandalone;;\n-    zookeeper) generateClusterZookeeper;;\n-    kubernetes) generateClusterK8s;;\n-    consul) generateClusterConsul;;\n-    etcd) generateClusterEtcd;;\n-    nacos) generateClusterNacos;;\n-    esac\n+# validate\n+[[ -z \"$SW_CLUSTER\" ]] || [[ -z \"$SW_STORAGE\" ]] || [[ -z \"$SW_CONFIGURATION\" ]] \\\n+    || [[ -z \"$SW_TELEMETRY\" ]] \\\n+    && { echo \"Error: please specify \\\"SW_CLUSTER\\\" \\\"SW_STORAGE\\\" \\\"SW_CONFIGURATION\\\" \\\"SW_TELEMETRY\\\"\"; exit 1; }\n \n-    #generate core\n-    cat <<EOT >> ${var_application_file}\n-core:\n-  default:\n-    # Mixed: Receive agent data, Level 1 aggregate, Level 2 aggregate\n-    # Receiver: Receive agent data, Level 1 aggregate\n-    # Aggregator: Level 2 aggregate\n-    role: \\${SW_CORE_ROLE:Mixed} # Mixed/Receiver/Aggregator\n-    restHost: \\${SW_CORE_REST_HOST:0.0.0.0}\n-    restPort: \\${SW_CORE_REST_PORT:12800}\n-    restContextPath: \\${SW_CORE_REST_CONTEXT_PATH:/}\n-    gRPCHost: \\${SW_CORE_GRPC_HOST:0.0.0.0}\n-    gRPCPort: \\${SW_CORE_GRPC_PORT:11800}\n-    gRPCSslEnabled: \\${SW_CORE_GRPC_SSL_ENABLED:false}\n-    gRPCSslKeyPath: \\${SW_CORE_GRPC_SSL_KEY_PATH:\"\"}\n-    gRPCSslCertChainPath: \\${SW_CORE_GRPC_SSL_CERT_CHAIN_PATH:\"\"}\n-    gRPCSslTrustedCAPath: \\${SW_CORE_GRPC_SSL_TRUSTED_CA_PATH:\"\"}\n-    downsampling:\n-    - Hour\n-    - Day\n-    - Month\n-    # Set a timeout on metrics data. After the timeout has expired, the metrics data will automatically be deleted.\n-    enableDataKeeperExecutor: \\${SW_CORE_ENABLE_DATA_KEEPER_EXECUTOR:true} # Turn it off then automatically metrics data delete will be close.\n-    dataKeeperExecutePeriod: \\${SW_CORE_DATA_KEEPER_EXECUTE_PERIOD:5} # How often the data keeper executor runs periodically, unit is minute\n-    recordDataTTL: \\${SW_CORE_RECORD_DATA_TTL:90} # Unit is minute\n-    minuteMetricsDataTTL: \\${SW_CORE_MINUTE_METRIC_DATA_TTL:90} # Unit is minute\n-    hourMetricsDataTTL: \\${SW_CORE_HOUR_METRIC_DATA_TTL:36} # Unit is hour\n-    dayMetricsDataTTL: \\${SW_CORE_DAY_METRIC_DATA_TTL:45} # Unit is day\n-    monthMetricsDataTTL: \\${SW_CORE_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-    # Cache metric data for 1 minute to reduce database queries, and if the OAP cluster changes within that minute,\n-    # the metrics may not be accurate within that minute.\n-    enableDatabaseSession: \\${SW_CORE_ENABLE_DATABASE_SESSION:true}\n-    topNReportPeriod: \\${SW_CORE_TOPN_REPORT_PERIOD:10}\n-EOT\n+validateVariables \"SW_CLUSTER\" \"$SW_CLUSTER\" \"standalone zookeeper kubernetes consul etcd nacos\"\n \n-    # generate storage\n-    case ${SW_STORAGE} in\n-    elasticsearch) generateStorageElastisearch;;\n-    h2) generateStorageH2;;\n-    mysql) generateStorageMySQL;;\n-    influxdb) generateStorageInfluxDB;;\n-    esac\n+validateVariables \"SW_STORAGE\" \"$SW_STORAGE\" \"elasticsearch h2 mysql influxdb\"\n \n-    cat <<EOT >> ${var_application_file}\n-receiver-sharing-server:\n-  default:\n-   restHost: \\${SW_RECEIVER_SHARING_REST_HOST:0.0.0.0}\n-   restPort: \\${SW_RECEIVER_SHARING_REST_PORT:0}\n-   restContextPath: \\${SW_RECEIVER_SHARING_REST_CONTEXT_PATH:/}\n-   gRPCHost: \\${SW_RECEIVER_SHARING_GRPC_HOST:0.0.0.0}\n-   gRPCPort: \\${SW_RECEIVER_SHARING_GRPC_PORT:0}\n-   maxConcurrentCallsPerConnection: \\${SW_RECEIVER_SHARING_MAX_CONCURRENT_CALL:0}\n-   maxMessageSize: \\${SW_RECEIVER_SHARING_MAX_MESSAGE_SIZE:0}\n-   gRPCThreadPoolSize: \\${SW_RECEIVER_SHARING_GRPC_THREAD_POOL_SIZE:0}\n-   gRPCThreadPoolQueueSize: \\${SW_RECEIVER_SHARING_GRPC_THREAD_POOL_QUEUE_SIZE:0}\n-   authentication: \\${SW_AUTHENTICATION:\"\"}\n-   gRPCSslEnabled: \\${SW_RECEIVER_SHARING_GRPC_SSL_ENABLED:false}\n-   gRPCSslKeyPath: \\${SW_RECEIVER_SHARING_GRPC_SSL_KEY_PATH:\"\"}\n-   gRPCSslCertChainPath: \\${SW_RECEIVER_SHARING_GRPC_SSL_CERT_CHAIN_PATH:\"\"}\n-receiver-register:\n-  default:\n-receiver-trace:\n-  default:\n-    bufferPath: \\${SW_RECEIVER_BUFFER_PATH:../trace-buffer/}  # Path to trace buffer files, suggest to use absolute path\n-    bufferOffsetMaxFileSize: \\${SW_RECEIVER_BUFFER_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n-    bufferDataMaxFileSize: \\${SW_RECEIVER_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n-    bufferFileCleanWhenRestart: \\${SW_RECEIVER_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n-    sampleRate: \\${SW_TRACE_SAMPLE_RATE:10000} # The sample rate precision is 1/10000. 10000 means 100% sample in default.\n-    slowDBAccessThreshold: \\${SW_SLOW_DB_THRESHOLD:default:200,mongodb:100} # The slow database access thresholds. Unit ms.\n-receiver-jvm:\n-  default:\n-receiver-clr:\n-  default:\n-service-mesh:\n-  default:\n-    bufferPath: \\${SW_SERVICE_MESH_BUFFER_PATH:../mesh-buffer/}  # Path to trace buffer files, suggest to use absolute path\n-    bufferOffsetMaxFileSize: \\${SW_SERVICE_MESH_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n-    bufferDataMaxFileSize: \\${SW_SERVICE_MESH_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n-    bufferFileCleanWhenRestart: \\${SW_SERVICE_MESH_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n-istio-telemetry:\n-  default:\n-query:\n-  graphql:\n-    path: \\${SW_QUERY_GRAPHQL_PATH:/graphql}\n-alarm:\n-  default:\n-EOT\n-    # generate telemetry\n-    case ${SW_TELEMETRY} in\n-    none) generateTelemetryNone;;\n-    prometheus) generateTelemetryPrometheus;;\n-    so11y) generateTelemetrySo11y;;\n-    esac\n+validateVariables \"SW_CONFIGURATION\" \"$SW_CONFIGURATION\" \"none apollo nacos zookeeper\"\n \n-    # generate configuration\n-    case ${SW_CONFIGURATION} in\n-    none) generateConfigurationNone;;\n-    apollo) generateConfigurationApollo;;\n-    nacos) generateConfigurationNacos;;\n-    zookeeper) generateConfigurationZookeeper;;\n-    consul) generateConfigurationConsul;;\n-    grpc) generateConfigurationGRPC;;\n-    esac\n+validateVariables \"SW_TELEMETRY\" \"$SW_TELEMETRY\" \"none prometheus so11y\"\n \n-    cat <<EOT >> ${var_application_file}\n-envoy-metric:\n-  default:\n-EOT\n-    if [[ \"$SW_ENVOY_ALS_ENABLED\" = \"true\" ]]; then\n-        cat <<EOT >> ${var_application_file}\n-    alsHTTPAnalysis: \\${SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS:k8s-mesh}\n-EOT\n-    fi\n-\n-    if [[ \"$SW_RECEIVER_ZIPKIN_ENABLED\" = \"true\" ]]; then\n-        cat <<EOT >> ${var_application_file}\n-receiver_zipkin:\n-  default:\n-    host: \\${SW_RECEIVER_ZIPKIN_HOST:0.0.0.0}\n-    port: \\${SW_RECEIVER_ZIPKIN_PORT:9411}\n-    contextPath: \\${SW_RECEIVER_ZIPKIN_CONTEXT_PATH:/}\n-EOT\n-    fi\n+if [[ \"$SW_ENVOY_ALS_ENABLED\" = \"true\" ]]; then\n+    export SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS=k8s-mesh\n+    echo \"Set SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS to ${SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS}\"\n+fi\n \n-    if [[ \"$SW_RECEIVER_JAEGER_ENABLED\" = \"true\" ]]; then\n-        cat <<EOT >> ${var_application_file}\n-receiver_jaeger:\n-  default:\n-    gRPCHost: \\${SW_RECEIVER_JAEGER_HOST:0.0.0.0}\n-    gRPCPort: \\${SW_RECEIVER_JAEGER_PORT:14250}\n-EOT\n-    fi\n+if [[ \"$SW_RECEIVER_ZIPKIN_ENABLED\" = \"true\" ]]; then\n+    export SW_RECEIVER_ZIPKIN=default\n+    echo \"Set SW_RECEIVER_ZIPKIN to ${SW_RECEIVER_ZIPKIN}\"\n+fi", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 445}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMzY4MjU5OnYy", "diffSide": "RIGHT", "path": "docker/oap-es7/docker-entrypoint.sh", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwNTozNzoxNlrOF2dC_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwNTo0NTozMlrOF2dEQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY0MzMyNA==", "bodyText": "same", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392643324", "createdAt": "2020-03-15T05:37:16Z", "author": {"login": "hanahmily"}, "path": "docker/oap-es7/docker-entrypoint.sh", "diffHunk": "@@ -294,202 +33,51 @@ validateVariables() {\n     fi\n }\n \n-generateApplicationYaml() {\n-    # validate\n-    [[ -z \"$SW_CLUSTER\" ]] && [[ -z \"$SW_STORAGE\" ]] && [[ -z \"$SW_CONFIGURATION\" ]] \\\n-        && [[ -z \"$SW_TELEMETRY\" ]] \\\n-        && { echo \"Error: please specify \\\"SW_CLUSTER\\\" \\\"SW_STORAGE\\\" \\\"SW_CONFIGURATION\\\" \\\"SW_TELEMETRY\\\"\"; exit 1; }\n-\n-    validateVariables \"SW_CLUSTER\" \"$SW_CLUSTER\" \"standalone zookeeper kubernetes consul etcd nacos\"\n-\n-    validateVariables \"SW_STORAGE\" \"$SW_STORAGE\" \"elasticsearch h2 mysql influxdb\"\n-\n-    validateVariables \"SW_CONFIGURATION\" \"$SW_CONFIGURATION\" \"none apollo nacos zookeeper\"\n-\n-    validateVariables \"SW_TELEMETRY\" \"$SW_TELEMETRY\" \"none prometheus so11y\"\n+echo \"[Entrypoint] Apache SkyWalking Docker Image\"\n \n-    echo \"# Generated by 'docker-entrypoint.sh'\" > ${var_application_file}\n-    #generate cluster\n-    case ${SW_CLUSTER} in\n-    standalone) generateClusterStandalone;;\n-    zookeeper) generateClusterZookeeper;;\n-    kubernetes) generateClusterK8s;;\n-    consul) generateClusterConsul;;\n-    etcd) generateClusterEtcd;;\n-    nacos) generateClusterNacos;;\n-    esac\n+# validate\n+[[ -z \"$SW_CLUSTER\" ]] || [[ -z \"$SW_STORAGE\" ]] || [[ -z \"$SW_CONFIGURATION\" ]] \\\n+    || [[ -z \"$SW_TELEMETRY\" ]] \\\n+    && { echo \"Error: please specify \\\"SW_CLUSTER\\\" \\\"SW_STORAGE\\\" \\\"SW_CONFIGURATION\\\" \\\"SW_TELEMETRY\\\"\"; exit 1; }\n \n-    #generate core\n-    cat <<EOT >> ${var_application_file}\n-core:\n-  default:\n-    # Mixed: Receive agent data, Level 1 aggregate, Level 2 aggregate\n-    # Receiver: Receive agent data, Level 1 aggregate\n-    # Aggregator: Level 2 aggregate\n-    role: \\${SW_CORE_ROLE:Mixed} # Mixed/Receiver/Aggregator\n-    restHost: \\${SW_CORE_REST_HOST:0.0.0.0}\n-    restPort: \\${SW_CORE_REST_PORT:12800}\n-    restContextPath: \\${SW_CORE_REST_CONTEXT_PATH:/}\n-    gRPCHost: \\${SW_CORE_GRPC_HOST:0.0.0.0}\n-    gRPCPort: \\${SW_CORE_GRPC_PORT:11800}\n-    gRPCSslEnabled: \\${SW_CORE_GRPC_SSL_ENABLED:false}\n-    gRPCSslKeyPath: \\${SW_CORE_GRPC_SSL_KEY_PATH:\"\"}\n-    gRPCSslCertChainPath: \\${SW_CORE_GRPC_SSL_CERT_CHAIN_PATH:\"\"}\n-    gRPCSslTrustedCAPath: \\${SW_CORE_GRPC_SSL_TRUSTED_CA_PATH:\"\"}\n-    downsampling:\n-    - Hour\n-    - Day\n-    - Month\n-    # Set a timeout on metrics data. After the timeout has expired, the metrics data will automatically be deleted.\n-    enableDataKeeperExecutor: \\${SW_CORE_ENABLE_DATA_KEEPER_EXECUTOR:true} # Turn it off then automatically metrics data delete will be close.\n-    dataKeeperExecutePeriod: \\${SW_CORE_DATA_KEEPER_EXECUTE_PERIOD:5} # How often the data keeper executor runs periodically, unit is minute\n-    recordDataTTL: \\${SW_CORE_RECORD_DATA_TTL:90} # Unit is minute\n-    minuteMetricsDataTTL: \\${SW_CORE_MINUTE_METRIC_DATA_TTL:90} # Unit is minute\n-    hourMetricsDataTTL: \\${SW_CORE_HOUR_METRIC_DATA_TTL:36} # Unit is hour\n-    dayMetricsDataTTL: \\${SW_CORE_DAY_METRIC_DATA_TTL:45} # Unit is day\n-    monthMetricsDataTTL: \\${SW_CORE_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-    # Cache metric data for 1 minute to reduce database queries, and if the OAP cluster changes within that minute,\n-    # the metrics may not be accurate within that minute.\n-    enableDatabaseSession: \\${SW_CORE_ENABLE_DATABASE_SESSION:true}\n-    topNReportPeriod: \\${SW_CORE_TOPN_REPORT_PERIOD:10}\n-EOT\n+validateVariables \"SW_CLUSTER\" \"$SW_CLUSTER\" \"standalone zookeeper kubernetes consul etcd nacos\"\n \n-    # generate storage\n-    case ${SW_STORAGE} in\n-    elasticsearch) generateStorageElastisearch;;\n-    h2) generateStorageH2;;\n-    mysql) generateStorageMySQL;;\n-    influxdb) generateStorageInfluxDB;;\n-    esac\n+validateVariables \"SW_STORAGE\" \"$SW_STORAGE\" \"elasticsearch h2 mysql influxdb\"\n \n-    cat <<EOT >> ${var_application_file}\n-receiver-sharing-server:\n-  default:\n-   restHost: \\${SW_RECEIVER_SHARING_REST_HOST:0.0.0.0}\n-   restPort: \\${SW_RECEIVER_SHARING_REST_PORT:0}\n-   restContextPath: \\${SW_RECEIVER_SHARING_REST_CONTEXT_PATH:/}\n-   gRPCHost: \\${SW_RECEIVER_SHARING_GRPC_HOST:0.0.0.0}\n-   gRPCPort: \\${SW_RECEIVER_SHARING_GRPC_PORT:0}\n-   maxConcurrentCallsPerConnection: \\${SW_RECEIVER_SHARING_MAX_CONCURRENT_CALL:0}\n-   maxMessageSize: \\${SW_RECEIVER_SHARING_MAX_MESSAGE_SIZE:0}\n-   gRPCThreadPoolSize: \\${SW_RECEIVER_SHARING_GRPC_THREAD_POOL_SIZE:0}\n-   gRPCThreadPoolQueueSize: \\${SW_RECEIVER_SHARING_GRPC_THREAD_POOL_QUEUE_SIZE:0}\n-   authentication: \\${SW_AUTHENTICATION:\"\"}\n-   gRPCSslEnabled: \\${SW_RECEIVER_SHARING_GRPC_SSL_ENABLED:false}\n-   gRPCSslKeyPath: \\${SW_RECEIVER_SHARING_GRPC_SSL_KEY_PATH:\"\"}\n-   gRPCSslCertChainPath: \\${SW_RECEIVER_SHARING_GRPC_SSL_CERT_CHAIN_PATH:\"\"}\n-receiver-register:\n-  default:\n-receiver-trace:\n-  default:\n-    bufferPath: \\${SW_RECEIVER_BUFFER_PATH:../trace-buffer/}  # Path to trace buffer files, suggest to use absolute path\n-    bufferOffsetMaxFileSize: \\${SW_RECEIVER_BUFFER_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n-    bufferDataMaxFileSize: \\${SW_RECEIVER_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n-    bufferFileCleanWhenRestart: \\${SW_RECEIVER_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n-    sampleRate: \\${SW_TRACE_SAMPLE_RATE:10000} # The sample rate precision is 1/10000. 10000 means 100% sample in default.\n-    slowDBAccessThreshold: \\${SW_SLOW_DB_THRESHOLD:default:200,mongodb:100} # The slow database access thresholds. Unit ms.\n-receiver-jvm:\n-  default:\n-receiver-clr:\n-  default:\n-service-mesh:\n-  default:\n-    bufferPath: \\${SW_SERVICE_MESH_BUFFER_PATH:../mesh-buffer/}  # Path to trace buffer files, suggest to use absolute path\n-    bufferOffsetMaxFileSize: \\${SW_SERVICE_MESH_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n-    bufferDataMaxFileSize: \\${SW_SERVICE_MESH_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n-    bufferFileCleanWhenRestart: \\${SW_SERVICE_MESH_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n-istio-telemetry:\n-  default:\n-query:\n-  graphql:\n-    path: \\${SW_QUERY_GRAPHQL_PATH:/graphql}\n-alarm:\n-  default:\n-EOT\n-    # generate telemetry\n-    case ${SW_TELEMETRY} in\n-    none) generateTelemetryNone;;\n-    prometheus) generateTelemetryPrometheus;;\n-    so11y) generateTelemetrySo11y;;\n-    esac\n+validateVariables \"SW_CONFIGURATION\" \"$SW_CONFIGURATION\" \"none apollo nacos zookeeper\"\n \n-    # generate configuration\n-    case ${SW_CONFIGURATION} in\n-    none) generateConfigurationNone;;\n-    apollo) generateConfigurationApollo;;\n-    nacos) generateConfigurationNacos;;\n-    zookeeper) generateConfigurationZookeeper;;\n-    consul) generateConfigurationConsul;;\n-    grpc) generateConfigurationGRPC;;\n-    esac\n+validateVariables \"SW_TELEMETRY\" \"$SW_TELEMETRY\" \"none prometheus so11y\"\n \n-    cat <<EOT >> ${var_application_file}\n-envoy-metric:\n-  default:\n-EOT\n-    if [[ \"$SW_ENVOY_ALS_ENABLED\" = \"true\" ]]; then\n-        cat <<EOT >> ${var_application_file}\n-    alsHTTPAnalysis: \\${SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS:k8s-mesh}\n-EOT\n-    fi\n-\n-    if [[ \"$SW_RECEIVER_ZIPKIN_ENABLED\" = \"true\" ]]; then\n-        cat <<EOT >> ${var_application_file}\n-receiver_zipkin:\n-  default:\n-    host: \\${SW_RECEIVER_ZIPKIN_HOST:0.0.0.0}\n-    port: \\${SW_RECEIVER_ZIPKIN_PORT:9411}\n-    contextPath: \\${SW_RECEIVER_ZIPKIN_CONTEXT_PATH:/}\n-EOT\n-    fi\n+if [[ \"$SW_ENVOY_ALS_ENABLED\" = \"true\" ]]; then\n+    export SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS=k8s-mesh\n+    echo \"Set SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS to ${SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS}\"\n+fi\n \n-    if [[ \"$SW_RECEIVER_JAEGER_ENABLED\" = \"true\" ]]; then\n-        cat <<EOT >> ${var_application_file}\n-receiver_jaeger:\n-  default:\n-    gRPCHost: \\${SW_RECEIVER_JAEGER_HOST:0.0.0.0}\n-    gRPCPort: \\${SW_RECEIVER_JAEGER_PORT:14250}\n-EOT\n-    fi\n+if [[ \"$SW_RECEIVER_ZIPKIN_ENABLED\" = \"true\" ]]; then\n+    export SW_RECEIVER_ZIPKIN=default\n+    echo \"Set SW_RECEIVER_ZIPKIN to ${SW_RECEIVER_ZIPKIN}\"\n+fi\n \n-    if [[ \"$SW_TELEMETRY\" = \"so11y\" ]]; then\n-        cat <<EOT >> ${var_application_file}\n-receiver-so11y:\n-  default:\n-EOT\n-    fi\n+if [[ \"$SW_RECEIVER_JAEGER_ENABLED\" = \"true\" ]]; then\n+    export SW_RECEIVER_JAEGER=default\n+    echo \"Set SW_RECEIVER_JAEGER to ${SW_RECEIVER_JAEGER}\"\n+fi", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 456}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY0MzY0OQ==", "bodyText": "Receiver enable seems a little different, @hanahmily. They are separated new module, not provider. We may need another feature to resolve this for docker.", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392643649", "createdAt": "2020-03-15T05:45:32Z", "author": {"login": "wu-sheng"}, "path": "docker/oap-es7/docker-entrypoint.sh", "diffHunk": "@@ -294,202 +33,51 @@ validateVariables() {\n     fi\n }\n \n-generateApplicationYaml() {\n-    # validate\n-    [[ -z \"$SW_CLUSTER\" ]] && [[ -z \"$SW_STORAGE\" ]] && [[ -z \"$SW_CONFIGURATION\" ]] \\\n-        && [[ -z \"$SW_TELEMETRY\" ]] \\\n-        && { echo \"Error: please specify \\\"SW_CLUSTER\\\" \\\"SW_STORAGE\\\" \\\"SW_CONFIGURATION\\\" \\\"SW_TELEMETRY\\\"\"; exit 1; }\n-\n-    validateVariables \"SW_CLUSTER\" \"$SW_CLUSTER\" \"standalone zookeeper kubernetes consul etcd nacos\"\n-\n-    validateVariables \"SW_STORAGE\" \"$SW_STORAGE\" \"elasticsearch h2 mysql influxdb\"\n-\n-    validateVariables \"SW_CONFIGURATION\" \"$SW_CONFIGURATION\" \"none apollo nacos zookeeper\"\n-\n-    validateVariables \"SW_TELEMETRY\" \"$SW_TELEMETRY\" \"none prometheus so11y\"\n+echo \"[Entrypoint] Apache SkyWalking Docker Image\"\n \n-    echo \"# Generated by 'docker-entrypoint.sh'\" > ${var_application_file}\n-    #generate cluster\n-    case ${SW_CLUSTER} in\n-    standalone) generateClusterStandalone;;\n-    zookeeper) generateClusterZookeeper;;\n-    kubernetes) generateClusterK8s;;\n-    consul) generateClusterConsul;;\n-    etcd) generateClusterEtcd;;\n-    nacos) generateClusterNacos;;\n-    esac\n+# validate\n+[[ -z \"$SW_CLUSTER\" ]] || [[ -z \"$SW_STORAGE\" ]] || [[ -z \"$SW_CONFIGURATION\" ]] \\\n+    || [[ -z \"$SW_TELEMETRY\" ]] \\\n+    && { echo \"Error: please specify \\\"SW_CLUSTER\\\" \\\"SW_STORAGE\\\" \\\"SW_CONFIGURATION\\\" \\\"SW_TELEMETRY\\\"\"; exit 1; }\n \n-    #generate core\n-    cat <<EOT >> ${var_application_file}\n-core:\n-  default:\n-    # Mixed: Receive agent data, Level 1 aggregate, Level 2 aggregate\n-    # Receiver: Receive agent data, Level 1 aggregate\n-    # Aggregator: Level 2 aggregate\n-    role: \\${SW_CORE_ROLE:Mixed} # Mixed/Receiver/Aggregator\n-    restHost: \\${SW_CORE_REST_HOST:0.0.0.0}\n-    restPort: \\${SW_CORE_REST_PORT:12800}\n-    restContextPath: \\${SW_CORE_REST_CONTEXT_PATH:/}\n-    gRPCHost: \\${SW_CORE_GRPC_HOST:0.0.0.0}\n-    gRPCPort: \\${SW_CORE_GRPC_PORT:11800}\n-    gRPCSslEnabled: \\${SW_CORE_GRPC_SSL_ENABLED:false}\n-    gRPCSslKeyPath: \\${SW_CORE_GRPC_SSL_KEY_PATH:\"\"}\n-    gRPCSslCertChainPath: \\${SW_CORE_GRPC_SSL_CERT_CHAIN_PATH:\"\"}\n-    gRPCSslTrustedCAPath: \\${SW_CORE_GRPC_SSL_TRUSTED_CA_PATH:\"\"}\n-    downsampling:\n-    - Hour\n-    - Day\n-    - Month\n-    # Set a timeout on metrics data. After the timeout has expired, the metrics data will automatically be deleted.\n-    enableDataKeeperExecutor: \\${SW_CORE_ENABLE_DATA_KEEPER_EXECUTOR:true} # Turn it off then automatically metrics data delete will be close.\n-    dataKeeperExecutePeriod: \\${SW_CORE_DATA_KEEPER_EXECUTE_PERIOD:5} # How often the data keeper executor runs periodically, unit is minute\n-    recordDataTTL: \\${SW_CORE_RECORD_DATA_TTL:90} # Unit is minute\n-    minuteMetricsDataTTL: \\${SW_CORE_MINUTE_METRIC_DATA_TTL:90} # Unit is minute\n-    hourMetricsDataTTL: \\${SW_CORE_HOUR_METRIC_DATA_TTL:36} # Unit is hour\n-    dayMetricsDataTTL: \\${SW_CORE_DAY_METRIC_DATA_TTL:45} # Unit is day\n-    monthMetricsDataTTL: \\${SW_CORE_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-    # Cache metric data for 1 minute to reduce database queries, and if the OAP cluster changes within that minute,\n-    # the metrics may not be accurate within that minute.\n-    enableDatabaseSession: \\${SW_CORE_ENABLE_DATABASE_SESSION:true}\n-    topNReportPeriod: \\${SW_CORE_TOPN_REPORT_PERIOD:10}\n-EOT\n+validateVariables \"SW_CLUSTER\" \"$SW_CLUSTER\" \"standalone zookeeper kubernetes consul etcd nacos\"\n \n-    # generate storage\n-    case ${SW_STORAGE} in\n-    elasticsearch) generateStorageElastisearch;;\n-    h2) generateStorageH2;;\n-    mysql) generateStorageMySQL;;\n-    influxdb) generateStorageInfluxDB;;\n-    esac\n+validateVariables \"SW_STORAGE\" \"$SW_STORAGE\" \"elasticsearch h2 mysql influxdb\"\n \n-    cat <<EOT >> ${var_application_file}\n-receiver-sharing-server:\n-  default:\n-   restHost: \\${SW_RECEIVER_SHARING_REST_HOST:0.0.0.0}\n-   restPort: \\${SW_RECEIVER_SHARING_REST_PORT:0}\n-   restContextPath: \\${SW_RECEIVER_SHARING_REST_CONTEXT_PATH:/}\n-   gRPCHost: \\${SW_RECEIVER_SHARING_GRPC_HOST:0.0.0.0}\n-   gRPCPort: \\${SW_RECEIVER_SHARING_GRPC_PORT:0}\n-   maxConcurrentCallsPerConnection: \\${SW_RECEIVER_SHARING_MAX_CONCURRENT_CALL:0}\n-   maxMessageSize: \\${SW_RECEIVER_SHARING_MAX_MESSAGE_SIZE:0}\n-   gRPCThreadPoolSize: \\${SW_RECEIVER_SHARING_GRPC_THREAD_POOL_SIZE:0}\n-   gRPCThreadPoolQueueSize: \\${SW_RECEIVER_SHARING_GRPC_THREAD_POOL_QUEUE_SIZE:0}\n-   authentication: \\${SW_AUTHENTICATION:\"\"}\n-   gRPCSslEnabled: \\${SW_RECEIVER_SHARING_GRPC_SSL_ENABLED:false}\n-   gRPCSslKeyPath: \\${SW_RECEIVER_SHARING_GRPC_SSL_KEY_PATH:\"\"}\n-   gRPCSslCertChainPath: \\${SW_RECEIVER_SHARING_GRPC_SSL_CERT_CHAIN_PATH:\"\"}\n-receiver-register:\n-  default:\n-receiver-trace:\n-  default:\n-    bufferPath: \\${SW_RECEIVER_BUFFER_PATH:../trace-buffer/}  # Path to trace buffer files, suggest to use absolute path\n-    bufferOffsetMaxFileSize: \\${SW_RECEIVER_BUFFER_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n-    bufferDataMaxFileSize: \\${SW_RECEIVER_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n-    bufferFileCleanWhenRestart: \\${SW_RECEIVER_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n-    sampleRate: \\${SW_TRACE_SAMPLE_RATE:10000} # The sample rate precision is 1/10000. 10000 means 100% sample in default.\n-    slowDBAccessThreshold: \\${SW_SLOW_DB_THRESHOLD:default:200,mongodb:100} # The slow database access thresholds. Unit ms.\n-receiver-jvm:\n-  default:\n-receiver-clr:\n-  default:\n-service-mesh:\n-  default:\n-    bufferPath: \\${SW_SERVICE_MESH_BUFFER_PATH:../mesh-buffer/}  # Path to trace buffer files, suggest to use absolute path\n-    bufferOffsetMaxFileSize: \\${SW_SERVICE_MESH_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n-    bufferDataMaxFileSize: \\${SW_SERVICE_MESH_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n-    bufferFileCleanWhenRestart: \\${SW_SERVICE_MESH_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n-istio-telemetry:\n-  default:\n-query:\n-  graphql:\n-    path: \\${SW_QUERY_GRAPHQL_PATH:/graphql}\n-alarm:\n-  default:\n-EOT\n-    # generate telemetry\n-    case ${SW_TELEMETRY} in\n-    none) generateTelemetryNone;;\n-    prometheus) generateTelemetryPrometheus;;\n-    so11y) generateTelemetrySo11y;;\n-    esac\n+validateVariables \"SW_CONFIGURATION\" \"$SW_CONFIGURATION\" \"none apollo nacos zookeeper\"\n \n-    # generate configuration\n-    case ${SW_CONFIGURATION} in\n-    none) generateConfigurationNone;;\n-    apollo) generateConfigurationApollo;;\n-    nacos) generateConfigurationNacos;;\n-    zookeeper) generateConfigurationZookeeper;;\n-    consul) generateConfigurationConsul;;\n-    grpc) generateConfigurationGRPC;;\n-    esac\n+validateVariables \"SW_TELEMETRY\" \"$SW_TELEMETRY\" \"none prometheus so11y\"\n \n-    cat <<EOT >> ${var_application_file}\n-envoy-metric:\n-  default:\n-EOT\n-    if [[ \"$SW_ENVOY_ALS_ENABLED\" = \"true\" ]]; then\n-        cat <<EOT >> ${var_application_file}\n-    alsHTTPAnalysis: \\${SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS:k8s-mesh}\n-EOT\n-    fi\n-\n-    if [[ \"$SW_RECEIVER_ZIPKIN_ENABLED\" = \"true\" ]]; then\n-        cat <<EOT >> ${var_application_file}\n-receiver_zipkin:\n-  default:\n-    host: \\${SW_RECEIVER_ZIPKIN_HOST:0.0.0.0}\n-    port: \\${SW_RECEIVER_ZIPKIN_PORT:9411}\n-    contextPath: \\${SW_RECEIVER_ZIPKIN_CONTEXT_PATH:/}\n-EOT\n-    fi\n+if [[ \"$SW_ENVOY_ALS_ENABLED\" = \"true\" ]]; then\n+    export SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS=k8s-mesh\n+    echo \"Set SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS to ${SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS}\"\n+fi\n \n-    if [[ \"$SW_RECEIVER_JAEGER_ENABLED\" = \"true\" ]]; then\n-        cat <<EOT >> ${var_application_file}\n-receiver_jaeger:\n-  default:\n-    gRPCHost: \\${SW_RECEIVER_JAEGER_HOST:0.0.0.0}\n-    gRPCPort: \\${SW_RECEIVER_JAEGER_PORT:14250}\n-EOT\n-    fi\n+if [[ \"$SW_RECEIVER_ZIPKIN_ENABLED\" = \"true\" ]]; then\n+    export SW_RECEIVER_ZIPKIN=default\n+    echo \"Set SW_RECEIVER_ZIPKIN to ${SW_RECEIVER_ZIPKIN}\"\n+fi\n \n-    if [[ \"$SW_TELEMETRY\" = \"so11y\" ]]; then\n-        cat <<EOT >> ${var_application_file}\n-receiver-so11y:\n-  default:\n-EOT\n-    fi\n+if [[ \"$SW_RECEIVER_JAEGER_ENABLED\" = \"true\" ]]; then\n+    export SW_RECEIVER_JAEGER=default\n+    echo \"Set SW_RECEIVER_JAEGER to ${SW_RECEIVER_JAEGER}\"\n+fi", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY0MzMyNA=="}, "originalCommit": null, "originalPosition": 456}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMzY4MzI1OnYy", "diffSide": "RIGHT", "path": "docker/oap-es7/docker-entrypoint.sh", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwNTozOTowMFrOF2dDSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwNTozOTowMFrOF2dDSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY0MzQwMg==", "bodyText": "same as above, remove it.", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392643402", "createdAt": "2020-03-15T05:39:00Z", "author": {"login": "hanahmily"}, "path": "docker/oap-es7/docker-entrypoint.sh", "diffHunk": "@@ -294,202 +33,51 @@ validateVariables() {\n     fi\n }\n \n-generateApplicationYaml() {\n-    # validate\n-    [[ -z \"$SW_CLUSTER\" ]] && [[ -z \"$SW_STORAGE\" ]] && [[ -z \"$SW_CONFIGURATION\" ]] \\\n-        && [[ -z \"$SW_TELEMETRY\" ]] \\\n-        && { echo \"Error: please specify \\\"SW_CLUSTER\\\" \\\"SW_STORAGE\\\" \\\"SW_CONFIGURATION\\\" \\\"SW_TELEMETRY\\\"\"; exit 1; }\n-\n-    validateVariables \"SW_CLUSTER\" \"$SW_CLUSTER\" \"standalone zookeeper kubernetes consul etcd nacos\"\n-\n-    validateVariables \"SW_STORAGE\" \"$SW_STORAGE\" \"elasticsearch h2 mysql influxdb\"\n-\n-    validateVariables \"SW_CONFIGURATION\" \"$SW_CONFIGURATION\" \"none apollo nacos zookeeper\"\n-\n-    validateVariables \"SW_TELEMETRY\" \"$SW_TELEMETRY\" \"none prometheus so11y\"\n+echo \"[Entrypoint] Apache SkyWalking Docker Image\"\n \n-    echo \"# Generated by 'docker-entrypoint.sh'\" > ${var_application_file}\n-    #generate cluster\n-    case ${SW_CLUSTER} in\n-    standalone) generateClusterStandalone;;\n-    zookeeper) generateClusterZookeeper;;\n-    kubernetes) generateClusterK8s;;\n-    consul) generateClusterConsul;;\n-    etcd) generateClusterEtcd;;\n-    nacos) generateClusterNacos;;\n-    esac\n+# validate\n+[[ -z \"$SW_CLUSTER\" ]] || [[ -z \"$SW_STORAGE\" ]] || [[ -z \"$SW_CONFIGURATION\" ]] \\\n+    || [[ -z \"$SW_TELEMETRY\" ]] \\\n+    && { echo \"Error: please specify \\\"SW_CLUSTER\\\" \\\"SW_STORAGE\\\" \\\"SW_CONFIGURATION\\\" \\\"SW_TELEMETRY\\\"\"; exit 1; }\n \n-    #generate core\n-    cat <<EOT >> ${var_application_file}\n-core:\n-  default:\n-    # Mixed: Receive agent data, Level 1 aggregate, Level 2 aggregate\n-    # Receiver: Receive agent data, Level 1 aggregate\n-    # Aggregator: Level 2 aggregate\n-    role: \\${SW_CORE_ROLE:Mixed} # Mixed/Receiver/Aggregator\n-    restHost: \\${SW_CORE_REST_HOST:0.0.0.0}\n-    restPort: \\${SW_CORE_REST_PORT:12800}\n-    restContextPath: \\${SW_CORE_REST_CONTEXT_PATH:/}\n-    gRPCHost: \\${SW_CORE_GRPC_HOST:0.0.0.0}\n-    gRPCPort: \\${SW_CORE_GRPC_PORT:11800}\n-    gRPCSslEnabled: \\${SW_CORE_GRPC_SSL_ENABLED:false}\n-    gRPCSslKeyPath: \\${SW_CORE_GRPC_SSL_KEY_PATH:\"\"}\n-    gRPCSslCertChainPath: \\${SW_CORE_GRPC_SSL_CERT_CHAIN_PATH:\"\"}\n-    gRPCSslTrustedCAPath: \\${SW_CORE_GRPC_SSL_TRUSTED_CA_PATH:\"\"}\n-    downsampling:\n-    - Hour\n-    - Day\n-    - Month\n-    # Set a timeout on metrics data. After the timeout has expired, the metrics data will automatically be deleted.\n-    enableDataKeeperExecutor: \\${SW_CORE_ENABLE_DATA_KEEPER_EXECUTOR:true} # Turn it off then automatically metrics data delete will be close.\n-    dataKeeperExecutePeriod: \\${SW_CORE_DATA_KEEPER_EXECUTE_PERIOD:5} # How often the data keeper executor runs periodically, unit is minute\n-    recordDataTTL: \\${SW_CORE_RECORD_DATA_TTL:90} # Unit is minute\n-    minuteMetricsDataTTL: \\${SW_CORE_MINUTE_METRIC_DATA_TTL:90} # Unit is minute\n-    hourMetricsDataTTL: \\${SW_CORE_HOUR_METRIC_DATA_TTL:36} # Unit is hour\n-    dayMetricsDataTTL: \\${SW_CORE_DAY_METRIC_DATA_TTL:45} # Unit is day\n-    monthMetricsDataTTL: \\${SW_CORE_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-    # Cache metric data for 1 minute to reduce database queries, and if the OAP cluster changes within that minute,\n-    # the metrics may not be accurate within that minute.\n-    enableDatabaseSession: \\${SW_CORE_ENABLE_DATABASE_SESSION:true}\n-    topNReportPeriod: \\${SW_CORE_TOPN_REPORT_PERIOD:10}\n-EOT\n+validateVariables \"SW_CLUSTER\" \"$SW_CLUSTER\" \"standalone zookeeper kubernetes consul etcd nacos\"\n \n-    # generate storage\n-    case ${SW_STORAGE} in\n-    elasticsearch) generateStorageElastisearch;;\n-    h2) generateStorageH2;;\n-    mysql) generateStorageMySQL;;\n-    influxdb) generateStorageInfluxDB;;\n-    esac\n+validateVariables \"SW_STORAGE\" \"$SW_STORAGE\" \"elasticsearch h2 mysql influxdb\"\n \n-    cat <<EOT >> ${var_application_file}\n-receiver-sharing-server:\n-  default:\n-   restHost: \\${SW_RECEIVER_SHARING_REST_HOST:0.0.0.0}\n-   restPort: \\${SW_RECEIVER_SHARING_REST_PORT:0}\n-   restContextPath: \\${SW_RECEIVER_SHARING_REST_CONTEXT_PATH:/}\n-   gRPCHost: \\${SW_RECEIVER_SHARING_GRPC_HOST:0.0.0.0}\n-   gRPCPort: \\${SW_RECEIVER_SHARING_GRPC_PORT:0}\n-   maxConcurrentCallsPerConnection: \\${SW_RECEIVER_SHARING_MAX_CONCURRENT_CALL:0}\n-   maxMessageSize: \\${SW_RECEIVER_SHARING_MAX_MESSAGE_SIZE:0}\n-   gRPCThreadPoolSize: \\${SW_RECEIVER_SHARING_GRPC_THREAD_POOL_SIZE:0}\n-   gRPCThreadPoolQueueSize: \\${SW_RECEIVER_SHARING_GRPC_THREAD_POOL_QUEUE_SIZE:0}\n-   authentication: \\${SW_AUTHENTICATION:\"\"}\n-   gRPCSslEnabled: \\${SW_RECEIVER_SHARING_GRPC_SSL_ENABLED:false}\n-   gRPCSslKeyPath: \\${SW_RECEIVER_SHARING_GRPC_SSL_KEY_PATH:\"\"}\n-   gRPCSslCertChainPath: \\${SW_RECEIVER_SHARING_GRPC_SSL_CERT_CHAIN_PATH:\"\"}\n-receiver-register:\n-  default:\n-receiver-trace:\n-  default:\n-    bufferPath: \\${SW_RECEIVER_BUFFER_PATH:../trace-buffer/}  # Path to trace buffer files, suggest to use absolute path\n-    bufferOffsetMaxFileSize: \\${SW_RECEIVER_BUFFER_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n-    bufferDataMaxFileSize: \\${SW_RECEIVER_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n-    bufferFileCleanWhenRestart: \\${SW_RECEIVER_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n-    sampleRate: \\${SW_TRACE_SAMPLE_RATE:10000} # The sample rate precision is 1/10000. 10000 means 100% sample in default.\n-    slowDBAccessThreshold: \\${SW_SLOW_DB_THRESHOLD:default:200,mongodb:100} # The slow database access thresholds. Unit ms.\n-receiver-jvm:\n-  default:\n-receiver-clr:\n-  default:\n-service-mesh:\n-  default:\n-    bufferPath: \\${SW_SERVICE_MESH_BUFFER_PATH:../mesh-buffer/}  # Path to trace buffer files, suggest to use absolute path\n-    bufferOffsetMaxFileSize: \\${SW_SERVICE_MESH_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n-    bufferDataMaxFileSize: \\${SW_SERVICE_MESH_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n-    bufferFileCleanWhenRestart: \\${SW_SERVICE_MESH_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n-istio-telemetry:\n-  default:\n-query:\n-  graphql:\n-    path: \\${SW_QUERY_GRAPHQL_PATH:/graphql}\n-alarm:\n-  default:\n-EOT\n-    # generate telemetry\n-    case ${SW_TELEMETRY} in\n-    none) generateTelemetryNone;;\n-    prometheus) generateTelemetryPrometheus;;\n-    so11y) generateTelemetrySo11y;;\n-    esac\n+validateVariables \"SW_CONFIGURATION\" \"$SW_CONFIGURATION\" \"none apollo nacos zookeeper\"\n \n-    # generate configuration\n-    case ${SW_CONFIGURATION} in\n-    none) generateConfigurationNone;;\n-    apollo) generateConfigurationApollo;;\n-    nacos) generateConfigurationNacos;;\n-    zookeeper) generateConfigurationZookeeper;;\n-    consul) generateConfigurationConsul;;\n-    grpc) generateConfigurationGRPC;;\n-    esac\n+validateVariables \"SW_TELEMETRY\" \"$SW_TELEMETRY\" \"none prometheus so11y\"\n \n-    cat <<EOT >> ${var_application_file}\n-envoy-metric:\n-  default:\n-EOT\n-    if [[ \"$SW_ENVOY_ALS_ENABLED\" = \"true\" ]]; then\n-        cat <<EOT >> ${var_application_file}\n-    alsHTTPAnalysis: \\${SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS:k8s-mesh}\n-EOT\n-    fi\n-\n-    if [[ \"$SW_RECEIVER_ZIPKIN_ENABLED\" = \"true\" ]]; then\n-        cat <<EOT >> ${var_application_file}\n-receiver_zipkin:\n-  default:\n-    host: \\${SW_RECEIVER_ZIPKIN_HOST:0.0.0.0}\n-    port: \\${SW_RECEIVER_ZIPKIN_PORT:9411}\n-    contextPath: \\${SW_RECEIVER_ZIPKIN_CONTEXT_PATH:/}\n-EOT\n-    fi\n+if [[ \"$SW_ENVOY_ALS_ENABLED\" = \"true\" ]]; then\n+    export SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS=k8s-mesh\n+    echo \"Set SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS to ${SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS}\"\n+fi\n \n-    if [[ \"$SW_RECEIVER_JAEGER_ENABLED\" = \"true\" ]]; then\n-        cat <<EOT >> ${var_application_file}\n-receiver_jaeger:\n-  default:\n-    gRPCHost: \\${SW_RECEIVER_JAEGER_HOST:0.0.0.0}\n-    gRPCPort: \\${SW_RECEIVER_JAEGER_PORT:14250}\n-EOT\n-    fi\n+if [[ \"$SW_RECEIVER_ZIPKIN_ENABLED\" = \"true\" ]]; then\n+    export SW_RECEIVER_ZIPKIN=default\n+    echo \"Set SW_RECEIVER_ZIPKIN to ${SW_RECEIVER_ZIPKIN}\"\n+fi\n \n-    if [[ \"$SW_TELEMETRY\" = \"so11y\" ]]; then\n-        cat <<EOT >> ${var_application_file}\n-receiver-so11y:\n-  default:\n-EOT\n-    fi\n+if [[ \"$SW_RECEIVER_JAEGER_ENABLED\" = \"true\" ]]; then\n+    export SW_RECEIVER_JAEGER=default\n+    echo \"Set SW_RECEIVER_JAEGER to ${SW_RECEIVER_JAEGER}\"\n+fi\n \n-    if [[ \"$SW_EXPORTER_ENABLED\" = \"true\" ]]; then\n-        cat <<EOT >> ${var_application_file}\n-exporter:\n-  grpc:\n-    targetHost: \\${SW_EXPORTER_GRPC_HOST:127.0.0.1}\n-    targetPort: \\${SW_EXPORTER_GRPC_PORT:9870}\n-EOT\n-    fi\n-}\n+if [[ \"$SW_TELEMETRY\" = \"so11y\" ]]; then\n+    export SW_RECEIVER_SO11Y=default\n+    echo \"Set SW_RECEIVER_SO11Y to ${SW_RECEIVER_SO11Y}\"\n+fi\n \n-echo \"[Entrypoint] Apache SkyWalking Docker Image\"\n+if [[ \"$SW_EXPORTER_ENABLED\" = \"true\" ]]; then\n+    export SW_EXPORTER=grpc\n+    echo \"Set SW_EXPORTER to ${SW_EXPORTER}\"\n+fi", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 476}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMzcyNjgzOnYy", "diffSide": "RIGHT", "path": "dist-material/application.yml", "isResolved": true, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwNzozMzowOVrOF2dYtg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwOTowMDo0NFrOF2duAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY0ODg4Ng==", "bodyText": "What does this none mean? I don't think we have none provider for this receiver.\nAccording to your implementation, https://github.com/apache/skywalking/blob/dae57dc8fddba8916d43351cdde824a116e2d58c/oap-server/server-bootstrap/src/main/java/org/apache/skywalking/oap/server/starter/config/ApplicationConfigLoader.java#L62-L64,\nthis seems meaning no provider for module receiver_zipkin? If this module is required by other module, what happens?\nI don't think providing a potential NPE in the runtime is a good idea.", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392648886", "createdAt": "2020-03-15T07:33:09Z", "author": {"login": "wu-sheng"}, "path": "dist-material/application.yml", "diffHunk": "@@ -83,180 +85,230 @@ core:\n     # and it will cause more load for memory, network of OAP and storage.\n     # But, being activated, user could see the name in the storage entities, which make users easier to use 3rd party tool, such as Kibana->ES, to query the data by themselves.\n     activeExtraModelColumns: ${SW_CORE_ACTIVE_EXTRA_MODEL_COLUMNS:false}\n+\n storage:\n-#  elasticsearch:\n-#    nameSpace: ${SW_NAMESPACE:\"\"}\n-#    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n-#    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n-#    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n-#    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n-#    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n-#    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n-#    user: ${SW_ES_USER:\"\"}\n-#    password: ${SW_ES_PASSWORD:\"\"}\n-#    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n-#    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n-#    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n-#    # Those data TTL settings will override the same settings in core module.\n-#    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n-#    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n-#    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-#    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n-#    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n-#    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n-#    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n-#    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n-#    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n-#    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n-#    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n-#  elasticsearch7:\n-#    nameSpace: ${SW_NAMESPACE:\"\"}\n-#    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n-#    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n-#    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n-#    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n-#    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n-#    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n-#    user: ${SW_ES_USER:\"\"}\n-#    password: ${SW_ES_PASSWORD:\"\"}\n-#    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n-#    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n-#    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n-#    # Those data TTL settings will override the same settings in core module.\n-#    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n-#    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n-#    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-#    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n-#    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n-#    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n-#    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n-#    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n-#    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n-#    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n-#    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n+  selector: ${SW_STORAGE:h2}\n+  elasticsearch:\n+    nameSpace: ${SW_NAMESPACE:\"\"}\n+    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n+    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n+    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n+    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n+    user: ${SW_ES_USER:\"\"}\n+    password: ${SW_ES_PASSWORD:\"\"}\n+    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n+    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n+    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n+    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n+    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n+    # Those data TTL settings will override the same settings in core module.\n+    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n+    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n+    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n+    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n+    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n+    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n+    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n+    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n+    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n+    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n+    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n+    advanced: ${SW_STORAGE_ES_ADVANCED:\"\"}\n+  elasticsearch7:\n+    nameSpace: ${SW_NAMESPACE:\"\"}\n+    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n+    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n+    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n+    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n+    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n+    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n+    user: ${SW_ES_USER:\"\"}\n+    password: ${SW_ES_PASSWORD:\"\"}\n+    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n+    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n+    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n+    # Those data TTL settings will override the same settings in core module.\n+    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n+    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n+    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n+    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n+    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n+    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n+    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n+    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n+    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n+    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n+    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n+    advanced: ${SW_STORAGE_ES_ADVANCED:\"\"}\n   h2:\n     driver: ${SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource}\n     url: ${SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db}\n     user: ${SW_STORAGE_H2_USER:sa}\n     metadataQueryMaxSize: ${SW_STORAGE_H2_QUERY_MAX_SIZE:5000}\n-#  mysql:\n-#    properties:\n-#      jdbcUrl: ${SW_JDBC_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n-#      dataSource.user: ${SW_DATA_SOURCE_USER:root}\n-#      dataSource.password: ${SW_DATA_SOURCE_PASSWORD:root@1234}\n-#      dataSource.cachePrepStmts: ${SW_DATA_SOURCE_CACHE_PREP_STMTS:true}\n-#      dataSource.prepStmtCacheSize: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_SIZE:250}\n-#      dataSource.prepStmtCacheSqlLimit: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n-#      dataSource.useServerPrepStmts: ${SW_DATA_SOURCE_USE_SERVER_PREP_STMTS:true}\n-#    metadataQueryMaxSize: ${SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000}\n-#  influx:\n-#    # Metadata storage provider configuration\n-#    metabaseType: ${SW_STORAGE_METABASE_TYPE:H2} # There are 2 options as Metabase provider, H2 or MySQL.\n-#    h2Props:\n-#      dataSourceClassName: ${SW_STORAGE_METABASE_DRIVER:org.h2.jdbcx.JdbcDataSource}\n-#      dataSource.url: ${SW_STORAGE_METABASE_URL:jdbc:h2:mem:skywalking-oap-db}\n-#      dataSource.user: ${SW_STORAGE_METABASE_USER:sa}\n-#      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:}\n-#    mysqlProps:\n-#      jdbcUrl: ${SW_STORAGE_METABASE_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n-#      dataSource.user: ${SW_STORAGE_METABASE_USER:root}\n-#      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:root@1234}\n-#      dataSource.cachePrepStmts: ${SW_STORAGE_METABASE_CACHE_PREP_STMTS:true}\n-#      dataSource.prepStmtCacheSize: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_SIZE:250}\n-#      dataSource.prepStmtCacheSqlLimit: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n-#      dataSource.useServerPrepStmts: ${SW_STORAGE_METABASE_USE_SERVER_PREP_STMTS:true}\n-#    metadataQueryMaxSize: ${SW_STORAGE_METABASE_QUERY_MAX_SIZE:5000}\n-#    # InfluxDB configuration\n-#    url: ${SW_STORAGE_INFLUXDB_URL:http://localhost:8086}\n-#    user: ${SW_STORAGE_INFLUXDB_USER:root}\n-#    password: ${SW_STORAGE_INFLUXDB_PASSWORD:}\n-#    database: ${SW_STORAGE_INFLUXDB_DATABASE:skywalking}\n-#    actions: ${SW_STORAGE_INFLUXDB_ACTIONS:1000} # the number of actions to collect\n-#    duration: ${SW_STORAGE_INFLUXDB_DURATION:1000} # the time to wait at most (milliseconds)\n-#    fetchTaskLogMaxSize: ${SW_STORAGE_INFLUXDB_FETCH_TASK_LOG_MAX_SIZE:5000} # the max number of fetch task log in a request\n+  mysql:\n+    properties:\n+      jdbcUrl: ${SW_JDBC_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n+      dataSource.user: ${SW_DATA_SOURCE_USER:root}\n+      dataSource.password: ${SW_DATA_SOURCE_PASSWORD:root@1234}\n+      dataSource.cachePrepStmts: ${SW_DATA_SOURCE_CACHE_PREP_STMTS:true}\n+      dataSource.prepStmtCacheSize: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_SIZE:250}\n+      dataSource.prepStmtCacheSqlLimit: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n+      dataSource.useServerPrepStmts: ${SW_DATA_SOURCE_USE_SERVER_PREP_STMTS:true}\n+    metadataQueryMaxSize: ${SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000}\n+  influxdb:\n+    # Metadata storage provider configuration\n+    metabaseType: ${SW_STORAGE_METABASE_TYPE:H2} # There are 2 options as Metabase provider, H2 or MySQL.\n+    h2Props:\n+      dataSourceClassName: ${SW_STORAGE_METABASE_DRIVER:org.h2.jdbcx.JdbcDataSource}\n+      dataSource.url: ${SW_STORAGE_METABASE_URL:jdbc:h2:mem:skywalking-oap-db}\n+      dataSource.user: ${SW_STORAGE_METABASE_USER:sa}\n+      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:}\n+    mysqlProps:\n+      jdbcUrl: ${SW_STORAGE_METABASE_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n+      dataSource.user: ${SW_STORAGE_METABASE_USER:root}\n+      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:root@1234}\n+      dataSource.cachePrepStmts: ${SW_STORAGE_METABASE_CACHE_PREP_STMTS:true}\n+      dataSource.prepStmtCacheSize: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_SIZE:250}\n+      dataSource.prepStmtCacheSqlLimit: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n+      dataSource.useServerPrepStmts: ${SW_STORAGE_METABASE_USE_SERVER_PREP_STMTS:true}\n+    metadataQueryMaxSize: ${SW_STORAGE_METABASE_QUERY_MAX_SIZE:5000}\n+    # InfluxDB configuration\n+    url: ${SW_STORAGE_INFLUXDB_URL:http://localhost:8086}\n+    user: ${SW_STORAGE_INFLUXDB_USER:root}\n+    password: ${SW_STORAGE_INFLUXDB_PASSWORD:}\n+    database: ${SW_STORAGE_INFLUXDB_DATABASE:skywalking}\n+    actions: ${SW_STORAGE_INFLUXDB_ACTIONS:1000} # the number of actions to collect\n+    duration: ${SW_STORAGE_INFLUXDB_DURATION:1000} # the time to wait at most (milliseconds)\n+    fetchTaskLogMaxSize: ${SW_STORAGE_INFLUXDB_FETCH_TASK_LOG_MAX_SIZE:5000} # the max number of fetch task log in a request\n+\n receiver-sharing-server:\n+  selector: ${SW_RECEIVER_SHARING_SERVER:default}\n   default:\n+    authentication: ${SW_AUTHENTICATION:\"\"}\n receiver-register:\n+  selector: ${SW_RECEIVER_REGISTER:default}\n   default:\n+\n receiver-trace:\n+  selector: ${SW_RECEIVER_TRACE:default}\n   default:\n     bufferPath: ${SW_RECEIVER_BUFFER_PATH:../trace-buffer/}  # Path to trace buffer files, suggest to use absolute path\n     bufferOffsetMaxFileSize: ${SW_RECEIVER_BUFFER_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n     bufferDataMaxFileSize: ${SW_RECEIVER_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n     bufferFileCleanWhenRestart: ${SW_RECEIVER_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n     sampleRate: ${SW_TRACE_SAMPLE_RATE:10000} # The sample rate precision is 1/10000. 10000 means 100% sample in default.\n     slowDBAccessThreshold: ${SW_SLOW_DB_THRESHOLD:default:200,mongodb:100} # The slow database access thresholds. Unit ms.\n+\n receiver-jvm:\n+  selector: ${SW_RECEIVER_JVM:default}\n   default:\n+\n receiver-clr:\n+  selector: ${SW_RECEIVER_CLR:default}\n   default:\n+\n receiver-profile:\n+  selector: ${SW_RECEIVER_PROFILE:default}\n   default:\n+\n service-mesh:\n+  selector: ${SW_SERVICE_MESH:default}\n   default:\n     bufferPath: ${SW_SERVICE_MESH_BUFFER_PATH:../mesh-buffer/}  # Path to trace buffer files, suggest to use absolute path\n     bufferOffsetMaxFileSize: ${SW_SERVICE_MESH_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n     bufferDataMaxFileSize: ${SW_SERVICE_MESH_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n     bufferFileCleanWhenRestart: ${SW_SERVICE_MESH_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n+\n istio-telemetry:\n+  selector: ${SW_ISTIO_TELEMETRY:default}\n   default:\n+\n envoy-metric:\n+  selector: ${SW_ENVOY_METRIC:default}\n   default:\n-#    alsHTTPAnalysis: ${SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS:k8s-mesh}\n-#receiver_zipkin:\n-#  default:\n-#    host: ${SW_RECEIVER_ZIPKIN_HOST:0.0.0.0}\n-#    port: ${SW_RECEIVER_ZIPKIN_PORT:9411}\n-#    contextPath: ${SW_RECEIVER_ZIPKIN_CONTEXT_PATH:/}\n+    alsHTTPAnalysis: ${SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS:none}\n+\n+receiver_zipkin:\n+  selector: ${SW_RECEIVER_ZIPKIN:none}", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 312}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY0ODk4Nw==", "bodyText": "Also, based on this, I could put some tricky parameter value such as any not existing provider name. And we magically accept it and start up successfully.", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392648987", "createdAt": "2020-03-15T07:35:07Z", "author": {"login": "wu-sheng"}, "path": "dist-material/application.yml", "diffHunk": "@@ -83,180 +85,230 @@ core:\n     # and it will cause more load for memory, network of OAP and storage.\n     # But, being activated, user could see the name in the storage entities, which make users easier to use 3rd party tool, such as Kibana->ES, to query the data by themselves.\n     activeExtraModelColumns: ${SW_CORE_ACTIVE_EXTRA_MODEL_COLUMNS:false}\n+\n storage:\n-#  elasticsearch:\n-#    nameSpace: ${SW_NAMESPACE:\"\"}\n-#    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n-#    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n-#    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n-#    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n-#    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n-#    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n-#    user: ${SW_ES_USER:\"\"}\n-#    password: ${SW_ES_PASSWORD:\"\"}\n-#    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n-#    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n-#    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n-#    # Those data TTL settings will override the same settings in core module.\n-#    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n-#    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n-#    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-#    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n-#    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n-#    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n-#    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n-#    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n-#    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n-#    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n-#    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n-#  elasticsearch7:\n-#    nameSpace: ${SW_NAMESPACE:\"\"}\n-#    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n-#    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n-#    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n-#    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n-#    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n-#    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n-#    user: ${SW_ES_USER:\"\"}\n-#    password: ${SW_ES_PASSWORD:\"\"}\n-#    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n-#    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n-#    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n-#    # Those data TTL settings will override the same settings in core module.\n-#    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n-#    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n-#    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-#    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n-#    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n-#    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n-#    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n-#    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n-#    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n-#    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n-#    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n+  selector: ${SW_STORAGE:h2}\n+  elasticsearch:\n+    nameSpace: ${SW_NAMESPACE:\"\"}\n+    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n+    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n+    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n+    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n+    user: ${SW_ES_USER:\"\"}\n+    password: ${SW_ES_PASSWORD:\"\"}\n+    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n+    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n+    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n+    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n+    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n+    # Those data TTL settings will override the same settings in core module.\n+    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n+    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n+    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n+    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n+    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n+    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n+    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n+    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n+    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n+    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n+    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n+    advanced: ${SW_STORAGE_ES_ADVANCED:\"\"}\n+  elasticsearch7:\n+    nameSpace: ${SW_NAMESPACE:\"\"}\n+    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n+    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n+    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n+    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n+    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n+    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n+    user: ${SW_ES_USER:\"\"}\n+    password: ${SW_ES_PASSWORD:\"\"}\n+    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n+    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n+    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n+    # Those data TTL settings will override the same settings in core module.\n+    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n+    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n+    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n+    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n+    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n+    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n+    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n+    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n+    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n+    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n+    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n+    advanced: ${SW_STORAGE_ES_ADVANCED:\"\"}\n   h2:\n     driver: ${SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource}\n     url: ${SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db}\n     user: ${SW_STORAGE_H2_USER:sa}\n     metadataQueryMaxSize: ${SW_STORAGE_H2_QUERY_MAX_SIZE:5000}\n-#  mysql:\n-#    properties:\n-#      jdbcUrl: ${SW_JDBC_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n-#      dataSource.user: ${SW_DATA_SOURCE_USER:root}\n-#      dataSource.password: ${SW_DATA_SOURCE_PASSWORD:root@1234}\n-#      dataSource.cachePrepStmts: ${SW_DATA_SOURCE_CACHE_PREP_STMTS:true}\n-#      dataSource.prepStmtCacheSize: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_SIZE:250}\n-#      dataSource.prepStmtCacheSqlLimit: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n-#      dataSource.useServerPrepStmts: ${SW_DATA_SOURCE_USE_SERVER_PREP_STMTS:true}\n-#    metadataQueryMaxSize: ${SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000}\n-#  influx:\n-#    # Metadata storage provider configuration\n-#    metabaseType: ${SW_STORAGE_METABASE_TYPE:H2} # There are 2 options as Metabase provider, H2 or MySQL.\n-#    h2Props:\n-#      dataSourceClassName: ${SW_STORAGE_METABASE_DRIVER:org.h2.jdbcx.JdbcDataSource}\n-#      dataSource.url: ${SW_STORAGE_METABASE_URL:jdbc:h2:mem:skywalking-oap-db}\n-#      dataSource.user: ${SW_STORAGE_METABASE_USER:sa}\n-#      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:}\n-#    mysqlProps:\n-#      jdbcUrl: ${SW_STORAGE_METABASE_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n-#      dataSource.user: ${SW_STORAGE_METABASE_USER:root}\n-#      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:root@1234}\n-#      dataSource.cachePrepStmts: ${SW_STORAGE_METABASE_CACHE_PREP_STMTS:true}\n-#      dataSource.prepStmtCacheSize: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_SIZE:250}\n-#      dataSource.prepStmtCacheSqlLimit: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n-#      dataSource.useServerPrepStmts: ${SW_STORAGE_METABASE_USE_SERVER_PREP_STMTS:true}\n-#    metadataQueryMaxSize: ${SW_STORAGE_METABASE_QUERY_MAX_SIZE:5000}\n-#    # InfluxDB configuration\n-#    url: ${SW_STORAGE_INFLUXDB_URL:http://localhost:8086}\n-#    user: ${SW_STORAGE_INFLUXDB_USER:root}\n-#    password: ${SW_STORAGE_INFLUXDB_PASSWORD:}\n-#    database: ${SW_STORAGE_INFLUXDB_DATABASE:skywalking}\n-#    actions: ${SW_STORAGE_INFLUXDB_ACTIONS:1000} # the number of actions to collect\n-#    duration: ${SW_STORAGE_INFLUXDB_DURATION:1000} # the time to wait at most (milliseconds)\n-#    fetchTaskLogMaxSize: ${SW_STORAGE_INFLUXDB_FETCH_TASK_LOG_MAX_SIZE:5000} # the max number of fetch task log in a request\n+  mysql:\n+    properties:\n+      jdbcUrl: ${SW_JDBC_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n+      dataSource.user: ${SW_DATA_SOURCE_USER:root}\n+      dataSource.password: ${SW_DATA_SOURCE_PASSWORD:root@1234}\n+      dataSource.cachePrepStmts: ${SW_DATA_SOURCE_CACHE_PREP_STMTS:true}\n+      dataSource.prepStmtCacheSize: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_SIZE:250}\n+      dataSource.prepStmtCacheSqlLimit: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n+      dataSource.useServerPrepStmts: ${SW_DATA_SOURCE_USE_SERVER_PREP_STMTS:true}\n+    metadataQueryMaxSize: ${SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000}\n+  influxdb:\n+    # Metadata storage provider configuration\n+    metabaseType: ${SW_STORAGE_METABASE_TYPE:H2} # There are 2 options as Metabase provider, H2 or MySQL.\n+    h2Props:\n+      dataSourceClassName: ${SW_STORAGE_METABASE_DRIVER:org.h2.jdbcx.JdbcDataSource}\n+      dataSource.url: ${SW_STORAGE_METABASE_URL:jdbc:h2:mem:skywalking-oap-db}\n+      dataSource.user: ${SW_STORAGE_METABASE_USER:sa}\n+      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:}\n+    mysqlProps:\n+      jdbcUrl: ${SW_STORAGE_METABASE_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n+      dataSource.user: ${SW_STORAGE_METABASE_USER:root}\n+      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:root@1234}\n+      dataSource.cachePrepStmts: ${SW_STORAGE_METABASE_CACHE_PREP_STMTS:true}\n+      dataSource.prepStmtCacheSize: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_SIZE:250}\n+      dataSource.prepStmtCacheSqlLimit: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n+      dataSource.useServerPrepStmts: ${SW_STORAGE_METABASE_USE_SERVER_PREP_STMTS:true}\n+    metadataQueryMaxSize: ${SW_STORAGE_METABASE_QUERY_MAX_SIZE:5000}\n+    # InfluxDB configuration\n+    url: ${SW_STORAGE_INFLUXDB_URL:http://localhost:8086}\n+    user: ${SW_STORAGE_INFLUXDB_USER:root}\n+    password: ${SW_STORAGE_INFLUXDB_PASSWORD:}\n+    database: ${SW_STORAGE_INFLUXDB_DATABASE:skywalking}\n+    actions: ${SW_STORAGE_INFLUXDB_ACTIONS:1000} # the number of actions to collect\n+    duration: ${SW_STORAGE_INFLUXDB_DURATION:1000} # the time to wait at most (milliseconds)\n+    fetchTaskLogMaxSize: ${SW_STORAGE_INFLUXDB_FETCH_TASK_LOG_MAX_SIZE:5000} # the max number of fetch task log in a request\n+\n receiver-sharing-server:\n+  selector: ${SW_RECEIVER_SHARING_SERVER:default}\n   default:\n+    authentication: ${SW_AUTHENTICATION:\"\"}\n receiver-register:\n+  selector: ${SW_RECEIVER_REGISTER:default}\n   default:\n+\n receiver-trace:\n+  selector: ${SW_RECEIVER_TRACE:default}\n   default:\n     bufferPath: ${SW_RECEIVER_BUFFER_PATH:../trace-buffer/}  # Path to trace buffer files, suggest to use absolute path\n     bufferOffsetMaxFileSize: ${SW_RECEIVER_BUFFER_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n     bufferDataMaxFileSize: ${SW_RECEIVER_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n     bufferFileCleanWhenRestart: ${SW_RECEIVER_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n     sampleRate: ${SW_TRACE_SAMPLE_RATE:10000} # The sample rate precision is 1/10000. 10000 means 100% sample in default.\n     slowDBAccessThreshold: ${SW_SLOW_DB_THRESHOLD:default:200,mongodb:100} # The slow database access thresholds. Unit ms.\n+\n receiver-jvm:\n+  selector: ${SW_RECEIVER_JVM:default}\n   default:\n+\n receiver-clr:\n+  selector: ${SW_RECEIVER_CLR:default}\n   default:\n+\n receiver-profile:\n+  selector: ${SW_RECEIVER_PROFILE:default}\n   default:\n+\n service-mesh:\n+  selector: ${SW_SERVICE_MESH:default}\n   default:\n     bufferPath: ${SW_SERVICE_MESH_BUFFER_PATH:../mesh-buffer/}  # Path to trace buffer files, suggest to use absolute path\n     bufferOffsetMaxFileSize: ${SW_SERVICE_MESH_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n     bufferDataMaxFileSize: ${SW_SERVICE_MESH_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n     bufferFileCleanWhenRestart: ${SW_SERVICE_MESH_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n+\n istio-telemetry:\n+  selector: ${SW_ISTIO_TELEMETRY:default}\n   default:\n+\n envoy-metric:\n+  selector: ${SW_ENVOY_METRIC:default}\n   default:\n-#    alsHTTPAnalysis: ${SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS:k8s-mesh}\n-#receiver_zipkin:\n-#  default:\n-#    host: ${SW_RECEIVER_ZIPKIN_HOST:0.0.0.0}\n-#    port: ${SW_RECEIVER_ZIPKIN_PORT:9411}\n-#    contextPath: ${SW_RECEIVER_ZIPKIN_CONTEXT_PATH:/}\n+    alsHTTPAnalysis: ${SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS:none}\n+\n+receiver_zipkin:\n+  selector: ${SW_RECEIVER_ZIPKIN:none}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY0ODg4Ng=="}, "originalCommit": null, "originalPosition": 312}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY0OTAyNw==", "bodyText": "At the module core level, should be strict validation to avoid illegal selector name.", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392649027", "createdAt": "2020-03-15T07:35:34Z", "author": {"login": "wu-sheng"}, "path": "dist-material/application.yml", "diffHunk": "@@ -83,180 +85,230 @@ core:\n     # and it will cause more load for memory, network of OAP and storage.\n     # But, being activated, user could see the name in the storage entities, which make users easier to use 3rd party tool, such as Kibana->ES, to query the data by themselves.\n     activeExtraModelColumns: ${SW_CORE_ACTIVE_EXTRA_MODEL_COLUMNS:false}\n+\n storage:\n-#  elasticsearch:\n-#    nameSpace: ${SW_NAMESPACE:\"\"}\n-#    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n-#    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n-#    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n-#    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n-#    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n-#    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n-#    user: ${SW_ES_USER:\"\"}\n-#    password: ${SW_ES_PASSWORD:\"\"}\n-#    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n-#    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n-#    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n-#    # Those data TTL settings will override the same settings in core module.\n-#    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n-#    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n-#    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-#    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n-#    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n-#    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n-#    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n-#    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n-#    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n-#    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n-#    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n-#  elasticsearch7:\n-#    nameSpace: ${SW_NAMESPACE:\"\"}\n-#    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n-#    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n-#    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n-#    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n-#    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n-#    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n-#    user: ${SW_ES_USER:\"\"}\n-#    password: ${SW_ES_PASSWORD:\"\"}\n-#    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n-#    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n-#    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n-#    # Those data TTL settings will override the same settings in core module.\n-#    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n-#    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n-#    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-#    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n-#    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n-#    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n-#    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n-#    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n-#    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n-#    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n-#    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n+  selector: ${SW_STORAGE:h2}\n+  elasticsearch:\n+    nameSpace: ${SW_NAMESPACE:\"\"}\n+    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n+    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n+    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n+    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n+    user: ${SW_ES_USER:\"\"}\n+    password: ${SW_ES_PASSWORD:\"\"}\n+    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n+    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n+    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n+    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n+    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n+    # Those data TTL settings will override the same settings in core module.\n+    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n+    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n+    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n+    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n+    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n+    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n+    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n+    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n+    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n+    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n+    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n+    advanced: ${SW_STORAGE_ES_ADVANCED:\"\"}\n+  elasticsearch7:\n+    nameSpace: ${SW_NAMESPACE:\"\"}\n+    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n+    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n+    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n+    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n+    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n+    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n+    user: ${SW_ES_USER:\"\"}\n+    password: ${SW_ES_PASSWORD:\"\"}\n+    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n+    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n+    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n+    # Those data TTL settings will override the same settings in core module.\n+    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n+    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n+    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n+    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n+    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n+    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n+    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n+    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n+    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n+    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n+    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n+    advanced: ${SW_STORAGE_ES_ADVANCED:\"\"}\n   h2:\n     driver: ${SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource}\n     url: ${SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db}\n     user: ${SW_STORAGE_H2_USER:sa}\n     metadataQueryMaxSize: ${SW_STORAGE_H2_QUERY_MAX_SIZE:5000}\n-#  mysql:\n-#    properties:\n-#      jdbcUrl: ${SW_JDBC_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n-#      dataSource.user: ${SW_DATA_SOURCE_USER:root}\n-#      dataSource.password: ${SW_DATA_SOURCE_PASSWORD:root@1234}\n-#      dataSource.cachePrepStmts: ${SW_DATA_SOURCE_CACHE_PREP_STMTS:true}\n-#      dataSource.prepStmtCacheSize: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_SIZE:250}\n-#      dataSource.prepStmtCacheSqlLimit: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n-#      dataSource.useServerPrepStmts: ${SW_DATA_SOURCE_USE_SERVER_PREP_STMTS:true}\n-#    metadataQueryMaxSize: ${SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000}\n-#  influx:\n-#    # Metadata storage provider configuration\n-#    metabaseType: ${SW_STORAGE_METABASE_TYPE:H2} # There are 2 options as Metabase provider, H2 or MySQL.\n-#    h2Props:\n-#      dataSourceClassName: ${SW_STORAGE_METABASE_DRIVER:org.h2.jdbcx.JdbcDataSource}\n-#      dataSource.url: ${SW_STORAGE_METABASE_URL:jdbc:h2:mem:skywalking-oap-db}\n-#      dataSource.user: ${SW_STORAGE_METABASE_USER:sa}\n-#      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:}\n-#    mysqlProps:\n-#      jdbcUrl: ${SW_STORAGE_METABASE_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n-#      dataSource.user: ${SW_STORAGE_METABASE_USER:root}\n-#      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:root@1234}\n-#      dataSource.cachePrepStmts: ${SW_STORAGE_METABASE_CACHE_PREP_STMTS:true}\n-#      dataSource.prepStmtCacheSize: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_SIZE:250}\n-#      dataSource.prepStmtCacheSqlLimit: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n-#      dataSource.useServerPrepStmts: ${SW_STORAGE_METABASE_USE_SERVER_PREP_STMTS:true}\n-#    metadataQueryMaxSize: ${SW_STORAGE_METABASE_QUERY_MAX_SIZE:5000}\n-#    # InfluxDB configuration\n-#    url: ${SW_STORAGE_INFLUXDB_URL:http://localhost:8086}\n-#    user: ${SW_STORAGE_INFLUXDB_USER:root}\n-#    password: ${SW_STORAGE_INFLUXDB_PASSWORD:}\n-#    database: ${SW_STORAGE_INFLUXDB_DATABASE:skywalking}\n-#    actions: ${SW_STORAGE_INFLUXDB_ACTIONS:1000} # the number of actions to collect\n-#    duration: ${SW_STORAGE_INFLUXDB_DURATION:1000} # the time to wait at most (milliseconds)\n-#    fetchTaskLogMaxSize: ${SW_STORAGE_INFLUXDB_FETCH_TASK_LOG_MAX_SIZE:5000} # the max number of fetch task log in a request\n+  mysql:\n+    properties:\n+      jdbcUrl: ${SW_JDBC_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n+      dataSource.user: ${SW_DATA_SOURCE_USER:root}\n+      dataSource.password: ${SW_DATA_SOURCE_PASSWORD:root@1234}\n+      dataSource.cachePrepStmts: ${SW_DATA_SOURCE_CACHE_PREP_STMTS:true}\n+      dataSource.prepStmtCacheSize: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_SIZE:250}\n+      dataSource.prepStmtCacheSqlLimit: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n+      dataSource.useServerPrepStmts: ${SW_DATA_SOURCE_USE_SERVER_PREP_STMTS:true}\n+    metadataQueryMaxSize: ${SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000}\n+  influxdb:\n+    # Metadata storage provider configuration\n+    metabaseType: ${SW_STORAGE_METABASE_TYPE:H2} # There are 2 options as Metabase provider, H2 or MySQL.\n+    h2Props:\n+      dataSourceClassName: ${SW_STORAGE_METABASE_DRIVER:org.h2.jdbcx.JdbcDataSource}\n+      dataSource.url: ${SW_STORAGE_METABASE_URL:jdbc:h2:mem:skywalking-oap-db}\n+      dataSource.user: ${SW_STORAGE_METABASE_USER:sa}\n+      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:}\n+    mysqlProps:\n+      jdbcUrl: ${SW_STORAGE_METABASE_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n+      dataSource.user: ${SW_STORAGE_METABASE_USER:root}\n+      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:root@1234}\n+      dataSource.cachePrepStmts: ${SW_STORAGE_METABASE_CACHE_PREP_STMTS:true}\n+      dataSource.prepStmtCacheSize: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_SIZE:250}\n+      dataSource.prepStmtCacheSqlLimit: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n+      dataSource.useServerPrepStmts: ${SW_STORAGE_METABASE_USE_SERVER_PREP_STMTS:true}\n+    metadataQueryMaxSize: ${SW_STORAGE_METABASE_QUERY_MAX_SIZE:5000}\n+    # InfluxDB configuration\n+    url: ${SW_STORAGE_INFLUXDB_URL:http://localhost:8086}\n+    user: ${SW_STORAGE_INFLUXDB_USER:root}\n+    password: ${SW_STORAGE_INFLUXDB_PASSWORD:}\n+    database: ${SW_STORAGE_INFLUXDB_DATABASE:skywalking}\n+    actions: ${SW_STORAGE_INFLUXDB_ACTIONS:1000} # the number of actions to collect\n+    duration: ${SW_STORAGE_INFLUXDB_DURATION:1000} # the time to wait at most (milliseconds)\n+    fetchTaskLogMaxSize: ${SW_STORAGE_INFLUXDB_FETCH_TASK_LOG_MAX_SIZE:5000} # the max number of fetch task log in a request\n+\n receiver-sharing-server:\n+  selector: ${SW_RECEIVER_SHARING_SERVER:default}\n   default:\n+    authentication: ${SW_AUTHENTICATION:\"\"}\n receiver-register:\n+  selector: ${SW_RECEIVER_REGISTER:default}\n   default:\n+\n receiver-trace:\n+  selector: ${SW_RECEIVER_TRACE:default}\n   default:\n     bufferPath: ${SW_RECEIVER_BUFFER_PATH:../trace-buffer/}  # Path to trace buffer files, suggest to use absolute path\n     bufferOffsetMaxFileSize: ${SW_RECEIVER_BUFFER_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n     bufferDataMaxFileSize: ${SW_RECEIVER_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n     bufferFileCleanWhenRestart: ${SW_RECEIVER_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n     sampleRate: ${SW_TRACE_SAMPLE_RATE:10000} # The sample rate precision is 1/10000. 10000 means 100% sample in default.\n     slowDBAccessThreshold: ${SW_SLOW_DB_THRESHOLD:default:200,mongodb:100} # The slow database access thresholds. Unit ms.\n+\n receiver-jvm:\n+  selector: ${SW_RECEIVER_JVM:default}\n   default:\n+\n receiver-clr:\n+  selector: ${SW_RECEIVER_CLR:default}\n   default:\n+\n receiver-profile:\n+  selector: ${SW_RECEIVER_PROFILE:default}\n   default:\n+\n service-mesh:\n+  selector: ${SW_SERVICE_MESH:default}\n   default:\n     bufferPath: ${SW_SERVICE_MESH_BUFFER_PATH:../mesh-buffer/}  # Path to trace buffer files, suggest to use absolute path\n     bufferOffsetMaxFileSize: ${SW_SERVICE_MESH_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n     bufferDataMaxFileSize: ${SW_SERVICE_MESH_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n     bufferFileCleanWhenRestart: ${SW_SERVICE_MESH_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n+\n istio-telemetry:\n+  selector: ${SW_ISTIO_TELEMETRY:default}\n   default:\n+\n envoy-metric:\n+  selector: ${SW_ENVOY_METRIC:default}\n   default:\n-#    alsHTTPAnalysis: ${SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS:k8s-mesh}\n-#receiver_zipkin:\n-#  default:\n-#    host: ${SW_RECEIVER_ZIPKIN_HOST:0.0.0.0}\n-#    port: ${SW_RECEIVER_ZIPKIN_PORT:9411}\n-#    contextPath: ${SW_RECEIVER_ZIPKIN_CONTEXT_PATH:/}\n+    alsHTTPAnalysis: ${SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS:none}\n+\n+receiver_zipkin:\n+  selector: ${SW_RECEIVER_ZIPKIN:none}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY0ODg4Ng=="}, "originalCommit": null, "originalPosition": 312}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY1MDc1Nw==", "bodyText": "If this module is required by other module, what happens?\nI don't think providing a potential NPE in the runtime is a good idea.\nAlso, based on this, I could put some tricky parameter value such as any not existing provider name. And we magically accept it and start up successfully.\n\nCan I just think of that this problem is not related to this pull request directly and it should be fixed in another pull request? In the old way, if the user just comment out the required module, what would happen? Are they the same problem here?", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392650757", "createdAt": "2020-03-15T08:04:22Z", "author": {"login": "kezhenxu94"}, "path": "dist-material/application.yml", "diffHunk": "@@ -83,180 +85,230 @@ core:\n     # and it will cause more load for memory, network of OAP and storage.\n     # But, being activated, user could see the name in the storage entities, which make users easier to use 3rd party tool, such as Kibana->ES, to query the data by themselves.\n     activeExtraModelColumns: ${SW_CORE_ACTIVE_EXTRA_MODEL_COLUMNS:false}\n+\n storage:\n-#  elasticsearch:\n-#    nameSpace: ${SW_NAMESPACE:\"\"}\n-#    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n-#    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n-#    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n-#    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n-#    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n-#    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n-#    user: ${SW_ES_USER:\"\"}\n-#    password: ${SW_ES_PASSWORD:\"\"}\n-#    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n-#    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n-#    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n-#    # Those data TTL settings will override the same settings in core module.\n-#    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n-#    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n-#    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-#    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n-#    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n-#    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n-#    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n-#    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n-#    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n-#    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n-#    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n-#  elasticsearch7:\n-#    nameSpace: ${SW_NAMESPACE:\"\"}\n-#    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n-#    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n-#    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n-#    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n-#    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n-#    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n-#    user: ${SW_ES_USER:\"\"}\n-#    password: ${SW_ES_PASSWORD:\"\"}\n-#    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n-#    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n-#    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n-#    # Those data TTL settings will override the same settings in core module.\n-#    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n-#    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n-#    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-#    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n-#    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n-#    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n-#    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n-#    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n-#    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n-#    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n-#    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n+  selector: ${SW_STORAGE:h2}\n+  elasticsearch:\n+    nameSpace: ${SW_NAMESPACE:\"\"}\n+    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n+    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n+    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n+    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n+    user: ${SW_ES_USER:\"\"}\n+    password: ${SW_ES_PASSWORD:\"\"}\n+    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n+    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n+    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n+    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n+    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n+    # Those data TTL settings will override the same settings in core module.\n+    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n+    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n+    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n+    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n+    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n+    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n+    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n+    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n+    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n+    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n+    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n+    advanced: ${SW_STORAGE_ES_ADVANCED:\"\"}\n+  elasticsearch7:\n+    nameSpace: ${SW_NAMESPACE:\"\"}\n+    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n+    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n+    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n+    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n+    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n+    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n+    user: ${SW_ES_USER:\"\"}\n+    password: ${SW_ES_PASSWORD:\"\"}\n+    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n+    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n+    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n+    # Those data TTL settings will override the same settings in core module.\n+    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n+    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n+    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n+    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n+    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n+    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n+    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n+    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n+    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n+    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n+    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n+    advanced: ${SW_STORAGE_ES_ADVANCED:\"\"}\n   h2:\n     driver: ${SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource}\n     url: ${SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db}\n     user: ${SW_STORAGE_H2_USER:sa}\n     metadataQueryMaxSize: ${SW_STORAGE_H2_QUERY_MAX_SIZE:5000}\n-#  mysql:\n-#    properties:\n-#      jdbcUrl: ${SW_JDBC_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n-#      dataSource.user: ${SW_DATA_SOURCE_USER:root}\n-#      dataSource.password: ${SW_DATA_SOURCE_PASSWORD:root@1234}\n-#      dataSource.cachePrepStmts: ${SW_DATA_SOURCE_CACHE_PREP_STMTS:true}\n-#      dataSource.prepStmtCacheSize: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_SIZE:250}\n-#      dataSource.prepStmtCacheSqlLimit: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n-#      dataSource.useServerPrepStmts: ${SW_DATA_SOURCE_USE_SERVER_PREP_STMTS:true}\n-#    metadataQueryMaxSize: ${SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000}\n-#  influx:\n-#    # Metadata storage provider configuration\n-#    metabaseType: ${SW_STORAGE_METABASE_TYPE:H2} # There are 2 options as Metabase provider, H2 or MySQL.\n-#    h2Props:\n-#      dataSourceClassName: ${SW_STORAGE_METABASE_DRIVER:org.h2.jdbcx.JdbcDataSource}\n-#      dataSource.url: ${SW_STORAGE_METABASE_URL:jdbc:h2:mem:skywalking-oap-db}\n-#      dataSource.user: ${SW_STORAGE_METABASE_USER:sa}\n-#      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:}\n-#    mysqlProps:\n-#      jdbcUrl: ${SW_STORAGE_METABASE_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n-#      dataSource.user: ${SW_STORAGE_METABASE_USER:root}\n-#      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:root@1234}\n-#      dataSource.cachePrepStmts: ${SW_STORAGE_METABASE_CACHE_PREP_STMTS:true}\n-#      dataSource.prepStmtCacheSize: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_SIZE:250}\n-#      dataSource.prepStmtCacheSqlLimit: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n-#      dataSource.useServerPrepStmts: ${SW_STORAGE_METABASE_USE_SERVER_PREP_STMTS:true}\n-#    metadataQueryMaxSize: ${SW_STORAGE_METABASE_QUERY_MAX_SIZE:5000}\n-#    # InfluxDB configuration\n-#    url: ${SW_STORAGE_INFLUXDB_URL:http://localhost:8086}\n-#    user: ${SW_STORAGE_INFLUXDB_USER:root}\n-#    password: ${SW_STORAGE_INFLUXDB_PASSWORD:}\n-#    database: ${SW_STORAGE_INFLUXDB_DATABASE:skywalking}\n-#    actions: ${SW_STORAGE_INFLUXDB_ACTIONS:1000} # the number of actions to collect\n-#    duration: ${SW_STORAGE_INFLUXDB_DURATION:1000} # the time to wait at most (milliseconds)\n-#    fetchTaskLogMaxSize: ${SW_STORAGE_INFLUXDB_FETCH_TASK_LOG_MAX_SIZE:5000} # the max number of fetch task log in a request\n+  mysql:\n+    properties:\n+      jdbcUrl: ${SW_JDBC_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n+      dataSource.user: ${SW_DATA_SOURCE_USER:root}\n+      dataSource.password: ${SW_DATA_SOURCE_PASSWORD:root@1234}\n+      dataSource.cachePrepStmts: ${SW_DATA_SOURCE_CACHE_PREP_STMTS:true}\n+      dataSource.prepStmtCacheSize: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_SIZE:250}\n+      dataSource.prepStmtCacheSqlLimit: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n+      dataSource.useServerPrepStmts: ${SW_DATA_SOURCE_USE_SERVER_PREP_STMTS:true}\n+    metadataQueryMaxSize: ${SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000}\n+  influxdb:\n+    # Metadata storage provider configuration\n+    metabaseType: ${SW_STORAGE_METABASE_TYPE:H2} # There are 2 options as Metabase provider, H2 or MySQL.\n+    h2Props:\n+      dataSourceClassName: ${SW_STORAGE_METABASE_DRIVER:org.h2.jdbcx.JdbcDataSource}\n+      dataSource.url: ${SW_STORAGE_METABASE_URL:jdbc:h2:mem:skywalking-oap-db}\n+      dataSource.user: ${SW_STORAGE_METABASE_USER:sa}\n+      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:}\n+    mysqlProps:\n+      jdbcUrl: ${SW_STORAGE_METABASE_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n+      dataSource.user: ${SW_STORAGE_METABASE_USER:root}\n+      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:root@1234}\n+      dataSource.cachePrepStmts: ${SW_STORAGE_METABASE_CACHE_PREP_STMTS:true}\n+      dataSource.prepStmtCacheSize: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_SIZE:250}\n+      dataSource.prepStmtCacheSqlLimit: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n+      dataSource.useServerPrepStmts: ${SW_STORAGE_METABASE_USE_SERVER_PREP_STMTS:true}\n+    metadataQueryMaxSize: ${SW_STORAGE_METABASE_QUERY_MAX_SIZE:5000}\n+    # InfluxDB configuration\n+    url: ${SW_STORAGE_INFLUXDB_URL:http://localhost:8086}\n+    user: ${SW_STORAGE_INFLUXDB_USER:root}\n+    password: ${SW_STORAGE_INFLUXDB_PASSWORD:}\n+    database: ${SW_STORAGE_INFLUXDB_DATABASE:skywalking}\n+    actions: ${SW_STORAGE_INFLUXDB_ACTIONS:1000} # the number of actions to collect\n+    duration: ${SW_STORAGE_INFLUXDB_DURATION:1000} # the time to wait at most (milliseconds)\n+    fetchTaskLogMaxSize: ${SW_STORAGE_INFLUXDB_FETCH_TASK_LOG_MAX_SIZE:5000} # the max number of fetch task log in a request\n+\n receiver-sharing-server:\n+  selector: ${SW_RECEIVER_SHARING_SERVER:default}\n   default:\n+    authentication: ${SW_AUTHENTICATION:\"\"}\n receiver-register:\n+  selector: ${SW_RECEIVER_REGISTER:default}\n   default:\n+\n receiver-trace:\n+  selector: ${SW_RECEIVER_TRACE:default}\n   default:\n     bufferPath: ${SW_RECEIVER_BUFFER_PATH:../trace-buffer/}  # Path to trace buffer files, suggest to use absolute path\n     bufferOffsetMaxFileSize: ${SW_RECEIVER_BUFFER_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n     bufferDataMaxFileSize: ${SW_RECEIVER_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n     bufferFileCleanWhenRestart: ${SW_RECEIVER_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n     sampleRate: ${SW_TRACE_SAMPLE_RATE:10000} # The sample rate precision is 1/10000. 10000 means 100% sample in default.\n     slowDBAccessThreshold: ${SW_SLOW_DB_THRESHOLD:default:200,mongodb:100} # The slow database access thresholds. Unit ms.\n+\n receiver-jvm:\n+  selector: ${SW_RECEIVER_JVM:default}\n   default:\n+\n receiver-clr:\n+  selector: ${SW_RECEIVER_CLR:default}\n   default:\n+\n receiver-profile:\n+  selector: ${SW_RECEIVER_PROFILE:default}\n   default:\n+\n service-mesh:\n+  selector: ${SW_SERVICE_MESH:default}\n   default:\n     bufferPath: ${SW_SERVICE_MESH_BUFFER_PATH:../mesh-buffer/}  # Path to trace buffer files, suggest to use absolute path\n     bufferOffsetMaxFileSize: ${SW_SERVICE_MESH_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n     bufferDataMaxFileSize: ${SW_SERVICE_MESH_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n     bufferFileCleanWhenRestart: ${SW_SERVICE_MESH_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n+\n istio-telemetry:\n+  selector: ${SW_ISTIO_TELEMETRY:default}\n   default:\n+\n envoy-metric:\n+  selector: ${SW_ENVOY_METRIC:default}\n   default:\n-#    alsHTTPAnalysis: ${SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS:k8s-mesh}\n-#receiver_zipkin:\n-#  default:\n-#    host: ${SW_RECEIVER_ZIPKIN_HOST:0.0.0.0}\n-#    port: ${SW_RECEIVER_ZIPKIN_PORT:9411}\n-#    contextPath: ${SW_RECEIVER_ZIPKIN_CONTEXT_PATH:/}\n+    alsHTTPAnalysis: ${SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS:none}\n+\n+receiver_zipkin:\n+  selector: ${SW_RECEIVER_ZIPKIN:none}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY0ODg4Ng=="}, "originalCommit": null, "originalPosition": 312}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY1MjY2OA==", "bodyText": "Read old ModuleDefine#prepare. Once the provider doesn't exist, throw new ProviderNotFoundException(this.name() + \" module no provider exists.\"); this shows up.\nBut because we enable multiple providers in YAML and using the selector, this check wouldn't work, that is why I asked.", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392652668", "createdAt": "2020-03-15T08:34:20Z", "author": {"login": "wu-sheng"}, "path": "dist-material/application.yml", "diffHunk": "@@ -83,180 +85,230 @@ core:\n     # and it will cause more load for memory, network of OAP and storage.\n     # But, being activated, user could see the name in the storage entities, which make users easier to use 3rd party tool, such as Kibana->ES, to query the data by themselves.\n     activeExtraModelColumns: ${SW_CORE_ACTIVE_EXTRA_MODEL_COLUMNS:false}\n+\n storage:\n-#  elasticsearch:\n-#    nameSpace: ${SW_NAMESPACE:\"\"}\n-#    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n-#    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n-#    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n-#    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n-#    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n-#    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n-#    user: ${SW_ES_USER:\"\"}\n-#    password: ${SW_ES_PASSWORD:\"\"}\n-#    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n-#    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n-#    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n-#    # Those data TTL settings will override the same settings in core module.\n-#    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n-#    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n-#    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-#    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n-#    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n-#    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n-#    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n-#    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n-#    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n-#    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n-#    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n-#  elasticsearch7:\n-#    nameSpace: ${SW_NAMESPACE:\"\"}\n-#    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n-#    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n-#    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n-#    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n-#    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n-#    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n-#    user: ${SW_ES_USER:\"\"}\n-#    password: ${SW_ES_PASSWORD:\"\"}\n-#    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n-#    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n-#    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n-#    # Those data TTL settings will override the same settings in core module.\n-#    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n-#    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n-#    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-#    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n-#    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n-#    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n-#    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n-#    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n-#    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n-#    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n-#    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n+  selector: ${SW_STORAGE:h2}\n+  elasticsearch:\n+    nameSpace: ${SW_NAMESPACE:\"\"}\n+    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n+    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n+    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n+    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n+    user: ${SW_ES_USER:\"\"}\n+    password: ${SW_ES_PASSWORD:\"\"}\n+    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n+    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n+    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n+    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n+    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n+    # Those data TTL settings will override the same settings in core module.\n+    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n+    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n+    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n+    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n+    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n+    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n+    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n+    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n+    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n+    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n+    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n+    advanced: ${SW_STORAGE_ES_ADVANCED:\"\"}\n+  elasticsearch7:\n+    nameSpace: ${SW_NAMESPACE:\"\"}\n+    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n+    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n+    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n+    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n+    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n+    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n+    user: ${SW_ES_USER:\"\"}\n+    password: ${SW_ES_PASSWORD:\"\"}\n+    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n+    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n+    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n+    # Those data TTL settings will override the same settings in core module.\n+    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n+    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n+    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n+    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n+    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n+    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n+    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n+    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n+    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n+    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n+    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n+    advanced: ${SW_STORAGE_ES_ADVANCED:\"\"}\n   h2:\n     driver: ${SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource}\n     url: ${SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db}\n     user: ${SW_STORAGE_H2_USER:sa}\n     metadataQueryMaxSize: ${SW_STORAGE_H2_QUERY_MAX_SIZE:5000}\n-#  mysql:\n-#    properties:\n-#      jdbcUrl: ${SW_JDBC_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n-#      dataSource.user: ${SW_DATA_SOURCE_USER:root}\n-#      dataSource.password: ${SW_DATA_SOURCE_PASSWORD:root@1234}\n-#      dataSource.cachePrepStmts: ${SW_DATA_SOURCE_CACHE_PREP_STMTS:true}\n-#      dataSource.prepStmtCacheSize: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_SIZE:250}\n-#      dataSource.prepStmtCacheSqlLimit: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n-#      dataSource.useServerPrepStmts: ${SW_DATA_SOURCE_USE_SERVER_PREP_STMTS:true}\n-#    metadataQueryMaxSize: ${SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000}\n-#  influx:\n-#    # Metadata storage provider configuration\n-#    metabaseType: ${SW_STORAGE_METABASE_TYPE:H2} # There are 2 options as Metabase provider, H2 or MySQL.\n-#    h2Props:\n-#      dataSourceClassName: ${SW_STORAGE_METABASE_DRIVER:org.h2.jdbcx.JdbcDataSource}\n-#      dataSource.url: ${SW_STORAGE_METABASE_URL:jdbc:h2:mem:skywalking-oap-db}\n-#      dataSource.user: ${SW_STORAGE_METABASE_USER:sa}\n-#      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:}\n-#    mysqlProps:\n-#      jdbcUrl: ${SW_STORAGE_METABASE_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n-#      dataSource.user: ${SW_STORAGE_METABASE_USER:root}\n-#      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:root@1234}\n-#      dataSource.cachePrepStmts: ${SW_STORAGE_METABASE_CACHE_PREP_STMTS:true}\n-#      dataSource.prepStmtCacheSize: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_SIZE:250}\n-#      dataSource.prepStmtCacheSqlLimit: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n-#      dataSource.useServerPrepStmts: ${SW_STORAGE_METABASE_USE_SERVER_PREP_STMTS:true}\n-#    metadataQueryMaxSize: ${SW_STORAGE_METABASE_QUERY_MAX_SIZE:5000}\n-#    # InfluxDB configuration\n-#    url: ${SW_STORAGE_INFLUXDB_URL:http://localhost:8086}\n-#    user: ${SW_STORAGE_INFLUXDB_USER:root}\n-#    password: ${SW_STORAGE_INFLUXDB_PASSWORD:}\n-#    database: ${SW_STORAGE_INFLUXDB_DATABASE:skywalking}\n-#    actions: ${SW_STORAGE_INFLUXDB_ACTIONS:1000} # the number of actions to collect\n-#    duration: ${SW_STORAGE_INFLUXDB_DURATION:1000} # the time to wait at most (milliseconds)\n-#    fetchTaskLogMaxSize: ${SW_STORAGE_INFLUXDB_FETCH_TASK_LOG_MAX_SIZE:5000} # the max number of fetch task log in a request\n+  mysql:\n+    properties:\n+      jdbcUrl: ${SW_JDBC_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n+      dataSource.user: ${SW_DATA_SOURCE_USER:root}\n+      dataSource.password: ${SW_DATA_SOURCE_PASSWORD:root@1234}\n+      dataSource.cachePrepStmts: ${SW_DATA_SOURCE_CACHE_PREP_STMTS:true}\n+      dataSource.prepStmtCacheSize: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_SIZE:250}\n+      dataSource.prepStmtCacheSqlLimit: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n+      dataSource.useServerPrepStmts: ${SW_DATA_SOURCE_USE_SERVER_PREP_STMTS:true}\n+    metadataQueryMaxSize: ${SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000}\n+  influxdb:\n+    # Metadata storage provider configuration\n+    metabaseType: ${SW_STORAGE_METABASE_TYPE:H2} # There are 2 options as Metabase provider, H2 or MySQL.\n+    h2Props:\n+      dataSourceClassName: ${SW_STORAGE_METABASE_DRIVER:org.h2.jdbcx.JdbcDataSource}\n+      dataSource.url: ${SW_STORAGE_METABASE_URL:jdbc:h2:mem:skywalking-oap-db}\n+      dataSource.user: ${SW_STORAGE_METABASE_USER:sa}\n+      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:}\n+    mysqlProps:\n+      jdbcUrl: ${SW_STORAGE_METABASE_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n+      dataSource.user: ${SW_STORAGE_METABASE_USER:root}\n+      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:root@1234}\n+      dataSource.cachePrepStmts: ${SW_STORAGE_METABASE_CACHE_PREP_STMTS:true}\n+      dataSource.prepStmtCacheSize: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_SIZE:250}\n+      dataSource.prepStmtCacheSqlLimit: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n+      dataSource.useServerPrepStmts: ${SW_STORAGE_METABASE_USE_SERVER_PREP_STMTS:true}\n+    metadataQueryMaxSize: ${SW_STORAGE_METABASE_QUERY_MAX_SIZE:5000}\n+    # InfluxDB configuration\n+    url: ${SW_STORAGE_INFLUXDB_URL:http://localhost:8086}\n+    user: ${SW_STORAGE_INFLUXDB_USER:root}\n+    password: ${SW_STORAGE_INFLUXDB_PASSWORD:}\n+    database: ${SW_STORAGE_INFLUXDB_DATABASE:skywalking}\n+    actions: ${SW_STORAGE_INFLUXDB_ACTIONS:1000} # the number of actions to collect\n+    duration: ${SW_STORAGE_INFLUXDB_DURATION:1000} # the time to wait at most (milliseconds)\n+    fetchTaskLogMaxSize: ${SW_STORAGE_INFLUXDB_FETCH_TASK_LOG_MAX_SIZE:5000} # the max number of fetch task log in a request\n+\n receiver-sharing-server:\n+  selector: ${SW_RECEIVER_SHARING_SERVER:default}\n   default:\n+    authentication: ${SW_AUTHENTICATION:\"\"}\n receiver-register:\n+  selector: ${SW_RECEIVER_REGISTER:default}\n   default:\n+\n receiver-trace:\n+  selector: ${SW_RECEIVER_TRACE:default}\n   default:\n     bufferPath: ${SW_RECEIVER_BUFFER_PATH:../trace-buffer/}  # Path to trace buffer files, suggest to use absolute path\n     bufferOffsetMaxFileSize: ${SW_RECEIVER_BUFFER_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n     bufferDataMaxFileSize: ${SW_RECEIVER_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n     bufferFileCleanWhenRestart: ${SW_RECEIVER_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n     sampleRate: ${SW_TRACE_SAMPLE_RATE:10000} # The sample rate precision is 1/10000. 10000 means 100% sample in default.\n     slowDBAccessThreshold: ${SW_SLOW_DB_THRESHOLD:default:200,mongodb:100} # The slow database access thresholds. Unit ms.\n+\n receiver-jvm:\n+  selector: ${SW_RECEIVER_JVM:default}\n   default:\n+\n receiver-clr:\n+  selector: ${SW_RECEIVER_CLR:default}\n   default:\n+\n receiver-profile:\n+  selector: ${SW_RECEIVER_PROFILE:default}\n   default:\n+\n service-mesh:\n+  selector: ${SW_SERVICE_MESH:default}\n   default:\n     bufferPath: ${SW_SERVICE_MESH_BUFFER_PATH:../mesh-buffer/}  # Path to trace buffer files, suggest to use absolute path\n     bufferOffsetMaxFileSize: ${SW_SERVICE_MESH_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n     bufferDataMaxFileSize: ${SW_SERVICE_MESH_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n     bufferFileCleanWhenRestart: ${SW_SERVICE_MESH_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n+\n istio-telemetry:\n+  selector: ${SW_ISTIO_TELEMETRY:default}\n   default:\n+\n envoy-metric:\n+  selector: ${SW_ENVOY_METRIC:default}\n   default:\n-#    alsHTTPAnalysis: ${SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS:k8s-mesh}\n-#receiver_zipkin:\n-#  default:\n-#    host: ${SW_RECEIVER_ZIPKIN_HOST:0.0.0.0}\n-#    port: ${SW_RECEIVER_ZIPKIN_PORT:9411}\n-#    contextPath: ${SW_RECEIVER_ZIPKIN_CONTEXT_PATH:/}\n+    alsHTTPAnalysis: ${SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS:none}\n+\n+receiver_zipkin:\n+  selector: ${SW_RECEIVER_ZIPKIN:none}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY0ODg4Ng=="}, "originalCommit": null, "originalPosition": 312}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY1Mzk5MQ==", "bodyText": "@wu-sheng hope I got your point correctly and I try to fix it at the phase when processing the configuration, to ensure that the processed configurations are the same as before, and verify like this, correct me if I made anything wrong still", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392653991", "createdAt": "2020-03-15T08:55:01Z", "author": {"login": "kezhenxu94"}, "path": "dist-material/application.yml", "diffHunk": "@@ -83,180 +85,230 @@ core:\n     # and it will cause more load for memory, network of OAP and storage.\n     # But, being activated, user could see the name in the storage entities, which make users easier to use 3rd party tool, such as Kibana->ES, to query the data by themselves.\n     activeExtraModelColumns: ${SW_CORE_ACTIVE_EXTRA_MODEL_COLUMNS:false}\n+\n storage:\n-#  elasticsearch:\n-#    nameSpace: ${SW_NAMESPACE:\"\"}\n-#    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n-#    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n-#    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n-#    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n-#    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n-#    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n-#    user: ${SW_ES_USER:\"\"}\n-#    password: ${SW_ES_PASSWORD:\"\"}\n-#    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n-#    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n-#    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n-#    # Those data TTL settings will override the same settings in core module.\n-#    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n-#    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n-#    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-#    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n-#    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n-#    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n-#    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n-#    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n-#    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n-#    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n-#    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n-#  elasticsearch7:\n-#    nameSpace: ${SW_NAMESPACE:\"\"}\n-#    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n-#    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n-#    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n-#    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n-#    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n-#    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n-#    user: ${SW_ES_USER:\"\"}\n-#    password: ${SW_ES_PASSWORD:\"\"}\n-#    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n-#    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n-#    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n-#    # Those data TTL settings will override the same settings in core module.\n-#    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n-#    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n-#    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-#    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n-#    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n-#    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n-#    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n-#    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n-#    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n-#    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n-#    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n+  selector: ${SW_STORAGE:h2}\n+  elasticsearch:\n+    nameSpace: ${SW_NAMESPACE:\"\"}\n+    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n+    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n+    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n+    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n+    user: ${SW_ES_USER:\"\"}\n+    password: ${SW_ES_PASSWORD:\"\"}\n+    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n+    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n+    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n+    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n+    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n+    # Those data TTL settings will override the same settings in core module.\n+    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n+    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n+    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n+    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n+    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n+    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n+    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n+    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n+    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n+    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n+    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n+    advanced: ${SW_STORAGE_ES_ADVANCED:\"\"}\n+  elasticsearch7:\n+    nameSpace: ${SW_NAMESPACE:\"\"}\n+    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n+    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n+    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n+    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n+    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n+    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n+    user: ${SW_ES_USER:\"\"}\n+    password: ${SW_ES_PASSWORD:\"\"}\n+    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n+    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n+    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n+    # Those data TTL settings will override the same settings in core module.\n+    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n+    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n+    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n+    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n+    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n+    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n+    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n+    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n+    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n+    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n+    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n+    advanced: ${SW_STORAGE_ES_ADVANCED:\"\"}\n   h2:\n     driver: ${SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource}\n     url: ${SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db}\n     user: ${SW_STORAGE_H2_USER:sa}\n     metadataQueryMaxSize: ${SW_STORAGE_H2_QUERY_MAX_SIZE:5000}\n-#  mysql:\n-#    properties:\n-#      jdbcUrl: ${SW_JDBC_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n-#      dataSource.user: ${SW_DATA_SOURCE_USER:root}\n-#      dataSource.password: ${SW_DATA_SOURCE_PASSWORD:root@1234}\n-#      dataSource.cachePrepStmts: ${SW_DATA_SOURCE_CACHE_PREP_STMTS:true}\n-#      dataSource.prepStmtCacheSize: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_SIZE:250}\n-#      dataSource.prepStmtCacheSqlLimit: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n-#      dataSource.useServerPrepStmts: ${SW_DATA_SOURCE_USE_SERVER_PREP_STMTS:true}\n-#    metadataQueryMaxSize: ${SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000}\n-#  influx:\n-#    # Metadata storage provider configuration\n-#    metabaseType: ${SW_STORAGE_METABASE_TYPE:H2} # There are 2 options as Metabase provider, H2 or MySQL.\n-#    h2Props:\n-#      dataSourceClassName: ${SW_STORAGE_METABASE_DRIVER:org.h2.jdbcx.JdbcDataSource}\n-#      dataSource.url: ${SW_STORAGE_METABASE_URL:jdbc:h2:mem:skywalking-oap-db}\n-#      dataSource.user: ${SW_STORAGE_METABASE_USER:sa}\n-#      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:}\n-#    mysqlProps:\n-#      jdbcUrl: ${SW_STORAGE_METABASE_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n-#      dataSource.user: ${SW_STORAGE_METABASE_USER:root}\n-#      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:root@1234}\n-#      dataSource.cachePrepStmts: ${SW_STORAGE_METABASE_CACHE_PREP_STMTS:true}\n-#      dataSource.prepStmtCacheSize: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_SIZE:250}\n-#      dataSource.prepStmtCacheSqlLimit: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n-#      dataSource.useServerPrepStmts: ${SW_STORAGE_METABASE_USE_SERVER_PREP_STMTS:true}\n-#    metadataQueryMaxSize: ${SW_STORAGE_METABASE_QUERY_MAX_SIZE:5000}\n-#    # InfluxDB configuration\n-#    url: ${SW_STORAGE_INFLUXDB_URL:http://localhost:8086}\n-#    user: ${SW_STORAGE_INFLUXDB_USER:root}\n-#    password: ${SW_STORAGE_INFLUXDB_PASSWORD:}\n-#    database: ${SW_STORAGE_INFLUXDB_DATABASE:skywalking}\n-#    actions: ${SW_STORAGE_INFLUXDB_ACTIONS:1000} # the number of actions to collect\n-#    duration: ${SW_STORAGE_INFLUXDB_DURATION:1000} # the time to wait at most (milliseconds)\n-#    fetchTaskLogMaxSize: ${SW_STORAGE_INFLUXDB_FETCH_TASK_LOG_MAX_SIZE:5000} # the max number of fetch task log in a request\n+  mysql:\n+    properties:\n+      jdbcUrl: ${SW_JDBC_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n+      dataSource.user: ${SW_DATA_SOURCE_USER:root}\n+      dataSource.password: ${SW_DATA_SOURCE_PASSWORD:root@1234}\n+      dataSource.cachePrepStmts: ${SW_DATA_SOURCE_CACHE_PREP_STMTS:true}\n+      dataSource.prepStmtCacheSize: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_SIZE:250}\n+      dataSource.prepStmtCacheSqlLimit: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n+      dataSource.useServerPrepStmts: ${SW_DATA_SOURCE_USE_SERVER_PREP_STMTS:true}\n+    metadataQueryMaxSize: ${SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000}\n+  influxdb:\n+    # Metadata storage provider configuration\n+    metabaseType: ${SW_STORAGE_METABASE_TYPE:H2} # There are 2 options as Metabase provider, H2 or MySQL.\n+    h2Props:\n+      dataSourceClassName: ${SW_STORAGE_METABASE_DRIVER:org.h2.jdbcx.JdbcDataSource}\n+      dataSource.url: ${SW_STORAGE_METABASE_URL:jdbc:h2:mem:skywalking-oap-db}\n+      dataSource.user: ${SW_STORAGE_METABASE_USER:sa}\n+      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:}\n+    mysqlProps:\n+      jdbcUrl: ${SW_STORAGE_METABASE_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n+      dataSource.user: ${SW_STORAGE_METABASE_USER:root}\n+      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:root@1234}\n+      dataSource.cachePrepStmts: ${SW_STORAGE_METABASE_CACHE_PREP_STMTS:true}\n+      dataSource.prepStmtCacheSize: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_SIZE:250}\n+      dataSource.prepStmtCacheSqlLimit: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n+      dataSource.useServerPrepStmts: ${SW_STORAGE_METABASE_USE_SERVER_PREP_STMTS:true}\n+    metadataQueryMaxSize: ${SW_STORAGE_METABASE_QUERY_MAX_SIZE:5000}\n+    # InfluxDB configuration\n+    url: ${SW_STORAGE_INFLUXDB_URL:http://localhost:8086}\n+    user: ${SW_STORAGE_INFLUXDB_USER:root}\n+    password: ${SW_STORAGE_INFLUXDB_PASSWORD:}\n+    database: ${SW_STORAGE_INFLUXDB_DATABASE:skywalking}\n+    actions: ${SW_STORAGE_INFLUXDB_ACTIONS:1000} # the number of actions to collect\n+    duration: ${SW_STORAGE_INFLUXDB_DURATION:1000} # the time to wait at most (milliseconds)\n+    fetchTaskLogMaxSize: ${SW_STORAGE_INFLUXDB_FETCH_TASK_LOG_MAX_SIZE:5000} # the max number of fetch task log in a request\n+\n receiver-sharing-server:\n+  selector: ${SW_RECEIVER_SHARING_SERVER:default}\n   default:\n+    authentication: ${SW_AUTHENTICATION:\"\"}\n receiver-register:\n+  selector: ${SW_RECEIVER_REGISTER:default}\n   default:\n+\n receiver-trace:\n+  selector: ${SW_RECEIVER_TRACE:default}\n   default:\n     bufferPath: ${SW_RECEIVER_BUFFER_PATH:../trace-buffer/}  # Path to trace buffer files, suggest to use absolute path\n     bufferOffsetMaxFileSize: ${SW_RECEIVER_BUFFER_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n     bufferDataMaxFileSize: ${SW_RECEIVER_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n     bufferFileCleanWhenRestart: ${SW_RECEIVER_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n     sampleRate: ${SW_TRACE_SAMPLE_RATE:10000} # The sample rate precision is 1/10000. 10000 means 100% sample in default.\n     slowDBAccessThreshold: ${SW_SLOW_DB_THRESHOLD:default:200,mongodb:100} # The slow database access thresholds. Unit ms.\n+\n receiver-jvm:\n+  selector: ${SW_RECEIVER_JVM:default}\n   default:\n+\n receiver-clr:\n+  selector: ${SW_RECEIVER_CLR:default}\n   default:\n+\n receiver-profile:\n+  selector: ${SW_RECEIVER_PROFILE:default}\n   default:\n+\n service-mesh:\n+  selector: ${SW_SERVICE_MESH:default}\n   default:\n     bufferPath: ${SW_SERVICE_MESH_BUFFER_PATH:../mesh-buffer/}  # Path to trace buffer files, suggest to use absolute path\n     bufferOffsetMaxFileSize: ${SW_SERVICE_MESH_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n     bufferDataMaxFileSize: ${SW_SERVICE_MESH_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n     bufferFileCleanWhenRestart: ${SW_SERVICE_MESH_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n+\n istio-telemetry:\n+  selector: ${SW_ISTIO_TELEMETRY:default}\n   default:\n+\n envoy-metric:\n+  selector: ${SW_ENVOY_METRIC:default}\n   default:\n-#    alsHTTPAnalysis: ${SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS:k8s-mesh}\n-#receiver_zipkin:\n-#  default:\n-#    host: ${SW_RECEIVER_ZIPKIN_HOST:0.0.0.0}\n-#    port: ${SW_RECEIVER_ZIPKIN_PORT:9411}\n-#    contextPath: ${SW_RECEIVER_ZIPKIN_CONTEXT_PATH:/}\n+    alsHTTPAnalysis: ${SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS:none}\n+\n+receiver_zipkin:\n+  selector: ${SW_RECEIVER_ZIPKIN:none}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY0ODg4Ng=="}, "originalCommit": null, "originalPosition": 312}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY1NDMzOA==", "bodyText": "This fails because some module request cluster module in the bootstrap stage, if not, then this error wouldn't show up. My point is, this should be a check rule.", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392654338", "createdAt": "2020-03-15T09:00:44Z", "author": {"login": "wu-sheng"}, "path": "dist-material/application.yml", "diffHunk": "@@ -83,180 +85,230 @@ core:\n     # and it will cause more load for memory, network of OAP and storage.\n     # But, being activated, user could see the name in the storage entities, which make users easier to use 3rd party tool, such as Kibana->ES, to query the data by themselves.\n     activeExtraModelColumns: ${SW_CORE_ACTIVE_EXTRA_MODEL_COLUMNS:false}\n+\n storage:\n-#  elasticsearch:\n-#    nameSpace: ${SW_NAMESPACE:\"\"}\n-#    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n-#    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n-#    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n-#    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n-#    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n-#    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n-#    user: ${SW_ES_USER:\"\"}\n-#    password: ${SW_ES_PASSWORD:\"\"}\n-#    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n-#    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n-#    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n-#    # Those data TTL settings will override the same settings in core module.\n-#    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n-#    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n-#    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-#    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n-#    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n-#    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n-#    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n-#    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n-#    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n-#    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n-#    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n-#  elasticsearch7:\n-#    nameSpace: ${SW_NAMESPACE:\"\"}\n-#    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n-#    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n-#    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n-#    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n-#    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n-#    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n-#    user: ${SW_ES_USER:\"\"}\n-#    password: ${SW_ES_PASSWORD:\"\"}\n-#    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n-#    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n-#    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n-#    # Those data TTL settings will override the same settings in core module.\n-#    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n-#    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n-#    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-#    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n-#    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n-#    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n-#    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n-#    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n-#    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n-#    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n-#    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n+  selector: ${SW_STORAGE:h2}\n+  elasticsearch:\n+    nameSpace: ${SW_NAMESPACE:\"\"}\n+    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n+    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n+    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n+    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n+    user: ${SW_ES_USER:\"\"}\n+    password: ${SW_ES_PASSWORD:\"\"}\n+    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n+    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n+    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n+    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n+    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n+    # Those data TTL settings will override the same settings in core module.\n+    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n+    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n+    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n+    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n+    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n+    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n+    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n+    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n+    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n+    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n+    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n+    advanced: ${SW_STORAGE_ES_ADVANCED:\"\"}\n+  elasticsearch7:\n+    nameSpace: ${SW_NAMESPACE:\"\"}\n+    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n+    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n+    trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"}\n+    trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"\"}\n+    enablePackedDownsampling: ${SW_STORAGE_ENABLE_PACKED_DOWNSAMPLING:true} # Hour and Day metrics will be merged into minute index.\n+    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.\n+    user: ${SW_ES_USER:\"\"}\n+    password: ${SW_ES_PASSWORD:\"\"}\n+    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.\n+    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n+    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n+    # Those data TTL settings will override the same settings in core module.\n+    recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n+    otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n+    monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n+    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n+    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests\n+    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n+    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n+    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n+    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n+    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n+    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}\n+    advanced: ${SW_STORAGE_ES_ADVANCED:\"\"}\n   h2:\n     driver: ${SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource}\n     url: ${SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db}\n     user: ${SW_STORAGE_H2_USER:sa}\n     metadataQueryMaxSize: ${SW_STORAGE_H2_QUERY_MAX_SIZE:5000}\n-#  mysql:\n-#    properties:\n-#      jdbcUrl: ${SW_JDBC_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n-#      dataSource.user: ${SW_DATA_SOURCE_USER:root}\n-#      dataSource.password: ${SW_DATA_SOURCE_PASSWORD:root@1234}\n-#      dataSource.cachePrepStmts: ${SW_DATA_SOURCE_CACHE_PREP_STMTS:true}\n-#      dataSource.prepStmtCacheSize: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_SIZE:250}\n-#      dataSource.prepStmtCacheSqlLimit: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n-#      dataSource.useServerPrepStmts: ${SW_DATA_SOURCE_USE_SERVER_PREP_STMTS:true}\n-#    metadataQueryMaxSize: ${SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000}\n-#  influx:\n-#    # Metadata storage provider configuration\n-#    metabaseType: ${SW_STORAGE_METABASE_TYPE:H2} # There are 2 options as Metabase provider, H2 or MySQL.\n-#    h2Props:\n-#      dataSourceClassName: ${SW_STORAGE_METABASE_DRIVER:org.h2.jdbcx.JdbcDataSource}\n-#      dataSource.url: ${SW_STORAGE_METABASE_URL:jdbc:h2:mem:skywalking-oap-db}\n-#      dataSource.user: ${SW_STORAGE_METABASE_USER:sa}\n-#      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:}\n-#    mysqlProps:\n-#      jdbcUrl: ${SW_STORAGE_METABASE_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n-#      dataSource.user: ${SW_STORAGE_METABASE_USER:root}\n-#      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:root@1234}\n-#      dataSource.cachePrepStmts: ${SW_STORAGE_METABASE_CACHE_PREP_STMTS:true}\n-#      dataSource.prepStmtCacheSize: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_SIZE:250}\n-#      dataSource.prepStmtCacheSqlLimit: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n-#      dataSource.useServerPrepStmts: ${SW_STORAGE_METABASE_USE_SERVER_PREP_STMTS:true}\n-#    metadataQueryMaxSize: ${SW_STORAGE_METABASE_QUERY_MAX_SIZE:5000}\n-#    # InfluxDB configuration\n-#    url: ${SW_STORAGE_INFLUXDB_URL:http://localhost:8086}\n-#    user: ${SW_STORAGE_INFLUXDB_USER:root}\n-#    password: ${SW_STORAGE_INFLUXDB_PASSWORD:}\n-#    database: ${SW_STORAGE_INFLUXDB_DATABASE:skywalking}\n-#    actions: ${SW_STORAGE_INFLUXDB_ACTIONS:1000} # the number of actions to collect\n-#    duration: ${SW_STORAGE_INFLUXDB_DURATION:1000} # the time to wait at most (milliseconds)\n-#    fetchTaskLogMaxSize: ${SW_STORAGE_INFLUXDB_FETCH_TASK_LOG_MAX_SIZE:5000} # the max number of fetch task log in a request\n+  mysql:\n+    properties:\n+      jdbcUrl: ${SW_JDBC_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n+      dataSource.user: ${SW_DATA_SOURCE_USER:root}\n+      dataSource.password: ${SW_DATA_SOURCE_PASSWORD:root@1234}\n+      dataSource.cachePrepStmts: ${SW_DATA_SOURCE_CACHE_PREP_STMTS:true}\n+      dataSource.prepStmtCacheSize: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_SIZE:250}\n+      dataSource.prepStmtCacheSqlLimit: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n+      dataSource.useServerPrepStmts: ${SW_DATA_SOURCE_USE_SERVER_PREP_STMTS:true}\n+    metadataQueryMaxSize: ${SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000}\n+  influxdb:\n+    # Metadata storage provider configuration\n+    metabaseType: ${SW_STORAGE_METABASE_TYPE:H2} # There are 2 options as Metabase provider, H2 or MySQL.\n+    h2Props:\n+      dataSourceClassName: ${SW_STORAGE_METABASE_DRIVER:org.h2.jdbcx.JdbcDataSource}\n+      dataSource.url: ${SW_STORAGE_METABASE_URL:jdbc:h2:mem:skywalking-oap-db}\n+      dataSource.user: ${SW_STORAGE_METABASE_USER:sa}\n+      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:}\n+    mysqlProps:\n+      jdbcUrl: ${SW_STORAGE_METABASE_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n+      dataSource.user: ${SW_STORAGE_METABASE_USER:root}\n+      dataSource.password: ${SW_STORAGE_METABASE_PASSWORD:root@1234}\n+      dataSource.cachePrepStmts: ${SW_STORAGE_METABASE_CACHE_PREP_STMTS:true}\n+      dataSource.prepStmtCacheSize: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_SIZE:250}\n+      dataSource.prepStmtCacheSqlLimit: ${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n+      dataSource.useServerPrepStmts: ${SW_STORAGE_METABASE_USE_SERVER_PREP_STMTS:true}\n+    metadataQueryMaxSize: ${SW_STORAGE_METABASE_QUERY_MAX_SIZE:5000}\n+    # InfluxDB configuration\n+    url: ${SW_STORAGE_INFLUXDB_URL:http://localhost:8086}\n+    user: ${SW_STORAGE_INFLUXDB_USER:root}\n+    password: ${SW_STORAGE_INFLUXDB_PASSWORD:}\n+    database: ${SW_STORAGE_INFLUXDB_DATABASE:skywalking}\n+    actions: ${SW_STORAGE_INFLUXDB_ACTIONS:1000} # the number of actions to collect\n+    duration: ${SW_STORAGE_INFLUXDB_DURATION:1000} # the time to wait at most (milliseconds)\n+    fetchTaskLogMaxSize: ${SW_STORAGE_INFLUXDB_FETCH_TASK_LOG_MAX_SIZE:5000} # the max number of fetch task log in a request\n+\n receiver-sharing-server:\n+  selector: ${SW_RECEIVER_SHARING_SERVER:default}\n   default:\n+    authentication: ${SW_AUTHENTICATION:\"\"}\n receiver-register:\n+  selector: ${SW_RECEIVER_REGISTER:default}\n   default:\n+\n receiver-trace:\n+  selector: ${SW_RECEIVER_TRACE:default}\n   default:\n     bufferPath: ${SW_RECEIVER_BUFFER_PATH:../trace-buffer/}  # Path to trace buffer files, suggest to use absolute path\n     bufferOffsetMaxFileSize: ${SW_RECEIVER_BUFFER_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n     bufferDataMaxFileSize: ${SW_RECEIVER_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n     bufferFileCleanWhenRestart: ${SW_RECEIVER_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n     sampleRate: ${SW_TRACE_SAMPLE_RATE:10000} # The sample rate precision is 1/10000. 10000 means 100% sample in default.\n     slowDBAccessThreshold: ${SW_SLOW_DB_THRESHOLD:default:200,mongodb:100} # The slow database access thresholds. Unit ms.\n+\n receiver-jvm:\n+  selector: ${SW_RECEIVER_JVM:default}\n   default:\n+\n receiver-clr:\n+  selector: ${SW_RECEIVER_CLR:default}\n   default:\n+\n receiver-profile:\n+  selector: ${SW_RECEIVER_PROFILE:default}\n   default:\n+\n service-mesh:\n+  selector: ${SW_SERVICE_MESH:default}\n   default:\n     bufferPath: ${SW_SERVICE_MESH_BUFFER_PATH:../mesh-buffer/}  # Path to trace buffer files, suggest to use absolute path\n     bufferOffsetMaxFileSize: ${SW_SERVICE_MESH_OFFSET_MAX_FILE_SIZE:100} # Unit is MB\n     bufferDataMaxFileSize: ${SW_SERVICE_MESH_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB\n     bufferFileCleanWhenRestart: ${SW_SERVICE_MESH_BUFFER_FILE_CLEAN_WHEN_RESTART:false}\n+\n istio-telemetry:\n+  selector: ${SW_ISTIO_TELEMETRY:default}\n   default:\n+\n envoy-metric:\n+  selector: ${SW_ENVOY_METRIC:default}\n   default:\n-#    alsHTTPAnalysis: ${SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS:k8s-mesh}\n-#receiver_zipkin:\n-#  default:\n-#    host: ${SW_RECEIVER_ZIPKIN_HOST:0.0.0.0}\n-#    port: ${SW_RECEIVER_ZIPKIN_PORT:9411}\n-#    contextPath: ${SW_RECEIVER_ZIPKIN_CONTEXT_PATH:/}\n+    alsHTTPAnalysis: ${SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS:none}\n+\n+receiver_zipkin:\n+  selector: ${SW_RECEIVER_ZIPKIN:none}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY0ODg4Ng=="}, "originalCommit": null, "originalPosition": 312}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMzc2NzM3OnYy", "diffSide": "RIGHT", "path": "oap-server/server-bootstrap/src/main/java/org/apache/skywalking/oap/server/starter/config/ApplicationConfigLoader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwOTowMjoyMlrOF2duZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwOTowMjoyMlrOF2duZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY1NDQzNg==", "bodyText": "@kezhenxu94 To be more clear,  after this remove, it could be no provider available, we should check and report error immidiately.", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392654436", "createdAt": "2020-03-15T09:02:22Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-bootstrap/src/main/java/org/apache/skywalking/oap/server/starter/config/ApplicationConfigLoader.java", "diffHunk": "@@ -105,6 +109,26 @@ private void overrideConfigBySystemEnv(ApplicationConfiguration configuration) {\n         }\n     }\n \n+    private void selectConfig(final Map<String, Map<String, Object>> moduleConfiguration) {\n+        final Set<String> modulesWithoutProvider = new HashSet<>();\n+        for (final Map.Entry<String, Map<String, Object>> entry : moduleConfiguration.entrySet()) {\n+            final String moduleName = entry.getKey();\n+            final Map<String, Object> providerConfig = entry.getValue();\n+            if (providerConfig.containsKey(\"selector\")) {\n+                final String selector = (String) providerConfig.get(\"selector\");\n+                final String resolvedSelector = PropertyPlaceholderHelper.INSTANCE.replacePlaceholders(\n+                    selector, System.getProperties()\n+                );\n+                providerConfig.entrySet().removeIf(e -> !resolvedSelector.equals(e.getKey()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMzg0NzQ2OnYy", "diffSide": "LEFT", "path": "docker/oap-es7/docker-entrypoint.sh", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQxMTozOToyM1rOF2eZKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQxMTozOToyM1rOF2eZKQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY2NTM4NQ==", "bodyText": "FYI @wu-sheng and @hanahmily , here is another bug in the Docker image, with this, the docker image for es7 never works", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392665385", "createdAt": "2020-03-15T11:39:23Z", "author": {"login": "kezhenxu94"}, "path": "docker/oap-es7/docker-entrypoint.sh", "diffHunk": "@@ -18,478 +18,18 @@\n \n set -e\n \n-var_application_file=\"config/application.yml\"\n-\n-generateClusterStandalone() {\n-    echo \"cluster:\" >> ${var_application_file}\n-    echo \"  standalone:\" >> ${var_application_file}\n-}\n-\n-generateClusterZookeeper() {\n-    cat <<EOT >> ${var_application_file}\n-cluster:\n-  zookeeper:\n-    nameSpace: \\${SW_NAMESPACE:\"\"}\n-    hostPort: \\${SW_CLUSTER_ZK_HOST_PORT:zookeeper:2181}\n-    #Retry Policy\n-    baseSleepTimeMs: \\${SW_CLUSTER_ZK_SLEEP_TIME:1000} # initial amount of time to wait between retries\n-    maxRetries: \\${SW_CLUSTER_ZK_MAX_RETRIES:3} # max number of times to retry\n-    # Enable ACL\n-    enableACL: \\${SW_ZK_ENABLE_ACL:false} # disable ACL in default\n-    schema: \\${SW_ZK_SCHEMA:digest} # only support digest schema\n-    expression: \\${SW_ZK_EXPRESSION:skywalking:skywalking}\n-EOT\n-}\n-\n-generateClusterK8s() {\n-    cat <<EOT >> ${var_application_file}\n-cluster:\n-  kubernetes:\n-    watchTimeoutSeconds: \\${SW_CLUSTER_K8S_WATCH_TIMEOUT:60}\n-    namespace: \\${SW_CLUSTER_K8S_NAMESPACE:default}\n-    labelSelector: \\${SW_CLUSTER_K8S_LABEL:app=collector,release=skywalking}\n-    uidEnvName: \\${SW_CLUSTER_K8S_UID:SKYWALKING_COLLECTOR_UID}\n-EOT\n-}\n-\n-generateClusterConsul() {\n-     cat <<EOT >> ${var_application_file}\n-cluster:\n-  consul:\n-    serviceName: \\${SW_SERVICE_NAME:\"SkyWalking_OAP_Cluster\"}\n-    # Consul cluster nodes, example: 10.0.0.1:8500,10.0.0.2:8500,10.0.0.3:8500\n-    hostPort: \\${SW_CLUSTER_CONSUL_HOST_PORT:consul:8500}\n-EOT\n-}\n-\n-generateClusterEtcd() {\n-    cat <<EOT >> ${var_application_file}\n-cluster:\n-  etcd:\n-    serviceName: \\${SW_SERVICE_NAME:\"SkyWalking_OAP_Cluster\"}\n-    # Etcd cluster nodes, example: 10.0.0.1:2379,10.0.0.2:2379,10.0.0.3:2379\n-    hostPort: \\${SW_CLUSTER_ETCD_HOST_PORT:etcd:2379}\n-EOT\n-}\n-\n-generateClusterNacos() {\n-    cat <<EOT >> ${var_application_file}\n-cluster:\n-  nacos:\n-    serviceName: \\${SW_SERVICE_NAME:\"SkyWalking_OAP_Cluster\"}\n-    namespace: \\${SW_CLUSTER_NACOS_NAMESPACE:\"\"}\n-    hostPort: \\${SW_CLUSTER_NACOS_HOST_PORT:nacos:8848}\n-EOT\n-}\n+echo \"[Entrypoint] Apache SkyWalking Docker Image\"\n \n-generateStorageElastisearch() {\n-if [[ \"$SW_RECEIVER_ZIPKIN_ENABLED\" = \"true\" ]]; then\n-    cat <<EOT >> ${var_application_file}\n-storage:\n-  zipkin-elasticsearch:\n-EOT\n-elif [[ \"$SW_RECEIVER_JAEGER_ENABLED\" = \"true\" ]]; then\n-    cat <<EOT >> ${var_application_file}\n-storage:\n-  jaeger-elasticsearch:\n-EOT\n-else\n-    cat <<EOT >> ${var_application_file}\n-storage:\n-  elasticsearch7:\n-EOT\n+if [[ \"$SW_TELEMETRY\" = \"so11y\" ]]; then\n+    export SW_RECEIVER_SO11Y=default\n+    echo \"Set SW_RECEIVER_SO11Y to ${SW_RECEIVER_SO11Y}\"\n fi\n-cat <<EOT >> ${var_application_file}\n-    nameSpace: \\${SW_NAMESPACE:\"\"}\n-    clusterNodes: \\${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}\n-    protocol: \\${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"}\n-    user: \\${SW_ES_USER:\"\"}\n-    password: \\${SW_ES_PASSWORD:\"\"}\n-    indexShardsNumber: \\${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}\n-    indexReplicasNumber: \\${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}\n-    # Those data TTL settings will override the same settings in core module.\n-    recordDataTTL: \\${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day\n-    otherMetricsDataTTL: \\${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day\n-    monthMetricsDataTTL: \\${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month\n-    # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html\n-    bulkActions: \\${SW_STORAGE_ES_BULK_ACTIONS:2000} # Execute the bulk every 2000 requests\n-    bulkSize: \\${SW_STORAGE_ES_BULK_SIZE:20} # flush the bulk every 20mb\n-    flushInterval: \\${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests\n-    concurrentRequests: \\${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests\n-    resultWindowMaxSize: \\${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}\n-    metadataQueryMaxSize: \\${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}\n-    segmentQueryMaxSize: \\${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}\n-EOT\n-}\n-\n-generateStorageH2() {\n-    cat <<EOT >> ${var_application_file}\n-storage:\n-  h2:\n-    driver: \\${SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource}\n-    url: \\${SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db}\n-    user: \\${SW_STORAGE_H2_USER:sa}\n-    metadataQueryMaxSize: \\${SW_STORAGE_H2_QUERY_MAX_SIZE:5000}\n-EOT\n-}\n-\n-generateStorageMySQL() {\n-    cat <<EOT >> ${var_application_file}\n-storage:\n-  mysql:\n-    properties:\n-        jdbcUrl: ${SW_JDBC_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n-        dataSource.user: ${SW_DATA_SOURCE_USER:root}\n-        dataSource.password: ${SW_DATA_SOURCE_PASSWORD:root@1234}\n-        dataSource.cachePrepStmts: ${SW_DATA_SOURCE_CACHE_PREP_STMTS:true}\n-        dataSource.prepStmtCacheSize: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_SIZE:250}\n-        dataSource.prepStmtCacheSqlLimit: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n-        dataSource.useServerPrepStmts: ${SW_DATA_SOURCE_USE_SERVER_PREP_STMTS:true}\n-    metadataQueryMaxSize: \\${SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000}\n-EOT\n-}\n-\n-generateStorageInfluxDB() {\n-    cat <<EOT >> ${var_application_file}\n-storage:\n-  influx:\n-    # Metadata storage provider configuration\n-    metabaseType: \\${SW_STORAGE_METABASE_TYPE:H2} # There are 2 options as Metabase provider, H2 or MySQL.\n-    h2Props:\n-      dataSourceClassName: \\${SW_STORAGE_METABASE_DRIVER:org.h2.jdbcx.JdbcDataSource}\n-      dataSource.url: \\${SW_STORAGE_METABASE_URL:jdbc:h2:mem:skywalking-oap-db}\n-      dataSource.user: \\${SW_STORAGE_METABASE_USER:sa}\n-      dataSource.password: \\${SW_STORAGE_METABASE_PASSWORD:}\n-    mysqlProps:\n-      jdbcUrl: \\${SW_STORAGE_METABASE_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n-      dataSource.user: \\${SW_STORAGE_METABASE_USER:root}\n-      dataSource.password: \\${SW_STORAGE_METABASE_PASSWORD:root@1234}\n-      dataSource.cachePrepStmts: \\${SW_STORAGE_METABASE_CACHE_PREP_STMTS:true}\n-      dataSource.prepStmtCacheSize: \\${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_SIZE:250}\n-      dataSource.prepStmtCacheSqlLimit: \\${SW_STORAGE_METABASE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n-      dataSource.useServerPrepStmts: \\${SW_STORAGE_METABASE_USE_SERVER_PREP_STMTS:true}\n-    metadataQueryMaxSize: \\${SW_STORAGE_METABASE_QUERY_MAX_SIZE:5000}\n-    # InfluxDB configuration\n-    url: \\${SW_STORAGE_INFLUXDB_URL:http://localhost:8086}\n-    user: \\${SW_STORAGE_INFLUXDB_USER:root}\n-    password: \\${SW_STORAGE_INFLUXDB_PASSWORD:}\n-    database: \\${SW_STORAGE_INFLUXDB_DATABASE:skywalking}\n-    actions: \\${SW_STORAGE_INFLUXDB_ACTIONS:1000} # the number of actions to collect\n-    duration: \\${SW_STORAGE_INFLUXDB_DURATION:1000} # the time to wait at most (milliseconds)\n-    fetchTaskLogMaxSize: \\${SW_STORAGE_INFLUXDB_FETCH_TASK_LOG_MAX_SIZE:5000} # the max number of fetch task log in a request\n-EOT\n-}\n-\n-generateConfigurationNone() {\n-    cat <<EOT >> ${var_application_file}\n-configuration:\n-  none:\n-EOT\n-}\n-\n-generateConfigurationApollo() {\n-    cat <<EOT >> ${var_application_file}\n-configuration:\n-  apollo:\n-    apolloMeta: \\${SW_CONFIGURATION_APOLLO_META:http://apollo:8080}\n-    apolloCluster: \\${SW_CONFIGURATION_APOLLO_CLUSTER:default}\n-    apolloEnv: \\${SW_CONFIGURATION_APOLLO_ENV:\"\"}\n-    appId: \\${SW_CONFIGURATION_APOLLO_APP_ID:skywalking}\n-    period: \\${SW_CONFIGURATION_APOLLO_PERIOD:5}\n-EOT\n-}\n-\n-generateConfigurationNacos() {\n-    cat <<EOT >> ${var_application_file}\n-configuration:\n-  nacos:\n-    # Nacos Server Host\n-    serverAddr: \\${SW_CONFIGURATION_NACOS_SERVER_ADDR:nacos}\n-    # Nacos Server Port\n-    port: \\${SW_CONFIGURATION_NACOS_PORT:8848}\n-    # Nacos Configuration Group\n-    group: \\${SW_CONFIGURATION_NACOS_GROUP:skywalking}\n-    # Nacos Configuration namespace\n-    namespace: \\${SW_CONFIGURATION_NACOS_NAMESPACE:\"\"}\n-    # Unit seconds, sync period. Default fetch every 60 seconds.\n-    period : \\${SW_CONFIGURATION_NACOS_PERIOD:5}\n-    # the name of current cluster, set the name if you want to upstream system known.\n-    clusterName: \\${SW_CONFIGURATION_NACOS_CLUSTER_NAME:default}\n-EOT\n-}\n-\n-generateConfigurationZookeeper() {\n-    cat <<EOT >> ${var_application_file}\n-configuration:\n-  zookeeper:\n-    period: \\${SW_CONFIGURATION_ZOOKEEPER_PERIOD:60} # Unit seconds, sync period. Default fetch every 60 seconds.\n-    nameSpace: \\${SW_CONFIGURATION_ZOOKEEPER_NAMESPACE:/default}\n-    hostPort: \\${SW_CONFIGURATION_ZOOKEEPER_HOST_PATH:localhost:2181}\n-    #Retry Policy\n-    baseSleepTimeMs: \\${SW_CONFIGURATION_ZOOKEEPER_BASE_SLEEP_TIME_MS:1000} # initial amount of time to wait between retries\n-    maxRetries: \\${SW_CONFIGURATION_ZOOKEEPER_MAX_RETRIES:3}3 # max number of times to retry\n-EOT\n-}\n-\n-generateConfigurationGRPC() {\n-    cat <<EOT >> ${var_application_file}\n-configuration:\n-  grpc:\n-    host: \\${SW_CONFIGURATION_GRPC_HOST:127.0.0.1}\n-    port: \\${SW_CONFIGURATION_GRPC_PORT:9555}\n-    period: \\${SW_CONFIGURATION_GRPC_PERIOD:60}\n-    clusterName: \\${SW_CONFIGURATION_GRPC_CLUSTER_NAME:\"default\"}\n-EOT\n-}\n-\n-generateConfigurationConsul() {\n-    cat <<EOT >> ${var_application_file}\n-configuration:\n-  consul:\n-    # Consul host and ports, separated by comma, e.g. 1.2.3.4:8500,2.3.4.5:8500\n-    hostAndPorts: \\${SW_CONFIGURATION_CONSUL_ADDRESS:127.0.0.1:8500}\n-    # Sync period in seconds. Defaults to 60 seconds.\n-    period: \\${SW_CONFIGURATION_CONSUL_PERIOD:60}\n-EOT\n-}\n-\n-generateTelemetryNone() {\n-    cat <<EOT >> ${var_application_file}\n-telemetry:\n-  none:\n-EOT\n-}\n-\n-generateTelemetryPrometheus() {\n-    cat <<EOT >> ${var_application_file}\n-telemetry:\n-  prometheus:\n-    host: \\${SW_TELEMETRY_PROMETHEUS_HOST:0.0.0.0}\n-    port: \\${SW_TELEMETRY_PROMETHEUS_PORT:1234}\n-EOT\n-}\n-\n-generateTelemetrySo11y() {\n-    cat <<EOT >> ${var_application_file}\n-telemetry:\n-  so11y:\n-    prometheusExporterEnabled: \\${SW_TELEMETRY_SO11Y_PROMETHEUS_ENABLED:true}\n-    prometheusExporterHost: \\${SW_TELEMETRY_PROMETHEUS_HOST:0.0.0.0}\n-    prometheusExporterPort: \\${SW_TELEMETRY_PROMETHEUS_PORT:1234}\n-EOT\n-}\n-\n-validateVariables() {\n-    name=$1; value=$2; list=$3\n-    valid=false\n-    for c in ${list} ; do\n-        if [[ \"$c\" = \"$value\" ]]; then\n-            valid=true\n-        fi\n-    done\n \n-    if ! ${valid}; then\n-        echo \"Error: $name=$value please specify $name = $list\"\n-        exit 1\n-    fi\n-}\n-\n-generateApplicationYaml() {\n-    # validate\n-    [[ -z \"$SW_CLUSTER\" ]] && [[ -z \"$SW_STORAGE\" ]] && [[ -z \"$SW_CONFIGURATION\" ]] \\\n-        && [[ -z \"$SW_TELEMETRY\" ]] \\\n-        && { echo \"Error: please specify \\\"SW_CLUSTER\\\" \\\"SW_STORAGE\\\" \\\"SW_CONFIGURATION\\\" \\\"SW_TELEMETRY\\\"\"; exit 1; }\n-\n-    validateVariables \"SW_CLUSTER\" \"$SW_CLUSTER\" \"standalone zookeeper kubernetes consul etcd nacos\"\n-\n-    validateVariables \"SW_STORAGE\" \"$SW_STORAGE\" \"elasticsearch h2 mysql influxdb\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 292}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMzg3ODEzOnYy", "diffSide": "RIGHT", "path": "docs/en/setup/backend/backend-setup.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQxMjozNTo1MFrOF2epzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQxMjozNTo1MFrOF2epzQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY2OTY0NQ==", "bodyText": "I think we also should indicate selector is optional if there is only one provider.", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392669645", "createdAt": "2020-03-15T12:35:50Z", "author": {"login": "wu-sheng"}, "path": "docs/en/setup/backend/backend-setup.md", "diffHunk": "@@ -14,26 +14,41 @@ End user can switch or assemble the collector features by their own requirements\n \n So, in `application.yml`, there are three levels.\n 1. **Level 1**, module name. Meaning this module is active in running mode.\n-1. **Level 2**, provider name. Set the provider of the module.\n+1. **Level 2**, provider name and provider selector. Available providers are listed here with a selector to indicate which one will actually take effect.\n 1. **Level 3**. settings of the provider.\n \n Example:\n+\n ```yaml\n-core:\n-  default:\n-    restHost: 0.0.0.0\n-    restPort: 12800\n-    restContextPath: /\n-    gRPCHost: 0.0.0.0\n-    gRPCPort: 11800\n+storage:\n+  selector: mysql # the mysql storage will actually be activated, while the h2 storage takes no effect\n+  h2:\n+    driver: ${SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource}\n+    url: ${SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db}\n+    user: ${SW_STORAGE_H2_USER:sa}\n+    metadataQueryMaxSize: ${SW_STORAGE_H2_QUERY_MAX_SIZE:5000}\n+  mysql:\n+    properties:\n+      jdbcUrl: ${SW_JDBC_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n+      dataSource.user: ${SW_DATA_SOURCE_USER:root}\n+      dataSource.password: ${SW_DATA_SOURCE_PASSWORD:root@1234}\n+      dataSource.cachePrepStmts: ${SW_DATA_SOURCE_CACHE_PREP_STMTS:true}\n+      dataSource.prepStmtCacheSize: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_SIZE:250}\n+      dataSource.prepStmtCacheSqlLimit: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n+      dataSource.useServerPrepStmts: ${SW_DATA_SOURCE_USE_SERVER_PREP_STMTS:true}\n+    metadataQueryMaxSize: ${SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000}\n+  # other configurations\n ```\n-1. **core** is the module.\n-1. **default** is the default implementor of core module.\n-1. `restHost`, `restPort`, ... `gRPCHost` are all setting items of the implementor.\n+\n+1. **`core`** is the module.\n+1. **`selector`** selects one out of the all providers listed below, the unselected ones take no effect as if they were deleted.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMzg4MDgxOnYy", "diffSide": "RIGHT", "path": "docs/en/setup/backend/backend-setup.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQxMjo0MDo0NlrOF2erOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQxMjo0MDo0NlrOF2erOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY3MDAxMQ==", "bodyText": "if there is provider called none, you can simply set it to the selectorto disable it, otherwise, please set- to the selector\n->\nSome modules have a provider implementation called none, meaning it only provides a shell with no actual logic, typically such as telemetry.\nSet - to the selector means this whole module will be excluded in the runtime.", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392670011", "createdAt": "2020-03-15T12:40:46Z", "author": {"login": "wu-sheng"}, "path": "docs/en/setup/backend/backend-setup.md", "diffHunk": "@@ -14,26 +14,41 @@ End user can switch or assemble the collector features by their own requirements\n \n So, in `application.yml`, there are three levels.\n 1. **Level 1**, module name. Meaning this module is active in running mode.\n-1. **Level 2**, provider name. Set the provider of the module.\n+1. **Level 2**, provider name and provider selector. Available providers are listed here with a selector to indicate which one will actually take effect.\n 1. **Level 3**. settings of the provider.\n \n Example:\n+\n ```yaml\n-core:\n-  default:\n-    restHost: 0.0.0.0\n-    restPort: 12800\n-    restContextPath: /\n-    gRPCHost: 0.0.0.0\n-    gRPCPort: 11800\n+storage:\n+  selector: mysql # the mysql storage will actually be activated, while the h2 storage takes no effect\n+  h2:\n+    driver: ${SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource}\n+    url: ${SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db}\n+    user: ${SW_STORAGE_H2_USER:sa}\n+    metadataQueryMaxSize: ${SW_STORAGE_H2_QUERY_MAX_SIZE:5000}\n+  mysql:\n+    properties:\n+      jdbcUrl: ${SW_JDBC_URL:\"jdbc:mysql://localhost:3306/swtest\"}\n+      dataSource.user: ${SW_DATA_SOURCE_USER:root}\n+      dataSource.password: ${SW_DATA_SOURCE_PASSWORD:root@1234}\n+      dataSource.cachePrepStmts: ${SW_DATA_SOURCE_CACHE_PREP_STMTS:true}\n+      dataSource.prepStmtCacheSize: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_SIZE:250}\n+      dataSource.prepStmtCacheSqlLimit: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_LIMIT:2048}\n+      dataSource.useServerPrepStmts: ${SW_DATA_SOURCE_USE_SERVER_PREP_STMTS:true}\n+    metadataQueryMaxSize: ${SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000}\n+  # other configurations\n ```\n-1. **core** is the module.\n-1. **default** is the default implementor of core module.\n-1. `restHost`, `restPort`, ... `gRPCHost` are all setting items of the implementor.\n+\n+1. **`core`** is the module.\n+1. **`selector`** selects one out of the all providers listed below, the unselected ones take no effect as if they were deleted.\n+1. **`default`** is the default implementor of core module.\n+1. `driver`, `url`, ... `metadataQueryMaxSize` are all setting items of the implementor.\n \n At the same time, modules includes required and optional, the required modules provide the skeleton of backend,\n-even modularization supported pluggable, remove those modules are meaningless. We highly recommend you don't try to\n-change APIs of those modules, unless you understand SkyWalking project and its codes very well.\n+even modularization supported pluggable, removing those modules are meaningless, for optional modules, if there is provider\n+called `none`, you can simply set it to the `selector` to disable it, otherwise, please set `-` to the selector.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMzg4MTQ1OnYy", "diffSide": "RIGHT", "path": "oap-server/server-bootstrap/src/main/java/org/apache/skywalking/oap/server/starter/config/ApplicationConfigLoader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQxMjo0MTozOVrOF2erkA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQxMjo0MTozOVrOF2erkA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY3MDA5Ng==", "bodyText": "This should be ProviderNotFoundException", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392670096", "createdAt": "2020-03-15T12:41:39Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-bootstrap/src/main/java/org/apache/skywalking/oap/server/starter/config/ApplicationConfigLoader.java", "diffHunk": "@@ -105,6 +112,48 @@ private void overrideConfigBySystemEnv(ApplicationConfiguration configuration) {\n         }\n     }\n \n+    private void selectConfig(final Map<String, Map<String, Object>> moduleConfiguration) {\n+        final Set<String> modulesWithoutProvider = new HashSet<>();\n+        for (final Map.Entry<String, Map<String, Object>> entry : moduleConfiguration.entrySet()) {\n+            final String moduleName = entry.getKey();\n+            final Map<String, Object> providerConfig = entry.getValue();\n+            if (!providerConfig.containsKey(SELECTOR)) {\n+                continue;\n+            }\n+            final String selector = (String) providerConfig.get(SELECTOR);\n+            final String resolvedSelector = PropertyPlaceholderHelper.INSTANCE.replacePlaceholders(\n+                selector, System.getProperties()\n+            );\n+            providerConfig.entrySet().removeIf(e -> !resolvedSelector.equals(e.getKey()));\n+\n+            if (!providerConfig.isEmpty()) {\n+                continue;\n+            }\n+\n+            if (!DISABLE_SELECTOR.equals(resolvedSelector)) {\n+                throw new RuntimeException(", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMzg4MTY0OnYy", "diffSide": "RIGHT", "path": "oap-server/server-bootstrap/src/main/java/org/apache/skywalking/oap/server/starter/config/ApplicationConfigLoader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQxMjo0MjoxOFrOF2ertg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQxMjo0MjoxOFrOF2ertg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY3MDEzNA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            logger.info(\"removing module {} without any provider\", module);\n          \n          \n            \n                            logger.info(\"Remove module {} without any provider\", module);", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392670134", "createdAt": "2020-03-15T12:42:18Z", "author": {"login": "wu-sheng"}, "path": "oap-server/server-bootstrap/src/main/java/org/apache/skywalking/oap/server/starter/config/ApplicationConfigLoader.java", "diffHunk": "@@ -105,6 +112,48 @@ private void overrideConfigBySystemEnv(ApplicationConfiguration configuration) {\n         }\n     }\n \n+    private void selectConfig(final Map<String, Map<String, Object>> moduleConfiguration) {\n+        final Set<String> modulesWithoutProvider = new HashSet<>();\n+        for (final Map.Entry<String, Map<String, Object>> entry : moduleConfiguration.entrySet()) {\n+            final String moduleName = entry.getKey();\n+            final Map<String, Object> providerConfig = entry.getValue();\n+            if (!providerConfig.containsKey(SELECTOR)) {\n+                continue;\n+            }\n+            final String selector = (String) providerConfig.get(SELECTOR);\n+            final String resolvedSelector = PropertyPlaceholderHelper.INSTANCE.replacePlaceholders(\n+                selector, System.getProperties()\n+            );\n+            providerConfig.entrySet().removeIf(e -> !resolvedSelector.equals(e.getKey()));\n+\n+            if (!providerConfig.isEmpty()) {\n+                continue;\n+            }\n+\n+            if (!DISABLE_SELECTOR.equals(resolvedSelector)) {\n+                throw new RuntimeException(\n+                    \"no provider found for module \" + moduleName + \", \" +\n+                        \"if you're sure it's not required module and want to remove it, \" +\n+                        \"set the selector to -\"\n+                );\n+            }\n+\n+            // now the module can be safely removed\n+            modulesWithoutProvider.add(moduleName);\n+        }\n+\n+        moduleConfiguration.entrySet().removeIf(e -> {\n+            final String module = e.getKey();\n+            final boolean shouldBeRemoved = modulesWithoutProvider.contains(module);\n+\n+            if (shouldBeRemoved) {\n+                logger.info(\"removing module {} without any provider\", module);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 81}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMzg4NDEyOnYy", "diffSide": "RIGHT", "path": "docs/en/setup/backend/backend-setup.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQxMjo0Njo1MlrOF2etCQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQxMjo0Njo1MlrOF2etCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY3MDQ3Mw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            1. **Level 2**, provider name and provider selector. Available providers are listed here with a selector to indicate which one will actually take effect.\n          \n          \n            \n            1. **Level 2**, provider option list and provider selector. Available providers are listed here with a selector to indicate which one will actually take effect.", "url": "https://github.com/apache/skywalking/pull/4514#discussion_r392670473", "createdAt": "2020-03-15T12:46:52Z", "author": {"login": "wu-sheng"}, "path": "docs/en/setup/backend/backend-setup.md", "diffHunk": "@@ -14,26 +14,41 @@ End user can switch or assemble the collector features by their own requirements\n \n So, in `application.yml`, there are three levels.\n 1. **Level 1**, module name. Meaning this module is active in running mode.\n-1. **Level 2**, provider name. Set the provider of the module.\n+1. **Level 2**, provider name and provider selector. Available providers are listed here with a selector to indicate which one will actually take effect.", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4427, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}