{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY5NTc1MjIz", "number": 3536, "reviewThreads": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQwNzoxNzo0M1rODcaEsQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQwNzoyNDowOFrODcaFbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMTEzOTA1OnYy", "diffSide": "RIGHT", "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQwNzoxNzo0M1rOFkcu7g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxMDo0MToyM1rOFktELg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2MzgyMg==", "bodyText": "No ?option in syntax. And label should be a single word, datamining or something as a category label.", "url": "https://github.com/apache/camel/pull/3536#discussion_r373763822", "createdAt": "2020-02-01T07:17:43Z", "author": {"login": "davsclaus"}, "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "diffHunk": "@@ -16,22 +16,46 @@\n  */\n package org.apache.camel.component.weka;\n \n+import java.io.BufferedReader;\n+import java.io.BufferedWriter;\n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.InputStreamReader;\n+import java.io.OutputStreamWriter;\n+import java.net.URL;\n+import java.nio.file.Paths;\n+\n import org.apache.camel.Consumer;\n+import org.apache.camel.Exchange;\n+import org.apache.camel.Message;\n import org.apache.camel.Processor;\n import org.apache.camel.Producer;\n+import org.apache.camel.component.file.GenericFile;\n import org.apache.camel.spi.UriEndpoint;\n import org.apache.camel.spi.UriParam;\n import org.apache.camel.support.DefaultEndpoint;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import io.nessus.weka.AssertState;\n+import io.nessus.weka.Dataset;\n+import io.nessus.weka.ModelLoader;\n+import io.nessus.weka.ModelPersister;\n+import io.nessus.weka.UncheckedException;\n+import weka.classifiers.Classifier;\n+import weka.classifiers.Evaluation;\n+import weka.core.Instances;\n import weka.core.Version;\n+import weka.core.converters.ArffLoader;\n+import weka.core.converters.CSVLoader;\n+import weka.core.converters.Loader;\n \n /**\n  * The camel-weka component provides Data Mining functionality through Weka.\n  */\n-@UriEndpoint(firstVersion = \"3.1.0\", scheme = \"weka\", title = \"Weka\",\n-        syntax = \"weka:cmd?options\", producerOnly = true, label = \"data mining\")\n+@UriEndpoint(firstVersion = \"3.1.0\", scheme = \"weka\", title = \"Weka\", syntax = \"weka:cmd?options\", label = \"data mining\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDAzMTQwNg==", "bodyText": "Done", "url": "https://github.com/apache/camel/pull/3536#discussion_r374031406", "createdAt": "2020-02-03T10:41:23Z", "author": {"login": "tdiesler"}, "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "diffHunk": "@@ -16,22 +16,46 @@\n  */\n package org.apache.camel.component.weka;\n \n+import java.io.BufferedReader;\n+import java.io.BufferedWriter;\n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.InputStreamReader;\n+import java.io.OutputStreamWriter;\n+import java.net.URL;\n+import java.nio.file.Paths;\n+\n import org.apache.camel.Consumer;\n+import org.apache.camel.Exchange;\n+import org.apache.camel.Message;\n import org.apache.camel.Processor;\n import org.apache.camel.Producer;\n+import org.apache.camel.component.file.GenericFile;\n import org.apache.camel.spi.UriEndpoint;\n import org.apache.camel.spi.UriParam;\n import org.apache.camel.support.DefaultEndpoint;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import io.nessus.weka.AssertState;\n+import io.nessus.weka.Dataset;\n+import io.nessus.weka.ModelLoader;\n+import io.nessus.weka.ModelPersister;\n+import io.nessus.weka.UncheckedException;\n+import weka.classifiers.Classifier;\n+import weka.classifiers.Evaluation;\n+import weka.core.Instances;\n import weka.core.Version;\n+import weka.core.converters.ArffLoader;\n+import weka.core.converters.CSVLoader;\n+import weka.core.converters.Loader;\n \n /**\n  * The camel-weka component provides Data Mining functionality through Weka.\n  */\n-@UriEndpoint(firstVersion = \"3.1.0\", scheme = \"weka\", title = \"Weka\",\n-        syntax = \"weka:cmd?options\", producerOnly = true, label = \"data mining\")\n+@UriEndpoint(firstVersion = \"3.1.0\", scheme = \"weka\", title = \"Weka\", syntax = \"weka:cmd?options\", label = \"data mining\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2MzgyMg=="}, "originalCommit": {"oid": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMTEzOTMxOnYy", "diffSide": "RIGHT", "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaConsumer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQwNzoxODo0M1rOFkcvDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQwNzoxODo0M1rOFkcvDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2Mzg1Mg==", "bodyText": "Its preferred to create thread via Camel. See CamelContext ExecutorServiceStrategy which has APIs for creating threads. Also you should stop the thread in doStop.", "url": "https://github.com/apache/camel/pull/3536#discussion_r373763852", "createdAt": "2020-02-01T07:18:43Z", "author": {"login": "davsclaus"}, "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaConsumer.java", "diffHunk": "@@ -0,0 +1,75 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.camel.component.weka;\n+\n+import org.apache.camel.Exchange;\n+import org.apache.camel.Processor;\n+import org.apache.camel.component.weka.WekaConfiguration.Command;\n+import org.apache.camel.support.DefaultConsumer;\n+\n+import io.nessus.weka.Dataset;\n+\n+public class WekaConsumer extends DefaultConsumer {\n+\n+    public WekaConsumer(WekaEndpoint endpoint, Processor processor) {\n+        super(endpoint, processor);\n+    }\n+\n+    @Override\n+    public WekaEndpoint getEndpoint() {\n+        return (WekaEndpoint)super.getEndpoint();\n+    }\n+\n+    public WekaConfiguration getConfiguration() {\n+        return getEndpoint().getConfiguration();\n+    }\n+    \n+    @Override\n+    protected void doStart() throws Exception {\n+        super.doStart();\n+        \n+        Thread thread = new Thread(new Runnable() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMTEzOTQxOnYy", "diffSide": "RIGHT", "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaConsumer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQwNzoxOToxNlrOFkcvGg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxMTowNDo1N1rOFkttsw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2Mzg2Ng==", "bodyText": "Check for invalid command in the component or the createConsumer method. Doing this here is too late.", "url": "https://github.com/apache/camel/pull/3536#discussion_r373763866", "createdAt": "2020-02-01T07:19:16Z", "author": {"login": "davsclaus"}, "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaConsumer.java", "diffHunk": "@@ -0,0 +1,75 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.camel.component.weka;\n+\n+import org.apache.camel.Exchange;\n+import org.apache.camel.Processor;\n+import org.apache.camel.component.weka.WekaConfiguration.Command;\n+import org.apache.camel.support.DefaultConsumer;\n+\n+import io.nessus.weka.Dataset;\n+\n+public class WekaConsumer extends DefaultConsumer {\n+\n+    public WekaConsumer(WekaEndpoint endpoint, Processor processor) {\n+        super(endpoint, processor);\n+    }\n+\n+    @Override\n+    public WekaEndpoint getEndpoint() {\n+        return (WekaEndpoint)super.getEndpoint();\n+    }\n+\n+    public WekaConfiguration getConfiguration() {\n+        return getEndpoint().getConfiguration();\n+    }\n+    \n+    @Override\n+    protected void doStart() throws Exception {\n+        super.doStart();\n+        \n+        Thread thread = new Thread(new Runnable() {\n+            \n+            @Override\n+            public void run() {\n+                \n+                WekaEndpoint endpoint = getEndpoint();\n+                Exchange exchange = endpoint.createExchange();\n+                \n+                Command cmd = getConfiguration().getCommand();\n+                if (Command.read != cmd) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDA0MjAzNQ==", "bodyText": "Done", "url": "https://github.com/apache/camel/pull/3536#discussion_r374042035", "createdAt": "2020-02-03T11:04:57Z", "author": {"login": "tdiesler"}, "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaConsumer.java", "diffHunk": "@@ -0,0 +1,75 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.camel.component.weka;\n+\n+import org.apache.camel.Exchange;\n+import org.apache.camel.Processor;\n+import org.apache.camel.component.weka.WekaConfiguration.Command;\n+import org.apache.camel.support.DefaultConsumer;\n+\n+import io.nessus.weka.Dataset;\n+\n+public class WekaConsumer extends DefaultConsumer {\n+\n+    public WekaConsumer(WekaEndpoint endpoint, Processor processor) {\n+        super(endpoint, processor);\n+    }\n+\n+    @Override\n+    public WekaEndpoint getEndpoint() {\n+        return (WekaEndpoint)super.getEndpoint();\n+    }\n+\n+    public WekaConfiguration getConfiguration() {\n+        return getEndpoint().getConfiguration();\n+    }\n+    \n+    @Override\n+    protected void doStart() throws Exception {\n+        super.doStart();\n+        \n+        Thread thread = new Thread(new Runnable() {\n+            \n+            @Override\n+            public void run() {\n+                \n+                WekaEndpoint endpoint = getEndpoint();\n+                Exchange exchange = endpoint.createExchange();\n+                \n+                Command cmd = getConfiguration().getCommand();\n+                if (Command.read != cmd) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2Mzg2Ng=="}, "originalCommit": {"oid": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMTEzOTUwOnYy", "diffSide": "RIGHT", "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQwNzoxOTo1OVrOFkcvJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxMTowNjo1MFrOFktwyw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2Mzg3OQ==", "bodyText": "You need to call configureConsumer too, see the other components", "url": "https://github.com/apache/camel/pull/3536#discussion_r373763879", "createdAt": "2020-02-01T07:19:59Z", "author": {"login": "davsclaus"}, "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "diffHunk": "@@ -44,14 +68,18 @@ public WekaEndpoint(String uri, WekaComponent component, WekaConfiguration confi\n         this.configuration = config;\n     }\n \n+    public WekaConfiguration getConfiguration() {\n+        return configuration;\n+    }\n+\n     @Override\n     public WekaComponent getComponent() {\n-        return (WekaComponent)super.getComponent();\n+        return (WekaComponent) super.getComponent();\n     }\n \n     @Override\n-    public Consumer createConsumer(Processor processor) throws Exception {\n-        throw new UnsupportedOperationException();\n+    public Consumer createConsumer(Processor processor) {\n+        return new WekaConsumer(this, processor);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDA0MjgyNw==", "bodyText": "Done", "url": "https://github.com/apache/camel/pull/3536#discussion_r374042827", "createdAt": "2020-02-03T11:06:50Z", "author": {"login": "tdiesler"}, "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "diffHunk": "@@ -44,14 +68,18 @@ public WekaEndpoint(String uri, WekaComponent component, WekaConfiguration confi\n         this.configuration = config;\n     }\n \n+    public WekaConfiguration getConfiguration() {\n+        return configuration;\n+    }\n+\n     @Override\n     public WekaComponent getComponent() {\n-        return (WekaComponent)super.getComponent();\n+        return (WekaComponent) super.getComponent();\n     }\n \n     @Override\n-    public Consumer createConsumer(Processor processor) throws Exception {\n-        throw new UnsupportedOperationException();\n+    public Consumer createConsumer(Processor processor) {\n+        return new WekaConsumer(this, processor);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2Mzg3OQ=="}, "originalCommit": {"oid": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMTEzOTYyOnYy", "diffSide": "RIGHT", "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQwNzoyMDozOFrOFkcvNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxMTowODowNVrOFkty9Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2Mzg5NQ==", "bodyText": "LOG.debug", "url": "https://github.com/apache/camel/pull/3536#discussion_r373763895", "createdAt": "2020-02-01T07:20:38Z", "author": {"login": "davsclaus"}, "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "diffHunk": "@@ -64,11 +92,245 @@ public boolean isSingleton() {\n         return false;\n     }\n \n-    public WekaConfiguration getConfiguration() {\n-        return configuration;\n-    }\n-\n     String wekaVersion() {\n         return Version.VERSION;\n     }\n+\n+    Dataset handlePushCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.push(dsname);\n+        } else {\n+            dataset.push();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handlePopCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.pop(dsname);\n+        } else {\n+            dataset.pop();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleReadCmd(Exchange exchange) throws Exception {\n+        \n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            Dataset dataset = Dataset.create(fpath);\n+            return dataset;\n+        }\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        return dataset;\n+    }\n+\n+    Object handleWriteCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            \n+            dataset.write(Paths.get(fpath));\n+            return dataset;\n+            \n+        } else {\n+            \n+            // The internal implementation of DataSink does this.. \n+            // Instances.toString().getBytes()\n+            //\n+            // Therefore, we avoid creating yet another copy of the\n+            // instance data and call Instances.toString() as well\n+            \n+            Instances instances = dataset.getInstances();\n+            byte[] bytes = instances.toString().getBytes();\n+            return new ByteArrayInputStream(bytes);\n+        }\n+    }\n+\n+    Dataset handleFilterCmd(Exchange exchange) throws Exception {\n+        \n+        String applyValue = configuration.getApply();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        dataset = dataset.apply(applyValue);\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleModelCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        \n+        String dsname = configuration.getDsname();\n+        boolean crossValidate = configuration.isXval();\n+        String buildSpec = configuration.getBuild();\n+        String loadFrom = configuration.getLoadFrom();\n+        String saveTo = configuration.getSaveTo();\n+        \n+        // Load the Model\n+        \n+        if (loadFrom != null) {\n+            \n+            Classifier cl = dataset\n+                    .loadClassifier(new ModelLoader(loadFrom))\n+                    .getClassifier();\n+            \n+            AssertState.notNull(cl, \"Cannot load the classifier from: \" + loadFrom);\n+            LOG.info(\"{}\", cl);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8"}, "originalPosition": 177}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDA0MzM4MQ==", "bodyText": "Done", "url": "https://github.com/apache/camel/pull/3536#discussion_r374043381", "createdAt": "2020-02-03T11:08:05Z", "author": {"login": "tdiesler"}, "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "diffHunk": "@@ -64,11 +92,245 @@ public boolean isSingleton() {\n         return false;\n     }\n \n-    public WekaConfiguration getConfiguration() {\n-        return configuration;\n-    }\n-\n     String wekaVersion() {\n         return Version.VERSION;\n     }\n+\n+    Dataset handlePushCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.push(dsname);\n+        } else {\n+            dataset.push();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handlePopCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.pop(dsname);\n+        } else {\n+            dataset.pop();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleReadCmd(Exchange exchange) throws Exception {\n+        \n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            Dataset dataset = Dataset.create(fpath);\n+            return dataset;\n+        }\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        return dataset;\n+    }\n+\n+    Object handleWriteCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            \n+            dataset.write(Paths.get(fpath));\n+            return dataset;\n+            \n+        } else {\n+            \n+            // The internal implementation of DataSink does this.. \n+            // Instances.toString().getBytes()\n+            //\n+            // Therefore, we avoid creating yet another copy of the\n+            // instance data and call Instances.toString() as well\n+            \n+            Instances instances = dataset.getInstances();\n+            byte[] bytes = instances.toString().getBytes();\n+            return new ByteArrayInputStream(bytes);\n+        }\n+    }\n+\n+    Dataset handleFilterCmd(Exchange exchange) throws Exception {\n+        \n+        String applyValue = configuration.getApply();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        dataset = dataset.apply(applyValue);\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleModelCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        \n+        String dsname = configuration.getDsname();\n+        boolean crossValidate = configuration.isXval();\n+        String buildSpec = configuration.getBuild();\n+        String loadFrom = configuration.getLoadFrom();\n+        String saveTo = configuration.getSaveTo();\n+        \n+        // Load the Model\n+        \n+        if (loadFrom != null) {\n+            \n+            Classifier cl = dataset\n+                    .loadClassifier(new ModelLoader(loadFrom))\n+                    .getClassifier();\n+            \n+            AssertState.notNull(cl, \"Cannot load the classifier from: \" + loadFrom);\n+            LOG.info(\"{}\", cl);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2Mzg5NQ=="}, "originalCommit": {"oid": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8"}, "originalPosition": 177}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMTEzOTkwOnYy", "diffSide": "RIGHT", "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQwNzoyMDo1N1rOFkcvVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxMTowNzo1OFrOFktyug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2MzkyNQ==", "bodyText": "debug logging", "url": "https://github.com/apache/camel/pull/3536#discussion_r373763925", "createdAt": "2020-02-01T07:20:57Z", "author": {"login": "davsclaus"}, "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "diffHunk": "@@ -64,11 +92,245 @@ public boolean isSingleton() {\n         return false;\n     }\n \n-    public WekaConfiguration getConfiguration() {\n-        return configuration;\n-    }\n-\n     String wekaVersion() {\n         return Version.VERSION;\n     }\n+\n+    Dataset handlePushCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.push(dsname);\n+        } else {\n+            dataset.push();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handlePopCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.pop(dsname);\n+        } else {\n+            dataset.pop();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleReadCmd(Exchange exchange) throws Exception {\n+        \n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            Dataset dataset = Dataset.create(fpath);\n+            return dataset;\n+        }\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        return dataset;\n+    }\n+\n+    Object handleWriteCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            \n+            dataset.write(Paths.get(fpath));\n+            return dataset;\n+            \n+        } else {\n+            \n+            // The internal implementation of DataSink does this.. \n+            // Instances.toString().getBytes()\n+            //\n+            // Therefore, we avoid creating yet another copy of the\n+            // instance data and call Instances.toString() as well\n+            \n+            Instances instances = dataset.getInstances();\n+            byte[] bytes = instances.toString().getBytes();\n+            return new ByteArrayInputStream(bytes);\n+        }\n+    }\n+\n+    Dataset handleFilterCmd(Exchange exchange) throws Exception {\n+        \n+        String applyValue = configuration.getApply();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        dataset = dataset.apply(applyValue);\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleModelCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        \n+        String dsname = configuration.getDsname();\n+        boolean crossValidate = configuration.isXval();\n+        String buildSpec = configuration.getBuild();\n+        String loadFrom = configuration.getLoadFrom();\n+        String saveTo = configuration.getSaveTo();\n+        \n+        // Load the Model\n+        \n+        if (loadFrom != null) {\n+            \n+            Classifier cl = dataset\n+                    .loadClassifier(new ModelLoader(loadFrom))\n+                    .getClassifier();\n+            \n+            AssertState.notNull(cl, \"Cannot load the classifier from: \" + loadFrom);\n+            LOG.info(\"{}\", cl);\n+        } \n+        \n+        // Build a classifier\n+        \n+        else if (buildSpec != null) {\n+            \n+            dataset.buildClassifier(buildSpec);\n+            \n+            // Cross Validate the Model\n+            \n+            if (crossValidate) {\n+                int seed = configuration.getSeed();\n+                int folds = configuration.getFolds();\n+                dataset.crossValidateModel(folds, seed);\n+            } \n+            \n+            // Validate the Model using explicit/current instances\n+            \n+            else {\n+                \n+                // Use the named data set training\n+                if (dsname != null) {\n+                    dataset.pop(dsname);\n+                }\n+                \n+                // Train with current instances\n+                dataset.evaluateModel();\n+            }\n+            \n+            Classifier cl = dataset.getClassifier();\n+            AssertState.notNull(cl, \"Model command requires 'load' or 'apply'\");\n+            LOG.info(\"{}\", cl);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8"}, "originalPosition": 209}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDA0MzMyMg==", "bodyText": "Done", "url": "https://github.com/apache/camel/pull/3536#discussion_r374043322", "createdAt": "2020-02-03T11:07:58Z", "author": {"login": "tdiesler"}, "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "diffHunk": "@@ -64,11 +92,245 @@ public boolean isSingleton() {\n         return false;\n     }\n \n-    public WekaConfiguration getConfiguration() {\n-        return configuration;\n-    }\n-\n     String wekaVersion() {\n         return Version.VERSION;\n     }\n+\n+    Dataset handlePushCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.push(dsname);\n+        } else {\n+            dataset.push();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handlePopCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.pop(dsname);\n+        } else {\n+            dataset.pop();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleReadCmd(Exchange exchange) throws Exception {\n+        \n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            Dataset dataset = Dataset.create(fpath);\n+            return dataset;\n+        }\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        return dataset;\n+    }\n+\n+    Object handleWriteCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            \n+            dataset.write(Paths.get(fpath));\n+            return dataset;\n+            \n+        } else {\n+            \n+            // The internal implementation of DataSink does this.. \n+            // Instances.toString().getBytes()\n+            //\n+            // Therefore, we avoid creating yet another copy of the\n+            // instance data and call Instances.toString() as well\n+            \n+            Instances instances = dataset.getInstances();\n+            byte[] bytes = instances.toString().getBytes();\n+            return new ByteArrayInputStream(bytes);\n+        }\n+    }\n+\n+    Dataset handleFilterCmd(Exchange exchange) throws Exception {\n+        \n+        String applyValue = configuration.getApply();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        dataset = dataset.apply(applyValue);\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleModelCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        \n+        String dsname = configuration.getDsname();\n+        boolean crossValidate = configuration.isXval();\n+        String buildSpec = configuration.getBuild();\n+        String loadFrom = configuration.getLoadFrom();\n+        String saveTo = configuration.getSaveTo();\n+        \n+        // Load the Model\n+        \n+        if (loadFrom != null) {\n+            \n+            Classifier cl = dataset\n+                    .loadClassifier(new ModelLoader(loadFrom))\n+                    .getClassifier();\n+            \n+            AssertState.notNull(cl, \"Cannot load the classifier from: \" + loadFrom);\n+            LOG.info(\"{}\", cl);\n+        } \n+        \n+        // Build a classifier\n+        \n+        else if (buildSpec != null) {\n+            \n+            dataset.buildClassifier(buildSpec);\n+            \n+            // Cross Validate the Model\n+            \n+            if (crossValidate) {\n+                int seed = configuration.getSeed();\n+                int folds = configuration.getFolds();\n+                dataset.crossValidateModel(folds, seed);\n+            } \n+            \n+            // Validate the Model using explicit/current instances\n+            \n+            else {\n+                \n+                // Use the named data set training\n+                if (dsname != null) {\n+                    dataset.pop(dsname);\n+                }\n+                \n+                // Train with current instances\n+                dataset.evaluateModel();\n+            }\n+            \n+            Classifier cl = dataset.getClassifier();\n+            AssertState.notNull(cl, \"Model command requires 'load' or 'apply'\");\n+            LOG.info(\"{}\", cl);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2MzkyNQ=="}, "originalCommit": {"oid": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8"}, "originalPosition": 209}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMTE0MDA3OnYy", "diffSide": "RIGHT", "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQwNzoyMTo0MFrOFkcvaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxMTowODoxOVrOFktzcw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2Mzk0NQ==", "bodyText": "Is this needed to be logged at info level? And is this per exchange which then can get noisy", "url": "https://github.com/apache/camel/pull/3536#discussion_r373763945", "createdAt": "2020-02-01T07:21:40Z", "author": {"login": "davsclaus"}, "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "diffHunk": "@@ -64,11 +92,245 @@ public boolean isSingleton() {\n         return false;\n     }\n \n-    public WekaConfiguration getConfiguration() {\n-        return configuration;\n-    }\n-\n     String wekaVersion() {\n         return Version.VERSION;\n     }\n+\n+    Dataset handlePushCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.push(dsname);\n+        } else {\n+            dataset.push();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handlePopCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.pop(dsname);\n+        } else {\n+            dataset.pop();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleReadCmd(Exchange exchange) throws Exception {\n+        \n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            Dataset dataset = Dataset.create(fpath);\n+            return dataset;\n+        }\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        return dataset;\n+    }\n+\n+    Object handleWriteCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            \n+            dataset.write(Paths.get(fpath));\n+            return dataset;\n+            \n+        } else {\n+            \n+            // The internal implementation of DataSink does this.. \n+            // Instances.toString().getBytes()\n+            //\n+            // Therefore, we avoid creating yet another copy of the\n+            // instance data and call Instances.toString() as well\n+            \n+            Instances instances = dataset.getInstances();\n+            byte[] bytes = instances.toString().getBytes();\n+            return new ByteArrayInputStream(bytes);\n+        }\n+    }\n+\n+    Dataset handleFilterCmd(Exchange exchange) throws Exception {\n+        \n+        String applyValue = configuration.getApply();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        dataset = dataset.apply(applyValue);\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleModelCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        \n+        String dsname = configuration.getDsname();\n+        boolean crossValidate = configuration.isXval();\n+        String buildSpec = configuration.getBuild();\n+        String loadFrom = configuration.getLoadFrom();\n+        String saveTo = configuration.getSaveTo();\n+        \n+        // Load the Model\n+        \n+        if (loadFrom != null) {\n+            \n+            Classifier cl = dataset\n+                    .loadClassifier(new ModelLoader(loadFrom))\n+                    .getClassifier();\n+            \n+            AssertState.notNull(cl, \"Cannot load the classifier from: \" + loadFrom);\n+            LOG.info(\"{}\", cl);\n+        } \n+        \n+        // Build a classifier\n+        \n+        else if (buildSpec != null) {\n+            \n+            dataset.buildClassifier(buildSpec);\n+            \n+            // Cross Validate the Model\n+            \n+            if (crossValidate) {\n+                int seed = configuration.getSeed();\n+                int folds = configuration.getFolds();\n+                dataset.crossValidateModel(folds, seed);\n+            } \n+            \n+            // Validate the Model using explicit/current instances\n+            \n+            else {\n+                \n+                // Use the named data set training\n+                if (dsname != null) {\n+                    dataset.pop(dsname);\n+                }\n+                \n+                // Train with current instances\n+                dataset.evaluateModel();\n+            }\n+            \n+            Classifier cl = dataset.getClassifier();\n+            AssertState.notNull(cl, \"Model command requires 'load' or 'apply'\");\n+            LOG.info(\"{}\", cl);\n+            \n+            Evaluation ev = dataset.getEvaluation();\n+            LOG.info(\"{}\", ev.toSummaryString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8"}, "originalPosition": 212}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDA0MzUwNw==", "bodyText": "Done", "url": "https://github.com/apache/camel/pull/3536#discussion_r374043507", "createdAt": "2020-02-03T11:08:19Z", "author": {"login": "tdiesler"}, "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "diffHunk": "@@ -64,11 +92,245 @@ public boolean isSingleton() {\n         return false;\n     }\n \n-    public WekaConfiguration getConfiguration() {\n-        return configuration;\n-    }\n-\n     String wekaVersion() {\n         return Version.VERSION;\n     }\n+\n+    Dataset handlePushCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.push(dsname);\n+        } else {\n+            dataset.push();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handlePopCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.pop(dsname);\n+        } else {\n+            dataset.pop();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleReadCmd(Exchange exchange) throws Exception {\n+        \n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            Dataset dataset = Dataset.create(fpath);\n+            return dataset;\n+        }\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        return dataset;\n+    }\n+\n+    Object handleWriteCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            \n+            dataset.write(Paths.get(fpath));\n+            return dataset;\n+            \n+        } else {\n+            \n+            // The internal implementation of DataSink does this.. \n+            // Instances.toString().getBytes()\n+            //\n+            // Therefore, we avoid creating yet another copy of the\n+            // instance data and call Instances.toString() as well\n+            \n+            Instances instances = dataset.getInstances();\n+            byte[] bytes = instances.toString().getBytes();\n+            return new ByteArrayInputStream(bytes);\n+        }\n+    }\n+\n+    Dataset handleFilterCmd(Exchange exchange) throws Exception {\n+        \n+        String applyValue = configuration.getApply();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        dataset = dataset.apply(applyValue);\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleModelCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        \n+        String dsname = configuration.getDsname();\n+        boolean crossValidate = configuration.isXval();\n+        String buildSpec = configuration.getBuild();\n+        String loadFrom = configuration.getLoadFrom();\n+        String saveTo = configuration.getSaveTo();\n+        \n+        // Load the Model\n+        \n+        if (loadFrom != null) {\n+            \n+            Classifier cl = dataset\n+                    .loadClassifier(new ModelLoader(loadFrom))\n+                    .getClassifier();\n+            \n+            AssertState.notNull(cl, \"Cannot load the classifier from: \" + loadFrom);\n+            LOG.info(\"{}\", cl);\n+        } \n+        \n+        // Build a classifier\n+        \n+        else if (buildSpec != null) {\n+            \n+            dataset.buildClassifier(buildSpec);\n+            \n+            // Cross Validate the Model\n+            \n+            if (crossValidate) {\n+                int seed = configuration.getSeed();\n+                int folds = configuration.getFolds();\n+                dataset.crossValidateModel(folds, seed);\n+            } \n+            \n+            // Validate the Model using explicit/current instances\n+            \n+            else {\n+                \n+                // Use the named data set training\n+                if (dsname != null) {\n+                    dataset.pop(dsname);\n+                }\n+                \n+                // Train with current instances\n+                dataset.evaluateModel();\n+            }\n+            \n+            Classifier cl = dataset.getClassifier();\n+            AssertState.notNull(cl, \"Model command requires 'load' or 'apply'\");\n+            LOG.info(\"{}\", cl);\n+            \n+            Evaluation ev = dataset.getEvaluation();\n+            LOG.info(\"{}\", ev.toSummaryString());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2Mzk0NQ=="}, "originalCommit": {"oid": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8"}, "originalPosition": 212}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMTE0MDUyOnYy", "diffSide": "RIGHT", "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQwNzoyMzowOVrOFkcvoQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxMToxMDo0MVrOFkt3Sw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2NDAwMQ==", "bodyText": "Can the stream not leak? eg need to close it after use", "url": "https://github.com/apache/camel/pull/3536#discussion_r373764001", "createdAt": "2020-02-01T07:23:09Z", "author": {"login": "davsclaus"}, "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "diffHunk": "@@ -64,11 +92,245 @@ public boolean isSingleton() {\n         return false;\n     }\n \n-    public WekaConfiguration getConfiguration() {\n-        return configuration;\n-    }\n-\n     String wekaVersion() {\n         return Version.VERSION;\n     }\n+\n+    Dataset handlePushCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.push(dsname);\n+        } else {\n+            dataset.push();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handlePopCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.pop(dsname);\n+        } else {\n+            dataset.pop();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleReadCmd(Exchange exchange) throws Exception {\n+        \n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            Dataset dataset = Dataset.create(fpath);\n+            return dataset;\n+        }\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        return dataset;\n+    }\n+\n+    Object handleWriteCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            \n+            dataset.write(Paths.get(fpath));\n+            return dataset;\n+            \n+        } else {\n+            \n+            // The internal implementation of DataSink does this.. \n+            // Instances.toString().getBytes()\n+            //\n+            // Therefore, we avoid creating yet another copy of the\n+            // instance data and call Instances.toString() as well\n+            \n+            Instances instances = dataset.getInstances();\n+            byte[] bytes = instances.toString().getBytes();\n+            return new ByteArrayInputStream(bytes);\n+        }\n+    }\n+\n+    Dataset handleFilterCmd(Exchange exchange) throws Exception {\n+        \n+        String applyValue = configuration.getApply();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        dataset = dataset.apply(applyValue);\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleModelCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        \n+        String dsname = configuration.getDsname();\n+        boolean crossValidate = configuration.isXval();\n+        String buildSpec = configuration.getBuild();\n+        String loadFrom = configuration.getLoadFrom();\n+        String saveTo = configuration.getSaveTo();\n+        \n+        // Load the Model\n+        \n+        if (loadFrom != null) {\n+            \n+            Classifier cl = dataset\n+                    .loadClassifier(new ModelLoader(loadFrom))\n+                    .getClassifier();\n+            \n+            AssertState.notNull(cl, \"Cannot load the classifier from: \" + loadFrom);\n+            LOG.info(\"{}\", cl);\n+        } \n+        \n+        // Build a classifier\n+        \n+        else if (buildSpec != null) {\n+            \n+            dataset.buildClassifier(buildSpec);\n+            \n+            // Cross Validate the Model\n+            \n+            if (crossValidate) {\n+                int seed = configuration.getSeed();\n+                int folds = configuration.getFolds();\n+                dataset.crossValidateModel(folds, seed);\n+            } \n+            \n+            // Validate the Model using explicit/current instances\n+            \n+            else {\n+                \n+                // Use the named data set training\n+                if (dsname != null) {\n+                    dataset.pop(dsname);\n+                }\n+                \n+                // Train with current instances\n+                dataset.evaluateModel();\n+            }\n+            \n+            Classifier cl = dataset.getClassifier();\n+            AssertState.notNull(cl, \"Model command requires 'load' or 'apply'\");\n+            LOG.info(\"{}\", cl);\n+            \n+            Evaluation ev = dataset.getEvaluation();\n+            LOG.info(\"{}\", ev.toSummaryString());\n+        }\n+        \n+        // Save the Model\n+        \n+        if (saveTo != null) {\n+            dataset.consumeClassifier(new ModelPersister(saveTo));\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    private Dataset assertDatasetBody(Exchange exchange) throws Exception {\n+        \n+        Message msg = exchange.getMessage();\n+        Object body = msg.getBody();\n+        \n+        Dataset dataset = msg.getBody(Dataset.class);\n+        \n+        if (dataset == null) {\n+            \n+            if (body instanceof Instances) {\n+\n+                dataset = Dataset.create((Instances) body);\n+                \n+            } else if (body instanceof GenericFile) {\n+                \n+                GenericFile<?> file = (GenericFile<?>) body;\n+                AssertState.isFalse(file.isDirectory(), \"Directory not supported: \" + file);\n+                String absolutePath = file.getAbsoluteFilePath();\n+                dataset = Dataset.create(absolutePath);\n+                \n+            } else if (body instanceof URL) {\n+                \n+                URL url = (URL) body;\n+                Instances instances = readInternal(url.openStream());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8"}, "originalPosition": 247}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDA0NDQ5MQ==", "bodyText": "Well spotted, thanks.", "url": "https://github.com/apache/camel/pull/3536#discussion_r374044491", "createdAt": "2020-02-03T11:10:41Z", "author": {"login": "tdiesler"}, "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "diffHunk": "@@ -64,11 +92,245 @@ public boolean isSingleton() {\n         return false;\n     }\n \n-    public WekaConfiguration getConfiguration() {\n-        return configuration;\n-    }\n-\n     String wekaVersion() {\n         return Version.VERSION;\n     }\n+\n+    Dataset handlePushCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.push(dsname);\n+        } else {\n+            dataset.push();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handlePopCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.pop(dsname);\n+        } else {\n+            dataset.pop();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleReadCmd(Exchange exchange) throws Exception {\n+        \n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            Dataset dataset = Dataset.create(fpath);\n+            return dataset;\n+        }\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        return dataset;\n+    }\n+\n+    Object handleWriteCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            \n+            dataset.write(Paths.get(fpath));\n+            return dataset;\n+            \n+        } else {\n+            \n+            // The internal implementation of DataSink does this.. \n+            // Instances.toString().getBytes()\n+            //\n+            // Therefore, we avoid creating yet another copy of the\n+            // instance data and call Instances.toString() as well\n+            \n+            Instances instances = dataset.getInstances();\n+            byte[] bytes = instances.toString().getBytes();\n+            return new ByteArrayInputStream(bytes);\n+        }\n+    }\n+\n+    Dataset handleFilterCmd(Exchange exchange) throws Exception {\n+        \n+        String applyValue = configuration.getApply();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        dataset = dataset.apply(applyValue);\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleModelCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        \n+        String dsname = configuration.getDsname();\n+        boolean crossValidate = configuration.isXval();\n+        String buildSpec = configuration.getBuild();\n+        String loadFrom = configuration.getLoadFrom();\n+        String saveTo = configuration.getSaveTo();\n+        \n+        // Load the Model\n+        \n+        if (loadFrom != null) {\n+            \n+            Classifier cl = dataset\n+                    .loadClassifier(new ModelLoader(loadFrom))\n+                    .getClassifier();\n+            \n+            AssertState.notNull(cl, \"Cannot load the classifier from: \" + loadFrom);\n+            LOG.info(\"{}\", cl);\n+        } \n+        \n+        // Build a classifier\n+        \n+        else if (buildSpec != null) {\n+            \n+            dataset.buildClassifier(buildSpec);\n+            \n+            // Cross Validate the Model\n+            \n+            if (crossValidate) {\n+                int seed = configuration.getSeed();\n+                int folds = configuration.getFolds();\n+                dataset.crossValidateModel(folds, seed);\n+            } \n+            \n+            // Validate the Model using explicit/current instances\n+            \n+            else {\n+                \n+                // Use the named data set training\n+                if (dsname != null) {\n+                    dataset.pop(dsname);\n+                }\n+                \n+                // Train with current instances\n+                dataset.evaluateModel();\n+            }\n+            \n+            Classifier cl = dataset.getClassifier();\n+            AssertState.notNull(cl, \"Model command requires 'load' or 'apply'\");\n+            LOG.info(\"{}\", cl);\n+            \n+            Evaluation ev = dataset.getEvaluation();\n+            LOG.info(\"{}\", ev.toSummaryString());\n+        }\n+        \n+        // Save the Model\n+        \n+        if (saveTo != null) {\n+            dataset.consumeClassifier(new ModelPersister(saveTo));\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    private Dataset assertDatasetBody(Exchange exchange) throws Exception {\n+        \n+        Message msg = exchange.getMessage();\n+        Object body = msg.getBody();\n+        \n+        Dataset dataset = msg.getBody(Dataset.class);\n+        \n+        if (dataset == null) {\n+            \n+            if (body instanceof Instances) {\n+\n+                dataset = Dataset.create((Instances) body);\n+                \n+            } else if (body instanceof GenericFile) {\n+                \n+                GenericFile<?> file = (GenericFile<?>) body;\n+                AssertState.isFalse(file.isDirectory(), \"Directory not supported: \" + file);\n+                String absolutePath = file.getAbsoluteFilePath();\n+                dataset = Dataset.create(absolutePath);\n+                \n+            } else if (body instanceof URL) {\n+                \n+                URL url = (URL) body;\n+                Instances instances = readInternal(url.openStream());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2NDAwMQ=="}, "originalCommit": {"oid": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8"}, "originalPosition": 247}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMTE0MDgwOnYy", "diffSide": "RIGHT", "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQwNzoyMzo0N1rOFkcvvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxMToxMTowOFrOFkt4Lw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2NDAzMQ==", "bodyText": "Can the stream not leak? eg need to close it after use", "url": "https://github.com/apache/camel/pull/3536#discussion_r373764031", "createdAt": "2020-02-01T07:23:47Z", "author": {"login": "davsclaus"}, "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "diffHunk": "@@ -64,11 +92,245 @@ public boolean isSingleton() {\n         return false;\n     }\n \n-    public WekaConfiguration getConfiguration() {\n-        return configuration;\n-    }\n-\n     String wekaVersion() {\n         return Version.VERSION;\n     }\n+\n+    Dataset handlePushCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.push(dsname);\n+        } else {\n+            dataset.push();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handlePopCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.pop(dsname);\n+        } else {\n+            dataset.pop();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleReadCmd(Exchange exchange) throws Exception {\n+        \n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            Dataset dataset = Dataset.create(fpath);\n+            return dataset;\n+        }\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        return dataset;\n+    }\n+\n+    Object handleWriteCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            \n+            dataset.write(Paths.get(fpath));\n+            return dataset;\n+            \n+        } else {\n+            \n+            // The internal implementation of DataSink does this.. \n+            // Instances.toString().getBytes()\n+            //\n+            // Therefore, we avoid creating yet another copy of the\n+            // instance data and call Instances.toString() as well\n+            \n+            Instances instances = dataset.getInstances();\n+            byte[] bytes = instances.toString().getBytes();\n+            return new ByteArrayInputStream(bytes);\n+        }\n+    }\n+\n+    Dataset handleFilterCmd(Exchange exchange) throws Exception {\n+        \n+        String applyValue = configuration.getApply();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        dataset = dataset.apply(applyValue);\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleModelCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        \n+        String dsname = configuration.getDsname();\n+        boolean crossValidate = configuration.isXval();\n+        String buildSpec = configuration.getBuild();\n+        String loadFrom = configuration.getLoadFrom();\n+        String saveTo = configuration.getSaveTo();\n+        \n+        // Load the Model\n+        \n+        if (loadFrom != null) {\n+            \n+            Classifier cl = dataset\n+                    .loadClassifier(new ModelLoader(loadFrom))\n+                    .getClassifier();\n+            \n+            AssertState.notNull(cl, \"Cannot load the classifier from: \" + loadFrom);\n+            LOG.info(\"{}\", cl);\n+        } \n+        \n+        // Build a classifier\n+        \n+        else if (buildSpec != null) {\n+            \n+            dataset.buildClassifier(buildSpec);\n+            \n+            // Cross Validate the Model\n+            \n+            if (crossValidate) {\n+                int seed = configuration.getSeed();\n+                int folds = configuration.getFolds();\n+                dataset.crossValidateModel(folds, seed);\n+            } \n+            \n+            // Validate the Model using explicit/current instances\n+            \n+            else {\n+                \n+                // Use the named data set training\n+                if (dsname != null) {\n+                    dataset.pop(dsname);\n+                }\n+                \n+                // Train with current instances\n+                dataset.evaluateModel();\n+            }\n+            \n+            Classifier cl = dataset.getClassifier();\n+            AssertState.notNull(cl, \"Model command requires 'load' or 'apply'\");\n+            LOG.info(\"{}\", cl);\n+            \n+            Evaluation ev = dataset.getEvaluation();\n+            LOG.info(\"{}\", ev.toSummaryString());\n+        }\n+        \n+        // Save the Model\n+        \n+        if (saveTo != null) {\n+            dataset.consumeClassifier(new ModelPersister(saveTo));\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    private Dataset assertDatasetBody(Exchange exchange) throws Exception {\n+        \n+        Message msg = exchange.getMessage();\n+        Object body = msg.getBody();\n+        \n+        Dataset dataset = msg.getBody(Dataset.class);\n+        \n+        if (dataset == null) {\n+            \n+            if (body instanceof Instances) {\n+\n+                dataset = Dataset.create((Instances) body);\n+                \n+            } else if (body instanceof GenericFile) {\n+                \n+                GenericFile<?> file = (GenericFile<?>) body;\n+                AssertState.isFalse(file.isDirectory(), \"Directory not supported: \" + file);\n+                String absolutePath = file.getAbsoluteFilePath();\n+                dataset = Dataset.create(absolutePath);\n+                \n+            } else if (body instanceof URL) {\n+                \n+                URL url = (URL) body;\n+                Instances instances = readInternal(url.openStream());\n+                dataset = Dataset.create(instances);\n+                \n+            } else if (body instanceof InputStream) {\n+                \n+                InputStream input = (InputStream) body;\n+                Instances instances = readInternal(input);\n+                dataset = Dataset.create(instances);\n+            }\n+        }\n+        \n+        AssertState.notNull(dataset, \"Cannot obtain dataset from body: \" + body);\n+        return dataset;\n+    }\n+\n+    // https://github.com/tdiesler/nessus-weka/issues/11\n+    private static Instances readInternal(InputStream input) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8"}, "originalPosition": 263}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDA0NDcxOQ==", "bodyText": "Caller resposibility", "url": "https://github.com/apache/camel/pull/3536#discussion_r374044719", "createdAt": "2020-02-03T11:11:08Z", "author": {"login": "tdiesler"}, "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "diffHunk": "@@ -64,11 +92,245 @@ public boolean isSingleton() {\n         return false;\n     }\n \n-    public WekaConfiguration getConfiguration() {\n-        return configuration;\n-    }\n-\n     String wekaVersion() {\n         return Version.VERSION;\n     }\n+\n+    Dataset handlePushCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.push(dsname);\n+        } else {\n+            dataset.push();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handlePopCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.pop(dsname);\n+        } else {\n+            dataset.pop();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleReadCmd(Exchange exchange) throws Exception {\n+        \n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            Dataset dataset = Dataset.create(fpath);\n+            return dataset;\n+        }\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        return dataset;\n+    }\n+\n+    Object handleWriteCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            \n+            dataset.write(Paths.get(fpath));\n+            return dataset;\n+            \n+        } else {\n+            \n+            // The internal implementation of DataSink does this.. \n+            // Instances.toString().getBytes()\n+            //\n+            // Therefore, we avoid creating yet another copy of the\n+            // instance data and call Instances.toString() as well\n+            \n+            Instances instances = dataset.getInstances();\n+            byte[] bytes = instances.toString().getBytes();\n+            return new ByteArrayInputStream(bytes);\n+        }\n+    }\n+\n+    Dataset handleFilterCmd(Exchange exchange) throws Exception {\n+        \n+        String applyValue = configuration.getApply();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        dataset = dataset.apply(applyValue);\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleModelCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        \n+        String dsname = configuration.getDsname();\n+        boolean crossValidate = configuration.isXval();\n+        String buildSpec = configuration.getBuild();\n+        String loadFrom = configuration.getLoadFrom();\n+        String saveTo = configuration.getSaveTo();\n+        \n+        // Load the Model\n+        \n+        if (loadFrom != null) {\n+            \n+            Classifier cl = dataset\n+                    .loadClassifier(new ModelLoader(loadFrom))\n+                    .getClassifier();\n+            \n+            AssertState.notNull(cl, \"Cannot load the classifier from: \" + loadFrom);\n+            LOG.info(\"{}\", cl);\n+        } \n+        \n+        // Build a classifier\n+        \n+        else if (buildSpec != null) {\n+            \n+            dataset.buildClassifier(buildSpec);\n+            \n+            // Cross Validate the Model\n+            \n+            if (crossValidate) {\n+                int seed = configuration.getSeed();\n+                int folds = configuration.getFolds();\n+                dataset.crossValidateModel(folds, seed);\n+            } \n+            \n+            // Validate the Model using explicit/current instances\n+            \n+            else {\n+                \n+                // Use the named data set training\n+                if (dsname != null) {\n+                    dataset.pop(dsname);\n+                }\n+                \n+                // Train with current instances\n+                dataset.evaluateModel();\n+            }\n+            \n+            Classifier cl = dataset.getClassifier();\n+            AssertState.notNull(cl, \"Model command requires 'load' or 'apply'\");\n+            LOG.info(\"{}\", cl);\n+            \n+            Evaluation ev = dataset.getEvaluation();\n+            LOG.info(\"{}\", ev.toSummaryString());\n+        }\n+        \n+        // Save the Model\n+        \n+        if (saveTo != null) {\n+            dataset.consumeClassifier(new ModelPersister(saveTo));\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    private Dataset assertDatasetBody(Exchange exchange) throws Exception {\n+        \n+        Message msg = exchange.getMessage();\n+        Object body = msg.getBody();\n+        \n+        Dataset dataset = msg.getBody(Dataset.class);\n+        \n+        if (dataset == null) {\n+            \n+            if (body instanceof Instances) {\n+\n+                dataset = Dataset.create((Instances) body);\n+                \n+            } else if (body instanceof GenericFile) {\n+                \n+                GenericFile<?> file = (GenericFile<?>) body;\n+                AssertState.isFalse(file.isDirectory(), \"Directory not supported: \" + file);\n+                String absolutePath = file.getAbsoluteFilePath();\n+                dataset = Dataset.create(absolutePath);\n+                \n+            } else if (body instanceof URL) {\n+                \n+                URL url = (URL) body;\n+                Instances instances = readInternal(url.openStream());\n+                dataset = Dataset.create(instances);\n+                \n+            } else if (body instanceof InputStream) {\n+                \n+                InputStream input = (InputStream) body;\n+                Instances instances = readInternal(input);\n+                dataset = Dataset.create(instances);\n+            }\n+        }\n+        \n+        AssertState.notNull(dataset, \"Cannot obtain dataset from body: \" + body);\n+        return dataset;\n+    }\n+\n+    // https://github.com/tdiesler/nessus-weka/issues/11\n+    private static Instances readInternal(InputStream input) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2NDAzMQ=="}, "originalCommit": {"oid": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8"}, "originalPosition": 263}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMTE0MDkyOnYy", "diffSide": "RIGHT", "path": "components/camel-weka/src/test/java/org/apache/camel/component/weka/DecisionTreeTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQwNzoyNDowOFrOFkcvzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQwNzoyNDowOFrOFkcvzg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2NDA0Ng==", "bodyText": "Add license headers for missing files.", "url": "https://github.com/apache/camel/pull/3536#discussion_r373764046", "createdAt": "2020-02-01T07:24:08Z", "author": {"login": "davsclaus"}, "path": "components/camel-weka/src/test/java/org/apache/camel/component/weka/DecisionTreeTest.java", "diffHunk": "@@ -0,0 +1,124 @@\n+package org.apache.camel.component.weka;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8"}, "originalPosition": 1}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4739, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}