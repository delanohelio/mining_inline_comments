{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk2MjQzNTI5", "number": 17659, "reviewThreads": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwNjozMzozMVrOEptFSw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQxMDozMToxN1rOEpxG5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMTY1NzA3OnYy", "diffSide": "RIGHT", "path": "docs/design/sql/10-distributed-scan.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwNjozMzozMVrOHbibow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwNjozMzozMVrOHbibow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODYzNzczMQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            a distributed data structure. Every member stores part of the index that is build for the local entries of the member. \n          \n          \n            \n            a distributed data structure. Every member stores part of the index that is built for the local entries of the member.", "url": "https://github.com/hazelcast/hazelcast/pull/17659#discussion_r498637731", "createdAt": "2020-10-02T06:33:31Z", "author": {"login": "viliam-durina"}, "path": "docs/design/sql/10-distributed-scan.md", "diffHunk": "@@ -0,0 +1,146 @@\n+# Distributed Scan\n+\n+## Overview\n+\n+The Hazelcast Mustang is a distributed query engine. When an SQL string is submitted for execution, it is converted into a \n+query plan, that contains the tree of relational operators, such as `scan`, `project` and `filter`. Leaf operators of the plan \n+act as data sources for the parent operators. The `scan` operator iterates over the `IMap` data structure. This document \n+explains how the distributed scan is performed.\n+\n+In this document, we describe the main design points of the scan operators: access path selection, local execution semantics,\n+and reaction to cluster reconfiguration.\n+\n+## 1 Background\n+\n+The Hazelcast IMDG is a distributed in-memory key-value storage. Data is stored in distributed objects, such as an `IMap`.\n+The cluster has a predefined number of partitions, 271 by default. Each partition is stored on a single member, and may have \n+zero, one or more backups on other members. Every distributed object is split across one or more partitions. Partitions may\n+migrate between members due to topology change events, such as member leave or join.\n+\n+The `IMap` is a distributed map. It could be accessed either directly, or through a secondary index. The secondary index is \n+a distributed data structure. Every member stores part of the index that is build for the local entries of the member. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4695be9542227e968384adcb79bd569a5007257f"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMTY2MDQ5OnYy", "diffSide": "RIGHT", "path": "docs/design/sql/10-distributed-scan.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwNjozNTozNFrOHbid1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwNjozNTozNFrOHbid1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODYzODI5NA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            expression, and `exp` is an expression that have only constants or parameters at leaves (i.e. it doesn't refer to other columns). \n          \n          \n            \n            expression, and `exp` is an expression that has only constants or parameters at leaves (i.e. it doesn't refer to other columns).", "url": "https://github.com/hazelcast/hazelcast/pull/17659#discussion_r498638294", "createdAt": "2020-10-02T06:35:34Z", "author": {"login": "viliam-durina"}, "path": "docs/design/sql/10-distributed-scan.md", "diffHunk": "@@ -0,0 +1,146 @@\n+# Distributed Scan\n+\n+## Overview\n+\n+The Hazelcast Mustang is a distributed query engine. When an SQL string is submitted for execution, it is converted into a \n+query plan, that contains the tree of relational operators, such as `scan`, `project` and `filter`. Leaf operators of the plan \n+act as data sources for the parent operators. The `scan` operator iterates over the `IMap` data structure. This document \n+explains how the distributed scan is performed.\n+\n+In this document, we describe the main design points of the scan operators: access path selection, local execution semantics,\n+and reaction to cluster reconfiguration.\n+\n+## 1 Background\n+\n+The Hazelcast IMDG is a distributed in-memory key-value storage. Data is stored in distributed objects, such as an `IMap`.\n+The cluster has a predefined number of partitions, 271 by default. Each partition is stored on a single member, and may have \n+zero, one or more backups on other members. Every distributed object is split across one or more partitions. Partitions may\n+migrate between members due to topology change events, such as member leave or join.\n+\n+The `IMap` is a distributed map. It could be accessed either directly, or through a secondary index. The secondary index is \n+a distributed data structure. Every member stores part of the index that is build for the local entries of the member. \n+\n+The goal of the Hazelcast Mustang engine is to pick the proper access method - direct scan or index scan, start execution of \n+the scan on members, and collect the results. In the above sections we describe how it is implemented.   \n+\n+## 2 Access Path Selection\n+\n+There are two ways to scan the `IMap` - iterate over the record store directly, or use one of the secondary indexes. During the\n+planning stage the proper access method is chosen. \n+\n+If there are no indexes on the table, the direct scan is chosen and no further optimization is performed.    \n+\n+If there are indexes on the table, we analyze the predicate stored in the table of the `TableScan` operator. The entry point\n+is `IndexResolver.createIndexScans`. \n+\n+First, we split the predicate into conjunctive normal form (CNF). For example, the predicate `a=1 AND b=2` is split into \n+`a=1` and `b=2`, while the predicate `a=1 OR b=2` remains unchanged.\n+\n+Second, for every sub-predicate we find those that could be used by some index. Assume that `col` is a simple column\n+expression, and `exp` is an expression that have only constants or parameters at leaves (i.e. it doesn't refer to other columns). ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4695be9542227e968384adcb79bd569a5007257f"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMTY2MjU0OnYy", "diffSide": "RIGHT", "path": "docs/design/sql/10-distributed-scan.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwNjozNjozOFrOHbifDQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwNjozNjozOFrOHbifDQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODYzODYwNQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            1. 'col = exp1 OR col = exp2' can be treated as union of two equality predicates \n          \n          \n            \n            1. `col = exp1 OR col = exp2` can be treated as union of two equality predicates", "url": "https://github.com/hazelcast/hazelcast/pull/17659#discussion_r498638605", "createdAt": "2020-10-02T06:36:38Z", "author": {"login": "viliam-durina"}, "path": "docs/design/sql/10-distributed-scan.md", "diffHunk": "@@ -0,0 +1,146 @@\n+# Distributed Scan\n+\n+## Overview\n+\n+The Hazelcast Mustang is a distributed query engine. When an SQL string is submitted for execution, it is converted into a \n+query plan, that contains the tree of relational operators, such as `scan`, `project` and `filter`. Leaf operators of the plan \n+act as data sources for the parent operators. The `scan` operator iterates over the `IMap` data structure. This document \n+explains how the distributed scan is performed.\n+\n+In this document, we describe the main design points of the scan operators: access path selection, local execution semantics,\n+and reaction to cluster reconfiguration.\n+\n+## 1 Background\n+\n+The Hazelcast IMDG is a distributed in-memory key-value storage. Data is stored in distributed objects, such as an `IMap`.\n+The cluster has a predefined number of partitions, 271 by default. Each partition is stored on a single member, and may have \n+zero, one or more backups on other members. Every distributed object is split across one or more partitions. Partitions may\n+migrate between members due to topology change events, such as member leave or join.\n+\n+The `IMap` is a distributed map. It could be accessed either directly, or through a secondary index. The secondary index is \n+a distributed data structure. Every member stores part of the index that is build for the local entries of the member. \n+\n+The goal of the Hazelcast Mustang engine is to pick the proper access method - direct scan or index scan, start execution of \n+the scan on members, and collect the results. In the above sections we describe how it is implemented.   \n+\n+## 2 Access Path Selection\n+\n+There are two ways to scan the `IMap` - iterate over the record store directly, or use one of the secondary indexes. During the\n+planning stage the proper access method is chosen. \n+\n+If there are no indexes on the table, the direct scan is chosen and no further optimization is performed.    \n+\n+If there are indexes on the table, we analyze the predicate stored in the table of the `TableScan` operator. The entry point\n+is `IndexResolver.createIndexScans`. \n+\n+First, we split the predicate into conjunctive normal form (CNF). For example, the predicate `a=1 AND b=2` is split into \n+`a=1` and `b=2`, while the predicate `a=1 OR b=2` remains unchanged.\n+\n+Second, for every sub-predicate we find those that could be used by some index. Assume that `col` is a simple column\n+expression, and `exp` is an expression that have only constants or parameters at leaves (i.e. it doesn't refer to other columns). \n+We use the following rules:\n+1. `col = exp` can be used with `SORTED` and `HASH` indexes\n+1. `col [comparison] exp` can be used with `SORTED` indexes\n+1. `col IS NULL/TRUE/FALSE` can be treated as equality expression (with slightly different semantics for `NULL` values)\n+1. 'col = exp1 OR col = exp2' can be treated as union of two equality predicates ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4695be9542227e968384adcb79bd569a5007257f"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMTY2NzUzOnYy", "diffSide": "RIGHT", "path": "docs/design/sql/10-distributed-scan.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwNjozOToyNlrOHbiiLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwNjozOToyNlrOHbiiLA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODYzOTQwNA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            1. Only continuous prefix of index columns could be used. E.g. for the index `(a, b, c)` and the condition `a=1 AND c=2` we \n          \n          \n            \n            1. Only a continuous prefix of index columns can be used. E.g. for the index `(a, b, c)` and the condition `a=1 AND c=2` we", "url": "https://github.com/hazelcast/hazelcast/pull/17659#discussion_r498639404", "createdAt": "2020-10-02T06:39:26Z", "author": {"login": "viliam-durina"}, "path": "docs/design/sql/10-distributed-scan.md", "diffHunk": "@@ -0,0 +1,146 @@\n+# Distributed Scan\n+\n+## Overview\n+\n+The Hazelcast Mustang is a distributed query engine. When an SQL string is submitted for execution, it is converted into a \n+query plan, that contains the tree of relational operators, such as `scan`, `project` and `filter`. Leaf operators of the plan \n+act as data sources for the parent operators. The `scan` operator iterates over the `IMap` data structure. This document \n+explains how the distributed scan is performed.\n+\n+In this document, we describe the main design points of the scan operators: access path selection, local execution semantics,\n+and reaction to cluster reconfiguration.\n+\n+## 1 Background\n+\n+The Hazelcast IMDG is a distributed in-memory key-value storage. Data is stored in distributed objects, such as an `IMap`.\n+The cluster has a predefined number of partitions, 271 by default. Each partition is stored on a single member, and may have \n+zero, one or more backups on other members. Every distributed object is split across one or more partitions. Partitions may\n+migrate between members due to topology change events, such as member leave or join.\n+\n+The `IMap` is a distributed map. It could be accessed either directly, or through a secondary index. The secondary index is \n+a distributed data structure. Every member stores part of the index that is build for the local entries of the member. \n+\n+The goal of the Hazelcast Mustang engine is to pick the proper access method - direct scan or index scan, start execution of \n+the scan on members, and collect the results. In the above sections we describe how it is implemented.   \n+\n+## 2 Access Path Selection\n+\n+There are two ways to scan the `IMap` - iterate over the record store directly, or use one of the secondary indexes. During the\n+planning stage the proper access method is chosen. \n+\n+If there are no indexes on the table, the direct scan is chosen and no further optimization is performed.    \n+\n+If there are indexes on the table, we analyze the predicate stored in the table of the `TableScan` operator. The entry point\n+is `IndexResolver.createIndexScans`. \n+\n+First, we split the predicate into conjunctive normal form (CNF). For example, the predicate `a=1 AND b=2` is split into \n+`a=1` and `b=2`, while the predicate `a=1 OR b=2` remains unchanged.\n+\n+Second, for every sub-predicate we find those that could be used by some index. Assume that `col` is a simple column\n+expression, and `exp` is an expression that have only constants or parameters at leaves (i.e. it doesn't refer to other columns). \n+We use the following rules:\n+1. `col = exp` can be used with `SORTED` and `HASH` indexes\n+1. `col [comparison] exp` can be used with `SORTED` indexes\n+1. `col IS NULL/TRUE/FALSE` can be treated as equality expression (with slightly different semantics for `NULL` values)\n+1. 'col = exp1 OR col = exp2' can be treated as union of two equality predicates \n+\n+The result of this step is a map from column to candidate expressions that could be used with indexes. For example, \n+`a=1 AND b>2 AND b<4` is returned as: \n+```\n+a -> [=1] \n+b -> [>2], [<4]\n+```\n+\n+Next, we iterate over every index, and try to bind candidates to the index based on the index columns and index type.\n+General rules are:\n+1. `SORTED` index may use equality and comparison conditions, while `HASH` index may use only equality conditions\n+1. Only continuous prefix of index columns could be used. E.g. for the index `(a, b, c)` and the condition `a=1 AND c=2` we ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4695be9542227e968384adcb79bd569a5007257f"}, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMTY3MjQ3OnYy", "diffSide": "RIGHT", "path": "docs/design/sql/10-distributed-scan.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwNjo0MTo1M1rOHbilPw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwNjo0MTo1M1rOHbilPw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODY0MDE5MQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Last, for every proposed index, we create a `MapIndexScanPhysicalRel` operator, that is added to the planner search space.\n          \n          \n            \n            At last, for every proposed index, we create a `MapIndexScanPhysicalRel` operator that is added to the planner search space.", "url": "https://github.com/hazelcast/hazelcast/pull/17659#discussion_r498640191", "createdAt": "2020-10-02T06:41:53Z", "author": {"login": "viliam-durina"}, "path": "docs/design/sql/10-distributed-scan.md", "diffHunk": "@@ -0,0 +1,146 @@\n+# Distributed Scan\n+\n+## Overview\n+\n+The Hazelcast Mustang is a distributed query engine. When an SQL string is submitted for execution, it is converted into a \n+query plan, that contains the tree of relational operators, such as `scan`, `project` and `filter`. Leaf operators of the plan \n+act as data sources for the parent operators. The `scan` operator iterates over the `IMap` data structure. This document \n+explains how the distributed scan is performed.\n+\n+In this document, we describe the main design points of the scan operators: access path selection, local execution semantics,\n+and reaction to cluster reconfiguration.\n+\n+## 1 Background\n+\n+The Hazelcast IMDG is a distributed in-memory key-value storage. Data is stored in distributed objects, such as an `IMap`.\n+The cluster has a predefined number of partitions, 271 by default. Each partition is stored on a single member, and may have \n+zero, one or more backups on other members. Every distributed object is split across one or more partitions. Partitions may\n+migrate between members due to topology change events, such as member leave or join.\n+\n+The `IMap` is a distributed map. It could be accessed either directly, or through a secondary index. The secondary index is \n+a distributed data structure. Every member stores part of the index that is build for the local entries of the member. \n+\n+The goal of the Hazelcast Mustang engine is to pick the proper access method - direct scan or index scan, start execution of \n+the scan on members, and collect the results. In the above sections we describe how it is implemented.   \n+\n+## 2 Access Path Selection\n+\n+There are two ways to scan the `IMap` - iterate over the record store directly, or use one of the secondary indexes. During the\n+planning stage the proper access method is chosen. \n+\n+If there are no indexes on the table, the direct scan is chosen and no further optimization is performed.    \n+\n+If there are indexes on the table, we analyze the predicate stored in the table of the `TableScan` operator. The entry point\n+is `IndexResolver.createIndexScans`. \n+\n+First, we split the predicate into conjunctive normal form (CNF). For example, the predicate `a=1 AND b=2` is split into \n+`a=1` and `b=2`, while the predicate `a=1 OR b=2` remains unchanged.\n+\n+Second, for every sub-predicate we find those that could be used by some index. Assume that `col` is a simple column\n+expression, and `exp` is an expression that have only constants or parameters at leaves (i.e. it doesn't refer to other columns). \n+We use the following rules:\n+1. `col = exp` can be used with `SORTED` and `HASH` indexes\n+1. `col [comparison] exp` can be used with `SORTED` indexes\n+1. `col IS NULL/TRUE/FALSE` can be treated as equality expression (with slightly different semantics for `NULL` values)\n+1. 'col = exp1 OR col = exp2' can be treated as union of two equality predicates \n+\n+The result of this step is a map from column to candidate expressions that could be used with indexes. For example, \n+`a=1 AND b>2 AND b<4` is returned as: \n+```\n+a -> [=1] \n+b -> [>2], [<4]\n+```\n+\n+Next, we iterate over every index, and try to bind candidates to the index based on the index columns and index type.\n+General rules are:\n+1. `SORTED` index may use equality and comparison conditions, while `HASH` index may use only equality conditions\n+1. Only continuous prefix of index columns could be used. E.g. for the index `(a, b, c)` and the condition `a=1 AND c=2` we \n+can use only `a=1`\n+1. All expressions in the prefix except for the last one must be equality conditions. E.g. for the index `(a, b)` and the \n+condition `a>1 AND b>2`, we can use only `a>1`   \n+\n+The result of this step is a map from index to the filter that should be used. For example, for the expression \n+`a=1 AND b>2 AND b<4`, and indexes on `(a, c)` and `(b)`, the result would be:\n+```\n+index(a, c) -> [a=1, NULL]\n+index(b) -> [b>2 AND b<4]\n+```\n+\n+Last, for every proposed index, we create a `MapIndexScanPhysicalRel` operator, that is added to the planner search space.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4695be9542227e968384adcb79bd569a5007257f"}, "originalPosition": 69}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMTY3NTY1OnYy", "diffSide": "RIGHT", "path": "docs/design/sql/10-distributed-scan.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwNjo0MzozNFrOHbinKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwNjo0MzozNFrOHbinKQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODY0MDY4MQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            For the direct map scan (`MapScanExec`), the iterator scan all local partitions one by one. For the index scan \n          \n          \n            \n            For the direct map scan (`MapScanExec`), the iterator scans all local partitions one by one. For the index scan", "url": "https://github.com/hazelcast/hazelcast/pull/17659#discussion_r498640681", "createdAt": "2020-10-02T06:43:34Z", "author": {"login": "viliam-durina"}, "path": "docs/design/sql/10-distributed-scan.md", "diffHunk": "@@ -0,0 +1,146 @@\n+# Distributed Scan\n+\n+## Overview\n+\n+The Hazelcast Mustang is a distributed query engine. When an SQL string is submitted for execution, it is converted into a \n+query plan, that contains the tree of relational operators, such as `scan`, `project` and `filter`. Leaf operators of the plan \n+act as data sources for the parent operators. The `scan` operator iterates over the `IMap` data structure. This document \n+explains how the distributed scan is performed.\n+\n+In this document, we describe the main design points of the scan operators: access path selection, local execution semantics,\n+and reaction to cluster reconfiguration.\n+\n+## 1 Background\n+\n+The Hazelcast IMDG is a distributed in-memory key-value storage. Data is stored in distributed objects, such as an `IMap`.\n+The cluster has a predefined number of partitions, 271 by default. Each partition is stored on a single member, and may have \n+zero, one or more backups on other members. Every distributed object is split across one or more partitions. Partitions may\n+migrate between members due to topology change events, such as member leave or join.\n+\n+The `IMap` is a distributed map. It could be accessed either directly, or through a secondary index. The secondary index is \n+a distributed data structure. Every member stores part of the index that is build for the local entries of the member. \n+\n+The goal of the Hazelcast Mustang engine is to pick the proper access method - direct scan or index scan, start execution of \n+the scan on members, and collect the results. In the above sections we describe how it is implemented.   \n+\n+## 2 Access Path Selection\n+\n+There are two ways to scan the `IMap` - iterate over the record store directly, or use one of the secondary indexes. During the\n+planning stage the proper access method is chosen. \n+\n+If there are no indexes on the table, the direct scan is chosen and no further optimization is performed.    \n+\n+If there are indexes on the table, we analyze the predicate stored in the table of the `TableScan` operator. The entry point\n+is `IndexResolver.createIndexScans`. \n+\n+First, we split the predicate into conjunctive normal form (CNF). For example, the predicate `a=1 AND b=2` is split into \n+`a=1` and `b=2`, while the predicate `a=1 OR b=2` remains unchanged.\n+\n+Second, for every sub-predicate we find those that could be used by some index. Assume that `col` is a simple column\n+expression, and `exp` is an expression that have only constants or parameters at leaves (i.e. it doesn't refer to other columns). \n+We use the following rules:\n+1. `col = exp` can be used with `SORTED` and `HASH` indexes\n+1. `col [comparison] exp` can be used with `SORTED` indexes\n+1. `col IS NULL/TRUE/FALSE` can be treated as equality expression (with slightly different semantics for `NULL` values)\n+1. 'col = exp1 OR col = exp2' can be treated as union of two equality predicates \n+\n+The result of this step is a map from column to candidate expressions that could be used with indexes. For example, \n+`a=1 AND b>2 AND b<4` is returned as: \n+```\n+a -> [=1] \n+b -> [>2], [<4]\n+```\n+\n+Next, we iterate over every index, and try to bind candidates to the index based on the index columns and index type.\n+General rules are:\n+1. `SORTED` index may use equality and comparison conditions, while `HASH` index may use only equality conditions\n+1. Only continuous prefix of index columns could be used. E.g. for the index `(a, b, c)` and the condition `a=1 AND c=2` we \n+can use only `a=1`\n+1. All expressions in the prefix except for the last one must be equality conditions. E.g. for the index `(a, b)` and the \n+condition `a>1 AND b>2`, we can use only `a>1`   \n+\n+The result of this step is a map from index to the filter that should be used. For example, for the expression \n+`a=1 AND b>2 AND b<4`, and indexes on `(a, c)` and `(b)`, the result would be:\n+```\n+index(a, c) -> [a=1, NULL]\n+index(b) -> [b>2 AND b<4]\n+```\n+\n+Last, for every proposed index, we create a `MapIndexScanPhysicalRel` operator, that is added to the planner search space.\n+\n+## 3 Local Execution\n+\n+Scan operators consist of three parts:\n+1. Access path (direct scan, index scan)\n+1. Optional filter\n+1. Column list\n+\n+The execution proceeds as follows. First, an iterator over the underlying data is opened (record stores, index). Then every \n+returned record is evaluated against the optional filter. If record is not filtered out, it is converted to a `Row` instance\n+based on the column list. The `Row` is added to the internal batch. When the batch reaches a certain size, or there are no\n+more records, the batch of rows is returned to the parent operator. \n+\n+For the direct map scan (`MapScanExec`), the iterator scan all local partitions one by one. For the index scan ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4695be9542227e968384adcb79bd569a5007257f"}, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMTY4MDM1OnYy", "diffSide": "RIGHT", "path": "docs/design/sql/10-distributed-scan.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwNjo0NjowM1rOHbiqAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwNjo0NjowM1rOHbiqAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODY0MTQxMA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            behavior is possible in many databases, including transactional one. Examples are: Redis [[1]], MongoDB [[2]], Microsoft \n          \n          \n            \n            behavior is possible in many databases, including transactional ones. Examples are: Redis [[1]], MongoDB [[2]], Microsoft", "url": "https://github.com/hazelcast/hazelcast/pull/17659#discussion_r498641410", "createdAt": "2020-10-02T06:46:03Z", "author": {"login": "viliam-durina"}, "path": "docs/design/sql/10-distributed-scan.md", "diffHunk": "@@ -0,0 +1,146 @@\n+# Distributed Scan\n+\n+## Overview\n+\n+The Hazelcast Mustang is a distributed query engine. When an SQL string is submitted for execution, it is converted into a \n+query plan, that contains the tree of relational operators, such as `scan`, `project` and `filter`. Leaf operators of the plan \n+act as data sources for the parent operators. The `scan` operator iterates over the `IMap` data structure. This document \n+explains how the distributed scan is performed.\n+\n+In this document, we describe the main design points of the scan operators: access path selection, local execution semantics,\n+and reaction to cluster reconfiguration.\n+\n+## 1 Background\n+\n+The Hazelcast IMDG is a distributed in-memory key-value storage. Data is stored in distributed objects, such as an `IMap`.\n+The cluster has a predefined number of partitions, 271 by default. Each partition is stored on a single member, and may have \n+zero, one or more backups on other members. Every distributed object is split across one or more partitions. Partitions may\n+migrate between members due to topology change events, such as member leave or join.\n+\n+The `IMap` is a distributed map. It could be accessed either directly, or through a secondary index. The secondary index is \n+a distributed data structure. Every member stores part of the index that is build for the local entries of the member. \n+\n+The goal of the Hazelcast Mustang engine is to pick the proper access method - direct scan or index scan, start execution of \n+the scan on members, and collect the results. In the above sections we describe how it is implemented.   \n+\n+## 2 Access Path Selection\n+\n+There are two ways to scan the `IMap` - iterate over the record store directly, or use one of the secondary indexes. During the\n+planning stage the proper access method is chosen. \n+\n+If there are no indexes on the table, the direct scan is chosen and no further optimization is performed.    \n+\n+If there are indexes on the table, we analyze the predicate stored in the table of the `TableScan` operator. The entry point\n+is `IndexResolver.createIndexScans`. \n+\n+First, we split the predicate into conjunctive normal form (CNF). For example, the predicate `a=1 AND b=2` is split into \n+`a=1` and `b=2`, while the predicate `a=1 OR b=2` remains unchanged.\n+\n+Second, for every sub-predicate we find those that could be used by some index. Assume that `col` is a simple column\n+expression, and `exp` is an expression that have only constants or parameters at leaves (i.e. it doesn't refer to other columns). \n+We use the following rules:\n+1. `col = exp` can be used with `SORTED` and `HASH` indexes\n+1. `col [comparison] exp` can be used with `SORTED` indexes\n+1. `col IS NULL/TRUE/FALSE` can be treated as equality expression (with slightly different semantics for `NULL` values)\n+1. 'col = exp1 OR col = exp2' can be treated as union of two equality predicates \n+\n+The result of this step is a map from column to candidate expressions that could be used with indexes. For example, \n+`a=1 AND b>2 AND b<4` is returned as: \n+```\n+a -> [=1] \n+b -> [>2], [<4]\n+```\n+\n+Next, we iterate over every index, and try to bind candidates to the index based on the index columns and index type.\n+General rules are:\n+1. `SORTED` index may use equality and comparison conditions, while `HASH` index may use only equality conditions\n+1. Only continuous prefix of index columns could be used. E.g. for the index `(a, b, c)` and the condition `a=1 AND c=2` we \n+can use only `a=1`\n+1. All expressions in the prefix except for the last one must be equality conditions. E.g. for the index `(a, b)` and the \n+condition `a>1 AND b>2`, we can use only `a>1`   \n+\n+The result of this step is a map from index to the filter that should be used. For example, for the expression \n+`a=1 AND b>2 AND b<4`, and indexes on `(a, c)` and `(b)`, the result would be:\n+```\n+index(a, c) -> [a=1, NULL]\n+index(b) -> [b>2 AND b<4]\n+```\n+\n+Last, for every proposed index, we create a `MapIndexScanPhysicalRel` operator, that is added to the planner search space.\n+\n+## 3 Local Execution\n+\n+Scan operators consist of three parts:\n+1. Access path (direct scan, index scan)\n+1. Optional filter\n+1. Column list\n+\n+The execution proceeds as follows. First, an iterator over the underlying data is opened (record stores, index). Then every \n+returned record is evaluated against the optional filter. If record is not filtered out, it is converted to a `Row` instance\n+based on the column list. The `Row` is added to the internal batch. When the batch reaches a certain size, or there are no\n+more records, the batch of rows is returned to the parent operator. \n+\n+For the direct map scan (`MapScanExec`), the iterator scan all local partitions one by one. For the index scan \n+(`MapIndexScanExec`), the iterator is opened against the index, based on the optional index condition. In both cases,\n+the full result set of the scan is never materialized, unlike the legacy predicate engine.\n+\n+An entry might be changed concurrently during execution of the query. Since the engine doesn't have transactions, it is\n+possible that the updated entry will be observed zero, one or several times, due to entry relocation within the underlying\n+data structure. To solve this problem, we would need a transactional engine, but we do not have one. Note that the described \n+behavior is possible in many databases, including transactional one. Examples are: Redis [[1]], MongoDB [[2]], Microsoft ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4695be9542227e968384adcb79bd569a5007257f"}, "originalPosition": 90}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMTY4NTAxOnYy", "diffSide": "RIGHT", "path": "docs/design/sql/10-distributed-scan.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwNjo0ODozM1rOHbitAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwNjo0ODozM1rOHbitAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODY0MjE3Ng==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            actually owned partitions do not match, and exception is thrown. For example, if the member is expected to have partitions \n          \n          \n            \n            actually owned partitions do not match, an exception is thrown. For example, if the member is expected to have partitions", "url": "https://github.com/hazelcast/hazelcast/pull/17659#discussion_r498642176", "createdAt": "2020-10-02T06:48:33Z", "author": {"login": "viliam-durina"}, "path": "docs/design/sql/10-distributed-scan.md", "diffHunk": "@@ -0,0 +1,146 @@\n+# Distributed Scan\n+\n+## Overview\n+\n+The Hazelcast Mustang is a distributed query engine. When an SQL string is submitted for execution, it is converted into a \n+query plan, that contains the tree of relational operators, such as `scan`, `project` and `filter`. Leaf operators of the plan \n+act as data sources for the parent operators. The `scan` operator iterates over the `IMap` data structure. This document \n+explains how the distributed scan is performed.\n+\n+In this document, we describe the main design points of the scan operators: access path selection, local execution semantics,\n+and reaction to cluster reconfiguration.\n+\n+## 1 Background\n+\n+The Hazelcast IMDG is a distributed in-memory key-value storage. Data is stored in distributed objects, such as an `IMap`.\n+The cluster has a predefined number of partitions, 271 by default. Each partition is stored on a single member, and may have \n+zero, one or more backups on other members. Every distributed object is split across one or more partitions. Partitions may\n+migrate between members due to topology change events, such as member leave or join.\n+\n+The `IMap` is a distributed map. It could be accessed either directly, or through a secondary index. The secondary index is \n+a distributed data structure. Every member stores part of the index that is build for the local entries of the member. \n+\n+The goal of the Hazelcast Mustang engine is to pick the proper access method - direct scan or index scan, start execution of \n+the scan on members, and collect the results. In the above sections we describe how it is implemented.   \n+\n+## 2 Access Path Selection\n+\n+There are two ways to scan the `IMap` - iterate over the record store directly, or use one of the secondary indexes. During the\n+planning stage the proper access method is chosen. \n+\n+If there are no indexes on the table, the direct scan is chosen and no further optimization is performed.    \n+\n+If there are indexes on the table, we analyze the predicate stored in the table of the `TableScan` operator. The entry point\n+is `IndexResolver.createIndexScans`. \n+\n+First, we split the predicate into conjunctive normal form (CNF). For example, the predicate `a=1 AND b=2` is split into \n+`a=1` and `b=2`, while the predicate `a=1 OR b=2` remains unchanged.\n+\n+Second, for every sub-predicate we find those that could be used by some index. Assume that `col` is a simple column\n+expression, and `exp` is an expression that have only constants or parameters at leaves (i.e. it doesn't refer to other columns). \n+We use the following rules:\n+1. `col = exp` can be used with `SORTED` and `HASH` indexes\n+1. `col [comparison] exp` can be used with `SORTED` indexes\n+1. `col IS NULL/TRUE/FALSE` can be treated as equality expression (with slightly different semantics for `NULL` values)\n+1. 'col = exp1 OR col = exp2' can be treated as union of two equality predicates \n+\n+The result of this step is a map from column to candidate expressions that could be used with indexes. For example, \n+`a=1 AND b>2 AND b<4` is returned as: \n+```\n+a -> [=1] \n+b -> [>2], [<4]\n+```\n+\n+Next, we iterate over every index, and try to bind candidates to the index based on the index columns and index type.\n+General rules are:\n+1. `SORTED` index may use equality and comparison conditions, while `HASH` index may use only equality conditions\n+1. Only continuous prefix of index columns could be used. E.g. for the index `(a, b, c)` and the condition `a=1 AND c=2` we \n+can use only `a=1`\n+1. All expressions in the prefix except for the last one must be equality conditions. E.g. for the index `(a, b)` and the \n+condition `a>1 AND b>2`, we can use only `a>1`   \n+\n+The result of this step is a map from index to the filter that should be used. For example, for the expression \n+`a=1 AND b>2 AND b<4`, and indexes on `(a, c)` and `(b)`, the result would be:\n+```\n+index(a, c) -> [a=1, NULL]\n+index(b) -> [b>2 AND b<4]\n+```\n+\n+Last, for every proposed index, we create a `MapIndexScanPhysicalRel` operator, that is added to the planner search space.\n+\n+## 3 Local Execution\n+\n+Scan operators consist of three parts:\n+1. Access path (direct scan, index scan)\n+1. Optional filter\n+1. Column list\n+\n+The execution proceeds as follows. First, an iterator over the underlying data is opened (record stores, index). Then every \n+returned record is evaluated against the optional filter. If record is not filtered out, it is converted to a `Row` instance\n+based on the column list. The `Row` is added to the internal batch. When the batch reaches a certain size, or there are no\n+more records, the batch of rows is returned to the parent operator. \n+\n+For the direct map scan (`MapScanExec`), the iterator scan all local partitions one by one. For the index scan \n+(`MapIndexScanExec`), the iterator is opened against the index, based on the optional index condition. In both cases,\n+the full result set of the scan is never materialized, unlike the legacy predicate engine.\n+\n+An entry might be changed concurrently during execution of the query. Since the engine doesn't have transactions, it is\n+possible that the updated entry will be observed zero, one or several times, due to entry relocation within the underlying\n+data structure. To solve this problem, we would need a transactional engine, but we do not have one. Note that the described \n+behavior is possible in many databases, including transactional one. Examples are: Redis [[1]], MongoDB [[2]], Microsoft \n+SQL Server with `READ_COMMITTED` isolation (the default behavior) [[3]]. \n+\n+## 4 Cluster Reconfiguration\n+\n+Cluster configuration may change during query execution: partitions may migrate between members, distributed objects may be \n+created and destroyed. This section describes the behavior of scan operators in the case of concurrent cluster reconfiguration.\n+\n+### 4.1 Partition Migration\n+\n+If the query is executed concurrently with partition migration, it is possible that some partitions will be scanned several \n+times, or missed completely. To avoid that we need a mechanics to ensure that the engine observed every partition exactly\n+once.  \n+\n+When the plan is created, we create the so-called **partition map**, that maps members to partitions. The partition map is saved\n+in the plan. If the partition distribution changes due to member join/leave, the plan is invalidated.  \n+\n+When the query is about to start, we explicitly assign partitions to every participant. For example:\n+```\n+member1 -> [1, 2]\n+member2 -> [3, 4]\n+```  \n+\n+When the scan operation is started on the member, we first check whether it contains expected partitions. If the expected and \n+actually owned partitions do not match, and exception is thrown. For example, if the member is expected to have partitions ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4695be9542227e968384adcb79bd569a5007257f"}, "originalPosition": 114}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMTY4NzMwOnYy", "diffSide": "RIGHT", "path": "docs/design/sql/10-distributed-scan.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwNjo0OTo1OFrOHbiujQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwNjo0OTo1OFrOHbiujQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODY0MjU3Mw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            concurrently, leading to missed entries. To avoid inconsistent results we **re-check** the partition distribution, before any\n          \n          \n            \n            concurrently, leading to missed entries. To avoid inconsistent results we **re-check** the partition distribution before any", "url": "https://github.com/hazelcast/hazelcast/pull/17659#discussion_r498642573", "createdAt": "2020-10-02T06:49:58Z", "author": {"login": "viliam-durina"}, "path": "docs/design/sql/10-distributed-scan.md", "diffHunk": "@@ -0,0 +1,146 @@\n+# Distributed Scan\n+\n+## Overview\n+\n+The Hazelcast Mustang is a distributed query engine. When an SQL string is submitted for execution, it is converted into a \n+query plan, that contains the tree of relational operators, such as `scan`, `project` and `filter`. Leaf operators of the plan \n+act as data sources for the parent operators. The `scan` operator iterates over the `IMap` data structure. This document \n+explains how the distributed scan is performed.\n+\n+In this document, we describe the main design points of the scan operators: access path selection, local execution semantics,\n+and reaction to cluster reconfiguration.\n+\n+## 1 Background\n+\n+The Hazelcast IMDG is a distributed in-memory key-value storage. Data is stored in distributed objects, such as an `IMap`.\n+The cluster has a predefined number of partitions, 271 by default. Each partition is stored on a single member, and may have \n+zero, one or more backups on other members. Every distributed object is split across one or more partitions. Partitions may\n+migrate between members due to topology change events, such as member leave or join.\n+\n+The `IMap` is a distributed map. It could be accessed either directly, or through a secondary index. The secondary index is \n+a distributed data structure. Every member stores part of the index that is build for the local entries of the member. \n+\n+The goal of the Hazelcast Mustang engine is to pick the proper access method - direct scan or index scan, start execution of \n+the scan on members, and collect the results. In the above sections we describe how it is implemented.   \n+\n+## 2 Access Path Selection\n+\n+There are two ways to scan the `IMap` - iterate over the record store directly, or use one of the secondary indexes. During the\n+planning stage the proper access method is chosen. \n+\n+If there are no indexes on the table, the direct scan is chosen and no further optimization is performed.    \n+\n+If there are indexes on the table, we analyze the predicate stored in the table of the `TableScan` operator. The entry point\n+is `IndexResolver.createIndexScans`. \n+\n+First, we split the predicate into conjunctive normal form (CNF). For example, the predicate `a=1 AND b=2` is split into \n+`a=1` and `b=2`, while the predicate `a=1 OR b=2` remains unchanged.\n+\n+Second, for every sub-predicate we find those that could be used by some index. Assume that `col` is a simple column\n+expression, and `exp` is an expression that have only constants or parameters at leaves (i.e. it doesn't refer to other columns). \n+We use the following rules:\n+1. `col = exp` can be used with `SORTED` and `HASH` indexes\n+1. `col [comparison] exp` can be used with `SORTED` indexes\n+1. `col IS NULL/TRUE/FALSE` can be treated as equality expression (with slightly different semantics for `NULL` values)\n+1. 'col = exp1 OR col = exp2' can be treated as union of two equality predicates \n+\n+The result of this step is a map from column to candidate expressions that could be used with indexes. For example, \n+`a=1 AND b>2 AND b<4` is returned as: \n+```\n+a -> [=1] \n+b -> [>2], [<4]\n+```\n+\n+Next, we iterate over every index, and try to bind candidates to the index based on the index columns and index type.\n+General rules are:\n+1. `SORTED` index may use equality and comparison conditions, while `HASH` index may use only equality conditions\n+1. Only continuous prefix of index columns could be used. E.g. for the index `(a, b, c)` and the condition `a=1 AND c=2` we \n+can use only `a=1`\n+1. All expressions in the prefix except for the last one must be equality conditions. E.g. for the index `(a, b)` and the \n+condition `a>1 AND b>2`, we can use only `a>1`   \n+\n+The result of this step is a map from index to the filter that should be used. For example, for the expression \n+`a=1 AND b>2 AND b<4`, and indexes on `(a, c)` and `(b)`, the result would be:\n+```\n+index(a, c) -> [a=1, NULL]\n+index(b) -> [b>2 AND b<4]\n+```\n+\n+Last, for every proposed index, we create a `MapIndexScanPhysicalRel` operator, that is added to the planner search space.\n+\n+## 3 Local Execution\n+\n+Scan operators consist of three parts:\n+1. Access path (direct scan, index scan)\n+1. Optional filter\n+1. Column list\n+\n+The execution proceeds as follows. First, an iterator over the underlying data is opened (record stores, index). Then every \n+returned record is evaluated against the optional filter. If record is not filtered out, it is converted to a `Row` instance\n+based on the column list. The `Row` is added to the internal batch. When the batch reaches a certain size, or there are no\n+more records, the batch of rows is returned to the parent operator. \n+\n+For the direct map scan (`MapScanExec`), the iterator scan all local partitions one by one. For the index scan \n+(`MapIndexScanExec`), the iterator is opened against the index, based on the optional index condition. In both cases,\n+the full result set of the scan is never materialized, unlike the legacy predicate engine.\n+\n+An entry might be changed concurrently during execution of the query. Since the engine doesn't have transactions, it is\n+possible that the updated entry will be observed zero, one or several times, due to entry relocation within the underlying\n+data structure. To solve this problem, we would need a transactional engine, but we do not have one. Note that the described \n+behavior is possible in many databases, including transactional one. Examples are: Redis [[1]], MongoDB [[2]], Microsoft \n+SQL Server with `READ_COMMITTED` isolation (the default behavior) [[3]]. \n+\n+## 4 Cluster Reconfiguration\n+\n+Cluster configuration may change during query execution: partitions may migrate between members, distributed objects may be \n+created and destroyed. This section describes the behavior of scan operators in the case of concurrent cluster reconfiguration.\n+\n+### 4.1 Partition Migration\n+\n+If the query is executed concurrently with partition migration, it is possible that some partitions will be scanned several \n+times, or missed completely. To avoid that we need a mechanics to ensure that the engine observed every partition exactly\n+once.  \n+\n+When the plan is created, we create the so-called **partition map**, that maps members to partitions. The partition map is saved\n+in the plan. If the partition distribution changes due to member join/leave, the plan is invalidated.  \n+\n+When the query is about to start, we explicitly assign partitions to every participant. For example:\n+```\n+member1 -> [1, 2]\n+member2 -> [3, 4]\n+```  \n+\n+When the scan operation is started on the member, we first check whether it contains expected partitions. If the expected and \n+actually owned partitions do not match, and exception is thrown. For example, if the member is expected to have partitions \n+`[1, 2]`, then:\n+```\n+[1] - error, because we may miss the partition [2]\n+[1, 2] - ok\n+[1, 2, 3] - error, because we may return duplicates for the partition [3]\n+```\n+\n+The check before the query start is not sufficient to guarantee the correctness of the results. The partition may migrate to the \n+member during execution of the query, leading to duplicates. Conversely, the partition may be removed from the member \n+concurrently, leading to missed entries. To avoid inconsistent results we **re-check** the partition distribution, before any", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4695be9542227e968384adcb79bd569a5007257f"}, "originalPosition": 124}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMTY5NDk4OnYy", "diffSide": "RIGHT", "path": "docs/design/sql/10-distributed-scan.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwNjo1MzozMlrOHbizPA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwNjo1MzozMlrOHbizPA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODY0Mzc3Mg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Better solution would hide the partitioning problems from the user completely. This is, however, is difficult to achieve \n          \n          \n            \n            in practice. To avoid duplicates and missed entries, we would have to track which parts of the operator input is processed, and \n          \n          \n            \n            re-schedule scans to other members in runtime. Therefore, the current design ensures that user does not see an inconsistent\n          \n          \n            \n            result, but forces the user to re-run the query manually if the result correctness cannot be guaranteed by the engine. In the\n          \n          \n            \n            A better solution would hide the partitioning problems from the user completely. This, however, is difficult to achieve \n          \n          \n            \n            in practice. To avoid duplicates and missed entries we would have to track which part of the operator input is processed, and \n          \n          \n            \n            re-schedule scans to other members at runtime. Therefore, the current design ensures that the user does not see an inconsistent\n          \n          \n            \n            result, but forces the user to re-run the query manually if the result correctness cannot be guaranteed by the engine. In the", "url": "https://github.com/hazelcast/hazelcast/pull/17659#discussion_r498643772", "createdAt": "2020-10-02T06:53:32Z", "author": {"login": "viliam-durina"}, "path": "docs/design/sql/10-distributed-scan.md", "diffHunk": "@@ -0,0 +1,146 @@\n+# Distributed Scan\n+\n+## Overview\n+\n+The Hazelcast Mustang is a distributed query engine. When an SQL string is submitted for execution, it is converted into a \n+query plan, that contains the tree of relational operators, such as `scan`, `project` and `filter`. Leaf operators of the plan \n+act as data sources for the parent operators. The `scan` operator iterates over the `IMap` data structure. This document \n+explains how the distributed scan is performed.\n+\n+In this document, we describe the main design points of the scan operators: access path selection, local execution semantics,\n+and reaction to cluster reconfiguration.\n+\n+## 1 Background\n+\n+The Hazelcast IMDG is a distributed in-memory key-value storage. Data is stored in distributed objects, such as an `IMap`.\n+The cluster has a predefined number of partitions, 271 by default. Each partition is stored on a single member, and may have \n+zero, one or more backups on other members. Every distributed object is split across one or more partitions. Partitions may\n+migrate between members due to topology change events, such as member leave or join.\n+\n+The `IMap` is a distributed map. It could be accessed either directly, or through a secondary index. The secondary index is \n+a distributed data structure. Every member stores part of the index that is build for the local entries of the member. \n+\n+The goal of the Hazelcast Mustang engine is to pick the proper access method - direct scan or index scan, start execution of \n+the scan on members, and collect the results. In the above sections we describe how it is implemented.   \n+\n+## 2 Access Path Selection\n+\n+There are two ways to scan the `IMap` - iterate over the record store directly, or use one of the secondary indexes. During the\n+planning stage the proper access method is chosen. \n+\n+If there are no indexes on the table, the direct scan is chosen and no further optimization is performed.    \n+\n+If there are indexes on the table, we analyze the predicate stored in the table of the `TableScan` operator. The entry point\n+is `IndexResolver.createIndexScans`. \n+\n+First, we split the predicate into conjunctive normal form (CNF). For example, the predicate `a=1 AND b=2` is split into \n+`a=1` and `b=2`, while the predicate `a=1 OR b=2` remains unchanged.\n+\n+Second, for every sub-predicate we find those that could be used by some index. Assume that `col` is a simple column\n+expression, and `exp` is an expression that have only constants or parameters at leaves (i.e. it doesn't refer to other columns). \n+We use the following rules:\n+1. `col = exp` can be used with `SORTED` and `HASH` indexes\n+1. `col [comparison] exp` can be used with `SORTED` indexes\n+1. `col IS NULL/TRUE/FALSE` can be treated as equality expression (with slightly different semantics for `NULL` values)\n+1. 'col = exp1 OR col = exp2' can be treated as union of two equality predicates \n+\n+The result of this step is a map from column to candidate expressions that could be used with indexes. For example, \n+`a=1 AND b>2 AND b<4` is returned as: \n+```\n+a -> [=1] \n+b -> [>2], [<4]\n+```\n+\n+Next, we iterate over every index, and try to bind candidates to the index based on the index columns and index type.\n+General rules are:\n+1. `SORTED` index may use equality and comparison conditions, while `HASH` index may use only equality conditions\n+1. Only continuous prefix of index columns could be used. E.g. for the index `(a, b, c)` and the condition `a=1 AND c=2` we \n+can use only `a=1`\n+1. All expressions in the prefix except for the last one must be equality conditions. E.g. for the index `(a, b)` and the \n+condition `a>1 AND b>2`, we can use only `a>1`   \n+\n+The result of this step is a map from index to the filter that should be used. For example, for the expression \n+`a=1 AND b>2 AND b<4`, and indexes on `(a, c)` and `(b)`, the result would be:\n+```\n+index(a, c) -> [a=1, NULL]\n+index(b) -> [b>2 AND b<4]\n+```\n+\n+Last, for every proposed index, we create a `MapIndexScanPhysicalRel` operator, that is added to the planner search space.\n+\n+## 3 Local Execution\n+\n+Scan operators consist of three parts:\n+1. Access path (direct scan, index scan)\n+1. Optional filter\n+1. Column list\n+\n+The execution proceeds as follows. First, an iterator over the underlying data is opened (record stores, index). Then every \n+returned record is evaluated against the optional filter. If record is not filtered out, it is converted to a `Row` instance\n+based on the column list. The `Row` is added to the internal batch. When the batch reaches a certain size, or there are no\n+more records, the batch of rows is returned to the parent operator. \n+\n+For the direct map scan (`MapScanExec`), the iterator scan all local partitions one by one. For the index scan \n+(`MapIndexScanExec`), the iterator is opened against the index, based on the optional index condition. In both cases,\n+the full result set of the scan is never materialized, unlike the legacy predicate engine.\n+\n+An entry might be changed concurrently during execution of the query. Since the engine doesn't have transactions, it is\n+possible that the updated entry will be observed zero, one or several times, due to entry relocation within the underlying\n+data structure. To solve this problem, we would need a transactional engine, but we do not have one. Note that the described \n+behavior is possible in many databases, including transactional one. Examples are: Redis [[1]], MongoDB [[2]], Microsoft \n+SQL Server with `READ_COMMITTED` isolation (the default behavior) [[3]]. \n+\n+## 4 Cluster Reconfiguration\n+\n+Cluster configuration may change during query execution: partitions may migrate between members, distributed objects may be \n+created and destroyed. This section describes the behavior of scan operators in the case of concurrent cluster reconfiguration.\n+\n+### 4.1 Partition Migration\n+\n+If the query is executed concurrently with partition migration, it is possible that some partitions will be scanned several \n+times, or missed completely. To avoid that we need a mechanics to ensure that the engine observed every partition exactly\n+once.  \n+\n+When the plan is created, we create the so-called **partition map**, that maps members to partitions. The partition map is saved\n+in the plan. If the partition distribution changes due to member join/leave, the plan is invalidated.  \n+\n+When the query is about to start, we explicitly assign partitions to every participant. For example:\n+```\n+member1 -> [1, 2]\n+member2 -> [3, 4]\n+```  \n+\n+When the scan operation is started on the member, we first check whether it contains expected partitions. If the expected and \n+actually owned partitions do not match, and exception is thrown. For example, if the member is expected to have partitions \n+`[1, 2]`, then:\n+```\n+[1] - error, because we may miss the partition [2]\n+[1, 2] - ok\n+[1, 2, 3] - error, because we may return duplicates for the partition [3]\n+```\n+\n+The check before the query start is not sufficient to guarantee the correctness of the results. The partition may migrate to the \n+member during execution of the query, leading to duplicates. Conversely, the partition may be removed from the member \n+concurrently, leading to missed entries. To avoid inconsistent results we **re-check** the partition distribution, before any\n+result is returned from the scan operator. \n+\n+Partition check logic depends on the operator type. For the direct map scan, we use the migration stamps \n+(`MapService.validateMigrationStamp`). For the index scans, we use index partition stamps \n+(`InternalIndex.validatePartitionStamp`).\n+\n+Better solution would hide the partitioning problems from the user completely. This is, however, is difficult to achieve \n+in practice. To avoid duplicates and missed entries, we would have to track which parts of the operator input is processed, and \n+re-schedule scans to other members in runtime. Therefore, the current design ensures that user does not see an inconsistent\n+result, but forces the user to re-run the query manually if the result correctness cannot be guaranteed by the engine. In the", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4695be9542227e968384adcb79bd569a5007257f"}, "originalPosition": 134}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMTcwNjUyOnYy", "diffSide": "RIGHT", "path": "docs/design/sql/10-distributed-scan.md", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwNjo1ODo1NlrOHbi6hw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwOTo1NToyMlrOHbn4FQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODY0NTYzOQ==", "bodyText": "What if we have an index for (a, b): if we split the predicate like this, will we find the index? If yes, this algorithm isn't described.", "url": "https://github.com/hazelcast/hazelcast/pull/17659#discussion_r498645639", "createdAt": "2020-10-02T06:58:56Z", "author": {"login": "viliam-durina"}, "path": "docs/design/sql/10-distributed-scan.md", "diffHunk": "@@ -0,0 +1,146 @@\n+# Distributed Scan\n+\n+## Overview\n+\n+The Hazelcast Mustang is a distributed query engine. When an SQL string is submitted for execution, it is converted into a \n+query plan, that contains the tree of relational operators, such as `scan`, `project` and `filter`. Leaf operators of the plan \n+act as data sources for the parent operators. The `scan` operator iterates over the `IMap` data structure. This document \n+explains how the distributed scan is performed.\n+\n+In this document, we describe the main design points of the scan operators: access path selection, local execution semantics,\n+and reaction to cluster reconfiguration.\n+\n+## 1 Background\n+\n+The Hazelcast IMDG is a distributed in-memory key-value storage. Data is stored in distributed objects, such as an `IMap`.\n+The cluster has a predefined number of partitions, 271 by default. Each partition is stored on a single member, and may have \n+zero, one or more backups on other members. Every distributed object is split across one or more partitions. Partitions may\n+migrate between members due to topology change events, such as member leave or join.\n+\n+The `IMap` is a distributed map. It could be accessed either directly, or through a secondary index. The secondary index is \n+a distributed data structure. Every member stores part of the index that is build for the local entries of the member. \n+\n+The goal of the Hazelcast Mustang engine is to pick the proper access method - direct scan or index scan, start execution of \n+the scan on members, and collect the results. In the above sections we describe how it is implemented.   \n+\n+## 2 Access Path Selection\n+\n+There are two ways to scan the `IMap` - iterate over the record store directly, or use one of the secondary indexes. During the\n+planning stage the proper access method is chosen. \n+\n+If there are no indexes on the table, the direct scan is chosen and no further optimization is performed.    \n+\n+If there are indexes on the table, we analyze the predicate stored in the table of the `TableScan` operator. The entry point\n+is `IndexResolver.createIndexScans`. \n+\n+First, we split the predicate into conjunctive normal form (CNF). For example, the predicate `a=1 AND b=2` is split into \n+`a=1` and `b=2`, while the predicate `a=1 OR b=2` remains unchanged.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4695be9542227e968384adcb79bd569a5007257f"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODY1MTM0Mw==", "bodyText": "It is explained in the next paragraphs - we assign every column a list of candidate predicates, then we iterate over all indexes, trying to build the index filter, using column predicates.", "url": "https://github.com/hazelcast/hazelcast/pull/17659#discussion_r498651343", "createdAt": "2020-10-02T07:15:08Z", "author": {"login": "devozerov"}, "path": "docs/design/sql/10-distributed-scan.md", "diffHunk": "@@ -0,0 +1,146 @@\n+# Distributed Scan\n+\n+## Overview\n+\n+The Hazelcast Mustang is a distributed query engine. When an SQL string is submitted for execution, it is converted into a \n+query plan, that contains the tree of relational operators, such as `scan`, `project` and `filter`. Leaf operators of the plan \n+act as data sources for the parent operators. The `scan` operator iterates over the `IMap` data structure. This document \n+explains how the distributed scan is performed.\n+\n+In this document, we describe the main design points of the scan operators: access path selection, local execution semantics,\n+and reaction to cluster reconfiguration.\n+\n+## 1 Background\n+\n+The Hazelcast IMDG is a distributed in-memory key-value storage. Data is stored in distributed objects, such as an `IMap`.\n+The cluster has a predefined number of partitions, 271 by default. Each partition is stored on a single member, and may have \n+zero, one or more backups on other members. Every distributed object is split across one or more partitions. Partitions may\n+migrate between members due to topology change events, such as member leave or join.\n+\n+The `IMap` is a distributed map. It could be accessed either directly, or through a secondary index. The secondary index is \n+a distributed data structure. Every member stores part of the index that is build for the local entries of the member. \n+\n+The goal of the Hazelcast Mustang engine is to pick the proper access method - direct scan or index scan, start execution of \n+the scan on members, and collect the results. In the above sections we describe how it is implemented.   \n+\n+## 2 Access Path Selection\n+\n+There are two ways to scan the `IMap` - iterate over the record store directly, or use one of the secondary indexes. During the\n+planning stage the proper access method is chosen. \n+\n+If there are no indexes on the table, the direct scan is chosen and no further optimization is performed.    \n+\n+If there are indexes on the table, we analyze the predicate stored in the table of the `TableScan` operator. The entry point\n+is `IndexResolver.createIndexScans`. \n+\n+First, we split the predicate into conjunctive normal form (CNF). For example, the predicate `a=1 AND b=2` is split into \n+`a=1` and `b=2`, while the predicate `a=1 OR b=2` remains unchanged.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODY0NTYzOQ=="}, "originalCommit": {"oid": "4695be9542227e968384adcb79bd569a5007257f"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyMDkxMQ==", "bodyText": "I guess it's like this:\n\ninput: predicate:  a=1 AND b=2, index: HASH(a, b)\nwe split the predicate into a=1 and b=2\nfor each sub-predicate we find an index that can be used. For a=1 the HASH(a, b) index can be used. For b=1, no index can be used. We continue with a=1 only\nwhen applying a=1 to the HASH(a, b) index we try to apply more predicates. We realize that we can also use the b=1 condition. And this step is not mentioned in the text, at least I can't find it. I think it happens in this method.", "url": "https://github.com/hazelcast/hazelcast/pull/17659#discussion_r498720911", "createdAt": "2020-10-02T09:42:32Z", "author": {"login": "viliam-durina"}, "path": "docs/design/sql/10-distributed-scan.md", "diffHunk": "@@ -0,0 +1,146 @@\n+# Distributed Scan\n+\n+## Overview\n+\n+The Hazelcast Mustang is a distributed query engine. When an SQL string is submitted for execution, it is converted into a \n+query plan, that contains the tree of relational operators, such as `scan`, `project` and `filter`. Leaf operators of the plan \n+act as data sources for the parent operators. The `scan` operator iterates over the `IMap` data structure. This document \n+explains how the distributed scan is performed.\n+\n+In this document, we describe the main design points of the scan operators: access path selection, local execution semantics,\n+and reaction to cluster reconfiguration.\n+\n+## 1 Background\n+\n+The Hazelcast IMDG is a distributed in-memory key-value storage. Data is stored in distributed objects, such as an `IMap`.\n+The cluster has a predefined number of partitions, 271 by default. Each partition is stored on a single member, and may have \n+zero, one or more backups on other members. Every distributed object is split across one or more partitions. Partitions may\n+migrate between members due to topology change events, such as member leave or join.\n+\n+The `IMap` is a distributed map. It could be accessed either directly, or through a secondary index. The secondary index is \n+a distributed data structure. Every member stores part of the index that is build for the local entries of the member. \n+\n+The goal of the Hazelcast Mustang engine is to pick the proper access method - direct scan or index scan, start execution of \n+the scan on members, and collect the results. In the above sections we describe how it is implemented.   \n+\n+## 2 Access Path Selection\n+\n+There are two ways to scan the `IMap` - iterate over the record store directly, or use one of the secondary indexes. During the\n+planning stage the proper access method is chosen. \n+\n+If there are no indexes on the table, the direct scan is chosen and no further optimization is performed.    \n+\n+If there are indexes on the table, we analyze the predicate stored in the table of the `TableScan` operator. The entry point\n+is `IndexResolver.createIndexScans`. \n+\n+First, we split the predicate into conjunctive normal form (CNF). For example, the predicate `a=1 AND b=2` is split into \n+`a=1` and `b=2`, while the predicate `a=1 OR b=2` remains unchanged.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODY0NTYzOQ=="}, "originalCommit": {"oid": "4695be9542227e968384adcb79bd569a5007257f"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyNjkzMw==", "bodyText": "This is explained in the paragraph \"Next, we iterate over every index, and try to bind candidates ...\". I expanded the explanation a bit: 612958c", "url": "https://github.com/hazelcast/hazelcast/pull/17659#discussion_r498726933", "createdAt": "2020-10-02T09:55:22Z", "author": {"login": "devozerov"}, "path": "docs/design/sql/10-distributed-scan.md", "diffHunk": "@@ -0,0 +1,146 @@\n+# Distributed Scan\n+\n+## Overview\n+\n+The Hazelcast Mustang is a distributed query engine. When an SQL string is submitted for execution, it is converted into a \n+query plan, that contains the tree of relational operators, such as `scan`, `project` and `filter`. Leaf operators of the plan \n+act as data sources for the parent operators. The `scan` operator iterates over the `IMap` data structure. This document \n+explains how the distributed scan is performed.\n+\n+In this document, we describe the main design points of the scan operators: access path selection, local execution semantics,\n+and reaction to cluster reconfiguration.\n+\n+## 1 Background\n+\n+The Hazelcast IMDG is a distributed in-memory key-value storage. Data is stored in distributed objects, such as an `IMap`.\n+The cluster has a predefined number of partitions, 271 by default. Each partition is stored on a single member, and may have \n+zero, one or more backups on other members. Every distributed object is split across one or more partitions. Partitions may\n+migrate between members due to topology change events, such as member leave or join.\n+\n+The `IMap` is a distributed map. It could be accessed either directly, or through a secondary index. The secondary index is \n+a distributed data structure. Every member stores part of the index that is build for the local entries of the member. \n+\n+The goal of the Hazelcast Mustang engine is to pick the proper access method - direct scan or index scan, start execution of \n+the scan on members, and collect the results. In the above sections we describe how it is implemented.   \n+\n+## 2 Access Path Selection\n+\n+There are two ways to scan the `IMap` - iterate over the record store directly, or use one of the secondary indexes. During the\n+planning stage the proper access method is chosen. \n+\n+If there are no indexes on the table, the direct scan is chosen and no further optimization is performed.    \n+\n+If there are indexes on the table, we analyze the predicate stored in the table of the `TableScan` operator. The entry point\n+is `IndexResolver.createIndexScans`. \n+\n+First, we split the predicate into conjunctive normal form (CNF). For example, the predicate `a=1 AND b=2` is split into \n+`a=1` and `b=2`, while the predicate `a=1 OR b=2` remains unchanged.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODY0NTYzOQ=="}, "originalCommit": {"oid": "4695be9542227e968384adcb79bd569a5007257f"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMjEyNTA3OnYy", "diffSide": "RIGHT", "path": "docs/design/sql/10-distributed-scan.md", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwOToyNDoxOFrOHbm_cg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwOTo1NzoxMFrOHbn7cA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcxMjQzNA==", "bodyText": "It would be great to have a paragraph on costing, how and why one scan is preferred over another index or map scan.", "url": "https://github.com/hazelcast/hazelcast/pull/17659#discussion_r498712434", "createdAt": "2020-10-02T09:24:18Z", "author": {"login": "taburet"}, "path": "docs/design/sql/10-distributed-scan.md", "diffHunk": "@@ -0,0 +1,146 @@\n+# Distributed Scan\n+\n+## Overview\n+\n+The Hazelcast Mustang is a distributed query engine. When an SQL string is submitted for execution, it is converted into a \n+query plan, that contains the tree of relational operators, such as `scan`, `project` and `filter`. Leaf operators of the plan \n+act as data sources for the parent operators. The `scan` operator iterates over the `IMap` data structure. This document \n+explains how the distributed scan is performed.\n+\n+In this document, we describe the main design points of the scan operators: access path selection, local execution semantics,\n+and reaction to cluster reconfiguration.\n+\n+## 1 Background\n+\n+The Hazelcast IMDG is a distributed in-memory key-value storage. Data is stored in distributed objects, such as an `IMap`.\n+The cluster has a predefined number of partitions, 271 by default. Each partition is stored on a single member, and may have \n+zero, one or more backups on other members. Every distributed object is split across one or more partitions. Partitions may\n+migrate between members due to topology change events, such as member leave or join.\n+\n+The `IMap` is a distributed map. It could be accessed either directly, or through a secondary index. The secondary index is \n+a distributed data structure. Every member stores part of the index that is built for the local entries of the member. \n+\n+The goal of the Hazelcast Mustang engine is to pick the proper access method - direct scan or index scan, start execution of \n+the scan on members, and collect the results. In the above sections we describe how it is implemented.   \n+\n+## 2 Access Path Selection\n+\n+There are two ways to scan the `IMap` - iterate over the record store directly, or use one of the secondary indexes. During the\n+planning stage the proper access method is chosen. \n+\n+If there are no indexes on the table, the direct scan is chosen and no further optimization is performed.    \n+\n+If there are indexes on the table, we analyze the predicate stored in the table of the `TableScan` operator. The entry point\n+is `IndexResolver.createIndexScans`. \n+\n+First, we split the predicate into conjunctive normal form (CNF). For example, the predicate `a=1 AND b=2` is split into \n+`a=1` and `b=2`, while the predicate `a=1 OR b=2` remains unchanged.\n+\n+Second, for every sub-predicate we find those that could be used by some index. Assume that `col` is a simple column\n+expression, and `exp` is an expression that has only constants or parameters at leaves (i.e. it doesn't refer to other columns). \n+We use the following rules:\n+1. `col = exp` can be used with `SORTED` and `HASH` indexes\n+1. `col [comparison] exp` can be used with `SORTED` indexes\n+1. `col IS NULL/TRUE/FALSE` can be treated as equality expression (with slightly different semantics for `NULL` values)\n+1. `col = exp1 OR col = exp2` can be treated as union of two equality predicates \n+\n+The result of this step is a map from column to candidate expressions that could be used with indexes. For example, \n+`a=1 AND b>2 AND b<4` is returned as: \n+```\n+a -> [=1] \n+b -> [>2], [<4]\n+```\n+\n+Next, we iterate over every index, and try to bind candidates to the index based on the index columns and index type.\n+General rules are:\n+1. `SORTED` index may use equality and comparison conditions, while `HASH` index may use only equality conditions\n+1. Only a continuous prefix of index columns can be used. E.g. for the index `(a, b, c)` and the condition `a=1 AND c=2` we \n+can use only `a=1`\n+1. All expressions in the prefix except for the last one must be equality conditions. E.g. for the index `(a, b)` and the \n+condition `a>1 AND b>2`, we can use only `a>1`   \n+\n+The result of this step is a map from index to the filter that should be used. For example, for the expression \n+`a=1 AND b>2 AND b<4`, and indexes on `(a, c)` and `(b)`, the result would be:\n+```\n+index(a, c) -> [a=1, NULL]\n+index(b) -> [b>2 AND b<4]\n+```\n+\n+At last, for every proposed index, we create a `MapIndexScanPhysicalRel` operator that is added to the planner search space.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "55af70162f3068e4b317444d7090fe82d414d713"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcxNzEzMw==", "bodyText": "It also worth to mention potential performance implications of having many matching index scans, how does it affect  the planing time, possible solutions for improving it, etc.", "url": "https://github.com/hazelcast/hazelcast/pull/17659#discussion_r498717133", "createdAt": "2020-10-02T09:34:15Z", "author": {"login": "taburet"}, "path": "docs/design/sql/10-distributed-scan.md", "diffHunk": "@@ -0,0 +1,146 @@\n+# Distributed Scan\n+\n+## Overview\n+\n+The Hazelcast Mustang is a distributed query engine. When an SQL string is submitted for execution, it is converted into a \n+query plan, that contains the tree of relational operators, such as `scan`, `project` and `filter`. Leaf operators of the plan \n+act as data sources for the parent operators. The `scan` operator iterates over the `IMap` data structure. This document \n+explains how the distributed scan is performed.\n+\n+In this document, we describe the main design points of the scan operators: access path selection, local execution semantics,\n+and reaction to cluster reconfiguration.\n+\n+## 1 Background\n+\n+The Hazelcast IMDG is a distributed in-memory key-value storage. Data is stored in distributed objects, such as an `IMap`.\n+The cluster has a predefined number of partitions, 271 by default. Each partition is stored on a single member, and may have \n+zero, one or more backups on other members. Every distributed object is split across one or more partitions. Partitions may\n+migrate between members due to topology change events, such as member leave or join.\n+\n+The `IMap` is a distributed map. It could be accessed either directly, or through a secondary index. The secondary index is \n+a distributed data structure. Every member stores part of the index that is built for the local entries of the member. \n+\n+The goal of the Hazelcast Mustang engine is to pick the proper access method - direct scan or index scan, start execution of \n+the scan on members, and collect the results. In the above sections we describe how it is implemented.   \n+\n+## 2 Access Path Selection\n+\n+There are two ways to scan the `IMap` - iterate over the record store directly, or use one of the secondary indexes. During the\n+planning stage the proper access method is chosen. \n+\n+If there are no indexes on the table, the direct scan is chosen and no further optimization is performed.    \n+\n+If there are indexes on the table, we analyze the predicate stored in the table of the `TableScan` operator. The entry point\n+is `IndexResolver.createIndexScans`. \n+\n+First, we split the predicate into conjunctive normal form (CNF). For example, the predicate `a=1 AND b=2` is split into \n+`a=1` and `b=2`, while the predicate `a=1 OR b=2` remains unchanged.\n+\n+Second, for every sub-predicate we find those that could be used by some index. Assume that `col` is a simple column\n+expression, and `exp` is an expression that has only constants or parameters at leaves (i.e. it doesn't refer to other columns). \n+We use the following rules:\n+1. `col = exp` can be used with `SORTED` and `HASH` indexes\n+1. `col [comparison] exp` can be used with `SORTED` indexes\n+1. `col IS NULL/TRUE/FALSE` can be treated as equality expression (with slightly different semantics for `NULL` values)\n+1. `col = exp1 OR col = exp2` can be treated as union of two equality predicates \n+\n+The result of this step is a map from column to candidate expressions that could be used with indexes. For example, \n+`a=1 AND b>2 AND b<4` is returned as: \n+```\n+a -> [=1] \n+b -> [>2], [<4]\n+```\n+\n+Next, we iterate over every index, and try to bind candidates to the index based on the index columns and index type.\n+General rules are:\n+1. `SORTED` index may use equality and comparison conditions, while `HASH` index may use only equality conditions\n+1. Only a continuous prefix of index columns can be used. E.g. for the index `(a, b, c)` and the condition `a=1 AND c=2` we \n+can use only `a=1`\n+1. All expressions in the prefix except for the last one must be equality conditions. E.g. for the index `(a, b)` and the \n+condition `a>1 AND b>2`, we can use only `a>1`   \n+\n+The result of this step is a map from index to the filter that should be used. For example, for the expression \n+`a=1 AND b>2 AND b<4`, and indexes on `(a, c)` and `(b)`, the result would be:\n+```\n+index(a, c) -> [a=1, NULL]\n+index(b) -> [b>2 AND b<4]\n+```\n+\n+At last, for every proposed index, we create a `MapIndexScanPhysicalRel` operator that is added to the planner search space.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcxMjQzNA=="}, "originalCommit": {"oid": "55af70162f3068e4b317444d7090fe82d414d713"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyMzU0Mw==", "bodyText": "Add an explanation of the cost model.", "url": "https://github.com/hazelcast/hazelcast/pull/17659#discussion_r498723543", "createdAt": "2020-10-02T09:48:13Z", "author": {"login": "devozerov"}, "path": "docs/design/sql/10-distributed-scan.md", "diffHunk": "@@ -0,0 +1,146 @@\n+# Distributed Scan\n+\n+## Overview\n+\n+The Hazelcast Mustang is a distributed query engine. When an SQL string is submitted for execution, it is converted into a \n+query plan, that contains the tree of relational operators, such as `scan`, `project` and `filter`. Leaf operators of the plan \n+act as data sources for the parent operators. The `scan` operator iterates over the `IMap` data structure. This document \n+explains how the distributed scan is performed.\n+\n+In this document, we describe the main design points of the scan operators: access path selection, local execution semantics,\n+and reaction to cluster reconfiguration.\n+\n+## 1 Background\n+\n+The Hazelcast IMDG is a distributed in-memory key-value storage. Data is stored in distributed objects, such as an `IMap`.\n+The cluster has a predefined number of partitions, 271 by default. Each partition is stored on a single member, and may have \n+zero, one or more backups on other members. Every distributed object is split across one or more partitions. Partitions may\n+migrate between members due to topology change events, such as member leave or join.\n+\n+The `IMap` is a distributed map. It could be accessed either directly, or through a secondary index. The secondary index is \n+a distributed data structure. Every member stores part of the index that is built for the local entries of the member. \n+\n+The goal of the Hazelcast Mustang engine is to pick the proper access method - direct scan or index scan, start execution of \n+the scan on members, and collect the results. In the above sections we describe how it is implemented.   \n+\n+## 2 Access Path Selection\n+\n+There are two ways to scan the `IMap` - iterate over the record store directly, or use one of the secondary indexes. During the\n+planning stage the proper access method is chosen. \n+\n+If there are no indexes on the table, the direct scan is chosen and no further optimization is performed.    \n+\n+If there are indexes on the table, we analyze the predicate stored in the table of the `TableScan` operator. The entry point\n+is `IndexResolver.createIndexScans`. \n+\n+First, we split the predicate into conjunctive normal form (CNF). For example, the predicate `a=1 AND b=2` is split into \n+`a=1` and `b=2`, while the predicate `a=1 OR b=2` remains unchanged.\n+\n+Second, for every sub-predicate we find those that could be used by some index. Assume that `col` is a simple column\n+expression, and `exp` is an expression that has only constants or parameters at leaves (i.e. it doesn't refer to other columns). \n+We use the following rules:\n+1. `col = exp` can be used with `SORTED` and `HASH` indexes\n+1. `col [comparison] exp` can be used with `SORTED` indexes\n+1. `col IS NULL/TRUE/FALSE` can be treated as equality expression (with slightly different semantics for `NULL` values)\n+1. `col = exp1 OR col = exp2` can be treated as union of two equality predicates \n+\n+The result of this step is a map from column to candidate expressions that could be used with indexes. For example, \n+`a=1 AND b>2 AND b<4` is returned as: \n+```\n+a -> [=1] \n+b -> [>2], [<4]\n+```\n+\n+Next, we iterate over every index, and try to bind candidates to the index based on the index columns and index type.\n+General rules are:\n+1. `SORTED` index may use equality and comparison conditions, while `HASH` index may use only equality conditions\n+1. Only a continuous prefix of index columns can be used. E.g. for the index `(a, b, c)` and the condition `a=1 AND c=2` we \n+can use only `a=1`\n+1. All expressions in the prefix except for the last one must be equality conditions. E.g. for the index `(a, b)` and the \n+condition `a>1 AND b>2`, we can use only `a>1`   \n+\n+The result of this step is a map from index to the filter that should be used. For example, for the expression \n+`a=1 AND b>2 AND b<4`, and indexes on `(a, c)` and `(b)`, the result would be:\n+```\n+index(a, c) -> [a=1, NULL]\n+index(b) -> [b>2 AND b<4]\n+```\n+\n+At last, for every proposed index, we create a `MapIndexScanPhysicalRel` operator that is added to the planner search space.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcxMjQzNA=="}, "originalCommit": {"oid": "55af70162f3068e4b317444d7090fe82d414d713"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyNzc5Mg==", "bodyText": "Index planning doesn't have any significant impact at the moment, because we do not have joins. We will have to reconsider how we add indexes to the search space in the future and add the appropriate design documentation.", "url": "https://github.com/hazelcast/hazelcast/pull/17659#discussion_r498727792", "createdAt": "2020-10-02T09:57:10Z", "author": {"login": "devozerov"}, "path": "docs/design/sql/10-distributed-scan.md", "diffHunk": "@@ -0,0 +1,146 @@\n+# Distributed Scan\n+\n+## Overview\n+\n+The Hazelcast Mustang is a distributed query engine. When an SQL string is submitted for execution, it is converted into a \n+query plan, that contains the tree of relational operators, such as `scan`, `project` and `filter`. Leaf operators of the plan \n+act as data sources for the parent operators. The `scan` operator iterates over the `IMap` data structure. This document \n+explains how the distributed scan is performed.\n+\n+In this document, we describe the main design points of the scan operators: access path selection, local execution semantics,\n+and reaction to cluster reconfiguration.\n+\n+## 1 Background\n+\n+The Hazelcast IMDG is a distributed in-memory key-value storage. Data is stored in distributed objects, such as an `IMap`.\n+The cluster has a predefined number of partitions, 271 by default. Each partition is stored on a single member, and may have \n+zero, one or more backups on other members. Every distributed object is split across one or more partitions. Partitions may\n+migrate between members due to topology change events, such as member leave or join.\n+\n+The `IMap` is a distributed map. It could be accessed either directly, or through a secondary index. The secondary index is \n+a distributed data structure. Every member stores part of the index that is built for the local entries of the member. \n+\n+The goal of the Hazelcast Mustang engine is to pick the proper access method - direct scan or index scan, start execution of \n+the scan on members, and collect the results. In the above sections we describe how it is implemented.   \n+\n+## 2 Access Path Selection\n+\n+There are two ways to scan the `IMap` - iterate over the record store directly, or use one of the secondary indexes. During the\n+planning stage the proper access method is chosen. \n+\n+If there are no indexes on the table, the direct scan is chosen and no further optimization is performed.    \n+\n+If there are indexes on the table, we analyze the predicate stored in the table of the `TableScan` operator. The entry point\n+is `IndexResolver.createIndexScans`. \n+\n+First, we split the predicate into conjunctive normal form (CNF). For example, the predicate `a=1 AND b=2` is split into \n+`a=1` and `b=2`, while the predicate `a=1 OR b=2` remains unchanged.\n+\n+Second, for every sub-predicate we find those that could be used by some index. Assume that `col` is a simple column\n+expression, and `exp` is an expression that has only constants or parameters at leaves (i.e. it doesn't refer to other columns). \n+We use the following rules:\n+1. `col = exp` can be used with `SORTED` and `HASH` indexes\n+1. `col [comparison] exp` can be used with `SORTED` indexes\n+1. `col IS NULL/TRUE/FALSE` can be treated as equality expression (with slightly different semantics for `NULL` values)\n+1. `col = exp1 OR col = exp2` can be treated as union of two equality predicates \n+\n+The result of this step is a map from column to candidate expressions that could be used with indexes. For example, \n+`a=1 AND b>2 AND b<4` is returned as: \n+```\n+a -> [=1] \n+b -> [>2], [<4]\n+```\n+\n+Next, we iterate over every index, and try to bind candidates to the index based on the index columns and index type.\n+General rules are:\n+1. `SORTED` index may use equality and comparison conditions, while `HASH` index may use only equality conditions\n+1. Only a continuous prefix of index columns can be used. E.g. for the index `(a, b, c)` and the condition `a=1 AND c=2` we \n+can use only `a=1`\n+1. All expressions in the prefix except for the last one must be equality conditions. E.g. for the index `(a, b)` and the \n+condition `a>1 AND b>2`, we can use only `a>1`   \n+\n+The result of this step is a map from index to the filter that should be used. For example, for the expression \n+`a=1 AND b>2 AND b<4`, and indexes on `(a, c)` and `(b)`, the result would be:\n+```\n+index(a, c) -> [a=1, NULL]\n+index(b) -> [b>2 AND b<4]\n+```\n+\n+At last, for every proposed index, we create a `MapIndexScanPhysicalRel` operator that is added to the planner search space.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcxMjQzNA=="}, "originalCommit": {"oid": "55af70162f3068e4b317444d7090fe82d414d713"}, "originalPosition": 69}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMjE3NTk5OnYy", "diffSide": "RIGHT", "path": "docs/design/sql/10-distributed-scan.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwOTo0MTo1OFrOHbnfjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwOTo1MDo1NFrOHbnwAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyMDY1Mw==", "bodyText": "Is there any specific reason why partitions are scanned one by one and not in parallel?", "url": "https://github.com/hazelcast/hazelcast/pull/17659#discussion_r498720653", "createdAt": "2020-10-02T09:41:58Z", "author": {"login": "taburet"}, "path": "docs/design/sql/10-distributed-scan.md", "diffHunk": "@@ -0,0 +1,146 @@\n+# Distributed Scan\n+\n+## Overview\n+\n+The Hazelcast Mustang is a distributed query engine. When an SQL string is submitted for execution, it is converted into a \n+query plan, that contains the tree of relational operators, such as `scan`, `project` and `filter`. Leaf operators of the plan \n+act as data sources for the parent operators. The `scan` operator iterates over the `IMap` data structure. This document \n+explains how the distributed scan is performed.\n+\n+In this document, we describe the main design points of the scan operators: access path selection, local execution semantics,\n+and reaction to cluster reconfiguration.\n+\n+## 1 Background\n+\n+The Hazelcast IMDG is a distributed in-memory key-value storage. Data is stored in distributed objects, such as an `IMap`.\n+The cluster has a predefined number of partitions, 271 by default. Each partition is stored on a single member, and may have \n+zero, one or more backups on other members. Every distributed object is split across one or more partitions. Partitions may\n+migrate between members due to topology change events, such as member leave or join.\n+\n+The `IMap` is a distributed map. It could be accessed either directly, or through a secondary index. The secondary index is \n+a distributed data structure. Every member stores part of the index that is built for the local entries of the member. \n+\n+The goal of the Hazelcast Mustang engine is to pick the proper access method - direct scan or index scan, start execution of \n+the scan on members, and collect the results. In the above sections we describe how it is implemented.   \n+\n+## 2 Access Path Selection\n+\n+There are two ways to scan the `IMap` - iterate over the record store directly, or use one of the secondary indexes. During the\n+planning stage the proper access method is chosen. \n+\n+If there are no indexes on the table, the direct scan is chosen and no further optimization is performed.    \n+\n+If there are indexes on the table, we analyze the predicate stored in the table of the `TableScan` operator. The entry point\n+is `IndexResolver.createIndexScans`. \n+\n+First, we split the predicate into conjunctive normal form (CNF). For example, the predicate `a=1 AND b=2` is split into \n+`a=1` and `b=2`, while the predicate `a=1 OR b=2` remains unchanged.\n+\n+Second, for every sub-predicate we find those that could be used by some index. Assume that `col` is a simple column\n+expression, and `exp` is an expression that has only constants or parameters at leaves (i.e. it doesn't refer to other columns). \n+We use the following rules:\n+1. `col = exp` can be used with `SORTED` and `HASH` indexes\n+1. `col [comparison] exp` can be used with `SORTED` indexes\n+1. `col IS NULL/TRUE/FALSE` can be treated as equality expression (with slightly different semantics for `NULL` values)\n+1. `col = exp1 OR col = exp2` can be treated as union of two equality predicates \n+\n+The result of this step is a map from column to candidate expressions that could be used with indexes. For example, \n+`a=1 AND b>2 AND b<4` is returned as: \n+```\n+a -> [=1] \n+b -> [>2], [<4]\n+```\n+\n+Next, we iterate over every index, and try to bind candidates to the index based on the index columns and index type.\n+General rules are:\n+1. `SORTED` index may use equality and comparison conditions, while `HASH` index may use only equality conditions\n+1. Only a continuous prefix of index columns can be used. E.g. for the index `(a, b, c)` and the condition `a=1 AND c=2` we \n+can use only `a=1`\n+1. All expressions in the prefix except for the last one must be equality conditions. E.g. for the index `(a, b)` and the \n+condition `a>1 AND b>2`, we can use only `a>1`   \n+\n+The result of this step is a map from index to the filter that should be used. For example, for the expression \n+`a=1 AND b>2 AND b<4`, and indexes on `(a, c)` and `(b)`, the result would be:\n+```\n+index(a, c) -> [a=1, NULL]\n+index(b) -> [b>2 AND b<4]\n+```\n+\n+At last, for every proposed index, we create a `MapIndexScanPhysicalRel` operator that is added to the planner search space.\n+\n+## 3 Local Execution\n+\n+Scan operators consist of three parts:\n+1. Access path (direct scan, index scan)\n+1. Optional filter\n+1. Column list\n+\n+The execution proceeds as follows. First, an iterator over the underlying data is opened (record stores, index). Then every \n+returned record is evaluated against the optional filter. If record is not filtered out, it is converted to a `Row` instance\n+based on the column list. The `Row` is added to the internal batch. When the batch reaches a certain size, or there are no\n+more records, the batch of rows is returned to the parent operator. \n+\n+For the direct map scan (`MapScanExec`), the iterator scans all local partitions one by one. For the index scan ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "55af70162f3068e4b317444d7090fe82d414d713"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyNDg2NA==", "bodyText": "We do not have operator parallelism yet, because this is a complicated topic. Parallelism increases total query resource consumption (e.g. memory buffers) and decrease total system throughput under load. We will have it in the future, but after the careful design and prototype are ready.", "url": "https://github.com/hazelcast/hazelcast/pull/17659#discussion_r498724864", "createdAt": "2020-10-02T09:50:54Z", "author": {"login": "devozerov"}, "path": "docs/design/sql/10-distributed-scan.md", "diffHunk": "@@ -0,0 +1,146 @@\n+# Distributed Scan\n+\n+## Overview\n+\n+The Hazelcast Mustang is a distributed query engine. When an SQL string is submitted for execution, it is converted into a \n+query plan, that contains the tree of relational operators, such as `scan`, `project` and `filter`. Leaf operators of the plan \n+act as data sources for the parent operators. The `scan` operator iterates over the `IMap` data structure. This document \n+explains how the distributed scan is performed.\n+\n+In this document, we describe the main design points of the scan operators: access path selection, local execution semantics,\n+and reaction to cluster reconfiguration.\n+\n+## 1 Background\n+\n+The Hazelcast IMDG is a distributed in-memory key-value storage. Data is stored in distributed objects, such as an `IMap`.\n+The cluster has a predefined number of partitions, 271 by default. Each partition is stored on a single member, and may have \n+zero, one or more backups on other members. Every distributed object is split across one or more partitions. Partitions may\n+migrate between members due to topology change events, such as member leave or join.\n+\n+The `IMap` is a distributed map. It could be accessed either directly, or through a secondary index. The secondary index is \n+a distributed data structure. Every member stores part of the index that is built for the local entries of the member. \n+\n+The goal of the Hazelcast Mustang engine is to pick the proper access method - direct scan or index scan, start execution of \n+the scan on members, and collect the results. In the above sections we describe how it is implemented.   \n+\n+## 2 Access Path Selection\n+\n+There are two ways to scan the `IMap` - iterate over the record store directly, or use one of the secondary indexes. During the\n+planning stage the proper access method is chosen. \n+\n+If there are no indexes on the table, the direct scan is chosen and no further optimization is performed.    \n+\n+If there are indexes on the table, we analyze the predicate stored in the table of the `TableScan` operator. The entry point\n+is `IndexResolver.createIndexScans`. \n+\n+First, we split the predicate into conjunctive normal form (CNF). For example, the predicate `a=1 AND b=2` is split into \n+`a=1` and `b=2`, while the predicate `a=1 OR b=2` remains unchanged.\n+\n+Second, for every sub-predicate we find those that could be used by some index. Assume that `col` is a simple column\n+expression, and `exp` is an expression that has only constants or parameters at leaves (i.e. it doesn't refer to other columns). \n+We use the following rules:\n+1. `col = exp` can be used with `SORTED` and `HASH` indexes\n+1. `col [comparison] exp` can be used with `SORTED` indexes\n+1. `col IS NULL/TRUE/FALSE` can be treated as equality expression (with slightly different semantics for `NULL` values)\n+1. `col = exp1 OR col = exp2` can be treated as union of two equality predicates \n+\n+The result of this step is a map from column to candidate expressions that could be used with indexes. For example, \n+`a=1 AND b>2 AND b<4` is returned as: \n+```\n+a -> [=1] \n+b -> [>2], [<4]\n+```\n+\n+Next, we iterate over every index, and try to bind candidates to the index based on the index columns and index type.\n+General rules are:\n+1. `SORTED` index may use equality and comparison conditions, while `HASH` index may use only equality conditions\n+1. Only a continuous prefix of index columns can be used. E.g. for the index `(a, b, c)` and the condition `a=1 AND c=2` we \n+can use only `a=1`\n+1. All expressions in the prefix except for the last one must be equality conditions. E.g. for the index `(a, b)` and the \n+condition `a>1 AND b>2`, we can use only `a>1`   \n+\n+The result of this step is a map from index to the filter that should be used. For example, for the expression \n+`a=1 AND b>2 AND b<4`, and indexes on `(a, c)` and `(b)`, the result would be:\n+```\n+index(a, c) -> [a=1, NULL]\n+index(b) -> [b>2 AND b<4]\n+```\n+\n+At last, for every proposed index, we create a `MapIndexScanPhysicalRel` operator that is added to the planner search space.\n+\n+## 3 Local Execution\n+\n+Scan operators consist of three parts:\n+1. Access path (direct scan, index scan)\n+1. Optional filter\n+1. Column list\n+\n+The execution proceeds as follows. First, an iterator over the underlying data is opened (record stores, index). Then every \n+returned record is evaluated against the optional filter. If record is not filtered out, it is converted to a `Row` instance\n+based on the column list. The `Row` is added to the internal batch. When the batch reaches a certain size, or there are no\n+more records, the batch of rows is returned to the parent operator. \n+\n+For the direct map scan (`MapScanExec`), the iterator scans all local partitions one by one. For the index scan ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyMDY1Mw=="}, "originalCommit": {"oid": "55af70162f3068e4b317444d7090fe82d414d713"}, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMjI4MjIwOnYy", "diffSide": "RIGHT", "path": "docs/design/sql/10-distributed-scan.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQxMDoxOToxOFrOHbohrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQxMDoxOToxOFrOHbohrQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODczNzU4MQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            For every proposed index, we create a `MapIndexScanPhysicalRel` operator that is added to the planner search space. At the \n          \n          \n            \n            moment we add all viable indexes to the search space. This might become a problem in the future releases, when we have \n          \n          \n            \n            joins and multiple table, because there will be too many alternatives to consider. The solution could be not to add certain\n          \n          \n            \n            indexes to the search space based on some heuristics. \n          \n          \n            \n            For every proposed index, we create a `MapIndexScanPhysicalRel` operator that is added to the planner search space. \n          \n          \n            \n            Currently, we add all usable indexes to the search space. This might become a problem in future releases, when we have \n          \n          \n            \n            joins and multiple tables, because there will be too many alternatives to consider. The solution could be to not add certain\n          \n          \n            \n            indexes to the search space based on some heuristics.", "url": "https://github.com/hazelcast/hazelcast/pull/17659#discussion_r498737581", "createdAt": "2020-10-02T10:19:18Z", "author": {"login": "viliam-durina"}, "path": "docs/design/sql/10-distributed-scan.md", "diffHunk": "@@ -0,0 +1,164 @@\n+# Distributed Scan\n+\n+## Overview\n+\n+The Hazelcast Mustang is a distributed query engine. When an SQL string is submitted for execution, it is converted into a \n+query plan, that contains the tree of relational operators, such as `scan`, `project` and `filter`. Leaf operators of the plan \n+act as data sources for the parent operators. The `scan` operator iterates over the `IMap` data structure. This document \n+explains how the distributed scan is performed.\n+\n+In this document, we describe the main design points of the scan operators: access path selection, local execution semantics,\n+and reaction to cluster reconfiguration.\n+\n+## 1 Background\n+\n+The Hazelcast IMDG is a distributed in-memory key-value storage. Data is stored in distributed objects, such as an `IMap`.\n+The cluster has a predefined number of partitions, 271 by default. Each partition is stored on a single member, and may have \n+zero, one or more backups on other members. Every distributed object is split across one or more partitions. Partitions may\n+migrate between members due to topology change events, such as member leave or join.\n+\n+The `IMap` is a distributed map. It could be accessed either directly, or through a secondary index. The secondary index is \n+a distributed data structure. Every member stores part of the index that is built for the local entries of the member. \n+\n+The goal of the Hazelcast Mustang engine is to pick the proper access method - direct scan or index scan, start execution of \n+the scan on members, and collect the results. In the above sections we describe how it is implemented.   \n+\n+## 2 Access Path Selection\n+\n+There are two ways to scan the `IMap` - iterate over the record store directly, or use one of the secondary indexes. During the\n+planning stage the proper access method is chosen. \n+\n+If there are no indexes on the table, the direct scan is chosen and no further optimization is performed.    \n+\n+If there are indexes on the table, we analyze the predicate stored in the table of the `TableScan` operator. The entry point\n+is `IndexResolver.createIndexScans`. \n+\n+First, we split the predicate into conjunctive normal form (CNF). For example, the predicate `a=1 AND b=2` is split into \n+`a=1` and `b=2`, while the predicate `a=1 OR b=2` remains unchanged.\n+\n+Second, for every sub-predicate we find those that could be used by some index. Assume that `col` is a simple column\n+expression, and `exp` is an expression that has only constants or parameters at leaves (i.e. it doesn't refer to other columns). \n+We use the following rules:\n+1. `col = exp` can be used with `SORTED` and `HASH` indexes\n+1. `col [comparison] exp` can be used with `SORTED` indexes\n+1. `col IS NULL/TRUE/FALSE` can be treated as equality expression (with slightly different semantics for `NULL` values)\n+1. `col = exp1 OR col = exp2` can be treated as union of two equality predicates \n+\n+The result of this step is a map from column to candidate expressions that could be used with indexes. For example, \n+`a=1 AND b>2 AND b<4` is returned as: \n+```\n+a -> [=1] \n+b -> [>2], [<4]\n+```\n+\n+Next, we iterate over every index, and try to bind candidates to the index based on the index columns and index type.\n+General rules are:\n+1. `SORTED` index may use equality and comparison conditions, while `HASH` index may use only equality conditions\n+1. Only a continuous prefix of index columns can be bound. E.g. for the index `(a, b, c)` and the condition `a=1 AND c=2` we \n+can bind only `a=1`, while for `a=1 AND b=2` we may bind both `a=1` and `b=2`\n+1. All expressions in the prefix except for the last one must be equality conditions. E.g. for the index `(a, b)` and the \n+condition `a>1 AND b>2`, we can use only `a>1`   \n+\n+The result of this step is a map from index to the filter that should be used. For example, for the expression \n+`a=1 AND b>2 AND b<4`, and indexes on `(a, b)`, `(a, c)` and `(b)`, the result would be:\n+```\n+index(a, b) -> [a=1, b>2 AND b<4]\n+index(a, c) -> [a=1, NULL]\n+index(b) -> [b>2 AND b<4]\n+```\n+\n+Once the index filter is built, we calculate the remainder filter, such that `indexFilter AND remainderFilter` is equivalent\n+to the original filter. \n+\n+For every proposed index, we create a `MapIndexScanPhysicalRel` operator that is added to the planner search space. At the \n+moment we add all viable indexes to the search space. This might become a problem in the future releases, when we have \n+joins and multiple table, because there will be too many alternatives to consider. The solution could be not to add certain\n+indexes to the search space based on some heuristics. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5caaa9f040eb701e08bf9e866e96eb0d06896f67"}, "originalPosition": 76}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMjMxNjU1OnYy", "diffSide": "RIGHT", "path": "docs/design/sql/10-distributed-scan.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQxMDozMToxN1rOHbo2gA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQxMDo0ODowNlrOHbpRtw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODc0MjkxMg==", "bodyText": "What happens if the object is deleted during the scan execution?", "url": "https://github.com/hazelcast/hazelcast/pull/17659#discussion_r498742912", "createdAt": "2020-10-02T10:31:17Z", "author": {"login": "taburet"}, "path": "docs/design/sql/10-distributed-scan.md", "diffHunk": "@@ -0,0 +1,164 @@\n+# Distributed Scan\n+\n+## Overview\n+\n+The Hazelcast Mustang is a distributed query engine. When an SQL string is submitted for execution, it is converted into a \n+query plan, that contains the tree of relational operators, such as `scan`, `project` and `filter`. Leaf operators of the plan \n+act as data sources for the parent operators. The `scan` operator iterates over the `IMap` data structure. This document \n+explains how the distributed scan is performed.\n+\n+In this document, we describe the main design points of the scan operators: access path selection, local execution semantics,\n+and reaction to cluster reconfiguration.\n+\n+## 1 Background\n+\n+The Hazelcast IMDG is a distributed in-memory key-value storage. Data is stored in distributed objects, such as an `IMap`.\n+The cluster has a predefined number of partitions, 271 by default. Each partition is stored on a single member, and may have \n+zero, one or more backups on other members. Every distributed object is split across one or more partitions. Partitions may\n+migrate between members due to topology change events, such as member leave or join.\n+\n+The `IMap` is a distributed map. It could be accessed either directly, or through a secondary index. The secondary index is \n+a distributed data structure. Every member stores part of the index that is built for the local entries of the member. \n+\n+The goal of the Hazelcast Mustang engine is to pick the proper access method - direct scan or index scan, start execution of \n+the scan on members, and collect the results. In the above sections we describe how it is implemented.   \n+\n+## 2 Access Path Selection\n+\n+There are two ways to scan the `IMap` - iterate over the record store directly, or use one of the secondary indexes. During the\n+planning stage the proper access method is chosen. \n+\n+If there are no indexes on the table, the direct scan is chosen and no further optimization is performed.    \n+\n+If there are indexes on the table, we analyze the predicate stored in the table of the `TableScan` operator. The entry point\n+is `IndexResolver.createIndexScans`. \n+\n+First, we split the predicate into conjunctive normal form (CNF). For example, the predicate `a=1 AND b=2` is split into \n+`a=1` and `b=2`, while the predicate `a=1 OR b=2` remains unchanged.\n+\n+Second, for every sub-predicate we find those that could be used by some index. Assume that `col` is a simple column\n+expression, and `exp` is an expression that has only constants or parameters at leaves (i.e. it doesn't refer to other columns). \n+We use the following rules:\n+1. `col = exp` can be used with `SORTED` and `HASH` indexes\n+1. `col [comparison] exp` can be used with `SORTED` indexes\n+1. `col IS NULL/TRUE/FALSE` can be treated as equality expression (with slightly different semantics for `NULL` values)\n+1. `col = exp1 OR col = exp2` can be treated as union of two equality predicates \n+\n+The result of this step is a map from column to candidate expressions that could be used with indexes. For example, \n+`a=1 AND b>2 AND b<4` is returned as: \n+```\n+a -> [=1] \n+b -> [>2], [<4]\n+```\n+\n+Next, we iterate over every index, and try to bind candidates to the index based on the index columns and index type.\n+General rules are:\n+1. `SORTED` index may use equality and comparison conditions, while `HASH` index may use only equality conditions\n+1. Only a continuous prefix of index columns can be bound. E.g. for the index `(a, b, c)` and the condition `a=1 AND c=2` we \n+can bind only `a=1`, while for `a=1 AND b=2` we may bind both `a=1` and `b=2`\n+1. All expressions in the prefix except for the last one must be equality conditions. E.g. for the index `(a, b)` and the \n+condition `a>1 AND b>2`, we can use only `a>1`   \n+\n+The result of this step is a map from index to the filter that should be used. For example, for the expression \n+`a=1 AND b>2 AND b<4`, and indexes on `(a, b)`, `(a, c)` and `(b)`, the result would be:\n+```\n+index(a, b) -> [a=1, b>2 AND b<4]\n+index(a, c) -> [a=1, NULL]\n+index(b) -> [b>2 AND b<4]\n+```\n+\n+Once the index filter is built, we calculate the remainder filter, such that `indexFilter AND remainderFilter` is equivalent\n+to the original filter. \n+\n+For every proposed index, we create a `MapIndexScanPhysicalRel` operator that is added to the planner search space. \n+Currently, we add all usable indexes to the search space. This might become a problem in future releases, when we have \n+joins and multiple tables, because there will be too many alternatives to consider. The solution could be to not add certain\n+indexes to the search space based on some heuristics. \n+\n+The cost model works as follows:\n+1. Get the expected number of rows to scan (`SCANNED_ROWS`). For the direct scan it equals to the number of rows in the map. For \n+the index scan this is `mapRowCount * selectivity(indexFilter)`.\n+1. Get the expected number of returned rows (`RETURNED_ROWS`), that depend on the selectivity of the original filter.\n+1. Assign a weight to the scanned rows, based on the access method (`SCAN_MULTIPLIER`). We assume that a direct scan is cheaper \n+than an index scan, because the latter requires indirection. Also, we assume that a scan of the `HASH` index is cheaper that \n+a scan of the `SORTED` index, because it requires less CPU for the lookup.\n+1. The final formula is `COST = SCANNED_ROWS * SCAN_MULTIPLIER + RETURNED_ROWS * PROJECTION_COST`. It ensures, that a direct\n+scan is picked when the filter has poor selectivity, and that an index scan is picked otherwise, giving a priority to `HASH`\n+index.\n+\n+## 3 Local Execution\n+\n+Scan operators consist of three parts:\n+1. Access path (direct scan, index scan)\n+1. Optional filter\n+1. Column list\n+\n+The execution proceeds as follows. First, an iterator over the underlying data is opened (record stores, index). Then every \n+returned record is evaluated against the optional filter. If record is not filtered out, it is converted to a `Row` instance\n+based on the column list. The `Row` is added to the internal batch. When the batch reaches a certain size, or there are no\n+more records, the batch of rows is returned to the parent operator. \n+\n+For the direct map scan (`MapScanExec`), the iterator scans all local partitions one by one. For the index scan \n+(`MapIndexScanExec`), the iterator is opened against the index, based on the optional index condition. In both cases,\n+the full result set of the scan is never materialized, unlike the legacy predicate engine.\n+\n+An entry might be changed concurrently during execution of the query. Since the engine doesn't have transactions, it is\n+possible that the updated entry will be observed zero, one or several times, due to entry relocation within the underlying\n+data structure. To solve this problem, we would need a transactional engine, but we do not have one. Note that the described \n+behavior is possible in many databases, including transactional ones. Examples are: Redis [[1]], MongoDB [[2]], Microsoft \n+SQL Server with `READ_COMMITTED` isolation (the default behavior) [[3]]. \n+\n+## 4 Cluster Reconfiguration\n+\n+Cluster configuration may change during query execution: partitions may migrate between members, distributed objects may be \n+created and destroyed. This section describes the behavior of scan operators in the case of concurrent cluster reconfiguration.\n+\n+### 4.1 Partition Migration\n+\n+If the query is executed concurrently with partition migration, it is possible that some partitions will be scanned several \n+times, or missed completely. To avoid that we need a mechanics to ensure that the engine observed every partition exactly\n+once.  \n+\n+When the plan is created, we create the so-called **partition map**, that maps members to partitions. The partition map is saved\n+in the plan. If the partition distribution changes due to member join/leave, the plan is invalidated.  \n+\n+When the query is about to start, we explicitly assign partitions to every participant. For example:\n+```\n+member1 -> [1, 2]\n+member2 -> [3, 4]\n+```  \n+\n+When the scan operation is started on the member, we first check whether it contains expected partitions. If the expected and \n+actually owned partitions do not match, an exception is thrown. For example, if the member is expected to have partitions \n+`[1, 2]`, then:\n+```\n+[1] - error, because we may miss the partition [2]\n+[1, 2] - ok\n+[1, 2, 3] - error, because we may return duplicates for the partition [3]\n+```\n+\n+The check before the query start is not sufficient to guarantee the correctness of the results. The partition may migrate to the \n+member during execution of the query, leading to duplicates. Conversely, the partition may be removed from the member \n+concurrently, leading to missed entries. To avoid inconsistent results we **re-check** the partition distribution before any\n+result is returned from the scan operator. \n+\n+Partition check logic depends on the operator type. For the direct map scan, we use the migration stamps \n+(`MapService.validateMigrationStamp`). For the index scans, we use index partition stamps \n+(`InternalIndex.validatePartitionStamp`).\n+\n+A better solution would hide the partitioning problems from the user completely. This, however, is difficult to achieve \n+in practice. To avoid duplicates and missed entries we would have to track which part of the operator input is processed, and \n+re-schedule scans to other members at runtime. Therefore, the current design ensures that the user does not see an inconsistent\n+result, but forces the user to re-run the query manually if the result correctness cannot be guaranteed by the engine. In the\n+long term we would like to avoid, or at least minimize, the number of cases when the error is thrown.\n+\n+### 4.2 Concurrent Schema Changes\n+\n+It may happen, that the referenced object (`IMap`, index) that was present during the query planning, no longer exists on the \n+local member. For example, because the map has been destroyed concurrently. Therefore, when the scan operation is about to\n+start, the existence of the required objects is checked. If the required object is not found, an exception is thrown, and the", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "660f8e377f64923efaf91689ba90e6b45c2fa194"}, "originalPosition": 159}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODc0OTg3OQ==", "bodyText": "Clarified in the commit: d40f45d", "url": "https://github.com/hazelcast/hazelcast/pull/17659#discussion_r498749879", "createdAt": "2020-10-02T10:48:06Z", "author": {"login": "devozerov"}, "path": "docs/design/sql/10-distributed-scan.md", "diffHunk": "@@ -0,0 +1,164 @@\n+# Distributed Scan\n+\n+## Overview\n+\n+The Hazelcast Mustang is a distributed query engine. When an SQL string is submitted for execution, it is converted into a \n+query plan, that contains the tree of relational operators, such as `scan`, `project` and `filter`. Leaf operators of the plan \n+act as data sources for the parent operators. The `scan` operator iterates over the `IMap` data structure. This document \n+explains how the distributed scan is performed.\n+\n+In this document, we describe the main design points of the scan operators: access path selection, local execution semantics,\n+and reaction to cluster reconfiguration.\n+\n+## 1 Background\n+\n+The Hazelcast IMDG is a distributed in-memory key-value storage. Data is stored in distributed objects, such as an `IMap`.\n+The cluster has a predefined number of partitions, 271 by default. Each partition is stored on a single member, and may have \n+zero, one or more backups on other members. Every distributed object is split across one or more partitions. Partitions may\n+migrate between members due to topology change events, such as member leave or join.\n+\n+The `IMap` is a distributed map. It could be accessed either directly, or through a secondary index. The secondary index is \n+a distributed data structure. Every member stores part of the index that is built for the local entries of the member. \n+\n+The goal of the Hazelcast Mustang engine is to pick the proper access method - direct scan or index scan, start execution of \n+the scan on members, and collect the results. In the above sections we describe how it is implemented.   \n+\n+## 2 Access Path Selection\n+\n+There are two ways to scan the `IMap` - iterate over the record store directly, or use one of the secondary indexes. During the\n+planning stage the proper access method is chosen. \n+\n+If there are no indexes on the table, the direct scan is chosen and no further optimization is performed.    \n+\n+If there are indexes on the table, we analyze the predicate stored in the table of the `TableScan` operator. The entry point\n+is `IndexResolver.createIndexScans`. \n+\n+First, we split the predicate into conjunctive normal form (CNF). For example, the predicate `a=1 AND b=2` is split into \n+`a=1` and `b=2`, while the predicate `a=1 OR b=2` remains unchanged.\n+\n+Second, for every sub-predicate we find those that could be used by some index. Assume that `col` is a simple column\n+expression, and `exp` is an expression that has only constants or parameters at leaves (i.e. it doesn't refer to other columns). \n+We use the following rules:\n+1. `col = exp` can be used with `SORTED` and `HASH` indexes\n+1. `col [comparison] exp` can be used with `SORTED` indexes\n+1. `col IS NULL/TRUE/FALSE` can be treated as equality expression (with slightly different semantics for `NULL` values)\n+1. `col = exp1 OR col = exp2` can be treated as union of two equality predicates \n+\n+The result of this step is a map from column to candidate expressions that could be used with indexes. For example, \n+`a=1 AND b>2 AND b<4` is returned as: \n+```\n+a -> [=1] \n+b -> [>2], [<4]\n+```\n+\n+Next, we iterate over every index, and try to bind candidates to the index based on the index columns and index type.\n+General rules are:\n+1. `SORTED` index may use equality and comparison conditions, while `HASH` index may use only equality conditions\n+1. Only a continuous prefix of index columns can be bound. E.g. for the index `(a, b, c)` and the condition `a=1 AND c=2` we \n+can bind only `a=1`, while for `a=1 AND b=2` we may bind both `a=1` and `b=2`\n+1. All expressions in the prefix except for the last one must be equality conditions. E.g. for the index `(a, b)` and the \n+condition `a>1 AND b>2`, we can use only `a>1`   \n+\n+The result of this step is a map from index to the filter that should be used. For example, for the expression \n+`a=1 AND b>2 AND b<4`, and indexes on `(a, b)`, `(a, c)` and `(b)`, the result would be:\n+```\n+index(a, b) -> [a=1, b>2 AND b<4]\n+index(a, c) -> [a=1, NULL]\n+index(b) -> [b>2 AND b<4]\n+```\n+\n+Once the index filter is built, we calculate the remainder filter, such that `indexFilter AND remainderFilter` is equivalent\n+to the original filter. \n+\n+For every proposed index, we create a `MapIndexScanPhysicalRel` operator that is added to the planner search space. \n+Currently, we add all usable indexes to the search space. This might become a problem in future releases, when we have \n+joins and multiple tables, because there will be too many alternatives to consider. The solution could be to not add certain\n+indexes to the search space based on some heuristics. \n+\n+The cost model works as follows:\n+1. Get the expected number of rows to scan (`SCANNED_ROWS`). For the direct scan it equals to the number of rows in the map. For \n+the index scan this is `mapRowCount * selectivity(indexFilter)`.\n+1. Get the expected number of returned rows (`RETURNED_ROWS`), that depend on the selectivity of the original filter.\n+1. Assign a weight to the scanned rows, based on the access method (`SCAN_MULTIPLIER`). We assume that a direct scan is cheaper \n+than an index scan, because the latter requires indirection. Also, we assume that a scan of the `HASH` index is cheaper that \n+a scan of the `SORTED` index, because it requires less CPU for the lookup.\n+1. The final formula is `COST = SCANNED_ROWS * SCAN_MULTIPLIER + RETURNED_ROWS * PROJECTION_COST`. It ensures, that a direct\n+scan is picked when the filter has poor selectivity, and that an index scan is picked otherwise, giving a priority to `HASH`\n+index.\n+\n+## 3 Local Execution\n+\n+Scan operators consist of three parts:\n+1. Access path (direct scan, index scan)\n+1. Optional filter\n+1. Column list\n+\n+The execution proceeds as follows. First, an iterator over the underlying data is opened (record stores, index). Then every \n+returned record is evaluated against the optional filter. If record is not filtered out, it is converted to a `Row` instance\n+based on the column list. The `Row` is added to the internal batch. When the batch reaches a certain size, or there are no\n+more records, the batch of rows is returned to the parent operator. \n+\n+For the direct map scan (`MapScanExec`), the iterator scans all local partitions one by one. For the index scan \n+(`MapIndexScanExec`), the iterator is opened against the index, based on the optional index condition. In both cases,\n+the full result set of the scan is never materialized, unlike the legacy predicate engine.\n+\n+An entry might be changed concurrently during execution of the query. Since the engine doesn't have transactions, it is\n+possible that the updated entry will be observed zero, one or several times, due to entry relocation within the underlying\n+data structure. To solve this problem, we would need a transactional engine, but we do not have one. Note that the described \n+behavior is possible in many databases, including transactional ones. Examples are: Redis [[1]], MongoDB [[2]], Microsoft \n+SQL Server with `READ_COMMITTED` isolation (the default behavior) [[3]]. \n+\n+## 4 Cluster Reconfiguration\n+\n+Cluster configuration may change during query execution: partitions may migrate between members, distributed objects may be \n+created and destroyed. This section describes the behavior of scan operators in the case of concurrent cluster reconfiguration.\n+\n+### 4.1 Partition Migration\n+\n+If the query is executed concurrently with partition migration, it is possible that some partitions will be scanned several \n+times, or missed completely. To avoid that we need a mechanics to ensure that the engine observed every partition exactly\n+once.  \n+\n+When the plan is created, we create the so-called **partition map**, that maps members to partitions. The partition map is saved\n+in the plan. If the partition distribution changes due to member join/leave, the plan is invalidated.  \n+\n+When the query is about to start, we explicitly assign partitions to every participant. For example:\n+```\n+member1 -> [1, 2]\n+member2 -> [3, 4]\n+```  \n+\n+When the scan operation is started on the member, we first check whether it contains expected partitions. If the expected and \n+actually owned partitions do not match, an exception is thrown. For example, if the member is expected to have partitions \n+`[1, 2]`, then:\n+```\n+[1] - error, because we may miss the partition [2]\n+[1, 2] - ok\n+[1, 2, 3] - error, because we may return duplicates for the partition [3]\n+```\n+\n+The check before the query start is not sufficient to guarantee the correctness of the results. The partition may migrate to the \n+member during execution of the query, leading to duplicates. Conversely, the partition may be removed from the member \n+concurrently, leading to missed entries. To avoid inconsistent results we **re-check** the partition distribution before any\n+result is returned from the scan operator. \n+\n+Partition check logic depends on the operator type. For the direct map scan, we use the migration stamps \n+(`MapService.validateMigrationStamp`). For the index scans, we use index partition stamps \n+(`InternalIndex.validatePartitionStamp`).\n+\n+A better solution would hide the partitioning problems from the user completely. This, however, is difficult to achieve \n+in practice. To avoid duplicates and missed entries we would have to track which part of the operator input is processed, and \n+re-schedule scans to other members at runtime. Therefore, the current design ensures that the user does not see an inconsistent\n+result, but forces the user to re-run the query manually if the result correctness cannot be guaranteed by the engine. In the\n+long term we would like to avoid, or at least minimize, the number of cases when the error is thrown.\n+\n+### 4.2 Concurrent Schema Changes\n+\n+It may happen, that the referenced object (`IMap`, index) that was present during the query planning, no longer exists on the \n+local member. For example, because the map has been destroyed concurrently. Therefore, when the scan operation is about to\n+start, the existence of the required objects is checked. If the required object is not found, an exception is thrown, and the", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODc0MjkxMg=="}, "originalCommit": {"oid": "660f8e377f64923efaf91689ba90e6b45c2fa194"}, "originalPosition": 159}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 154, "cost": 1, "resetAt": "2021-11-12T20:28:25Z"}}}