{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDUzMTg0MzA2", "number": 17239, "title": "Remove InetSockedAddressCache From Client", "bodyText": "InetSocketAddressCache was introduced in Blue/Green prd to make\na clear point where the failover takes place.\nAs long as fail over will not happen, the cache was not cleared.\nA scenario that we can not support with the cache is as follows:\n\nMembers are configured via hostname.\nWhen a member machine restarted the ip address that hostname\ncorresponds changes.\nAfter this there could be several problems.\na. A single member restarts in a multi member cluster.\nb. Whole cluster restarted.\n\nIn scenario a, the client can not connect to the single restarted\nmember ever. The operations that needs to go to that member fails\nwith exception constantly.\nIn scenario b, the client cannot connect to any of the members and\nshutdown.\nThis fix aims to solve both problems so that client can continue\nto work, while preserving the behaviours in Blue/Green case.\nSince I could not find a way to test this with single machine no\ntest is provided. The tests are done in aws enviorenmenti with\nmulti member and CNAME changes.\nFixes #17062", "createdAt": "2020-07-20T08:18:08Z", "url": "https://github.com/hazelcast/hazelcast/pull/17239", "merged": true, "mergeCommit": {"oid": "cc11605b4d24d5b51def850b71268f3b23fc7a87"}, "closed": true, "closedAt": "2020-12-01T10:38:35Z", "author": {"login": "sancar"}, "timelineItems": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc2uj4WgBqjM1NjQ5NDk1ODI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdh3KDrAFqTU0MTc0NTU2NQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "217bbc53135fc2231d0fc5047ad1b646510d8189", "author": {"user": {"login": "sancar", "name": "sancar"}}, "url": "https://github.com/hazelcast/hazelcast/commit/217bbc53135fc2231d0fc5047ad1b646510d8189", "committedDate": "2020-07-20T07:58:22Z", "message": "Remove InetSockedAddressCache From Client\n\nInetSocketAddressCache was introduced in Blue/Green prd to make\na clear point where the failover takes place.\nAs long as fail over will not happen, the cache was not cleared.\n\nA scenario that we can not support with the cache is as follows:\n1. Members are configured via hostname.\n2. When a member machine restarted the ip address that hostname\ncorresponds changes.\n3. After this there could be several problems.\n   a. A single member restarts in a multi member cluster.\n   b. Whole cluster restarted.\n\nIn scenario a, the client can not connect to the single restarted\nmember ever. The operations that needs to go to that member fails\nwith exception constantly.\n\nIn scenario b, the client cannot connect to any of the members and\nshutdown.\n\nThis fix aims to solve both problems so that client can continue\nto work, while preserving the behaviours in Blue/Green case.\n\nSince I could not find a way to test this with single machine no\ntest is provided. The tests are done in aws enviorenmenti with\nmulti member and CNAME changes."}, "afterCommit": {"oid": "22070ed713abbc1dd59ff465dc6424c2616ff8b2", "author": {"user": {"login": "sancar", "name": "sancar"}}, "url": "https://github.com/hazelcast/hazelcast/commit/22070ed713abbc1dd59ff465dc6424c2616ff8b2", "committedDate": "2020-07-20T09:46:05Z", "message": "Remove InetSockedAddressCache From Client\n\nInetSocketAddressCache was introduced in Blue/Green prd to make\na clear point where the failover takes place.\nAs long as fail over will not happen, the cache was not cleared.\n\nA scenario that we can not support with the cache is as follows:\n1. Members are configured via hostname.\n2. When a member machine restarted the ip address that hostname\ncorresponds changes.\n3. After this there could be several problems.\n   a. A single member restarts in a multi member cluster.\n   b. Whole cluster restarted.\n\nIn scenario a, the client can not connect to the single restarted\nmember ever. The operations that needs to go to that member fails\nwith exception constantly.\n\nIn scenario b, the client cannot connect to any of the members and\nshutdown.\n\nThis fix aims to solve both problems so that client can continue\nto work, while preserving the behaviours in Blue/Green case.\n\nSince I could not find a way to test this with single machine no\ntest is provided. The tests are done in aws enviorenmenti with\nmulti member and CNAME changes."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUxNTY1NTI4", "url": "https://github.com/hazelcast/hazelcast/pull/17239#pullrequestreview-451565528", "createdAt": "2020-07-20T12:37:23Z", "commit": {"oid": "22070ed713abbc1dd59ff465dc6424c2616ff8b2"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQxMjozNzoyM1rOG0KBug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQxMjozNzoyM1rOG0KBug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzM0MzQxOA==", "bodyText": "Use HashUtils.hashToIndex instead.", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r457343418", "createdAt": "2020-07-20T12:37:23Z", "author": {"login": "pveentjer"}, "path": "hazelcast/src/main/java/com/hazelcast/client/impl/connection/tcp/TcpClientConnectionManager.java", "diffHunk": "@@ -586,6 +593,10 @@ TcpClientConnection getOrConnect(@Nonnull Address address) {\n         }\n     }\n \n+    private Object getLockObject(InetSocketAddress inetSocketAddress) {\n+        return mutexes[Math.abs(inetSocketAddress.hashCode() % mutexes.length)];", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "22070ed713abbc1dd59ff465dc6424c2616ff8b2"}, "originalPosition": 74}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f85ecdc6476ae681be6f69d12d47a020432543ec", "author": {"user": {"login": "sancar", "name": "sancar"}}, "url": "https://github.com/hazelcast/hazelcast/commit/f85ecdc6476ae681be6f69d12d47a020432543ec", "committedDate": "2020-07-20T14:35:22Z", "message": "make use of HashUtil.hashToIndex"}, "afterCommit": {"oid": "e9e36fca17a22c6a1e61e355a8d09acf6a93f402", "author": {"user": {"login": "sancar", "name": "sancar"}}, "url": "https://github.com/hazelcast/hazelcast/commit/e9e36fca17a22c6a1e61e355a8d09acf6a93f402", "committedDate": "2020-08-12T10:12:24Z", "message": "Remove InetSockedAddressCache From Client\n\nInetSocketAddressCache was introduced in Blue/Green prd to make\na clear point where the failover takes place.\nAs long as fail over will not happen, the cache was not cleared.\n\nA scenario that we can not support with the cache is as follows:\n1. Members are configured via hostname.\n2. When a member machine restarted the ip address that hostname\ncorresponds changes.\n3. After this there could be several problems.\n   a. A single member restarts in a multi member cluster.\n   b. Whole cluster restarted.\n\nIn scenario a, the client can not connect to the single restarted\nmember ever. The operations that needs to go to that member fails\nwith exception constantly.\n\nIn scenario b, the client cannot connect to any of the members and\nshutdown.\n\nThis fix aims to solve both problems so that client can continue\nto work, while preserving the behaviours in Blue/Green case.\n\nSince I could not find a way to test this with single machine no\ntest is provided. The tests are done in aws enviorenmenti with\nmulti member and CNAME changes."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3MzQ4MDE2", "url": "https://github.com/hazelcast/hazelcast/pull/17239#pullrequestreview-467348016", "createdAt": "2020-08-14T06:59:08Z", "commit": {"oid": "e9e36fca17a22c6a1e61e355a8d09acf6a93f402"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwNjo1OTowOVrOHApsaA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwNzowMTowMlrOHApvcQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQ0NTE2MA==", "bodyText": "drawback: with little probability if hashes to the same mutex, even if the other threads are available, will wait for the mutex.\nalternative solution: putIfAbsent into concurrent hash map {inetSocketAddress, mutex} and lock on that mutex. (implementing a similar aproach at dev branch: https://github.com/ihsandemir/hazelcast-cpp-client/blob/protocol/hazelcast/src/hazelcast/client/network.cpp#L218)", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r470445160", "createdAt": "2020-08-14T06:59:09Z", "author": {"login": "ihsandemir"}, "path": "hazelcast/src/main/java/com/hazelcast/client/impl/connection/tcp/TcpClientConnectionManager.java", "diffHunk": "@@ -586,6 +594,10 @@ TcpClientConnection getOrConnect(@Nonnull Address address) {\n         }\n     }\n \n+    private Object getLockObject(InetSocketAddress inetSocketAddress) {\n+        return mutexes[HashUtil.hashToIndex(inetSocketAddress.hashCode(), mutexes.length)];", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e9e36fca17a22c6a1e61e355a8d09acf6a93f402"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQ0NTkzNw==", "bodyText": "you can pass parameter connectionsEmpty  to this method.", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r470445937", "createdAt": "2020-08-14T07:01:02Z", "author": {"login": "ihsandemir"}, "path": "hazelcast/src/main/java/com/hazelcast/client/impl/connection/tcp/TcpClientConnectionManager.java", "diffHunk": "@@ -824,18 +834,19 @@ private void handleSuccessfulAuth(TcpClientConnection connection, ClientAuthenti\n                 logger.fine(\"Checking the cluster: \" + newClusterId + \", current cluster: \" + this.clusterId);\n             }\n \n-            boolean initialConnection = activeConnections.isEmpty();\n-            boolean changedCluster = initialConnection && this.clusterId != null && !newClusterId.equals(this.clusterId);\n-            if (changedCluster) {\n+            boolean connectionsEmpty = activeConnections.isEmpty();\n+            boolean clusterIdChanged = this.clusterId != null && !newClusterId.equals(this.clusterId);\n+            if (clusterIdChanged) {\n+                checkClientStateOnClusterIdChange(connection);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e9e36fca17a22c6a1e61e355a8d09acf6a93f402"}, "originalPosition": 101}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3NDEzMzI0", "url": "https://github.com/hazelcast/hazelcast/pull/17239#pullrequestreview-467413324", "createdAt": "2020-08-14T08:52:19Z", "commit": {"oid": "2e4c56fe83f375b4f9e809737634c2610038a386"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAzNTk1Mjc5", "url": "https://github.com/hazelcast/hazelcast/pull/17239#pullrequestreview-503595279", "createdAt": "2020-10-07T07:29:42Z", "commit": {"oid": "2e4c56fe83f375b4f9e809737634c2610038a386"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QwNzoyOTo0M1rOHdmF_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QwNzoyOTo0M1rOHdmF_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDc5NDg3Nw==", "bodyText": "I'm not sure about the speed at which these objects are created.\nThe problem with creating (and destroying) objects with a potentially inflated monitor, is that it can be a huge performance hog when doing GC. For example, our initial future used the same approach; later we replaced it by lock support to get rid of this inflated monitor and performance increased and latencies became a lot better.\nFor such situations, I would suggest using a striped lock.\nApart from that.. I see you are synchronizing while communicating with external systems. You create the connection, which needs to go through a 3-way handshake (and potentially a few extra steps due to TLS) and then you have authentication. Which is another set of remote steps.\nIf for whatever reason such remote interaction stalls, this thread stalls and this can lead to serious problems in the system. Also, any other thread that hits the same address, could also block indefinitely.\nI think a better approach needs to be found than synchronization.", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r500794877", "createdAt": "2020-10-07T07:29:43Z", "author": {"login": "pveentjer"}, "path": "hazelcast/src/main/java/com/hazelcast/client/impl/connection/tcp/TcpClientConnectionManager.java", "diffHunk": "@@ -571,18 +571,24 @@ TcpClientConnection getOrConnect(@Nonnull Address address) {\n             return connection;\n         }\n \n-        synchronized (resolveAddress(address)) {\n-            // this critical section is used for making a single connection\n-            // attempt to the given address at a time.\n-            connection = getConnection(address);\n-            if (connection != null) {\n+        InetSocketAddress inetSocketAddress = resolveAddress(address);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e4c56fe83f375b4f9e809737634c2610038a386"}, "originalPosition": 53}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA5MTYxNDQw", "url": "https://github.com/hazelcast/hazelcast/pull/17239#pullrequestreview-509161440", "createdAt": "2020-10-15T08:55:59Z", "commit": {"oid": "2e4c56fe83f375b4f9e809737634c2610038a386"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQwODo1NTo1OVrOHh9RMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQwODo1NTo1OVrOHh9RMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTM2ODg4MQ==", "bodyText": "I'm thinking out loud.\nWhat you could do is to create a CHM with address as key and a Future as value.\nThe future will either block if no value is set, or will return the correct connection.\nYou could add this future using e.g. a putIfAbsent. so that only 1 thread will wait for a connection and then set that value on the future.", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r505368881", "createdAt": "2020-10-15T08:55:59Z", "author": {"login": "pveentjer"}, "path": "hazelcast/src/main/java/com/hazelcast/client/impl/connection/tcp/TcpClientConnectionManager.java", "diffHunk": "@@ -571,18 +571,24 @@ TcpClientConnection getOrConnect(@Nonnull Address address) {\n             return connection;\n         }\n \n-        synchronized (resolveAddress(address)) {\n-            // this critical section is used for making a single connection\n-            // attempt to the given address at a time.\n-            connection = getConnection(address);\n-            if (connection != null) {\n+        InetSocketAddress inetSocketAddress = resolveAddress(address);\n+        try {\n+            Object mutex = ConcurrencyUtil.getOrPutIfAbsent(mutexes, inetSocketAddress, key -> new Object());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e4c56fe83f375b4f9e809737634c2610038a386"}, "originalPosition": 55}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA5MTcxMjE3", "url": "https://github.com/hazelcast/hazelcast/pull/17239#pullrequestreview-509171217", "createdAt": "2020-10-15T09:07:18Z", "commit": {"oid": "2e4c56fe83f375b4f9e809737634c2610038a386"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQwOTowNzoxOFrOHh94gA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQwOTowNzoxOFrOHh94gA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTM3ODk0NA==", "bodyText": "I had a closer look at the code and this is on the ConnectionManager. I don't see a problem if another thread blocks on acquring a concurrent connection. He can't do anything useful anyway since the method itself is blocking.\nSo using a lock isn't that much of a problem.\nI would be careful with using an intrinsic lock due to inflation/GC problems as I already indicated in my first comment. It will not immediately cause problems since connections will not be created and destroyed in a very high rate. But eventually you could still run into some GC issues.", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r505378944", "createdAt": "2020-10-15T09:07:18Z", "author": {"login": "pveentjer"}, "path": "hazelcast/src/main/java/com/hazelcast/client/impl/connection/tcp/TcpClientConnectionManager.java", "diffHunk": "@@ -571,18 +571,24 @@ TcpClientConnection getOrConnect(@Nonnull Address address) {\n             return connection;\n         }\n \n-        synchronized (resolveAddress(address)) {\n-            // this critical section is used for making a single connection\n-            // attempt to the given address at a time.\n-            connection = getConnection(address);\n-            if (connection != null) {\n+        InetSocketAddress inetSocketAddress = resolveAddress(address);\n+        try {\n+            Object mutex = ConcurrencyUtil.getOrPutIfAbsent(mutexes, inetSocketAddress, key -> new Object());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e4c56fe83f375b4f9e809737634c2610038a386"}, "originalPosition": 55}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2e4c56fe83f375b4f9e809737634c2610038a386", "author": {"user": {"login": "sancar", "name": "sancar"}}, "url": "https://github.com/hazelcast/hazelcast/commit/2e4c56fe83f375b4f9e809737634c2610038a386", "committedDate": "2020-08-14T08:28:01Z", "message": "review update. Changed mutexes from array to concurrent map"}, "afterCommit": {"oid": "32a4f5a4245ecdcd53fb96c46b7652084ded5107", "author": {"user": {"login": "sancar", "name": "sancar"}}, "url": "https://github.com/hazelcast/hazelcast/commit/32a4f5a4245ecdcd53fb96c46b7652084ded5107", "committedDate": "2020-11-11T13:53:19Z", "message": "review update. Changed mutexes from array to concurrent map"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "32a4f5a4245ecdcd53fb96c46b7652084ded5107", "author": {"user": {"login": "sancar", "name": "sancar"}}, "url": "https://github.com/hazelcast/hazelcast/commit/32a4f5a4245ecdcd53fb96c46b7652084ded5107", "committedDate": "2020-11-11T13:53:19Z", "message": "review update. Changed mutexes from array to concurrent map"}, "afterCommit": {"oid": "1a30276270295ff30cf378e6de8286cc8fb5aa17", "author": {"user": {"login": "sancar", "name": "sancar"}}, "url": "https://github.com/hazelcast/hazelcast/commit/1a30276270295ff30cf378e6de8286cc8fb5aa17", "committedDate": "2020-11-25T08:07:35Z", "message": "review update. Changed mutexes from array to concurrent map"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6bd2412320a35c408cc4cd30b7713fa5d8ba4403", "author": {"user": {"login": "sancar", "name": "sancar"}}, "url": "https://github.com/hazelcast/hazelcast/commit/6bd2412320a35c408cc4cd30b7713fa5d8ba4403", "committedDate": "2020-11-25T08:11:21Z", "message": "Remove InetSockedAddressCache From Client\n\nInetSocketAddressCache was introduced in Blue/Green prd to make\na clear point where the failover takes place.\nAs long as fail over will not happen, the cache was not cleared.\n\nA scenario that we can not support with the cache is as follows:\n1. Members are configured via hostname.\n2. When a member machine restarted the ip address that hostname\ncorresponds changes.\n3. After this there could be several problems.\n   a. A single member restarts in a multi member cluster.\n   b. Whole cluster restarted.\n\nIn scenario a, the client can not connect to the single restarted\nmember ever. The operations that needs to go to that member fails\nwith exception constantly.\n\nIn scenario b, the client cannot connect to any of the members and\nshutdown.\n\nThis fix aims to solve both problems so that client can continue\nto work, while preserving the behaviours in Blue/Green case.\n\nSince I could not find a way to test this with single machine no\ntest is provided. The tests are done in aws enviorenmenti with\nmulti member and CNAME changes."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "1a30276270295ff30cf378e6de8286cc8fb5aa17", "author": {"user": {"login": "sancar", "name": "sancar"}}, "url": "https://github.com/hazelcast/hazelcast/commit/1a30276270295ff30cf378e6de8286cc8fb5aa17", "committedDate": "2020-11-25T08:07:35Z", "message": "review update. Changed mutexes from array to concurrent map"}, "afterCommit": {"oid": "6bd2412320a35c408cc4cd30b7713fa5d8ba4403", "author": {"user": {"login": "sancar", "name": "sancar"}}, "url": "https://github.com/hazelcast/hazelcast/commit/6bd2412320a35c408cc4cd30b7713fa5d8ba4403", "committedDate": "2020-11-25T08:11:21Z", "message": "Remove InetSockedAddressCache From Client\n\nInetSocketAddressCache was introduced in Blue/Green prd to make\na clear point where the failover takes place.\nAs long as fail over will not happen, the cache was not cleared.\n\nA scenario that we can not support with the cache is as follows:\n1. Members are configured via hostname.\n2. When a member machine restarted the ip address that hostname\ncorresponds changes.\n3. After this there could be several problems.\n   a. A single member restarts in a multi member cluster.\n   b. Whole cluster restarted.\n\nIn scenario a, the client can not connect to the single restarted\nmember ever. The operations that needs to go to that member fails\nwith exception constantly.\n\nIn scenario b, the client cannot connect to any of the members and\nshutdown.\n\nThis fix aims to solve both problems so that client can continue\nto work, while preserving the behaviours in Blue/Green case.\n\nSince I could not find a way to test this with single machine no\ntest is provided. The tests are done in aws enviorenmenti with\nmulti member and CNAME changes."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQwOTMxNDUz", "url": "https://github.com/hazelcast/hazelcast/pull/17239#pullrequestreview-540931453", "createdAt": "2020-11-30T13:58:41Z", "commit": {"oid": "6bd2412320a35c408cc4cd30b7713fa5d8ba4403"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQxMzo1ODo0MlrOH78RQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQxNDowOTozMlrOH78ujw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYxNTQ4OQ==", "bodyText": "nit: could be simplified to if (activeConnections.isEmpty()) {", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r532615489", "createdAt": "2020-11-30T13:58:42Z", "author": {"login": "puzpuzpuz"}, "path": "hazelcast/src/main/java/com/hazelcast/client/impl/connection/tcp/TcpClientConnectionManager.java", "diffHunk": "@@ -876,18 +873,18 @@ private TcpClientConnection onAuthenticated(TcpClientConnection connection,\n                 logger.fine(\"Checking the cluster: \" + newClusterId + \", current cluster: \" + this.clusterId);\n             }\n \n-            boolean initialConnection = activeConnections.isEmpty();\n-            boolean changedCluster = initialConnection && this.clusterId != null && !newClusterId.equals(this.clusterId);\n-            if (changedCluster) {\n+            boolean clusterIdChanged = this.clusterId != null && !newClusterId.equals(this.clusterId);\n+            if (clusterIdChanged) {\n+                checkClientStateOnClusterIdChange(connection);\n                 logger.warning(\"Switching from current cluster: \" + this.clusterId + \" to new cluster: \" + newClusterId);\n                 client.onClusterRestart();\n             }\n \n+            boolean connectionsEmpty = activeConnections.isEmpty();\n             activeConnections.put(response.memberUuid, connection);\n-\n-            if (initialConnection) {\n+            if (connectionsEmpty) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6bd2412320a35c408cc4cd30b7713fa5d8ba4403"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYxNzk5OA==", "bodyText": "nit: missing space (//We -> // We) here and in other comments below.", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r532617998", "createdAt": "2020-11-30T14:02:15Z", "author": {"login": "puzpuzpuz"}, "path": "hazelcast/src/main/java/com/hazelcast/client/impl/connection/tcp/TcpClientConnectionManager.java", "diffHunk": "@@ -914,6 +911,30 @@ private TcpClientConnection onAuthenticated(TcpClientConnection connection,\n         return connection;\n     }\n \n+    private void checkClientStateOnClusterIdChange(TcpClientConnection connection) {\n+        if (activeConnections.isEmpty()) {\n+            //We only have single connection established", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6bd2412320a35c408cc4cd30b7713fa5d8ba4403"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYyMjk5MQ==", "bodyText": "What if there are other connections, but they're not yet closed by the HeartbeatManager (consider a situation when a cluster restarted fast enough)? Is it ok to close the connection in this case?", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r532622991", "createdAt": "2020-11-30T14:09:32Z", "author": {"login": "puzpuzpuz"}, "path": "hazelcast/src/main/java/com/hazelcast/client/impl/connection/tcp/TcpClientConnectionManager.java", "diffHunk": "@@ -914,6 +911,30 @@ private TcpClientConnection onAuthenticated(TcpClientConnection connection,\n         return connection;\n     }\n \n+    private void checkClientStateOnClusterIdChange(TcpClientConnection connection) {\n+        if (activeConnections.isEmpty()) {\n+            //We only have single connection established\n+            if (failoverConfigProvided) {\n+                //If failover is provided, and this single connection is established after failover logic kicks in\n+                // (checked via `switchingToNextCluster`), then it is OK to continue. Otherwise, we force the failover logic\n+                // to be used by throwing `ClientNotAllowedInClusterException`\n+                if (switchingToNextCluster) {\n+                    switchingToNextCluster = false;\n+                } else {\n+                    String reason = \"Force to hard cluster switch\";\n+                    connection.close(reason, null);\n+                    throw new ClientNotAllowedInClusterException(reason);\n+                }\n+            }\n+        } else {\n+            //If there are other connections that means we have a connection to wrong cluster.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6bd2412320a35c408cc4cd30b7713fa5d8ba4403"}, "originalPosition": 124}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQwODk5Nzk0", "url": "https://github.com/hazelcast/hazelcast/pull/17239#pullrequestreview-540899794", "createdAt": "2020-11-30T13:20:00Z", "commit": {"oid": "6bd2412320a35c408cc4cd30b7713fa5d8ba4403"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQxMzo0MDoyMVrOH77h3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQxMzo0MDoyMVrOH77h3g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYwMzM1OA==", "bodyText": "Assume that,\n\nFailover config is enabled\nClient connects the first cluster configured\nCluster restarts and the client loses all of its connections\nClient tries to reconnect through doConnectToCandidateCluster. It will first try to connect to the current cluster without setting switchingToNextCluster to true. Now, since the cluster is restarted, I assume that the client should connect to it on the first try (Old code also does this). But that won't happen since switchingToNextCluster is false. We will throw ClientNotAllowedInClusterException here and try to connect alternative clusters. Isn't that a behavior change?", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r532603358", "createdAt": "2020-11-30T13:40:21Z", "author": {"login": "mdumandag"}, "path": "hazelcast/src/main/java/com/hazelcast/client/impl/connection/tcp/TcpClientConnectionManager.java", "diffHunk": "@@ -914,6 +911,30 @@ private TcpClientConnection onAuthenticated(TcpClientConnection connection,\n         return connection;\n     }\n \n+    private void checkClientStateOnClusterIdChange(TcpClientConnection connection) {\n+        if (activeConnections.isEmpty()) {\n+            //We only have single connection established\n+            if (failoverConfigProvided) {\n+                //If failover is provided, and this single connection is established after failover logic kicks in\n+                // (checked via `switchingToNextCluster`), then it is OK to continue. Otherwise, we force the failover logic\n+                // to be used by throwing `ClientNotAllowedInClusterException`\n+                if (switchingToNextCluster) {\n+                    switchingToNextCluster = false;\n+                } else {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6bd2412320a35c408cc4cd30b7713fa5d8ba4403"}, "originalPosition": 117}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQxNzE1MTgx", "url": "https://github.com/hazelcast/hazelcast/pull/17239#pullrequestreview-541715181", "createdAt": "2020-12-01T09:37:36Z", "commit": {"oid": "6bd2412320a35c408cc4cd30b7713fa5d8ba4403"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQxNzQ1NTY1", "url": "https://github.com/hazelcast/hazelcast/pull/17239#pullrequestreview-541745565", "createdAt": "2020-12-01T10:12:30Z", "commit": {"oid": "6bd2412320a35c408cc4cd30b7713fa5d8ba4403"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3580, "cost": 1, "resetAt": "2021-11-01T14:51:55Z"}}}