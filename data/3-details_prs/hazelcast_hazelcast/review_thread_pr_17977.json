{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQwNzE4NDYy", "number": 17977, "reviewThreads": {"totalCount": 29, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QxNTo1MToyMlrOFTpaog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMzo1MjozOFrOFWL_PA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2MTQ1ODI2OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/ExpirationTimeSetter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QxNTo1MToyM1rOIbOlJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxNDoxNzowNlrOIb5qSQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTQyMTM0OQ==", "bodyText": "How can it be negative? Or is it just a sanity check?", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r565421349", "createdAt": "2021-01-27T15:51:23Z", "author": {"login": "blazember"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/ExpirationTimeSetter.java", "diffHunk": "@@ -31,81 +28,15 @@\n     private ExpirationTimeSetter() {\n     }\n \n-    /**\n-     * Sets expiration time if statistics are enabled.\n-     */\n-    public static void setExpirationTime(Record record) {\n-        long expirationTime = calculateExpirationTime(record);\n-        record.setExpirationTime(expirationTime);\n-    }\n-\n-    private static long calculateExpirationTime(Record record) {\n-        // calculate TTL expiration time\n-        long ttl = checkedTime(record.getTtl());\n-        long ttlExpirationTime = sumForExpiration(ttl, getLifeStartTime(record));\n-\n-        // calculate MaxIdle expiration time\n-        long maxIdle = checkedTime(record.getMaxIdle());\n-        long maxIdleExpirationTime = sumForExpiration(maxIdle, getIdlenessStartTime(record));\n+    public static long calculateExpirationTime(long ttlMillis, long maxIdleMillis, long now) {\n         // select most nearest expiration time\n-        return Math.min(ttlExpirationTime, maxIdleExpirationTime);\n-    }\n-\n-    /**\n-     * Returns last-access-time of an entry if it was accessed before, otherwise it returns creation-time of the entry.\n-     * This calculation is required for max-idle-seconds expiration, because after first creation of an entry via\n-     * {@link IMap#put}, the {@code lastAccessTime} is zero till the first access.\n-     * Any subsequent get or update operation after first put will increase the {@code lastAccessTime}.\n-     */\n-    public static long getIdlenessStartTime(Record record) {\n-        long lastAccessTime = record.getLastAccessTime();\n-        return lastAccessTime <= 0 ? record.getCreationTime() : lastAccessTime;\n-    }\n-\n-    /**\n-     * Returns last-update-time of an entry if it was updated before, otherwise it returns creation-time of the entry.\n-     * This calculation is required for time-to-live expiration, because after first creation of an entry via\n-     * {@link IMap#put}, the {@code lastUpdateTime} is zero till the first update.\n-     */\n-    public static long getLifeStartTime(Record record) {\n-        long lastUpdateTime = record.getLastUpdateTime();\n-        return lastUpdateTime <= 0 ? record.getCreationTime() : lastUpdateTime;\n-    }\n-\n-    private static long checkedTime(long time) {\n-        return time <= 0 ? Long.MAX_VALUE : time;\n-    }\n-\n-    private static long sumForExpiration(long criteriaTime, long now) {\n-        if (criteriaTime < 0 || now < 0) {\n-            throw new IllegalArgumentException(\"Parameters can not have negative values\");\n+        long expiryTime = Math.min(ttlMillis, maxIdleMillis);\n+        if (expiryTime == Long.MAX_VALUE) {\n+            return expiryTime;\n+        } else {\n+            long nextExpiryTime = expiryTime + now;\n+            return nextExpiryTime <= 0 ? Long.MAX_VALUE : nextExpiryTime;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjEyNzE3Nw==", "bodyText": "it is for overflows.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r566127177", "createdAt": "2021-01-28T14:17:06Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/ExpirationTimeSetter.java", "diffHunk": "@@ -31,81 +28,15 @@\n     private ExpirationTimeSetter() {\n     }\n \n-    /**\n-     * Sets expiration time if statistics are enabled.\n-     */\n-    public static void setExpirationTime(Record record) {\n-        long expirationTime = calculateExpirationTime(record);\n-        record.setExpirationTime(expirationTime);\n-    }\n-\n-    private static long calculateExpirationTime(Record record) {\n-        // calculate TTL expiration time\n-        long ttl = checkedTime(record.getTtl());\n-        long ttlExpirationTime = sumForExpiration(ttl, getLifeStartTime(record));\n-\n-        // calculate MaxIdle expiration time\n-        long maxIdle = checkedTime(record.getMaxIdle());\n-        long maxIdleExpirationTime = sumForExpiration(maxIdle, getIdlenessStartTime(record));\n+    public static long calculateExpirationTime(long ttlMillis, long maxIdleMillis, long now) {\n         // select most nearest expiration time\n-        return Math.min(ttlExpirationTime, maxIdleExpirationTime);\n-    }\n-\n-    /**\n-     * Returns last-access-time of an entry if it was accessed before, otherwise it returns creation-time of the entry.\n-     * This calculation is required for max-idle-seconds expiration, because after first creation of an entry via\n-     * {@link IMap#put}, the {@code lastAccessTime} is zero till the first access.\n-     * Any subsequent get or update operation after first put will increase the {@code lastAccessTime}.\n-     */\n-    public static long getIdlenessStartTime(Record record) {\n-        long lastAccessTime = record.getLastAccessTime();\n-        return lastAccessTime <= 0 ? record.getCreationTime() : lastAccessTime;\n-    }\n-\n-    /**\n-     * Returns last-update-time of an entry if it was updated before, otherwise it returns creation-time of the entry.\n-     * This calculation is required for time-to-live expiration, because after first creation of an entry via\n-     * {@link IMap#put}, the {@code lastUpdateTime} is zero till the first update.\n-     */\n-    public static long getLifeStartTime(Record record) {\n-        long lastUpdateTime = record.getLastUpdateTime();\n-        return lastUpdateTime <= 0 ? record.getCreationTime() : lastUpdateTime;\n-    }\n-\n-    private static long checkedTime(long time) {\n-        return time <= 0 ? Long.MAX_VALUE : time;\n-    }\n-\n-    private static long sumForExpiration(long criteriaTime, long now) {\n-        if (criteriaTime < 0 || now < 0) {\n-            throw new IllegalArgumentException(\"Parameters can not have negative values\");\n+        long expiryTime = Math.min(ttlMillis, maxIdleMillis);\n+        if (expiryTime == Long.MAX_VALUE) {\n+            return expiryTime;\n+        } else {\n+            long nextExpiryTime = expiryTime + now;\n+            return nextExpiryTime <= 0 ? Long.MAX_VALUE : nextExpiryTime;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTQyMTM0OQ=="}, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 69}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2MTg0NzE0OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/operation/EvictBatchBackupOperation.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QxNzoxMToyMlrOIbSbWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxNDozMTo0MVrOIb6WZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTQ4NDM3Nw==", "bodyText": "Is it safe to remove the canEvictRecord check? It seems it was protecting against removing an evicted but then readded entry on the backups.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r565484377", "createdAt": "2021-01-27T17:11:22Z", "author": {"login": "blazember"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/operation/EvictBatchBackupOperation.java", "diffHunk": "@@ -63,11 +62,7 @@ protected void runInternal() {\n         }\n \n         for (ExpiredKey expiredKey : expiredKeys) {\n-            Data key = expiredKey.getKey();\n-            Record existingRecord = recordStore.getRecord(key);\n-            if (canEvictRecord(existingRecord, expiredKey)) {\n-                recordStore.evict(key, true);\n-            }\n+            recordStore.evict(expiredKey.getKey(), true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjEzODQ2OQ==", "bodyText": "Good point, I will work on a fix after merge, created an issue for it now: #18111", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r566138469", "createdAt": "2021-01-28T14:31:41Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/operation/EvictBatchBackupOperation.java", "diffHunk": "@@ -63,11 +62,7 @@ protected void runInternal() {\n         }\n \n         for (ExpiredKey expiredKey : expiredKeys) {\n-            Data key = expiredKey.getKey();\n-            Record existingRecord = recordStore.getRecord(key);\n-            if (canEvictRecord(existingRecord, expiredKey)) {\n-                recordStore.evict(key, true);\n-            }\n+            recordStore.evict(expiredKey.getKey(), true);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTQ4NDM3Nw=="}, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2MTg3Mzk0OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/operation/MapClearExpiredOperation.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QxNzoxNzozMVrOIbSsdg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxNDozNToxN1rOIb6gsA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTQ4ODc1OA==", "bodyText": "What's the reason for removing the size check? Or what was the reason for it? \ud83d\ude04 It was just a shortcut we don't need anymore?", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r565488758", "createdAt": "2021-01-27T17:17:31Z", "author": {"login": "blazember"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/operation/MapClearExpiredOperation.java", "diffHunk": "@@ -62,9 +62,10 @@ public void run() throws Exception {\n         PartitionContainer partitionContainer = mapServiceContext.getPartitionContainer(getPartitionId());\n         ConcurrentMap<String, RecordStore> recordStores = partitionContainer.getMaps();\n         boolean backup = !isOwner();\n+        long now = Clock.currentTimeMillis();\n         for (RecordStore recordStore : recordStores.values()) {\n-            if (recordStore.size() > 0 && recordStore.isExpirable()) {\n-                recordStore.evictExpiredEntries(expirationPercentage, backup);\n+            if (recordStore.isExpirable()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjE0MTEwNA==", "bodyText": "yes no need to it since we have a new isolated expiry system, only checking over it is fine. In most situations it is a redundant check.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r566141104", "createdAt": "2021-01-28T14:35:17Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/operation/MapClearExpiredOperation.java", "diffHunk": "@@ -62,9 +62,10 @@ public void run() throws Exception {\n         PartitionContainer partitionContainer = mapServiceContext.getPartitionContainer(getPartitionId());\n         ConcurrentMap<String, RecordStore> recordStores = partitionContainer.getMaps();\n         boolean backup = !isOwner();\n+        long now = Clock.currentTimeMillis();\n         for (RecordStore recordStore : recordStores.values()) {\n-            if (recordStore.size() > 0 && recordStore.isExpirable()) {\n-                recordStore.evictExpiredEntries(expirationPercentage, backup);\n+            if (recordStore.isExpirable()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTQ4ODc1OA=="}, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2MjcyNjk4OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/AbstractRecord.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QyMDo0OTo1NVrOIba8TA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QyMDo0OTo1NVrOIba8TA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTYyMzg4NA==", "bodyText": "Not sure an int fits here well. I think we can overflow with a long-living, frequently updated entry.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r565623884", "createdAt": "2021-01-27T20:49:55Z", "author": {"login": "blazember"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/AbstractRecord.java", "diffHunk": "@@ -16,63 +16,45 @@\n \n package com.hazelcast.map.impl.record;\n \n-import com.hazelcast.query.impl.Metadata;\n import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n \n-import java.util.Objects;\n-\n import static com.hazelcast.internal.nio.Bits.INT_SIZE_IN_BYTES;\n-import static com.hazelcast.internal.nio.Bits.LONG_SIZE_IN_BYTES;\n-import static com.hazelcast.map.impl.record.RecordReaderWriter.DATA_RECORD_READER_WRITER;\n+import static com.hazelcast.internal.util.JVMUtil.OBJECT_HEADER_SIZE;\n+import static com.hazelcast.map.impl.record.RecordReaderWriter.DATA_RECORD_WITH_STATS_READER_WRITER;\n \n /**\n  * @param <V> the type of the value of Record.\n  */\n @SuppressWarnings({\"checkstyle:methodcount\", \"VolatileLongOrDoubleField\"})\n public abstract class AbstractRecord<V> implements Record<V> {\n \n-    private static final int NUMBER_OF_LONGS = 1;\n     private static final int NUMBER_OF_INTS = 6;\n \n-    protected int ttl;\n-    protected int maxIdle;\n-    protected long version;\n-\n+    protected int version;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2MjgwOTg0OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/DataRecordFactory.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QyMToxMjo1MVrOIbbuVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxNTozNzozOVrOIb9hOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTYzNjY5Mg==", "bodyText": "This if is redundant.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r565636692", "createdAt": "2021-01-27T21:12:51Z", "author": {"login": "blazember"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/DataRecordFactory.java", "diffHunk": "@@ -17,31 +17,88 @@\n package com.hazelcast.map.impl.record;\n \n import com.hazelcast.config.CacheDeserializedValues;\n+import com.hazelcast.config.EvictionPolicy;\n import com.hazelcast.config.MapConfig;\n-import com.hazelcast.internal.serialization.SerializationService;\n import com.hazelcast.internal.serialization.Data;\n+import com.hazelcast.internal.serialization.SerializationService;\n+import com.hazelcast.map.impl.MapContainer;\n+\n+import javax.annotation.Nonnull;\n+\n+import static com.hazelcast.map.impl.eviction.Evictor.NULL_EVICTOR;\n \n public class DataRecordFactory implements RecordFactory<Data> {\n \n-    private final boolean statisticsEnabled;\n+    private final MapContainer mapContainer;\n     private final SerializationService ss;\n-    private final CacheDeserializedValues cacheDeserializedValues;\n \n-    public DataRecordFactory(MapConfig config, SerializationService ss) {\n+    public DataRecordFactory(MapContainer mapContainer, SerializationService ss) {\n         this.ss = ss;\n-        this.statisticsEnabled = config.isStatisticsEnabled();\n-        this.cacheDeserializedValues = config.getCacheDeserializedValues();\n+        this.mapContainer = mapContainer;\n     }\n \n     @Override\n     public Record<Data> newRecord(Object value) {\n+        MapConfig mapConfig = mapContainer.getMapConfig();\n+        boolean statisticsEnabled = mapConfig.isStatisticsEnabled();\n+        CacheDeserializedValues cacheDeserializedValues = mapConfig.getCacheDeserializedValues();\n+        boolean hasEviction = mapContainer.getEvictor() != NULL_EVICTOR;\n+\n         Data valueData = ss.toData(value);\n \n         switch (cacheDeserializedValues) {\n             case NEVER:\n-                return statisticsEnabled ? new DataRecordWithStats(valueData) : new DataRecord(valueData);\n+                return newSimpleRecord(valueData, mapConfig, statisticsEnabled, hasEviction);\n             default:\n-                return statisticsEnabled ? new CachedDataRecordWithStats(valueData) : new CachedDataRecord(valueData);\n+                return newCachedSimpleRecord(valueData, mapConfig, statisticsEnabled, hasEviction);\n+        }\n+    }\n+\n+    @Nonnull\n+    private Record<Data> newCachedSimpleRecord(Data valueData, MapConfig mapConfig,\n+                                               boolean statisticsEnabled, boolean hasEviction) {\n+        if (!statisticsEnabled && !hasEviction) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjE5MDM5Mg==", "bodyText": "fixed.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r566190392", "createdAt": "2021-01-28T15:37:39Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/DataRecordFactory.java", "diffHunk": "@@ -17,31 +17,88 @@\n package com.hazelcast.map.impl.record;\n \n import com.hazelcast.config.CacheDeserializedValues;\n+import com.hazelcast.config.EvictionPolicy;\n import com.hazelcast.config.MapConfig;\n-import com.hazelcast.internal.serialization.SerializationService;\n import com.hazelcast.internal.serialization.Data;\n+import com.hazelcast.internal.serialization.SerializationService;\n+import com.hazelcast.map.impl.MapContainer;\n+\n+import javax.annotation.Nonnull;\n+\n+import static com.hazelcast.map.impl.eviction.Evictor.NULL_EVICTOR;\n \n public class DataRecordFactory implements RecordFactory<Data> {\n \n-    private final boolean statisticsEnabled;\n+    private final MapContainer mapContainer;\n     private final SerializationService ss;\n-    private final CacheDeserializedValues cacheDeserializedValues;\n \n-    public DataRecordFactory(MapConfig config, SerializationService ss) {\n+    public DataRecordFactory(MapContainer mapContainer, SerializationService ss) {\n         this.ss = ss;\n-        this.statisticsEnabled = config.isStatisticsEnabled();\n-        this.cacheDeserializedValues = config.getCacheDeserializedValues();\n+        this.mapContainer = mapContainer;\n     }\n \n     @Override\n     public Record<Data> newRecord(Object value) {\n+        MapConfig mapConfig = mapContainer.getMapConfig();\n+        boolean statisticsEnabled = mapConfig.isStatisticsEnabled();\n+        CacheDeserializedValues cacheDeserializedValues = mapConfig.getCacheDeserializedValues();\n+        boolean hasEviction = mapContainer.getEvictor() != NULL_EVICTOR;\n+\n         Data valueData = ss.toData(value);\n \n         switch (cacheDeserializedValues) {\n             case NEVER:\n-                return statisticsEnabled ? new DataRecordWithStats(valueData) : new DataRecord(valueData);\n+                return newSimpleRecord(valueData, mapConfig, statisticsEnabled, hasEviction);\n             default:\n-                return statisticsEnabled ? new CachedDataRecordWithStats(valueData) : new CachedDataRecord(valueData);\n+                return newCachedSimpleRecord(valueData, mapConfig, statisticsEnabled, hasEviction);\n+        }\n+    }\n+\n+    @Nonnull\n+    private Record<Data> newCachedSimpleRecord(Data valueData, MapConfig mapConfig,\n+                                               boolean statisticsEnabled, boolean hasEviction) {\n+        if (!statisticsEnabled && !hasEviction) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTYzNjY5Mg=="}, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2MjgxMTU2OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/DataRecordFactory.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QyMToxMzoyMlrOIbbvbw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxNTozNzo0M1rOIb9hdg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTYzNjk3NQ==", "bodyText": "Same redundancy here.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r565636975", "createdAt": "2021-01-27T21:13:22Z", "author": {"login": "blazember"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/DataRecordFactory.java", "diffHunk": "@@ -17,31 +17,88 @@\n package com.hazelcast.map.impl.record;\n \n import com.hazelcast.config.CacheDeserializedValues;\n+import com.hazelcast.config.EvictionPolicy;\n import com.hazelcast.config.MapConfig;\n-import com.hazelcast.internal.serialization.SerializationService;\n import com.hazelcast.internal.serialization.Data;\n+import com.hazelcast.internal.serialization.SerializationService;\n+import com.hazelcast.map.impl.MapContainer;\n+\n+import javax.annotation.Nonnull;\n+\n+import static com.hazelcast.map.impl.eviction.Evictor.NULL_EVICTOR;\n \n public class DataRecordFactory implements RecordFactory<Data> {\n \n-    private final boolean statisticsEnabled;\n+    private final MapContainer mapContainer;\n     private final SerializationService ss;\n-    private final CacheDeserializedValues cacheDeserializedValues;\n \n-    public DataRecordFactory(MapConfig config, SerializationService ss) {\n+    public DataRecordFactory(MapContainer mapContainer, SerializationService ss) {\n         this.ss = ss;\n-        this.statisticsEnabled = config.isStatisticsEnabled();\n-        this.cacheDeserializedValues = config.getCacheDeserializedValues();\n+        this.mapContainer = mapContainer;\n     }\n \n     @Override\n     public Record<Data> newRecord(Object value) {\n+        MapConfig mapConfig = mapContainer.getMapConfig();\n+        boolean statisticsEnabled = mapConfig.isStatisticsEnabled();\n+        CacheDeserializedValues cacheDeserializedValues = mapConfig.getCacheDeserializedValues();\n+        boolean hasEviction = mapContainer.getEvictor() != NULL_EVICTOR;\n+\n         Data valueData = ss.toData(value);\n \n         switch (cacheDeserializedValues) {\n             case NEVER:\n-                return statisticsEnabled ? new DataRecordWithStats(valueData) : new DataRecord(valueData);\n+                return newSimpleRecord(valueData, mapConfig, statisticsEnabled, hasEviction);\n             default:\n-                return statisticsEnabled ? new CachedDataRecordWithStats(valueData) : new CachedDataRecord(valueData);\n+                return newCachedSimpleRecord(valueData, mapConfig, statisticsEnabled, hasEviction);\n+        }\n+    }\n+\n+    @Nonnull\n+    private Record<Data> newCachedSimpleRecord(Data valueData, MapConfig mapConfig,\n+                                               boolean statisticsEnabled, boolean hasEviction) {\n+        if (!statisticsEnabled && !hasEviction) {\n+            return new CachedSimpleRecord(valueData);\n+        }\n+\n+        if (statisticsEnabled) {\n+            return new CachedDataRecordWithStats(valueData);\n         }\n+\n+        if (hasEviction) {\n+            if (mapConfig.getEvictionConfig().getEvictionPolicy() == EvictionPolicy.LRU) {\n+                return new CachedSimpleRecordWithLRUEviction(valueData);\n+            }\n+\n+            if (mapConfig.getEvictionConfig().getEvictionPolicy() == EvictionPolicy.LFU) {\n+                return new CachedSimpleRecordWithLFUEviction(valueData);\n+            }\n+        }\n+\n+        return new CachedSimpleRecord(valueData);\n+    }\n+\n+    @Nonnull\n+    private Record<Data> newSimpleRecord(Data valueData, MapConfig mapConfig,\n+                                         boolean statisticsEnabled, boolean hasEviction) {\n+        if (!statisticsEnabled && !hasEviction) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjE5MDQ1NA==", "bodyText": "fixed.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r566190454", "createdAt": "2021-01-28T15:37:43Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/DataRecordFactory.java", "diffHunk": "@@ -17,31 +17,88 @@\n package com.hazelcast.map.impl.record;\n \n import com.hazelcast.config.CacheDeserializedValues;\n+import com.hazelcast.config.EvictionPolicy;\n import com.hazelcast.config.MapConfig;\n-import com.hazelcast.internal.serialization.SerializationService;\n import com.hazelcast.internal.serialization.Data;\n+import com.hazelcast.internal.serialization.SerializationService;\n+import com.hazelcast.map.impl.MapContainer;\n+\n+import javax.annotation.Nonnull;\n+\n+import static com.hazelcast.map.impl.eviction.Evictor.NULL_EVICTOR;\n \n public class DataRecordFactory implements RecordFactory<Data> {\n \n-    private final boolean statisticsEnabled;\n+    private final MapContainer mapContainer;\n     private final SerializationService ss;\n-    private final CacheDeserializedValues cacheDeserializedValues;\n \n-    public DataRecordFactory(MapConfig config, SerializationService ss) {\n+    public DataRecordFactory(MapContainer mapContainer, SerializationService ss) {\n         this.ss = ss;\n-        this.statisticsEnabled = config.isStatisticsEnabled();\n-        this.cacheDeserializedValues = config.getCacheDeserializedValues();\n+        this.mapContainer = mapContainer;\n     }\n \n     @Override\n     public Record<Data> newRecord(Object value) {\n+        MapConfig mapConfig = mapContainer.getMapConfig();\n+        boolean statisticsEnabled = mapConfig.isStatisticsEnabled();\n+        CacheDeserializedValues cacheDeserializedValues = mapConfig.getCacheDeserializedValues();\n+        boolean hasEviction = mapContainer.getEvictor() != NULL_EVICTOR;\n+\n         Data valueData = ss.toData(value);\n \n         switch (cacheDeserializedValues) {\n             case NEVER:\n-                return statisticsEnabled ? new DataRecordWithStats(valueData) : new DataRecord(valueData);\n+                return newSimpleRecord(valueData, mapConfig, statisticsEnabled, hasEviction);\n             default:\n-                return statisticsEnabled ? new CachedDataRecordWithStats(valueData) : new CachedDataRecord(valueData);\n+                return newCachedSimpleRecord(valueData, mapConfig, statisticsEnabled, hasEviction);\n+        }\n+    }\n+\n+    @Nonnull\n+    private Record<Data> newCachedSimpleRecord(Data valueData, MapConfig mapConfig,\n+                                               boolean statisticsEnabled, boolean hasEviction) {\n+        if (!statisticsEnabled && !hasEviction) {\n+            return new CachedSimpleRecord(valueData);\n+        }\n+\n+        if (statisticsEnabled) {\n+            return new CachedDataRecordWithStats(valueData);\n         }\n+\n+        if (hasEviction) {\n+            if (mapConfig.getEvictionConfig().getEvictionPolicy() == EvictionPolicy.LRU) {\n+                return new CachedSimpleRecordWithLRUEviction(valueData);\n+            }\n+\n+            if (mapConfig.getEvictionConfig().getEvictionPolicy() == EvictionPolicy.LFU) {\n+                return new CachedSimpleRecordWithLFUEviction(valueData);\n+            }\n+        }\n+\n+        return new CachedSimpleRecord(valueData);\n+    }\n+\n+    @Nonnull\n+    private Record<Data> newSimpleRecord(Data valueData, MapConfig mapConfig,\n+                                         boolean statisticsEnabled, boolean hasEviction) {\n+        if (!statisticsEnabled && !hasEviction) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTYzNjk3NQ=="}, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 76}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2MjgyNjgwOnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/ObjectRecordFactory.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QyMToxNzowNlrOIbb4RA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxNTozNzo0NlrOIb9hnA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTYzOTIzNg==", "bodyText": "Redundant if.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r565639236", "createdAt": "2021-01-27T21:17:06Z", "author": {"login": "blazember"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/ObjectRecordFactory.java", "diffHunk": "@@ -16,25 +16,58 @@\n \n package com.hazelcast.map.impl.record;\n \n+import com.hazelcast.config.EvictionPolicy;\n import com.hazelcast.config.MapConfig;\n import com.hazelcast.internal.serialization.SerializationService;\n+import com.hazelcast.map.impl.MapContainer;\n+\n+import javax.annotation.Nonnull;\n+\n+import static com.hazelcast.map.impl.eviction.Evictor.NULL_EVICTOR;\n \n public class ObjectRecordFactory implements RecordFactory<Object> {\n \n-    private final boolean statisticsEnabled;\n+    private final MapContainer mapContainer;\n     private final SerializationService serializationService;\n \n-    public ObjectRecordFactory(MapConfig config,\n+    public ObjectRecordFactory(MapContainer mapContainer,\n                                SerializationService serializationService) {\n         this.serializationService = serializationService;\n-        this.statisticsEnabled = config.isStatisticsEnabled();\n+        this.mapContainer = mapContainer;\n     }\n \n     @Override\n     public Record<Object> newRecord(Object value) {\n+        MapConfig mapConfig = mapContainer.getMapConfig();\n+        boolean statisticsEnabled = mapConfig.isStatisticsEnabled();\n+        boolean hasEviction = mapContainer.getEvictor() != NULL_EVICTOR;\n+\n         Object objectValue = serializationService.toObject(value);\n-        return statisticsEnabled\n-                ? new ObjectRecordWithStats(objectValue)\n-                : new ObjectRecord(objectValue);\n+\n+        return newRecord(mapConfig, statisticsEnabled, hasEviction, objectValue);\n+    }\n+\n+    @Nonnull\n+    private Record<Object> newRecord(MapConfig mapConfig, boolean statisticsEnabled,\n+                                     boolean hasEviction, Object objectValue) {\n+        if (!statisticsEnabled && !hasEviction) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjE5MDQ5Mg==", "bodyText": "fixed.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r566190492", "createdAt": "2021-01-28T15:37:46Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/ObjectRecordFactory.java", "diffHunk": "@@ -16,25 +16,58 @@\n \n package com.hazelcast.map.impl.record;\n \n+import com.hazelcast.config.EvictionPolicy;\n import com.hazelcast.config.MapConfig;\n import com.hazelcast.internal.serialization.SerializationService;\n+import com.hazelcast.map.impl.MapContainer;\n+\n+import javax.annotation.Nonnull;\n+\n+import static com.hazelcast.map.impl.eviction.Evictor.NULL_EVICTOR;\n \n public class ObjectRecordFactory implements RecordFactory<Object> {\n \n-    private final boolean statisticsEnabled;\n+    private final MapContainer mapContainer;\n     private final SerializationService serializationService;\n \n-    public ObjectRecordFactory(MapConfig config,\n+    public ObjectRecordFactory(MapContainer mapContainer,\n                                SerializationService serializationService) {\n         this.serializationService = serializationService;\n-        this.statisticsEnabled = config.isStatisticsEnabled();\n+        this.mapContainer = mapContainer;\n     }\n \n     @Override\n     public Record<Object> newRecord(Object value) {\n+        MapConfig mapConfig = mapContainer.getMapConfig();\n+        boolean statisticsEnabled = mapConfig.isStatisticsEnabled();\n+        boolean hasEviction = mapContainer.getEvictor() != NULL_EVICTOR;\n+\n         Object objectValue = serializationService.toObject(value);\n-        return statisticsEnabled\n-                ? new ObjectRecordWithStats(objectValue)\n-                : new ObjectRecord(objectValue);\n+\n+        return newRecord(mapConfig, statisticsEnabled, hasEviction, objectValue);\n+    }\n+\n+    @Nonnull\n+    private Record<Object> newRecord(MapConfig mapConfig, boolean statisticsEnabled,\n+                                     boolean hasEviction, Object objectValue) {\n+        if (!statisticsEnabled && !hasEviction) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTYzOTIzNg=="}, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2MzE4MjI1OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/Record.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QyMjo1NDo1NVrOIbfQnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxNTo0NToyM1rOIb95TA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY5NDYyMA==", "bodyText": "Can't it break the txn if we freeze max int in version?", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r565694620", "createdAt": "2021-01-27T22:54:55Z", "author": {"login": "blazember"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/Record.java", "diffHunk": "@@ -197,7 +161,12 @@ default void onAccessSafe(long now) {\n     }\n \n     default void onUpdate(long now) {\n-        setVersion(getVersion() + 1);\n+        int version = getVersion();\n+        if (version < Integer.MAX_VALUE) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjE5NjU1Ng==", "bodyText": "Change it to allow overflows, so it is possible that version can also be negative after overflow.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r566196556", "createdAt": "2021-01-28T15:45:23Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/Record.java", "diffHunk": "@@ -197,7 +161,12 @@ default void onAccessSafe(long now) {\n     }\n \n     default void onUpdate(long now) {\n-        setVersion(getVersion() + 1);\n+        int version = getVersion();\n+        if (version < Integer.MAX_VALUE) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY5NDYyMA=="}, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 82}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2MzI0MjcyOnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/Records.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QyMzoxNToxMVrOIbf0Dg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxNTozNzo1MFrOIb9h0g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTcwMzY5NA==", "bodyText": "Minor: can be simplified to\nif (version.isLessThan(Versions.V4_2)) {\n  readerWriter  = RU_COMPAT_MAP.get(readerWriter);\n}\nout.writeByte(readerWriter.getId());", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r565703694", "createdAt": "2021-01-27T23:15:11Z", "author": {"login": "blazember"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/Records.java", "diffHunk": "@@ -16,32 +16,74 @@\n \n package com.hazelcast.map.impl.record;\n \n+import com.hazelcast.internal.cluster.Versions;\n+import com.hazelcast.internal.serialization.Data;\n import com.hazelcast.internal.serialization.SerializationService;\n+import com.hazelcast.map.impl.recordstore.expiry.ExpiryMetadata;\n import com.hazelcast.nio.ObjectDataInput;\n import com.hazelcast.nio.ObjectDataOutput;\n-import com.hazelcast.internal.serialization.Data;\n+import com.hazelcast.version.Version;\n \n import java.io.IOException;\n+import java.util.EnumMap;\n+import java.util.Map;\n \n import static com.hazelcast.map.impl.record.Record.NOT_CACHED;\n+import static com.hazelcast.map.impl.record.RecordReaderWriter.DATA_RECORD_READER_WRITER;\n+import static com.hazelcast.map.impl.record.RecordReaderWriter.DATA_RECORD_WITH_STATS_READER_WRITER;\n+import static com.hazelcast.map.impl.record.RecordReaderWriter.SIMPLE_DATA_RECORD_READER_WRITER;\n+import static com.hazelcast.map.impl.record.RecordReaderWriter.SIMPLE_DATA_RECORD_WITH_LFU_EVICTION_READER_WRITER;\n+import static com.hazelcast.map.impl.record.RecordReaderWriter.SIMPLE_DATA_RECORD_WITH_LRU_EVICTION_READER_WRITER;\n import static com.hazelcast.map.impl.record.RecordReaderWriter.getById;\n \n /**\n- * Contains various factory &amp; helper methods for a {@link com.hazelcast.map.impl.record.Record} object.\n+ * Contains various factory &amp; helper methods for a {@link\n+ * com.hazelcast.map.impl.record.Record} object.\n  */\n public final class Records {\n \n+    // RU_COMPAT_4_1\n+    /**\n+     * Maps RecordReaderWriter objects to their 4.1 equivalents. This is used to\n+     * support compatibility between 4.1 and 4.2 during rolling upgrades.\n+     */\n+    private static final Map<RecordReaderWriter, RecordReaderWriter> RU_COMPAT_MAP = createAndInitRuCompatMap();\n+\n     private Records() {\n     }\n \n-    public static void writeRecord(ObjectDataOutput out, Record record, Data dataValue) throws IOException {\n-        out.writeByte(record.getMatchingRecordReaderWriter().getId());\n-        record.getMatchingRecordReaderWriter().writeRecord(out, record, dataValue);\n+    private static EnumMap<RecordReaderWriter, RecordReaderWriter> createAndInitRuCompatMap() {\n+        EnumMap<RecordReaderWriter, RecordReaderWriter> ruCompatMap = new EnumMap<>(RecordReaderWriter.class);\n+        ruCompatMap.put(SIMPLE_DATA_RECORD_READER_WRITER, DATA_RECORD_READER_WRITER);\n+        ruCompatMap.put(SIMPLE_DATA_RECORD_WITH_LFU_EVICTION_READER_WRITER, DATA_RECORD_READER_WRITER);\n+        ruCompatMap.put(SIMPLE_DATA_RECORD_WITH_LRU_EVICTION_READER_WRITER, DATA_RECORD_READER_WRITER);\n+        ruCompatMap.put(DATA_RECORD_READER_WRITER, DATA_RECORD_READER_WRITER);\n+        ruCompatMap.put(DATA_RECORD_WITH_STATS_READER_WRITER, DATA_RECORD_WITH_STATS_READER_WRITER);\n+\n+        assert ruCompatMap.size() == RecordReaderWriter.values().length\n+                : \"Missing enum mapping for RU compatibility\";\n+\n+        return ruCompatMap;\n+    }\n+\n+    public static void writeRecord(ObjectDataOutput out, Record record,\n+                                   Data dataValue, ExpiryMetadata expiryMetadata) throws IOException {\n+        RecordReaderWriter readerWriter = record.getMatchingRecordReaderWriter();\n+        // RU_COMPAT_4_1\n+        Version version = out.getVersion();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjE5MDU0Ng==", "bodyText": "fixed.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r566190546", "createdAt": "2021-01-28T15:37:50Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/Records.java", "diffHunk": "@@ -16,32 +16,74 @@\n \n package com.hazelcast.map.impl.record;\n \n+import com.hazelcast.internal.cluster.Versions;\n+import com.hazelcast.internal.serialization.Data;\n import com.hazelcast.internal.serialization.SerializationService;\n+import com.hazelcast.map.impl.recordstore.expiry.ExpiryMetadata;\n import com.hazelcast.nio.ObjectDataInput;\n import com.hazelcast.nio.ObjectDataOutput;\n-import com.hazelcast.internal.serialization.Data;\n+import com.hazelcast.version.Version;\n \n import java.io.IOException;\n+import java.util.EnumMap;\n+import java.util.Map;\n \n import static com.hazelcast.map.impl.record.Record.NOT_CACHED;\n+import static com.hazelcast.map.impl.record.RecordReaderWriter.DATA_RECORD_READER_WRITER;\n+import static com.hazelcast.map.impl.record.RecordReaderWriter.DATA_RECORD_WITH_STATS_READER_WRITER;\n+import static com.hazelcast.map.impl.record.RecordReaderWriter.SIMPLE_DATA_RECORD_READER_WRITER;\n+import static com.hazelcast.map.impl.record.RecordReaderWriter.SIMPLE_DATA_RECORD_WITH_LFU_EVICTION_READER_WRITER;\n+import static com.hazelcast.map.impl.record.RecordReaderWriter.SIMPLE_DATA_RECORD_WITH_LRU_EVICTION_READER_WRITER;\n import static com.hazelcast.map.impl.record.RecordReaderWriter.getById;\n \n /**\n- * Contains various factory &amp; helper methods for a {@link com.hazelcast.map.impl.record.Record} object.\n+ * Contains various factory &amp; helper methods for a {@link\n+ * com.hazelcast.map.impl.record.Record} object.\n  */\n public final class Records {\n \n+    // RU_COMPAT_4_1\n+    /**\n+     * Maps RecordReaderWriter objects to their 4.1 equivalents. This is used to\n+     * support compatibility between 4.1 and 4.2 during rolling upgrades.\n+     */\n+    private static final Map<RecordReaderWriter, RecordReaderWriter> RU_COMPAT_MAP = createAndInitRuCompatMap();\n+\n     private Records() {\n     }\n \n-    public static void writeRecord(ObjectDataOutput out, Record record, Data dataValue) throws IOException {\n-        out.writeByte(record.getMatchingRecordReaderWriter().getId());\n-        record.getMatchingRecordReaderWriter().writeRecord(out, record, dataValue);\n+    private static EnumMap<RecordReaderWriter, RecordReaderWriter> createAndInitRuCompatMap() {\n+        EnumMap<RecordReaderWriter, RecordReaderWriter> ruCompatMap = new EnumMap<>(RecordReaderWriter.class);\n+        ruCompatMap.put(SIMPLE_DATA_RECORD_READER_WRITER, DATA_RECORD_READER_WRITER);\n+        ruCompatMap.put(SIMPLE_DATA_RECORD_WITH_LFU_EVICTION_READER_WRITER, DATA_RECORD_READER_WRITER);\n+        ruCompatMap.put(SIMPLE_DATA_RECORD_WITH_LRU_EVICTION_READER_WRITER, DATA_RECORD_READER_WRITER);\n+        ruCompatMap.put(DATA_RECORD_READER_WRITER, DATA_RECORD_READER_WRITER);\n+        ruCompatMap.put(DATA_RECORD_WITH_STATS_READER_WRITER, DATA_RECORD_WITH_STATS_READER_WRITER);\n+\n+        assert ruCompatMap.size() == RecordReaderWriter.values().length\n+                : \"Missing enum mapping for RU compatibility\";\n+\n+        return ruCompatMap;\n+    }\n+\n+    public static void writeRecord(ObjectDataOutput out, Record record,\n+                                   Data dataValue, ExpiryMetadata expiryMetadata) throws IOException {\n+        RecordReaderWriter readerWriter = record.getMatchingRecordReaderWriter();\n+        // RU_COMPAT_4_1\n+        Version version = out.getVersion();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTcwMzY5NA=="}, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2MzI3MDQ5OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/SimpleRecord.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QyMzoyNTowOVrOIbgEeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxNTozNzo1M1rOIb9h9A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTcwNzg5Nw==", "bodyText": "Is it intentionally 0? Shouldn't it be OBJECT_HEADER_SIZE + REFERENCE_COST_IN_BYTES?", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r565707897", "createdAt": "2021-01-27T23:25:09Z", "author": {"login": "blazember"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/SimpleRecord.java", "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.map.impl.record;\n+\n+import com.hazelcast.config.MapConfig;\n+import com.hazelcast.internal.serialization.Data;\n+\n+import java.util.Objects;\n+\n+import static com.hazelcast.internal.util.JVMUtil.OBJECT_HEADER_SIZE;\n+import static com.hazelcast.internal.util.JVMUtil.REFERENCE_COST_IN_BYTES;\n+import static com.hazelcast.map.impl.record.RecordReaderWriter.SIMPLE_DATA_RECORD_READER_WRITER;\n+\n+/**\n+ * Used when {@link MapConfig#isStatisticsEnabled()} is {@code false}\n+ */\n+@SuppressWarnings({\"checkstyle:methodcount\", \"VolatileLongOrDoubleField\"})\n+class SimpleRecord<V> implements Record<V> {\n+    protected volatile V value;\n+    private int version;\n+\n+    SimpleRecord() {\n+    }\n+\n+    SimpleRecord(V value) {\n+        setValue(value);\n+    }\n+\n+    @Override\n+    public final int getVersion() {\n+        return version;\n+    }\n+\n+    @Override\n+    public final void setVersion(int version) {\n+        this.version = version;\n+    }\n+\n+    @Override\n+    public long getLastAccessTime() {\n+        return UNSET;\n+    }\n+\n+    @Override\n+    public void setLastAccessTime(long lastAccessTime) {\n+    }\n+\n+    @Override\n+    public long getLastUpdateTime() {\n+        return UNSET;\n+    }\n+\n+    @Override\n+    public void setLastUpdateTime(long lastUpdateTime) {\n+    }\n+\n+    @Override\n+    public long getCreationTime() {\n+        return UNSET;\n+    }\n+\n+    @Override\n+    public void setCreationTime(long creationTime) {\n+    }\n+\n+    @Override\n+    public int getHits() {\n+        return UNSET;\n+    }\n+\n+    @Override\n+    public void setHits(int hits) {\n+    }\n+\n+    @Override\n+    public V getValue() {\n+        return value;\n+    }\n+\n+    @Override\n+    public void setValue(V value) {\n+        this.value = value;\n+    }\n+\n+    @Override\n+    public Object getCachedValueUnsafe() {\n+        return Record.NOT_CACHED;\n+    }\n+\n+    @Override\n+    public boolean casCachedValue(Object expectedValue, Object newValue) {\n+        return true;\n+    }\n+\n+    @Override\n+    public final long getSequence() {\n+        return UNSET;\n+    }\n+\n+    @Override\n+    public final void setSequence(long sequence) {\n+    }\n+\n+    @Override\n+    public long getLastStoredTime() {\n+        return UNSET;\n+    }\n+\n+    @Override\n+    public void setLastStoredTime(long lastStoredTime) {\n+    }\n+\n+    @Override\n+    public long getCost() {\n+        if (value instanceof Data) {\n+            return OBJECT_HEADER_SIZE\n+                    + REFERENCE_COST_IN_BYTES + ((Data) value).getHeapCost();\n+        } else {\n+            return 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 133}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjE5MDU4MA==", "bodyText": "For OBJECT in-memory-format we don't calculate cost for now. Add comment to make it clear.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r566190580", "createdAt": "2021-01-28T15:37:53Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/SimpleRecord.java", "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.map.impl.record;\n+\n+import com.hazelcast.config.MapConfig;\n+import com.hazelcast.internal.serialization.Data;\n+\n+import java.util.Objects;\n+\n+import static com.hazelcast.internal.util.JVMUtil.OBJECT_HEADER_SIZE;\n+import static com.hazelcast.internal.util.JVMUtil.REFERENCE_COST_IN_BYTES;\n+import static com.hazelcast.map.impl.record.RecordReaderWriter.SIMPLE_DATA_RECORD_READER_WRITER;\n+\n+/**\n+ * Used when {@link MapConfig#isStatisticsEnabled()} is {@code false}\n+ */\n+@SuppressWarnings({\"checkstyle:methodcount\", \"VolatileLongOrDoubleField\"})\n+class SimpleRecord<V> implements Record<V> {\n+    protected volatile V value;\n+    private int version;\n+\n+    SimpleRecord() {\n+    }\n+\n+    SimpleRecord(V value) {\n+        setValue(value);\n+    }\n+\n+    @Override\n+    public final int getVersion() {\n+        return version;\n+    }\n+\n+    @Override\n+    public final void setVersion(int version) {\n+        this.version = version;\n+    }\n+\n+    @Override\n+    public long getLastAccessTime() {\n+        return UNSET;\n+    }\n+\n+    @Override\n+    public void setLastAccessTime(long lastAccessTime) {\n+    }\n+\n+    @Override\n+    public long getLastUpdateTime() {\n+        return UNSET;\n+    }\n+\n+    @Override\n+    public void setLastUpdateTime(long lastUpdateTime) {\n+    }\n+\n+    @Override\n+    public long getCreationTime() {\n+        return UNSET;\n+    }\n+\n+    @Override\n+    public void setCreationTime(long creationTime) {\n+    }\n+\n+    @Override\n+    public int getHits() {\n+        return UNSET;\n+    }\n+\n+    @Override\n+    public void setHits(int hits) {\n+    }\n+\n+    @Override\n+    public V getValue() {\n+        return value;\n+    }\n+\n+    @Override\n+    public void setValue(V value) {\n+        this.value = value;\n+    }\n+\n+    @Override\n+    public Object getCachedValueUnsafe() {\n+        return Record.NOT_CACHED;\n+    }\n+\n+    @Override\n+    public boolean casCachedValue(Object expectedValue, Object newValue) {\n+        return true;\n+    }\n+\n+    @Override\n+    public final long getSequence() {\n+        return UNSET;\n+    }\n+\n+    @Override\n+    public final void setSequence(long sequence) {\n+    }\n+\n+    @Override\n+    public long getLastStoredTime() {\n+        return UNSET;\n+    }\n+\n+    @Override\n+    public void setLastStoredTime(long lastStoredTime) {\n+    }\n+\n+    @Override\n+    public long getCost() {\n+        if (value instanceof Data) {\n+            return OBJECT_HEADER_SIZE\n+                    + REFERENCE_COST_IN_BYTES + ((Data) value).getHeapCost();\n+        } else {\n+            return 0;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTcwNzg5Nw=="}, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 133}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2MzMwNTQ5OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/recordstore/DefaultRecordStore.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QyMzozMzowMVrOIbgZXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxNTozNzo1NVrOIb9iFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTcxMzI0NQ==", "bodyText": "Leftover", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r565713245", "createdAt": "2021-01-27T23:33:01Z", "author": {"login": "blazember"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/recordstore/DefaultRecordStore.java", "diffHunk": "@@ -83,13 +84,12 @@\n  */\n @SuppressWarnings({\"checkstyle:methodcount\", \"checkstyle:classfanoutcomplexity\"})\n public class DefaultRecordStore extends AbstractEvictableRecordStore {\n-\n     protected final ILogger logger;\n     protected final RecordStoreLoader recordStoreLoader;\n     protected final MapKeyLoader keyLoader;\n     /**\n      * A collection of futures representing pending completion of the key and\n-     * value loading tasks.\n+     * value loading tasks.ois", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjE5MDYxMw==", "bodyText": "removed.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r566190613", "createdAt": "2021-01-28T15:37:55Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/recordstore/DefaultRecordStore.java", "diffHunk": "@@ -83,13 +84,12 @@\n  */\n @SuppressWarnings({\"checkstyle:methodcount\", \"checkstyle:classfanoutcomplexity\"})\n public class DefaultRecordStore extends AbstractEvictableRecordStore {\n-\n     protected final ILogger logger;\n     protected final RecordStoreLoader recordStoreLoader;\n     protected final MapKeyLoader keyLoader;\n     /**\n      * A collection of futures representing pending completion of the key and\n-     * value loading tasks.\n+     * value loading tasks.ois", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTcxMzI0NQ=="}, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2MzMzNjM4OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/recordstore/DefaultRecordStore.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QyMzo0MjoyNFrOIbgseA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxNTozNzo1N1rOIb9iMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTcxODEzNg==", "bodyText": "Minor: we can simply return with the returned value, no need for the if.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r565718136", "createdAt": "2021-01-27T23:42:24Z", "author": {"login": "blazember"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/recordstore/DefaultRecordStore.java", "diffHunk": "@@ -827,72 +858,78 @@ private Object putInternal(Data key, Object newValue, long ttl,\n \n         // Put new record or update existing one.\n         if (record == null) {\n-            putNewRecord(key, oldValue, newValue, ttl, maxIdle, now,\n+            putNewRecord(key, oldValue, newValue, ttl, maxIdle, expiryTime, now,\n                     transactionId, putFromLoad ? LOADED : ADDED, store, backup);\n         } else {\n-            updateRecord(record, key, oldValue, newValue, ttl, maxIdle, now,\n+            updateRecord(record, key, oldValue, newValue, ttl, maxIdle, expiryTime, now,\n                     transactionId, store, countAsAccess, backup);\n         }\n         return oldValue;\n     }\n \n-    private Record getOrLoadRecord(@Nullable Record record, Data key,\n-                                   long now, Address callerAddress, boolean backup) {\n-        if (record != null) {\n-            accessRecord(record, now);\n-            return record;\n+    @SuppressWarnings(\"checkstyle:parameternumber\")\n+    protected Record putNewRecord(Data key, Object oldValue, Object newValue, long ttl,\n+                                  long maxIdle, long expiryTime, long now, UUID transactionId,\n+                                  EntryEventType entryEventType, boolean store,\n+                                  boolean backup) {\n+        Record record = createRecord(newValue, ttl, maxIdle, now);\n+        if (mapDataStore != EMPTY_MAP_DATA_STORE && store) {\n+            putIntoMapStore(record, key, newValue, ttl, maxIdle, now, transactionId);\n         }\n+        storage.put(key, record);\n \n-        Record loadedRecord = loadRecordOrNull(key, backup, callerAddress);\n-        if (loadedRecord != null) {\n-            return loadedRecord;\n-        }\n+        expirySystem.addKeyIfExpirable(key, ttl, maxIdle, expiryTime, now);\n \n-        return null;\n+        if (entryEventType == EntryEventType.LOADED) {\n+            mutationObserver.onLoadRecord(key, record, backup);\n+        } else {\n+            mutationObserver.onPutRecord(key, record, oldValue, backup);\n+        }\n+        return record;\n     }\n \n     @SuppressWarnings(\"checkstyle:parameternumber\")\n     protected void updateRecord(Record record, Data key, Object oldValue, Object newValue,\n-                                long ttl, long maxIdle, long now, UUID transactionId,\n+                                long ttl, long maxIdle, long expiryTime, long now, UUID transactionId,\n                                 boolean store, boolean countAsAccess, boolean backup) {\n         updateStatsOnPut(countAsAccess, now);\n         record.onUpdate(now);\n+\n         if (countAsAccess) {\n             record.onAccess(now);\n         }\n-        setExpirationTimes(record, ttl, maxIdle, mapContainer.getMapConfig());\n-        if (store) {\n-            newValue = putIntoMapStore(record, key, newValue, now, transactionId);\n+\n+        if (mapDataStore != EMPTY_MAP_DATA_STORE && store) {\n+            newValue = putIntoMapStore(record, key, newValue,\n+                    ttl, maxIdle, now, transactionId);\n         }\n+\n         storage.updateRecordValue(key, record, newValue);\n-        markRecordStoreExpirable(ttl, maxIdle);\n+        expirySystem.addKeyIfExpirable(key, ttl, maxIdle, expiryTime, now);\n+\n         mutationObserver.onUpdateRecord(key, record, oldValue, newValue, backup);\n     }\n \n-    @SuppressWarnings(\"checkstyle:parameternumber\")\n-    protected Record putNewRecord(Data key, Object oldValue, Object newValue, long ttlMillis,\n-                                  long maxIdleMillis, long now, UUID transactionId,\n-                                  EntryEventType entryEventType, boolean store,\n-                                  boolean backup) {\n-\n-        Record record = createRecord(key, newValue, ttlMillis, maxIdleMillis, now);\n-        if (store) {\n-            putIntoMapStore(record, key, newValue, now, transactionId);\n+    private Record getOrLoadRecord(@Nullable Record record, Data key,\n+                                   long now, Address callerAddress, boolean backup) {\n+        if (record != null) {\n+            accessRecord(key, record, now);\n+            return record;\n         }\n-        storage.put(key, record);\n-        markRecordStoreExpirable(ttlMillis, maxIdleMillis);\n-        if (entryEventType == EntryEventType.LOADED) {\n-            mutationObserver.onLoadRecord(key, record, backup);\n-        } else {\n-            mutationObserver.onPutRecord(key, record, oldValue, backup);\n+\n+        Record loadedRecord = loadRecordOrNull(key, backup, callerAddress);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 385}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjE5MDY0Mw==", "bodyText": "updated.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r566190643", "createdAt": "2021-01-28T15:37:57Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/recordstore/DefaultRecordStore.java", "diffHunk": "@@ -827,72 +858,78 @@ private Object putInternal(Data key, Object newValue, long ttl,\n \n         // Put new record or update existing one.\n         if (record == null) {\n-            putNewRecord(key, oldValue, newValue, ttl, maxIdle, now,\n+            putNewRecord(key, oldValue, newValue, ttl, maxIdle, expiryTime, now,\n                     transactionId, putFromLoad ? LOADED : ADDED, store, backup);\n         } else {\n-            updateRecord(record, key, oldValue, newValue, ttl, maxIdle, now,\n+            updateRecord(record, key, oldValue, newValue, ttl, maxIdle, expiryTime, now,\n                     transactionId, store, countAsAccess, backup);\n         }\n         return oldValue;\n     }\n \n-    private Record getOrLoadRecord(@Nullable Record record, Data key,\n-                                   long now, Address callerAddress, boolean backup) {\n-        if (record != null) {\n-            accessRecord(record, now);\n-            return record;\n+    @SuppressWarnings(\"checkstyle:parameternumber\")\n+    protected Record putNewRecord(Data key, Object oldValue, Object newValue, long ttl,\n+                                  long maxIdle, long expiryTime, long now, UUID transactionId,\n+                                  EntryEventType entryEventType, boolean store,\n+                                  boolean backup) {\n+        Record record = createRecord(newValue, ttl, maxIdle, now);\n+        if (mapDataStore != EMPTY_MAP_DATA_STORE && store) {\n+            putIntoMapStore(record, key, newValue, ttl, maxIdle, now, transactionId);\n         }\n+        storage.put(key, record);\n \n-        Record loadedRecord = loadRecordOrNull(key, backup, callerAddress);\n-        if (loadedRecord != null) {\n-            return loadedRecord;\n-        }\n+        expirySystem.addKeyIfExpirable(key, ttl, maxIdle, expiryTime, now);\n \n-        return null;\n+        if (entryEventType == EntryEventType.LOADED) {\n+            mutationObserver.onLoadRecord(key, record, backup);\n+        } else {\n+            mutationObserver.onPutRecord(key, record, oldValue, backup);\n+        }\n+        return record;\n     }\n \n     @SuppressWarnings(\"checkstyle:parameternumber\")\n     protected void updateRecord(Record record, Data key, Object oldValue, Object newValue,\n-                                long ttl, long maxIdle, long now, UUID transactionId,\n+                                long ttl, long maxIdle, long expiryTime, long now, UUID transactionId,\n                                 boolean store, boolean countAsAccess, boolean backup) {\n         updateStatsOnPut(countAsAccess, now);\n         record.onUpdate(now);\n+\n         if (countAsAccess) {\n             record.onAccess(now);\n         }\n-        setExpirationTimes(record, ttl, maxIdle, mapContainer.getMapConfig());\n-        if (store) {\n-            newValue = putIntoMapStore(record, key, newValue, now, transactionId);\n+\n+        if (mapDataStore != EMPTY_MAP_DATA_STORE && store) {\n+            newValue = putIntoMapStore(record, key, newValue,\n+                    ttl, maxIdle, now, transactionId);\n         }\n+\n         storage.updateRecordValue(key, record, newValue);\n-        markRecordStoreExpirable(ttl, maxIdle);\n+        expirySystem.addKeyIfExpirable(key, ttl, maxIdle, expiryTime, now);\n+\n         mutationObserver.onUpdateRecord(key, record, oldValue, newValue, backup);\n     }\n \n-    @SuppressWarnings(\"checkstyle:parameternumber\")\n-    protected Record putNewRecord(Data key, Object oldValue, Object newValue, long ttlMillis,\n-                                  long maxIdleMillis, long now, UUID transactionId,\n-                                  EntryEventType entryEventType, boolean store,\n-                                  boolean backup) {\n-\n-        Record record = createRecord(key, newValue, ttlMillis, maxIdleMillis, now);\n-        if (store) {\n-            putIntoMapStore(record, key, newValue, now, transactionId);\n+    private Record getOrLoadRecord(@Nullable Record record, Data key,\n+                                   long now, Address callerAddress, boolean backup) {\n+        if (record != null) {\n+            accessRecord(key, record, now);\n+            return record;\n         }\n-        storage.put(key, record);\n-        markRecordStoreExpirable(ttlMillis, maxIdleMillis);\n-        if (entryEventType == EntryEventType.LOADED) {\n-            mutationObserver.onLoadRecord(key, record, backup);\n-        } else {\n-            mutationObserver.onPutRecord(key, record, oldValue, backup);\n+\n+        Record loadedRecord = loadRecordOrNull(key, backup, callerAddress);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTcxODEzNg=="}, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 385}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2MzM1NDUyOnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/recordstore/expiry/ExpiryMetadata.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QyMzo0OTozOFrOIbg3NA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxNTozODowMVrOIb9ibQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTcyMDg4NA==", "bodyText": "Maybe these can be moved into TimeUtil?", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r565720884", "createdAt": "2021-01-27T23:49:38Z", "author": {"login": "blazember"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/recordstore/expiry/ExpiryMetadata.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.map.impl.recordstore.expiry;\n+\n+import static com.hazelcast.map.impl.record.Record.EPOCH_TIME;\n+import static com.hazelcast.map.impl.record.Record.UNSET;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+public interface ExpiryMetadata {\n+\n+    @SuppressWarnings(\"checkstyle:anoninnerlength\")\n+    ExpiryMetadata NULL = new ExpiryMetadata() {\n+        @Override\n+        public long getTtl() {\n+            return Long.MAX_VALUE;\n+        }\n+\n+        @Override\n+        public int getRawTtl() {\n+            return Integer.MAX_VALUE;\n+        }\n+\n+        @Override\n+        public ExpiryMetadata setTtl(long ttl) {\n+            throw new UnsupportedOperationException();\n+        }\n+\n+        @Override\n+        public ExpiryMetadata setRawTtl(int ttl) {\n+            throw new UnsupportedOperationException();\n+        }\n+\n+        @Override\n+        public long getMaxIdle() {\n+            return Long.MAX_VALUE;\n+        }\n+\n+        @Override\n+        public int getRawMaxIdle() {\n+            return Integer.MAX_VALUE;\n+        }\n+\n+        @Override\n+        public ExpiryMetadata setMaxIdle(long maxIdle) {\n+            throw new UnsupportedOperationException();\n+        }\n+\n+        @Override\n+        public ExpiryMetadata setRawMaxIdle(int maxIdle) {\n+            throw new UnsupportedOperationException();\n+        }\n+\n+        @Override\n+        public long getExpirationTime() {\n+            return Long.MAX_VALUE;\n+        }\n+\n+        @Override\n+        public int getRawExpirationTime() {\n+            return Integer.MAX_VALUE;\n+        }\n+\n+        @Override\n+        public ExpiryMetadata setExpirationTime(long expirationTime) {\n+            throw new UnsupportedOperationException();\n+        }\n+\n+        @Override\n+        public ExpiryMetadata setRawExpirationTime(int expirationTime) {\n+            throw new UnsupportedOperationException();\n+        }\n+    };\n+\n+\n+    long getTtl();\n+\n+    int getRawTtl();\n+\n+    ExpiryMetadata setTtl(long ttl);\n+\n+    ExpiryMetadata setRawTtl(int ttl);\n+\n+    long getMaxIdle();\n+\n+    int getRawMaxIdle();\n+\n+    ExpiryMetadata setMaxIdle(long maxIdle);\n+\n+    ExpiryMetadata setRawMaxIdle(int maxIdle);\n+\n+    long getExpirationTime();\n+\n+    int getRawExpirationTime();\n+\n+    ExpiryMetadata setExpirationTime(long expirationTime);\n+\n+    ExpiryMetadata setRawExpirationTime(int expirationTime);\n+\n+    default int stripBaseTime(long value) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 114}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjE5MDcwMQ==", "bodyText": "i can do it in a later enhancement PR.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r566190701", "createdAt": "2021-01-28T15:38:01Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/recordstore/expiry/ExpiryMetadata.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.map.impl.recordstore.expiry;\n+\n+import static com.hazelcast.map.impl.record.Record.EPOCH_TIME;\n+import static com.hazelcast.map.impl.record.Record.UNSET;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+public interface ExpiryMetadata {\n+\n+    @SuppressWarnings(\"checkstyle:anoninnerlength\")\n+    ExpiryMetadata NULL = new ExpiryMetadata() {\n+        @Override\n+        public long getTtl() {\n+            return Long.MAX_VALUE;\n+        }\n+\n+        @Override\n+        public int getRawTtl() {\n+            return Integer.MAX_VALUE;\n+        }\n+\n+        @Override\n+        public ExpiryMetadata setTtl(long ttl) {\n+            throw new UnsupportedOperationException();\n+        }\n+\n+        @Override\n+        public ExpiryMetadata setRawTtl(int ttl) {\n+            throw new UnsupportedOperationException();\n+        }\n+\n+        @Override\n+        public long getMaxIdle() {\n+            return Long.MAX_VALUE;\n+        }\n+\n+        @Override\n+        public int getRawMaxIdle() {\n+            return Integer.MAX_VALUE;\n+        }\n+\n+        @Override\n+        public ExpiryMetadata setMaxIdle(long maxIdle) {\n+            throw new UnsupportedOperationException();\n+        }\n+\n+        @Override\n+        public ExpiryMetadata setRawMaxIdle(int maxIdle) {\n+            throw new UnsupportedOperationException();\n+        }\n+\n+        @Override\n+        public long getExpirationTime() {\n+            return Long.MAX_VALUE;\n+        }\n+\n+        @Override\n+        public int getRawExpirationTime() {\n+            return Integer.MAX_VALUE;\n+        }\n+\n+        @Override\n+        public ExpiryMetadata setExpirationTime(long expirationTime) {\n+            throw new UnsupportedOperationException();\n+        }\n+\n+        @Override\n+        public ExpiryMetadata setRawExpirationTime(int expirationTime) {\n+            throw new UnsupportedOperationException();\n+        }\n+    };\n+\n+\n+    long getTtl();\n+\n+    int getRawTtl();\n+\n+    ExpiryMetadata setTtl(long ttl);\n+\n+    ExpiryMetadata setRawTtl(int ttl);\n+\n+    long getMaxIdle();\n+\n+    int getRawMaxIdle();\n+\n+    ExpiryMetadata setMaxIdle(long maxIdle);\n+\n+    ExpiryMetadata setRawMaxIdle(int maxIdle);\n+\n+    long getExpirationTime();\n+\n+    int getRawExpirationTime();\n+\n+    ExpiryMetadata setExpirationTime(long expirationTime);\n+\n+    ExpiryMetadata setRawExpirationTime(int expirationTime);\n+\n+    default int stripBaseTime(long value) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTcyMDg4NA=="}, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 114}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2MzM4NDQ3OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/recordstore/expiry/ExpirySystem.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQwMDowMTowN1rOIbhI-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxNTozODowNFrOIb9inA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTcyNTQzNQ==", "bodyText": "Has this been done?", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r565725435", "createdAt": "2021-01-28T00:01:07Z", "author": {"login": "blazember"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/recordstore/expiry/ExpirySystem.java", "diffHunk": "@@ -0,0 +1,361 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.map.impl.recordstore.expiry;\n+\n+import com.hazelcast.config.MapConfig;\n+import com.hazelcast.internal.eviction.ClearExpiredRecordsTask;\n+import com.hazelcast.internal.eviction.ExpiredKey;\n+import com.hazelcast.internal.nearcache.impl.invalidation.InvalidationQueue;\n+import com.hazelcast.internal.serialization.Data;\n+import com.hazelcast.internal.util.MapUtil;\n+import com.hazelcast.logging.ILogger;\n+import com.hazelcast.map.impl.ExpirationTimeSetter;\n+import com.hazelcast.map.impl.MapContainer;\n+import com.hazelcast.map.impl.MapServiceContext;\n+import com.hazelcast.map.impl.eviction.Evictor;\n+import com.hazelcast.map.impl.recordstore.RecordStore;\n+import com.hazelcast.spi.impl.NodeEngine;\n+import com.hazelcast.spi.properties.ClusterProperty;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.hazelcast.internal.util.ToHeapDataConverter.toHeapData;\n+import static com.hazelcast.map.impl.ExpirationTimeSetter.pickMaxIdleMillis;\n+import static com.hazelcast.map.impl.ExpirationTimeSetter.pickTTLMillis;\n+import static com.hazelcast.map.impl.record.Record.UNSET;\n+import static java.util.concurrent.TimeUnit.NANOSECONDS;\n+\n+/**\n+ * This class has all logic to remove expired entries. Expiry reason\n+ * can be ttl or idleness. An instance of this class is created for\n+ * each {@link RecordStore} and it is always accessed by same single thread.\n+ */\n+public class ExpirySystem {\n+    private static final long DEFAULT_EXPIRED_KEY_SCAN_TIMEOUT_NANOS\n+            = TimeUnit.MILLISECONDS.toNanos(1);\n+    private static final String PROP_EXPIRED_KEY_SCAN_TIMEOUT_NANOS\n+            = \"hazelcast.internal.map.expired.key.scan.timeout.nanos\";\n+    private static final HazelcastProperty EXPIRED_KEY_SCAN_TIMEOUT_NANOS\n+            = new HazelcastProperty(PROP_EXPIRED_KEY_SCAN_TIMEOUT_NANOS,\n+            DEFAULT_EXPIRED_KEY_SCAN_TIMEOUT_NANOS, NANOSECONDS);\n+    private static final int ONE_HUNDRED_PERCENT = 100;\n+    private static final int MIN_SCANNABLE_ENTRY_COUNT = 100;\n+\n+    private final long expiryDelayMillis;\n+    private final long expiredKeyScanTimeoutNanos;\n+    private final boolean canPrimaryDriveExpiration;\n+    private final ILogger logger;\n+    private final RecordStore recordStore;\n+    private final MapContainer mapContainer;\n+    private final MapServiceContext mapServiceContext;\n+    private final ClearExpiredRecordsTask clearExpiredRecordsTask;\n+    private final InvalidationQueue<ExpiredKey> expiredKeys = new InvalidationQueue<>();\n+\n+    private Iterator<Map.Entry<Data, ExpiryMetadata>> cachedExpirationIterator;\n+    private Map<Data, ExpiryMetadata> expireTimeByKey;\n+\n+    public ExpirySystem(RecordStore recordStore,\n+                        MapContainer mapContainer,\n+                        MapServiceContext mapServiceContext) {\n+        this.recordStore = recordStore;\n+        this.clearExpiredRecordsTask = mapServiceContext.getExpirationManager().getTask();\n+        NodeEngine nodeEngine = mapServiceContext.getNodeEngine();\n+        this.logger = nodeEngine.getLogger(getClass());\n+        HazelcastProperties hazelcastProperties = nodeEngine.getProperties();\n+        this.expiryDelayMillis = hazelcastProperties.getMillis(ClusterProperty.MAP_EXPIRY_DELAY_SECONDS);\n+        this.mapContainer = mapContainer;\n+        this.mapServiceContext = mapServiceContext;\n+        this.canPrimaryDriveExpiration = mapServiceContext.getClearExpiredRecordsTask().canPrimaryDriveExpiration();\n+        this.expiredKeyScanTimeoutNanos = nodeEngine.getProperties().getNanos(EXPIRED_KEY_SCAN_TIMEOUT_NANOS);\n+    }\n+\n+    public boolean isEmpty() {\n+        return MapUtil.isNullOrEmpty(expireTimeByKey);\n+    }\n+\n+    // this method is overridden\n+    protected Map<Data, ExpiryMetadata> createExpiryTimeByKeyMap() {\n+        // Only one thread can access this class but we\n+        // used CHM here, because its iterator doesn't\n+        // throw ConcurrentModificationException.\n+        return new ConcurrentHashMap<>();\n+    }\n+\n+    // this method is overridden\n+    public void clear() {\n+        Map<Data, ExpiryMetadata> map = getOrCreateExpireTimeByKeyMap(false);\n+        map.clear();\n+    }\n+\n+    protected Map<Data, ExpiryMetadata> getOrCreateExpireTimeByKeyMap(boolean createIfAbsent) {\n+        if (expireTimeByKey != null) {\n+            return expireTimeByKey;\n+        }\n+\n+        if (createIfAbsent) {\n+            expireTimeByKey = createExpiryTimeByKeyMap();\n+            return expireTimeByKey;\n+        }\n+\n+        return Collections.emptyMap();\n+    }\n+\n+    // this method is overridden\n+    protected ExpiryMetadata createExpiryMetadata(long ttlMillis, long maxIdleMillis, long expirationTime) {\n+        return new ExpiryMetadataImpl(ttlMillis, maxIdleMillis, expirationTime);\n+    }\n+\n+    public void addKeyIfExpirable(Data key, long ttl, long maxIdle, long expiryTime, long now) {\n+        if (expiryTime <= 0) {\n+            MapConfig mapConfig = mapContainer.getMapConfig();\n+            long ttlMillis = pickTTLMillis(ttl, mapConfig);\n+            long maxIdleMillis = pickMaxIdleMillis(maxIdle, mapConfig);\n+            long expirationTime = ExpirationTimeSetter.calculateExpirationTime(ttlMillis, maxIdleMillis, now);\n+            addExpirableKey(key, ttlMillis, maxIdleMillis, expirationTime);\n+        } else {\n+            addExpirableKey(key, ttl, maxIdle, expiryTime);\n+        }\n+    }\n+\n+    private void addExpirableKey(Data key, long ttlMillis, long maxIdleMillis, long expirationTime) {\n+        if (expirationTime == Long.MAX_VALUE) {\n+            Map<Data, ExpiryMetadata> map = getOrCreateExpireTimeByKeyMap(false);\n+            if (!map.isEmpty()) {\n+                Data nativeKey = recordStore.getStorage().toBackingDataKeyFormat(key);\n+                callRemove(nativeKey, expireTimeByKey);\n+            }\n+            return;\n+        }\n+\n+        Map<Data, ExpiryMetadata> expireTimeByKey = getOrCreateExpireTimeByKeyMap(true);\n+        ExpiryMetadata expiryMetadata = expireTimeByKey.get(key);\n+        if (expiryMetadata == null) {\n+            expiryMetadata = createExpiryMetadata(ttlMillis, maxIdleMillis, expirationTime);\n+            Data nativeKey = recordStore.getStorage().toBackingDataKeyFormat(key);\n+            expireTimeByKey.put(nativeKey, expiryMetadata);\n+        } else {\n+            expiryMetadata.setTtl(ttlMillis)\n+                    .setMaxIdle(maxIdleMillis)\n+                    .setExpirationTime(expirationTime);\n+        }\n+\n+        mapServiceContext.getExpirationManager().scheduleExpirationTask();\n+    }\n+\n+    public long calculateExpirationTime(long ttl, long maxIdle, long now) {\n+        MapConfig mapConfig = mapContainer.getMapConfig();\n+        long ttlMillis = pickTTLMillis(ttl, mapConfig);\n+        long maxIdleMillis = pickMaxIdleMillis(maxIdle, mapConfig);\n+        return ExpirationTimeSetter.calculateExpirationTime(ttlMillis, maxIdleMillis, now);\n+    }\n+\n+    public void removeKeyFromExpirySystem(Data key) {\n+        Map<Data, ExpiryMetadata> expireTimeByKey = getOrCreateExpireTimeByKeyMap(false);\n+        if (expireTimeByKey.isEmpty()) {\n+            return;\n+        }\n+        callRemove(key, expireTimeByKey);\n+    }\n+\n+    // TODO add test for this.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 183}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjE5MDc0OA==", "bodyText": "yes we have a test for it here: ExpirationTimeTest#testExpirationTime_withMaxIdleTime_afterMultipleAccesses", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r566190748", "createdAt": "2021-01-28T15:38:04Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/recordstore/expiry/ExpirySystem.java", "diffHunk": "@@ -0,0 +1,361 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.map.impl.recordstore.expiry;\n+\n+import com.hazelcast.config.MapConfig;\n+import com.hazelcast.internal.eviction.ClearExpiredRecordsTask;\n+import com.hazelcast.internal.eviction.ExpiredKey;\n+import com.hazelcast.internal.nearcache.impl.invalidation.InvalidationQueue;\n+import com.hazelcast.internal.serialization.Data;\n+import com.hazelcast.internal.util.MapUtil;\n+import com.hazelcast.logging.ILogger;\n+import com.hazelcast.map.impl.ExpirationTimeSetter;\n+import com.hazelcast.map.impl.MapContainer;\n+import com.hazelcast.map.impl.MapServiceContext;\n+import com.hazelcast.map.impl.eviction.Evictor;\n+import com.hazelcast.map.impl.recordstore.RecordStore;\n+import com.hazelcast.spi.impl.NodeEngine;\n+import com.hazelcast.spi.properties.ClusterProperty;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.hazelcast.internal.util.ToHeapDataConverter.toHeapData;\n+import static com.hazelcast.map.impl.ExpirationTimeSetter.pickMaxIdleMillis;\n+import static com.hazelcast.map.impl.ExpirationTimeSetter.pickTTLMillis;\n+import static com.hazelcast.map.impl.record.Record.UNSET;\n+import static java.util.concurrent.TimeUnit.NANOSECONDS;\n+\n+/**\n+ * This class has all logic to remove expired entries. Expiry reason\n+ * can be ttl or idleness. An instance of this class is created for\n+ * each {@link RecordStore} and it is always accessed by same single thread.\n+ */\n+public class ExpirySystem {\n+    private static final long DEFAULT_EXPIRED_KEY_SCAN_TIMEOUT_NANOS\n+            = TimeUnit.MILLISECONDS.toNanos(1);\n+    private static final String PROP_EXPIRED_KEY_SCAN_TIMEOUT_NANOS\n+            = \"hazelcast.internal.map.expired.key.scan.timeout.nanos\";\n+    private static final HazelcastProperty EXPIRED_KEY_SCAN_TIMEOUT_NANOS\n+            = new HazelcastProperty(PROP_EXPIRED_KEY_SCAN_TIMEOUT_NANOS,\n+            DEFAULT_EXPIRED_KEY_SCAN_TIMEOUT_NANOS, NANOSECONDS);\n+    private static final int ONE_HUNDRED_PERCENT = 100;\n+    private static final int MIN_SCANNABLE_ENTRY_COUNT = 100;\n+\n+    private final long expiryDelayMillis;\n+    private final long expiredKeyScanTimeoutNanos;\n+    private final boolean canPrimaryDriveExpiration;\n+    private final ILogger logger;\n+    private final RecordStore recordStore;\n+    private final MapContainer mapContainer;\n+    private final MapServiceContext mapServiceContext;\n+    private final ClearExpiredRecordsTask clearExpiredRecordsTask;\n+    private final InvalidationQueue<ExpiredKey> expiredKeys = new InvalidationQueue<>();\n+\n+    private Iterator<Map.Entry<Data, ExpiryMetadata>> cachedExpirationIterator;\n+    private Map<Data, ExpiryMetadata> expireTimeByKey;\n+\n+    public ExpirySystem(RecordStore recordStore,\n+                        MapContainer mapContainer,\n+                        MapServiceContext mapServiceContext) {\n+        this.recordStore = recordStore;\n+        this.clearExpiredRecordsTask = mapServiceContext.getExpirationManager().getTask();\n+        NodeEngine nodeEngine = mapServiceContext.getNodeEngine();\n+        this.logger = nodeEngine.getLogger(getClass());\n+        HazelcastProperties hazelcastProperties = nodeEngine.getProperties();\n+        this.expiryDelayMillis = hazelcastProperties.getMillis(ClusterProperty.MAP_EXPIRY_DELAY_SECONDS);\n+        this.mapContainer = mapContainer;\n+        this.mapServiceContext = mapServiceContext;\n+        this.canPrimaryDriveExpiration = mapServiceContext.getClearExpiredRecordsTask().canPrimaryDriveExpiration();\n+        this.expiredKeyScanTimeoutNanos = nodeEngine.getProperties().getNanos(EXPIRED_KEY_SCAN_TIMEOUT_NANOS);\n+    }\n+\n+    public boolean isEmpty() {\n+        return MapUtil.isNullOrEmpty(expireTimeByKey);\n+    }\n+\n+    // this method is overridden\n+    protected Map<Data, ExpiryMetadata> createExpiryTimeByKeyMap() {\n+        // Only one thread can access this class but we\n+        // used CHM here, because its iterator doesn't\n+        // throw ConcurrentModificationException.\n+        return new ConcurrentHashMap<>();\n+    }\n+\n+    // this method is overridden\n+    public void clear() {\n+        Map<Data, ExpiryMetadata> map = getOrCreateExpireTimeByKeyMap(false);\n+        map.clear();\n+    }\n+\n+    protected Map<Data, ExpiryMetadata> getOrCreateExpireTimeByKeyMap(boolean createIfAbsent) {\n+        if (expireTimeByKey != null) {\n+            return expireTimeByKey;\n+        }\n+\n+        if (createIfAbsent) {\n+            expireTimeByKey = createExpiryTimeByKeyMap();\n+            return expireTimeByKey;\n+        }\n+\n+        return Collections.emptyMap();\n+    }\n+\n+    // this method is overridden\n+    protected ExpiryMetadata createExpiryMetadata(long ttlMillis, long maxIdleMillis, long expirationTime) {\n+        return new ExpiryMetadataImpl(ttlMillis, maxIdleMillis, expirationTime);\n+    }\n+\n+    public void addKeyIfExpirable(Data key, long ttl, long maxIdle, long expiryTime, long now) {\n+        if (expiryTime <= 0) {\n+            MapConfig mapConfig = mapContainer.getMapConfig();\n+            long ttlMillis = pickTTLMillis(ttl, mapConfig);\n+            long maxIdleMillis = pickMaxIdleMillis(maxIdle, mapConfig);\n+            long expirationTime = ExpirationTimeSetter.calculateExpirationTime(ttlMillis, maxIdleMillis, now);\n+            addExpirableKey(key, ttlMillis, maxIdleMillis, expirationTime);\n+        } else {\n+            addExpirableKey(key, ttl, maxIdle, expiryTime);\n+        }\n+    }\n+\n+    private void addExpirableKey(Data key, long ttlMillis, long maxIdleMillis, long expirationTime) {\n+        if (expirationTime == Long.MAX_VALUE) {\n+            Map<Data, ExpiryMetadata> map = getOrCreateExpireTimeByKeyMap(false);\n+            if (!map.isEmpty()) {\n+                Data nativeKey = recordStore.getStorage().toBackingDataKeyFormat(key);\n+                callRemove(nativeKey, expireTimeByKey);\n+            }\n+            return;\n+        }\n+\n+        Map<Data, ExpiryMetadata> expireTimeByKey = getOrCreateExpireTimeByKeyMap(true);\n+        ExpiryMetadata expiryMetadata = expireTimeByKey.get(key);\n+        if (expiryMetadata == null) {\n+            expiryMetadata = createExpiryMetadata(ttlMillis, maxIdleMillis, expirationTime);\n+            Data nativeKey = recordStore.getStorage().toBackingDataKeyFormat(key);\n+            expireTimeByKey.put(nativeKey, expiryMetadata);\n+        } else {\n+            expiryMetadata.setTtl(ttlMillis)\n+                    .setMaxIdle(maxIdleMillis)\n+                    .setExpirationTime(expirationTime);\n+        }\n+\n+        mapServiceContext.getExpirationManager().scheduleExpirationTask();\n+    }\n+\n+    public long calculateExpirationTime(long ttl, long maxIdle, long now) {\n+        MapConfig mapConfig = mapContainer.getMapConfig();\n+        long ttlMillis = pickTTLMillis(ttl, mapConfig);\n+        long maxIdleMillis = pickMaxIdleMillis(maxIdle, mapConfig);\n+        return ExpirationTimeSetter.calculateExpirationTime(ttlMillis, maxIdleMillis, now);\n+    }\n+\n+    public void removeKeyFromExpirySystem(Data key) {\n+        Map<Data, ExpiryMetadata> expireTimeByKey = getOrCreateExpireTimeByKeyMap(false);\n+        if (expireTimeByKey.isEmpty()) {\n+            return;\n+        }\n+        callRemove(key, expireTimeByKey);\n+    }\n+\n+    // TODO add test for this.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTcyNTQzNQ=="}, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 183}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2MzQyMjc0OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/exec/scan/MapScanExecIterator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQwMDoxNjo1MlrOIbhfnw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxNTozODowN1rOIb9izQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTczMTIzMQ==", "bodyText": "To skip the records that should have already been removed by the expiry logic if it was run since the expiry time of the record elapsed?", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r565731231", "createdAt": "2021-01-28T00:16:52Z", "author": {"login": "blazember"}, "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/exec/scan/MapScanExecIterator.java", "diffHunk": "@@ -121,7 +121,8 @@ private void advance0() {\n             while (currentRecordStoreIterator.hasNext()) {\n                 Map.Entry<Data, Record<Object>> entry = currentRecordStoreIterator.next();\n \n-                if (!currentRecordStore.isExpired(entry.getValue(), now, false)) {\n+                // TODO why do we have expiry check here", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjE5MDc5Nw==", "bodyText": "record-store has a forEach method for that, it may be used there.\nupdated todo comment.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r566190797", "createdAt": "2021-01-28T15:38:07Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/exec/scan/MapScanExecIterator.java", "diffHunk": "@@ -121,7 +121,8 @@ private void advance0() {\n             while (currentRecordStoreIterator.hasNext()) {\n                 Map.Entry<Data, Record<Object>> entry = currentRecordStoreIterator.next();\n \n-                if (!currentRecordStore.isExpired(entry.getValue(), now, false)) {\n+                // TODO why do we have expiry check here", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTczMTIzMQ=="}, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2MzQyNzU3OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/test/java/com/hazelcast/internal/eviction/MapExpirationStressTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQwMDoxODo0MVrOIbhiVw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxNTozODoxMVrOIb9i7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTczMTkyNw==", "bodyText": "Is it intentionally remained QuickTest?", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r565731927", "createdAt": "2021-01-28T00:18:41Z", "author": {"login": "blazember"}, "path": "hazelcast/src/test/java/com/hazelcast/internal/eviction/MapExpirationStressTest.java", "diffHunk": "@@ -43,7 +43,7 @@\n import static com.hazelcast.test.backup.TestBackupUtils.assertBackupSizeEventually;\n \n @RunWith(HazelcastSerialClassRunner.class)\n-@Category(NightlyTest.class)\n+@Category(QuickTest.class)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjE5MDgzMQ==", "bodyText": "put into NightlyTest back.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r566190831", "createdAt": "2021-01-28T15:38:11Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/test/java/com/hazelcast/internal/eviction/MapExpirationStressTest.java", "diffHunk": "@@ -43,7 +43,7 @@\n import static com.hazelcast.test.backup.TestBackupUtils.assertBackupSizeEventually;\n \n @RunWith(HazelcastSerialClassRunner.class)\n-@Category(NightlyTest.class)\n+@Category(QuickTest.class)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTczMTkyNw=="}, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2MzQzMDIyOnYy", "diffSide": "RIGHT", "path": "hazelcast/src/test/java/com/hazelcast/map/EntryCostEstimatorTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQwMDoxOTo0NFrOIbhjyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxNTozODoxNFrOIb9jHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTczMjI5OA==", "bodyText": "Leftover?", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r565732298", "createdAt": "2021-01-28T00:19:44Z", "author": {"login": "blazember"}, "path": "hazelcast/src/test/java/com/hazelcast/map/EntryCostEstimatorTest.java", "diffHunk": "@@ -33,6 +34,7 @@\n import static org.junit.Assert.assertEquals;\n import static org.junit.Assert.assertTrue;\n \n+@Ignore", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjE5MDg3OQ==", "bodyText": "Removed @Ignore", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r566190879", "createdAt": "2021-01-28T15:38:14Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/test/java/com/hazelcast/map/EntryCostEstimatorTest.java", "diffHunk": "@@ -33,6 +34,7 @@\n import static org.junit.Assert.assertEquals;\n import static org.junit.Assert.assertTrue;\n \n+@Ignore", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTczMjI5OA=="}, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2MzQzMzI0OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/test/java/com/hazelcast/map/ExpirationTimeTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQwMDoyMDo1MlrOIbhlWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxNTozODoxOFrOIb9jSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTczMjY5OQ==", "bodyText": "Are these intentionally kept scaled down?", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r565732699", "createdAt": "2021-01-28T00:20:52Z", "author": {"login": "blazember"}, "path": "hazelcast/src/test/java/com/hazelcast/map/ExpirationTimeTest.java", "diffHunk": "@@ -140,25 +140,26 @@ public void test_replicated_entries_view_equal_after_cluster_scale_up() {\n \n         HazelcastInstance node1 = factory.newHazelcastInstance(config);\n         IMap<Integer, Integer> map = node1.getMap(mapName);\n-        for (int i = 0; i < 10; i++) {\n+        for (int i = 0; i < 1; i++) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjE5MDkyMg==", "bodyText": "restored original version.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r566190922", "createdAt": "2021-01-28T15:38:18Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/test/java/com/hazelcast/map/ExpirationTimeTest.java", "diffHunk": "@@ -140,25 +140,26 @@ public void test_replicated_entries_view_equal_after_cluster_scale_up() {\n \n         HazelcastInstance node1 = factory.newHazelcastInstance(config);\n         IMap<Integer, Integer> map = node1.getMap(mapName);\n-        for (int i = 0; i < 10; i++) {\n+        for (int i = 0; i < 1; i++) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTczMjY5OQ=="}, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2MzQzODY0OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/test/java/com/hazelcast/map/impl/mapstore/writebehind/MapStoreWriteBehindTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQwMDoyMjoxM1rOIbhoYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxNTozODoyMFrOIb9jcQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTczMzQ3Mw==", "bodyText": "Leftover", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r565733473", "createdAt": "2021-01-28T00:22:13Z", "author": {"login": "blazember"}, "path": "hazelcast/src/test/java/com/hazelcast/map/impl/mapstore/writebehind/MapStoreWriteBehindTest.java", "diffHunk": "@@ -80,6 +80,7 @@\n     public void testOneMemberWriteBehindWithMaxIdle() {\n         final EventBasedMapStore testMapStore = new EventBasedMapStore();\n         Config config = newConfig(testMapStore, 5, InitialLoadMode.EAGER);\n+//        Config config = getConfig();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjE5MDk2MQ==", "bodyText": "yes, deleted it.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r566190961", "createdAt": "2021-01-28T15:38:20Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/test/java/com/hazelcast/map/impl/mapstore/writebehind/MapStoreWriteBehindTest.java", "diffHunk": "@@ -80,6 +80,7 @@\n     public void testOneMemberWriteBehindWithMaxIdle() {\n         final EventBasedMapStore testMapStore = new EventBasedMapStore();\n         Config config = newConfig(testMapStore, 5, InitialLoadMode.EAGER);\n+//        Config config = getConfig();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTczMzQ3Mw=="}, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2MzQ0ODQ0OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/test/java/com/hazelcast/map/impl/recordstore/LazyEvictableEntryViewTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQwMDoyMzo0NFrOIbhtlw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxNTozODoyM1rOIb9jmA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTczNDgwNw==", "bodyText": "Leftover", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r565734807", "createdAt": "2021-01-28T00:23:44Z", "author": {"login": "blazember"}, "path": "hazelcast/src/test/java/com/hazelcast/map/impl/recordstore/LazyEvictableEntryViewTest.java", "diffHunk": "@@ -77,6 +84,8 @@ public void test_getValue() {\n     }\n \n     @Test\n+    @Ignore\n+    // TODO fixme", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjE5MTAwMA==", "bodyText": "yes, fixed.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r566191000", "createdAt": "2021-01-28T15:38:23Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/test/java/com/hazelcast/map/impl/recordstore/LazyEvictableEntryViewTest.java", "diffHunk": "@@ -77,6 +84,8 @@ public void test_getValue() {\n     }\n \n     @Test\n+    @Ignore\n+    // TODO fixme", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTczNDgwNw=="}, "originalCommit": {"oid": "b09caaaae8cbe09328786ff450e042f29decae55"}, "originalPosition": 58}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2Njc1MzExOnYy", "diffSide": "RIGHT", "path": "hazelcast/src/test/java/com/hazelcast/map/EntryCostEstimatorTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOFQxNjo0NzoxN1rOIcA4xA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yOVQwOToyNzo1M1rOIcb24g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjI0NTU3Mg==", "bodyText": "Maybe keeping the math with the comments we had before would be better.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r566245572", "createdAt": "2021-01-28T16:47:17Z", "author": {"login": "blazember"}, "path": "hazelcast/src/test/java/com/hazelcast/map/EntryCostEstimatorTest.java", "diffHunk": "@@ -39,22 +39,29 @@\n         extends HazelcastTestSupport {\n \n     protected TestHazelcastInstanceFactory factory = createHazelcastInstanceFactory(2);\n-    // the JVM-independent portion of the cost of Integer key + Long value record is 104 bytes\n-    // (without taking into account 8 references to key, record and value objects)\n-    private static final int JVM_INDEPENDENT_ENTRY_COST_IN_BYTES = 100;\n-    // JVM-dependent total cost of entry\n-    private static final int ENTRY_COST_IN_BYTES = JVM_INDEPENDENT_ENTRY_COST_IN_BYTES + 8 * REFERENCE_COST_IN_BYTES;\n+\n+    public static final int ENTRY_COST_IN_BYTES = getExpectedCostInBytes();\n+\n+    private static int getExpectedCostInBytes() {\n+        if (JVMUtil.is32bitJVM() && JVMUtil.isCompressedOops()) {\n+            return 140;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dfbcd8e2f8ba2f3f84c850080a1d6df991f817a9"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjY4NzQ1OA==", "bodyText": "The math is highly dependent to internals and this makes it hard to express correctly after refactorings/changes. I found the values here by logging entry costs, this seemed easy to me.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r566687458", "createdAt": "2021-01-29T09:27:53Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/test/java/com/hazelcast/map/EntryCostEstimatorTest.java", "diffHunk": "@@ -39,22 +39,29 @@\n         extends HazelcastTestSupport {\n \n     protected TestHazelcastInstanceFactory factory = createHazelcastInstanceFactory(2);\n-    // the JVM-independent portion of the cost of Integer key + Long value record is 104 bytes\n-    // (without taking into account 8 references to key, record and value objects)\n-    private static final int JVM_INDEPENDENT_ENTRY_COST_IN_BYTES = 100;\n-    // JVM-dependent total cost of entry\n-    private static final int ENTRY_COST_IN_BYTES = JVM_INDEPENDENT_ENTRY_COST_IN_BYTES + 8 * REFERENCE_COST_IN_BYTES;\n+\n+    public static final int ENTRY_COST_IN_BYTES = getExpectedCostInBytes();\n+\n+    private static int getExpectedCostInBytes() {\n+        if (JVMUtil.is32bitJVM() && JVMUtil.isCompressedOops()) {\n+            return 140;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjI0NTU3Mg=="}, "originalCommit": {"oid": "dfbcd8e2f8ba2f3f84c850080a1d6df991f817a9"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4NzUwMzg4OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/ExpirationTimeSetter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMToyNjo0OFrOIe9k_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wNFQwODowODoyNFrOIfnMuA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTMzNzA4Ng==", "bodyText": "In which conditions operationTTLMillis is negative?", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r569337086", "createdAt": "2021-02-03T11:26:48Z", "author": {"login": "petrpleshachkov"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/ExpirationTimeSetter.java", "diffHunk": "@@ -115,51 +48,41 @@ public static void setExpirationTimes(Record record, long operationTTLMillis,\n      * @param mapConfig          used to get configured TTL\n      * @return TTL value in millis to set to record\n      */\n-    private static long pickTTLMillis(long operationTTLMillis, MapConfig mapConfig) {\n-        // if user set operationTTLMillis when calling operation, use it\n-        if (operationTTLMillis > 0) {\n-            return checkedTime(operationTTLMillis);\n+    public static long pickTTLMillis(long operationTTLMillis, MapConfig mapConfig) {\n+        if (operationTTLMillis < 0 && mapConfig.getTimeToLiveSeconds() == 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ad19b6d763861a7b1f704c6b43da775c985a23c"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDAxOTAwMA==", "bodyText": "it is negative for regular put", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r570019000", "createdAt": "2021-02-04T08:08:24Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/ExpirationTimeSetter.java", "diffHunk": "@@ -115,51 +48,41 @@ public static void setExpirationTimes(Record record, long operationTTLMillis,\n      * @param mapConfig          used to get configured TTL\n      * @return TTL value in millis to set to record\n      */\n-    private static long pickTTLMillis(long operationTTLMillis, MapConfig mapConfig) {\n-        // if user set operationTTLMillis when calling operation, use it\n-        if (operationTTLMillis > 0) {\n-            return checkedTime(operationTTLMillis);\n+    public static long pickTTLMillis(long operationTTLMillis, MapConfig mapConfig) {\n+        if (operationTTLMillis < 0 && mapConfig.getTimeToLiveSeconds() == 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTMzNzA4Ng=="}, "originalCommit": {"oid": "4ad19b6d763861a7b1f704c6b43da775c985a23c"}, "originalPosition": 111}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4NzU5MDk4OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/operation/PutIfAbsentOperation.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMTo0OTo1MFrOIe-ajQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wNFQwODowOTozMFrOIfnPQA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTM1MDc5Nw==", "bodyText": "Not sure that I understood this change. Can you please elaborate a bit?", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r569350797", "createdAt": "2021-02-03T11:49:50Z", "author": {"login": "petrpleshachkov"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/operation/PutIfAbsentOperation.java", "diffHunk": "@@ -63,7 +63,7 @@ public Object getResponse() {\n \n     @Override\n     public boolean shouldBackup() {\n-        return successful && recordStore.getRecord(dataKey) != null;\n+        return successful && super.shouldBackup();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ad19b6d763861a7b1f704c6b43da775c985a23c"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDAxOTY0OA==", "bodyText": "called super's backup-condition since they both same.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r570019648", "createdAt": "2021-02-04T08:09:30Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/operation/PutIfAbsentOperation.java", "diffHunk": "@@ -63,7 +63,7 @@ public Object getResponse() {\n \n     @Override\n     public boolean shouldBackup() {\n-        return successful && recordStore.getRecord(dataKey) != null;\n+        return successful && super.shouldBackup();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTM1MDc5Nw=="}, "originalCommit": {"oid": "4ad19b6d763861a7b1f704c6b43da775c985a23c"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4NzU5NjQzOnYy", "diffSide": "LEFT", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/proxy/MapProxySupport.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMTo1MToxMFrOIe-dug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wNFQwODoxMToyNVrOIfnTmw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTM1MTYxMA==", "bodyText": "Why we're not considering this case anymore?", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r569351610", "createdAt": "2021-02-03T11:51:10Z", "author": {"login": "petrpleshachkov"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/proxy/MapProxySupport.java", "diffHunk": "@@ -1314,9 +1313,6 @@ public void addIndex(IndexConfig indexConfig) {\n \n     @Override\n     public LocalMapStats getLocalMapStats() {\n-        if (!mapConfig.isStatisticsEnabled()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ad19b6d763861a7b1f704c6b43da775c985a23c"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDAyMDc2Mw==", "bodyText": "Independent of it is enabled or not-enabled, we always collect record-store-level stats and no point to hide this.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r570020763", "createdAt": "2021-02-04T08:11:25Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/proxy/MapProxySupport.java", "diffHunk": "@@ -1314,9 +1313,6 @@ public void addIndex(IndexConfig indexConfig) {\n \n     @Override\n     public LocalMapStats getLocalMapStats() {\n-        if (!mapConfig.isStatisticsEnabled()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTM1MTYxMA=="}, "originalCommit": {"oid": "4ad19b6d763861a7b1f704c6b43da775c985a23c"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4NzYwMTY2OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/query/PartitionScanRunner.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMTo1MjoyOFrOIe-gtw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wNFQwODoxMjowMlrOIfnUuQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTM1MjM3NQ==", "bodyText": "We have metadata store only in HD case. Will it work in the on-heap scenario?", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r569352375", "createdAt": "2021-02-03T11:52:28Z", "author": {"login": "petrpleshachkov"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/query/PartitionScanRunner.java", "diffHunk": "@@ -101,7 +100,7 @@ public void accept(Data key, Record record) {\n \n                 queryEntry.init(ss, key, value, extractors);\n                 queryEntry.setRecord(record);\n-                queryEntry.setMetadata(PartitionScanRunner.this.getMetadataFromRecord(recordStore, key, record));\n+                queryEntry.setMetadata(recordStore.getMetadataStore().get(key));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ad19b6d763861a7b1f704c6b43da775c985a23c"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDAyMTA0OQ==", "bodyText": "For now, we also store HD metadata on heap, so there should be no issue with this.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r570021049", "createdAt": "2021-02-04T08:12:02Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/query/PartitionScanRunner.java", "diffHunk": "@@ -101,7 +100,7 @@ public void accept(Data key, Record record) {\n \n                 queryEntry.init(ss, key, value, extractors);\n                 queryEntry.setRecord(record);\n-                queryEntry.setMetadata(PartitionScanRunner.this.getMetadataFromRecord(recordStore, key, record));\n+                queryEntry.setMetadata(recordStore.getMetadataStore().get(key));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTM1MjM3NQ=="}, "originalCommit": {"oid": "4ad19b6d763861a7b1f704c6b43da775c985a23c"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4NzY4NDQ5OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/Record.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMjoxNDo0MVrOIe_SeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wNFQwODoyMzo0OFrOIfnu9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTM2NTExMw==", "bodyText": "We replace long with int here. Is int enough?", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r569365113", "createdAt": "2021-02-03T12:14:41Z", "author": {"login": "petrpleshachkov"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/Record.java", "diffHunk": "@@ -66,9 +65,9 @@\n      */\n     long getCost();\n \n-    long getVersion();\n+    int getVersion();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ad19b6d763861a7b1f704c6b43da775c985a23c"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDAyNzc2Ng==", "bodyText": "it should be ok. Reasoning: if version is updated in every millisecond, it will take nearly ~50 days to hit the same value.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r570027766", "createdAt": "2021-02-04T08:23:48Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/Record.java", "diffHunk": "@@ -66,9 +65,9 @@\n      */\n     long getCost();\n \n-    long getVersion();\n+    int getVersion();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTM2NTExMw=="}, "originalCommit": {"oid": "4ad19b6d763861a7b1f704c6b43da775c985a23c"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4NzY4ODc3OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/RecordReaderWriter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMjoxNTo0NlrOIe_VCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wNFQwODoxNTozMlrOIfncQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTM2NTc2OA==", "bodyText": "Is it for backward compatibility?", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r569365768", "createdAt": "2021-02-03T12:15:46Z", "author": {"login": "petrpleshachkov"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/RecordReaderWriter.java", "diffHunk": "@@ -16,78 +16,165 @@\n \n package com.hazelcast.map.impl.record;\n \n+import com.hazelcast.internal.serialization.Data;\n+import com.hazelcast.map.impl.recordstore.expiry.ExpiryMetadata;\n import com.hazelcast.nio.ObjectDataInput;\n import com.hazelcast.nio.ObjectDataOutput;\n-import com.hazelcast.internal.serialization.Data;\n \n import java.io.IOException;\n \n import static com.hazelcast.internal.nio.IOUtil.readData;\n import static com.hazelcast.internal.nio.IOUtil.writeData;\n+import static com.hazelcast.map.impl.record.Record.UNSET;\n \n /**\n  * Used when reading and writing records\n  * for backup and replication operations\n  */\n public enum RecordReaderWriter {\n+    // RU_COMPAT_4_1\n+    // Remove enum DATA_RECORD_READER_WRITER in 4.3\n     DATA_RECORD_READER_WRITER(TypeId.DATA_RECORD_TYPE_ID) {\n         @Override\n-        void writeRecord(ObjectDataOutput out,\n-                         Record record, Data dataValue) throws IOException {\n+        void writeRecord(ObjectDataOutput out, Record record, Data dataValue,\n+                         ExpiryMetadata expiryMetadata) throws IOException {\n             writeData(out, dataValue);\n-            out.writeInt(record.getRawTtl());\n-            out.writeInt(record.getRawMaxIdle());\n-            out.writeInt(record.getRawCreationTime());\n-            out.writeInt(record.getRawLastAccessTime());\n-            out.writeInt(record.getRawLastUpdateTime());\n+            out.writeInt(expiryMetadata.getRawTtl());\n+            out.writeInt(expiryMetadata.getRawMaxIdle());\n+            out.writeInt(UNSET);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ad19b6d763861a7b1f704c6b43da775c985a23c"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDAyMjk3OA==", "bodyText": "Good point, i have updated this part and have removed value UNSET. If cluster version is 4.1, we need to create records that remote server can meaningfully understand, to have this, i have updated RecordFactorys, now it is creating 4.1 friendly records.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r570022978", "createdAt": "2021-02-04T08:15:32Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/record/RecordReaderWriter.java", "diffHunk": "@@ -16,78 +16,165 @@\n \n package com.hazelcast.map.impl.record;\n \n+import com.hazelcast.internal.serialization.Data;\n+import com.hazelcast.map.impl.recordstore.expiry.ExpiryMetadata;\n import com.hazelcast.nio.ObjectDataInput;\n import com.hazelcast.nio.ObjectDataOutput;\n-import com.hazelcast.internal.serialization.Data;\n \n import java.io.IOException;\n \n import static com.hazelcast.internal.nio.IOUtil.readData;\n import static com.hazelcast.internal.nio.IOUtil.writeData;\n+import static com.hazelcast.map.impl.record.Record.UNSET;\n \n /**\n  * Used when reading and writing records\n  * for backup and replication operations\n  */\n public enum RecordReaderWriter {\n+    // RU_COMPAT_4_1\n+    // Remove enum DATA_RECORD_READER_WRITER in 4.3\n     DATA_RECORD_READER_WRITER(TypeId.DATA_RECORD_TYPE_ID) {\n         @Override\n-        void writeRecord(ObjectDataOutput out,\n-                         Record record, Data dataValue) throws IOException {\n+        void writeRecord(ObjectDataOutput out, Record record, Data dataValue,\n+                         ExpiryMetadata expiryMetadata) throws IOException {\n             writeData(out, dataValue);\n-            out.writeInt(record.getRawTtl());\n-            out.writeInt(record.getRawMaxIdle());\n-            out.writeInt(record.getRawCreationTime());\n-            out.writeInt(record.getRawLastAccessTime());\n-            out.writeInt(record.getRawLastUpdateTime());\n+            out.writeInt(expiryMetadata.getRawTtl());\n+            out.writeInt(expiryMetadata.getRawMaxIdle());\n+            out.writeInt(UNSET);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTM2NTc2OA=="}, "originalCommit": {"oid": "4ad19b6d763861a7b1f704c6b43da775c985a23c"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4ODA3MDYxOnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/recordstore/expiry/ExpiryReason.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMzo0NzozOFrOIfC8-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wNFQwODoxNTozN1rOIfncbw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQyNTE0Nw==", "bodyText": "Please add Javadoc", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r569425147", "createdAt": "2021-02-03T13:47:38Z", "author": {"login": "petrpleshachkov"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/recordstore/expiry/ExpiryReason.java", "diffHunk": "@@ -0,0 +1,23 @@\n+/*\n+ * Copyright (c) 2008-2021, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.map.impl.recordstore.expiry;\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ad19b6d763861a7b1f704c6b43da775c985a23c"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDAyMzAyMw==", "bodyText": "done.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r570023023", "createdAt": "2021-02-04T08:15:37Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/recordstore/expiry/ExpiryReason.java", "diffHunk": "@@ -0,0 +1,23 @@\n+/*\n+ * Copyright (c) 2008-2021, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.map.impl.recordstore.expiry;\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQyNTE0Nw=="}, "originalCommit": {"oid": "4ad19b6d763861a7b1f704c6b43da775c985a23c"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU4ODA5NDA0OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/recordstore/expiry/ExpirySystem.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wM1QxMzo1MjozOFrOIfDLBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wNFQwODoxNzowOFrOIfnf1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQyODc0MA==", "bodyText": "What if the iterator has not next element?", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r569428740", "createdAt": "2021-02-03T13:52:38Z", "author": {"login": "petrpleshachkov"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/recordstore/expiry/ExpirySystem.java", "diffHunk": "@@ -0,0 +1,360 @@\n+/*\n+ * Copyright (c) 2008-2021, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.map.impl.recordstore.expiry;\n+\n+import com.hazelcast.config.MapConfig;\n+import com.hazelcast.internal.eviction.ClearExpiredRecordsTask;\n+import com.hazelcast.internal.eviction.ExpiredKey;\n+import com.hazelcast.internal.nearcache.impl.invalidation.InvalidationQueue;\n+import com.hazelcast.internal.serialization.Data;\n+import com.hazelcast.internal.util.MapUtil;\n+import com.hazelcast.logging.ILogger;\n+import com.hazelcast.map.impl.ExpirationTimeSetter;\n+import com.hazelcast.map.impl.MapContainer;\n+import com.hazelcast.map.impl.MapServiceContext;\n+import com.hazelcast.map.impl.eviction.Evictor;\n+import com.hazelcast.map.impl.recordstore.RecordStore;\n+import com.hazelcast.spi.impl.NodeEngine;\n+import com.hazelcast.spi.properties.ClusterProperty;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.hazelcast.internal.util.ToHeapDataConverter.toHeapData;\n+import static com.hazelcast.map.impl.ExpirationTimeSetter.pickMaxIdleMillis;\n+import static com.hazelcast.map.impl.ExpirationTimeSetter.pickTTLMillis;\n+import static com.hazelcast.map.impl.record.Record.UNSET;\n+import static java.util.concurrent.TimeUnit.NANOSECONDS;\n+\n+/**\n+ * This class has all logic to remove expired entries. Expiry reason\n+ * can be ttl or idleness. An instance of this class is created for\n+ * each {@link RecordStore} and it is always accessed by same single thread.\n+ */\n+public class ExpirySystem {\n+    private static final long DEFAULT_EXPIRED_KEY_SCAN_TIMEOUT_NANOS\n+            = TimeUnit.MILLISECONDS.toNanos(1);\n+    private static final String PROP_EXPIRED_KEY_SCAN_TIMEOUT_NANOS\n+            = \"hazelcast.internal.map.expired.key.scan.timeout.nanos\";\n+    private static final HazelcastProperty EXPIRED_KEY_SCAN_TIMEOUT_NANOS\n+            = new HazelcastProperty(PROP_EXPIRED_KEY_SCAN_TIMEOUT_NANOS,\n+            DEFAULT_EXPIRED_KEY_SCAN_TIMEOUT_NANOS, NANOSECONDS);\n+    private static final int ONE_HUNDRED_PERCENT = 100;\n+    private static final int MIN_SCANNABLE_ENTRY_COUNT = 100;\n+\n+    private final long expiryDelayMillis;\n+    private final long expiredKeyScanTimeoutNanos;\n+    private final boolean canPrimaryDriveExpiration;\n+    private final ILogger logger;\n+    private final RecordStore recordStore;\n+    private final MapContainer mapContainer;\n+    private final MapServiceContext mapServiceContext;\n+    private final ClearExpiredRecordsTask clearExpiredRecordsTask;\n+    private final InvalidationQueue<ExpiredKey> expiredKeys = new InvalidationQueue<>();\n+\n+    private Iterator<Map.Entry<Data, ExpiryMetadata>> cachedExpirationIterator;\n+    private Map<Data, ExpiryMetadata> expireTimeByKey;\n+\n+    public ExpirySystem(RecordStore recordStore,\n+                        MapContainer mapContainer,\n+                        MapServiceContext mapServiceContext) {\n+        this.recordStore = recordStore;\n+        this.clearExpiredRecordsTask = mapServiceContext.getExpirationManager().getTask();\n+        NodeEngine nodeEngine = mapServiceContext.getNodeEngine();\n+        this.logger = nodeEngine.getLogger(getClass());\n+        HazelcastProperties hazelcastProperties = nodeEngine.getProperties();\n+        this.expiryDelayMillis = hazelcastProperties.getMillis(ClusterProperty.MAP_EXPIRY_DELAY_SECONDS);\n+        this.mapContainer = mapContainer;\n+        this.mapServiceContext = mapServiceContext;\n+        this.canPrimaryDriveExpiration = mapServiceContext.getClearExpiredRecordsTask().canPrimaryDriveExpiration();\n+        this.expiredKeyScanTimeoutNanos = nodeEngine.getProperties().getNanos(EXPIRED_KEY_SCAN_TIMEOUT_NANOS);\n+    }\n+\n+    public boolean isEmpty() {\n+        return MapUtil.isNullOrEmpty(expireTimeByKey);\n+    }\n+\n+    // this method is overridden\n+    protected Map<Data, ExpiryMetadata> createExpiryTimeByKeyMap() {\n+        // Only one thread can access this class but we\n+        // used CHM here, because its iterator doesn't\n+        // throw ConcurrentModificationException.\n+        return new ConcurrentHashMap<>();\n+    }\n+\n+    // this method is overridden\n+    public void clear() {\n+        Map<Data, ExpiryMetadata> map = getOrCreateExpireTimeByKeyMap(false);\n+        map.clear();\n+    }\n+\n+    protected Map<Data, ExpiryMetadata> getOrCreateExpireTimeByKeyMap(boolean createIfAbsent) {\n+        if (expireTimeByKey != null) {\n+            return expireTimeByKey;\n+        }\n+\n+        if (createIfAbsent) {\n+            expireTimeByKey = createExpiryTimeByKeyMap();\n+            return expireTimeByKey;\n+        }\n+\n+        return Collections.emptyMap();\n+    }\n+\n+    // this method is overridden\n+    protected ExpiryMetadata createExpiryMetadata(long ttlMillis, long maxIdleMillis, long expirationTime) {\n+        return new ExpiryMetadataImpl(ttlMillis, maxIdleMillis, expirationTime);\n+    }\n+\n+    public void addKeyIfExpirable(Data key, long ttl, long maxIdle, long expiryTime, long now) {\n+        if (expiryTime <= 0) {\n+            MapConfig mapConfig = mapContainer.getMapConfig();\n+            long ttlMillis = pickTTLMillis(ttl, mapConfig);\n+            long maxIdleMillis = pickMaxIdleMillis(maxIdle, mapConfig);\n+            long expirationTime = ExpirationTimeSetter.calculateExpirationTime(ttlMillis, maxIdleMillis, now);\n+            addExpirableKey(key, ttlMillis, maxIdleMillis, expirationTime);\n+        } else {\n+            addExpirableKey(key, ttl, maxIdle, expiryTime);\n+        }\n+    }\n+\n+    private void addExpirableKey(Data key, long ttlMillis, long maxIdleMillis, long expirationTime) {\n+        if (expirationTime == Long.MAX_VALUE) {\n+            Map<Data, ExpiryMetadata> map = getOrCreateExpireTimeByKeyMap(false);\n+            if (!map.isEmpty()) {\n+                Data nativeKey = recordStore.getStorage().toBackingDataKeyFormat(key);\n+                callRemove(nativeKey, expireTimeByKey);\n+            }\n+            return;\n+        }\n+\n+        Map<Data, ExpiryMetadata> expireTimeByKey = getOrCreateExpireTimeByKeyMap(true);\n+        ExpiryMetadata expiryMetadata = expireTimeByKey.get(key);\n+        if (expiryMetadata == null) {\n+            expiryMetadata = createExpiryMetadata(ttlMillis, maxIdleMillis, expirationTime);\n+            Data nativeKey = recordStore.getStorage().toBackingDataKeyFormat(key);\n+            expireTimeByKey.put(nativeKey, expiryMetadata);\n+        } else {\n+            expiryMetadata.setTtl(ttlMillis)\n+                    .setMaxIdle(maxIdleMillis)\n+                    .setExpirationTime(expirationTime);\n+        }\n+\n+        mapServiceContext.getExpirationManager().scheduleExpirationTask();\n+    }\n+\n+    public long calculateExpirationTime(long ttl, long maxIdle, long now) {\n+        MapConfig mapConfig = mapContainer.getMapConfig();\n+        long ttlMillis = pickTTLMillis(ttl, mapConfig);\n+        long maxIdleMillis = pickMaxIdleMillis(maxIdle, mapConfig);\n+        return ExpirationTimeSetter.calculateExpirationTime(ttlMillis, maxIdleMillis, now);\n+    }\n+\n+    public void removeKeyFromExpirySystem(Data key) {\n+        Map<Data, ExpiryMetadata> expireTimeByKey = getOrCreateExpireTimeByKeyMap(false);\n+        if (expireTimeByKey.isEmpty()) {\n+            return;\n+        }\n+        callRemove(key, expireTimeByKey);\n+    }\n+\n+    public void extendExpiryTime(Data dataKey, long now) {\n+        if (isEmpty()) {\n+            return;\n+        }\n+\n+        Map<Data, ExpiryMetadata> expireTimeByKey = getOrCreateExpireTimeByKeyMap(false);\n+        if (expireTimeByKey.isEmpty()) {\n+            return;\n+        }\n+\n+        ExpiryMetadata expiryMetadata = getExpiryMetadataForExpiryCheck(dataKey, expireTimeByKey);\n+        if (expiryMetadata == null\n+                || expiryMetadata.getMaxIdle() == Long.MAX_VALUE) {\n+            return;\n+        }\n+\n+        long expirationTime = ExpirationTimeSetter.calculateExpirationTime(expiryMetadata.getTtl(),\n+                expiryMetadata.getMaxIdle(), now);\n+        expiryMetadata.setExpirationTime(expirationTime);\n+    }\n+\n+    public ExpiryReason hasExpired(Data key, long now, boolean backup) {\n+        Map<Data, ExpiryMetadata> expireTimeByKey = getOrCreateExpireTimeByKeyMap(false);\n+        if (expireTimeByKey.isEmpty()) {\n+            return ExpiryReason.NOT_EXPIRED;\n+        }\n+        ExpiryMetadata expiryMetadata = getExpiryMetadataForExpiryCheck(key, expireTimeByKey);\n+        return hasExpired(expiryMetadata, now, backup);\n+    }\n+\n+    private ExpiryReason hasExpired(ExpiryMetadata expiryMetadata, long now, boolean backup) {\n+        if (expiryMetadata == null) {\n+            return ExpiryReason.NOT_EXPIRED;\n+        }\n+\n+        long nextExpirationTime = backup\n+                ? expiryMetadata.getExpirationTime() + expiryDelayMillis\n+                : expiryMetadata.getExpirationTime();\n+\n+        if (nextExpirationTime > now) {\n+            return ExpiryReason.NOT_EXPIRED;\n+        }\n+\n+        ExpiryReason expiryReason = expiryMetadata.getTtl() > expiryMetadata.getMaxIdle()\n+                ? ExpiryReason.IDLENESS : ExpiryReason.TTL;\n+        if (backup && canPrimaryDriveExpiration\n+                && expiryReason == ExpiryReason.IDLENESS) {\n+            return ExpiryReason.NOT_EXPIRED;\n+        }\n+        return expiryReason;\n+    }\n+\n+    public InvalidationQueue<ExpiredKey> getExpiredKeys() {\n+        return expiredKeys;\n+    }\n+\n+    @Nonnull\n+    public ExpiryMetadata getExpiredMetadata(Data key) {\n+        ExpiryMetadata expiryMetadata = getOrCreateExpireTimeByKeyMap(false).get(key);\n+        return expiryMetadata != null ? expiryMetadata : ExpiryMetadata.NULL;\n+    }\n+\n+    @SuppressWarnings(\"checkstyle:magicnumber\")\n+    public void evictExpiredEntries(int percentage, long now, boolean backup) {\n+        Map<Data, ExpiryMetadata> expireTimeByKey = getOrCreateExpireTimeByKeyMap(false);\n+        if (expireTimeByKey.isEmpty()) {\n+            return;\n+        }\n+\n+        // Find max scannable key count\n+        int expirableKeysMapSize = expireTimeByKey.size();\n+        int keyCountInPercentage = (int) (1D * expirableKeysMapSize * percentage / ONE_HUNDRED_PERCENT);\n+        int maxScannableKeyCount = Math.max(MIN_SCANNABLE_ENTRY_COUNT, keyCountInPercentage);\n+\n+        scanAndEvictExpiredKeys(maxScannableKeyCount, now, backup);\n+\n+        accumulateOrSendExpiredKey(null);\n+    }\n+\n+    /**\n+     * Get cachedExpirationIterator or init it if it has no next entry.\n+     */\n+    private Iterator<Map.Entry<Data, ExpiryMetadata>> getOrInitCachedIterator() {\n+        if (cachedExpirationIterator == null || !cachedExpirationIterator.hasNext()) {\n+            cachedExpirationIterator = initIteratorOf(expireTimeByKey);\n+        }\n+\n+        return cachedExpirationIterator;\n+    }\n+\n+    private void scanAndEvictExpiredKeys(int maxScannableKeyCount, long now, boolean backup) {\n+        // Scan to find expired keys.\n+        long scanLoopStartNanos = System.nanoTime();\n+        List expiredKeyExpiryReasonList = new ArrayList<>();\n+        int scannedKeyCount = 0;\n+        int expiredKeyCount = 0;\n+        do {\n+            Map.Entry<Data, ExpiryMetadata> entry = getOrInitCachedIterator().next();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ad19b6d763861a7b1f704c6b43da775c985a23c"}, "originalPosition": 280}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDAyMzg5NQ==", "bodyText": "If map is empty, we return immediately before coming that line, so there should be no problem.", "url": "https://github.com/hazelcast/hazelcast/pull/17977#discussion_r570023895", "createdAt": "2021-02-04T08:17:08Z", "author": {"login": "ahmetmircik"}, "path": "hazelcast/src/main/java/com/hazelcast/map/impl/recordstore/expiry/ExpirySystem.java", "diffHunk": "@@ -0,0 +1,360 @@\n+/*\n+ * Copyright (c) 2008-2021, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.map.impl.recordstore.expiry;\n+\n+import com.hazelcast.config.MapConfig;\n+import com.hazelcast.internal.eviction.ClearExpiredRecordsTask;\n+import com.hazelcast.internal.eviction.ExpiredKey;\n+import com.hazelcast.internal.nearcache.impl.invalidation.InvalidationQueue;\n+import com.hazelcast.internal.serialization.Data;\n+import com.hazelcast.internal.util.MapUtil;\n+import com.hazelcast.logging.ILogger;\n+import com.hazelcast.map.impl.ExpirationTimeSetter;\n+import com.hazelcast.map.impl.MapContainer;\n+import com.hazelcast.map.impl.MapServiceContext;\n+import com.hazelcast.map.impl.eviction.Evictor;\n+import com.hazelcast.map.impl.recordstore.RecordStore;\n+import com.hazelcast.spi.impl.NodeEngine;\n+import com.hazelcast.spi.properties.ClusterProperty;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.hazelcast.internal.util.ToHeapDataConverter.toHeapData;\n+import static com.hazelcast.map.impl.ExpirationTimeSetter.pickMaxIdleMillis;\n+import static com.hazelcast.map.impl.ExpirationTimeSetter.pickTTLMillis;\n+import static com.hazelcast.map.impl.record.Record.UNSET;\n+import static java.util.concurrent.TimeUnit.NANOSECONDS;\n+\n+/**\n+ * This class has all logic to remove expired entries. Expiry reason\n+ * can be ttl or idleness. An instance of this class is created for\n+ * each {@link RecordStore} and it is always accessed by same single thread.\n+ */\n+public class ExpirySystem {\n+    private static final long DEFAULT_EXPIRED_KEY_SCAN_TIMEOUT_NANOS\n+            = TimeUnit.MILLISECONDS.toNanos(1);\n+    private static final String PROP_EXPIRED_KEY_SCAN_TIMEOUT_NANOS\n+            = \"hazelcast.internal.map.expired.key.scan.timeout.nanos\";\n+    private static final HazelcastProperty EXPIRED_KEY_SCAN_TIMEOUT_NANOS\n+            = new HazelcastProperty(PROP_EXPIRED_KEY_SCAN_TIMEOUT_NANOS,\n+            DEFAULT_EXPIRED_KEY_SCAN_TIMEOUT_NANOS, NANOSECONDS);\n+    private static final int ONE_HUNDRED_PERCENT = 100;\n+    private static final int MIN_SCANNABLE_ENTRY_COUNT = 100;\n+\n+    private final long expiryDelayMillis;\n+    private final long expiredKeyScanTimeoutNanos;\n+    private final boolean canPrimaryDriveExpiration;\n+    private final ILogger logger;\n+    private final RecordStore recordStore;\n+    private final MapContainer mapContainer;\n+    private final MapServiceContext mapServiceContext;\n+    private final ClearExpiredRecordsTask clearExpiredRecordsTask;\n+    private final InvalidationQueue<ExpiredKey> expiredKeys = new InvalidationQueue<>();\n+\n+    private Iterator<Map.Entry<Data, ExpiryMetadata>> cachedExpirationIterator;\n+    private Map<Data, ExpiryMetadata> expireTimeByKey;\n+\n+    public ExpirySystem(RecordStore recordStore,\n+                        MapContainer mapContainer,\n+                        MapServiceContext mapServiceContext) {\n+        this.recordStore = recordStore;\n+        this.clearExpiredRecordsTask = mapServiceContext.getExpirationManager().getTask();\n+        NodeEngine nodeEngine = mapServiceContext.getNodeEngine();\n+        this.logger = nodeEngine.getLogger(getClass());\n+        HazelcastProperties hazelcastProperties = nodeEngine.getProperties();\n+        this.expiryDelayMillis = hazelcastProperties.getMillis(ClusterProperty.MAP_EXPIRY_DELAY_SECONDS);\n+        this.mapContainer = mapContainer;\n+        this.mapServiceContext = mapServiceContext;\n+        this.canPrimaryDriveExpiration = mapServiceContext.getClearExpiredRecordsTask().canPrimaryDriveExpiration();\n+        this.expiredKeyScanTimeoutNanos = nodeEngine.getProperties().getNanos(EXPIRED_KEY_SCAN_TIMEOUT_NANOS);\n+    }\n+\n+    public boolean isEmpty() {\n+        return MapUtil.isNullOrEmpty(expireTimeByKey);\n+    }\n+\n+    // this method is overridden\n+    protected Map<Data, ExpiryMetadata> createExpiryTimeByKeyMap() {\n+        // Only one thread can access this class but we\n+        // used CHM here, because its iterator doesn't\n+        // throw ConcurrentModificationException.\n+        return new ConcurrentHashMap<>();\n+    }\n+\n+    // this method is overridden\n+    public void clear() {\n+        Map<Data, ExpiryMetadata> map = getOrCreateExpireTimeByKeyMap(false);\n+        map.clear();\n+    }\n+\n+    protected Map<Data, ExpiryMetadata> getOrCreateExpireTimeByKeyMap(boolean createIfAbsent) {\n+        if (expireTimeByKey != null) {\n+            return expireTimeByKey;\n+        }\n+\n+        if (createIfAbsent) {\n+            expireTimeByKey = createExpiryTimeByKeyMap();\n+            return expireTimeByKey;\n+        }\n+\n+        return Collections.emptyMap();\n+    }\n+\n+    // this method is overridden\n+    protected ExpiryMetadata createExpiryMetadata(long ttlMillis, long maxIdleMillis, long expirationTime) {\n+        return new ExpiryMetadataImpl(ttlMillis, maxIdleMillis, expirationTime);\n+    }\n+\n+    public void addKeyIfExpirable(Data key, long ttl, long maxIdle, long expiryTime, long now) {\n+        if (expiryTime <= 0) {\n+            MapConfig mapConfig = mapContainer.getMapConfig();\n+            long ttlMillis = pickTTLMillis(ttl, mapConfig);\n+            long maxIdleMillis = pickMaxIdleMillis(maxIdle, mapConfig);\n+            long expirationTime = ExpirationTimeSetter.calculateExpirationTime(ttlMillis, maxIdleMillis, now);\n+            addExpirableKey(key, ttlMillis, maxIdleMillis, expirationTime);\n+        } else {\n+            addExpirableKey(key, ttl, maxIdle, expiryTime);\n+        }\n+    }\n+\n+    private void addExpirableKey(Data key, long ttlMillis, long maxIdleMillis, long expirationTime) {\n+        if (expirationTime == Long.MAX_VALUE) {\n+            Map<Data, ExpiryMetadata> map = getOrCreateExpireTimeByKeyMap(false);\n+            if (!map.isEmpty()) {\n+                Data nativeKey = recordStore.getStorage().toBackingDataKeyFormat(key);\n+                callRemove(nativeKey, expireTimeByKey);\n+            }\n+            return;\n+        }\n+\n+        Map<Data, ExpiryMetadata> expireTimeByKey = getOrCreateExpireTimeByKeyMap(true);\n+        ExpiryMetadata expiryMetadata = expireTimeByKey.get(key);\n+        if (expiryMetadata == null) {\n+            expiryMetadata = createExpiryMetadata(ttlMillis, maxIdleMillis, expirationTime);\n+            Data nativeKey = recordStore.getStorage().toBackingDataKeyFormat(key);\n+            expireTimeByKey.put(nativeKey, expiryMetadata);\n+        } else {\n+            expiryMetadata.setTtl(ttlMillis)\n+                    .setMaxIdle(maxIdleMillis)\n+                    .setExpirationTime(expirationTime);\n+        }\n+\n+        mapServiceContext.getExpirationManager().scheduleExpirationTask();\n+    }\n+\n+    public long calculateExpirationTime(long ttl, long maxIdle, long now) {\n+        MapConfig mapConfig = mapContainer.getMapConfig();\n+        long ttlMillis = pickTTLMillis(ttl, mapConfig);\n+        long maxIdleMillis = pickMaxIdleMillis(maxIdle, mapConfig);\n+        return ExpirationTimeSetter.calculateExpirationTime(ttlMillis, maxIdleMillis, now);\n+    }\n+\n+    public void removeKeyFromExpirySystem(Data key) {\n+        Map<Data, ExpiryMetadata> expireTimeByKey = getOrCreateExpireTimeByKeyMap(false);\n+        if (expireTimeByKey.isEmpty()) {\n+            return;\n+        }\n+        callRemove(key, expireTimeByKey);\n+    }\n+\n+    public void extendExpiryTime(Data dataKey, long now) {\n+        if (isEmpty()) {\n+            return;\n+        }\n+\n+        Map<Data, ExpiryMetadata> expireTimeByKey = getOrCreateExpireTimeByKeyMap(false);\n+        if (expireTimeByKey.isEmpty()) {\n+            return;\n+        }\n+\n+        ExpiryMetadata expiryMetadata = getExpiryMetadataForExpiryCheck(dataKey, expireTimeByKey);\n+        if (expiryMetadata == null\n+                || expiryMetadata.getMaxIdle() == Long.MAX_VALUE) {\n+            return;\n+        }\n+\n+        long expirationTime = ExpirationTimeSetter.calculateExpirationTime(expiryMetadata.getTtl(),\n+                expiryMetadata.getMaxIdle(), now);\n+        expiryMetadata.setExpirationTime(expirationTime);\n+    }\n+\n+    public ExpiryReason hasExpired(Data key, long now, boolean backup) {\n+        Map<Data, ExpiryMetadata> expireTimeByKey = getOrCreateExpireTimeByKeyMap(false);\n+        if (expireTimeByKey.isEmpty()) {\n+            return ExpiryReason.NOT_EXPIRED;\n+        }\n+        ExpiryMetadata expiryMetadata = getExpiryMetadataForExpiryCheck(key, expireTimeByKey);\n+        return hasExpired(expiryMetadata, now, backup);\n+    }\n+\n+    private ExpiryReason hasExpired(ExpiryMetadata expiryMetadata, long now, boolean backup) {\n+        if (expiryMetadata == null) {\n+            return ExpiryReason.NOT_EXPIRED;\n+        }\n+\n+        long nextExpirationTime = backup\n+                ? expiryMetadata.getExpirationTime() + expiryDelayMillis\n+                : expiryMetadata.getExpirationTime();\n+\n+        if (nextExpirationTime > now) {\n+            return ExpiryReason.NOT_EXPIRED;\n+        }\n+\n+        ExpiryReason expiryReason = expiryMetadata.getTtl() > expiryMetadata.getMaxIdle()\n+                ? ExpiryReason.IDLENESS : ExpiryReason.TTL;\n+        if (backup && canPrimaryDriveExpiration\n+                && expiryReason == ExpiryReason.IDLENESS) {\n+            return ExpiryReason.NOT_EXPIRED;\n+        }\n+        return expiryReason;\n+    }\n+\n+    public InvalidationQueue<ExpiredKey> getExpiredKeys() {\n+        return expiredKeys;\n+    }\n+\n+    @Nonnull\n+    public ExpiryMetadata getExpiredMetadata(Data key) {\n+        ExpiryMetadata expiryMetadata = getOrCreateExpireTimeByKeyMap(false).get(key);\n+        return expiryMetadata != null ? expiryMetadata : ExpiryMetadata.NULL;\n+    }\n+\n+    @SuppressWarnings(\"checkstyle:magicnumber\")\n+    public void evictExpiredEntries(int percentage, long now, boolean backup) {\n+        Map<Data, ExpiryMetadata> expireTimeByKey = getOrCreateExpireTimeByKeyMap(false);\n+        if (expireTimeByKey.isEmpty()) {\n+            return;\n+        }\n+\n+        // Find max scannable key count\n+        int expirableKeysMapSize = expireTimeByKey.size();\n+        int keyCountInPercentage = (int) (1D * expirableKeysMapSize * percentage / ONE_HUNDRED_PERCENT);\n+        int maxScannableKeyCount = Math.max(MIN_SCANNABLE_ENTRY_COUNT, keyCountInPercentage);\n+\n+        scanAndEvictExpiredKeys(maxScannableKeyCount, now, backup);\n+\n+        accumulateOrSendExpiredKey(null);\n+    }\n+\n+    /**\n+     * Get cachedExpirationIterator or init it if it has no next entry.\n+     */\n+    private Iterator<Map.Entry<Data, ExpiryMetadata>> getOrInitCachedIterator() {\n+        if (cachedExpirationIterator == null || !cachedExpirationIterator.hasNext()) {\n+            cachedExpirationIterator = initIteratorOf(expireTimeByKey);\n+        }\n+\n+        return cachedExpirationIterator;\n+    }\n+\n+    private void scanAndEvictExpiredKeys(int maxScannableKeyCount, long now, boolean backup) {\n+        // Scan to find expired keys.\n+        long scanLoopStartNanos = System.nanoTime();\n+        List expiredKeyExpiryReasonList = new ArrayList<>();\n+        int scannedKeyCount = 0;\n+        int expiredKeyCount = 0;\n+        do {\n+            Map.Entry<Data, ExpiryMetadata> entry = getOrInitCachedIterator().next();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTQyODc0MA=="}, "originalCommit": {"oid": "4ad19b6d763861a7b1f704c6b43da775c985a23c"}, "originalPosition": 280}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 25, "cost": 1, "resetAt": "2021-11-12T20:28:25Z"}}}