{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU4MjY4NDQz", "number": 17278, "reviewThreads": {"totalCount": 18, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQwOTozMDoyMlrOEVVcPw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNzoyOToxNVrOEXue7Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwODA2ODQ3OnYy", "diffSide": "RIGHT", "path": "docs/design/sql/06-plan-caching.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQwOTozMDoyMlrOG8Bxxg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxMDo1MDoxOVrOG8ucUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTU5Njg3MA==", "bodyText": "\"cache plans\" -> \"cached plans\"", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r465596870", "createdAt": "2020-08-05T09:30:22Z", "author": {"login": "viliam-durina"}, "path": "docs/design/sql/06-plan-caching.md", "diffHunk": "@@ -0,0 +1,129 @@\n+# Plan Caching\n+\n+## Overview\n+\n+Optimization of a query may take considerable time. In many applications, the set of queries is fixed. Therefore, the result of \n+query optimization could be cached and reused. This document explains the design of the plan cache in the Hazelcast Mustang SQL\n+engine.\n+\n+In section 1 we discuss the high-level requirements to the plan cache. In section 2 we describe the design. \n+\n+## 1. Requirements\n+\n+We assume that the result of query optimization is deterministic. That is, the same query plan is produced for the same set of \n+inputs. The inputs of the query optimizer are:\n+1. Catalog (schemas, tables, indexes)\n+1. The original query: query string, current schema, and parameters \n+1. Metadata\n+\n+### 1.1 Catalog\n+\n+A  catalog is a set of objects that may participate in query execution. The catalog is often referred to as \"schema\" in \n+the literature. We use the term \"catalog\" to disambiguate from the logical object containers, which are also called \"schemas\".\n+ \n+The catalog has three types of objects. *Schema* is a logical container for other objects. *Table* is a relation backed\n+by some physical storage, such as an `IMap`. *Index* is an additional data structure of a table that speeds up the execution \n+of queries. The catalog is used to resolve objects mentioned in the query and choose the proper access method. \n+\n+If the catalog is changed, the plan created earlier might become invalid. For example, if the table is dropped, the execution \n+of the plan will produce an error. If a new index is added, the optimizer may pick a better access path.\n+\n+The plan cache must be able to find and remove plans that have become invalid after changing the catalog. \n+\n+### 1.2 Query\n+\n+The query consists of the query string, the current schema, and parameters. Each of them may influence the optimization result.\n+\n+The current schema affects object resolution. For example, the query `SELECT * FROM map` may refer to `IMap` or `ReplicatedMap`\n+depending on the current schema (`partitioned` or `replicated`). \n+\n+Parameter values may alter statistics derivation and access path selection. For example, `SELECT ... FROM sales WHERE region=?`\n+may have different optimal plans for regions `EMEA` and `APAC`.  \n+ \n+The plan cache must use query content properly to ensure the correctness and efficiency of the query execution.  \n+ \n+### 1.3 Metadata\n+ \n+In the query optimization theory, metadata is external information that is used for optimization. Examples are \n+statistics, column uniqueness, data distribution, etc.\n+\n+In this document, we consider only partition distribution because this is the only metadata we use in our optimizer, \n+that is not part of the catalog, and that could change across query runs.\n+\n+Every plan is built for the specific partition distribution. That is, the distribution and participating members are saved \n+in the plan.\n+\n+The plan cache must be able to find and remove plans with obsolete partition distribution. \n+ \n+## 2. Design\n+\n+### 2.1 Plan Key\n+\n+The plan key is a key used to locate the cache plan. It should be possible to derive the key from the query before the \n+optimization phase. \n+\n+We use the following key:\n+```\n+PlanKey {\n+    List<List<String>> searchPaths;\n+    String sql;\n+}\n+```\n+`searchPaths` is the list of schemas that are used to resolve non-fully qualified objects during query parsing. Search paths\n+are created based on configured table resolvers, and the current schema. `sql` is a query string.   \n+\n+For the same catalog, two queries with the same search paths, and the same query string will always resolve the same objects. \n+On the contrary, the same query string may resolve different objects for different search paths, as shown in section 1.2. \n+Therefore, search paths must be part of the key.  \n+\n+### 2.2 Data Structure\n+\n+We use `ConcurrentHashMap` to store cache plans. `PlanKey` is a key, the plan is a value.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjMyODY1OA==", "bodyText": "Fixed", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r466328658", "createdAt": "2020-08-06T10:50:19Z", "author": {"login": "devozerov"}, "path": "docs/design/sql/06-plan-caching.md", "diffHunk": "@@ -0,0 +1,129 @@\n+# Plan Caching\n+\n+## Overview\n+\n+Optimization of a query may take considerable time. In many applications, the set of queries is fixed. Therefore, the result of \n+query optimization could be cached and reused. This document explains the design of the plan cache in the Hazelcast Mustang SQL\n+engine.\n+\n+In section 1 we discuss the high-level requirements to the plan cache. In section 2 we describe the design. \n+\n+## 1. Requirements\n+\n+We assume that the result of query optimization is deterministic. That is, the same query plan is produced for the same set of \n+inputs. The inputs of the query optimizer are:\n+1. Catalog (schemas, tables, indexes)\n+1. The original query: query string, current schema, and parameters \n+1. Metadata\n+\n+### 1.1 Catalog\n+\n+A  catalog is a set of objects that may participate in query execution. The catalog is often referred to as \"schema\" in \n+the literature. We use the term \"catalog\" to disambiguate from the logical object containers, which are also called \"schemas\".\n+ \n+The catalog has three types of objects. *Schema* is a logical container for other objects. *Table* is a relation backed\n+by some physical storage, such as an `IMap`. *Index* is an additional data structure of a table that speeds up the execution \n+of queries. The catalog is used to resolve objects mentioned in the query and choose the proper access method. \n+\n+If the catalog is changed, the plan created earlier might become invalid. For example, if the table is dropped, the execution \n+of the plan will produce an error. If a new index is added, the optimizer may pick a better access path.\n+\n+The plan cache must be able to find and remove plans that have become invalid after changing the catalog. \n+\n+### 1.2 Query\n+\n+The query consists of the query string, the current schema, and parameters. Each of them may influence the optimization result.\n+\n+The current schema affects object resolution. For example, the query `SELECT * FROM map` may refer to `IMap` or `ReplicatedMap`\n+depending on the current schema (`partitioned` or `replicated`). \n+\n+Parameter values may alter statistics derivation and access path selection. For example, `SELECT ... FROM sales WHERE region=?`\n+may have different optimal plans for regions `EMEA` and `APAC`.  \n+ \n+The plan cache must use query content properly to ensure the correctness and efficiency of the query execution.  \n+ \n+### 1.3 Metadata\n+ \n+In the query optimization theory, metadata is external information that is used for optimization. Examples are \n+statistics, column uniqueness, data distribution, etc.\n+\n+In this document, we consider only partition distribution because this is the only metadata we use in our optimizer, \n+that is not part of the catalog, and that could change across query runs.\n+\n+Every plan is built for the specific partition distribution. That is, the distribution and participating members are saved \n+in the plan.\n+\n+The plan cache must be able to find and remove plans with obsolete partition distribution. \n+ \n+## 2. Design\n+\n+### 2.1 Plan Key\n+\n+The plan key is a key used to locate the cache plan. It should be possible to derive the key from the query before the \n+optimization phase. \n+\n+We use the following key:\n+```\n+PlanKey {\n+    List<List<String>> searchPaths;\n+    String sql;\n+}\n+```\n+`searchPaths` is the list of schemas that are used to resolve non-fully qualified objects during query parsing. Search paths\n+are created based on configured table resolvers, and the current schema. `sql` is a query string.   \n+\n+For the same catalog, two queries with the same search paths, and the same query string will always resolve the same objects. \n+On the contrary, the same query string may resolve different objects for different search paths, as shown in section 1.2. \n+Therefore, search paths must be part of the key.  \n+\n+### 2.2 Data Structure\n+\n+We use `ConcurrentHashMap` to store cache plans. `PlanKey` is a key, the plan is a value.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTU5Njg3MA=="}, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 81}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwODYxNzQyOnYy", "diffSide": "RIGHT", "path": "docs/design/sql/06-plan-caching.md", "isResolved": true, "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMjoxNjozNlrOG8HEBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQxMDowNzo0OVrOG-IkwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY4MzQ2MA==", "bodyText": "Isn't the issue also with parameter types? For example consider this query:\nSELECT * FROM my_may WHERE field=?\nThe field type is a VARCHAR. If the parameter type is also varchar, we can use an index for field. If parameter type is numeric, field will be implicitly cast to a number and index cannot be used.", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r465683460", "createdAt": "2020-08-05T12:16:36Z", "author": {"login": "viliam-durina"}, "path": "docs/design/sql/06-plan-caching.md", "diffHunk": "@@ -0,0 +1,129 @@\n+# Plan Caching\n+\n+## Overview\n+\n+Optimization of a query may take considerable time. In many applications, the set of queries is fixed. Therefore, the result of \n+query optimization could be cached and reused. This document explains the design of the plan cache in the Hazelcast Mustang SQL\n+engine.\n+\n+In section 1 we discuss the high-level requirements to the plan cache. In section 2 we describe the design. \n+\n+## 1. Requirements\n+\n+We assume that the result of query optimization is deterministic. That is, the same query plan is produced for the same set of \n+inputs. The inputs of the query optimizer are:\n+1. Catalog (schemas, tables, indexes)\n+1. The original query: query string, current schema, and parameters \n+1. Metadata\n+\n+### 1.1 Catalog\n+\n+A  catalog is a set of objects that may participate in query execution. The catalog is often referred to as \"schema\" in \n+the literature. We use the term \"catalog\" to disambiguate from the logical object containers, which are also called \"schemas\".\n+ \n+The catalog has three types of objects. *Schema* is a logical container for other objects. *Table* is a relation backed\n+by some physical storage, such as an `IMap`. *Index* is an additional data structure of a table that speeds up the execution \n+of queries. The catalog is used to resolve objects mentioned in the query and choose the proper access method. \n+\n+If the catalog is changed, the plan created earlier might become invalid. For example, if the table is dropped, the execution \n+of the plan will produce an error. If a new index is added, the optimizer may pick a better access path.\n+\n+The plan cache must be able to find and remove plans that have become invalid after changing the catalog. \n+\n+### 1.2 Query\n+\n+The query consists of the query string, the current schema, and parameters. Each of them may influence the optimization result.\n+\n+The current schema affects object resolution. For example, the query `SELECT * FROM map` may refer to `IMap` or `ReplicatedMap`\n+depending on the current schema (`partitioned` or `replicated`). \n+\n+Parameter values may alter statistics derivation and access path selection. For example, `SELECT ... FROM sales WHERE region=?`\n+may have different optimal plans for regions `EMEA` and `APAC`.  \n+ \n+The plan cache must use query content properly to ensure the correctness and efficiency of the query execution.  \n+ \n+### 1.3 Metadata\n+ \n+In the query optimization theory, metadata is external information that is used for optimization. Examples are \n+statistics, column uniqueness, data distribution, etc.\n+\n+In this document, we consider only partition distribution because this is the only metadata we use in our optimizer, \n+that is not part of the catalog, and that could change across query runs.\n+\n+Every plan is built for the specific partition distribution. That is, the distribution and participating members are saved \n+in the plan.\n+\n+The plan cache must be able to find and remove plans with obsolete partition distribution. \n+ \n+## 2. Design\n+\n+### 2.1 Plan Key\n+\n+The plan key is a key used to locate the cache plan. It should be possible to derive the key from the query before the \n+optimization phase. \n+\n+We use the following key:\n+```\n+PlanKey {\n+    List<List<String>> searchPaths;\n+    String sql;\n+}\n+```\n+`searchPaths` is the list of schemas that are used to resolve non-fully qualified objects during query parsing. Search paths\n+are created based on configured table resolvers, and the current schema. `sql` is a query string.   \n+\n+For the same catalog, two queries with the same search paths, and the same query string will always resolve the same objects. \n+On the contrary, the same query string may resolve different objects for different search paths, as shown in section 1.2. \n+Therefore, search paths must be part of the key.  \n+\n+### 2.2 Data Structure\n+\n+We use `ConcurrentHashMap` to store cache plans. `PlanKey` is a key, the plan is a value.\n+ \n+### 2.3 Maximum Size and Plan Eviction\n+\n+The maximum size of the cache is required to prevent out-of-memory if too many distinct queries are submitted.\n+\n+When a plan is added to the map, the map size is checked. If the map size is greater than the maximum size, some plans are \n+evicted. \n+\n+Eviction is synchronous because the asynchronous variant is prone to out-of-memory. We assume that for the most workloads \n+evictions should be rare. \n+\n+We use the LRU (least recently used) approach to find the plans to evict. Whenever a plan is accessed, it's `lastUsed` field is \n+updated with the current time. During the eviction, plans are sorted by their `lastUsed` values, and the least recently used\n+plans are removed.   \n+\n+### 2.4 Reacting to Catalog and Partition Distribution Changes\n+\n+If a catalog or partition distribution is changed, some plans must be invalidated. There are two different ways to achieve \n+this: `push` and `pull`.\n+\n+With the `push` approach, the plan cache is notified about a change, from the relevant component. E.g., if an index is created,\n+then the map service notifies the plan cache about the change. The advantage of this solution is that any change is reflected \n+in the plan cache immediately. However, this approach increases coupling, because many components (map service, \n+replicated map service, partition service) now have to be aware of the SQL subsystem. This approach also requires complex\n+synchronization between query optimizer, plan cache, and dependent components, to ensure that no stale plan is ever cached.\n+\n+With the `pull` approach, the SQL subsystem queries other components periodically, collects the changes, and invalidates \n+affected plans. The advantage of this approach is simplicity. No synchronization or changes to other components are needed. \n+Invalid plans are guaranteed to be removed eventually. The downside is that invalid plans might be active for some time after\n+the change has occurred.\n+\n+We choose the `pull` approach due to simplicity and sufficient guarantees. The background worker reconstructs the catalog \n+periodically, and verifies that existing plans are compatible with the current catalog and partition distribution. \n+\n+To counter the problem with outdated plans, we add a special `invalidatePlan` flag to `QueryException`. If an invalid plan\n+is used, an exception with this flag will be thrown at some point. When the initiator member receives an exception with \n+this flag, the plan is invalidated. \n+\n+Note that currently, users will have to re-execute the query in this case. In future versions, we will add a transparent\n+query retry, so that invalid plans will not be visible to users.    \n+\n+### 2.5 No Use of Parameters\n+\n+In other databases, parameters are used for plan caching, because the same queries with different parameters may have different \n+optimal plans.\n+\n+We do not use parameters at the moment, because we do not have statistics. We may change this decision in the future when \n+statistics are available.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 129}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjMyOTI2MQ==", "bodyText": "Parameter types are fixed in the plan. They are resolved based on the context. E.g. in this specific example the expected parameter type will be VARCHAR. Before the query is executed, the real parameters are converted to expected types.", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r466329261", "createdAt": "2020-08-06T10:51:38Z", "author": {"login": "devozerov"}, "path": "docs/design/sql/06-plan-caching.md", "diffHunk": "@@ -0,0 +1,129 @@\n+# Plan Caching\n+\n+## Overview\n+\n+Optimization of a query may take considerable time. In many applications, the set of queries is fixed. Therefore, the result of \n+query optimization could be cached and reused. This document explains the design of the plan cache in the Hazelcast Mustang SQL\n+engine.\n+\n+In section 1 we discuss the high-level requirements to the plan cache. In section 2 we describe the design. \n+\n+## 1. Requirements\n+\n+We assume that the result of query optimization is deterministic. That is, the same query plan is produced for the same set of \n+inputs. The inputs of the query optimizer are:\n+1. Catalog (schemas, tables, indexes)\n+1. The original query: query string, current schema, and parameters \n+1. Metadata\n+\n+### 1.1 Catalog\n+\n+A  catalog is a set of objects that may participate in query execution. The catalog is often referred to as \"schema\" in \n+the literature. We use the term \"catalog\" to disambiguate from the logical object containers, which are also called \"schemas\".\n+ \n+The catalog has three types of objects. *Schema* is a logical container for other objects. *Table* is a relation backed\n+by some physical storage, such as an `IMap`. *Index* is an additional data structure of a table that speeds up the execution \n+of queries. The catalog is used to resolve objects mentioned in the query and choose the proper access method. \n+\n+If the catalog is changed, the plan created earlier might become invalid. For example, if the table is dropped, the execution \n+of the plan will produce an error. If a new index is added, the optimizer may pick a better access path.\n+\n+The plan cache must be able to find and remove plans that have become invalid after changing the catalog. \n+\n+### 1.2 Query\n+\n+The query consists of the query string, the current schema, and parameters. Each of them may influence the optimization result.\n+\n+The current schema affects object resolution. For example, the query `SELECT * FROM map` may refer to `IMap` or `ReplicatedMap`\n+depending on the current schema (`partitioned` or `replicated`). \n+\n+Parameter values may alter statistics derivation and access path selection. For example, `SELECT ... FROM sales WHERE region=?`\n+may have different optimal plans for regions `EMEA` and `APAC`.  \n+ \n+The plan cache must use query content properly to ensure the correctness and efficiency of the query execution.  \n+ \n+### 1.3 Metadata\n+ \n+In the query optimization theory, metadata is external information that is used for optimization. Examples are \n+statistics, column uniqueness, data distribution, etc.\n+\n+In this document, we consider only partition distribution because this is the only metadata we use in our optimizer, \n+that is not part of the catalog, and that could change across query runs.\n+\n+Every plan is built for the specific partition distribution. That is, the distribution and participating members are saved \n+in the plan.\n+\n+The plan cache must be able to find and remove plans with obsolete partition distribution. \n+ \n+## 2. Design\n+\n+### 2.1 Plan Key\n+\n+The plan key is a key used to locate the cache plan. It should be possible to derive the key from the query before the \n+optimization phase. \n+\n+We use the following key:\n+```\n+PlanKey {\n+    List<List<String>> searchPaths;\n+    String sql;\n+}\n+```\n+`searchPaths` is the list of schemas that are used to resolve non-fully qualified objects during query parsing. Search paths\n+are created based on configured table resolvers, and the current schema. `sql` is a query string.   \n+\n+For the same catalog, two queries with the same search paths, and the same query string will always resolve the same objects. \n+On the contrary, the same query string may resolve different objects for different search paths, as shown in section 1.2. \n+Therefore, search paths must be part of the key.  \n+\n+### 2.2 Data Structure\n+\n+We use `ConcurrentHashMap` to store cache plans. `PlanKey` is a key, the plan is a value.\n+ \n+### 2.3 Maximum Size and Plan Eviction\n+\n+The maximum size of the cache is required to prevent out-of-memory if too many distinct queries are submitted.\n+\n+When a plan is added to the map, the map size is checked. If the map size is greater than the maximum size, some plans are \n+evicted. \n+\n+Eviction is synchronous because the asynchronous variant is prone to out-of-memory. We assume that for the most workloads \n+evictions should be rare. \n+\n+We use the LRU (least recently used) approach to find the plans to evict. Whenever a plan is accessed, it's `lastUsed` field is \n+updated with the current time. During the eviction, plans are sorted by their `lastUsed` values, and the least recently used\n+plans are removed.   \n+\n+### 2.4 Reacting to Catalog and Partition Distribution Changes\n+\n+If a catalog or partition distribution is changed, some plans must be invalidated. There are two different ways to achieve \n+this: `push` and `pull`.\n+\n+With the `push` approach, the plan cache is notified about a change, from the relevant component. E.g., if an index is created,\n+then the map service notifies the plan cache about the change. The advantage of this solution is that any change is reflected \n+in the plan cache immediately. However, this approach increases coupling, because many components (map service, \n+replicated map service, partition service) now have to be aware of the SQL subsystem. This approach also requires complex\n+synchronization between query optimizer, plan cache, and dependent components, to ensure that no stale plan is ever cached.\n+\n+With the `pull` approach, the SQL subsystem queries other components periodically, collects the changes, and invalidates \n+affected plans. The advantage of this approach is simplicity. No synchronization or changes to other components are needed. \n+Invalid plans are guaranteed to be removed eventually. The downside is that invalid plans might be active for some time after\n+the change has occurred.\n+\n+We choose the `pull` approach due to simplicity and sufficient guarantees. The background worker reconstructs the catalog \n+periodically, and verifies that existing plans are compatible with the current catalog and partition distribution. \n+\n+To counter the problem with outdated plans, we add a special `invalidatePlan` flag to `QueryException`. If an invalid plan\n+is used, an exception with this flag will be thrown at some point. When the initiator member receives an exception with \n+this flag, the plan is invalidated. \n+\n+Note that currently, users will have to re-execute the query in this case. In future versions, we will add a transparent\n+query retry, so that invalid plans will not be visible to users.    \n+\n+### 2.5 No Use of Parameters\n+\n+In other databases, parameters are used for plan caching, because the same queries with different parameters may have different \n+optimal plans.\n+\n+We do not use parameters at the moment, because we do not have statistics. We may change this decision in the future when \n+statistics are available.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY4MzQ2MA=="}, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 129}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM4ODc1NA==", "bodyText": "Wanted to test it but found out that parameters are not yet supported. Are they in scope for 4.1? I guess so, they are in the public API.\nI wrote this test:\n@Test\npublic void test() {\n    TestHazelcastInstanceFactory factory = new TestHazelcastInstanceFactory();\n    HazelcastInstance inst = factory.newHazelcastInstance();\n    IMap<Object, Object> map = inst.getMap(\"map\");\n    map.put(\"05\", \"05\");\n    map.put(\"5\", \"5\");\n\n    executeAndPrint(inst, \"select __key from map where this=?\", \"05\");\n    executeAndPrint(inst, \"select __key from map where this=?\", 5);\n    ((SqlServiceImpl) inst.getSql()).getPlanCache().clear();\n    System.out.println(\"plan cache invalidated\");\n    executeAndPrint(inst, \"select __key from map where this=?\", 5);\n}\n\nprivate void executeAndPrint(HazelcastInstance inst, String sql, Object ... params) {\n    System.out.println(\"params: \" + Arrays.stream(params)\n                                          .map(p -> p.getClass().getSimpleName() + \" \" + p)\n                                          .collect(Collectors.joining(\",\")));\n    for (SqlRow r : inst.getSql().query(sql, params)) {\n        System.out.println(r);\n    }\n    System.out.println(\"----\");\n}\nI expect this output:\nparams: String 05\n[__key VARCHAR=05]\nparams: Integer 5\n[__key VARCHAR=5]\nplan cache invalidated\nparams: Integer 5\n[__key VARCHAR=05]\n[__key VARCHAR=5]\n\nThat is, the first query will have VARCHAR parameter and will get cached, including the parameter type. The second query will have INT parameter. The cached plan will be used, the INT will be casted to VARCHAR and used in the filter. After invalidating the plan cache, new plan will be created, this time with INT parameter. The field will be casted to INT and this time, both entries will be returned.\nMaybe the key in the plan cache should also include parameter types.", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r466388754", "createdAt": "2020-08-06T12:51:52Z", "author": {"login": "viliam-durina"}, "path": "docs/design/sql/06-plan-caching.md", "diffHunk": "@@ -0,0 +1,129 @@\n+# Plan Caching\n+\n+## Overview\n+\n+Optimization of a query may take considerable time. In many applications, the set of queries is fixed. Therefore, the result of \n+query optimization could be cached and reused. This document explains the design of the plan cache in the Hazelcast Mustang SQL\n+engine.\n+\n+In section 1 we discuss the high-level requirements to the plan cache. In section 2 we describe the design. \n+\n+## 1. Requirements\n+\n+We assume that the result of query optimization is deterministic. That is, the same query plan is produced for the same set of \n+inputs. The inputs of the query optimizer are:\n+1. Catalog (schemas, tables, indexes)\n+1. The original query: query string, current schema, and parameters \n+1. Metadata\n+\n+### 1.1 Catalog\n+\n+A  catalog is a set of objects that may participate in query execution. The catalog is often referred to as \"schema\" in \n+the literature. We use the term \"catalog\" to disambiguate from the logical object containers, which are also called \"schemas\".\n+ \n+The catalog has three types of objects. *Schema* is a logical container for other objects. *Table* is a relation backed\n+by some physical storage, such as an `IMap`. *Index* is an additional data structure of a table that speeds up the execution \n+of queries. The catalog is used to resolve objects mentioned in the query and choose the proper access method. \n+\n+If the catalog is changed, the plan created earlier might become invalid. For example, if the table is dropped, the execution \n+of the plan will produce an error. If a new index is added, the optimizer may pick a better access path.\n+\n+The plan cache must be able to find and remove plans that have become invalid after changing the catalog. \n+\n+### 1.2 Query\n+\n+The query consists of the query string, the current schema, and parameters. Each of them may influence the optimization result.\n+\n+The current schema affects object resolution. For example, the query `SELECT * FROM map` may refer to `IMap` or `ReplicatedMap`\n+depending on the current schema (`partitioned` or `replicated`). \n+\n+Parameter values may alter statistics derivation and access path selection. For example, `SELECT ... FROM sales WHERE region=?`\n+may have different optimal plans for regions `EMEA` and `APAC`.  \n+ \n+The plan cache must use query content properly to ensure the correctness and efficiency of the query execution.  \n+ \n+### 1.3 Metadata\n+ \n+In the query optimization theory, metadata is external information that is used for optimization. Examples are \n+statistics, column uniqueness, data distribution, etc.\n+\n+In this document, we consider only partition distribution because this is the only metadata we use in our optimizer, \n+that is not part of the catalog, and that could change across query runs.\n+\n+Every plan is built for the specific partition distribution. That is, the distribution and participating members are saved \n+in the plan.\n+\n+The plan cache must be able to find and remove plans with obsolete partition distribution. \n+ \n+## 2. Design\n+\n+### 2.1 Plan Key\n+\n+The plan key is a key used to locate the cache plan. It should be possible to derive the key from the query before the \n+optimization phase. \n+\n+We use the following key:\n+```\n+PlanKey {\n+    List<List<String>> searchPaths;\n+    String sql;\n+}\n+```\n+`searchPaths` is the list of schemas that are used to resolve non-fully qualified objects during query parsing. Search paths\n+are created based on configured table resolvers, and the current schema. `sql` is a query string.   \n+\n+For the same catalog, two queries with the same search paths, and the same query string will always resolve the same objects. \n+On the contrary, the same query string may resolve different objects for different search paths, as shown in section 1.2. \n+Therefore, search paths must be part of the key.  \n+\n+### 2.2 Data Structure\n+\n+We use `ConcurrentHashMap` to store cache plans. `PlanKey` is a key, the plan is a value.\n+ \n+### 2.3 Maximum Size and Plan Eviction\n+\n+The maximum size of the cache is required to prevent out-of-memory if too many distinct queries are submitted.\n+\n+When a plan is added to the map, the map size is checked. If the map size is greater than the maximum size, some plans are \n+evicted. \n+\n+Eviction is synchronous because the asynchronous variant is prone to out-of-memory. We assume that for the most workloads \n+evictions should be rare. \n+\n+We use the LRU (least recently used) approach to find the plans to evict. Whenever a plan is accessed, it's `lastUsed` field is \n+updated with the current time. During the eviction, plans are sorted by their `lastUsed` values, and the least recently used\n+plans are removed.   \n+\n+### 2.4 Reacting to Catalog and Partition Distribution Changes\n+\n+If a catalog or partition distribution is changed, some plans must be invalidated. There are two different ways to achieve \n+this: `push` and `pull`.\n+\n+With the `push` approach, the plan cache is notified about a change, from the relevant component. E.g., if an index is created,\n+then the map service notifies the plan cache about the change. The advantage of this solution is that any change is reflected \n+in the plan cache immediately. However, this approach increases coupling, because many components (map service, \n+replicated map service, partition service) now have to be aware of the SQL subsystem. This approach also requires complex\n+synchronization between query optimizer, plan cache, and dependent components, to ensure that no stale plan is ever cached.\n+\n+With the `pull` approach, the SQL subsystem queries other components periodically, collects the changes, and invalidates \n+affected plans. The advantage of this approach is simplicity. No synchronization or changes to other components are needed. \n+Invalid plans are guaranteed to be removed eventually. The downside is that invalid plans might be active for some time after\n+the change has occurred.\n+\n+We choose the `pull` approach due to simplicity and sufficient guarantees. The background worker reconstructs the catalog \n+periodically, and verifies that existing plans are compatible with the current catalog and partition distribution. \n+\n+To counter the problem with outdated plans, we add a special `invalidatePlan` flag to `QueryException`. If an invalid plan\n+is used, an exception with this flag will be thrown at some point. When the initiator member receives an exception with \n+this flag, the plan is invalidated. \n+\n+Note that currently, users will have to re-execute the query in this case. In future versions, we will add a transparent\n+query retry, so that invalid plans will not be visible to users.    \n+\n+### 2.5 No Use of Parameters\n+\n+In other databases, parameters are used for plan caching, because the same queries with different parameters may have different \n+optimal plans.\n+\n+We do not use parameters at the moment, because we do not have statistics. We may change this decision in the future when \n+statistics are available.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY4MzQ2MA=="}, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 129}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQzMDc2NQ==", "bodyText": "As explained above, parameter values do not participate in plan creation. Whatever parameter values are passed, the created plan will be the same.", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r466430765", "createdAt": "2020-08-06T13:55:56Z", "author": {"login": "devozerov"}, "path": "docs/design/sql/06-plan-caching.md", "diffHunk": "@@ -0,0 +1,129 @@\n+# Plan Caching\n+\n+## Overview\n+\n+Optimization of a query may take considerable time. In many applications, the set of queries is fixed. Therefore, the result of \n+query optimization could be cached and reused. This document explains the design of the plan cache in the Hazelcast Mustang SQL\n+engine.\n+\n+In section 1 we discuss the high-level requirements to the plan cache. In section 2 we describe the design. \n+\n+## 1. Requirements\n+\n+We assume that the result of query optimization is deterministic. That is, the same query plan is produced for the same set of \n+inputs. The inputs of the query optimizer are:\n+1. Catalog (schemas, tables, indexes)\n+1. The original query: query string, current schema, and parameters \n+1. Metadata\n+\n+### 1.1 Catalog\n+\n+A  catalog is a set of objects that may participate in query execution. The catalog is often referred to as \"schema\" in \n+the literature. We use the term \"catalog\" to disambiguate from the logical object containers, which are also called \"schemas\".\n+ \n+The catalog has three types of objects. *Schema* is a logical container for other objects. *Table* is a relation backed\n+by some physical storage, such as an `IMap`. *Index* is an additional data structure of a table that speeds up the execution \n+of queries. The catalog is used to resolve objects mentioned in the query and choose the proper access method. \n+\n+If the catalog is changed, the plan created earlier might become invalid. For example, if the table is dropped, the execution \n+of the plan will produce an error. If a new index is added, the optimizer may pick a better access path.\n+\n+The plan cache must be able to find and remove plans that have become invalid after changing the catalog. \n+\n+### 1.2 Query\n+\n+The query consists of the query string, the current schema, and parameters. Each of them may influence the optimization result.\n+\n+The current schema affects object resolution. For example, the query `SELECT * FROM map` may refer to `IMap` or `ReplicatedMap`\n+depending on the current schema (`partitioned` or `replicated`). \n+\n+Parameter values may alter statistics derivation and access path selection. For example, `SELECT ... FROM sales WHERE region=?`\n+may have different optimal plans for regions `EMEA` and `APAC`.  \n+ \n+The plan cache must use query content properly to ensure the correctness and efficiency of the query execution.  \n+ \n+### 1.3 Metadata\n+ \n+In the query optimization theory, metadata is external information that is used for optimization. Examples are \n+statistics, column uniqueness, data distribution, etc.\n+\n+In this document, we consider only partition distribution because this is the only metadata we use in our optimizer, \n+that is not part of the catalog, and that could change across query runs.\n+\n+Every plan is built for the specific partition distribution. That is, the distribution and participating members are saved \n+in the plan.\n+\n+The plan cache must be able to find and remove plans with obsolete partition distribution. \n+ \n+## 2. Design\n+\n+### 2.1 Plan Key\n+\n+The plan key is a key used to locate the cache plan. It should be possible to derive the key from the query before the \n+optimization phase. \n+\n+We use the following key:\n+```\n+PlanKey {\n+    List<List<String>> searchPaths;\n+    String sql;\n+}\n+```\n+`searchPaths` is the list of schemas that are used to resolve non-fully qualified objects during query parsing. Search paths\n+are created based on configured table resolvers, and the current schema. `sql` is a query string.   \n+\n+For the same catalog, two queries with the same search paths, and the same query string will always resolve the same objects. \n+On the contrary, the same query string may resolve different objects for different search paths, as shown in section 1.2. \n+Therefore, search paths must be part of the key.  \n+\n+### 2.2 Data Structure\n+\n+We use `ConcurrentHashMap` to store cache plans. `PlanKey` is a key, the plan is a value.\n+ \n+### 2.3 Maximum Size and Plan Eviction\n+\n+The maximum size of the cache is required to prevent out-of-memory if too many distinct queries are submitted.\n+\n+When a plan is added to the map, the map size is checked. If the map size is greater than the maximum size, some plans are \n+evicted. \n+\n+Eviction is synchronous because the asynchronous variant is prone to out-of-memory. We assume that for the most workloads \n+evictions should be rare. \n+\n+We use the LRU (least recently used) approach to find the plans to evict. Whenever a plan is accessed, it's `lastUsed` field is \n+updated with the current time. During the eviction, plans are sorted by their `lastUsed` values, and the least recently used\n+plans are removed.   \n+\n+### 2.4 Reacting to Catalog and Partition Distribution Changes\n+\n+If a catalog or partition distribution is changed, some plans must be invalidated. There are two different ways to achieve \n+this: `push` and `pull`.\n+\n+With the `push` approach, the plan cache is notified about a change, from the relevant component. E.g., if an index is created,\n+then the map service notifies the plan cache about the change. The advantage of this solution is that any change is reflected \n+in the plan cache immediately. However, this approach increases coupling, because many components (map service, \n+replicated map service, partition service) now have to be aware of the SQL subsystem. This approach also requires complex\n+synchronization between query optimizer, plan cache, and dependent components, to ensure that no stale plan is ever cached.\n+\n+With the `pull` approach, the SQL subsystem queries other components periodically, collects the changes, and invalidates \n+affected plans. The advantage of this approach is simplicity. No synchronization or changes to other components are needed. \n+Invalid plans are guaranteed to be removed eventually. The downside is that invalid plans might be active for some time after\n+the change has occurred.\n+\n+We choose the `pull` approach due to simplicity and sufficient guarantees. The background worker reconstructs the catalog \n+periodically, and verifies that existing plans are compatible with the current catalog and partition distribution. \n+\n+To counter the problem with outdated plans, we add a special `invalidatePlan` flag to `QueryException`. If an invalid plan\n+is used, an exception with this flag will be thrown at some point. When the initiator member receives an exception with \n+this flag, the plan is invalidated. \n+\n+Note that currently, users will have to re-execute the query in this case. In future versions, we will add a transparent\n+query retry, so that invalid plans will not be visible to users.    \n+\n+### 2.5 No Use of Parameters\n+\n+In other databases, parameters are used for plan caching, because the same queries with different parameters may have different \n+optimal plans.\n+\n+We do not use parameters at the moment, because we do not have statistics. We may change this decision in the future when \n+statistics are available.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY4MzQ2MA=="}, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 129}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjU3NjgyOQ==", "bodyText": "I tried it in the expressions PR and indeed it seems that the parameter is converted to a type based on the expression it appears in. This is really surprising to me. The consequence is that implicit conversion rules of SQL do not apply as in my example above: if you have a VARCHAR field and compare it to NUMBER parameter, the number parameter gets converted to VARCHAR and not the other way as would be the case if the number was a literal.\nThen I tried SELECT ? FROM map and got Illegal use of dynamic parameter - obviously. Also SELECT a FROM t WHERE f=? + ? throws Cannot apply '+' to arguments of type '<UNKNOWN> + <UNKNOWN>.\nIf this is the behavior of expressions, then this PR is correct, we don't need to store parameter types in plan cache key. But I think this behavior is not correct. Checked with PostgreSQL, parameter type is taken into account. You also can do SELECT ?. I don't have other DB at hand locally, but this fiddle with oracle suggests that oracle also takes the type of dynamic parameter into account: queries in PL/SQL blocks are converted to ones with parameters.\nAlso it is not as JDBC is designed. In JDBC you set the parameters in a typed way, using PreparedStatement.setInt(), setString() etc. I checked a few JDBC implementations, all but HSQLDB store the type used to set the parameter. Mysql even replaces the parameter with a literal.\ncc: @taburet", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r466576829", "createdAt": "2020-08-06T17:36:12Z", "author": {"login": "viliam-durina"}, "path": "docs/design/sql/06-plan-caching.md", "diffHunk": "@@ -0,0 +1,129 @@\n+# Plan Caching\n+\n+## Overview\n+\n+Optimization of a query may take considerable time. In many applications, the set of queries is fixed. Therefore, the result of \n+query optimization could be cached and reused. This document explains the design of the plan cache in the Hazelcast Mustang SQL\n+engine.\n+\n+In section 1 we discuss the high-level requirements to the plan cache. In section 2 we describe the design. \n+\n+## 1. Requirements\n+\n+We assume that the result of query optimization is deterministic. That is, the same query plan is produced for the same set of \n+inputs. The inputs of the query optimizer are:\n+1. Catalog (schemas, tables, indexes)\n+1. The original query: query string, current schema, and parameters \n+1. Metadata\n+\n+### 1.1 Catalog\n+\n+A  catalog is a set of objects that may participate in query execution. The catalog is often referred to as \"schema\" in \n+the literature. We use the term \"catalog\" to disambiguate from the logical object containers, which are also called \"schemas\".\n+ \n+The catalog has three types of objects. *Schema* is a logical container for other objects. *Table* is a relation backed\n+by some physical storage, such as an `IMap`. *Index* is an additional data structure of a table that speeds up the execution \n+of queries. The catalog is used to resolve objects mentioned in the query and choose the proper access method. \n+\n+If the catalog is changed, the plan created earlier might become invalid. For example, if the table is dropped, the execution \n+of the plan will produce an error. If a new index is added, the optimizer may pick a better access path.\n+\n+The plan cache must be able to find and remove plans that have become invalid after changing the catalog. \n+\n+### 1.2 Query\n+\n+The query consists of the query string, the current schema, and parameters. Each of them may influence the optimization result.\n+\n+The current schema affects object resolution. For example, the query `SELECT * FROM map` may refer to `IMap` or `ReplicatedMap`\n+depending on the current schema (`partitioned` or `replicated`). \n+\n+Parameter values may alter statistics derivation and access path selection. For example, `SELECT ... FROM sales WHERE region=?`\n+may have different optimal plans for regions `EMEA` and `APAC`.  \n+ \n+The plan cache must use query content properly to ensure the correctness and efficiency of the query execution.  \n+ \n+### 1.3 Metadata\n+ \n+In the query optimization theory, metadata is external information that is used for optimization. Examples are \n+statistics, column uniqueness, data distribution, etc.\n+\n+In this document, we consider only partition distribution because this is the only metadata we use in our optimizer, \n+that is not part of the catalog, and that could change across query runs.\n+\n+Every plan is built for the specific partition distribution. That is, the distribution and participating members are saved \n+in the plan.\n+\n+The plan cache must be able to find and remove plans with obsolete partition distribution. \n+ \n+## 2. Design\n+\n+### 2.1 Plan Key\n+\n+The plan key is a key used to locate the cache plan. It should be possible to derive the key from the query before the \n+optimization phase. \n+\n+We use the following key:\n+```\n+PlanKey {\n+    List<List<String>> searchPaths;\n+    String sql;\n+}\n+```\n+`searchPaths` is the list of schemas that are used to resolve non-fully qualified objects during query parsing. Search paths\n+are created based on configured table resolvers, and the current schema. `sql` is a query string.   \n+\n+For the same catalog, two queries with the same search paths, and the same query string will always resolve the same objects. \n+On the contrary, the same query string may resolve different objects for different search paths, as shown in section 1.2. \n+Therefore, search paths must be part of the key.  \n+\n+### 2.2 Data Structure\n+\n+We use `ConcurrentHashMap` to store cache plans. `PlanKey` is a key, the plan is a value.\n+ \n+### 2.3 Maximum Size and Plan Eviction\n+\n+The maximum size of the cache is required to prevent out-of-memory if too many distinct queries are submitted.\n+\n+When a plan is added to the map, the map size is checked. If the map size is greater than the maximum size, some plans are \n+evicted. \n+\n+Eviction is synchronous because the asynchronous variant is prone to out-of-memory. We assume that for the most workloads \n+evictions should be rare. \n+\n+We use the LRU (least recently used) approach to find the plans to evict. Whenever a plan is accessed, it's `lastUsed` field is \n+updated with the current time. During the eviction, plans are sorted by their `lastUsed` values, and the least recently used\n+plans are removed.   \n+\n+### 2.4 Reacting to Catalog and Partition Distribution Changes\n+\n+If a catalog or partition distribution is changed, some plans must be invalidated. There are two different ways to achieve \n+this: `push` and `pull`.\n+\n+With the `push` approach, the plan cache is notified about a change, from the relevant component. E.g., if an index is created,\n+then the map service notifies the plan cache about the change. The advantage of this solution is that any change is reflected \n+in the plan cache immediately. However, this approach increases coupling, because many components (map service, \n+replicated map service, partition service) now have to be aware of the SQL subsystem. This approach also requires complex\n+synchronization between query optimizer, plan cache, and dependent components, to ensure that no stale plan is ever cached.\n+\n+With the `pull` approach, the SQL subsystem queries other components periodically, collects the changes, and invalidates \n+affected plans. The advantage of this approach is simplicity. No synchronization or changes to other components are needed. \n+Invalid plans are guaranteed to be removed eventually. The downside is that invalid plans might be active for some time after\n+the change has occurred.\n+\n+We choose the `pull` approach due to simplicity and sufficient guarantees. The background worker reconstructs the catalog \n+periodically, and verifies that existing plans are compatible with the current catalog and partition distribution. \n+\n+To counter the problem with outdated plans, we add a special `invalidatePlan` flag to `QueryException`. If an invalid plan\n+is used, an exception with this flag will be thrown at some point. When the initiator member receives an exception with \n+this flag, the plan is invalidated. \n+\n+Note that currently, users will have to re-execute the query in this case. In future versions, we will add a transparent\n+query retry, so that invalid plans will not be visible to users.    \n+\n+### 2.5 No Use of Parameters\n+\n+In other databases, parameters are used for plan caching, because the same queries with different parameters may have different \n+optimal plans.\n+\n+We do not use parameters at the moment, because we do not have statistics. We may change this decision in the future when \n+statistics are available.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY4MzQ2MA=="}, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 129}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY0Nzg1NQ==", "bodyText": "Parameters are not used in planning for a reason - there will be too many different plans otherwise. We would like to avoid this complexity unless there is an obvious reason to go into it. There is no correct or wrong way of handling parameters wrt the ANSI standard. We are free to choose the way we find it convenient.\nIsolated usage of parameters (e.g. SELECT ? ..., or ? + ?) will work in future releases, there is an issue for this. Things like SELECT varchar + ? attempts to use the existing context to derive the result, the correct semantics is yet to be understood during beta, but, for example, assuming that the parameter is DECIMAL would be reasonable for the most cases. And the main thing - if the user is not satisfied with the result, he can always use CAST operator.\nRegarding JDBC - this is not really the case. This is not the user who defines parameter types. Parameter types are defined by the database before the actual values are provided. The database gives users information about expected parameter types through PreparedStatement.getParameterMetadata before they are actually set, and users use this information to invoke the proper setters.\nNevertheless, this doesn't mean that the JDBC result set metadata doesn't depend on actual parameters. For example, some databases (e.g. Postgres) may decide to use a special UNKNOWN type for parameter placeholder for the statement SELECT ?, and the result set metadata will be different for different parameter values. Other vendors may use fixed types assigned to parameters. None of these approaches violate ANSI SQL or JDBC to my knowledge.", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r466647855", "createdAt": "2020-08-06T19:48:16Z", "author": {"login": "devozerov"}, "path": "docs/design/sql/06-plan-caching.md", "diffHunk": "@@ -0,0 +1,129 @@\n+# Plan Caching\n+\n+## Overview\n+\n+Optimization of a query may take considerable time. In many applications, the set of queries is fixed. Therefore, the result of \n+query optimization could be cached and reused. This document explains the design of the plan cache in the Hazelcast Mustang SQL\n+engine.\n+\n+In section 1 we discuss the high-level requirements to the plan cache. In section 2 we describe the design. \n+\n+## 1. Requirements\n+\n+We assume that the result of query optimization is deterministic. That is, the same query plan is produced for the same set of \n+inputs. The inputs of the query optimizer are:\n+1. Catalog (schemas, tables, indexes)\n+1. The original query: query string, current schema, and parameters \n+1. Metadata\n+\n+### 1.1 Catalog\n+\n+A  catalog is a set of objects that may participate in query execution. The catalog is often referred to as \"schema\" in \n+the literature. We use the term \"catalog\" to disambiguate from the logical object containers, which are also called \"schemas\".\n+ \n+The catalog has three types of objects. *Schema* is a logical container for other objects. *Table* is a relation backed\n+by some physical storage, such as an `IMap`. *Index* is an additional data structure of a table that speeds up the execution \n+of queries. The catalog is used to resolve objects mentioned in the query and choose the proper access method. \n+\n+If the catalog is changed, the plan created earlier might become invalid. For example, if the table is dropped, the execution \n+of the plan will produce an error. If a new index is added, the optimizer may pick a better access path.\n+\n+The plan cache must be able to find and remove plans that have become invalid after changing the catalog. \n+\n+### 1.2 Query\n+\n+The query consists of the query string, the current schema, and parameters. Each of them may influence the optimization result.\n+\n+The current schema affects object resolution. For example, the query `SELECT * FROM map` may refer to `IMap` or `ReplicatedMap`\n+depending on the current schema (`partitioned` or `replicated`). \n+\n+Parameter values may alter statistics derivation and access path selection. For example, `SELECT ... FROM sales WHERE region=?`\n+may have different optimal plans for regions `EMEA` and `APAC`.  \n+ \n+The plan cache must use query content properly to ensure the correctness and efficiency of the query execution.  \n+ \n+### 1.3 Metadata\n+ \n+In the query optimization theory, metadata is external information that is used for optimization. Examples are \n+statistics, column uniqueness, data distribution, etc.\n+\n+In this document, we consider only partition distribution because this is the only metadata we use in our optimizer, \n+that is not part of the catalog, and that could change across query runs.\n+\n+Every plan is built for the specific partition distribution. That is, the distribution and participating members are saved \n+in the plan.\n+\n+The plan cache must be able to find and remove plans with obsolete partition distribution. \n+ \n+## 2. Design\n+\n+### 2.1 Plan Key\n+\n+The plan key is a key used to locate the cache plan. It should be possible to derive the key from the query before the \n+optimization phase. \n+\n+We use the following key:\n+```\n+PlanKey {\n+    List<List<String>> searchPaths;\n+    String sql;\n+}\n+```\n+`searchPaths` is the list of schemas that are used to resolve non-fully qualified objects during query parsing. Search paths\n+are created based on configured table resolvers, and the current schema. `sql` is a query string.   \n+\n+For the same catalog, two queries with the same search paths, and the same query string will always resolve the same objects. \n+On the contrary, the same query string may resolve different objects for different search paths, as shown in section 1.2. \n+Therefore, search paths must be part of the key.  \n+\n+### 2.2 Data Structure\n+\n+We use `ConcurrentHashMap` to store cache plans. `PlanKey` is a key, the plan is a value.\n+ \n+### 2.3 Maximum Size and Plan Eviction\n+\n+The maximum size of the cache is required to prevent out-of-memory if too many distinct queries are submitted.\n+\n+When a plan is added to the map, the map size is checked. If the map size is greater than the maximum size, some plans are \n+evicted. \n+\n+Eviction is synchronous because the asynchronous variant is prone to out-of-memory. We assume that for the most workloads \n+evictions should be rare. \n+\n+We use the LRU (least recently used) approach to find the plans to evict. Whenever a plan is accessed, it's `lastUsed` field is \n+updated with the current time. During the eviction, plans are sorted by their `lastUsed` values, and the least recently used\n+plans are removed.   \n+\n+### 2.4 Reacting to Catalog and Partition Distribution Changes\n+\n+If a catalog or partition distribution is changed, some plans must be invalidated. There are two different ways to achieve \n+this: `push` and `pull`.\n+\n+With the `push` approach, the plan cache is notified about a change, from the relevant component. E.g., if an index is created,\n+then the map service notifies the plan cache about the change. The advantage of this solution is that any change is reflected \n+in the plan cache immediately. However, this approach increases coupling, because many components (map service, \n+replicated map service, partition service) now have to be aware of the SQL subsystem. This approach also requires complex\n+synchronization between query optimizer, plan cache, and dependent components, to ensure that no stale plan is ever cached.\n+\n+With the `pull` approach, the SQL subsystem queries other components periodically, collects the changes, and invalidates \n+affected plans. The advantage of this approach is simplicity. No synchronization or changes to other components are needed. \n+Invalid plans are guaranteed to be removed eventually. The downside is that invalid plans might be active for some time after\n+the change has occurred.\n+\n+We choose the `pull` approach due to simplicity and sufficient guarantees. The background worker reconstructs the catalog \n+periodically, and verifies that existing plans are compatible with the current catalog and partition distribution. \n+\n+To counter the problem with outdated plans, we add a special `invalidatePlan` flag to `QueryException`. If an invalid plan\n+is used, an exception with this flag will be thrown at some point. When the initiator member receives an exception with \n+this flag, the plan is invalidated. \n+\n+Note that currently, users will have to re-execute the query in this case. In future versions, we will add a transparent\n+query retry, so that invalid plans will not be visible to users.    \n+\n+### 2.5 No Use of Parameters\n+\n+In other databases, parameters are used for plan caching, because the same queries with different parameters may have different \n+optimal plans.\n+\n+We do not use parameters at the moment, because we do not have statistics. We may change this decision in the future when \n+statistics are available.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY4MzQ2MA=="}, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 129}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg5OTA3Nw==", "bodyText": "Parameters are not used in planning for a reason - there will be too many different plans otherwise\n\nWe can cache the plan based just on the parameter type, not value. Then there won't be that many plans for each SQL string, one most of the time.\nWhile it's probably true that neither ANSI nor JDBC specify this detail, I still think we should consider using the type from the client in planning. As you see, the current approach opens many questions. It's the question whether a parameter is a drop-in replacement for a literal or not.", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r466899077", "createdAt": "2020-08-07T08:29:04Z", "author": {"login": "viliam-durina"}, "path": "docs/design/sql/06-plan-caching.md", "diffHunk": "@@ -0,0 +1,129 @@\n+# Plan Caching\n+\n+## Overview\n+\n+Optimization of a query may take considerable time. In many applications, the set of queries is fixed. Therefore, the result of \n+query optimization could be cached and reused. This document explains the design of the plan cache in the Hazelcast Mustang SQL\n+engine.\n+\n+In section 1 we discuss the high-level requirements to the plan cache. In section 2 we describe the design. \n+\n+## 1. Requirements\n+\n+We assume that the result of query optimization is deterministic. That is, the same query plan is produced for the same set of \n+inputs. The inputs of the query optimizer are:\n+1. Catalog (schemas, tables, indexes)\n+1. The original query: query string, current schema, and parameters \n+1. Metadata\n+\n+### 1.1 Catalog\n+\n+A  catalog is a set of objects that may participate in query execution. The catalog is often referred to as \"schema\" in \n+the literature. We use the term \"catalog\" to disambiguate from the logical object containers, which are also called \"schemas\".\n+ \n+The catalog has three types of objects. *Schema* is a logical container for other objects. *Table* is a relation backed\n+by some physical storage, such as an `IMap`. *Index* is an additional data structure of a table that speeds up the execution \n+of queries. The catalog is used to resolve objects mentioned in the query and choose the proper access method. \n+\n+If the catalog is changed, the plan created earlier might become invalid. For example, if the table is dropped, the execution \n+of the plan will produce an error. If a new index is added, the optimizer may pick a better access path.\n+\n+The plan cache must be able to find and remove plans that have become invalid after changing the catalog. \n+\n+### 1.2 Query\n+\n+The query consists of the query string, the current schema, and parameters. Each of them may influence the optimization result.\n+\n+The current schema affects object resolution. For example, the query `SELECT * FROM map` may refer to `IMap` or `ReplicatedMap`\n+depending on the current schema (`partitioned` or `replicated`). \n+\n+Parameter values may alter statistics derivation and access path selection. For example, `SELECT ... FROM sales WHERE region=?`\n+may have different optimal plans for regions `EMEA` and `APAC`.  \n+ \n+The plan cache must use query content properly to ensure the correctness and efficiency of the query execution.  \n+ \n+### 1.3 Metadata\n+ \n+In the query optimization theory, metadata is external information that is used for optimization. Examples are \n+statistics, column uniqueness, data distribution, etc.\n+\n+In this document, we consider only partition distribution because this is the only metadata we use in our optimizer, \n+that is not part of the catalog, and that could change across query runs.\n+\n+Every plan is built for the specific partition distribution. That is, the distribution and participating members are saved \n+in the plan.\n+\n+The plan cache must be able to find and remove plans with obsolete partition distribution. \n+ \n+## 2. Design\n+\n+### 2.1 Plan Key\n+\n+The plan key is a key used to locate the cache plan. It should be possible to derive the key from the query before the \n+optimization phase. \n+\n+We use the following key:\n+```\n+PlanKey {\n+    List<List<String>> searchPaths;\n+    String sql;\n+}\n+```\n+`searchPaths` is the list of schemas that are used to resolve non-fully qualified objects during query parsing. Search paths\n+are created based on configured table resolvers, and the current schema. `sql` is a query string.   \n+\n+For the same catalog, two queries with the same search paths, and the same query string will always resolve the same objects. \n+On the contrary, the same query string may resolve different objects for different search paths, as shown in section 1.2. \n+Therefore, search paths must be part of the key.  \n+\n+### 2.2 Data Structure\n+\n+We use `ConcurrentHashMap` to store cache plans. `PlanKey` is a key, the plan is a value.\n+ \n+### 2.3 Maximum Size and Plan Eviction\n+\n+The maximum size of the cache is required to prevent out-of-memory if too many distinct queries are submitted.\n+\n+When a plan is added to the map, the map size is checked. If the map size is greater than the maximum size, some plans are \n+evicted. \n+\n+Eviction is synchronous because the asynchronous variant is prone to out-of-memory. We assume that for the most workloads \n+evictions should be rare. \n+\n+We use the LRU (least recently used) approach to find the plans to evict. Whenever a plan is accessed, it's `lastUsed` field is \n+updated with the current time. During the eviction, plans are sorted by their `lastUsed` values, and the least recently used\n+plans are removed.   \n+\n+### 2.4 Reacting to Catalog and Partition Distribution Changes\n+\n+If a catalog or partition distribution is changed, some plans must be invalidated. There are two different ways to achieve \n+this: `push` and `pull`.\n+\n+With the `push` approach, the plan cache is notified about a change, from the relevant component. E.g., if an index is created,\n+then the map service notifies the plan cache about the change. The advantage of this solution is that any change is reflected \n+in the plan cache immediately. However, this approach increases coupling, because many components (map service, \n+replicated map service, partition service) now have to be aware of the SQL subsystem. This approach also requires complex\n+synchronization between query optimizer, plan cache, and dependent components, to ensure that no stale plan is ever cached.\n+\n+With the `pull` approach, the SQL subsystem queries other components periodically, collects the changes, and invalidates \n+affected plans. The advantage of this approach is simplicity. No synchronization or changes to other components are needed. \n+Invalid plans are guaranteed to be removed eventually. The downside is that invalid plans might be active for some time after\n+the change has occurred.\n+\n+We choose the `pull` approach due to simplicity and sufficient guarantees. The background worker reconstructs the catalog \n+periodically, and verifies that existing plans are compatible with the current catalog and partition distribution. \n+\n+To counter the problem with outdated plans, we add a special `invalidatePlan` flag to `QueryException`. If an invalid plan\n+is used, an exception with this flag will be thrown at some point. When the initiator member receives an exception with \n+this flag, the plan is invalidated. \n+\n+Note that currently, users will have to re-execute the query in this case. In future versions, we will add a transparent\n+query retry, so that invalid plans will not be visible to users.    \n+\n+### 2.5 No Use of Parameters\n+\n+In other databases, parameters are used for plan caching, because the same queries with different parameters may have different \n+optimal plans.\n+\n+We do not use parameters at the moment, because we do not have statistics. We may change this decision in the future when \n+statistics are available.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY4MzQ2MA=="}, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 129}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzgwNTM3Nw==", "bodyText": "I'm marking this as resolved as it's not related to this PR but rather to #17183", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r467805377", "createdAt": "2020-08-10T10:07:49Z", "author": {"login": "viliam-durina"}, "path": "docs/design/sql/06-plan-caching.md", "diffHunk": "@@ -0,0 +1,129 @@\n+# Plan Caching\n+\n+## Overview\n+\n+Optimization of a query may take considerable time. In many applications, the set of queries is fixed. Therefore, the result of \n+query optimization could be cached and reused. This document explains the design of the plan cache in the Hazelcast Mustang SQL\n+engine.\n+\n+In section 1 we discuss the high-level requirements to the plan cache. In section 2 we describe the design. \n+\n+## 1. Requirements\n+\n+We assume that the result of query optimization is deterministic. That is, the same query plan is produced for the same set of \n+inputs. The inputs of the query optimizer are:\n+1. Catalog (schemas, tables, indexes)\n+1. The original query: query string, current schema, and parameters \n+1. Metadata\n+\n+### 1.1 Catalog\n+\n+A  catalog is a set of objects that may participate in query execution. The catalog is often referred to as \"schema\" in \n+the literature. We use the term \"catalog\" to disambiguate from the logical object containers, which are also called \"schemas\".\n+ \n+The catalog has three types of objects. *Schema* is a logical container for other objects. *Table* is a relation backed\n+by some physical storage, such as an `IMap`. *Index* is an additional data structure of a table that speeds up the execution \n+of queries. The catalog is used to resolve objects mentioned in the query and choose the proper access method. \n+\n+If the catalog is changed, the plan created earlier might become invalid. For example, if the table is dropped, the execution \n+of the plan will produce an error. If a new index is added, the optimizer may pick a better access path.\n+\n+The plan cache must be able to find and remove plans that have become invalid after changing the catalog. \n+\n+### 1.2 Query\n+\n+The query consists of the query string, the current schema, and parameters. Each of them may influence the optimization result.\n+\n+The current schema affects object resolution. For example, the query `SELECT * FROM map` may refer to `IMap` or `ReplicatedMap`\n+depending on the current schema (`partitioned` or `replicated`). \n+\n+Parameter values may alter statistics derivation and access path selection. For example, `SELECT ... FROM sales WHERE region=?`\n+may have different optimal plans for regions `EMEA` and `APAC`.  \n+ \n+The plan cache must use query content properly to ensure the correctness and efficiency of the query execution.  \n+ \n+### 1.3 Metadata\n+ \n+In the query optimization theory, metadata is external information that is used for optimization. Examples are \n+statistics, column uniqueness, data distribution, etc.\n+\n+In this document, we consider only partition distribution because this is the only metadata we use in our optimizer, \n+that is not part of the catalog, and that could change across query runs.\n+\n+Every plan is built for the specific partition distribution. That is, the distribution and participating members are saved \n+in the plan.\n+\n+The plan cache must be able to find and remove plans with obsolete partition distribution. \n+ \n+## 2. Design\n+\n+### 2.1 Plan Key\n+\n+The plan key is a key used to locate the cache plan. It should be possible to derive the key from the query before the \n+optimization phase. \n+\n+We use the following key:\n+```\n+PlanKey {\n+    List<List<String>> searchPaths;\n+    String sql;\n+}\n+```\n+`searchPaths` is the list of schemas that are used to resolve non-fully qualified objects during query parsing. Search paths\n+are created based on configured table resolvers, and the current schema. `sql` is a query string.   \n+\n+For the same catalog, two queries with the same search paths, and the same query string will always resolve the same objects. \n+On the contrary, the same query string may resolve different objects for different search paths, as shown in section 1.2. \n+Therefore, search paths must be part of the key.  \n+\n+### 2.2 Data Structure\n+\n+We use `ConcurrentHashMap` to store cache plans. `PlanKey` is a key, the plan is a value.\n+ \n+### 2.3 Maximum Size and Plan Eviction\n+\n+The maximum size of the cache is required to prevent out-of-memory if too many distinct queries are submitted.\n+\n+When a plan is added to the map, the map size is checked. If the map size is greater than the maximum size, some plans are \n+evicted. \n+\n+Eviction is synchronous because the asynchronous variant is prone to out-of-memory. We assume that for the most workloads \n+evictions should be rare. \n+\n+We use the LRU (least recently used) approach to find the plans to evict. Whenever a plan is accessed, it's `lastUsed` field is \n+updated with the current time. During the eviction, plans are sorted by their `lastUsed` values, and the least recently used\n+plans are removed.   \n+\n+### 2.4 Reacting to Catalog and Partition Distribution Changes\n+\n+If a catalog or partition distribution is changed, some plans must be invalidated. There are two different ways to achieve \n+this: `push` and `pull`.\n+\n+With the `push` approach, the plan cache is notified about a change, from the relevant component. E.g., if an index is created,\n+then the map service notifies the plan cache about the change. The advantage of this solution is that any change is reflected \n+in the plan cache immediately. However, this approach increases coupling, because many components (map service, \n+replicated map service, partition service) now have to be aware of the SQL subsystem. This approach also requires complex\n+synchronization between query optimizer, plan cache, and dependent components, to ensure that no stale plan is ever cached.\n+\n+With the `pull` approach, the SQL subsystem queries other components periodically, collects the changes, and invalidates \n+affected plans. The advantage of this approach is simplicity. No synchronization or changes to other components are needed. \n+Invalid plans are guaranteed to be removed eventually. The downside is that invalid plans might be active for some time after\n+the change has occurred.\n+\n+We choose the `pull` approach due to simplicity and sufficient guarantees. The background worker reconstructs the catalog \n+periodically, and verifies that existing plans are compatible with the current catalog and partition distribution. \n+\n+To counter the problem with outdated plans, we add a special `invalidatePlan` flag to `QueryException`. If an invalid plan\n+is used, an exception with this flag will be thrown at some point. When the initiator member receives an exception with \n+this flag, the plan is invalidated. \n+\n+Note that currently, users will have to re-execute the query in this case. In future versions, we will add a transparent\n+query retry, so that invalid plans will not be visible to users.    \n+\n+### 2.5 No Use of Parameters\n+\n+In other databases, parameters are used for plan caching, because the same queries with different parameters may have different \n+optimal plans.\n+\n+We do not use parameters at the moment, because we do not have statistics. We may change this decision in the future when \n+statistics are available.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY4MzQ2MA=="}, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 129}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwODYyNTg1OnYy", "diffSide": "RIGHT", "path": "hazelcast-sql/.gitignore", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMjoxOToxN1rOG8HJLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxMDo0OToyNlrOG8uadg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY4NDc4MA==", "bodyText": "This file should not be here.", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r465684780", "createdAt": "2020-08-05T12:19:17Z", "author": {"login": "viliam-durina"}, "path": "hazelcast-sql/.gitignore", "diffHunk": "@@ -0,0 +1 @@\n+tpch/", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjMyODE4Mg==", "bodyText": "Removed", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r466328182", "createdAt": "2020-08-06T10:49:26Z", "author": {"login": "devozerov"}, "path": "hazelcast-sql/.gitignore", "diffHunk": "@@ -0,0 +1 @@\n+tpch/", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY4NDc4MA=="}, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwODcwNDA3OnYy", "diffSide": "RIGHT", "path": "hazelcast-sql/src/main/java/com/hazelcast/sql/impl/calcite/OptimizerContext.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMjo0MToyMlrOG8H4Zg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxMDo0OTozNVrOG8uavQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY5Njg3MA==", "bodyText": "We should use searchPaths to be consistent", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r465696870", "createdAt": "2020-08-05T12:41:22Z", "author": {"login": "viliam-durina"}, "path": "hazelcast-sql/src/main/java/com/hazelcast/sql/impl/calcite/OptimizerContext.java", "diffHunk": "@@ -165,6 +161,8 @@ public RelNode optimize(RelNode node, RuleSet rules, RelTraitSet traitSet) {\n         HazelcastSchema rootSchema,\n         List<List<String>> schemaPaths\n     ) {\n+        assert schemaPaths != null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjMyODI1Mw==", "bodyText": "Renamed", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r466328253", "createdAt": "2020-08-06T10:49:35Z", "author": {"login": "devozerov"}, "path": "hazelcast-sql/src/main/java/com/hazelcast/sql/impl/calcite/OptimizerContext.java", "diffHunk": "@@ -165,6 +161,8 @@ public RelNode optimize(RelNode node, RuleSet rules, RelTraitSet traitSet) {\n         HazelcastSchema rootSchema,\n         List<List<String>> schemaPaths\n     ) {\n+        assert schemaPaths != null;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY5Njg3MA=="}, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwODczMzA4OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/plan/cache/PartitionedMapPlanObjectId.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMjo0ODo1MVrOG8IKEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxMDo1NTowMFrOG8ukeg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTcwMTM5NQ==", "bodyText": "TableField doesn't have equals method implemented. It's not strictly necessary for imdg because it never uses it, but it's necessary for Jet because we use it for some connectors.", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r465701395", "createdAt": "2020-08-05T12:48:51Z", "author": {"login": "viliam-durina"}, "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/plan/cache/PartitionedMapPlanObjectId.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.plan.cache;\n+\n+import com.hazelcast.sql.impl.extract.QueryTargetDescriptor;\n+import com.hazelcast.sql.impl.schema.TableField;\n+\n+import java.util.List;\n+import java.util.Set;\n+\n+public class PartitionedMapPlanObjectId implements PlanObjectId {\n+\n+    private final String schemaName;\n+    private final String name;\n+    private final List<TableField> fields;\n+    private final QueryTargetDescriptor keyDescriptor;\n+    private final QueryTargetDescriptor valueDescriptor;\n+    private final Set<String> conflictingSchemas;\n+\n+    public PartitionedMapPlanObjectId(\n+        String schemaName,\n+        String name,\n+        List<TableField> fields,\n+        Set<String> conflictingSchemas,\n+        QueryTargetDescriptor keyDescriptor,\n+        QueryTargetDescriptor valueDescriptor\n+    ) {\n+        this.schemaName = schemaName;\n+        this.name = name;\n+        this.fields = fields;\n+        this.keyDescriptor = keyDescriptor;\n+        this.valueDescriptor = valueDescriptor;\n+        this.conflictingSchemas = conflictingSchemas;\n+    }\n+\n+    @Override\n+    public boolean equals(Object o) {\n+        if (this == o) {\n+            return true;\n+        }\n+\n+        if (o == null || getClass() != o.getClass()) {\n+            return false;\n+        }\n+\n+        PartitionedMapPlanObjectId that = (PartitionedMapPlanObjectId) o;\n+\n+        return schemaName.equals(that.schemaName)\n+            && name.equals(that.name)\n+            && fields.equals(that.fields)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjMzMDc0Ng==", "bodyText": "Added equals/hashCode", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r466330746", "createdAt": "2020-08-06T10:55:00Z", "author": {"login": "devozerov"}, "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/plan/cache/PartitionedMapPlanObjectId.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.plan.cache;\n+\n+import com.hazelcast.sql.impl.extract.QueryTargetDescriptor;\n+import com.hazelcast.sql.impl.schema.TableField;\n+\n+import java.util.List;\n+import java.util.Set;\n+\n+public class PartitionedMapPlanObjectId implements PlanObjectId {\n+\n+    private final String schemaName;\n+    private final String name;\n+    private final List<TableField> fields;\n+    private final QueryTargetDescriptor keyDescriptor;\n+    private final QueryTargetDescriptor valueDescriptor;\n+    private final Set<String> conflictingSchemas;\n+\n+    public PartitionedMapPlanObjectId(\n+        String schemaName,\n+        String name,\n+        List<TableField> fields,\n+        Set<String> conflictingSchemas,\n+        QueryTargetDescriptor keyDescriptor,\n+        QueryTargetDescriptor valueDescriptor\n+    ) {\n+        this.schemaName = schemaName;\n+        this.name = name;\n+        this.fields = fields;\n+        this.keyDescriptor = keyDescriptor;\n+        this.valueDescriptor = valueDescriptor;\n+        this.conflictingSchemas = conflictingSchemas;\n+    }\n+\n+    @Override\n+    public boolean equals(Object o) {\n+        if (this == o) {\n+            return true;\n+        }\n+\n+        if (o == null || getClass() != o.getClass()) {\n+            return false;\n+        }\n+\n+        PartitionedMapPlanObjectId that = (PartitionedMapPlanObjectId) o;\n+\n+        return schemaName.equals(that.schemaName)\n+            && name.equals(that.name)\n+            && fields.equals(that.fields)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTcwMTM5NQ=="}, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwOTAxMzcwOnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/schema/SqlCatalog.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMzo1ODowM1rOG8K5Hg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxMDo1ODozNlrOG8urkA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc0NjIwNg==", "bodyText": "We can add this test to understand the logic here:\n@RunWith(HazelcastSerialClassRunner.class)\n@Category({QuickTest.class, ParallelJVMTest.class})\npublic class SqlCatalogTest {\n\n    @Test\n    public void when_sameNameInTwoSchemas_then_conflict() {\n        // When\n        Table s1t1 = new MockTable(\"s1\", \"t1\");\n        Table s1t2 = new MockTable(\"s1\", \"t2\");\n        Table s2t2 = new MockTable(\"s2\", \"t2\");\n\n        TableResolver tr1 = new MockTableResolver(s1t1, s1t2, s2t2);\n        new SqlCatalog(singletonList(tr1));\n\n        // Then\n        assertEquals(emptySet(), s1t1.getConflictingSchemas());\n        assertEquals(new HashSet<>(asList(\"s1\", \"s2\")), s1t2.getConflictingSchemas());\n        assertEquals(new HashSet<>(asList(\"s1\", \"s2\")), s2t2.getConflictingSchemas());\n    }\n\n    @Test\n    public void when_sameFqn_then_noConflict() {\n        Table s1t1_1 = new MockTable(\"s1\", \"t1\");\n        Table s1t1_2 = new MockTable(\"s1\", \"t1\");\n\n        // When\n        TableResolver tr1 = new MockTableResolver(s1t1_1, s1t1_2);\n        new SqlCatalog(singletonList(tr1));\n\n        // Then\n        assertEquals(emptySet(), s1t1_1.getConflictingSchemas());\n        assertEquals(emptySet(), s1t1_2.getConflictingSchemas());\n    }\n\n    @Test\n    public void when_sameFqnAndConflict_then_conflict() {\n        Table s1t1_1 = new MockTable(\"s1\", \"t1\");\n        Table s1t1_2 = new MockTable(\"s1\", \"t1\");\n        Table s2t1 = new MockTable(\"s2\", \"t1\");\n\n        // When\n        TableResolver tr1 = new MockTableResolver(s1t1_1);\n        TableResolver tr2 = new MockTableResolver(s1t1_2, s2t1);\n        new SqlCatalog(asList(tr1, tr2));\n\n        // Then\n        Set<String> bothSchemas = new HashSet<>(asList(\"s1\", \"s2\"));\n        assertEquals(bothSchemas, s1t1_1.getConflictingSchemas());\n        // the second occurrence of s1t1 doesn't have the conflicts set\n        assertEquals(emptySet(), s1t1_2.getConflictingSchemas());\n        assertEquals(bothSchemas, s2t1.getConflictingSchemas());\n    }\n\n    private static class MockTableResolver implements TableResolver {\n        private final List<Table> tables;\n\n        private MockTableResolver(Table ... tables) {\n            this.tables = asList(tables);\n        }\n\n        @Override\n        public List<List<String>> getDefaultSearchPaths() {\n            throw new UnsupportedOperationException();\n        }\n\n        @Nonnull\n        @Override\n        public List<Table> getTables() {\n            return tables;\n        }\n\n    }\n\n    private static class MockTable extends Table {\n        MockTable(String schema, String tableName) {\n            super(schema, tableName, emptyList(), null);\n        }\n\n        @Override\n        public PlanObjectId getObjectId() {\n            return null;\n        }\n    }\n}", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r465746206", "createdAt": "2020-08-05T13:58:03Z", "author": {"login": "viliam-durina"}, "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/schema/SqlCatalog.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.schema;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+/**\n+ * Schema that is used for the duration of query.\n+ */\n+public class SqlCatalog {\n+\n+    private final Map<String, Map<String, Table>> schemas;\n+\n+    public SqlCatalog(List<TableResolver> tableResolvers) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjMzMjU2MA==", "bodyText": "Added to the PR, thank you for the suggestion!", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r466332560", "createdAt": "2020-08-06T10:58:36Z", "author": {"login": "devozerov"}, "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/schema/SqlCatalog.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.schema;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+/**\n+ * Schema that is used for the duration of query.\n+ */\n+public class SqlCatalog {\n+\n+    private final Map<String, Map<String, Table>> schemas;\n+\n+    public SqlCatalog(List<TableResolver> tableResolvers) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc0NjIwNg=="}, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwOTAxODYwOnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/schema/SqlCatalog.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMzo1OToxM1rOG8K8fQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxMDo0ODowNlrOG8uX9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc0NzA2OQ==", "bodyText": "Is it guaranteed that if there are two objects with the same FQN, the second one will never be resolved, given the table resolver list isn't changed? We rely on it.", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r465747069", "createdAt": "2020-08-05T13:59:13Z", "author": {"login": "viliam-durina"}, "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/schema/SqlCatalog.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.schema;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+/**\n+ * Schema that is used for the duration of query.\n+ */\n+public class SqlCatalog {\n+\n+    private final Map<String, Map<String, Table>> schemas;\n+\n+    public SqlCatalog(List<TableResolver> tableResolvers) {\n+        // Populate schemas and tables.\n+        schemas = new HashMap<>();\n+\n+        Map<String, Set<Table>> tableConflicts = new HashMap<>();\n+\n+        for (TableResolver tableResolver : tableResolvers) {\n+            Collection<Table> tables = tableResolver.getTables();\n+\n+            for (Table table : tables) {\n+                String schemaName = table.getSchemaName();\n+                String tableName = table.getName();\n+\n+                Table oldTable = schemas.computeIfAbsent(schemaName, key -> new HashMap<>()).putIfAbsent(tableName, table);\n+\n+                if (oldTable == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjMyNzU0Mw==", "bodyText": "If there are two objects with the same FQN, then they are guaranteed to be in the same schema. computeIfAbsent ensures that only one object per schema is registered, and hence only one object with the given FQN is resolved. The list of resolvers is fixed for the duration of the process lifetime.\nNow consider that in one run a resolver returned two tables with the same FQN in the order [T1, T2], and in all subsequent runs the order is {T2, T1]. As a result, in the first run we will have a table [T1], and in the next runs we will have only [T2].\nConsider that we cached a plan with the table [T1] in the first run. On the second run, we will not find the table [T1] in the list of catalog tables, and hence the cached plan will be invalidated.", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r466327543", "createdAt": "2020-08-06T10:48:06Z", "author": {"login": "devozerov"}, "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/schema/SqlCatalog.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.schema;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+/**\n+ * Schema that is used for the duration of query.\n+ */\n+public class SqlCatalog {\n+\n+    private final Map<String, Map<String, Table>> schemas;\n+\n+    public SqlCatalog(List<TableResolver> tableResolvers) {\n+        // Populate schemas and tables.\n+        schemas = new HashMap<>();\n+\n+        Map<String, Set<Table>> tableConflicts = new HashMap<>();\n+\n+        for (TableResolver tableResolver : tableResolvers) {\n+            Collection<Table> tables = tableResolver.getTables();\n+\n+            for (Table table : tables) {\n+                String schemaName = table.getSchemaName();\n+                String tableName = table.getName();\n+\n+                Table oldTable = schemas.computeIfAbsent(schemaName, key -> new HashMap<>()).putIfAbsent(tableName, table);\n+\n+                if (oldTable == null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc0NzA2OQ=="}, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwOTA1NzQxOnYy", "diffSide": "RIGHT", "path": "hazelcast-sql/src/main/java/com/hazelcast/sql/impl/calcite/schema/HazelcastSchemaUtils.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxNDowNzo0OFrOG8LUhg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxMDo0MTo0NlrOG8uLdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc1MzIyMg==", "bodyText": "We can use Map<String, org.apache.calcite.schema.Table> here and remove the @SuppressWarnings", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r465753222", "createdAt": "2020-08-05T14:07:48Z", "author": {"login": "viliam-durina"}, "path": "hazelcast-sql/src/main/java/com/hazelcast/sql/impl/calcite/schema/HazelcastSchemaUtils.java", "diffHunk": "@@ -57,38 +55,33 @@ public static HazelcastSchema createCatalog(Schema schema) {\n      * objects such as IMap and ReplicatedMap as well as external tables created by Jet. This approach will not work well\n      * should we need a relaxed/dynamic object resolution at some point in future.\n      *\n-     * @param tableResolvers Table resolver to be used to get the list of existing tables.\n      * @return Top-level schema.\n      */\n     @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n-    public static HazelcastSchema createRootSchema(List<TableResolver> tableResolvers) {\n-        // Create tables.\n-        Map<String, Map<String, HazelcastTable>> tableMap = new HashMap<>();\n+    public static HazelcastSchema createRootSchema(SqlCatalog catalog) {\n+        // Create schemas.\n+        Map<String, Schema> schemaMap = new HashMap<>();\n+\n+        for (Map.Entry<String, Map<String, Table>> currentSchemaEntry : catalog.getSchemas().entrySet()) {\n+            String schemaName = currentSchemaEntry.getKey();\n+\n+            Map schemaTables = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjMyNDM0MQ==", "bodyText": "Fixed.", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r466324341", "createdAt": "2020-08-06T10:41:46Z", "author": {"login": "devozerov"}, "path": "hazelcast-sql/src/main/java/com/hazelcast/sql/impl/calcite/schema/HazelcastSchemaUtils.java", "diffHunk": "@@ -57,38 +55,33 @@ public static HazelcastSchema createCatalog(Schema schema) {\n      * objects such as IMap and ReplicatedMap as well as external tables created by Jet. This approach will not work well\n      * should we need a relaxed/dynamic object resolution at some point in future.\n      *\n-     * @param tableResolvers Table resolver to be used to get the list of existing tables.\n      * @return Top-level schema.\n      */\n     @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n-    public static HazelcastSchema createRootSchema(List<TableResolver> tableResolvers) {\n-        // Create tables.\n-        Map<String, Map<String, HazelcastTable>> tableMap = new HashMap<>();\n+    public static HazelcastSchema createRootSchema(SqlCatalog catalog) {\n+        // Create schemas.\n+        Map<String, Schema> schemaMap = new HashMap<>();\n+\n+        for (Map.Entry<String, Map<String, Table>> currentSchemaEntry : catalog.getSchemas().entrySet()) {\n+            String schemaName = currentSchemaEntry.getKey();\n+\n+            Map schemaTables = new HashMap<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc1MzIyMg=="}, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwOTE2MDU0OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/plan/cache/CachedPlan.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxNDozMDowM1rOG8MVTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxMDo0MDo1NVrOG8uJwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc2OTgwNg==", "bodyText": "A better name would be CacheablePlan", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r465769806", "createdAt": "2020-08-05T14:30:03Z", "author": {"login": "viliam-durina"}, "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/plan/cache/CachedPlan.java", "diffHunk": "@@ -0,0 +1,29 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.plan.cache;\n+\n+import com.hazelcast.sql.impl.optimizer.SqlPlan;\n+\n+/**\n+ * Plan that could be cached.\n+ */\n+public interface CachedPlan extends SqlPlan {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjMyMzkwNA==", "bodyText": "Renamed", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r466323904", "createdAt": "2020-08-06T10:40:55Z", "author": {"login": "devozerov"}, "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/plan/cache/CachedPlan.java", "diffHunk": "@@ -0,0 +1,29 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.plan.cache;\n+\n+import com.hazelcast.sql.impl.optimizer.SqlPlan;\n+\n+/**\n+ * Plan that could be cached.\n+ */\n+public interface CachedPlan extends SqlPlan {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc2OTgwNg=="}, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwOTI0NzIwOnYy", "diffSide": "RIGHT", "path": "hazelcast-sql/src/test/java/com/hazelcast/sql/impl/calcite/TestMapTable.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxNDo0OToxM1rOG8NMFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxMDozOTo0NVrOG8uHWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc4MzgyOQ==", "bodyText": "Bad import", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r465783829", "createdAt": "2020-08-05T14:49:13Z", "author": {"login": "viliam-durina"}, "path": "hazelcast-sql/src/test/java/com/hazelcast/sql/impl/calcite/TestMapTable.java", "diffHunk": "@@ -17,11 +17,13 @@\n package com.hazelcast.sql.impl.calcite;\n \n import com.hazelcast.sql.impl.extract.GenericQueryTargetDescriptor;\n+import com.hazelcast.sql.impl.plan.cache.PlanObjectId;\n import com.hazelcast.sql.impl.schema.ConstantTableStatistics;\n import com.hazelcast.sql.impl.schema.TableField;\n import com.hazelcast.sql.impl.schema.TableStatistics;\n import com.hazelcast.sql.impl.schema.map.AbstractMapTable;\n import com.hazelcast.sql.impl.type.QueryDataType;\n+import com.sun.corba.se.spi.ior.ObjectId;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjMyMzI5MQ==", "bodyText": "Fixed", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r466323291", "createdAt": "2020-08-06T10:39:45Z", "author": {"login": "devozerov"}, "path": "hazelcast-sql/src/test/java/com/hazelcast/sql/impl/calcite/TestMapTable.java", "diffHunk": "@@ -17,11 +17,13 @@\n package com.hazelcast.sql.impl.calcite;\n \n import com.hazelcast.sql.impl.extract.GenericQueryTargetDescriptor;\n+import com.hazelcast.sql.impl.plan.cache.PlanObjectId;\n import com.hazelcast.sql.impl.schema.ConstantTableStatistics;\n import com.hazelcast.sql.impl.schema.TableField;\n import com.hazelcast.sql.impl.schema.TableStatistics;\n import com.hazelcast.sql.impl.schema.map.AbstractMapTable;\n import com.hazelcast.sql.impl.type.QueryDataType;\n+import com.sun.corba.se.spi.ior.ObjectId;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc4MzgyOQ=="}, "originalCommit": {"oid": "27f2595a576b35d2084c05b1c96f0a55db2dc468"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMzM0MTA2OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/schema/map/PartitionedMapTable.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxMzo1MjowMVrOG80gBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxMzo1ODo1NlrOG80z1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQyNzkwOA==", "bodyText": "\"Object ID\" sounds too generic to me. ID implies that it's stable, but it changes with any property change. Maybe \"comparison key\" would be better. Or \"object key\", for brevity. Also should contain \"plan\", because the key is tailored for plan. What about this?:\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public PlanObjectId getObjectId() {\n          \n          \n            \n                public PlanObjectKey getPlanObjectKey() {", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r466427908", "createdAt": "2020-08-06T13:52:01Z", "author": {"login": "viliam-durina"}, "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/schema/map/PartitionedMapTable.java", "diffHunk": "@@ -39,4 +41,20 @@ public PartitionedMapTable(\n     public PartitionedMapTable(String name, QueryException exception) {\n         super(SCHEMA_NAME_PARTITIONED, name, exception);\n     }\n+\n+    @Override\n+    public PlanObjectId getObjectId() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e560f89a36d2d63729eb6b930de148ac62a4a93a"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQzMjk4Mg==", "bodyText": "Renamed", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r466432982", "createdAt": "2020-08-06T13:58:56Z", "author": {"login": "devozerov"}, "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/schema/map/PartitionedMapTable.java", "diffHunk": "@@ -39,4 +41,20 @@ public PartitionedMapTable(\n     public PartitionedMapTable(String name, QueryException exception) {\n         super(SCHEMA_NAME_PARTITIONED, name, exception);\n     }\n+\n+    @Override\n+    public PlanObjectId getObjectId() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQyNzkwOA=="}, "originalCommit": {"oid": "e560f89a36d2d63729eb6b930de148ac62a4a93a"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzMTE2OTY5OnYy", "diffSide": "RIGHT", "path": "docs/design/sql/06-plan-caching.md", "isResolved": true, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwOTowMzozOFrOG_YdGw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QwNzoyMzoyOFrOG__LWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTExNDEzOQ==", "bodyText": "Is it going to be documented anywhere? How the users can detect that the exception indicates an invalid plan?", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r469114139", "createdAt": "2020-08-12T09:03:38Z", "author": {"login": "petrpleshachkov"}, "path": "docs/design/sql/06-plan-caching.md", "diffHunk": "@@ -0,0 +1,129 @@\n+# Plan Caching\n+\n+## Overview\n+\n+Optimization of a query may take considerable time. In many applications, the set of queries is fixed. Therefore, the result of \n+query optimization could be cached and reused. This document explains the design of the plan cache in the Hazelcast Mustang SQL\n+engine.\n+\n+In section 1 we discuss the high-level requirements to the plan cache. In section 2 we describe the design. \n+\n+## 1. Requirements\n+\n+We assume that the result of query optimization is deterministic. That is, the same query plan is produced for the same set of \n+inputs. The inputs of the query optimizer are:\n+1. Catalog (schemas, tables, indexes)\n+1. The original query: query string, current schema, and parameters \n+1. Metadata\n+\n+### 1.1 Catalog\n+\n+A  catalog is a set of objects that may participate in query execution. The catalog is often referred to as \"schema\" in \n+the literature. We use the term \"catalog\" to disambiguate from the logical object containers, which are also called \"schemas\".\n+ \n+The catalog has three types of objects. *Schema* is a logical container for other objects. *Table* is a relation backed\n+by some physical storage, such as an `IMap`. *Index* is an additional data structure of a table that speeds up the execution \n+of queries. The catalog is used to resolve objects mentioned in the query and choose the proper access method. \n+\n+If the catalog is changed, the plan created earlier might become invalid. For example, if the table is dropped, the execution \n+of the plan will produce an error. If a new index is added, the optimizer may pick a better access path.\n+\n+The plan cache must be able to find and remove plans that have become invalid after changing the catalog. \n+\n+### 1.2 Query\n+\n+The query consists of the query string, the current schema, and parameters. Each of them may influence the optimization result.\n+\n+The current schema affects object resolution. For example, the query `SELECT * FROM map` may refer to `IMap` or `ReplicatedMap`\n+depending on the current schema (`partitioned` or `replicated`). \n+\n+Parameter values may alter statistics derivation and access path selection. For example, `SELECT ... FROM sales WHERE region=?`\n+may have different optimal plans for regions `EMEA` and `APAC`.  \n+ \n+The plan cache must use query content properly to ensure the correctness and efficiency of the query execution.  \n+ \n+### 1.3 Metadata\n+ \n+In the query optimization theory, metadata is external information that is used for optimization. Examples are \n+statistics, column uniqueness, data distribution, etc.\n+\n+In this document, we consider only partition distribution because this is the only metadata we use in our optimizer, \n+that is not part of the catalog, and that could change across query runs.\n+\n+Every plan is built for the specific partition distribution. That is, the distribution and participating members are saved \n+in the plan.\n+\n+The plan cache must be able to find and remove plans with obsolete partition distribution. \n+ \n+## 2. Design\n+\n+### 2.1 Plan Key\n+\n+The plan key is a key used to locate the cache plan. It should be possible to derive the key from the query before the \n+optimization phase. \n+\n+We use the following key:\n+```\n+PlanKey {\n+    List<List<String>> searchPaths;\n+    String sql;\n+}\n+```\n+`searchPaths` is the list of schemas that are used to resolve non-fully qualified objects during query parsing. Search paths\n+are created based on configured table resolvers, and the current schema. `sql` is a query string.   \n+\n+For the same catalog, two queries with the same search paths, and the same query string will always resolve the same objects. \n+On the contrary, the same query string may resolve different objects for different search paths, as shown in section 1.2. \n+Therefore, search paths must be part of the key.  \n+\n+### 2.2 Data Structure\n+\n+We use `ConcurrentHashMap` to store cached plans. `PlanKey` is a key, the plan is a value.\n+ \n+### 2.3 Maximum Size and Plan Eviction\n+\n+The maximum size of the cache is required to prevent out-of-memory if too many distinct queries are submitted.\n+\n+When a plan is added to the map, the map size is checked. If the map size is greater than the maximum size, some plans are \n+evicted. \n+\n+Eviction is synchronous because the asynchronous variant is prone to out-of-memory. We assume that for the most workloads \n+evictions should be rare. \n+\n+We use the LRU (least recently used) approach to find the plans to evict. Whenever a plan is accessed, it's `lastUsed` field is \n+updated with the current time. During the eviction, plans are sorted by their `lastUsed` values, and the least recently used\n+plans are removed.   \n+\n+### 2.4 Reacting to Catalog and Partition Distribution Changes\n+\n+If a catalog or partition distribution is changed, some plans must be invalidated. There are two different ways to achieve \n+this: `push` and `pull`.\n+\n+With the `push` approach, the plan cache is notified about a change, from the relevant component. E.g., if an index is created,\n+then the map service notifies the plan cache about the change. The advantage of this solution is that any change is reflected \n+in the plan cache immediately. However, this approach increases coupling, because many components (map service, \n+replicated map service, partition service) now have to be aware of the SQL subsystem. This approach also requires complex\n+synchronization between query optimizer, plan cache, and dependent components, to ensure that no stale plan is ever cached.\n+\n+With the `pull` approach, the SQL subsystem queries other components periodically, collects the changes, and invalidates \n+affected plans. The advantage of this approach is simplicity. No synchronization or changes to other components are needed. \n+Invalid plans are guaranteed to be removed eventually. The downside is that invalid plans might be active for some time after\n+the change has occurred.\n+\n+We choose the `pull` approach due to simplicity and sufficient guarantees. The background worker reconstructs the catalog \n+periodically, and verifies that existing plans are compatible with the current catalog and partition distribution. \n+\n+To counter the problem with outdated plans, we add a special `invalidatePlan` flag to `QueryException`. If an invalid plan\n+is used, an exception with this flag will be thrown at some point. When the initiator member receives an exception with \n+this flag, the plan is invalidated. \n+\n+Note that currently, users will have to re-execute the query in this case. In future versions, we will add a transparent\n+query retry, so that invalid plans will not be visible to users.    ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1e5df9a208bfa6ad07eec638546a37376abc4dc"}, "originalPosition": 121}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM0MzYyMw==", "bodyText": "This will be implemented in a way transparent for users. No documentation is needed.", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r469343623", "createdAt": "2020-08-12T15:25:55Z", "author": {"login": "devozerov"}, "path": "docs/design/sql/06-plan-caching.md", "diffHunk": "@@ -0,0 +1,129 @@\n+# Plan Caching\n+\n+## Overview\n+\n+Optimization of a query may take considerable time. In many applications, the set of queries is fixed. Therefore, the result of \n+query optimization could be cached and reused. This document explains the design of the plan cache in the Hazelcast Mustang SQL\n+engine.\n+\n+In section 1 we discuss the high-level requirements to the plan cache. In section 2 we describe the design. \n+\n+## 1. Requirements\n+\n+We assume that the result of query optimization is deterministic. That is, the same query plan is produced for the same set of \n+inputs. The inputs of the query optimizer are:\n+1. Catalog (schemas, tables, indexes)\n+1. The original query: query string, current schema, and parameters \n+1. Metadata\n+\n+### 1.1 Catalog\n+\n+A  catalog is a set of objects that may participate in query execution. The catalog is often referred to as \"schema\" in \n+the literature. We use the term \"catalog\" to disambiguate from the logical object containers, which are also called \"schemas\".\n+ \n+The catalog has three types of objects. *Schema* is a logical container for other objects. *Table* is a relation backed\n+by some physical storage, such as an `IMap`. *Index* is an additional data structure of a table that speeds up the execution \n+of queries. The catalog is used to resolve objects mentioned in the query and choose the proper access method. \n+\n+If the catalog is changed, the plan created earlier might become invalid. For example, if the table is dropped, the execution \n+of the plan will produce an error. If a new index is added, the optimizer may pick a better access path.\n+\n+The plan cache must be able to find and remove plans that have become invalid after changing the catalog. \n+\n+### 1.2 Query\n+\n+The query consists of the query string, the current schema, and parameters. Each of them may influence the optimization result.\n+\n+The current schema affects object resolution. For example, the query `SELECT * FROM map` may refer to `IMap` or `ReplicatedMap`\n+depending on the current schema (`partitioned` or `replicated`). \n+\n+Parameter values may alter statistics derivation and access path selection. For example, `SELECT ... FROM sales WHERE region=?`\n+may have different optimal plans for regions `EMEA` and `APAC`.  \n+ \n+The plan cache must use query content properly to ensure the correctness and efficiency of the query execution.  \n+ \n+### 1.3 Metadata\n+ \n+In the query optimization theory, metadata is external information that is used for optimization. Examples are \n+statistics, column uniqueness, data distribution, etc.\n+\n+In this document, we consider only partition distribution because this is the only metadata we use in our optimizer, \n+that is not part of the catalog, and that could change across query runs.\n+\n+Every plan is built for the specific partition distribution. That is, the distribution and participating members are saved \n+in the plan.\n+\n+The plan cache must be able to find and remove plans with obsolete partition distribution. \n+ \n+## 2. Design\n+\n+### 2.1 Plan Key\n+\n+The plan key is a key used to locate the cache plan. It should be possible to derive the key from the query before the \n+optimization phase. \n+\n+We use the following key:\n+```\n+PlanKey {\n+    List<List<String>> searchPaths;\n+    String sql;\n+}\n+```\n+`searchPaths` is the list of schemas that are used to resolve non-fully qualified objects during query parsing. Search paths\n+are created based on configured table resolvers, and the current schema. `sql` is a query string.   \n+\n+For the same catalog, two queries with the same search paths, and the same query string will always resolve the same objects. \n+On the contrary, the same query string may resolve different objects for different search paths, as shown in section 1.2. \n+Therefore, search paths must be part of the key.  \n+\n+### 2.2 Data Structure\n+\n+We use `ConcurrentHashMap` to store cached plans. `PlanKey` is a key, the plan is a value.\n+ \n+### 2.3 Maximum Size and Plan Eviction\n+\n+The maximum size of the cache is required to prevent out-of-memory if too many distinct queries are submitted.\n+\n+When a plan is added to the map, the map size is checked. If the map size is greater than the maximum size, some plans are \n+evicted. \n+\n+Eviction is synchronous because the asynchronous variant is prone to out-of-memory. We assume that for the most workloads \n+evictions should be rare. \n+\n+We use the LRU (least recently used) approach to find the plans to evict. Whenever a plan is accessed, it's `lastUsed` field is \n+updated with the current time. During the eviction, plans are sorted by their `lastUsed` values, and the least recently used\n+plans are removed.   \n+\n+### 2.4 Reacting to Catalog and Partition Distribution Changes\n+\n+If a catalog or partition distribution is changed, some plans must be invalidated. There are two different ways to achieve \n+this: `push` and `pull`.\n+\n+With the `push` approach, the plan cache is notified about a change, from the relevant component. E.g., if an index is created,\n+then the map service notifies the plan cache about the change. The advantage of this solution is that any change is reflected \n+in the plan cache immediately. However, this approach increases coupling, because many components (map service, \n+replicated map service, partition service) now have to be aware of the SQL subsystem. This approach also requires complex\n+synchronization between query optimizer, plan cache, and dependent components, to ensure that no stale plan is ever cached.\n+\n+With the `pull` approach, the SQL subsystem queries other components periodically, collects the changes, and invalidates \n+affected plans. The advantage of this approach is simplicity. No synchronization or changes to other components are needed. \n+Invalid plans are guaranteed to be removed eventually. The downside is that invalid plans might be active for some time after\n+the change has occurred.\n+\n+We choose the `pull` approach due to simplicity and sufficient guarantees. The background worker reconstructs the catalog \n+periodically, and verifies that existing plans are compatible with the current catalog and partition distribution. \n+\n+To counter the problem with outdated plans, we add a special `invalidatePlan` flag to `QueryException`. If an invalid plan\n+is used, an exception with this flag will be thrown at some point. When the initiator member receives an exception with \n+this flag, the plan is invalidated. \n+\n+Note that currently, users will have to re-execute the query in this case. In future versions, we will add a transparent\n+query retry, so that invalid plans will not be visible to users.    ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTExNDEzOQ=="}, "originalCommit": {"oid": "d1e5df9a208bfa6ad07eec638546a37376abc4dc"}, "originalPosition": 121}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTczMTY0OA==", "bodyText": "Not sure that I got it. According to this document, the users will have to re-execute the query. Is it the behavior in 4.1? If so, it should be documented.", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r469731648", "createdAt": "2020-08-13T06:46:13Z", "author": {"login": "petrpleshachkov"}, "path": "docs/design/sql/06-plan-caching.md", "diffHunk": "@@ -0,0 +1,129 @@\n+# Plan Caching\n+\n+## Overview\n+\n+Optimization of a query may take considerable time. In many applications, the set of queries is fixed. Therefore, the result of \n+query optimization could be cached and reused. This document explains the design of the plan cache in the Hazelcast Mustang SQL\n+engine.\n+\n+In section 1 we discuss the high-level requirements to the plan cache. In section 2 we describe the design. \n+\n+## 1. Requirements\n+\n+We assume that the result of query optimization is deterministic. That is, the same query plan is produced for the same set of \n+inputs. The inputs of the query optimizer are:\n+1. Catalog (schemas, tables, indexes)\n+1. The original query: query string, current schema, and parameters \n+1. Metadata\n+\n+### 1.1 Catalog\n+\n+A  catalog is a set of objects that may participate in query execution. The catalog is often referred to as \"schema\" in \n+the literature. We use the term \"catalog\" to disambiguate from the logical object containers, which are also called \"schemas\".\n+ \n+The catalog has three types of objects. *Schema* is a logical container for other objects. *Table* is a relation backed\n+by some physical storage, such as an `IMap`. *Index* is an additional data structure of a table that speeds up the execution \n+of queries. The catalog is used to resolve objects mentioned in the query and choose the proper access method. \n+\n+If the catalog is changed, the plan created earlier might become invalid. For example, if the table is dropped, the execution \n+of the plan will produce an error. If a new index is added, the optimizer may pick a better access path.\n+\n+The plan cache must be able to find and remove plans that have become invalid after changing the catalog. \n+\n+### 1.2 Query\n+\n+The query consists of the query string, the current schema, and parameters. Each of them may influence the optimization result.\n+\n+The current schema affects object resolution. For example, the query `SELECT * FROM map` may refer to `IMap` or `ReplicatedMap`\n+depending on the current schema (`partitioned` or `replicated`). \n+\n+Parameter values may alter statistics derivation and access path selection. For example, `SELECT ... FROM sales WHERE region=?`\n+may have different optimal plans for regions `EMEA` and `APAC`.  \n+ \n+The plan cache must use query content properly to ensure the correctness and efficiency of the query execution.  \n+ \n+### 1.3 Metadata\n+ \n+In the query optimization theory, metadata is external information that is used for optimization. Examples are \n+statistics, column uniqueness, data distribution, etc.\n+\n+In this document, we consider only partition distribution because this is the only metadata we use in our optimizer, \n+that is not part of the catalog, and that could change across query runs.\n+\n+Every plan is built for the specific partition distribution. That is, the distribution and participating members are saved \n+in the plan.\n+\n+The plan cache must be able to find and remove plans with obsolete partition distribution. \n+ \n+## 2. Design\n+\n+### 2.1 Plan Key\n+\n+The plan key is a key used to locate the cache plan. It should be possible to derive the key from the query before the \n+optimization phase. \n+\n+We use the following key:\n+```\n+PlanKey {\n+    List<List<String>> searchPaths;\n+    String sql;\n+}\n+```\n+`searchPaths` is the list of schemas that are used to resolve non-fully qualified objects during query parsing. Search paths\n+are created based on configured table resolvers, and the current schema. `sql` is a query string.   \n+\n+For the same catalog, two queries with the same search paths, and the same query string will always resolve the same objects. \n+On the contrary, the same query string may resolve different objects for different search paths, as shown in section 1.2. \n+Therefore, search paths must be part of the key.  \n+\n+### 2.2 Data Structure\n+\n+We use `ConcurrentHashMap` to store cached plans. `PlanKey` is a key, the plan is a value.\n+ \n+### 2.3 Maximum Size and Plan Eviction\n+\n+The maximum size of the cache is required to prevent out-of-memory if too many distinct queries are submitted.\n+\n+When a plan is added to the map, the map size is checked. If the map size is greater than the maximum size, some plans are \n+evicted. \n+\n+Eviction is synchronous because the asynchronous variant is prone to out-of-memory. We assume that for the most workloads \n+evictions should be rare. \n+\n+We use the LRU (least recently used) approach to find the plans to evict. Whenever a plan is accessed, it's `lastUsed` field is \n+updated with the current time. During the eviction, plans are sorted by their `lastUsed` values, and the least recently used\n+plans are removed.   \n+\n+### 2.4 Reacting to Catalog and Partition Distribution Changes\n+\n+If a catalog or partition distribution is changed, some plans must be invalidated. There are two different ways to achieve \n+this: `push` and `pull`.\n+\n+With the `push` approach, the plan cache is notified about a change, from the relevant component. E.g., if an index is created,\n+then the map service notifies the plan cache about the change. The advantage of this solution is that any change is reflected \n+in the plan cache immediately. However, this approach increases coupling, because many components (map service, \n+replicated map service, partition service) now have to be aware of the SQL subsystem. This approach also requires complex\n+synchronization between query optimizer, plan cache, and dependent components, to ensure that no stale plan is ever cached.\n+\n+With the `pull` approach, the SQL subsystem queries other components periodically, collects the changes, and invalidates \n+affected plans. The advantage of this approach is simplicity. No synchronization or changes to other components are needed. \n+Invalid plans are guaranteed to be removed eventually. The downside is that invalid plans might be active for some time after\n+the change has occurred.\n+\n+We choose the `pull` approach due to simplicity and sufficient guarantees. The background worker reconstructs the catalog \n+periodically, and verifies that existing plans are compatible with the current catalog and partition distribution. \n+\n+To counter the problem with outdated plans, we add a special `invalidatePlan` flag to `QueryException`. If an invalid plan\n+is used, an exception with this flag will be thrown at some point. When the initiator member receives an exception with \n+this flag, the plan is invalidated. \n+\n+Note that currently, users will have to re-execute the query in this case. In future versions, we will add a transparent\n+query retry, so that invalid plans will not be visible to users.    ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTExNDEzOQ=="}, "originalCommit": {"oid": "d1e5df9a208bfa6ad07eec638546a37376abc4dc"}, "originalPosition": 121}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTczNTE0OQ==", "bodyText": "I am not sure where exactly you propose to document it?", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r469735149", "createdAt": "2020-08-13T06:54:29Z", "author": {"login": "devozerov"}, "path": "docs/design/sql/06-plan-caching.md", "diffHunk": "@@ -0,0 +1,129 @@\n+# Plan Caching\n+\n+## Overview\n+\n+Optimization of a query may take considerable time. In many applications, the set of queries is fixed. Therefore, the result of \n+query optimization could be cached and reused. This document explains the design of the plan cache in the Hazelcast Mustang SQL\n+engine.\n+\n+In section 1 we discuss the high-level requirements to the plan cache. In section 2 we describe the design. \n+\n+## 1. Requirements\n+\n+We assume that the result of query optimization is deterministic. That is, the same query plan is produced for the same set of \n+inputs. The inputs of the query optimizer are:\n+1. Catalog (schemas, tables, indexes)\n+1. The original query: query string, current schema, and parameters \n+1. Metadata\n+\n+### 1.1 Catalog\n+\n+A  catalog is a set of objects that may participate in query execution. The catalog is often referred to as \"schema\" in \n+the literature. We use the term \"catalog\" to disambiguate from the logical object containers, which are also called \"schemas\".\n+ \n+The catalog has three types of objects. *Schema* is a logical container for other objects. *Table* is a relation backed\n+by some physical storage, such as an `IMap`. *Index* is an additional data structure of a table that speeds up the execution \n+of queries. The catalog is used to resolve objects mentioned in the query and choose the proper access method. \n+\n+If the catalog is changed, the plan created earlier might become invalid. For example, if the table is dropped, the execution \n+of the plan will produce an error. If a new index is added, the optimizer may pick a better access path.\n+\n+The plan cache must be able to find and remove plans that have become invalid after changing the catalog. \n+\n+### 1.2 Query\n+\n+The query consists of the query string, the current schema, and parameters. Each of them may influence the optimization result.\n+\n+The current schema affects object resolution. For example, the query `SELECT * FROM map` may refer to `IMap` or `ReplicatedMap`\n+depending on the current schema (`partitioned` or `replicated`). \n+\n+Parameter values may alter statistics derivation and access path selection. For example, `SELECT ... FROM sales WHERE region=?`\n+may have different optimal plans for regions `EMEA` and `APAC`.  \n+ \n+The plan cache must use query content properly to ensure the correctness and efficiency of the query execution.  \n+ \n+### 1.3 Metadata\n+ \n+In the query optimization theory, metadata is external information that is used for optimization. Examples are \n+statistics, column uniqueness, data distribution, etc.\n+\n+In this document, we consider only partition distribution because this is the only metadata we use in our optimizer, \n+that is not part of the catalog, and that could change across query runs.\n+\n+Every plan is built for the specific partition distribution. That is, the distribution and participating members are saved \n+in the plan.\n+\n+The plan cache must be able to find and remove plans with obsolete partition distribution. \n+ \n+## 2. Design\n+\n+### 2.1 Plan Key\n+\n+The plan key is a key used to locate the cache plan. It should be possible to derive the key from the query before the \n+optimization phase. \n+\n+We use the following key:\n+```\n+PlanKey {\n+    List<List<String>> searchPaths;\n+    String sql;\n+}\n+```\n+`searchPaths` is the list of schemas that are used to resolve non-fully qualified objects during query parsing. Search paths\n+are created based on configured table resolvers, and the current schema. `sql` is a query string.   \n+\n+For the same catalog, two queries with the same search paths, and the same query string will always resolve the same objects. \n+On the contrary, the same query string may resolve different objects for different search paths, as shown in section 1.2. \n+Therefore, search paths must be part of the key.  \n+\n+### 2.2 Data Structure\n+\n+We use `ConcurrentHashMap` to store cached plans. `PlanKey` is a key, the plan is a value.\n+ \n+### 2.3 Maximum Size and Plan Eviction\n+\n+The maximum size of the cache is required to prevent out-of-memory if too many distinct queries are submitted.\n+\n+When a plan is added to the map, the map size is checked. If the map size is greater than the maximum size, some plans are \n+evicted. \n+\n+Eviction is synchronous because the asynchronous variant is prone to out-of-memory. We assume that for the most workloads \n+evictions should be rare. \n+\n+We use the LRU (least recently used) approach to find the plans to evict. Whenever a plan is accessed, it's `lastUsed` field is \n+updated with the current time. During the eviction, plans are sorted by their `lastUsed` values, and the least recently used\n+plans are removed.   \n+\n+### 2.4 Reacting to Catalog and Partition Distribution Changes\n+\n+If a catalog or partition distribution is changed, some plans must be invalidated. There are two different ways to achieve \n+this: `push` and `pull`.\n+\n+With the `push` approach, the plan cache is notified about a change, from the relevant component. E.g., if an index is created,\n+then the map service notifies the plan cache about the change. The advantage of this solution is that any change is reflected \n+in the plan cache immediately. However, this approach increases coupling, because many components (map service, \n+replicated map service, partition service) now have to be aware of the SQL subsystem. This approach also requires complex\n+synchronization between query optimizer, plan cache, and dependent components, to ensure that no stale plan is ever cached.\n+\n+With the `pull` approach, the SQL subsystem queries other components periodically, collects the changes, and invalidates \n+affected plans. The advantage of this approach is simplicity. No synchronization or changes to other components are needed. \n+Invalid plans are guaranteed to be removed eventually. The downside is that invalid plans might be active for some time after\n+the change has occurred.\n+\n+We choose the `pull` approach due to simplicity and sufficient guarantees. The background worker reconstructs the catalog \n+periodically, and verifies that existing plans are compatible with the current catalog and partition distribution. \n+\n+To counter the problem with outdated plans, we add a special `invalidatePlan` flag to `QueryException`. If an invalid plan\n+is used, an exception with this flag will be thrown at some point. When the initiator member receives an exception with \n+this flag, the plan is invalidated. \n+\n+Note that currently, users will have to re-execute the query in this case. In future versions, we will add a transparent\n+query retry, so that invalid plans will not be visible to users.    ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTExNDEzOQ=="}, "originalCommit": {"oid": "d1e5df9a208bfa6ad07eec638546a37376abc4dc"}, "originalPosition": 121}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTc0NTQ1Ng==", "bodyText": "In HZ manual", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r469745456", "createdAt": "2020-08-13T07:17:07Z", "author": {"login": "petrpleshachkov"}, "path": "docs/design/sql/06-plan-caching.md", "diffHunk": "@@ -0,0 +1,129 @@\n+# Plan Caching\n+\n+## Overview\n+\n+Optimization of a query may take considerable time. In many applications, the set of queries is fixed. Therefore, the result of \n+query optimization could be cached and reused. This document explains the design of the plan cache in the Hazelcast Mustang SQL\n+engine.\n+\n+In section 1 we discuss the high-level requirements to the plan cache. In section 2 we describe the design. \n+\n+## 1. Requirements\n+\n+We assume that the result of query optimization is deterministic. That is, the same query plan is produced for the same set of \n+inputs. The inputs of the query optimizer are:\n+1. Catalog (schemas, tables, indexes)\n+1. The original query: query string, current schema, and parameters \n+1. Metadata\n+\n+### 1.1 Catalog\n+\n+A  catalog is a set of objects that may participate in query execution. The catalog is often referred to as \"schema\" in \n+the literature. We use the term \"catalog\" to disambiguate from the logical object containers, which are also called \"schemas\".\n+ \n+The catalog has three types of objects. *Schema* is a logical container for other objects. *Table* is a relation backed\n+by some physical storage, such as an `IMap`. *Index* is an additional data structure of a table that speeds up the execution \n+of queries. The catalog is used to resolve objects mentioned in the query and choose the proper access method. \n+\n+If the catalog is changed, the plan created earlier might become invalid. For example, if the table is dropped, the execution \n+of the plan will produce an error. If a new index is added, the optimizer may pick a better access path.\n+\n+The plan cache must be able to find and remove plans that have become invalid after changing the catalog. \n+\n+### 1.2 Query\n+\n+The query consists of the query string, the current schema, and parameters. Each of them may influence the optimization result.\n+\n+The current schema affects object resolution. For example, the query `SELECT * FROM map` may refer to `IMap` or `ReplicatedMap`\n+depending on the current schema (`partitioned` or `replicated`). \n+\n+Parameter values may alter statistics derivation and access path selection. For example, `SELECT ... FROM sales WHERE region=?`\n+may have different optimal plans for regions `EMEA` and `APAC`.  \n+ \n+The plan cache must use query content properly to ensure the correctness and efficiency of the query execution.  \n+ \n+### 1.3 Metadata\n+ \n+In the query optimization theory, metadata is external information that is used for optimization. Examples are \n+statistics, column uniqueness, data distribution, etc.\n+\n+In this document, we consider only partition distribution because this is the only metadata we use in our optimizer, \n+that is not part of the catalog, and that could change across query runs.\n+\n+Every plan is built for the specific partition distribution. That is, the distribution and participating members are saved \n+in the plan.\n+\n+The plan cache must be able to find and remove plans with obsolete partition distribution. \n+ \n+## 2. Design\n+\n+### 2.1 Plan Key\n+\n+The plan key is a key used to locate the cache plan. It should be possible to derive the key from the query before the \n+optimization phase. \n+\n+We use the following key:\n+```\n+PlanKey {\n+    List<List<String>> searchPaths;\n+    String sql;\n+}\n+```\n+`searchPaths` is the list of schemas that are used to resolve non-fully qualified objects during query parsing. Search paths\n+are created based on configured table resolvers, and the current schema. `sql` is a query string.   \n+\n+For the same catalog, two queries with the same search paths, and the same query string will always resolve the same objects. \n+On the contrary, the same query string may resolve different objects for different search paths, as shown in section 1.2. \n+Therefore, search paths must be part of the key.  \n+\n+### 2.2 Data Structure\n+\n+We use `ConcurrentHashMap` to store cached plans. `PlanKey` is a key, the plan is a value.\n+ \n+### 2.3 Maximum Size and Plan Eviction\n+\n+The maximum size of the cache is required to prevent out-of-memory if too many distinct queries are submitted.\n+\n+When a plan is added to the map, the map size is checked. If the map size is greater than the maximum size, some plans are \n+evicted. \n+\n+Eviction is synchronous because the asynchronous variant is prone to out-of-memory. We assume that for the most workloads \n+evictions should be rare. \n+\n+We use the LRU (least recently used) approach to find the plans to evict. Whenever a plan is accessed, it's `lastUsed` field is \n+updated with the current time. During the eviction, plans are sorted by their `lastUsed` values, and the least recently used\n+plans are removed.   \n+\n+### 2.4 Reacting to Catalog and Partition Distribution Changes\n+\n+If a catalog or partition distribution is changed, some plans must be invalidated. There are two different ways to achieve \n+this: `push` and `pull`.\n+\n+With the `push` approach, the plan cache is notified about a change, from the relevant component. E.g., if an index is created,\n+then the map service notifies the plan cache about the change. The advantage of this solution is that any change is reflected \n+in the plan cache immediately. However, this approach increases coupling, because many components (map service, \n+replicated map service, partition service) now have to be aware of the SQL subsystem. This approach also requires complex\n+synchronization between query optimizer, plan cache, and dependent components, to ensure that no stale plan is ever cached.\n+\n+With the `pull` approach, the SQL subsystem queries other components periodically, collects the changes, and invalidates \n+affected plans. The advantage of this approach is simplicity. No synchronization or changes to other components are needed. \n+Invalid plans are guaranteed to be removed eventually. The downside is that invalid plans might be active for some time after\n+the change has occurred.\n+\n+We choose the `pull` approach due to simplicity and sufficient guarantees. The background worker reconstructs the catalog \n+periodically, and verifies that existing plans are compatible with the current catalog and partition distribution. \n+\n+To counter the problem with outdated plans, we add a special `invalidatePlan` flag to `QueryException`. If an invalid plan\n+is used, an exception with this flag will be thrown at some point. When the initiator member receives an exception with \n+this flag, the plan is invalidated. \n+\n+Note that currently, users will have to re-execute the query in this case. In future versions, we will add a transparent\n+query retry, so that invalid plans will not be visible to users.    ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTExNDEzOQ=="}, "originalCommit": {"oid": "d1e5df9a208bfa6ad07eec638546a37376abc4dc"}, "originalPosition": 121}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTc0ODU0MA==", "bodyText": "We will document error conditions in the manual, this is out of scope if this PR. Note that there is no such thing as \u201cplan\u201d or \u201cplan invalidation\u201d from the user perspective. Instead, there are some error conditions, such as map destroy or partition migration, which may lead to plan invalidation, which is purely internal thing. The improvement I mentioned (retries on plan invalidation), will help us hide such errors from users sometimes, but not always.", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r469748540", "createdAt": "2020-08-13T07:23:25Z", "author": {"login": "devozerov"}, "path": "docs/design/sql/06-plan-caching.md", "diffHunk": "@@ -0,0 +1,129 @@\n+# Plan Caching\n+\n+## Overview\n+\n+Optimization of a query may take considerable time. In many applications, the set of queries is fixed. Therefore, the result of \n+query optimization could be cached and reused. This document explains the design of the plan cache in the Hazelcast Mustang SQL\n+engine.\n+\n+In section 1 we discuss the high-level requirements to the plan cache. In section 2 we describe the design. \n+\n+## 1. Requirements\n+\n+We assume that the result of query optimization is deterministic. That is, the same query plan is produced for the same set of \n+inputs. The inputs of the query optimizer are:\n+1. Catalog (schemas, tables, indexes)\n+1. The original query: query string, current schema, and parameters \n+1. Metadata\n+\n+### 1.1 Catalog\n+\n+A  catalog is a set of objects that may participate in query execution. The catalog is often referred to as \"schema\" in \n+the literature. We use the term \"catalog\" to disambiguate from the logical object containers, which are also called \"schemas\".\n+ \n+The catalog has three types of objects. *Schema* is a logical container for other objects. *Table* is a relation backed\n+by some physical storage, such as an `IMap`. *Index* is an additional data structure of a table that speeds up the execution \n+of queries. The catalog is used to resolve objects mentioned in the query and choose the proper access method. \n+\n+If the catalog is changed, the plan created earlier might become invalid. For example, if the table is dropped, the execution \n+of the plan will produce an error. If a new index is added, the optimizer may pick a better access path.\n+\n+The plan cache must be able to find and remove plans that have become invalid after changing the catalog. \n+\n+### 1.2 Query\n+\n+The query consists of the query string, the current schema, and parameters. Each of them may influence the optimization result.\n+\n+The current schema affects object resolution. For example, the query `SELECT * FROM map` may refer to `IMap` or `ReplicatedMap`\n+depending on the current schema (`partitioned` or `replicated`). \n+\n+Parameter values may alter statistics derivation and access path selection. For example, `SELECT ... FROM sales WHERE region=?`\n+may have different optimal plans for regions `EMEA` and `APAC`.  \n+ \n+The plan cache must use query content properly to ensure the correctness and efficiency of the query execution.  \n+ \n+### 1.3 Metadata\n+ \n+In the query optimization theory, metadata is external information that is used for optimization. Examples are \n+statistics, column uniqueness, data distribution, etc.\n+\n+In this document, we consider only partition distribution because this is the only metadata we use in our optimizer, \n+that is not part of the catalog, and that could change across query runs.\n+\n+Every plan is built for the specific partition distribution. That is, the distribution and participating members are saved \n+in the plan.\n+\n+The plan cache must be able to find and remove plans with obsolete partition distribution. \n+ \n+## 2. Design\n+\n+### 2.1 Plan Key\n+\n+The plan key is a key used to locate the cache plan. It should be possible to derive the key from the query before the \n+optimization phase. \n+\n+We use the following key:\n+```\n+PlanKey {\n+    List<List<String>> searchPaths;\n+    String sql;\n+}\n+```\n+`searchPaths` is the list of schemas that are used to resolve non-fully qualified objects during query parsing. Search paths\n+are created based on configured table resolvers, and the current schema. `sql` is a query string.   \n+\n+For the same catalog, two queries with the same search paths, and the same query string will always resolve the same objects. \n+On the contrary, the same query string may resolve different objects for different search paths, as shown in section 1.2. \n+Therefore, search paths must be part of the key.  \n+\n+### 2.2 Data Structure\n+\n+We use `ConcurrentHashMap` to store cached plans. `PlanKey` is a key, the plan is a value.\n+ \n+### 2.3 Maximum Size and Plan Eviction\n+\n+The maximum size of the cache is required to prevent out-of-memory if too many distinct queries are submitted.\n+\n+When a plan is added to the map, the map size is checked. If the map size is greater than the maximum size, some plans are \n+evicted. \n+\n+Eviction is synchronous because the asynchronous variant is prone to out-of-memory. We assume that for the most workloads \n+evictions should be rare. \n+\n+We use the LRU (least recently used) approach to find the plans to evict. Whenever a plan is accessed, it's `lastUsed` field is \n+updated with the current time. During the eviction, plans are sorted by their `lastUsed` values, and the least recently used\n+plans are removed.   \n+\n+### 2.4 Reacting to Catalog and Partition Distribution Changes\n+\n+If a catalog or partition distribution is changed, some plans must be invalidated. There are two different ways to achieve \n+this: `push` and `pull`.\n+\n+With the `push` approach, the plan cache is notified about a change, from the relevant component. E.g., if an index is created,\n+then the map service notifies the plan cache about the change. The advantage of this solution is that any change is reflected \n+in the plan cache immediately. However, this approach increases coupling, because many components (map service, \n+replicated map service, partition service) now have to be aware of the SQL subsystem. This approach also requires complex\n+synchronization between query optimizer, plan cache, and dependent components, to ensure that no stale plan is ever cached.\n+\n+With the `pull` approach, the SQL subsystem queries other components periodically, collects the changes, and invalidates \n+affected plans. The advantage of this approach is simplicity. No synchronization or changes to other components are needed. \n+Invalid plans are guaranteed to be removed eventually. The downside is that invalid plans might be active for some time after\n+the change has occurred.\n+\n+We choose the `pull` approach due to simplicity and sufficient guarantees. The background worker reconstructs the catalog \n+periodically, and verifies that existing plans are compatible with the current catalog and partition distribution. \n+\n+To counter the problem with outdated plans, we add a special `invalidatePlan` flag to `QueryException`. If an invalid plan\n+is used, an exception with this flag will be thrown at some point. When the initiator member receives an exception with \n+this flag, the plan is invalidated. \n+\n+Note that currently, users will have to re-execute the query in this case. In future versions, we will add a transparent\n+query retry, so that invalid plans will not be visible to users.    ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTExNDEzOQ=="}, "originalCommit": {"oid": "d1e5df9a208bfa6ad07eec638546a37376abc4dc"}, "originalPosition": 121}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTc0ODU2OQ==", "bodyText": "We will document error conditions in the manual, this is out of scope if this PR. Note that there is no such thing as \u201cplan\u201d or \u201cplan invalidation\u201d from the user perspective. Instead, there are some error conditions visible to users, such as map destroy or partition migration. They may lead to plan invalidation, which is purely internal thing. The improvement I mentioned (retries on plan invalidation), will help us hide such errors from users sometimes, but not always.", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r469748569", "createdAt": "2020-08-13T07:23:28Z", "author": {"login": "devozerov"}, "path": "docs/design/sql/06-plan-caching.md", "diffHunk": "@@ -0,0 +1,129 @@\n+# Plan Caching\n+\n+## Overview\n+\n+Optimization of a query may take considerable time. In many applications, the set of queries is fixed. Therefore, the result of \n+query optimization could be cached and reused. This document explains the design of the plan cache in the Hazelcast Mustang SQL\n+engine.\n+\n+In section 1 we discuss the high-level requirements to the plan cache. In section 2 we describe the design. \n+\n+## 1. Requirements\n+\n+We assume that the result of query optimization is deterministic. That is, the same query plan is produced for the same set of \n+inputs. The inputs of the query optimizer are:\n+1. Catalog (schemas, tables, indexes)\n+1. The original query: query string, current schema, and parameters \n+1. Metadata\n+\n+### 1.1 Catalog\n+\n+A  catalog is a set of objects that may participate in query execution. The catalog is often referred to as \"schema\" in \n+the literature. We use the term \"catalog\" to disambiguate from the logical object containers, which are also called \"schemas\".\n+ \n+The catalog has three types of objects. *Schema* is a logical container for other objects. *Table* is a relation backed\n+by some physical storage, such as an `IMap`. *Index* is an additional data structure of a table that speeds up the execution \n+of queries. The catalog is used to resolve objects mentioned in the query and choose the proper access method. \n+\n+If the catalog is changed, the plan created earlier might become invalid. For example, if the table is dropped, the execution \n+of the plan will produce an error. If a new index is added, the optimizer may pick a better access path.\n+\n+The plan cache must be able to find and remove plans that have become invalid after changing the catalog. \n+\n+### 1.2 Query\n+\n+The query consists of the query string, the current schema, and parameters. Each of them may influence the optimization result.\n+\n+The current schema affects object resolution. For example, the query `SELECT * FROM map` may refer to `IMap` or `ReplicatedMap`\n+depending on the current schema (`partitioned` or `replicated`). \n+\n+Parameter values may alter statistics derivation and access path selection. For example, `SELECT ... FROM sales WHERE region=?`\n+may have different optimal plans for regions `EMEA` and `APAC`.  \n+ \n+The plan cache must use query content properly to ensure the correctness and efficiency of the query execution.  \n+ \n+### 1.3 Metadata\n+ \n+In the query optimization theory, metadata is external information that is used for optimization. Examples are \n+statistics, column uniqueness, data distribution, etc.\n+\n+In this document, we consider only partition distribution because this is the only metadata we use in our optimizer, \n+that is not part of the catalog, and that could change across query runs.\n+\n+Every plan is built for the specific partition distribution. That is, the distribution and participating members are saved \n+in the plan.\n+\n+The plan cache must be able to find and remove plans with obsolete partition distribution. \n+ \n+## 2. Design\n+\n+### 2.1 Plan Key\n+\n+The plan key is a key used to locate the cache plan. It should be possible to derive the key from the query before the \n+optimization phase. \n+\n+We use the following key:\n+```\n+PlanKey {\n+    List<List<String>> searchPaths;\n+    String sql;\n+}\n+```\n+`searchPaths` is the list of schemas that are used to resolve non-fully qualified objects during query parsing. Search paths\n+are created based on configured table resolvers, and the current schema. `sql` is a query string.   \n+\n+For the same catalog, two queries with the same search paths, and the same query string will always resolve the same objects. \n+On the contrary, the same query string may resolve different objects for different search paths, as shown in section 1.2. \n+Therefore, search paths must be part of the key.  \n+\n+### 2.2 Data Structure\n+\n+We use `ConcurrentHashMap` to store cached plans. `PlanKey` is a key, the plan is a value.\n+ \n+### 2.3 Maximum Size and Plan Eviction\n+\n+The maximum size of the cache is required to prevent out-of-memory if too many distinct queries are submitted.\n+\n+When a plan is added to the map, the map size is checked. If the map size is greater than the maximum size, some plans are \n+evicted. \n+\n+Eviction is synchronous because the asynchronous variant is prone to out-of-memory. We assume that for the most workloads \n+evictions should be rare. \n+\n+We use the LRU (least recently used) approach to find the plans to evict. Whenever a plan is accessed, it's `lastUsed` field is \n+updated with the current time. During the eviction, plans are sorted by their `lastUsed` values, and the least recently used\n+plans are removed.   \n+\n+### 2.4 Reacting to Catalog and Partition Distribution Changes\n+\n+If a catalog or partition distribution is changed, some plans must be invalidated. There are two different ways to achieve \n+this: `push` and `pull`.\n+\n+With the `push` approach, the plan cache is notified about a change, from the relevant component. E.g., if an index is created,\n+then the map service notifies the plan cache about the change. The advantage of this solution is that any change is reflected \n+in the plan cache immediately. However, this approach increases coupling, because many components (map service, \n+replicated map service, partition service) now have to be aware of the SQL subsystem. This approach also requires complex\n+synchronization between query optimizer, plan cache, and dependent components, to ensure that no stale plan is ever cached.\n+\n+With the `pull` approach, the SQL subsystem queries other components periodically, collects the changes, and invalidates \n+affected plans. The advantage of this approach is simplicity. No synchronization or changes to other components are needed. \n+Invalid plans are guaranteed to be removed eventually. The downside is that invalid plans might be active for some time after\n+the change has occurred.\n+\n+We choose the `pull` approach due to simplicity and sufficient guarantees. The background worker reconstructs the catalog \n+periodically, and verifies that existing plans are compatible with the current catalog and partition distribution. \n+\n+To counter the problem with outdated plans, we add a special `invalidatePlan` flag to `QueryException`. If an invalid plan\n+is used, an exception with this flag will be thrown at some point. When the initiator member receives an exception with \n+this flag, the plan is invalidated. \n+\n+Note that currently, users will have to re-execute the query in this case. In future versions, we will add a transparent\n+query retry, so that invalid plans will not be visible to users.    ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTExNDEzOQ=="}, "originalCommit": {"oid": "d1e5df9a208bfa6ad07eec638546a37376abc4dc"}, "originalPosition": 121}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzMTM1MDU5OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/SqlServiceImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwOTo1MDozNVrOG_aJ6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNjowMjoxNlrOG_oJzQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTE0MTk5NQ==", "bodyText": "What is a reasoning behind this default?", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r469141995", "createdAt": "2020-08-12T09:50:35Z", "author": {"login": "petrpleshachkov"}, "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/SqlServiceImpl.java", "diffHunk": "@@ -51,6 +59,8 @@\n     /** Default state check frequency. */\n     private static final long STATE_CHECK_FREQUENCY = 1_000L;\n \n+    private static final int PLAN_CACHE_SIZE = 10_000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1e5df9a208bfa6ad07eec638546a37376abc4dc"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM3MTM0MQ==", "bodyText": "There is no precise reasoning around this default. The cache should be big enough to avoid evictions in most cases, and small enough to avoid excessive memory consumption for unfortunate workloads.\nTypical applications do not have many different queries. On the other hand, the memory consumed by each plan is not that big (around several KB), so there is not much sense to make the cache size too small.", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r469371341", "createdAt": "2020-08-12T16:02:16Z", "author": {"login": "devozerov"}, "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/SqlServiceImpl.java", "diffHunk": "@@ -51,6 +59,8 @@\n     /** Default state check frequency. */\n     private static final long STATE_CHECK_FREQUENCY = 1_000L;\n \n+    private static final int PLAN_CACHE_SIZE = 10_000;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTE0MTk5NQ=="}, "originalCommit": {"oid": "d1e5df9a208bfa6ad07eec638546a37376abc4dc"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzMTM2NDQ0OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/SqlServiceImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwOTo1NDozNVrOG_aS0g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNTozNDowNVrOG_m0Lw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTE0NDI3NA==", "bodyText": "What is the reasoning behind magic number 3 ?", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r469144274", "createdAt": "2020-08-12T09:54:35Z", "author": {"login": "petrpleshachkov"}, "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/SqlServiceImpl.java", "diffHunk": "@@ -242,4 +291,12 @@ private SqlOptimizer createOptimizer(NodeEngine nodeEngine) {\n             throw new HazelcastException(\"Failed to instantiate the optimizer class \" + className + \": \" + e.getMessage(), e);\n         }\n     }\n+\n+    private static List<TableResolver> createTableResolvers(NodeEngine nodeEngine) {\n+        List<TableResolver> res = new ArrayList<>(3);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1e5df9a208bfa6ad07eec638546a37376abc4dc"}, "originalPosition": 157}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM0OTQyMw==", "bodyText": "It makes no sense now. Removed.", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r469349423", "createdAt": "2020-08-12T15:34:05Z", "author": {"login": "devozerov"}, "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/SqlServiceImpl.java", "diffHunk": "@@ -242,4 +291,12 @@ private SqlOptimizer createOptimizer(NodeEngine nodeEngine) {\n             throw new HazelcastException(\"Failed to instantiate the optimizer class \" + className + \": \" + e.getMessage(), e);\n         }\n     }\n+\n+    private static List<TableResolver> createTableResolvers(NodeEngine nodeEngine) {\n+        List<TableResolver> res = new ArrayList<>(3);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTE0NDI3NA=="}, "originalCommit": {"oid": "d1e5df9a208bfa6ad07eec638546a37376abc4dc"}, "originalPosition": 157}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzMTM5MTc1OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/exec/scan/KeyValueIterator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxMDowMjoxNVrOG_ajTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNjowMjoyN1rOG_oKOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTE0ODQ5NA==", "bodyText": "Javadoc of the interface methods would be helpful.", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r469148494", "createdAt": "2020-08-12T10:02:15Z", "author": {"login": "petrpleshachkov"}, "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/exec/scan/KeyValueIterator.java", "diffHunk": "@@ -0,0 +1,27 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.exec.scan;\n+\n+/**\n+ * Iterator over key/value pairs.\n+ */\n+public interface KeyValueIterator {\n+    boolean tryAdvance();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1e5df9a208bfa6ad07eec638546a37376abc4dc"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM3MTQ0OA==", "bodyText": "Added JavaDoc.", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r469371448", "createdAt": "2020-08-12T16:02:27Z", "author": {"login": "devozerov"}, "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/exec/scan/KeyValueIterator.java", "diffHunk": "@@ -0,0 +1,27 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.exec.scan;\n+\n+/**\n+ * Iterator over key/value pairs.\n+ */\n+public interface KeyValueIterator {\n+    boolean tryAdvance();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTE0ODQ5NA=="}, "originalCommit": {"oid": "d1e5df9a208bfa6ad07eec638546a37376abc4dc"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzMTQzODUxOnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/plan/cache/CachedPlanInvalidationCallback.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxMDoxNjo1M1rOG_bAkg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNjowMjozNVrOG_oKig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTE1NTk4Ng==", "bodyText": "Javadoc", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r469155986", "createdAt": "2020-08-12T10:16:53Z", "author": {"login": "petrpleshachkov"}, "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/plan/cache/CachedPlanInvalidationCallback.java", "diffHunk": "@@ -0,0 +1,21 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.plan.cache;\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1e5df9a208bfa6ad07eec638546a37376abc4dc"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM3MTUzMA==", "bodyText": "Added JavaDoc.", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r469371530", "createdAt": "2020-08-12T16:02:35Z", "author": {"login": "devozerov"}, "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/plan/cache/CachedPlanInvalidationCallback.java", "diffHunk": "@@ -0,0 +1,21 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.plan.cache;\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTE1NTk4Ng=="}, "originalCommit": {"oid": "d1e5df9a208bfa6ad07eec638546a37376abc4dc"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzMTQ2Nzk2OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/plan/cache/PlanCache.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxMDoyNjowOVrOG_bTGg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNTo1ODozNFrOG_oAQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTE2MDczMA==", "bodyText": "Sorting on every put might be very expensive, have you considered to use ordered concurrent data structure (e.g. ConcurrentSkipListMap) for the cache to avoid this intermediate step?", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r469160730", "createdAt": "2020-08-12T10:26:09Z", "author": {"login": "petrpleshachkov"}, "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/plan/cache/PlanCache.java", "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.plan.cache;\n+\n+import java.util.TreeMap;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+/**\n+ * Cache for plans.\n+ */\n+public class PlanCache implements CachedPlanInvalidationCallback {\n+\n+    private final int maxSize;\n+    private final ConcurrentHashMap<PlanCacheKey, CacheablePlan> plans = new ConcurrentHashMap<>();\n+\n+    public PlanCache(int maxSize) {\n+        assert maxSize > 0;\n+\n+        this.maxSize = maxSize;\n+    }\n+\n+    public CacheablePlan get(PlanCacheKey key) {\n+        CacheablePlan plan = plans.get(key);\n+\n+        if (plan != null) {\n+            plan.onPlanUsed();\n+\n+            return plan;\n+        } else {\n+            return null;\n+        }\n+    }\n+\n+    public void put(PlanCacheKey key, CacheablePlan plan) {\n+        plans.put(key, plan);\n+\n+        plan.onPlanUsed();\n+\n+        shrinkIfNeeded();\n+    }\n+\n+    public void invalidate(CacheablePlan plan) {\n+        remove(plan);\n+    }\n+\n+    public void clear() {\n+        plans.clear();\n+    }\n+\n+    public int size() {\n+        return plans.size();\n+    }\n+\n+    public void check(PlanCheckContext context) {\n+        plans.values().removeIf(plan -> !plan.isPlanValid(context));\n+    }\n+\n+    private void shrinkIfNeeded() {\n+        int oversize = plans.size() - maxSize;\n+\n+        if (oversize <= 0) {\n+            return;\n+        }\n+\n+        // Sort plans according to their last used timestamps\n+        TreeMap<Long, CacheablePlan> sorted = new TreeMap<>();\n+\n+        for (CacheablePlan plan : plans.values()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1e5df9a208bfa6ad07eec638546a37376abc4dc"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTI3Mjk1NA==", "bodyText": "We had similar use case in Jet. What we did is that when the maximum number was exceeded, we sorted the data and deleted 100 items at once.", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r469272954", "createdAt": "2020-08-12T13:48:49Z", "author": {"login": "viliam-durina"}, "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/plan/cache/PlanCache.java", "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.plan.cache;\n+\n+import java.util.TreeMap;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+/**\n+ * Cache for plans.\n+ */\n+public class PlanCache implements CachedPlanInvalidationCallback {\n+\n+    private final int maxSize;\n+    private final ConcurrentHashMap<PlanCacheKey, CacheablePlan> plans = new ConcurrentHashMap<>();\n+\n+    public PlanCache(int maxSize) {\n+        assert maxSize > 0;\n+\n+        this.maxSize = maxSize;\n+    }\n+\n+    public CacheablePlan get(PlanCacheKey key) {\n+        CacheablePlan plan = plans.get(key);\n+\n+        if (plan != null) {\n+            plan.onPlanUsed();\n+\n+            return plan;\n+        } else {\n+            return null;\n+        }\n+    }\n+\n+    public void put(PlanCacheKey key, CacheablePlan plan) {\n+        plans.put(key, plan);\n+\n+        plan.onPlanUsed();\n+\n+        shrinkIfNeeded();\n+    }\n+\n+    public void invalidate(CacheablePlan plan) {\n+        remove(plan);\n+    }\n+\n+    public void clear() {\n+        plans.clear();\n+    }\n+\n+    public int size() {\n+        return plans.size();\n+    }\n+\n+    public void check(PlanCheckContext context) {\n+        plans.values().removeIf(plan -> !plan.isPlanValid(context));\n+    }\n+\n+    private void shrinkIfNeeded() {\n+        int oversize = plans.size() - maxSize;\n+\n+        if (oversize <= 0) {\n+            return;\n+        }\n+\n+        // Sort plans according to their last used timestamps\n+        TreeMap<Long, CacheablePlan> sorted = new TreeMap<>();\n+\n+        for (CacheablePlan plan : plans.values()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTE2MDczMA=="}, "originalCommit": {"oid": "d1e5df9a208bfa6ad07eec638546a37376abc4dc"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM2ODg5Nw==", "bodyText": "We assume that normally the number of plans is limited and normally should not exceed the maximum size. So the slow path is almost never invoked. If this happens, then a user is in trouble anyway, because planning takes significant time. For example, this may happen if a user uses literals with concatenation instead of parameters.\nThis assumption means that there is a high hit rate. We would like to make plan lookup as cheap as possible. Therefore, ConcurrentSkipListMap is not an option: we use LRU algorithm and with ConcurrentSkipListMap we would have to update this data structure on every access.", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r469368897", "createdAt": "2020-08-12T15:58:34Z", "author": {"login": "devozerov"}, "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/plan/cache/PlanCache.java", "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.plan.cache;\n+\n+import java.util.TreeMap;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+/**\n+ * Cache for plans.\n+ */\n+public class PlanCache implements CachedPlanInvalidationCallback {\n+\n+    private final int maxSize;\n+    private final ConcurrentHashMap<PlanCacheKey, CacheablePlan> plans = new ConcurrentHashMap<>();\n+\n+    public PlanCache(int maxSize) {\n+        assert maxSize > 0;\n+\n+        this.maxSize = maxSize;\n+    }\n+\n+    public CacheablePlan get(PlanCacheKey key) {\n+        CacheablePlan plan = plans.get(key);\n+\n+        if (plan != null) {\n+            plan.onPlanUsed();\n+\n+            return plan;\n+        } else {\n+            return null;\n+        }\n+    }\n+\n+    public void put(PlanCacheKey key, CacheablePlan plan) {\n+        plans.put(key, plan);\n+\n+        plan.onPlanUsed();\n+\n+        shrinkIfNeeded();\n+    }\n+\n+    public void invalidate(CacheablePlan plan) {\n+        remove(plan);\n+    }\n+\n+    public void clear() {\n+        plans.clear();\n+    }\n+\n+    public int size() {\n+        return plans.size();\n+    }\n+\n+    public void check(PlanCheckContext context) {\n+        plans.values().removeIf(plan -> !plan.isPlanValid(context));\n+    }\n+\n+    private void shrinkIfNeeded() {\n+        int oversize = plans.size() - maxSize;\n+\n+        if (oversize <= 0) {\n+            return;\n+        }\n+\n+        // Sort plans according to their last used timestamps\n+        TreeMap<Long, CacheablePlan> sorted = new TreeMap<>();\n+\n+        for (CacheablePlan plan : plans.values()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTE2MDczMA=="}, "originalCommit": {"oid": "d1e5df9a208bfa6ad07eec638546a37376abc4dc"}, "originalPosition": 82}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzMzE0Mjg1OnYy", "diffSide": "RIGHT", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/exec/scan/KeyValueIterator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNzoyOToxNVrOG_rXeA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QwNzo1Njo1N1rOHAAQdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQyMzk5Mg==", "bodyText": "A leftover?", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r469423992", "createdAt": "2020-08-12T17:29:15Z", "author": {"login": "viliam-durina"}, "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/exec/scan/KeyValueIterator.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.exec.scan;\n+\n+/**\n+ * Iterator over key/value pairs.\n+ */\n+public interface KeyValueIterator {\n+    /**\n+     * Advances the iterator to the next available record.\n+     * <p>\n+     * If the method has returned {@code true}, the key and the value could be accessed through\n+     * {@link #getKey()} and {@link #getValue()} respectively.\n+     *\n+     * @return {@code} t", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "be5f78b8654839186e97c07ff8b3c35c7042b18e"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTc2NjI2MQ==", "bodyText": "Yes, thanks for spotting this. Fixed.", "url": "https://github.com/hazelcast/hazelcast/pull/17278#discussion_r469766261", "createdAt": "2020-08-13T07:56:57Z", "author": {"login": "devozerov"}, "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/exec/scan/KeyValueIterator.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.exec.scan;\n+\n+/**\n+ * Iterator over key/value pairs.\n+ */\n+public interface KeyValueIterator {\n+    /**\n+     * Advances the iterator to the next available record.\n+     * <p>\n+     * If the method has returned {@code true}, the key and the value could be accessed through\n+     * {@link #getKey()} and {@link #getValue()} respectively.\n+     *\n+     * @return {@code} t", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQyMzk5Mg=="}, "originalCommit": {"oid": "be5f78b8654839186e97c07ff8b3c35c7042b18e"}, "originalPosition": 29}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 375, "cost": 1, "resetAt": "2021-11-12T20:28:25Z"}}}