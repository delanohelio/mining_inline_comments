{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg2MjY1MTA5", "number": 53350, "title": "Add logstash system index APIs", "bodyText": "This commit adds REST apis for logstash and its system index, .logstash, which is used to store pipelines for central management. The module adds new endpoints that enable CRUD operations\non the pipelines stored in the index.", "createdAt": "2020-03-10T17:22:16Z", "url": "https://github.com/elastic/elasticsearch/pull/53350", "merged": true, "mergeCommit": {"oid": "fb7471b32955c80f1fe850054d68d5b66aca2896"}, "closed": true, "closedAt": "2020-09-14T21:20:37Z", "author": {"login": "jaymode"}, "timelineItems": {"totalCount": 35, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcKav5DAH2gAyMzg2MjY1MTA5OjA0NWFhYWVkMmFjOGY1OTYzNzFkYWZlYmZhYzk4ZGJkZGVhNzdiMTU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdI5KX-gH2gAyMzg2MjY1MTA5OjExYzZhZmI0NDAwMzIzNzczOTQ2OTMxNmQ2YTkxNWZhMjU5OTE3MGQ=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "045aaaed2ac8f596371dafebfac98dbddea77b15", "author": {"user": {"login": "jaymode", "name": "Jay Modi"}}, "url": "https://github.com/elastic/elasticsearch/commit/045aaaed2ac8f596371dafebfac98dbddea77b15", "committedDate": "2020-03-04T17:55:10Z", "message": "Add logstash module with wrapped APIs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "742c6216b4bf508b5752da70953bd1e2b401b35a", "author": {"user": {"login": "jaymode", "name": "Jay Modi"}}, "url": "https://github.com/elastic/elasticsearch/commit/742c6216b4bf508b5752da70953bd1e2b401b35a", "committedDate": "2020-03-09T20:58:12Z", "message": "remove wrapped APIs and add dedicated logstash APIs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5328277cbac4864d927745eaad0bbefa57687013", "author": {"user": {"login": "jaymode", "name": "Jay Modi"}}, "url": "https://github.com/elastic/elasticsearch/commit/5328277cbac4864d927745eaad0bbefa57687013", "committedDate": "2020-03-10T14:49:16Z", "message": "Merge branch 'master' into logstash_system_index_plugin"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dd17265ff50a21fa0c1cb2dab80e64a8e3f68446", "author": {"user": {"login": "jaymode", "name": "Jay Modi"}}, "url": "https://github.com/elastic/elasticsearch/commit/dd17265ff50a21fa0c1cb2dab80e64a8e3f68446", "committedDate": "2020-03-10T18:55:50Z", "message": "merge with x-pack plugin"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c94574fac1f45a5ee54005a98ac5ba03a02872b9", "author": {"user": {"login": "jaymode", "name": "Jay Modi"}}, "url": "https://github.com/elastic/elasticsearch/commit/c94574fac1f45a5ee54005a98ac5ba03a02872b9", "committedDate": "2020-03-10T20:20:23Z", "message": "add system index access allowance"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d227480099926f5122329c60d250fd99cc09e9f1", "author": {"user": {"login": "jaymode", "name": "Jay Modi"}}, "url": "https://github.com/elastic/elasticsearch/commit/d227480099926f5122329c60d250fd99cc09e9f1", "committedDate": "2020-03-11T14:40:35Z", "message": "Merge branch 'master' into logstash_system_index_plugin"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a63f268e34c7811a10c463ac053e9889d9ae3e07", "author": {"user": {"login": "jaymode", "name": "Jay Modi"}}, "url": "https://github.com/elastic/elasticsearch/commit/a63f268e34c7811a10c463ac053e9889d9ae3e07", "committedDate": "2020-03-11T14:43:37Z", "message": "formatting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "922d3117dbd16e62267036789d6746f71de68f57", "author": {"user": {"login": "jaymode", "name": "Jay Modi"}}, "url": "https://github.com/elastic/elasticsearch/commit/922d3117dbd16e62267036789d6746f71de68f57", "committedDate": "2020-03-11T17:10:47Z", "message": "serialization tests and fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "765963d13695e256144f2a2e9cb5484c713c087d", "author": {"user": {"login": "jaymode", "name": "Jay Modi"}}, "url": "https://github.com/elastic/elasticsearch/commit/765963d13695e256144f2a2e9cb5484c713c087d", "committedDate": "2020-03-11T17:11:42Z", "message": "license"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b82253e1c0637fd7a05b7c329669ca488f5eb900", "author": {"user": {"login": "jaymode", "name": "Jay Modi"}}, "url": "https://github.com/elastic/elasticsearch/commit/b82253e1c0637fd7a05b7c329669ca488f5eb900", "committedDate": "2020-03-11T17:25:12Z", "message": "format"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bcfa925ee3d699e23f4e5596876f8d1089e961b7", "author": {"user": {"login": "jaymode", "name": "Jay Modi"}}, "url": "https://github.com/elastic/elasticsearch/commit/bcfa925ee3d699e23f4e5596876f8d1089e961b7", "committedDate": "2020-03-11T21:53:02Z", "message": "Merge branch 'master' into logstash_system_index_plugin"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc0NDY2Mjg4", "url": "https://github.com/elastic/elasticsearch/pull/53350#pullrequestreview-374466288", "createdAt": "2020-03-13T17:01:14Z", "commit": {"oid": "bcfa925ee3d699e23f4e5596876f8d1089e961b7"}, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xM1QxNzowMToxNVrOF2LgZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xM1QxNzoxODo0NFrOF2MEgw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjM1NTk0Mg==", "bodyText": "Aesthetic nitpick: Could we move this to an import so this is just extends ActionType<DeletePipelineResponse>?", "url": "https://github.com/elastic/elasticsearch/pull/53350#discussion_r392355942", "createdAt": "2020-03-13T17:01:15Z", "author": {"login": "gwbrown"}, "path": "x-pack/plugin/logstash/src/main/java/org/elasticsearch/xpack/logstash/action/DeletePipelineAction.java", "diffHunk": "@@ -0,0 +1,19 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.logstash.action;\n+\n+import org.elasticsearch.action.ActionType;\n+\n+public class DeletePipelineAction extends ActionType<org.elasticsearch.xpack.logstash.action.DeletePipelineResponse> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bcfa925ee3d699e23f4e5596876f8d1089e961b7"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjM1NjkxNA==", "bodyText": "Why not make this an AcknowledgedResponse?", "url": "https://github.com/elastic/elasticsearch/pull/53350#discussion_r392356914", "createdAt": "2020-03-13T17:03:04Z", "author": {"login": "gwbrown"}, "path": "x-pack/plugin/logstash/src/main/java/org/elasticsearch/xpack/logstash/action/DeletePipelineResponse.java", "diffHunk": "@@ -0,0 +1,36 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.logstash.action;\n+\n+import org.elasticsearch.action.ActionResponse;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+\n+import java.io.IOException;\n+\n+public class DeletePipelineResponse extends ActionResponse {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bcfa925ee3d699e23f4e5596876f8d1089e961b7"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjM1OTM4Ng==", "bodyText": "Given that Logstash.LOGSTASH_CONCRETE_INDEX_NAME is now public, why not use it here?", "url": "https://github.com/elastic/elasticsearch/pull/53350#discussion_r392359386", "createdAt": "2020-03-13T17:07:45Z", "author": {"login": "gwbrown"}, "path": "x-pack/plugin/logstash/src/main/java/org/elasticsearch/xpack/logstash/action/TransportGetPipelineAction.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.logstash.action;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.get.GetResponse;\n+import org.elasticsearch.action.get.MultiGetItemResponse;\n+import org.elasticsearch.action.search.ClearScrollRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.ActionFilters;\n+import org.elasticsearch.action.support.HandledTransportAction;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.search.SearchHit;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.tasks.Task;\n+import org.elasticsearch.transport.TransportService;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+public class TransportGetPipelineAction extends HandledTransportAction<GetPipelineRequest, GetPipelineResponse> {\n+\n+    private static final Logger logger = LogManager.getLogger(TransportGetPipelineAction.class);\n+    private final Client client;\n+\n+    @Inject\n+    public TransportGetPipelineAction(TransportService transportService, ActionFilters actionFilters, Client client) {\n+        super(GetPipelineAction.NAME, transportService, actionFilters, GetPipelineRequest::new);\n+        this.client = client;\n+    }\n+\n+    @Override\n+    protected void doExecute(Task task, GetPipelineRequest request, ActionListener<GetPipelineResponse> listener) {\n+        if (request.ids().isEmpty()) {\n+            client.prepareSearch(\".logstash\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bcfa925ee3d699e23f4e5596876f8d1089e961b7"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjM1OTY2OA==", "bodyText": "Same here about Logstash.LOGSTASH_CONCRETE_INDEX_NAME.", "url": "https://github.com/elastic/elasticsearch/pull/53350#discussion_r392359668", "createdAt": "2020-03-13T17:08:22Z", "author": {"login": "gwbrown"}, "path": "x-pack/plugin/logstash/src/main/java/org/elasticsearch/xpack/logstash/action/TransportGetPipelineAction.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.logstash.action;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.get.GetResponse;\n+import org.elasticsearch.action.get.MultiGetItemResponse;\n+import org.elasticsearch.action.search.ClearScrollRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.ActionFilters;\n+import org.elasticsearch.action.support.HandledTransportAction;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.search.SearchHit;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.tasks.Task;\n+import org.elasticsearch.transport.TransportService;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+public class TransportGetPipelineAction extends HandledTransportAction<GetPipelineRequest, GetPipelineResponse> {\n+\n+    private static final Logger logger = LogManager.getLogger(TransportGetPipelineAction.class);\n+    private final Client client;\n+\n+    @Inject\n+    public TransportGetPipelineAction(TransportService transportService, ActionFilters actionFilters, Client client) {\n+        super(GetPipelineAction.NAME, transportService, actionFilters, GetPipelineRequest::new);\n+        this.client = client;\n+    }\n+\n+    @Override\n+    protected void doExecute(Task task, GetPipelineRequest request, ActionListener<GetPipelineResponse> listener) {\n+        if (request.ids().isEmpty()) {\n+            client.prepareSearch(\".logstash\")\n+                .setSource(\n+                    SearchSourceBuilder.searchSource()\n+                        .fetchSource(true)\n+                        .query(QueryBuilders.matchAllQuery())\n+                        .size(1000)\n+                        .trackTotalHits(true)\n+                )\n+                .setScroll(TimeValue.timeValueMinutes(1L))\n+                .execute(ActionListener.wrap(searchResponse -> {\n+                    final int numHits = Math.toIntExact(searchResponse.getHits().getTotalHits().value);\n+                    final Map<String, BytesReference> pipelineSources = new HashMap<>(numHits);\n+                    final Consumer<SearchResponse> clearScroll = (response) -> {\n+                        if (response != null && response.getScrollId() != null) {\n+                            ClearScrollRequest clearScrollRequest = new ClearScrollRequest();\n+                            clearScrollRequest.addScrollId(response.getScrollId());\n+                            client.clearScroll(\n+                                clearScrollRequest,\n+                                ActionListener.wrap(\n+                                    (r) -> {},\n+                                    e -> logger.warn(\n+                                        new ParameterizedMessage(\"clear scroll failed for scroll id [{}]\", response.getScrollId()),\n+                                        e\n+                                    )\n+                                )\n+                            );\n+                        }\n+                    };\n+                    handleSearchResponse(searchResponse, pipelineSources, clearScroll, listener);\n+                }, listener::onFailure));\n+        } else if (request.ids().size() == 1) {\n+            client.prepareGet(\".logstash\", request.ids().get(0)).setFetchSource(true).execute(ActionListener.wrap(response -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bcfa925ee3d699e23f4e5596876f8d1089e961b7"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjM1OTg1MA==", "bodyText": "Same here about Logstash.LOGSTASH_CONCRETE_INDEX_NAME.", "url": "https://github.com/elastic/elasticsearch/pull/53350#discussion_r392359850", "createdAt": "2020-03-13T17:08:43Z", "author": {"login": "gwbrown"}, "path": "x-pack/plugin/logstash/src/main/java/org/elasticsearch/xpack/logstash/action/TransportGetPipelineAction.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.logstash.action;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.get.GetResponse;\n+import org.elasticsearch.action.get.MultiGetItemResponse;\n+import org.elasticsearch.action.search.ClearScrollRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.ActionFilters;\n+import org.elasticsearch.action.support.HandledTransportAction;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.search.SearchHit;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.tasks.Task;\n+import org.elasticsearch.transport.TransportService;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+public class TransportGetPipelineAction extends HandledTransportAction<GetPipelineRequest, GetPipelineResponse> {\n+\n+    private static final Logger logger = LogManager.getLogger(TransportGetPipelineAction.class);\n+    private final Client client;\n+\n+    @Inject\n+    public TransportGetPipelineAction(TransportService transportService, ActionFilters actionFilters, Client client) {\n+        super(GetPipelineAction.NAME, transportService, actionFilters, GetPipelineRequest::new);\n+        this.client = client;\n+    }\n+\n+    @Override\n+    protected void doExecute(Task task, GetPipelineRequest request, ActionListener<GetPipelineResponse> listener) {\n+        if (request.ids().isEmpty()) {\n+            client.prepareSearch(\".logstash\")\n+                .setSource(\n+                    SearchSourceBuilder.searchSource()\n+                        .fetchSource(true)\n+                        .query(QueryBuilders.matchAllQuery())\n+                        .size(1000)\n+                        .trackTotalHits(true)\n+                )\n+                .setScroll(TimeValue.timeValueMinutes(1L))\n+                .execute(ActionListener.wrap(searchResponse -> {\n+                    final int numHits = Math.toIntExact(searchResponse.getHits().getTotalHits().value);\n+                    final Map<String, BytesReference> pipelineSources = new HashMap<>(numHits);\n+                    final Consumer<SearchResponse> clearScroll = (response) -> {\n+                        if (response != null && response.getScrollId() != null) {\n+                            ClearScrollRequest clearScrollRequest = new ClearScrollRequest();\n+                            clearScrollRequest.addScrollId(response.getScrollId());\n+                            client.clearScroll(\n+                                clearScrollRequest,\n+                                ActionListener.wrap(\n+                                    (r) -> {},\n+                                    e -> logger.warn(\n+                                        new ParameterizedMessage(\"clear scroll failed for scroll id [{}]\", response.getScrollId()),\n+                                        e\n+                                    )\n+                                )\n+                            );\n+                        }\n+                    };\n+                    handleSearchResponse(searchResponse, pipelineSources, clearScroll, listener);\n+                }, listener::onFailure));\n+        } else if (request.ids().size() == 1) {\n+            client.prepareGet(\".logstash\", request.ids().get(0)).setFetchSource(true).execute(ActionListener.wrap(response -> {\n+                if (response.isExists()) {\n+                    listener.onResponse(new GetPipelineResponse(Map.of(response.getId(), response.getSourceAsBytesRef())));\n+                } else {\n+                    listener.onResponse(new GetPipelineResponse(Map.of()));\n+                }\n+            }, listener::onFailure));\n+        } else {\n+            client.prepareMultiGet()\n+                .addIds(\".logstash\", request.ids())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bcfa925ee3d699e23f4e5596876f8d1089e961b7"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjM2MDk3Mg==", "bodyText": "I'm not sure what to do instead, but if some of the GETs fail, do we really just want to silently swallow that? Should we at least log something here?", "url": "https://github.com/elastic/elasticsearch/pull/53350#discussion_r392360972", "createdAt": "2020-03-13T17:10:53Z", "author": {"login": "gwbrown"}, "path": "x-pack/plugin/logstash/src/main/java/org/elasticsearch/xpack/logstash/action/TransportGetPipelineAction.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.logstash.action;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.get.GetResponse;\n+import org.elasticsearch.action.get.MultiGetItemResponse;\n+import org.elasticsearch.action.search.ClearScrollRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.ActionFilters;\n+import org.elasticsearch.action.support.HandledTransportAction;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.search.SearchHit;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.tasks.Task;\n+import org.elasticsearch.transport.TransportService;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+public class TransportGetPipelineAction extends HandledTransportAction<GetPipelineRequest, GetPipelineResponse> {\n+\n+    private static final Logger logger = LogManager.getLogger(TransportGetPipelineAction.class);\n+    private final Client client;\n+\n+    @Inject\n+    public TransportGetPipelineAction(TransportService transportService, ActionFilters actionFilters, Client client) {\n+        super(GetPipelineAction.NAME, transportService, actionFilters, GetPipelineRequest::new);\n+        this.client = client;\n+    }\n+\n+    @Override\n+    protected void doExecute(Task task, GetPipelineRequest request, ActionListener<GetPipelineResponse> listener) {\n+        if (request.ids().isEmpty()) {\n+            client.prepareSearch(\".logstash\")\n+                .setSource(\n+                    SearchSourceBuilder.searchSource()\n+                        .fetchSource(true)\n+                        .query(QueryBuilders.matchAllQuery())\n+                        .size(1000)\n+                        .trackTotalHits(true)\n+                )\n+                .setScroll(TimeValue.timeValueMinutes(1L))\n+                .execute(ActionListener.wrap(searchResponse -> {\n+                    final int numHits = Math.toIntExact(searchResponse.getHits().getTotalHits().value);\n+                    final Map<String, BytesReference> pipelineSources = new HashMap<>(numHits);\n+                    final Consumer<SearchResponse> clearScroll = (response) -> {\n+                        if (response != null && response.getScrollId() != null) {\n+                            ClearScrollRequest clearScrollRequest = new ClearScrollRequest();\n+                            clearScrollRequest.addScrollId(response.getScrollId());\n+                            client.clearScroll(\n+                                clearScrollRequest,\n+                                ActionListener.wrap(\n+                                    (r) -> {},\n+                                    e -> logger.warn(\n+                                        new ParameterizedMessage(\"clear scroll failed for scroll id [{}]\", response.getScrollId()),\n+                                        e\n+                                    )\n+                                )\n+                            );\n+                        }\n+                    };\n+                    handleSearchResponse(searchResponse, pipelineSources, clearScroll, listener);\n+                }, listener::onFailure));\n+        } else if (request.ids().size() == 1) {\n+            client.prepareGet(\".logstash\", request.ids().get(0)).setFetchSource(true).execute(ActionListener.wrap(response -> {\n+                if (response.isExists()) {\n+                    listener.onResponse(new GetPipelineResponse(Map.of(response.getId(), response.getSourceAsBytesRef())));\n+                } else {\n+                    listener.onResponse(new GetPipelineResponse(Map.of()));\n+                }\n+            }, listener::onFailure));\n+        } else {\n+            client.prepareMultiGet()\n+                .addIds(\".logstash\", request.ids())\n+                .execute(\n+                    ActionListener.wrap(\n+                        mGetResponse -> listener.onResponse(\n+                            new GetPipelineResponse(\n+                                Arrays.stream(mGetResponse.getResponses())\n+                                    .filter(itemResponse -> itemResponse.isFailed() == false)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bcfa925ee3d699e23f4e5596876f8d1089e961b7"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjM2MTE5MQ==", "bodyText": "Same here about Logstash.LOGSTASH_CONCRETE_INDEX_NAME.", "url": "https://github.com/elastic/elasticsearch/pull/53350#discussion_r392361191", "createdAt": "2020-03-13T17:11:18Z", "author": {"login": "gwbrown"}, "path": "x-pack/plugin/logstash/src/main/java/org/elasticsearch/xpack/logstash/action/TransportPutPipelineAction.java", "diffHunk": "@@ -0,0 +1,39 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.logstash.action;\n+\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.support.ActionFilters;\n+import org.elasticsearch.action.support.HandledTransportAction;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.tasks.Task;\n+import org.elasticsearch.transport.TransportService;\n+\n+public class TransportPutPipelineAction extends HandledTransportAction<PutPipelineRequest, PutPipelineResponse> {\n+\n+    private final Client client;\n+\n+    @Inject\n+    public TransportPutPipelineAction(TransportService transportService, ActionFilters actionFilters, Client client) {\n+        super(PutPipelineAction.NAME, transportService, actionFilters, PutPipelineRequest::new);\n+        this.client = client;\n+    }\n+\n+    @Override\n+    protected void doExecute(Task task, PutPipelineRequest request, ActionListener<PutPipelineResponse> listener) {\n+        client.prepareIndex(\".logstash\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bcfa925ee3d699e23f4e5596876f8d1089e961b7"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjM2NTE4Nw==", "bodyText": "Weak recommendation: Break these out into AbstractWireSerializingTestCases and get equals/hashcode tests for free, plus make it a bit easier to find the tests for each class.", "url": "https://github.com/elastic/elasticsearch/pull/53350#discussion_r392365187", "createdAt": "2020-03-13T17:18:44Z", "author": {"login": "gwbrown"}, "path": "x-pack/plugin/logstash/src/test/java/org/elasticsearch/xpack/logstash/PipelineRequestResponseSerializationTests.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.logstash;\n+\n+import org.elasticsearch.common.bytes.BytesArray;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.io.stream.BytesStreamOutput;\n+import org.elasticsearch.common.xcontent.XContentType;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.xpack.logstash.action.DeletePipelineRequest;\n+import org.elasticsearch.xpack.logstash.action.DeletePipelineResponse;\n+import org.elasticsearch.xpack.logstash.action.GetPipelineRequest;\n+import org.elasticsearch.xpack.logstash.action.GetPipelineResponse;\n+import org.elasticsearch.xpack.logstash.action.PutPipelineRequest;\n+import org.elasticsearch.xpack.logstash.action.PutPipelineResponse;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+public class PipelineRequestResponseSerializationTests extends ESTestCase {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bcfa925ee3d699e23f4e5596876f8d1089e961b7"}, "originalPosition": 26}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "59583e243e0589d18035be3973733fc44bd35d8a", "author": {"user": {"login": "jaymode", "name": "Jay Modi"}}, "url": "https://github.com/elastic/elasticsearch/commit/59583e243e0589d18035be3973733fc44bd35d8a", "committedDate": "2020-07-22T17:25:53Z", "message": "Merge branch 'master' into logstash_system_index_plugin"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7fa4d07daadc6d0308d80d00668c79148ad46221", "author": {"user": {"login": "jaymode", "name": "Jay Modi"}}, "url": "https://github.com/elastic/elasticsearch/commit/7fa4d07daadc6d0308d80d00668c79148ad46221", "committedDate": "2020-07-22T17:35:09Z", "message": "fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c839bf7d8759790049d2f9762885259c735aaaa0", "author": {"user": {"login": "jaymode", "name": "Jay Modi"}}, "url": "https://github.com/elastic/elasticsearch/commit/c839bf7d8759790049d2f9762885259c735aaaa0", "committedDate": "2020-07-22T17:35:42Z", "message": "aesthetics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6a1be8cb80fadb6078dd0c8b913dec78ba0ed0c7", "author": {"user": {"login": "jaymode", "name": "Jay Modi"}}, "url": "https://github.com/elastic/elasticsearch/commit/6a1be8cb80fadb6078dd0c8b913dec78ba0ed0c7", "committedDate": "2020-07-22T17:38:48Z", "message": "constants"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1cac8880bec12bbc0033c68389d2eb2be4cfc44b", "author": {"user": {"login": "jaymode", "name": "Jay Modi"}}, "url": "https://github.com/elastic/elasticsearch/commit/1cac8880bec12bbc0033c68389d2eb2be4cfc44b", "committedDate": "2020-07-22T18:16:28Z", "message": "spotless"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "45d0040ed051e77e77592b3b2236038204a0805f", "author": {"user": {"login": "williamrandolph", "name": "William Brafford"}}, "url": "https://github.com/elastic/elasticsearch/commit/45d0040ed051e77e77592b3b2236038204a0805f", "committedDate": "2020-07-31T19:44:12Z", "message": "Merge branch 'master' into logstash_system_index_plugin"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9f075cb26ffa616185cc6cbb275d17af081aadb8", "author": {"user": {"login": "williamrandolph", "name": "William Brafford"}}, "url": "https://github.com/elastic/elasticsearch/commit/9f075cb26ffa616185cc6cbb275d17af081aadb8", "committedDate": "2020-08-03T19:18:22Z", "message": "Merge branch 'master' into logstash_system_index_plugin"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2b3d16e7dd4420f40513297b33e880fae318f27e", "author": {"user": {"login": "williamrandolph", "name": "William Brafford"}}, "url": "https://github.com/elastic/elasticsearch/commit/2b3d16e7dd4420f40513297b33e880fae318f27e", "committedDate": "2020-08-05T02:23:48Z", "message": "Break out serialization tests into distinct classes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0747a10804ba48feb3475f05a6637482ce0cbf70", "author": {"user": {"login": "williamrandolph", "name": "William Brafford"}}, "url": "https://github.com/elastic/elasticsearch/commit/0747a10804ba48feb3475f05a6637482ce0cbf70", "committedDate": "2020-08-05T02:24:32Z", "message": "Merge branch 'master' into logstash_system_index_plugin"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "02d1cdadbe2f53ab33cf79fb275514945e3d349a", "author": {"user": {"login": "williamrandolph", "name": "William Brafford"}}, "url": "https://github.com/elastic/elasticsearch/commit/02d1cdadbe2f53ab33cf79fb275514945e3d349a", "committedDate": "2020-08-05T11:53:46Z", "message": "Merge branch 'master' into logstash_system_index_plugin"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "de4060325b994f9f513e114c3f1f64214729dc1a", "author": {"user": {"login": "williamrandolph", "name": "William Brafford"}}, "url": "https://github.com/elastic/elasticsearch/commit/de4060325b994f9f513e114c3f1f64214729dc1a", "committedDate": "2020-08-05T20:29:07Z", "message": "Remove test of obsolete setting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0d11fb353290544ab5ffd5dbb4d9b8aeb72d25f0", "author": {"user": {"login": "williamrandolph", "name": "William Brafford"}}, "url": "https://github.com/elastic/elasticsearch/commit/0d11fb353290544ab5ffd5dbb4d9b8aeb72d25f0", "committedDate": "2020-08-12T18:06:06Z", "message": "Merge branch 'master' into logstash_system_index_plugin"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "453b2b1b97696d7248ebe2fa609a924037817466", "author": {"user": {"login": "williamrandolph", "name": "William Brafford"}}, "url": "https://github.com/elastic/elasticsearch/commit/453b2b1b97696d7248ebe2fa609a924037817466", "committedDate": "2020-08-13T00:51:52Z", "message": "Add test for pipeline multiget logic"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bc529ac7bdfe83948c8b9c68029902db337278e0", "author": {"user": {"login": "williamrandolph", "name": "William Brafford"}}, "url": "https://github.com/elastic/elasticsearch/commit/bc529ac7bdfe83948c8b9c68029902db337278e0", "committedDate": "2020-08-13T20:59:28Z", "message": "Log failures for partial multiget failure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "435df7b5afd4f9be33f2a5eecd325d83794c40b7", "author": {"user": {"login": "williamrandolph", "name": "William Brafford"}}, "url": "https://github.com/elastic/elasticsearch/commit/435df7b5afd4f9be33f2a5eecd325d83794c40b7", "committedDate": "2020-08-14T19:22:26Z", "message": "Clean up and add comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fa51c6270d6ca57129cf0464b25504c06ff26ed9", "author": {"user": {"login": "williamrandolph", "name": "William Brafford"}}, "url": "https://github.com/elastic/elasticsearch/commit/fa51c6270d6ca57129cf0464b25504c06ff26ed9", "committedDate": "2020-08-18T16:23:51Z", "message": "Fix Javadoc"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0e998033e4118013a48fcc3b5a14ef0e1c385355", "author": {"user": {"login": "williamrandolph", "name": "William Brafford"}}, "url": "https://github.com/elastic/elasticsearch/commit/0e998033e4118013a48fcc3b5a14ef0e1c385355", "committedDate": "2020-08-18T17:39:07Z", "message": "Merge branch 'master' into logstash_system_index_plugin"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc3MTI4MTIw", "url": "https://github.com/elastic/elasticsearch/pull/53350#pullrequestreview-477128120", "createdAt": "2020-08-27T22:31:23Z", "commit": {"oid": "0e998033e4118013a48fcc3b5a14ef0e1c385355"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QyMjozMToyM1rOHIjcfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QyMzowODoyOVrOHIkNCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODczMTM4OQ==", "bodyText": "I don't think we need to change it for this API given it'll only be used by Logstash, but generally we're trying to move away from having dynamic keys like this because it makes API specs difficult to write.\n(no action item here, just to spread information)", "url": "https://github.com/elastic/elasticsearch/pull/53350#discussion_r478731389", "createdAt": "2020-08-27T22:31:23Z", "author": {"login": "gwbrown"}, "path": "x-pack/plugin/logstash/src/main/java/org/elasticsearch/xpack/logstash/action/GetPipelineResponse.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.logstash.action;\n+\n+import org.elasticsearch.action.ActionResponse;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+\n+import java.io.IOException;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.Objects;\n+\n+public class GetPipelineResponse extends ActionResponse implements ToXContentObject {\n+\n+    private final Map<String, BytesReference> pipelines;\n+\n+    public GetPipelineResponse(Map<String, BytesReference> pipelines) {\n+        this.pipelines = pipelines;\n+    }\n+\n+    public GetPipelineResponse(StreamInput in) throws IOException {\n+        super(in);\n+        this.pipelines = in.readMap(StreamInput::readString, StreamInput::readBytesReference);\n+    }\n+\n+    public Map<String, BytesReference> pipelines() {\n+        return pipelines;\n+    }\n+\n+    @Override\n+    public void writeTo(StreamOutput out) throws IOException {\n+        out.writeMap(pipelines, StreamOutput::writeString, StreamOutput::writeBytesReference);\n+    }\n+\n+    @Override\n+    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n+        builder.startObject();\n+        for (Entry<String, BytesReference> entry : pipelines.entrySet()) {\n+            builder.rawField(entry.getKey(), entry.getValue().streamInput());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0e998033e4118013a48fcc3b5a14ef0e1c385355"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODczNzU5MA==", "bodyText": "You can remove this comment, the refresh API will allow system index access by default.", "url": "https://github.com/elastic/elasticsearch/pull/53350#discussion_r478737590", "createdAt": "2020-08-27T22:49:59Z", "author": {"login": "gwbrown"}, "path": "x-pack/plugin/src/test/java/org/elasticsearch/xpack/test/rest/LogstashSystemIndexIT.java", "diffHunk": "@@ -0,0 +1,184 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.test.rest;\n+\n+import org.apache.http.util.EntityUtils;\n+import org.elasticsearch.client.Request;\n+import org.elasticsearch.client.Response;\n+import org.elasticsearch.client.ResponseException;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.ThreadContext;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.XContentType;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.test.rest.ESRestTestCase;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.xpack.test.rest.XPackRestIT.BASIC_AUTH_VALUE;\n+import static org.hamcrest.Matchers.containsString;\n+import static org.hamcrest.Matchers.is;\n+\n+public class LogstashSystemIndexIT extends ESRestTestCase {\n+\n+    @Override\n+    protected Settings restClientSettings() {\n+        return Settings.builder()\n+            .put(ThreadContext.PREFIX + \".Authorization\", BASIC_AUTH_VALUE)\n+            .build();\n+    }\n+\n+    public void testTemplateIsPut() throws Exception {\n+        assertBusy(\n+            () -> assertThat(\n+                client().performRequest(new Request(\"HEAD\", \"/_template/.logstash-management\")).getStatusLine().getStatusCode(),\n+                is(200)\n+            )\n+        );\n+    }\n+\n+    public void testPipelineCRUD() throws Exception {\n+        // put pipeline\n+        final String pipelineJson = getPipelineJson();\n+        createPipeline(\"test_pipeline\", pipelineJson);\n+\n+        // get pipeline\n+        Request getRequest = new Request(\"GET\", \"/_logstash/pipeline/test_pipeline\");\n+        Response getResponse = client().performRequest(getRequest);\n+        assertThat(getResponse.getStatusLine().getStatusCode(), is(200));\n+        assertThat(EntityUtils.toString(getResponse.getEntity()), containsString(pipelineJson));\n+\n+        // update\n+        final String updatedJson = getPipelineJson(\"2020-03-09T15:42:35.229Z\");\n+        Request putRequest = new Request(\"PUT\", \"/_logstash/pipeline/test_pipeline\");\n+        putRequest.setJsonEntity(updatedJson);\n+        Response putResponse = client().performRequest(putRequest);\n+        assertThat(putResponse.getStatusLine().getStatusCode(), is(200));\n+\n+        getRequest = new Request(\"GET\", \"/_logstash/pipeline/test_pipeline\");\n+        getResponse = client().performRequest(getRequest);\n+        assertThat(getResponse.getStatusLine().getStatusCode(), is(200));\n+        assertThat(EntityUtils.toString(getResponse.getEntity()), containsString(updatedJson));\n+\n+        // delete\n+        Request deleteRequest = new Request(\"DELETE\", \"/_logstash/pipeline/test_pipeline\");\n+        Response deleteResponse = client().performRequest(deleteRequest);\n+        assertThat(deleteResponse.getStatusLine().getStatusCode(), is(200));\n+\n+        // list is now empty\n+        Request listAll = new Request(\"GET\", \"/_logstash/pipeline\");\n+        Response listAllResponse = client().performRequest(listAll);\n+        assertThat(listAllResponse.getStatusLine().getStatusCode(), is(200));\n+        assertThat(EntityUtils.toString(listAllResponse.getEntity()), is(\"{}\"));\n+    }\n+\n+    public void testGetNonExistingPipeline() {\n+        Request getRequest = new Request(\"GET\", \"/_logstash/pipeline/test_pipeline\");\n+        ResponseException re = expectThrows(ResponseException.class, () -> client().performRequest(getRequest));\n+        Response getResponse = re.getResponse();\n+        assertThat(getResponse.getStatusLine().getStatusCode(), is(404));\n+    }\n+\n+    public void testDeleteNonExistingPipeline() {\n+        Request deleteRequest = new Request(\"DELETE\", \"/_logstash/pipeline/test_pipeline\");\n+        ResponseException re = expectThrows(ResponseException.class, () -> client().performRequest(deleteRequest));\n+        Response getResponse = re.getResponse();\n+        assertThat(getResponse.getStatusLine().getStatusCode(), is(404));\n+    }\n+\n+    public void testMultiplePipelines() throws IOException {\n+        final int numPipelines = scaledRandomIntBetween(2, 2000);\n+        final List<String> ids = new ArrayList<>(numPipelines);\n+        final String pipelineJson = getPipelineJson();\n+        for (int i = 0; i < numPipelines; i++) {\n+            final String id = \"id\" + i;\n+            ids.add(id);\n+            createPipeline(id, pipelineJson);\n+        }\n+\n+        // test mget-like\n+        final int numToGet = scaledRandomIntBetween(2, Math.min(100, numPipelines)); // limit number to avoid HTTP line length issues\n+        final List<String> mgetIds = randomSubsetOf(numToGet, ids);\n+        final String path = \"/_logstash/pipeline/\" + Strings.collectionToCommaDelimitedString(mgetIds);\n+        Request getRequest = new Request(\"GET\", path);\n+        Response getResponse = client().performRequest(getRequest);\n+        assertThat(getResponse.getStatusLine().getStatusCode(), is(200));\n+        Map<String, Object> responseMap = XContentHelper.convertToMap(\n+            XContentType.JSON.xContent(),\n+            EntityUtils.toString(getResponse.getEntity()),\n+            false\n+        );\n+\n+        for (String id : mgetIds) {\n+            assertTrue(responseMap.containsKey(id));\n+        }\n+\n+        // TODO need to update this after system indices are truly system indices to enable refresh", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0e998033e4118013a48fcc3b5a14ef0e1c385355"}, "originalPosition": 126}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODc0MzgxOA==", "bodyText": "Can you make these request/response tests implement mutateInstance as well? That's required to automatically check .equals() for the case of an object of the same type that's not equal.", "url": "https://github.com/elastic/elasticsearch/pull/53350#discussion_r478743818", "createdAt": "2020-08-27T23:08:29Z", "author": {"login": "gwbrown"}, "path": "x-pack/plugin/logstash/src/test/java/org/elasticsearch/xpack/logstash/action/DeletePipelineRequestTests.java", "diffHunk": "@@ -0,0 +1,23 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.logstash.action;\n+\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.test.AbstractWireSerializingTestCase;\n+\n+public class DeletePipelineRequestTests extends AbstractWireSerializingTestCase<DeletePipelineRequest> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0e998033e4118013a48fcc3b5a14ef0e1c385355"}, "originalPosition": 12}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "505104be5986f2e7890e0ef3265825d6109d05fe", "author": {"user": {"login": "williamrandolph", "name": "William Brafford"}}, "url": "https://github.com/elastic/elasticsearch/commit/505104be5986f2e7890e0ef3265825d6109d05fe", "committedDate": "2020-09-09T18:25:51Z", "message": "Merge branch 'master' into logstash_system_index_plugin"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b734883c7cd6e91fab4d18f8e6e68186f67658e7", "author": {"user": {"login": "williamrandolph", "name": "William Brafford"}}, "url": "https://github.com/elastic/elasticsearch/commit/b734883c7cd6e91fab4d18f8e6e68186f67658e7", "committedDate": "2020-09-10T17:20:07Z", "message": "Move LogstashSystemIndexIT to javaRestTest task"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "551a789e20a0a111f9697e7bad7fe3c0683ed8fb", "author": {"user": {"login": "williamrandolph", "name": "William Brafford"}}, "url": "https://github.com/elastic/elasticsearch/commit/551a789e20a0a111f9697e7bad7fe3c0683ed8fb", "committedDate": "2020-09-10T21:17:58Z", "message": "Respond to PR feedback"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5f8a4c3aa409d5dd4165bcbccfd0e5733bb799fe", "author": {"user": {"login": "williamrandolph", "name": "William Brafford"}}, "url": "https://github.com/elastic/elasticsearch/commit/5f8a4c3aa409d5dd4165bcbccfd0e5733bb799fe", "committedDate": "2020-09-10T21:37:10Z", "message": "Remove unused imports, apply spotless"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "11c6afb44003237739469316d6a915fa2599170d", "author": {"user": {"login": "williamrandolph", "name": "William Brafford"}}, "url": "https://github.com/elastic/elasticsearch/commit/11c6afb44003237739469316d6a915fa2599170d", "committedDate": "2020-09-14T20:24:33Z", "message": "Merge branch 'master' into logstash_system_index_plugin"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1696, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}