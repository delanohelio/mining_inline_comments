{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ4OTc1NDIx", "number": 59552, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNjoxMDoxOFrOEOU_mg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNjoxMzoyMFrOEOVEVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNDU5NDgyOnYy", "diffSide": "LEFT", "path": "docs/reference/eql/eql-search-api.asciidoc", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNjoxMDoxOFrOGxazKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNjoxMTowOVrOGxa1gA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ3MjQ5MQ==", "bodyText": "@jrodewig removed return of sort.", "url": "https://github.com/elastic/elasticsearch/pull/59552#discussion_r454472491", "createdAt": "2020-07-14T16:10:18Z", "author": {"login": "costin"}, "path": "docs/reference/eql/eql-search-api.asciidoc", "diffHunk": "@@ -564,10 +564,7 @@ the events in ascending, lexicographic order.\n             \"name\": \"cmd.exe\",\n             \"path\": \"C:\\\\Windows\\\\System32\\\\cmd.exe\"\n           }\n-        },\n-        \"sort\": [", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb9a5168b2f1ac91ad5f4448a2bd2ba0340279e7"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ3MzA4OA==", "bodyText": "Thanks for the heads up!", "url": "https://github.com/elastic/elasticsearch/pull/59552#discussion_r454473088", "createdAt": "2020-07-14T16:11:09Z", "author": {"login": "jrodewig"}, "path": "docs/reference/eql/eql-search-api.asciidoc", "diffHunk": "@@ -564,10 +564,7 @@ the events in ascending, lexicographic order.\n             \"name\": \"cmd.exe\",\n             \"path\": \"C:\\\\Windows\\\\System32\\\\cmd.exe\"\n           }\n-        },\n-        \"sort\": [", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ3MjQ5MQ=="}, "originalCommit": {"oid": "fb9a5168b2f1ac91ad5f4448a2bd2ba0340279e7"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNDYwMDE5OnYy", "diffSide": "RIGHT", "path": "docs/reference/eql/search.asciidoc", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNjoxMTozOVrOGxa2tw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNjoxOToyOVrOGxbLHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ3MzM5OQ==", "bodyText": "@jrodewig since I've removed the fields from the results, I had to remove this whole section (the two fields are essentially used only internally and get removed before being returned).", "url": "https://github.com/elastic/elasticsearch/pull/59552#discussion_r454473399", "createdAt": "2020-07-14T16:11:39Z", "author": {"login": "costin"}, "path": "docs/reference/eql/search.asciidoc", "diffHunk": "@@ -495,15 +477,7 @@ GET /sec_logs/_eql/search\n ----\n // TEST[s/search/search\\?filter_path\\=\\-\\*\\.events\\.\\*fields/]\n \n-The API returns the following response. Note the `sort` property of each\n-matching event contains an array of two items:\n-\n-* The first item is the event's <<eql-search-api-timestamp-field,timestamp>>,\n-converted to milliseconds since the https://en.wikipedia.org/wiki/Unix_time[Unix\n-epoch].\n-\n-* The second item is the event's `event.id` value. This value is used as a sort\n-tiebreaker for events with the same timestamp.\n+The API returns the following response.\n ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb9a5168b2f1ac91ad5f4448a2bd2ba0340279e7"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ3ODYyMA==", "bodyText": "That works. I can review the docs after this PR merges.", "url": "https://github.com/elastic/elasticsearch/pull/59552#discussion_r454478620", "createdAt": "2020-07-14T16:19:29Z", "author": {"login": "jrodewig"}, "path": "docs/reference/eql/search.asciidoc", "diffHunk": "@@ -495,15 +477,7 @@ GET /sec_logs/_eql/search\n ----\n // TEST[s/search/search\\?filter_path\\=\\-\\*\\.events\\.\\*fields/]\n \n-The API returns the following response. Note the `sort` property of each\n-matching event contains an array of two items:\n-\n-* The first item is the event's <<eql-search-api-timestamp-field,timestamp>>,\n-converted to milliseconds since the https://en.wikipedia.org/wiki/Unix_time[Unix\n-epoch].\n-\n-* The second item is the event's `event.id` value. This value is used as a sort\n-tiebreaker for events with the same timestamp.\n+The API returns the following response.\n ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ3MzM5OQ=="}, "originalCommit": {"oid": "fb9a5168b2f1ac91ad5f4448a2bd2ba0340279e7"}, "originalPosition": 95}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNDYwNTYxOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/search/BasicQueryClient.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNjoxMjo1OFrOGxa6CQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxODoxMTowM1rOGxfcIw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ3NDI0OQ==", "bodyText": "@jrodewig Normally these need to be set as well however I didn't want to make this PR longer. For event queries we do return these fields however the docs doesn't include them for sequences.\nConsidering the tight deadline, not sure what's the easiest fix until the next release?", "url": "https://github.com/elastic/elasticsearch/pull/59552#discussion_r454474249", "createdAt": "2020-07-14T16:12:58Z", "author": {"login": "costin"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/search/BasicQueryClient.java", "diffHunk": "@@ -49,4 +67,69 @@ public void query(QueryRequest request, ActionListener<Payload> listener) {\n         SearchRequest search = prepareRequest(client, searchSource, false, indices);\n         client.search(search, new BasicListener(listener));\n     }\n-}\n+\n+    @Override\n+    public void get(Iterable<List<HitReference>> refs, ActionListener<List<List<SearchHit>>> listener) {\n+        MultiGetRequestBuilder requestBuilder = client.prepareMultiGet();\n+        // no need for real-time\n+        requestBuilder.setRealtime(false)\n+                      .setRefresh(false);\n+\n+        int sz = 0;\n+\n+        for (List<HitReference> list : refs) {\n+            sz = list.size();\n+            for (HitReference ref : list) {\n+                Item item = new Item(ref.index(), ref.id());\n+                // make sure to get the whole source\n+                item.fetchSourceContext(FetchSourceContext.FETCH_SOURCE);\n+                requestBuilder.add(item);\n+            }\n+        }\n+        \n+        final int listSize = sz;\n+        client.multiGet(requestBuilder.request(), wrap(r -> {\n+            List<List<SearchHit>> hits = new ArrayList<>(r.getResponses().length / listSize);\n+            \n+            List<SearchHit> sequence = new ArrayList<>(listSize);\n+            \n+            // copy streams - reused across the whole loop\n+            PipedInputStream in = new PipedInputStream();\n+            PipedOutputStream out = new PipedOutputStream(in);\n+            StreamOutput so = new OutputStreamStreamOutput(out);\n+            StreamInput si = new InputStreamStreamInput(in);\n+\n+            int counter = 0;\n+            for (MultiGetItemResponse mgr : r.getResponses()) {\n+                if (mgr.isFailed()) {\n+                    listener.onFailure(mgr.getFailure().getFailure());\n+                    return;\n+                }\n+                // HACK: the only way to get GetResult is to serialize it and then load it back :(\n+                mgr.getResponse().writeTo(so);\n+                GetResult result = new GetResult(si);\n+\n+                SearchHit hit = new SearchHit(-1, result.getId(), result.getDocumentFields(), result.getMetadataFields());\n+                hit.sourceRef(result.internalSourceRef());\n+                // need to create these objects to set the index\n+                hit.shard(new SearchShardTarget(null, new ShardId(result.getIndex(), \"\", -1), null, null));\n+\n+                //hit.setSeqNo(result.getSeqNo());\n+                //hit.setPrimaryTerm(result.getPrimaryTerm());\n+                //hit.version(result.getVersion());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb9a5168b2f1ac91ad5f4448a2bd2ba0340279e7"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ4MDk3OA==", "bodyText": "Just add a // TESTRESPONSE[skip: response format changed] to any failing response for now.\nThat should skip the CI tests for it. I can go in an fix up any skipped test responses as part of a follow-up PR.", "url": "https://github.com/elastic/elasticsearch/pull/59552#discussion_r454480978", "createdAt": "2020-07-14T16:23:01Z", "author": {"login": "jrodewig"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/search/BasicQueryClient.java", "diffHunk": "@@ -49,4 +67,69 @@ public void query(QueryRequest request, ActionListener<Payload> listener) {\n         SearchRequest search = prepareRequest(client, searchSource, false, indices);\n         client.search(search, new BasicListener(listener));\n     }\n-}\n+\n+    @Override\n+    public void get(Iterable<List<HitReference>> refs, ActionListener<List<List<SearchHit>>> listener) {\n+        MultiGetRequestBuilder requestBuilder = client.prepareMultiGet();\n+        // no need for real-time\n+        requestBuilder.setRealtime(false)\n+                      .setRefresh(false);\n+\n+        int sz = 0;\n+\n+        for (List<HitReference> list : refs) {\n+            sz = list.size();\n+            for (HitReference ref : list) {\n+                Item item = new Item(ref.index(), ref.id());\n+                // make sure to get the whole source\n+                item.fetchSourceContext(FetchSourceContext.FETCH_SOURCE);\n+                requestBuilder.add(item);\n+            }\n+        }\n+        \n+        final int listSize = sz;\n+        client.multiGet(requestBuilder.request(), wrap(r -> {\n+            List<List<SearchHit>> hits = new ArrayList<>(r.getResponses().length / listSize);\n+            \n+            List<SearchHit> sequence = new ArrayList<>(listSize);\n+            \n+            // copy streams - reused across the whole loop\n+            PipedInputStream in = new PipedInputStream();\n+            PipedOutputStream out = new PipedOutputStream(in);\n+            StreamOutput so = new OutputStreamStreamOutput(out);\n+            StreamInput si = new InputStreamStreamInput(in);\n+\n+            int counter = 0;\n+            for (MultiGetItemResponse mgr : r.getResponses()) {\n+                if (mgr.isFailed()) {\n+                    listener.onFailure(mgr.getFailure().getFailure());\n+                    return;\n+                }\n+                // HACK: the only way to get GetResult is to serialize it and then load it back :(\n+                mgr.getResponse().writeTo(so);\n+                GetResult result = new GetResult(si);\n+\n+                SearchHit hit = new SearchHit(-1, result.getId(), result.getDocumentFields(), result.getMetadataFields());\n+                hit.sourceRef(result.internalSourceRef());\n+                // need to create these objects to set the index\n+                hit.shard(new SearchShardTarget(null, new ShardId(result.getIndex(), \"\", -1), null, null));\n+\n+                //hit.setSeqNo(result.getSeqNo());\n+                //hit.setPrimaryTerm(result.getPrimaryTerm());\n+                //hit.version(result.getVersion());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ3NDI0OQ=="}, "originalCommit": {"oid": "fb9a5168b2f1ac91ad5f4448a2bd2ba0340279e7"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ5MjU1OQ==", "bodyText": "I skipped affected docs tests here: 4c3a6bf and f778181\nI un-commented these lines and also tested locally to check that the docs snippet CI passed. You can add these to the response if wanted and the CI shouldn't fail.", "url": "https://github.com/elastic/elasticsearch/pull/59552#discussion_r454492559", "createdAt": "2020-07-14T16:40:52Z", "author": {"login": "jrodewig"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/search/BasicQueryClient.java", "diffHunk": "@@ -49,4 +67,69 @@ public void query(QueryRequest request, ActionListener<Payload> listener) {\n         SearchRequest search = prepareRequest(client, searchSource, false, indices);\n         client.search(search, new BasicListener(listener));\n     }\n-}\n+\n+    @Override\n+    public void get(Iterable<List<HitReference>> refs, ActionListener<List<List<SearchHit>>> listener) {\n+        MultiGetRequestBuilder requestBuilder = client.prepareMultiGet();\n+        // no need for real-time\n+        requestBuilder.setRealtime(false)\n+                      .setRefresh(false);\n+\n+        int sz = 0;\n+\n+        for (List<HitReference> list : refs) {\n+            sz = list.size();\n+            for (HitReference ref : list) {\n+                Item item = new Item(ref.index(), ref.id());\n+                // make sure to get the whole source\n+                item.fetchSourceContext(FetchSourceContext.FETCH_SOURCE);\n+                requestBuilder.add(item);\n+            }\n+        }\n+        \n+        final int listSize = sz;\n+        client.multiGet(requestBuilder.request(), wrap(r -> {\n+            List<List<SearchHit>> hits = new ArrayList<>(r.getResponses().length / listSize);\n+            \n+            List<SearchHit> sequence = new ArrayList<>(listSize);\n+            \n+            // copy streams - reused across the whole loop\n+            PipedInputStream in = new PipedInputStream();\n+            PipedOutputStream out = new PipedOutputStream(in);\n+            StreamOutput so = new OutputStreamStreamOutput(out);\n+            StreamInput si = new InputStreamStreamInput(in);\n+\n+            int counter = 0;\n+            for (MultiGetItemResponse mgr : r.getResponses()) {\n+                if (mgr.isFailed()) {\n+                    listener.onFailure(mgr.getFailure().getFailure());\n+                    return;\n+                }\n+                // HACK: the only way to get GetResult is to serialize it and then load it back :(\n+                mgr.getResponse().writeTo(so);\n+                GetResult result = new GetResult(si);\n+\n+                SearchHit hit = new SearchHit(-1, result.getId(), result.getDocumentFields(), result.getMetadataFields());\n+                hit.sourceRef(result.internalSourceRef());\n+                // need to create these objects to set the index\n+                hit.shard(new SearchShardTarget(null, new ShardId(result.getIndex(), \"\", -1), null, null));\n+\n+                //hit.setSeqNo(result.getSeqNo());\n+                //hit.setPrimaryTerm(result.getPrimaryTerm());\n+                //hit.version(result.getVersion());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ3NDI0OQ=="}, "originalCommit": {"oid": "fb9a5168b2f1ac91ad5f4448a2bd2ba0340279e7"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU0ODUxNQ==", "bodyText": "Thanks @jrodewig. I've removed the comments for said lines - let's see what the build thinks of it.", "url": "https://github.com/elastic/elasticsearch/pull/59552#discussion_r454548515", "createdAt": "2020-07-14T18:11:03Z", "author": {"login": "costin"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/search/BasicQueryClient.java", "diffHunk": "@@ -49,4 +67,69 @@ public void query(QueryRequest request, ActionListener<Payload> listener) {\n         SearchRequest search = prepareRequest(client, searchSource, false, indices);\n         client.search(search, new BasicListener(listener));\n     }\n-}\n+\n+    @Override\n+    public void get(Iterable<List<HitReference>> refs, ActionListener<List<List<SearchHit>>> listener) {\n+        MultiGetRequestBuilder requestBuilder = client.prepareMultiGet();\n+        // no need for real-time\n+        requestBuilder.setRealtime(false)\n+                      .setRefresh(false);\n+\n+        int sz = 0;\n+\n+        for (List<HitReference> list : refs) {\n+            sz = list.size();\n+            for (HitReference ref : list) {\n+                Item item = new Item(ref.index(), ref.id());\n+                // make sure to get the whole source\n+                item.fetchSourceContext(FetchSourceContext.FETCH_SOURCE);\n+                requestBuilder.add(item);\n+            }\n+        }\n+        \n+        final int listSize = sz;\n+        client.multiGet(requestBuilder.request(), wrap(r -> {\n+            List<List<SearchHit>> hits = new ArrayList<>(r.getResponses().length / listSize);\n+            \n+            List<SearchHit> sequence = new ArrayList<>(listSize);\n+            \n+            // copy streams - reused across the whole loop\n+            PipedInputStream in = new PipedInputStream();\n+            PipedOutputStream out = new PipedOutputStream(in);\n+            StreamOutput so = new OutputStreamStreamOutput(out);\n+            StreamInput si = new InputStreamStreamInput(in);\n+\n+            int counter = 0;\n+            for (MultiGetItemResponse mgr : r.getResponses()) {\n+                if (mgr.isFailed()) {\n+                    listener.onFailure(mgr.getFailure().getFailure());\n+                    return;\n+                }\n+                // HACK: the only way to get GetResult is to serialize it and then load it back :(\n+                mgr.getResponse().writeTo(so);\n+                GetResult result = new GetResult(si);\n+\n+                SearchHit hit = new SearchHit(-1, result.getId(), result.getDocumentFields(), result.getMetadataFields());\n+                hit.sourceRef(result.internalSourceRef());\n+                // need to create these objects to set the index\n+                hit.shard(new SearchShardTarget(null, new ShardId(result.getIndex(), \"\", -1), null, null));\n+\n+                //hit.setSeqNo(result.getSeqNo());\n+                //hit.setPrimaryTerm(result.getPrimaryTerm());\n+                //hit.version(result.getVersion());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ3NDI0OQ=="}, "originalCommit": {"oid": "fb9a5168b2f1ac91ad5f4448a2bd2ba0340279e7"}, "originalPosition": 88}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNDYwNjk1OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/sequence/SequenceMatcher.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNjoxMzoyMFrOGxa67g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNjoyMzoxNFrOGxbU4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ3NDQ3OA==", "bodyText": "Need to remove this as well.", "url": "https://github.com/elastic/elasticsearch/pull/59552#discussion_r454474478", "createdAt": "2020-07-14T16:13:20Z", "author": {"login": "costin"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/sequence/SequenceMatcher.java", "diffHunk": "@@ -207,14 +206,19 @@ public boolean hasCandidates(int stage) {\n         return false;\n     }\n \n-    public Payload payload(long startTime) {\n-        TimeValue tookTime = new TimeValue(System.currentTimeMillis() - startTime);\n-        List<Sequence> view = limit != null ? limit.view(completed) : completed;\n-        Payload p = new SequencePayload(view, false, tookTime);\n-        clear();\n-        return p;\n+\n+    public List<Sequence> completed() {\n+        return limit != null ? limit.view(completed) : completed;\n     }\n \n+    //    public Payload payload(long startTime) {\n+    //        TimeValue tookTime = new TimeValue(System.currentTimeMillis() - startTime);\n+    //\n+    //        Payload p = new SequencePayload(view, false, tookTime);\n+    //        clear();\n+    //        return p;\n+    //    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb9a5168b2f1ac91ad5f4448a2bd2ba0340279e7"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ4MTEyMw==", "bodyText": "// TESTRESPONSE[skip: response format changed] should work here too. I can fix this as part of a follow-up PR.", "url": "https://github.com/elastic/elasticsearch/pull/59552#discussion_r454481123", "createdAt": "2020-07-14T16:23:14Z", "author": {"login": "jrodewig"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/sequence/SequenceMatcher.java", "diffHunk": "@@ -207,14 +206,19 @@ public boolean hasCandidates(int stage) {\n         return false;\n     }\n \n-    public Payload payload(long startTime) {\n-        TimeValue tookTime = new TimeValue(System.currentTimeMillis() - startTime);\n-        List<Sequence> view = limit != null ? limit.view(completed) : completed;\n-        Payload p = new SequencePayload(view, false, tookTime);\n-        clear();\n-        return p;\n+\n+    public List<Sequence> completed() {\n+        return limit != null ? limit.view(completed) : completed;\n     }\n \n+    //    public Payload payload(long startTime) {\n+    //        TimeValue tookTime = new TimeValue(System.currentTimeMillis() - startTime);\n+    //\n+    //        Payload p = new SequencePayload(view, false, tookTime);\n+    //        clear();\n+    //        return p;\n+    //    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ3NDQ3OA=="}, "originalCommit": {"oid": "fb9a5168b2f1ac91ad5f4448a2bd2ba0340279e7"}, "originalPosition": 65}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2295, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}