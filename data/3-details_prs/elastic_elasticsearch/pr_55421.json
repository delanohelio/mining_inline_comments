{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA1MzQ0OTg2", "number": 55421, "title": "Fix security manager bug writing large blobs to GCS", "bodyText": "This commit addresses a security manager permissions issue writing large blobs (on the resumable upload path) to GCS. The underlying issue here is that we need to wrap the close and write calls on the channel. It is not enough to do this:\nSocketAccess.doPrivilegedVoidIOException(\n  () -> Streams.copy(\n    inputStream,\n    Channels.newOutputStream(client().writer(blobInfo, writeOptions))));\nThis reason that this is not enough is because Streams#copy will be in the stacktrace and it is not granted the security manager permissions needed to close or write this channel. We only grant those permissions to classes loaded in the plugin classloader, and Streams#copy is from the parent classloader. This is why we must wrap the close and write calls as privileged, to truncate the Streams#copy call out of the stacktrace.\nThe reason that this issue is not caught in testing is because the size of data that we use in testing is too small to trigger the large blob resumable upload path. Therefore, we address this by adding a system property to control the threshold, which we can then set in tests to exercise this code path. Prior to rewriting the writeBlobResumable method to wrap the close and write calls as privileged, with this additional test, we are able to reproduce the security manager permissions issue. After adding the wrapping, this test now passes.\nRelates #51596", "createdAt": "2020-04-17T21:18:54Z", "url": "https://github.com/elastic/elasticsearch/pull/55421", "merged": true, "mergeCommit": {"oid": "a10b25e185a5f5918b5bbb460cc27c5baa8ebad7"}, "closed": true, "closedAt": "2020-04-17T22:48:35Z", "author": {"login": "jasontedor"}, "timelineItems": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcYoAmDgH2gAyNDA1MzQ0OTg2OjdkZjlkNzg5MzdkMmI2OTI4YzQyZjU5MGZhYjcwZDY2MWRhZjg4OTI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcYoLUlAH2gAyNDA1MzQ0OTg2OmNjM2Q5YTMxNWQ3ZWQ1NDBmMTI0MDRhNzUwODhlMDZjM2Q0ZDdlZjU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "7df9d78937d2b6928c42f590fab70d661daf8892", "author": {"user": {"login": "jasontedor", "name": "Jason Tedor"}}, "url": "https://github.com/elastic/elasticsearch/commit/7df9d78937d2b6928c42f590fab70d661daf8892", "committedDate": "2020-04-17T21:17:07Z", "message": "Fix security manager bug writing large blobs to GCS\n\nThis commit addresses a security manager permissions issue writing large\nblobs (on the resumable upload path) to GCS. The underlying issue here\nis that we need to wrap the close and write calls on the channel. It is\nnot enough to do this:\n\nSocketAccess.doPrivilegedVoidIOException(\n  () -> Streams.copy(\n    inputStream,\n    Channels.newOutputStream(client().writer(blobInfo, writeOptions))));\n\nThis reason that this is not enough is because Streams#copy will be in\nthe stacktrace and it is not granted the security manager permissions\nneeded to close or write this channel. We only grant those permissions\nto classes loaded in the plugin classloader, and Streams#copy is from\nthe parent classloader. This is why we must wrap the close and write\ncalls as privileged, to truncate the Streams#copy call out of the\nstacktrace.\n\nThe reason that this issue is not caught in testing is because the size\nof data that we use in testing is too small to trigger the large blob\nresumable upload path. Therefore, we address this by adding a system\nproperty to control the threshold, which we can then set in tests to\nexercise this code path. Prior to rewriting the writeBlobResumable\nmethod to wrap the close and write calls as privileged, with this\nadditional test, we are able to reproduce the security manager\npermissions issue. After adding the wrapping, this test now passes."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk1NzgwNzk4", "url": "https://github.com/elastic/elasticsearch/pull/55421#pullrequestreview-395780798", "createdAt": "2020-04-17T21:22:49Z", "commit": {"oid": "7df9d78937d2b6928c42f590fab70d661daf8892"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QyMToyMjo0OVrOGHdf6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QyMToyMjo0OVrOGHdf6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDQ3NjUyMw==", "bodyText": "leftover debugging?", "url": "https://github.com/elastic/elasticsearch/pull/55421#discussion_r410476523", "createdAt": "2020-04-17T21:22:49Z", "author": {"login": "rjernst"}, "path": "plugins/repository-gcs/src/main/java/org/elasticsearch/repositories/gcs/GoogleCloudStorageBlobStore.java", "diffHunk": "@@ -68,7 +73,29 @@\n     // request. Larger files should be uploaded over multiple requests (this is\n     // called \"resumable upload\")\n     // https://cloud.google.com/storage/docs/json_api/v1/how-tos/resumable-upload\n-    public static final int LARGE_BLOB_THRESHOLD_BYTE_SIZE = 5 * 1024 * 1024;\n+    public static final int LARGE_BLOB_THRESHOLD_BYTE_SIZE;\n+\n+    static {\n+        final String key = \"es.repository_gcs.large_blob_threshold_byte_size\";\n+        final String largeBlobThresholdByteSizeProperty = System.getProperty(key);\n+        if (largeBlobThresholdByteSizeProperty == null) {\n+            LARGE_BLOB_THRESHOLD_BYTE_SIZE = Math.toIntExact(new ByteSizeValue(5, ByteSizeUnit.MB).getBytes());\n+        } else {\n+            if (true) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7df9d78937d2b6928c42f590fab70d661daf8892"}, "originalPosition": 37}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8ad5470a7d4b051cf2ddb71e276555fd4efc759f", "author": {"user": {"login": "jasontedor", "name": "Jason Tedor"}}, "url": "https://github.com/elastic/elasticsearch/commit/8ad5470a7d4b051cf2ddb71e276555fd4efc759f", "committedDate": "2020-04-17T21:26:13Z", "message": "Fix forbidden APIs issue"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cc3d9a315d7ed540f12404a75088e06c3d4d7ef5", "author": {"user": {"login": "jasontedor", "name": "Jason Tedor"}}, "url": "https://github.com/elastic/elasticsearch/commit/cc3d9a315d7ed540f12404a75088e06c3d4d7ef5", "committedDate": "2020-04-17T21:28:50Z", "message": "Remove leftover debugging"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3304, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}