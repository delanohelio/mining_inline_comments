{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI3NzI3Mjg5", "number": 65520, "reviewThreads": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yN1QwNjoxMzoxMlrOE93sHA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xM1QxMzo0ODozMlrOFEqCdg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMzMzExMDA0OnYy", "diffSide": "LEFT", "path": "server/src/internalClusterTest/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderIT.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yN1QwNjoxMzoxMlrOH6yG1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yN1QwNjoxMzoxMlrOH6yG1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTQwMDQwNw==", "bodyText": "The changes in this class does not need review, they are contained in #65540 and will be merged before this is merged.", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r531400407", "createdAt": "2020-11-27T06:13:12Z", "author": {"login": "henningandersen"}, "path": "server/src/internalClusterTest/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderIT.java", "diffHunk": "@@ -37,107 +34,47 @@\n import org.elasticsearch.cluster.routing.allocation.decider.EnableAllocationDecider.Rebalance;\n import org.elasticsearch.cluster.service.ClusterService;\n import org.elasticsearch.common.Priority;\n-import org.elasticsearch.common.io.PathUtils;\n-import org.elasticsearch.common.io.PathUtilsForTesting;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.unit.ByteSizeUnit;\n import org.elasticsearch.common.unit.ByteSizeValue;\n-import org.elasticsearch.core.internal.io.IOUtils;\n-import org.elasticsearch.env.Environment;\n import org.elasticsearch.env.NodeEnvironment;\n-import org.elasticsearch.monitor.fs.FsService;\n-import org.elasticsearch.plugins.Plugin;\n import org.elasticsearch.repositories.fs.FsRepository;\n import org.elasticsearch.snapshots.RestoreInfo;\n import org.elasticsearch.snapshots.SnapshotInfo;\n import org.elasticsearch.snapshots.SnapshotState;\n import org.elasticsearch.test.ESIntegTestCase;\n-import org.elasticsearch.test.InternalSettingsPlugin;\n import org.hamcrest.Matcher;\n-import org.junit.After;\n-import org.junit.Before;\n-\n-import java.io.FileNotFoundException;\n-import java.io.IOException;\n-import java.nio.file.DirectoryStream;\n-import java.nio.file.FileStore;\n-import java.nio.file.FileSystem;\n-import java.nio.file.Files;\n-import java.nio.file.NoSuchFileException;\n-import java.nio.file.NotDirectoryException;\n-import java.nio.file.Path;\n+\n import java.util.Arrays;\n-import java.util.Collection;\n import java.util.HashSet;\n-import java.util.List;\n import java.util.Locale;\n-import java.util.Map;\n import java.util.Set;\n import java.util.concurrent.TimeUnit;\n-import java.util.stream.Collectors;\n import java.util.stream.StreamSupport;\n \n-import static org.elasticsearch.common.util.concurrent.ConcurrentCollections.newConcurrentMap;\n import static org.elasticsearch.index.store.Store.INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING;\n import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;\n-import static org.hamcrest.Matchers.anyOf;\n import static org.hamcrest.Matchers.empty;\n import static org.hamcrest.Matchers.equalTo;\n-import static org.hamcrest.Matchers.greaterThan;\n import static org.hamcrest.Matchers.hasSize;\n import static org.hamcrest.Matchers.is;\n \n @ESIntegTestCase.ClusterScope(scope = ESIntegTestCase.Scope.TEST, numDataNodes = 0)\n-public class DiskThresholdDeciderIT extends ESIntegTestCase {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e36f6e86d89699ffe9505b43df7e690b646f30c5"}, "originalPosition": 73}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMzMzExMDI5OnYy", "diffSide": "RIGHT", "path": "test/framework/src/main/java/org/elasticsearch/cluster/DiskUsageIntegTestCase.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yN1QwNjoxMzoyNlrOH6yHAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yN1QwNjoxMzoyNlrOH6yHAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTQwMDQ0OA==", "bodyText": "The changes in this class does not need review, they are contained in #65540 and will be merged before this is merged.", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r531400448", "createdAt": "2020-11-27T06:13:26Z", "author": {"login": "henningandersen"}, "path": "test/framework/src/main/java/org/elasticsearch/cluster/DiskUsageIntegTestCase.java", "diffHunk": "@@ -0,0 +1,236 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.cluster;\n+\n+import org.apache.lucene.mockfile.FilterFileStore;\n+import org.apache.lucene.mockfile.FilterFileSystemProvider;\n+import org.apache.lucene.mockfile.FilterPath;\n+import org.apache.lucene.util.Constants;\n+import org.elasticsearch.common.io.PathUtils;\n+import org.elasticsearch.common.io.PathUtilsForTesting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.core.internal.io.IOUtils;\n+import org.elasticsearch.env.Environment;\n+import org.elasticsearch.monitor.fs.FsService;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.test.ESIntegTestCase;\n+import org.elasticsearch.test.InternalSettingsPlugin;\n+import org.junit.After;\n+import org.junit.Before;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.nio.file.DirectoryStream;\n+import java.nio.file.FileStore;\n+import java.nio.file.FileSystem;\n+import java.nio.file.Files;\n+import java.nio.file.NoSuchFileException;\n+import java.nio.file.NotDirectoryException;\n+import java.nio.file.Path;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import static org.elasticsearch.common.util.concurrent.ConcurrentCollections.newConcurrentMap;\n+import static org.hamcrest.Matchers.anyOf;\n+import static org.hamcrest.Matchers.greaterThan;\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.is;\n+\n+/**\n+ * An integration test case that allows mocking the disk usage per node. Notice that only files count towards disk usage and translog and\n+ * state files are disregarded.\n+ */\n+public class DiskUsageIntegTestCase extends ESIntegTestCase {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e36f6e86d89699ffe9505b43df7e690b646f30c5"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQwNDIzMTYzOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/capacity/AutoscalingDeciderContext.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xM1QxMzoyMDo1NVrOIE0cXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xM1QxNjo1NjowM1rOIE2xjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyNDQ0Ng==", "bodyText": "Could you add Javadocs to these new methods, and also state?", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541924446", "createdAt": "2020-12-13T13:20:55Z", "author": {"login": "jasontedor"}, "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/capacity/AutoscalingDeciderContext.java", "diffHunk": "@@ -24,4 +26,8 @@\n      * Return the nodes governed by the policy.\n      */\n     Set<DiscoveryNode> nodes();\n+\n+    ClusterInfo info();\n+\n+    SnapshotShardSizeInfo snapshotShardSizeInfo();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f28fb9a0ed9cc82720505c884887107b0cb96270"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTk2MjYzOQ==", "bodyText": "\ud83d\udc4d, 22456be", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541962639", "createdAt": "2020-12-13T16:56:03Z", "author": {"login": "henningandersen"}, "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/capacity/AutoscalingDeciderContext.java", "diffHunk": "@@ -24,4 +26,8 @@\n      * Return the nodes governed by the policy.\n      */\n     Set<DiscoveryNode> nodes();\n+\n+    ClusterInfo info();\n+\n+    SnapshotShardSizeInfo snapshotShardSizeInfo();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyNDQ0Ng=="}, "originalCommit": {"oid": "f28fb9a0ed9cc82720505c884887107b0cb96270"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQwNDIzOTA2OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xM1QxMzoyNTozNVrOIE0fnw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xM1QxNjo1NjozNVrOIE2x2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyNTI3OQ==", "bodyText": "We'll probably want a test that collects all the roles that return true for DiscoveryNodeRole#canContainData and ensure they are returned in this list. I'm thinking of when we add a role for frozen, ensuring that this list is maintained properly.", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541925279", "createdAt": "2020-12-13T13:25:35Z", "author": {"login": "jasontedor"}, "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.ClusterInfo;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.DiskUsage;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.cluster.routing.allocation.decider.Decision;\n+import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.snapshots.SnapshotShardSizeInfo;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class ReactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"reactive_storage\";\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ReactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<Setting<?>> deciderSettings() {\n+        return List.of();\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(\n+            DiscoveryNodeRole.DATA_ROLE,\n+            DataTier.DATA_CONTENT_NODE_ROLE,\n+            DataTier.DATA_HOT_NODE_ROLE,\n+            DataTier.DATA_WARM_NODE_ROLE,\n+            DataTier.DATA_COLD_NODE_ROLE", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f28fb9a0ed9cc82720505c884887107b0cb96270"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTk2MjcxMw==", "bodyText": "\ud83d\udc4d, 555991a", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541962713", "createdAt": "2020-12-13T16:56:35Z", "author": {"login": "henningandersen"}, "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.ClusterInfo;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.DiskUsage;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.cluster.routing.allocation.decider.Decision;\n+import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.snapshots.SnapshotShardSizeInfo;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class ReactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"reactive_storage\";\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ReactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<Setting<?>> deciderSettings() {\n+        return List.of();\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(\n+            DiscoveryNodeRole.DATA_ROLE,\n+            DataTier.DATA_CONTENT_NODE_ROLE,\n+            DataTier.DATA_HOT_NODE_ROLE,\n+            DataTier.DATA_WARM_NODE_ROLE,\n+            DataTier.DATA_COLD_NODE_ROLE", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyNTI3OQ=="}, "originalCommit": {"oid": "f28fb9a0ed9cc82720505c884887107b0cb96270"}, "originalPosition": 75}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQwNDI0Njg1OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xM1QxMzozMDo0NlrOIE0jHg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xM1QxMzozMDo0NlrOIE0jHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyNjE3NA==", "bodyText": "\ud83d\udc4d", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541926174", "createdAt": "2020-12-13T13:30:46Z", "author": {"login": "jasontedor"}, "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.ClusterInfo;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.DiskUsage;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.cluster.routing.allocation.decider.Decision;\n+import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.snapshots.SnapshotShardSizeInfo;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class ReactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"reactive_storage\";\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ReactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<Setting<?>> deciderSettings() {\n+        return List.of();\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(\n+            DiscoveryNodeRole.DATA_ROLE,\n+            DataTier.DATA_CONTENT_NODE_ROLE,\n+            DataTier.DATA_HOT_NODE_ROLE,\n+            DataTier.DATA_WARM_NODE_ROLE,\n+            DataTier.DATA_COLD_NODE_ROLE\n+        );\n+    }\n+\n+    @Override\n+    public AutoscalingDeciderResult scale(Settings configuration, AutoscalingDeciderContext context) {\n+        AutoscalingCapacity autoscalingCapacity = context.currentCapacity();\n+        if (autoscalingCapacity == null || autoscalingCapacity.total().storage() == null) {\n+            return new AutoscalingDeciderResult(null, new ReactiveReason(\"current capacity not available\", -1, -1));\n+        }\n+\n+        AllocationState allocationState = new AllocationState(context, diskThresholdSettings, allocationDeciders);\n+        long unassigned = allocationState.storagePreventsAllocation();\n+        long assigned = allocationState.storagePreventsRemainOrMove();\n+        long maxShard = allocationState.maxShardSize();\n+        assert assigned >= 0;\n+        assert unassigned >= 0;\n+        assert maxShard >= 0;\n+        String message = unassigned > 0 || assigned > 0 ? \"not enough storage available, needs \" + (unassigned + assigned) : \"storage ok\";\n+        AutoscalingCapacity requiredCapacity = AutoscalingCapacity.builder()\n+            .total(autoscalingCapacity.total().storage().getBytes() + unassigned + assigned, null)\n+            .node(maxShard, null)\n+            .build();\n+        return new AutoscalingDeciderResult(requiredCapacity, new ReactiveReason(message, unassigned, assigned));\n+    }\n+\n+    static boolean isDiskOnlyNoDecision(Decision decision) {\n+        // we consider throttling==yes, throttling should be temporary.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f28fb9a0ed9cc82720505c884887107b0cb96270"}, "originalPosition": 102}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQwNDI2NTEyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xM1QxMzo0MjoyNVrOIE0rRw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xM1QxNjo1Njo1N1rOIE2yOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyODI2Mw==", "bodyText": "Can you leave a comment explaining why we need to enable allocation debugging here?", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541928263", "createdAt": "2020-12-13T13:42:25Z", "author": {"login": "jasontedor"}, "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.ClusterInfo;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.DiskUsage;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.cluster.routing.allocation.decider.Decision;\n+import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.snapshots.SnapshotShardSizeInfo;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class ReactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"reactive_storage\";\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ReactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<Setting<?>> deciderSettings() {\n+        return List.of();\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(\n+            DiscoveryNodeRole.DATA_ROLE,\n+            DataTier.DATA_CONTENT_NODE_ROLE,\n+            DataTier.DATA_HOT_NODE_ROLE,\n+            DataTier.DATA_WARM_NODE_ROLE,\n+            DataTier.DATA_COLD_NODE_ROLE\n+        );\n+    }\n+\n+    @Override\n+    public AutoscalingDeciderResult scale(Settings configuration, AutoscalingDeciderContext context) {\n+        AutoscalingCapacity autoscalingCapacity = context.currentCapacity();\n+        if (autoscalingCapacity == null || autoscalingCapacity.total().storage() == null) {\n+            return new AutoscalingDeciderResult(null, new ReactiveReason(\"current capacity not available\", -1, -1));\n+        }\n+\n+        AllocationState allocationState = new AllocationState(context, diskThresholdSettings, allocationDeciders);\n+        long unassigned = allocationState.storagePreventsAllocation();\n+        long assigned = allocationState.storagePreventsRemainOrMove();\n+        long maxShard = allocationState.maxShardSize();\n+        assert assigned >= 0;\n+        assert unassigned >= 0;\n+        assert maxShard >= 0;\n+        String message = unassigned > 0 || assigned > 0 ? \"not enough storage available, needs \" + (unassigned + assigned) : \"storage ok\";\n+        AutoscalingCapacity requiredCapacity = AutoscalingCapacity.builder()\n+            .total(autoscalingCapacity.total().storage().getBytes() + unassigned + assigned, null)\n+            .node(maxShard, null)\n+            .build();\n+        return new AutoscalingDeciderResult(requiredCapacity, new ReactiveReason(message, unassigned, assigned));\n+    }\n+\n+    static boolean isDiskOnlyNoDecision(Decision decision) {\n+        // we consider throttling==yes, throttling should be temporary.\n+        List<Decision> nos = decision.getDecisions()\n+            .stream()\n+            .filter(single -> single.type() == Decision.Type.NO)\n+            .collect(Collectors.toList());\n+        return nos.size() == 1 && DiskThresholdDecider.NAME.equals(nos.get(0).label());\n+    }\n+\n+    static class AllocationState {\n+        private final ClusterState state;\n+        private final AllocationDeciders allocationDeciders;\n+        private final DiskThresholdSettings diskThresholdSettings;\n+        private final ClusterInfo info;\n+        private final SnapshotShardSizeInfo shardSizeInfo;\n+        private final Predicate<DiscoveryNode> nodeTierPredicate;\n+        private final Set<DiscoveryNode> nodes;\n+\n+        AllocationState(\n+            AutoscalingDeciderContext context,\n+            DiskThresholdSettings diskThresholdSettings,\n+            AllocationDeciders allocationDeciders\n+        ) {\n+            this(\n+                context.state(),\n+                allocationDeciders,\n+                diskThresholdSettings,\n+                context.info(),\n+                context.snapshotShardSizeInfo(),\n+                context.nodes()\n+            );\n+        }\n+\n+        AllocationState(\n+            ClusterState state,\n+            AllocationDeciders allocationDeciders,\n+            DiskThresholdSettings diskThresholdSettings,\n+            ClusterInfo info,\n+            SnapshotShardSizeInfo shardSizeInfo,\n+            Set<DiscoveryNode> nodes\n+        ) {\n+            this.state = state;\n+            this.allocationDeciders = allocationDeciders;\n+            this.diskThresholdSettings = diskThresholdSettings;\n+            this.info = info;\n+            this.shardSizeInfo = shardSizeInfo;\n+            this.nodes = nodes;\n+            this.nodeTierPredicate = nodes::contains;\n+        }\n+\n+        public long storagePreventsAllocation() {\n+            RoutingNodes routingNodes = new RoutingNodes(state, false);\n+            RoutingAllocation allocation = new RoutingAllocation(\n+                allocationDeciders,\n+                routingNodes,\n+                state,\n+                info,\n+                shardSizeInfo,\n+                System.nanoTime()\n+            );\n+            return StreamSupport.stream(state.getRoutingNodes().unassigned().spliterator(), false)\n+                .filter(shard -> canAllocate(shard, allocation) == false)\n+                .filter(shard -> cannotAllocateDueToStorage(shard, allocation))\n+                .mapToLong(this::sizeOf)\n+                .sum();\n+        }\n+\n+        public long storagePreventsRemainOrMove() {\n+            RoutingNodes routingNodes = new RoutingNodes(state, false);\n+            RoutingAllocation allocation = new RoutingAllocation(\n+                allocationDeciders,\n+                routingNodes,\n+                state,\n+                info,\n+                shardSizeInfo,\n+                System.nanoTime()\n+            );\n+            List<ShardRouting> candidates = state.getRoutingNodes()\n+                .shardsWithState(ShardRoutingState.STARTED)\n+                .stream()\n+                .filter(shard -> allocationDeciders.canRemain(shard, routingNodes.node(shard.currentNodeId()), allocation) == Decision.NO)\n+                .filter(shard -> canAllocate(shard, allocation) == false)\n+                .collect(Collectors.toList());\n+\n+            // track these to ensure we do not double account if they both cannot remain and allocated due to storage.\n+            Set<ShardRouting> unmovableShards = candidates.stream()\n+                .filter(s -> allocatedToTier(s, allocation))\n+                .filter(s -> cannotRemainDueToStorage(s, allocation))\n+                .collect(Collectors.toSet());\n+            long unmovableBytes = unmovableShards.stream()\n+                .collect(Collectors.groupingBy(ShardRouting::currentNodeId))\n+                .entrySet()\n+                .stream()\n+                .mapToLong(e -> unmovableSize(e.getKey(), e.getValue()))\n+                .sum();\n+\n+            long unallocatableBytes = candidates.stream()\n+                .filter(Predicate.not(unmovableShards::contains))\n+                .filter(s1 -> cannotAllocateDueToStorage(s1, allocation))\n+                .mapToLong(this::sizeOf)\n+                .sum();\n+\n+            return unallocatableBytes + unmovableBytes;\n+        }\n+\n+        private boolean allocatedToTier(ShardRouting s, RoutingAllocation allocation) {\n+            return nodeTierPredicate.test(allocation.routingNodes().node(s.currentNodeId()).node());\n+        }\n+\n+        /**\n+         * Check that disk decider is only decider for a node preventing allocation of the shard.\n+         * @return true if and only if a node exists in the tier where only disk decider prevents allocation\n+         */\n+        private boolean cannotAllocateDueToStorage(ShardRouting shard, RoutingAllocation allocation) {\n+            assert allocation.debugDecision() == false;\n+            allocation.debugDecision(true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f28fb9a0ed9cc82720505c884887107b0cb96270"}, "originalPosition": 216}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTk2MjgwOQ==", "bodyText": "\ud83d\udc4d, 6a9c5cb", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541962809", "createdAt": "2020-12-13T16:56:57Z", "author": {"login": "henningandersen"}, "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.ClusterInfo;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.DiskUsage;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.cluster.routing.allocation.decider.Decision;\n+import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.snapshots.SnapshotShardSizeInfo;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class ReactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"reactive_storage\";\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ReactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<Setting<?>> deciderSettings() {\n+        return List.of();\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(\n+            DiscoveryNodeRole.DATA_ROLE,\n+            DataTier.DATA_CONTENT_NODE_ROLE,\n+            DataTier.DATA_HOT_NODE_ROLE,\n+            DataTier.DATA_WARM_NODE_ROLE,\n+            DataTier.DATA_COLD_NODE_ROLE\n+        );\n+    }\n+\n+    @Override\n+    public AutoscalingDeciderResult scale(Settings configuration, AutoscalingDeciderContext context) {\n+        AutoscalingCapacity autoscalingCapacity = context.currentCapacity();\n+        if (autoscalingCapacity == null || autoscalingCapacity.total().storage() == null) {\n+            return new AutoscalingDeciderResult(null, new ReactiveReason(\"current capacity not available\", -1, -1));\n+        }\n+\n+        AllocationState allocationState = new AllocationState(context, diskThresholdSettings, allocationDeciders);\n+        long unassigned = allocationState.storagePreventsAllocation();\n+        long assigned = allocationState.storagePreventsRemainOrMove();\n+        long maxShard = allocationState.maxShardSize();\n+        assert assigned >= 0;\n+        assert unassigned >= 0;\n+        assert maxShard >= 0;\n+        String message = unassigned > 0 || assigned > 0 ? \"not enough storage available, needs \" + (unassigned + assigned) : \"storage ok\";\n+        AutoscalingCapacity requiredCapacity = AutoscalingCapacity.builder()\n+            .total(autoscalingCapacity.total().storage().getBytes() + unassigned + assigned, null)\n+            .node(maxShard, null)\n+            .build();\n+        return new AutoscalingDeciderResult(requiredCapacity, new ReactiveReason(message, unassigned, assigned));\n+    }\n+\n+    static boolean isDiskOnlyNoDecision(Decision decision) {\n+        // we consider throttling==yes, throttling should be temporary.\n+        List<Decision> nos = decision.getDecisions()\n+            .stream()\n+            .filter(single -> single.type() == Decision.Type.NO)\n+            .collect(Collectors.toList());\n+        return nos.size() == 1 && DiskThresholdDecider.NAME.equals(nos.get(0).label());\n+    }\n+\n+    static class AllocationState {\n+        private final ClusterState state;\n+        private final AllocationDeciders allocationDeciders;\n+        private final DiskThresholdSettings diskThresholdSettings;\n+        private final ClusterInfo info;\n+        private final SnapshotShardSizeInfo shardSizeInfo;\n+        private final Predicate<DiscoveryNode> nodeTierPredicate;\n+        private final Set<DiscoveryNode> nodes;\n+\n+        AllocationState(\n+            AutoscalingDeciderContext context,\n+            DiskThresholdSettings diskThresholdSettings,\n+            AllocationDeciders allocationDeciders\n+        ) {\n+            this(\n+                context.state(),\n+                allocationDeciders,\n+                diskThresholdSettings,\n+                context.info(),\n+                context.snapshotShardSizeInfo(),\n+                context.nodes()\n+            );\n+        }\n+\n+        AllocationState(\n+            ClusterState state,\n+            AllocationDeciders allocationDeciders,\n+            DiskThresholdSettings diskThresholdSettings,\n+            ClusterInfo info,\n+            SnapshotShardSizeInfo shardSizeInfo,\n+            Set<DiscoveryNode> nodes\n+        ) {\n+            this.state = state;\n+            this.allocationDeciders = allocationDeciders;\n+            this.diskThresholdSettings = diskThresholdSettings;\n+            this.info = info;\n+            this.shardSizeInfo = shardSizeInfo;\n+            this.nodes = nodes;\n+            this.nodeTierPredicate = nodes::contains;\n+        }\n+\n+        public long storagePreventsAllocation() {\n+            RoutingNodes routingNodes = new RoutingNodes(state, false);\n+            RoutingAllocation allocation = new RoutingAllocation(\n+                allocationDeciders,\n+                routingNodes,\n+                state,\n+                info,\n+                shardSizeInfo,\n+                System.nanoTime()\n+            );\n+            return StreamSupport.stream(state.getRoutingNodes().unassigned().spliterator(), false)\n+                .filter(shard -> canAllocate(shard, allocation) == false)\n+                .filter(shard -> cannotAllocateDueToStorage(shard, allocation))\n+                .mapToLong(this::sizeOf)\n+                .sum();\n+        }\n+\n+        public long storagePreventsRemainOrMove() {\n+            RoutingNodes routingNodes = new RoutingNodes(state, false);\n+            RoutingAllocation allocation = new RoutingAllocation(\n+                allocationDeciders,\n+                routingNodes,\n+                state,\n+                info,\n+                shardSizeInfo,\n+                System.nanoTime()\n+            );\n+            List<ShardRouting> candidates = state.getRoutingNodes()\n+                .shardsWithState(ShardRoutingState.STARTED)\n+                .stream()\n+                .filter(shard -> allocationDeciders.canRemain(shard, routingNodes.node(shard.currentNodeId()), allocation) == Decision.NO)\n+                .filter(shard -> canAllocate(shard, allocation) == false)\n+                .collect(Collectors.toList());\n+\n+            // track these to ensure we do not double account if they both cannot remain and allocated due to storage.\n+            Set<ShardRouting> unmovableShards = candidates.stream()\n+                .filter(s -> allocatedToTier(s, allocation))\n+                .filter(s -> cannotRemainDueToStorage(s, allocation))\n+                .collect(Collectors.toSet());\n+            long unmovableBytes = unmovableShards.stream()\n+                .collect(Collectors.groupingBy(ShardRouting::currentNodeId))\n+                .entrySet()\n+                .stream()\n+                .mapToLong(e -> unmovableSize(e.getKey(), e.getValue()))\n+                .sum();\n+\n+            long unallocatableBytes = candidates.stream()\n+                .filter(Predicate.not(unmovableShards::contains))\n+                .filter(s1 -> cannotAllocateDueToStorage(s1, allocation))\n+                .mapToLong(this::sizeOf)\n+                .sum();\n+\n+            return unallocatableBytes + unmovableBytes;\n+        }\n+\n+        private boolean allocatedToTier(ShardRouting s, RoutingAllocation allocation) {\n+            return nodeTierPredicate.test(allocation.routingNodes().node(s.currentNodeId()).node());\n+        }\n+\n+        /**\n+         * Check that disk decider is only decider for a node preventing allocation of the shard.\n+         * @return true if and only if a node exists in the tier where only disk decider prevents allocation\n+         */\n+        private boolean cannotAllocateDueToStorage(ShardRouting shard, RoutingAllocation allocation) {\n+            assert allocation.debugDecision() == false;\n+            allocation.debugDecision(true);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyODI2Mw=="}, "originalCommit": {"oid": "f28fb9a0ed9cc82720505c884887107b0cb96270"}, "originalPosition": 216}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQwNDI2NTMyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xM1QxMzo0MjozMFrOIE0rXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xM1QxMzo0MjozMFrOIE0rXA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyODI4NA==", "bodyText": "Can you leave a comment explaining why we need to enable allocation debugging here?", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541928284", "createdAt": "2020-12-13T13:42:30Z", "author": {"login": "jasontedor"}, "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.ClusterInfo;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.DiskUsage;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.cluster.routing.allocation.decider.Decision;\n+import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.snapshots.SnapshotShardSizeInfo;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class ReactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"reactive_storage\";\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ReactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<Setting<?>> deciderSettings() {\n+        return List.of();\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(\n+            DiscoveryNodeRole.DATA_ROLE,\n+            DataTier.DATA_CONTENT_NODE_ROLE,\n+            DataTier.DATA_HOT_NODE_ROLE,\n+            DataTier.DATA_WARM_NODE_ROLE,\n+            DataTier.DATA_COLD_NODE_ROLE\n+        );\n+    }\n+\n+    @Override\n+    public AutoscalingDeciderResult scale(Settings configuration, AutoscalingDeciderContext context) {\n+        AutoscalingCapacity autoscalingCapacity = context.currentCapacity();\n+        if (autoscalingCapacity == null || autoscalingCapacity.total().storage() == null) {\n+            return new AutoscalingDeciderResult(null, new ReactiveReason(\"current capacity not available\", -1, -1));\n+        }\n+\n+        AllocationState allocationState = new AllocationState(context, diskThresholdSettings, allocationDeciders);\n+        long unassigned = allocationState.storagePreventsAllocation();\n+        long assigned = allocationState.storagePreventsRemainOrMove();\n+        long maxShard = allocationState.maxShardSize();\n+        assert assigned >= 0;\n+        assert unassigned >= 0;\n+        assert maxShard >= 0;\n+        String message = unassigned > 0 || assigned > 0 ? \"not enough storage available, needs \" + (unassigned + assigned) : \"storage ok\";\n+        AutoscalingCapacity requiredCapacity = AutoscalingCapacity.builder()\n+            .total(autoscalingCapacity.total().storage().getBytes() + unassigned + assigned, null)\n+            .node(maxShard, null)\n+            .build();\n+        return new AutoscalingDeciderResult(requiredCapacity, new ReactiveReason(message, unassigned, assigned));\n+    }\n+\n+    static boolean isDiskOnlyNoDecision(Decision decision) {\n+        // we consider throttling==yes, throttling should be temporary.\n+        List<Decision> nos = decision.getDecisions()\n+            .stream()\n+            .filter(single -> single.type() == Decision.Type.NO)\n+            .collect(Collectors.toList());\n+        return nos.size() == 1 && DiskThresholdDecider.NAME.equals(nos.get(0).label());\n+    }\n+\n+    static class AllocationState {\n+        private final ClusterState state;\n+        private final AllocationDeciders allocationDeciders;\n+        private final DiskThresholdSettings diskThresholdSettings;\n+        private final ClusterInfo info;\n+        private final SnapshotShardSizeInfo shardSizeInfo;\n+        private final Predicate<DiscoveryNode> nodeTierPredicate;\n+        private final Set<DiscoveryNode> nodes;\n+\n+        AllocationState(\n+            AutoscalingDeciderContext context,\n+            DiskThresholdSettings diskThresholdSettings,\n+            AllocationDeciders allocationDeciders\n+        ) {\n+            this(\n+                context.state(),\n+                allocationDeciders,\n+                diskThresholdSettings,\n+                context.info(),\n+                context.snapshotShardSizeInfo(),\n+                context.nodes()\n+            );\n+        }\n+\n+        AllocationState(\n+            ClusterState state,\n+            AllocationDeciders allocationDeciders,\n+            DiskThresholdSettings diskThresholdSettings,\n+            ClusterInfo info,\n+            SnapshotShardSizeInfo shardSizeInfo,\n+            Set<DiscoveryNode> nodes\n+        ) {\n+            this.state = state;\n+            this.allocationDeciders = allocationDeciders;\n+            this.diskThresholdSettings = diskThresholdSettings;\n+            this.info = info;\n+            this.shardSizeInfo = shardSizeInfo;\n+            this.nodes = nodes;\n+            this.nodeTierPredicate = nodes::contains;\n+        }\n+\n+        public long storagePreventsAllocation() {\n+            RoutingNodes routingNodes = new RoutingNodes(state, false);\n+            RoutingAllocation allocation = new RoutingAllocation(\n+                allocationDeciders,\n+                routingNodes,\n+                state,\n+                info,\n+                shardSizeInfo,\n+                System.nanoTime()\n+            );\n+            return StreamSupport.stream(state.getRoutingNodes().unassigned().spliterator(), false)\n+                .filter(shard -> canAllocate(shard, allocation) == false)\n+                .filter(shard -> cannotAllocateDueToStorage(shard, allocation))\n+                .mapToLong(this::sizeOf)\n+                .sum();\n+        }\n+\n+        public long storagePreventsRemainOrMove() {\n+            RoutingNodes routingNodes = new RoutingNodes(state, false);\n+            RoutingAllocation allocation = new RoutingAllocation(\n+                allocationDeciders,\n+                routingNodes,\n+                state,\n+                info,\n+                shardSizeInfo,\n+                System.nanoTime()\n+            );\n+            List<ShardRouting> candidates = state.getRoutingNodes()\n+                .shardsWithState(ShardRoutingState.STARTED)\n+                .stream()\n+                .filter(shard -> allocationDeciders.canRemain(shard, routingNodes.node(shard.currentNodeId()), allocation) == Decision.NO)\n+                .filter(shard -> canAllocate(shard, allocation) == false)\n+                .collect(Collectors.toList());\n+\n+            // track these to ensure we do not double account if they both cannot remain and allocated due to storage.\n+            Set<ShardRouting> unmovableShards = candidates.stream()\n+                .filter(s -> allocatedToTier(s, allocation))\n+                .filter(s -> cannotRemainDueToStorage(s, allocation))\n+                .collect(Collectors.toSet());\n+            long unmovableBytes = unmovableShards.stream()\n+                .collect(Collectors.groupingBy(ShardRouting::currentNodeId))\n+                .entrySet()\n+                .stream()\n+                .mapToLong(e -> unmovableSize(e.getKey(), e.getValue()))\n+                .sum();\n+\n+            long unallocatableBytes = candidates.stream()\n+                .filter(Predicate.not(unmovableShards::contains))\n+                .filter(s1 -> cannotAllocateDueToStorage(s1, allocation))\n+                .mapToLong(this::sizeOf)\n+                .sum();\n+\n+            return unallocatableBytes + unmovableBytes;\n+        }\n+\n+        private boolean allocatedToTier(ShardRouting s, RoutingAllocation allocation) {\n+            return nodeTierPredicate.test(allocation.routingNodes().node(s.currentNodeId()).node());\n+        }\n+\n+        /**\n+         * Check that disk decider is only decider for a node preventing allocation of the shard.\n+         * @return true if and only if a node exists in the tier where only disk decider prevents allocation\n+         */\n+        private boolean cannotAllocateDueToStorage(ShardRouting shard, RoutingAllocation allocation) {\n+            assert allocation.debugDecision() == false;\n+            allocation.debugDecision(true);\n+            try {\n+                return nodesInTier(allocation.routingNodes()).map(node -> allocationDeciders.canAllocate(shard, node, allocation))\n+                    .anyMatch(ReactiveStorageDeciderService::isDiskOnlyNoDecision);\n+            } finally {\n+                allocation.debugDecision(false);\n+            }\n+        }\n+\n+        /**\n+         * Check that the disk decider is only decider that says NO to let shard remain on current node.\n+         * @return true if and only if disk decider is only decider that says NO to canRemain.\n+         */\n+        private boolean cannotRemainDueToStorage(ShardRouting shard, RoutingAllocation allocation) {\n+            assert allocation.debugDecision() == false;\n+            allocation.debugDecision(true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f28fb9a0ed9cc82720505c884887107b0cb96270"}, "originalPosition": 231}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQwNDI2Nzg5OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xM1QxMzo0NDozMFrOIE0skQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xM1QxMzo0NDozMFrOIE0skQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyODU5Mw==", "bodyText": "Minor nit: since these represent bytes and not a count of shards, could we clarify the names: unassignedBytes, assignedBytes, and maxShardSize?", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541928593", "createdAt": "2020-12-13T13:44:30Z", "author": {"login": "jasontedor"}, "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.ClusterInfo;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.DiskUsage;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.cluster.routing.allocation.decider.Decision;\n+import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.snapshots.SnapshotShardSizeInfo;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class ReactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"reactive_storage\";\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ReactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<Setting<?>> deciderSettings() {\n+        return List.of();\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(\n+            DiscoveryNodeRole.DATA_ROLE,\n+            DataTier.DATA_CONTENT_NODE_ROLE,\n+            DataTier.DATA_HOT_NODE_ROLE,\n+            DataTier.DATA_WARM_NODE_ROLE,\n+            DataTier.DATA_COLD_NODE_ROLE\n+        );\n+    }\n+\n+    @Override\n+    public AutoscalingDeciderResult scale(Settings configuration, AutoscalingDeciderContext context) {\n+        AutoscalingCapacity autoscalingCapacity = context.currentCapacity();\n+        if (autoscalingCapacity == null || autoscalingCapacity.total().storage() == null) {\n+            return new AutoscalingDeciderResult(null, new ReactiveReason(\"current capacity not available\", -1, -1));\n+        }\n+\n+        AllocationState allocationState = new AllocationState(context, diskThresholdSettings, allocationDeciders);\n+        long unassigned = allocationState.storagePreventsAllocation();\n+        long assigned = allocationState.storagePreventsRemainOrMove();\n+        long maxShard = allocationState.maxShardSize();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f28fb9a0ed9cc82720505c884887107b0cb96270"}, "originalPosition": 89}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQwNDI3MzgyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xM1QxMzo0ODozMlrOIE0vPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xM1QxNjo1ODowNFrOIE2y-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyOTI3OA==", "bodyText": "I wonder if this should be human readable bytes? So new ByteSizeValue(unassigned + assigned).toString()?", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541929278", "createdAt": "2020-12-13T13:48:32Z", "author": {"login": "jasontedor"}, "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.ClusterInfo;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.DiskUsage;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.cluster.routing.allocation.decider.Decision;\n+import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.snapshots.SnapshotShardSizeInfo;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class ReactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"reactive_storage\";\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ReactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<Setting<?>> deciderSettings() {\n+        return List.of();\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(\n+            DiscoveryNodeRole.DATA_ROLE,\n+            DataTier.DATA_CONTENT_NODE_ROLE,\n+            DataTier.DATA_HOT_NODE_ROLE,\n+            DataTier.DATA_WARM_NODE_ROLE,\n+            DataTier.DATA_COLD_NODE_ROLE\n+        );\n+    }\n+\n+    @Override\n+    public AutoscalingDeciderResult scale(Settings configuration, AutoscalingDeciderContext context) {\n+        AutoscalingCapacity autoscalingCapacity = context.currentCapacity();\n+        if (autoscalingCapacity == null || autoscalingCapacity.total().storage() == null) {\n+            return new AutoscalingDeciderResult(null, new ReactiveReason(\"current capacity not available\", -1, -1));\n+        }\n+\n+        AllocationState allocationState = new AllocationState(context, diskThresholdSettings, allocationDeciders);\n+        long unassigned = allocationState.storagePreventsAllocation();\n+        long assigned = allocationState.storagePreventsRemainOrMove();\n+        long maxShard = allocationState.maxShardSize();\n+        assert assigned >= 0;\n+        assert unassigned >= 0;\n+        assert maxShard >= 0;\n+        String message = unassigned > 0 || assigned > 0 ? \"not enough storage available, needs \" + (unassigned + assigned) : \"storage ok\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f28fb9a0ed9cc82720505c884887107b0cb96270"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyOTM1NA==", "bodyText": "And if not,  bytes should be appended to the message.", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541929354", "createdAt": "2020-12-13T13:48:56Z", "author": {"login": "jasontedor"}, "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.ClusterInfo;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.DiskUsage;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.cluster.routing.allocation.decider.Decision;\n+import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.snapshots.SnapshotShardSizeInfo;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class ReactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"reactive_storage\";\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ReactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<Setting<?>> deciderSettings() {\n+        return List.of();\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(\n+            DiscoveryNodeRole.DATA_ROLE,\n+            DataTier.DATA_CONTENT_NODE_ROLE,\n+            DataTier.DATA_HOT_NODE_ROLE,\n+            DataTier.DATA_WARM_NODE_ROLE,\n+            DataTier.DATA_COLD_NODE_ROLE\n+        );\n+    }\n+\n+    @Override\n+    public AutoscalingDeciderResult scale(Settings configuration, AutoscalingDeciderContext context) {\n+        AutoscalingCapacity autoscalingCapacity = context.currentCapacity();\n+        if (autoscalingCapacity == null || autoscalingCapacity.total().storage() == null) {\n+            return new AutoscalingDeciderResult(null, new ReactiveReason(\"current capacity not available\", -1, -1));\n+        }\n+\n+        AllocationState allocationState = new AllocationState(context, diskThresholdSettings, allocationDeciders);\n+        long unassigned = allocationState.storagePreventsAllocation();\n+        long assigned = allocationState.storagePreventsRemainOrMove();\n+        long maxShard = allocationState.maxShardSize();\n+        assert assigned >= 0;\n+        assert unassigned >= 0;\n+        assert maxShard >= 0;\n+        String message = unassigned > 0 || assigned > 0 ? \"not enough storage available, needs \" + (unassigned + assigned) : \"storage ok\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyOTI3OA=="}, "originalCommit": {"oid": "f28fb9a0ed9cc82720505c884887107b0cb96270"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTk2MzAwMg==", "bodyText": "\ud83d\udc4d, b58d294", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541963002", "createdAt": "2020-12-13T16:58:04Z", "author": {"login": "henningandersen"}, "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.ClusterInfo;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.DiskUsage;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.cluster.routing.allocation.decider.Decision;\n+import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.snapshots.SnapshotShardSizeInfo;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class ReactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"reactive_storage\";\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ReactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<Setting<?>> deciderSettings() {\n+        return List.of();\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(\n+            DiscoveryNodeRole.DATA_ROLE,\n+            DataTier.DATA_CONTENT_NODE_ROLE,\n+            DataTier.DATA_HOT_NODE_ROLE,\n+            DataTier.DATA_WARM_NODE_ROLE,\n+            DataTier.DATA_COLD_NODE_ROLE\n+        );\n+    }\n+\n+    @Override\n+    public AutoscalingDeciderResult scale(Settings configuration, AutoscalingDeciderContext context) {\n+        AutoscalingCapacity autoscalingCapacity = context.currentCapacity();\n+        if (autoscalingCapacity == null || autoscalingCapacity.total().storage() == null) {\n+            return new AutoscalingDeciderResult(null, new ReactiveReason(\"current capacity not available\", -1, -1));\n+        }\n+\n+        AllocationState allocationState = new AllocationState(context, diskThresholdSettings, allocationDeciders);\n+        long unassigned = allocationState.storagePreventsAllocation();\n+        long assigned = allocationState.storagePreventsRemainOrMove();\n+        long maxShard = allocationState.maxShardSize();\n+        assert assigned >= 0;\n+        assert unassigned >= 0;\n+        assert maxShard >= 0;\n+        String message = unassigned > 0 || assigned > 0 ? \"not enough storage available, needs \" + (unassigned + assigned) : \"storage ok\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyOTI3OA=="}, "originalCommit": {"oid": "f28fb9a0ed9cc82720505c884887107b0cb96270"}, "originalPosition": 93}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1943, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}