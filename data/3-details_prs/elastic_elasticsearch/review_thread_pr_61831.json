{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDc3NjQwMjI0", "number": 61831, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNzowMjoyNVrOEgdr8Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNVQwMzoxODowM1rOEgkHvA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNDc2MjczOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/search/internal/LegacyReaderContext.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNzowMjoyNlrOHNVtnQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wN1QwNzoyNzo0MlrOHNzOVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc0OTI3Nw==", "bodyText": "++", "url": "https://github.com/elastic/elasticsearch/pull/61831#discussion_r483749277", "createdAt": "2020-09-04T17:02:26Z", "author": {"login": "dnhatn"}, "path": "server/src/main/java/org/elasticsearch/search/internal/LegacyReaderContext.java", "diffHunk": "@@ -61,6 +61,7 @@ public LegacyReaderContext(long id, IndexService indexService, IndexShard indexS\n             if (searcher == null) {\n                 Engine.Searcher delegate = searcherSupplier.acquireSearcher(source);\n                 onClose = delegate::close;\n+                // wrap the searcher so that closing is a noop, the actual closing happens when this context is closed", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f89a0a69f317feabf1745d3b54ea62f9c108bb5b"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDEwMzcxNw==", "bodyText": "@jimczi I looked at this again (while investigating the perf issue). I think we need to double-check with synchronization before acquiring a searcher to avoid leaking it.", "url": "https://github.com/elastic/elasticsearch/pull/61831#discussion_r484103717", "createdAt": "2020-09-06T19:05:09Z", "author": {"login": "dnhatn"}, "path": "server/src/main/java/org/elasticsearch/search/internal/LegacyReaderContext.java", "diffHunk": "@@ -61,6 +61,7 @@ public LegacyReaderContext(long id, IndexService indexService, IndexShard indexS\n             if (searcher == null) {\n                 Engine.Searcher delegate = searcherSupplier.acquireSearcher(source);\n                 onClose = delegate::close;\n+                // wrap the searcher so that closing is a noop, the actual closing happens when this context is closed", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc0OTI3Nw=="}, "originalCommit": {"oid": "f89a0a69f317feabf1745d3b54ea62f9c108bb5b"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDEwMzk4Nw==", "bodyText": "Or we can just always addOnClose(delegate) instead.", "url": "https://github.com/elastic/elasticsearch/pull/61831#discussion_r484103987", "createdAt": "2020-09-06T19:08:54Z", "author": {"login": "dnhatn"}, "path": "server/src/main/java/org/elasticsearch/search/internal/LegacyReaderContext.java", "diffHunk": "@@ -61,6 +61,7 @@ public LegacyReaderContext(long id, IndexService indexService, IndexShard indexS\n             if (searcher == null) {\n                 Engine.Searcher delegate = searcherSupplier.acquireSearcher(source);\n                 onClose = delegate::close;\n+                // wrap the searcher so that closing is a noop, the actual closing happens when this context is closed", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc0OTI3Nw=="}, "originalCommit": {"oid": "f89a0a69f317feabf1745d3b54ea62f9c108bb5b"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDEyOTYxMg==", "bodyText": "I found another issue while investigating the perf issue. We don't have a happens-before relation between the initial search and subsequent scroll requests. The searcher field needs to be volatile; otherwise, we might acquire and wrap searcher more than once.  I've pushed 0c42f9c. Let me know if you are ok with this change.", "url": "https://github.com/elastic/elasticsearch/pull/61831#discussion_r484129612", "createdAt": "2020-09-06T23:42:37Z", "author": {"login": "dnhatn"}, "path": "server/src/main/java/org/elasticsearch/search/internal/LegacyReaderContext.java", "diffHunk": "@@ -61,6 +61,7 @@ public LegacyReaderContext(long id, IndexService indexService, IndexShard indexS\n             if (searcher == null) {\n                 Engine.Searcher delegate = searcherSupplier.acquireSearcher(source);\n                 onClose = delegate::close;\n+                // wrap the searcher so that closing is a noop, the actual closing happens when this context is closed", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc0OTI3Nw=="}, "originalCommit": {"oid": "f89a0a69f317feabf1745d3b54ea62f9c108bb5b"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDIzMjc4OA==", "bodyText": "Great catch, thanks!", "url": "https://github.com/elastic/elasticsearch/pull/61831#discussion_r484232788", "createdAt": "2020-09-07T07:27:42Z", "author": {"login": "jimczi"}, "path": "server/src/main/java/org/elasticsearch/search/internal/LegacyReaderContext.java", "diffHunk": "@@ -61,6 +61,7 @@ public LegacyReaderContext(long id, IndexService indexService, IndexShard indexS\n             if (searcher == null) {\n                 Engine.Searcher delegate = searcherSupplier.acquireSearcher(source);\n                 onClose = delegate::close;\n+                // wrap the searcher so that closing is a noop, the actual closing happens when this context is closed", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc0OTI3Nw=="}, "originalCommit": {"oid": "f89a0a69f317feabf1745d3b54ea62f9c108bb5b"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNTgxNTAwOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/search/SearchService.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNVQwMzoxNDo1NFrOHNfI-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wN1QwNzoyODowM1rOHNzPDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzkwMzczNg==", "bodyText": "I know processFailure and markAsUsed do not throw exceptions, but can we use Releases.close() to ensure that we always notify the listener?", "url": "https://github.com/elastic/elasticsearch/pull/61831#discussion_r483903736", "createdAt": "2020-09-05T03:14:54Z", "author": {"login": "dnhatn"}, "path": "server/src/main/java/org/elasticsearch/search/SearchService.java", "diffHunk": "@@ -861,17 +854,38 @@ private void checkKeepAliveLimit(long keepAlive) {\n         }\n     }\n \n-    private void processFailure(ShardSearchRequest request, ReaderContext context, Exception e) {\n-        if (context.singleSession() || request.scroll() != null) {\n+    private <T> ActionListener<T> wrapFailureListener(ActionListener<T> listener, ReaderContext context, Releasable releasable) {\n+        return new ActionListener<>() {\n+            @Override\n+            public void onResponse(T resp) {\n+                releasable.close();\n+                listener.onResponse(resp);\n+            }\n+\n+            @Override\n+            public void onFailure(Exception exc) {\n+                processFailure(context, exc);\n+                releasable.close();\n+                listener.onFailure(exc);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f89a0a69f317feabf1745d3b54ea62f9c108bb5b"}, "originalPosition": 228}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDIzMjk3NA==", "bodyText": "++, 16ea240", "url": "https://github.com/elastic/elasticsearch/pull/61831#discussion_r484232974", "createdAt": "2020-09-07T07:28:03Z", "author": {"login": "jimczi"}, "path": "server/src/main/java/org/elasticsearch/search/SearchService.java", "diffHunk": "@@ -861,17 +854,38 @@ private void checkKeepAliveLimit(long keepAlive) {\n         }\n     }\n \n-    private void processFailure(ShardSearchRequest request, ReaderContext context, Exception e) {\n-        if (context.singleSession() || request.scroll() != null) {\n+    private <T> ActionListener<T> wrapFailureListener(ActionListener<T> listener, ReaderContext context, Releasable releasable) {\n+        return new ActionListener<>() {\n+            @Override\n+            public void onResponse(T resp) {\n+                releasable.close();\n+                listener.onResponse(resp);\n+            }\n+\n+            @Override\n+            public void onFailure(Exception exc) {\n+                processFailure(context, exc);\n+                releasable.close();\n+                listener.onFailure(exc);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzkwMzczNg=="}, "originalCommit": {"oid": "f89a0a69f317feabf1745d3b54ea62f9c108bb5b"}, "originalPosition": 228}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNTgxNjkyOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/search/SearchService.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNVQwMzoxODowM1rOHNfJ1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNVQwMzoxODowM1rOHNfJ1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzkwMzk1Nw==", "bodyText": "Nice!", "url": "https://github.com/elastic/elasticsearch/pull/61831#discussion_r483903957", "createdAt": "2020-09-05T03:18:03Z", "author": {"login": "dnhatn"}, "path": "server/src/main/java/org/elasticsearch/search/SearchService.java", "diffHunk": "@@ -420,17 +421,8 @@ public void onResponse(ShardSearchRequest orig) {\n                 }\n \n                 // fork the execution in the search thread pool\n-                runAsync(getExecutor(shard), () -> {\n-                    try (markAsUsed) {\n-                        return executeQueryPhase(orig, task, readerContext);\n-                    }\n-                }, ActionListener.wrap(listener::onResponse, exc -> {\n-                    try (markAsUsed) {\n-                        listener.onFailure(exc);\n-                    } finally {\n-                        processFailure(request, readerContext, exc);\n-                    }\n-                }));\n+                runAsync(getExecutor(shard), () -> executeQueryPhase(orig, task, readerContext),\n+                    wrapFailureListener(listener, readerContext, markAsUsed));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f89a0a69f317feabf1745d3b54ea62f9c108bb5b"}, "originalPosition": 48}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1829, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}