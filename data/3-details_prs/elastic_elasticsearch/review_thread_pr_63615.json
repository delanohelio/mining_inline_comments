{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTAyMzc5MjAw", "number": 63615, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNDozNzowMlrOEtEoLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNDozNzowMlrOEtEoLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1Njk3MTk4OnYy", "diffSide": "RIGHT", "path": "distribution/docker/src/docker/Dockerfile", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNDozNzowMlrOHgqE3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxMjo1MjowNFrOHhRb-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDAwNTg1NA==", "bodyText": "A small note: one issue here is that if any of the three wgets fails here, the entire loop will fail and all downloads will be retried. Is this deliberate? Alternatively we'd have to split the wget's within separate loops.", "url": "https://github.com/elastic/elasticsearch/pull/63615#discussion_r504005854", "createdAt": "2020-10-13T14:37:02Z", "author": {"login": "dliappis"}, "path": "distribution/docker/src/docker/Dockerfile", "diffHunk": "@@ -61,10 +61,14 @@ RUN apk add gnupg gcc make musl-dev openssl-dev openssl-libs-static file\n RUN mkdir /work\n WORKDIR /work\n \n-# Fetch curl sources and files for validation\n-RUN wget \"https://daniel.haxx.se/mykey.asc\" -O \"curl-gpg.pub\" && \\\\\n-    wget \"\\${TARBALL_URL}.asc\" -O \"\\${TARBALL_PATH}.asc\" && \\\\\n-    wget \"\\${TARBALL_URL}\" -O \"\\${TARBALL_PATH}\"\n+# Fetch curl sources and files for validation. Note that alpine's `wget` doesn't have retry options.\n+RUN for iter in {1..10}; do \\\\\n+      wget \"https://daniel.haxx.se/mykey.asc\" -O \"curl-gpg.pub\" && \\\\\n+      wget \"\\${TARBALL_URL}.asc\" -O \"\\${TARBALL_PATH}.asc\" && \\\\\n+      wget \"\\${TARBALL_URL}\" -O \"\\${TARBALL_PATH}\" && \\\\", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f3f76bbb1fc95b37a38b174441c60b6c6ac09d65"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDEwNzQyNA==", "bodyText": "These are idempotent operations so that's not a huge deal but you do risk that one fails one iteration and another fails the next. This is still an improvement though. Wrapping each of these is going to start getting a bit silly unless we can somehow encapsulate this logic in a function of some kind.", "url": "https://github.com/elastic/elasticsearch/pull/63615#discussion_r504107424", "createdAt": "2020-10-13T16:45:35Z", "author": {"login": "mark-vieira"}, "path": "distribution/docker/src/docker/Dockerfile", "diffHunk": "@@ -61,10 +61,14 @@ RUN apk add gnupg gcc make musl-dev openssl-dev openssl-libs-static file\n RUN mkdir /work\n WORKDIR /work\n \n-# Fetch curl sources and files for validation\n-RUN wget \"https://daniel.haxx.se/mykey.asc\" -O \"curl-gpg.pub\" && \\\\\n-    wget \"\\${TARBALL_URL}.asc\" -O \"\\${TARBALL_PATH}.asc\" && \\\\\n-    wget \"\\${TARBALL_URL}\" -O \"\\${TARBALL_PATH}\"\n+# Fetch curl sources and files for validation. Note that alpine's `wget` doesn't have retry options.\n+RUN for iter in {1..10}; do \\\\\n+      wget \"https://daniel.haxx.se/mykey.asc\" -O \"curl-gpg.pub\" && \\\\\n+      wget \"\\${TARBALL_URL}.asc\" -O \"\\${TARBALL_PATH}.asc\" && \\\\\n+      wget \"\\${TARBALL_URL}\" -O \"\\${TARBALL_PATH}\" && \\\\", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDAwNTg1NA=="}, "originalCommit": {"oid": "f3f76bbb1fc95b37a38b174441c60b6c6ac09d65"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDExMDczOQ==", "bodyText": "Yeah and while having an inline function within the scope of RUN is possible it'll look convoluted. I agree this is already an improvement.", "url": "https://github.com/elastic/elasticsearch/pull/63615#discussion_r504110739", "createdAt": "2020-10-13T16:50:50Z", "author": {"login": "dliappis"}, "path": "distribution/docker/src/docker/Dockerfile", "diffHunk": "@@ -61,10 +61,14 @@ RUN apk add gnupg gcc make musl-dev openssl-dev openssl-libs-static file\n RUN mkdir /work\n WORKDIR /work\n \n-# Fetch curl sources and files for validation\n-RUN wget \"https://daniel.haxx.se/mykey.asc\" -O \"curl-gpg.pub\" && \\\\\n-    wget \"\\${TARBALL_URL}.asc\" -O \"\\${TARBALL_PATH}.asc\" && \\\\\n-    wget \"\\${TARBALL_URL}\" -O \"\\${TARBALL_PATH}\"\n+# Fetch curl sources and files for validation. Note that alpine's `wget` doesn't have retry options.\n+RUN for iter in {1..10}; do \\\\\n+      wget \"https://daniel.haxx.se/mykey.asc\" -O \"curl-gpg.pub\" && \\\\\n+      wget \"\\${TARBALL_URL}.asc\" -O \"\\${TARBALL_PATH}.asc\" && \\\\\n+      wget \"\\${TARBALL_URL}\" -O \"\\${TARBALL_PATH}\" && \\\\", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDAwNTg1NA=="}, "originalCommit": {"oid": "f3f76bbb1fc95b37a38b174441c60b6c6ac09d65"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDUyODc5Mg==", "bodyText": "@dliappis Actually the inline function isn't too bad - I've pushed a change, see what you think.", "url": "https://github.com/elastic/elasticsearch/pull/63615#discussion_r504528792", "createdAt": "2020-10-14T09:19:21Z", "author": {"login": "pugnascotia"}, "path": "distribution/docker/src/docker/Dockerfile", "diffHunk": "@@ -61,10 +61,14 @@ RUN apk add gnupg gcc make musl-dev openssl-dev openssl-libs-static file\n RUN mkdir /work\n WORKDIR /work\n \n-# Fetch curl sources and files for validation\n-RUN wget \"https://daniel.haxx.se/mykey.asc\" -O \"curl-gpg.pub\" && \\\\\n-    wget \"\\${TARBALL_URL}.asc\" -O \"\\${TARBALL_PATH}.asc\" && \\\\\n-    wget \"\\${TARBALL_URL}\" -O \"\\${TARBALL_PATH}\"\n+# Fetch curl sources and files for validation. Note that alpine's `wget` doesn't have retry options.\n+RUN for iter in {1..10}; do \\\\\n+      wget \"https://daniel.haxx.se/mykey.asc\" -O \"curl-gpg.pub\" && \\\\\n+      wget \"\\${TARBALL_URL}.asc\" -O \"\\${TARBALL_PATH}.asc\" && \\\\\n+      wget \"\\${TARBALL_URL}\" -O \"\\${TARBALL_PATH}\" && \\\\", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDAwNTg1NA=="}, "originalCommit": {"oid": "f3f76bbb1fc95b37a38b174441c60b6c6ac09d65"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDY1MDc0NA==", "bodyText": "@pugnascotia Looks MUCH better, thank you!", "url": "https://github.com/elastic/elasticsearch/pull/63615#discussion_r504650744", "createdAt": "2020-10-14T12:52:04Z", "author": {"login": "dliappis"}, "path": "distribution/docker/src/docker/Dockerfile", "diffHunk": "@@ -61,10 +61,14 @@ RUN apk add gnupg gcc make musl-dev openssl-dev openssl-libs-static file\n RUN mkdir /work\n WORKDIR /work\n \n-# Fetch curl sources and files for validation\n-RUN wget \"https://daniel.haxx.se/mykey.asc\" -O \"curl-gpg.pub\" && \\\\\n-    wget \"\\${TARBALL_URL}.asc\" -O \"\\${TARBALL_PATH}.asc\" && \\\\\n-    wget \"\\${TARBALL_URL}\" -O \"\\${TARBALL_PATH}\"\n+# Fetch curl sources and files for validation. Note that alpine's `wget` doesn't have retry options.\n+RUN for iter in {1..10}; do \\\\\n+      wget \"https://daniel.haxx.se/mykey.asc\" -O \"curl-gpg.pub\" && \\\\\n+      wget \"\\${TARBALL_URL}.asc\" -O \"\\${TARBALL_PATH}.asc\" && \\\\\n+      wget \"\\${TARBALL_URL}\" -O \"\\${TARBALL_PATH}\" && \\\\", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDAwNTg1NA=="}, "originalCommit": {"oid": "f3f76bbb1fc95b37a38b174441c60b6c6ac09d65"}, "originalPosition": 12}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2969, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}