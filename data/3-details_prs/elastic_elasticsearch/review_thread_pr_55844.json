{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA5OTU5ODg5", "number": 55844, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQwODoyMzozNVrOD3FMGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQwODoyNTo1NVrOD3FPuQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5MDgzMjg5OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/common/compress/CompressedXContent.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQwODoyMzozNVrOGNIkQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQwODoyMzozNVrOGNIkQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQyNTAyNg==", "bodyText": "This should be much more efficient here as we mainly use it on strings that are internally coded as UTF-8 already (mapping update requests) so we just do a simple byte[] copy here instead of creating an oversized array and doing char by char work in the BytesRef code", "url": "https://github.com/elastic/elasticsearch/pull/55844#discussion_r416425026", "createdAt": "2020-04-28T08:23:35Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/common/compress/CompressedXContent.java", "diffHunk": "@@ -124,7 +116,7 @@ public CompressedXContent(byte[] data) throws IOException {\n     }\n \n     public CompressedXContent(String str) throws IOException {\n-        this(new BytesArray(new BytesRef(str)));\n+        this(new BytesArray(str.getBytes(StandardCharsets.UTF_8)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "39013946261ff09a720d274616e1e4c6d1382977"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5MDg0MjE3OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/cluster/metadata/MappingMetadata.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQwODoyNTo1NVrOGNIqZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQwODoyNTo1NVrOGNIqZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQyNjU5OQ==", "bodyText": "We get here a lot as part of some snapshot repo operations (when reading index metadata) and it's quite wasteful to first serialize the map to bytes into one buffer only to then compress that buffer to another buffer => just serialize and compress in one go", "url": "https://github.com/elastic/elasticsearch/pull/55844#discussion_r416426599", "createdAt": "2020-04-28T08:25:55Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/cluster/metadata/MappingMetadata.java", "diffHunk": "@@ -73,10 +72,9 @@ public MappingMetadata(CompressedXContent mapping) {\n     public MappingMetadata(String type, Map<String, Object> mapping) {\n         this.type = type;\n         try {\n-            XContentBuilder mappingBuilder = XContentFactory.jsonBuilder().map(mapping);\n-            this.source = new CompressedXContent(BytesReference.bytes(mappingBuilder));\n-        }\n-        catch (IOException e) {\n+            this.source = new CompressedXContent(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "39013946261ff09a720d274616e1e4c6d1382977"}, "originalPosition": 24}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2641, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}