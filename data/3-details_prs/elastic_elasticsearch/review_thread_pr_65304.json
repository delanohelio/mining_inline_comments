{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI0NTY3MjMz", "number": 65304, "reviewThreads": {"totalCount": 28, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwOTozMDo0NVrOE9jL0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQxMDoxNDo0M1rOFCPRWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyOTc1MDU5OnYy", "diffSide": "RIGHT", "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/transform/transforms/TransformConfig.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwOTozMDo0NVrOH6S4hw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxMTozMjoyNVrOH-WLyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDg4ODgzOQ==", "bodyText": "pivot and latest should be mutually exclusive.\nI think in the client we can check and throw in the constructor.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r530888839", "createdAt": "2020-11-26T09:30:45Z", "author": {"login": "hendrikmuhs"}, "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/transform/transforms/TransformConfig.java", "diffHunk": "@@ -162,6 +184,7 @@ public static TransformConfig forPreview(final SourceConfig source, final PivotC\n         this.frequency = frequency;\n         this.syncConfig = syncConfig;\n         this.pivotConfig = pivotConfig;\n+        this.latestDocConfig = latestDocConfig;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzQyNDEyMg==", "bodyText": "Shouldn't we validate on the server-side only and make the client more of a pass-through for anything user provides?\nThere already is a validation for mutually-exclusive functions in org.elasticsearch.xpack.core.transform.transforms.TransformConfig class.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r533424122", "createdAt": "2020-12-01T13:55:28Z", "author": {"login": "przemekwitek"}, "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/transform/transforms/TransformConfig.java", "diffHunk": "@@ -162,6 +184,7 @@ public static TransformConfig forPreview(final SourceConfig source, final PivotC\n         this.frequency = frequency;\n         this.syncConfig = syncConfig;\n         this.pivotConfig = pivotConfig;\n+        this.latestDocConfig = latestDocConfig;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDg4ODgzOQ=="}, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEyNjMxMg==", "bodyText": "I agree, the validation should be backend only. Especially since the validation would run against a GET and the HLRC needs to be forwards compatible.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534126312", "createdAt": "2020-12-02T12:23:46Z", "author": {"login": "benwtrent"}, "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/transform/transforms/TransformConfig.java", "diffHunk": "@@ -162,6 +184,7 @@ public static TransformConfig forPreview(final SourceConfig source, final PivotC\n         this.frequency = frequency;\n         this.syncConfig = syncConfig;\n         this.pivotConfig = pivotConfig;\n+        this.latestDocConfig = latestDocConfig;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDg4ODgzOQ=="}, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkwNDM1MA==", "bodyText": "I don't think we will ever support both, but it's ok.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534904350", "createdAt": "2020-12-03T08:25:09Z", "author": {"login": "hendrikmuhs"}, "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/transform/transforms/TransformConfig.java", "diffHunk": "@@ -162,6 +184,7 @@ public static TransformConfig forPreview(final SourceConfig source, final PivotC\n         this.frequency = frequency;\n         this.syncConfig = syncConfig;\n         this.pivotConfig = pivotConfig;\n+        this.latestDocConfig = latestDocConfig;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDg4ODgzOQ=="}, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTEzNzIyNQ==", "bodyText": "The other possibility is to pass Function function. That would be the most object-oriented solution. TBH I haven't looked closely what changes would be needed to make this change.\nI think there are some dependencies on the function being pivot so I'll leave that out of this PR as a possible refactoring.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535137225", "createdAt": "2020-12-03T11:32:25Z", "author": {"login": "przemekwitek"}, "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/transform/transforms/TransformConfig.java", "diffHunk": "@@ -162,6 +184,7 @@ public static TransformConfig forPreview(final SourceConfig source, final PivotC\n         this.frequency = frequency;\n         this.syncConfig = syncConfig;\n         this.pivotConfig = pivotConfig;\n+        this.latestDocConfig = latestDocConfig;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDg4ODgzOQ=="}, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 97}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyOTc4OTA3OnYy", "diffSide": "RIGHT", "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/transform/transforms/latest/LatestDocConfig.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwOTozOTo0MlrOH6TP3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxMjoyNDo1MFrOH-ZHYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDg5NDgxNQ==", "bodyText": "we haven't decided yet, what we do with missing_bucket. We should bring that up in the design discussion again.\nDefault terms that have no value are omitted, with missing_bucket: true they are returned as null value.\nI wonder if this should be:\n\na per field setting\na setting for all fields together\nnot have a setting but internally default to true\n\nI rule out the option to not have a setting but internally default to false as this seems strange to me.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r530894815", "createdAt": "2020-11-26T09:39:42Z", "author": {"login": "hendrikmuhs"}, "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.client.transform.transforms.latest;\n+\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+/**\n+ * Class describing how to compute latest doc for every unique key\n+ */\n+public class LatestDocConfig implements ToXContentObject {\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");\n+\n+    private final List<String> uniqueKey;\n+    private final List<SortBuilder<?>> sort;\n+\n+    @SuppressWarnings(\"unchecked\")\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> PARSER =\n+        new ConstructingObjectParser<>(\n+            \"latest_doc_config\", true, args -> new LatestDocConfig((List<String>) args[0], (List<SortBuilder<?>>) args[1]));\n+\n+    static {\n+        PARSER.declareStringArray(constructorArg(), UNIQUE_KEY);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDkyNjUwMQ==", "bodyText": "the more I think about it, the more I think we should take option 3 (no setting, default true).", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r530926501", "createdAt": "2020-11-26T10:27:44Z", "author": {"login": "hendrikmuhs"}, "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.client.transform.transforms.latest;\n+\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+/**\n+ * Class describing how to compute latest doc for every unique key\n+ */\n+public class LatestDocConfig implements ToXContentObject {\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");\n+\n+    private final List<String> uniqueKey;\n+    private final List<SortBuilder<?>> sort;\n+\n+    @SuppressWarnings(\"unchecked\")\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> PARSER =\n+        new ConstructingObjectParser<>(\n+            \"latest_doc_config\", true, args -> new LatestDocConfig((List<String>) args[0], (List<SortBuilder<?>>) args[1]));\n+\n+    static {\n+        PARSER.declareStringArray(constructorArg(), UNIQUE_KEY);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDg5NDgxNQ=="}, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzk2NzcwNg==", "bodyText": "Agree.\nOption 3 is the simplest one and gives sensible default.\nIn case users need more customization, we can always introduce per-field setting later.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r533967706", "createdAt": "2020-12-02T08:09:20Z", "author": {"login": "przemekwitek"}, "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.client.transform.transforms.latest;\n+\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+/**\n+ * Class describing how to compute latest doc for every unique key\n+ */\n+public class LatestDocConfig implements ToXContentObject {\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");\n+\n+    private final List<String> uniqueKey;\n+    private final List<SortBuilder<?>> sort;\n+\n+    @SuppressWarnings(\"unchecked\")\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> PARSER =\n+        new ConstructingObjectParser<>(\n+            \"latest_doc_config\", true, args -> new LatestDocConfig((List<String>) args[0], (List<SortBuilder<?>>) args[1]));\n+\n+    static {\n+        PARSER.declareStringArray(constructorArg(), UNIQUE_KEY);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDg5NDgxNQ=="}, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE4NTI0OQ==", "bodyText": "the more I think about it, the more I think we should take option 3 (no setting, default true).\n\nDone.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535185249", "createdAt": "2020-12-03T12:24:50Z", "author": {"login": "przemekwitek"}, "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.client.transform.transforms.latest;\n+\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+/**\n+ * Class describing how to compute latest doc for every unique key\n+ */\n+public class LatestDocConfig implements ToXContentObject {\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");\n+\n+    private final List<String> uniqueKey;\n+    private final List<SortBuilder<?>> sort;\n+\n+    @SuppressWarnings(\"unchecked\")\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> PARSER =\n+        new ConstructingObjectParser<>(\n+            \"latest_doc_config\", true, args -> new LatestDocConfig((List<String>) args[0], (List<SortBuilder<?>>) args[1]));\n+\n+    static {\n+        PARSER.declareStringArray(constructorArg(), UNIQUE_KEY);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDg5NDgxNQ=="}, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyOTg0NjUwOnYy", "diffSide": "RIGHT", "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/transform/transforms/latest/LatestDocConfig.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwOTo1MzoxOFrOH6TzXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQwODoxNDozOVrOH9O-gQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDkwMzkwMg==", "bodyText": "do we support all options? This seems problematic for continuous. Maybe we should start simple and only allow strings? I think however it is a good idea to internally use List<SortBuilder<?>>. If you look at TopHitsAggregationBuilder it contains convenience methods that take a string build the SortBuilder internally. I think that would be good.\nLet's maybe revisit after you have a 1st implementation for continuous and after we know what is possible or not. Maybe its better to reduce the number options.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r530903902", "createdAt": "2020-11-26T09:53:18Z", "author": {"login": "hendrikmuhs"}, "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.client.transform.transforms.latest;\n+\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+/**\n+ * Class describing how to compute latest doc for every unique key\n+ */\n+public class LatestDocConfig implements ToXContentObject {\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");\n+\n+    private final List<String> uniqueKey;\n+    private final List<SortBuilder<?>> sort;\n+\n+    @SuppressWarnings(\"unchecked\")\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> PARSER =\n+        new ConstructingObjectParser<>(\n+            \"latest_doc_config\", true, args -> new LatestDocConfig((List<String>) args[0], (List<SortBuilder<?>>) args[1]));\n+\n+    static {\n+        PARSER.declareStringArray(constructorArg(), UNIQUE_KEY);\n+        PARSER.declareField(constructorArg(), (p, c) -> SortBuilder.fromXContent(p), SORT, ObjectParser.ValueType.OBJECT_ARRAY_OR_STRING);\n+    }\n+\n+    public static LatestDocConfig fromXContent(final XContentParser parser) {\n+        return PARSER.apply(parser, null);\n+    }\n+\n+    LatestDocConfig(List<String> uniqueKey, List<SortBuilder<?>> sort) {\n+        this.uniqueKey = uniqueKey;\n+        this.sort = sort;\n+    }\n+\n+    @Override\n+    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n+        builder.startObject();\n+        builder.field(UNIQUE_KEY.getPreferredName(), uniqueKey);\n+        builder.field(SORT.getPreferredName(), sort);\n+        builder.endObject();\n+        return builder;\n+    }\n+\n+    public List<String> getUniqueKey() {\n+        return uniqueKey;\n+    }\n+\n+    public List<SortBuilder<?>> getSort() {\n+        return sort;\n+    }\n+\n+    @Override\n+    public boolean equals(Object other) {\n+        if (this == other) {\n+            return true;\n+        }\n+        if (other == null || getClass() != other.getClass()) {\n+            return false;\n+        }\n+        LatestDocConfig that = (LatestDocConfig) other;\n+        return Objects.equals(this.uniqueKey, that.uniqueKey) && Objects.equals(this.sort, that.sort);\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return Objects.hash(uniqueKey, sort);\n+    }\n+\n+    public static Builder builder() {\n+        return new Builder();\n+    }\n+\n+    public static class Builder {\n+        private List<String> uniqueKey;\n+        private List<SortBuilder<?>> sort;\n+\n+        /**\n+         * Set how to group the source data\n+         * @param uniqueKey The configuration describing how to group the source data\n+         * @return the {@link Builder} with the interval set.\n+         */\n+        public Builder setUniqueKey(String... uniqueKey) {\n+            return setUniqueKey(Arrays.asList(uniqueKey));\n+        }\n+\n+        public Builder setUniqueKey(List<String> uniqueKey) {\n+            this.uniqueKey = uniqueKey;\n+            return this;\n+        }\n+\n+        public Builder setSort(FieldSortBuilder sort) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 125}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzk3MDU2MQ==", "bodyText": "do we support all options? This seems problematic for continuous. Maybe we should start simple and only allow strings?\n\nMy intention is to allow strings rather than (in addition to) full sort spec. Let me verify that but IIUC an array of strings will be parsed correctly by this line:\n        PARSER.declareField(constructorArg(), (p, c) -> SortBuilder.fromXContent(p), SORT, ObjectParser.ValueType.OBJECT_ARRAY_OR_STRING);\n\nIn the fullness of time I think we should support both ASC and  DESC as latest could work for any monotonic function (either increasing or decreasing).\nBut in the first version we can prevent that and require that the only sort field is SyncConfig.timestamp and always use order of DESC", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r533970561", "createdAt": "2020-12-02T08:14:39Z", "author": {"login": "przemekwitek"}, "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.client.transform.transforms.latest;\n+\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+/**\n+ * Class describing how to compute latest doc for every unique key\n+ */\n+public class LatestDocConfig implements ToXContentObject {\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");\n+\n+    private final List<String> uniqueKey;\n+    private final List<SortBuilder<?>> sort;\n+\n+    @SuppressWarnings(\"unchecked\")\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> PARSER =\n+        new ConstructingObjectParser<>(\n+            \"latest_doc_config\", true, args -> new LatestDocConfig((List<String>) args[0], (List<SortBuilder<?>>) args[1]));\n+\n+    static {\n+        PARSER.declareStringArray(constructorArg(), UNIQUE_KEY);\n+        PARSER.declareField(constructorArg(), (p, c) -> SortBuilder.fromXContent(p), SORT, ObjectParser.ValueType.OBJECT_ARRAY_OR_STRING);\n+    }\n+\n+    public static LatestDocConfig fromXContent(final XContentParser parser) {\n+        return PARSER.apply(parser, null);\n+    }\n+\n+    LatestDocConfig(List<String> uniqueKey, List<SortBuilder<?>> sort) {\n+        this.uniqueKey = uniqueKey;\n+        this.sort = sort;\n+    }\n+\n+    @Override\n+    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n+        builder.startObject();\n+        builder.field(UNIQUE_KEY.getPreferredName(), uniqueKey);\n+        builder.field(SORT.getPreferredName(), sort);\n+        builder.endObject();\n+        return builder;\n+    }\n+\n+    public List<String> getUniqueKey() {\n+        return uniqueKey;\n+    }\n+\n+    public List<SortBuilder<?>> getSort() {\n+        return sort;\n+    }\n+\n+    @Override\n+    public boolean equals(Object other) {\n+        if (this == other) {\n+            return true;\n+        }\n+        if (other == null || getClass() != other.getClass()) {\n+            return false;\n+        }\n+        LatestDocConfig that = (LatestDocConfig) other;\n+        return Objects.equals(this.uniqueKey, that.uniqueKey) && Objects.equals(this.sort, that.sort);\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return Objects.hash(uniqueKey, sort);\n+    }\n+\n+    public static Builder builder() {\n+        return new Builder();\n+    }\n+\n+    public static class Builder {\n+        private List<String> uniqueKey;\n+        private List<SortBuilder<?>> sort;\n+\n+        /**\n+         * Set how to group the source data\n+         * @param uniqueKey The configuration describing how to group the source data\n+         * @return the {@link Builder} with the interval set.\n+         */\n+        public Builder setUniqueKey(String... uniqueKey) {\n+            return setUniqueKey(Arrays.asList(uniqueKey));\n+        }\n+\n+        public Builder setUniqueKey(List<String> uniqueKey) {\n+            this.uniqueKey = uniqueKey;\n+            return this;\n+        }\n+\n+        public Builder setSort(FieldSortBuilder sort) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDkwMzkwMg=="}, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 125}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyOTg1NjIwOnYy", "diffSide": "RIGHT", "path": "client/rest-high-level/src/test/java/org/elasticsearch/client/transform/transforms/TransformConfigTests.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwOTo1NToyNVrOH6T5Qg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxMzo1Nzo1OFrOH8tu-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDkwNTQxMA==", "bodyText": "a test for expectThrows if both are given, to test mutual exclusiveness", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r530905410", "createdAt": "2020-11-26T09:55:25Z", "author": {"login": "hendrikmuhs"}, "path": "client/rest-high-level/src/test/java/org/elasticsearch/client/transform/transforms/TransformConfigTests.java", "diffHunk": "@@ -41,13 +44,23 @@\n public class TransformConfigTests extends AbstractXContentTestCase<TransformConfig> {\n \n     public static TransformConfig randomTransformConfig() {\n+        PivotConfig pivotConfig;\n+        LatestDocConfig latestDocConfig;\n+        if (randomBoolean()) {\n+            pivotConfig = PivotConfigTests.randomPivotConfig();\n+            latestDocConfig = null;\n+        } else {\n+            pivotConfig = null;\n+            latestDocConfig = LatestDocConfigTests.randomLatestDocConfig();\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzQyNTkxNA==", "bodyText": "Please see my comment in client/rest-high-level/src/main/java/org/elasticsearch/client/transform/transforms/TransformConfig.java.\nIf we decide to validate in the client code, I'll definitely add a test here.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r533425914", "createdAt": "2020-12-01T13:57:58Z", "author": {"login": "przemekwitek"}, "path": "client/rest-high-level/src/test/java/org/elasticsearch/client/transform/transforms/TransformConfigTests.java", "diffHunk": "@@ -41,13 +44,23 @@\n public class TransformConfigTests extends AbstractXContentTestCase<TransformConfig> {\n \n     public static TransformConfig randomTransformConfig() {\n+        PivotConfig pivotConfig;\n+        LatestDocConfig latestDocConfig;\n+        if (randomBoolean()) {\n+            pivotConfig = PivotConfigTests.randomPivotConfig();\n+            latestDocConfig = null;\n+        } else {\n+            pivotConfig = null;\n+            latestDocConfig = LatestDocConfigTests.randomLatestDocConfig();\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDkwNTQxMA=="}, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyOTg3OTkzOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/latest/LatestDocConfig.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQxMDowMDo0NFrOH6UHvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxMjoxNzo0N1rOH-Y1tw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDkwOTExOQ==", "bodyText": "same remark: we need to sort out what we do with missing_bucket", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r530909119", "createdAt": "2020-11-26T10:00:44Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core.transform.transforms.latest;\n+\n+import org.elasticsearch.action.ActionRequestValidationException;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+import org.elasticsearch.xpack.core.transform.utils.ExceptionsHelper;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+public class LatestDocConfig implements Writeable, ToXContentObject {\n+\n+    private static final String NAME = \"transform_latest_doc\";\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzk2Nzk2Mw==", "bodyText": "Please see my other comment.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r533967963", "createdAt": "2020-12-02T08:09:48Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core.transform.transforms.latest;\n+\n+import org.elasticsearch.action.ActionRequestValidationException;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+import org.elasticsearch.xpack.core.transform.utils.ExceptionsHelper;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+public class LatestDocConfig implements Writeable, ToXContentObject {\n+\n+    private static final String NAME = \"transform_latest_doc\";\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDkwOTExOQ=="}, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkzNjA4Mw==", "bodyText": "\ud83d\udc4d lets omit missing_bucket but hard code it to true in the implementation of latest", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534936083", "createdAt": "2020-12-03T08:44:44Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core.transform.transforms.latest;\n+\n+import org.elasticsearch.action.ActionRequestValidationException;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+import org.elasticsearch.xpack.core.transform.utils.ExceptionsHelper;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+public class LatestDocConfig implements Writeable, ToXContentObject {\n+\n+    private static final String NAME = \"transform_latest_doc\";\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDkwOTExOQ=="}, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE4MDcyNw==", "bodyText": "Done.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535180727", "createdAt": "2020-12-03T12:17:47Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core.transform.transforms.latest;\n+\n+import org.elasticsearch.action.ActionRequestValidationException;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+import org.elasticsearch.xpack.core.transform.utils.ExceptionsHelper;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+public class LatestDocConfig implements Writeable, ToXContentObject {\n+\n+    private static final String NAME = \"transform_latest_doc\";\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDkwOTExOQ=="}, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyOTg5MjI5OnYy", "diffSide": "RIGHT", "path": "client/rest-high-level/src/test/java/org/elasticsearch/client/transform/transforms/latest/LatestDocConfigTests.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQxMDowMzo0MVrOH6UPNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxNDowNzoyM1rOH8uJdg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDkxMTAzMQ==", "bodyText": "there are also test classes for hlrc <-> server and back in the hlrc sub package. Every new class should implement this, although we haven't reached full coverage yet. Adding support for latest should be easy.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r530911031", "createdAt": "2020-11-26T10:03:41Z", "author": {"login": "hendrikmuhs"}, "path": "client/rest-high-level/src/test/java/org/elasticsearch/client/transform/transforms/latest/LatestDocConfigTests.java", "diffHunk": "@@ -0,0 +1,58 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.client.transform.transforms.latest;\n+\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.sort.SortBuilders;\n+import org.elasticsearch.test.AbstractXContentTestCase;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.function.Predicate;\n+\n+public class LatestDocConfigTests extends AbstractXContentTestCase<LatestDocConfig> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzQzMjY5NA==", "bodyText": "Done.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r533432694", "createdAt": "2020-12-01T14:07:23Z", "author": {"login": "przemekwitek"}, "path": "client/rest-high-level/src/test/java/org/elasticsearch/client/transform/transforms/latest/LatestDocConfigTests.java", "diffHunk": "@@ -0,0 +1,58 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.client.transform.transforms.latest;\n+\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.sort.SortBuilders;\n+import org.elasticsearch.test.AbstractXContentTestCase;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.function.Predicate;\n+\n+public class LatestDocConfigTests extends AbstractXContentTestCase<LatestDocConfig> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDkxMTAzMQ=="}, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyOTkxNDQyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQxMDowOTowN1rOH6Ucyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQwNzo1NTo1MFrOH9OZjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDkxNDUwNg==", "bodyText": "do we have an idea about this default? I agree that we should have a higher default than pivot.\nshould make this a constant which can be overridden with config.getMaxPageSearchSize()", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r530914506", "createdAt": "2020-11-26T10:09:07Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "diffHunk": "@@ -0,0 +1,276 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.latest;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesAction;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesRequest;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.search.SearchAction;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.query.BoolQueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.search.aggregations.Aggregation;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.Aggregations;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.metrics.TopHits;\n+import org.elasticsearch.search.aggregations.metrics.TopHitsAggregationBuilder;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.transform.TransformMessages;\n+import org.elasticsearch.xpack.core.transform.transforms.SourceConfig;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformIndexerStats;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformProgress;\n+import org.elasticsearch.xpack.core.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.xpack.transform.transforms.Function;\n+import org.elasticsearch.xpack.transform.transforms.pivot.SchemaUtil;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.function.Predicate.not;\n+import static java.util.stream.Collectors.toMap;\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class LatestDoc implements Function {\n+\n+    public static final int TEST_QUERY_PAGE_SIZE = 50;\n+\n+    private static final String COMPOSITE_AGGREGATION_NAME = \"_transform\";\n+    private static final String LATEST_AGGREGATION_NAME = \"_latest\";\n+    private static final Logger logger = LogManager.getLogger(LatestDoc.class);\n+\n+    private final LatestDocConfig config;\n+\n+    // objects for re-using\n+    private final CompositeAggregationBuilder cachedCompositeAggregation;\n+\n+    public LatestDoc(LatestDocConfig config) {\n+        if (config.getSort().size() != 1) {\n+            throw new ElasticsearchException(\"sort must specify exactly one sorting field\");\n+        }\n+        this.config = config;\n+        this.cachedCompositeAggregation = createCompositeAggregation(config);\n+    }\n+\n+    private static CompositeAggregationBuilder createCompositeAggregation(LatestDocConfig config) {\n+        assert config.getSort().size() >= 1 && config.getSort().get(0) instanceof FieldSortBuilder;\n+\n+        CompositeAggregationBuilder compositeAggregation;\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            config.toCompositeAggXContent(builder);\n+            XContentParser parser = builder.generator()\n+                .contentType()\n+                .xContent()\n+                .createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, BytesReference.bytes(builder).streamInput());\n+            compositeAggregation = CompositeAggregationBuilder.PARSER.parse(parser, COMPOSITE_AGGREGATION_NAME);\n+        } catch (IOException e) {\n+            throw new RuntimeException(\n+                TransformMessages.getMessage(TransformMessages.TRANSFORM_FAILED_TO_CREATE_COMPOSITE_AGGREGATION, \"latest_doc\"), e);\n+        }\n+        TopHitsAggregationBuilder topHitsAgg = AggregationBuilders.topHits(LATEST_AGGREGATION_NAME).size(1).sort(config.getSort().get(0));\n+        compositeAggregation.subAggregation(topHitsAgg);\n+        return compositeAggregation;\n+    }\n+\n+    @Override\n+    public int getInitialPageSize() {\n+        return 5000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzk2MTEwMw==", "bodyText": "do we have an idea about this default?\n\nTBH 5000 is an arbitrary number, not backed by any experiments.\n\nshould make this a constant which can be overridden with config.getMaxPageSearchSize()\n\nShould I add LatestDoc.getMaxPageSearchSize or maybe move PivotConfig.getMaxPageSearchSize out of pivot (but this requires BWC code...)?", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r533961103", "createdAt": "2020-12-02T07:55:50Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "diffHunk": "@@ -0,0 +1,276 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.latest;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesAction;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesRequest;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.search.SearchAction;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.query.BoolQueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.search.aggregations.Aggregation;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.Aggregations;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.metrics.TopHits;\n+import org.elasticsearch.search.aggregations.metrics.TopHitsAggregationBuilder;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.transform.TransformMessages;\n+import org.elasticsearch.xpack.core.transform.transforms.SourceConfig;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformIndexerStats;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformProgress;\n+import org.elasticsearch.xpack.core.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.xpack.transform.transforms.Function;\n+import org.elasticsearch.xpack.transform.transforms.pivot.SchemaUtil;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.function.Predicate.not;\n+import static java.util.stream.Collectors.toMap;\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class LatestDoc implements Function {\n+\n+    public static final int TEST_QUERY_PAGE_SIZE = 50;\n+\n+    private static final String COMPOSITE_AGGREGATION_NAME = \"_transform\";\n+    private static final String LATEST_AGGREGATION_NAME = \"_latest\";\n+    private static final Logger logger = LogManager.getLogger(LatestDoc.class);\n+\n+    private final LatestDocConfig config;\n+\n+    // objects for re-using\n+    private final CompositeAggregationBuilder cachedCompositeAggregation;\n+\n+    public LatestDoc(LatestDocConfig config) {\n+        if (config.getSort().size() != 1) {\n+            throw new ElasticsearchException(\"sort must specify exactly one sorting field\");\n+        }\n+        this.config = config;\n+        this.cachedCompositeAggregation = createCompositeAggregation(config);\n+    }\n+\n+    private static CompositeAggregationBuilder createCompositeAggregation(LatestDocConfig config) {\n+        assert config.getSort().size() >= 1 && config.getSort().get(0) instanceof FieldSortBuilder;\n+\n+        CompositeAggregationBuilder compositeAggregation;\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            config.toCompositeAggXContent(builder);\n+            XContentParser parser = builder.generator()\n+                .contentType()\n+                .xContent()\n+                .createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, BytesReference.bytes(builder).streamInput());\n+            compositeAggregation = CompositeAggregationBuilder.PARSER.parse(parser, COMPOSITE_AGGREGATION_NAME);\n+        } catch (IOException e) {\n+            throw new RuntimeException(\n+                TransformMessages.getMessage(TransformMessages.TRANSFORM_FAILED_TO_CREATE_COMPOSITE_AGGREGATION, \"latest_doc\"), e);\n+        }\n+        TopHitsAggregationBuilder topHitsAgg = AggregationBuilders.topHits(LATEST_AGGREGATION_NAME).size(1).sort(config.getSort().get(0));\n+        compositeAggregation.subAggregation(topHitsAgg);\n+        return compositeAggregation;\n+    }\n+\n+    @Override\n+    public int getInitialPageSize() {\n+        return 5000;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDkxNDUwNg=="}, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 103}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyOTk3NTIzOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/pivot/SchemaUtil.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQxMDoyMzo0OFrOH6VBrA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQxMDozMzozOFrOH_K0yg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDkyMzk0OA==", "bodyText": "this is used for latest? In this case we should think about moving SchemaUtil out of the pivot package.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r530923948", "createdAt": "2020-11-26T10:23:48Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/pivot/SchemaUtil.java", "diffHunk": "@@ -265,7 +265,7 @@ private static void getSourceFieldMappings(\n         );\n     }\n \n-    private static Map<String, String> extractFieldMappings(FieldCapabilitiesResponse response) {\n+    public static Map<String, String> extractFieldMappings(FieldCapabilitiesResponse response) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzQ2NjgxNA==", "bodyText": "this is used for latest?\n\nYes\n\nIn this case we should think about moving SchemaUtil out of the pivot package.\n\nAgree. I need to figure out the best class layout for that. latest only needs this small method and there are dependencies SchemaUtil -> pivot in other methods.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r533466814", "createdAt": "2020-12-01T14:46:59Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/pivot/SchemaUtil.java", "diffHunk": "@@ -265,7 +265,7 @@ private static void getSourceFieldMappings(\n         );\n     }\n \n-    private static Map<String, String> extractFieldMappings(FieldCapabilitiesResponse response) {\n+    public static Map<String, String> extractFieldMappings(FieldCapabilitiesResponse response) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDkyMzk0OA=="}, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk5OTY5MA==", "bodyText": "I've moved the extractFieldMappings method to common.DocumentConversionUtils class so that it is accessible from both pivot and latest packages.\nThis way there are no more dependencies from latest to pivot.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535999690", "createdAt": "2020-12-04T10:33:38Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/pivot/SchemaUtil.java", "diffHunk": "@@ -265,7 +265,7 @@ private static void getSourceFieldMappings(\n         );\n     }\n \n-    private static Map<String, String> extractFieldMappings(FieldCapabilitiesResponse response) {\n+    public static Map<String, String> extractFieldMappings(FieldCapabilitiesResponse response) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDkyMzk0OA=="}, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1MTE5OTI1OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/TransformConfig.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxMjoyNjoyNVrOH9Yk_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxMzoxNjowOVrOH9aalA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEyNzg3MA==", "bodyText": "TRANSFORM_CONFIGURATION_NO_TRANSFORM could you rename this message constant? I know the message is probably OK (since it says \"exactly 1\") but the constant name implies something else.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534127870", "createdAt": "2020-12-02T12:26:25Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/TransformConfig.java", "diffHunk": "@@ -176,11 +183,12 @@ public static String documentId(String transformId) {\n         this.syncConfig = syncConfig;\n         this.setHeaders(headers == null ? Collections.emptyMap() : headers);\n         this.pivotConfig = pivotConfig;\n+        this.latestDocConfig = latestDocConfig;\n         this.description = description;\n         this.settings = settings == null ? new SettingsConfig() : settings;\n \n-        // at least one function must be defined\n-        if (this.pivotConfig == null) {\n+        // exactly one function must be defined\n+        if ((this.pivotConfig == null) == (this.latestDocConfig == null)) {\n             throw new IllegalArgumentException(TransformMessages.TRANSFORM_CONFIGURATION_NO_TRANSFORM);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDE1Nzk3Mg==", "bodyText": "Done (changed to TRANSFORM_CONFIGURATION_BAD_FUNCTION_COUNT).", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534157972", "createdAt": "2020-12-02T13:16:09Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/TransformConfig.java", "diffHunk": "@@ -176,11 +183,12 @@ public static String documentId(String transformId) {\n         this.syncConfig = syncConfig;\n         this.setHeaders(headers == null ? Collections.emptyMap() : headers);\n         this.pivotConfig = pivotConfig;\n+        this.latestDocConfig = latestDocConfig;\n         this.description = description;\n         this.settings = settings == null ? new SettingsConfig() : settings;\n \n-        // at least one function must be defined\n-        if (this.pivotConfig == null) {\n+        // exactly one function must be defined\n+        if ((this.pivotConfig == null) == (this.latestDocConfig == null)) {\n             throw new IllegalArgumentException(TransformMessages.TRANSFORM_CONFIGURATION_NO_TRANSFORM);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEyNzg3MA=="}, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 97}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1MTIwOTA4OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/latest/LatestDocConfig.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxMjoyODo1NFrOH9YqxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxMzoyNjo0OFrOH9a1ow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEyOTM0OA==", "bodyText": "Is there a chance that an API caller would see this?\nIf so, we definitely need to adjust this from FieldSortBuilder to something API friendly.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534129348", "createdAt": "2020-12-02T12:28:54Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core.transform.transforms.latest;\n+\n+import org.elasticsearch.action.ActionRequestValidationException;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.bucket.terms.TermsAggregationBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+import org.elasticsearch.xpack.core.transform.utils.ExceptionsHelper;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.action.ValidateActions.addValidationError;\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+public class LatestDocConfig implements Writeable, ToXContentObject {\n+\n+    private static final String NAME = \"transform_latest_doc\";\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");\n+\n+    private final List<String> uniqueKey;\n+    private final List<SortBuilder<?>> sort;\n+\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> STRICT_PARSER = createParser(false);\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> LENIENT_PARSER = createParser(true);\n+\n+    private static ConstructingObjectParser<LatestDocConfig, Void> createParser(boolean lenient) {\n+        ConstructingObjectParser<LatestDocConfig, Void> parser =\n+            new ConstructingObjectParser<>(\n+                NAME, lenient, args -> new LatestDocConfig((List<String>) args[0], (List<SortBuilder<?>>) args[1]));\n+\n+        parser.declareStringArray(constructorArg(), UNIQUE_KEY);\n+        parser.declareField(constructorArg(), (p, c) -> SortBuilder.fromXContent(p), SORT, ObjectParser.ValueType.OBJECT_ARRAY_OR_STRING);\n+\n+        return parser;\n+    }\n+\n+    public static LatestDocConfig fromXContent(final XContentParser parser, boolean lenient) throws IOException {\n+        return lenient ? LENIENT_PARSER.apply(parser, null) : STRICT_PARSER.apply(parser, null);\n+    }\n+\n+    public LatestDocConfig(List<String> uniqueKey, List<SortBuilder<?>> sort) {\n+        this.uniqueKey = ExceptionsHelper.requireNonNull(uniqueKey, UNIQUE_KEY.getPreferredName());\n+        this.sort = ExceptionsHelper.requireNonNull(sort, SORT.getPreferredName());\n+    }\n+\n+    public LatestDocConfig(StreamInput in) throws IOException {\n+        this.uniqueKey = in.readStringList();\n+        this.sort = in.readList(FieldSortBuilder::new);\n+    }\n+\n+    public List<String> getUniqueKey() {\n+        return uniqueKey;\n+    }\n+\n+    public List<SortBuilder<?>> getSort() {\n+        return sort;\n+    }\n+\n+    public ActionRequestValidationException validate(ActionRequestValidationException validationException) {\n+        if (uniqueKey.isEmpty()) {\n+            validationException = addValidationError(\"latest_doc.unique_key must be non-empty\", validationException);\n+        } else {\n+            for (int i = 0; i < uniqueKey.size(); ++i) {\n+                if (Strings.isNullOrEmpty(uniqueKey.get(i))) {\n+                    validationException =\n+                        addValidationError(\"latest_doc.unique_key[\" + i + \"] element must be non-empty\", validationException);\n+                }\n+            }\n+        }\n+\n+        if (sort.size() != 1) {\n+            validationException = addValidationError(\"latest_doc.sort must have exactly one element\", validationException);\n+        } else {\n+            SortBuilder<?> theOnlySort = sort.get(0);\n+            if (theOnlySort instanceof FieldSortBuilder == false) {\n+                validationException =\n+                    addValidationError(\n+                        \"latest_doc.sort[0] must be of type FieldSortBuilder, was: \" + theOnlySort.getClass().getSimpleName(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDE2NDg5OQ==", "bodyText": "Done.\nThe message will be:\nlatest_doc.sort[0] must be sorting based on a document field, was: _script\n\nif the caller specifies _script sort. Similarly for other sort types.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534164899", "createdAt": "2020-12-02T13:26:48Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core.transform.transforms.latest;\n+\n+import org.elasticsearch.action.ActionRequestValidationException;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.bucket.terms.TermsAggregationBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+import org.elasticsearch.xpack.core.transform.utils.ExceptionsHelper;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.action.ValidateActions.addValidationError;\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+public class LatestDocConfig implements Writeable, ToXContentObject {\n+\n+    private static final String NAME = \"transform_latest_doc\";\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");\n+\n+    private final List<String> uniqueKey;\n+    private final List<SortBuilder<?>> sort;\n+\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> STRICT_PARSER = createParser(false);\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> LENIENT_PARSER = createParser(true);\n+\n+    private static ConstructingObjectParser<LatestDocConfig, Void> createParser(boolean lenient) {\n+        ConstructingObjectParser<LatestDocConfig, Void> parser =\n+            new ConstructingObjectParser<>(\n+                NAME, lenient, args -> new LatestDocConfig((List<String>) args[0], (List<SortBuilder<?>>) args[1]));\n+\n+        parser.declareStringArray(constructorArg(), UNIQUE_KEY);\n+        parser.declareField(constructorArg(), (p, c) -> SortBuilder.fromXContent(p), SORT, ObjectParser.ValueType.OBJECT_ARRAY_OR_STRING);\n+\n+        return parser;\n+    }\n+\n+    public static LatestDocConfig fromXContent(final XContentParser parser, boolean lenient) throws IOException {\n+        return lenient ? LENIENT_PARSER.apply(parser, null) : STRICT_PARSER.apply(parser, null);\n+    }\n+\n+    public LatestDocConfig(List<String> uniqueKey, List<SortBuilder<?>> sort) {\n+        this.uniqueKey = ExceptionsHelper.requireNonNull(uniqueKey, UNIQUE_KEY.getPreferredName());\n+        this.sort = ExceptionsHelper.requireNonNull(sort, SORT.getPreferredName());\n+    }\n+\n+    public LatestDocConfig(StreamInput in) throws IOException {\n+        this.uniqueKey = in.readStringList();\n+        this.sort = in.readList(FieldSortBuilder::new);\n+    }\n+\n+    public List<String> getUniqueKey() {\n+        return uniqueKey;\n+    }\n+\n+    public List<SortBuilder<?>> getSort() {\n+        return sort;\n+    }\n+\n+    public ActionRequestValidationException validate(ActionRequestValidationException validationException) {\n+        if (uniqueKey.isEmpty()) {\n+            validationException = addValidationError(\"latest_doc.unique_key must be non-empty\", validationException);\n+        } else {\n+            for (int i = 0; i < uniqueKey.size(); ++i) {\n+                if (Strings.isNullOrEmpty(uniqueKey.get(i))) {\n+                    validationException =\n+                        addValidationError(\"latest_doc.unique_key[\" + i + \"] element must be non-empty\", validationException);\n+                }\n+            }\n+        }\n+\n+        if (sort.size() != 1) {\n+            validationException = addValidationError(\"latest_doc.sort must have exactly one element\", validationException);\n+        } else {\n+            SortBuilder<?> theOnlySort = sort.get(0);\n+            if (theOnlySort instanceof FieldSortBuilder == false) {\n+                validationException =\n+                    addValidationError(\n+                        \"latest_doc.sort[0] must be of type FieldSortBuilder, was: \" + theOnlySort.getClass().getSimpleName(),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEyOTM0OA=="}, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 98}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1MTIyMjA5OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/common/DocumentConversionUtils.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxMjozMjoxNlrOH9Yykg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQxMDo1MzoyOFrOH_Llog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzMTM0Ng==", "bodyText": "I am not 100% sure about this. Is it valid for a user to have their OWN field that starts with _?", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534131346", "createdAt": "2020-12-02T12:32:16Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/common/DocumentConversionUtils.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.common;\n+\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Map;\n+\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class DocumentConversionUtils {\n+\n+    public static IndexRequest convertDocumentToIndexRequest(Map<String, Object> document,\n+                                                             String destinationIndex,\n+                                                             String destinationPipeline) {\n+        String id = (String) document.get(TransformField.DOCUMENT_ID_FIELD);\n+        if (id == null) {\n+            throw new RuntimeException(\"Expected a document id but got null.\");\n+        }\n+\n+        XContentBuilder builder = skipInternalFields(document);\n+        IndexRequest request = new IndexRequest(destinationIndex).source(builder).id(id);\n+        if (destinationPipeline != null) {\n+            request.setPipeline(destinationPipeline);\n+        }\n+        return request;\n+    }\n+\n+    private static XContentBuilder skipInternalFields(Map<String, Object> document) {\n+        XContentBuilder builder;\n+        try {\n+            builder = jsonBuilder();\n+            builder.startObject();\n+            for (Map.Entry<String, ?> value : document.entrySet()) {\n+                // skip all internal fields\n+                if (value.getKey().startsWith(\"_\") == false) {\n+                    builder.field(value.getKey(), value.getValue());\n+                }\n+            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTAyMjMyOQ==", "bodyText": "_ is supposed to be reserved for internal usage, but I am not sure if we are strict on it everywhere. Might be worth a follow up issue.\nWe could disallow _ prefixes in the transform config, it seems indexing allows _ as long as you do not try to set reserved fields like _index, _source, etc.\nFor aggs it is valid to start with _.\nIt seems e.g. > is invalid for aggs, so it might be better to use >. As its completely internal and not stored anywhere, we can change it without any BWC issues.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535022329", "createdAt": "2020-12-03T09:47:26Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/common/DocumentConversionUtils.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.common;\n+\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Map;\n+\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class DocumentConversionUtils {\n+\n+    public static IndexRequest convertDocumentToIndexRequest(Map<String, Object> document,\n+                                                             String destinationIndex,\n+                                                             String destinationPipeline) {\n+        String id = (String) document.get(TransformField.DOCUMENT_ID_FIELD);\n+        if (id == null) {\n+            throw new RuntimeException(\"Expected a document id but got null.\");\n+        }\n+\n+        XContentBuilder builder = skipInternalFields(document);\n+        IndexRequest request = new IndexRequest(destinationIndex).source(builder).id(id);\n+        if (destinationPipeline != null) {\n+            request.setPipeline(destinationPipeline);\n+        }\n+        return request;\n+    }\n+\n+    private static XContentBuilder skipInternalFields(Map<String, Object> document) {\n+        XContentBuilder builder;\n+        try {\n+            builder = jsonBuilder();\n+            builder.startObject();\n+            for (Map.Entry<String, ?> value : document.entrySet()) {\n+                // skip all internal fields\n+                if (value.getKey().startsWith(\"_\") == false) {\n+                    builder.field(value.getKey(), value.getValue());\n+                }\n+            }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzMTM0Ng=="}, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE3NDQ4Mg==", "bodyText": "OK, sounds good. I do think we will want to investigate this. It seems weird to not use _ fields if it is possible for valid data to have that prefix.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535174482", "createdAt": "2020-12-03T12:11:29Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/common/DocumentConversionUtils.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.common;\n+\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Map;\n+\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class DocumentConversionUtils {\n+\n+    public static IndexRequest convertDocumentToIndexRequest(Map<String, Object> document,\n+                                                             String destinationIndex,\n+                                                             String destinationPipeline) {\n+        String id = (String) document.get(TransformField.DOCUMENT_ID_FIELD);\n+        if (id == null) {\n+            throw new RuntimeException(\"Expected a document id but got null.\");\n+        }\n+\n+        XContentBuilder builder = skipInternalFields(document);\n+        IndexRequest request = new IndexRequest(destinationIndex).source(builder).id(id);\n+        if (destinationPipeline != null) {\n+            request.setPipeline(destinationPipeline);\n+        }\n+        return request;\n+    }\n+\n+    private static XContentBuilder skipInternalFields(Map<String, Object> document) {\n+        XContentBuilder builder;\n+        try {\n+            builder = jsonBuilder();\n+            builder.startObject();\n+            for (Map.Entry<String, ?> value : document.entrySet()) {\n+                // skip all internal fields\n+                if (value.getKey().startsWith(\"_\") == false) {\n+                    builder.field(value.getKey(), value.getValue());\n+                }\n+            }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzMTM0Ng=="}, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjAxMjE5NA==", "bodyText": "I agree, this needs investigation.\nI've added TODO in the DocumentConversionUtils.removeInternalFields method comment (this method now is the only place we filter based on the '_' prefix).", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r536012194", "createdAt": "2020-12-04T10:53:28Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/common/DocumentConversionUtils.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.common;\n+\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Map;\n+\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class DocumentConversionUtils {\n+\n+    public static IndexRequest convertDocumentToIndexRequest(Map<String, Object> document,\n+                                                             String destinationIndex,\n+                                                             String destinationPipeline) {\n+        String id = (String) document.get(TransformField.DOCUMENT_ID_FIELD);\n+        if (id == null) {\n+            throw new RuntimeException(\"Expected a document id but got null.\");\n+        }\n+\n+        XContentBuilder builder = skipInternalFields(document);\n+        IndexRequest request = new IndexRequest(destinationIndex).source(builder).id(id);\n+        if (destinationPipeline != null) {\n+            request.setPipeline(destinationPipeline);\n+        }\n+        return request;\n+    }\n+\n+    private static XContentBuilder skipInternalFields(Map<String, Object> document) {\n+        XContentBuilder builder;\n+        try {\n+            builder = jsonBuilder();\n+            builder.startObject();\n+            for (Map.Entry<String, ?> value : document.entrySet()) {\n+                // skip all internal fields\n+                if (value.getKey().startsWith(\"_\") == false) {\n+                    builder.field(value.getKey(), value.getValue());\n+                }\n+            }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzMTM0Ng=="}, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1MTIyODI1OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxMjozNDowMFrOH9Y2Rw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxMTo1NTo1OFrOH-Xkdg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzMjI5NQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    logger.trace(\"Search request: {}\", searchRequest);\n          \n          \n            \n                    logger.trace(() -> new ParameterizedMessage(\"Search request: {}\", searchRequest));", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534132295", "createdAt": "2020-12-02T12:34:00Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.latest;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesAction;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesRequest;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.search.SearchAction;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.query.BoolQueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.Aggregations;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.metrics.TopHits;\n+import org.elasticsearch.search.aggregations.metrics.TopHitsAggregationBuilder;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+import org.elasticsearch.xpack.core.transform.TransformMessages;\n+import org.elasticsearch.xpack.core.transform.transforms.SourceConfig;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformIndexerStats;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformProgress;\n+import org.elasticsearch.xpack.core.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.xpack.transform.transforms.Function;\n+import org.elasticsearch.xpack.transform.transforms.IDGenerator;\n+import org.elasticsearch.xpack.transform.transforms.pivot.SchemaUtil;\n+import org.elasticsearch.xpack.transform.transforms.common.DocumentConversionUtils;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.function.Predicate.not;\n+import static java.util.stream.Collectors.toMap;\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class LatestDoc implements Function {\n+\n+    public static final int DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE = 5000;\n+    public static final int TEST_QUERY_PAGE_SIZE = 50;\n+\n+    private static final String COMPOSITE_AGGREGATION_NAME = \"_transform\";\n+    private static final String TOP_HITS_AGGREGATION_NAME = \"_top_hits\";\n+    private static final Logger logger = LogManager.getLogger(LatestDoc.class);\n+\n+    private final LatestDocConfig config;\n+\n+    // objects for re-using\n+    private final CompositeAggregationBuilder cachedCompositeAggregation;\n+\n+    public LatestDoc(LatestDocConfig config) {\n+        this.config = config;\n+        this.cachedCompositeAggregation = createCompositeAggregation(config);\n+    }\n+\n+    private static CompositeAggregationBuilder createCompositeAggregation(LatestDocConfig config) {\n+        assert config.getSort().size() == 1 && config.getSort().get(0) instanceof FieldSortBuilder;\n+\n+        CompositeAggregationBuilder compositeAggregation;\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            config.toCompositeAggXContent(builder);\n+            XContentParser parser = builder.generator()\n+                .contentType()\n+                .xContent()\n+                .createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, BytesReference.bytes(builder).streamInput());\n+            compositeAggregation = CompositeAggregationBuilder.PARSER.parse(parser, COMPOSITE_AGGREGATION_NAME);\n+        } catch (IOException e) {\n+            throw new RuntimeException(\n+                TransformMessages.getMessage(TransformMessages.TRANSFORM_FAILED_TO_CREATE_COMPOSITE_AGGREGATION, \"latest_doc\"), e);\n+        }\n+        TopHitsAggregationBuilder topHitsAgg =\n+            AggregationBuilders.topHits(TOP_HITS_AGGREGATION_NAME)\n+                .size(1)  // we are only interested in the top-1\n+                .sorts(config.getSort());  // we copy the sort config directly from the function config\n+        compositeAggregation.subAggregation(topHitsAgg);\n+        return compositeAggregation;\n+    }\n+\n+    @Override\n+    public int getInitialPageSize() {\n+        return DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE;\n+    }\n+\n+    private SearchRequest buildSearchRequest(SourceConfig sourceConfig, Map<String, Object> position, int pageSize) {\n+        SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();\n+        buildSearchQuery(sourceBuilder, null, pageSize);\n+        sourceBuilder.query(sourceConfig.getQueryConfig().getQuery());\n+        SearchRequest searchRequest =\n+            new SearchRequest(sourceConfig.getIndex())\n+                .source(sourceBuilder)\n+                .indicesOptions(IndicesOptions.LENIENT_EXPAND_OPEN);\n+        logger.trace(\"Search request: {}\", searchRequest);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDE1Njc4NA==", "bodyText": "Done.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534156784", "createdAt": "2020-12-02T13:14:21Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.latest;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesAction;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesRequest;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.search.SearchAction;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.query.BoolQueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.Aggregations;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.metrics.TopHits;\n+import org.elasticsearch.search.aggregations.metrics.TopHitsAggregationBuilder;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+import org.elasticsearch.xpack.core.transform.TransformMessages;\n+import org.elasticsearch.xpack.core.transform.transforms.SourceConfig;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformIndexerStats;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformProgress;\n+import org.elasticsearch.xpack.core.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.xpack.transform.transforms.Function;\n+import org.elasticsearch.xpack.transform.transforms.IDGenerator;\n+import org.elasticsearch.xpack.transform.transforms.pivot.SchemaUtil;\n+import org.elasticsearch.xpack.transform.transforms.common.DocumentConversionUtils;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.function.Predicate.not;\n+import static java.util.stream.Collectors.toMap;\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class LatestDoc implements Function {\n+\n+    public static final int DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE = 5000;\n+    public static final int TEST_QUERY_PAGE_SIZE = 50;\n+\n+    private static final String COMPOSITE_AGGREGATION_NAME = \"_transform\";\n+    private static final String TOP_HITS_AGGREGATION_NAME = \"_top_hits\";\n+    private static final Logger logger = LogManager.getLogger(LatestDoc.class);\n+\n+    private final LatestDocConfig config;\n+\n+    // objects for re-using\n+    private final CompositeAggregationBuilder cachedCompositeAggregation;\n+\n+    public LatestDoc(LatestDocConfig config) {\n+        this.config = config;\n+        this.cachedCompositeAggregation = createCompositeAggregation(config);\n+    }\n+\n+    private static CompositeAggregationBuilder createCompositeAggregation(LatestDocConfig config) {\n+        assert config.getSort().size() == 1 && config.getSort().get(0) instanceof FieldSortBuilder;\n+\n+        CompositeAggregationBuilder compositeAggregation;\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            config.toCompositeAggXContent(builder);\n+            XContentParser parser = builder.generator()\n+                .contentType()\n+                .xContent()\n+                .createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, BytesReference.bytes(builder).streamInput());\n+            compositeAggregation = CompositeAggregationBuilder.PARSER.parse(parser, COMPOSITE_AGGREGATION_NAME);\n+        } catch (IOException e) {\n+            throw new RuntimeException(\n+                TransformMessages.getMessage(TransformMessages.TRANSFORM_FAILED_TO_CREATE_COMPOSITE_AGGREGATION, \"latest_doc\"), e);\n+        }\n+        TopHitsAggregationBuilder topHitsAgg =\n+            AggregationBuilders.topHits(TOP_HITS_AGGREGATION_NAME)\n+                .size(1)  // we are only interested in the top-1\n+                .sorts(config.getSort());  // we copy the sort config directly from the function config\n+        compositeAggregation.subAggregation(topHitsAgg);\n+        return compositeAggregation;\n+    }\n+\n+    @Override\n+    public int getInitialPageSize() {\n+        return DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE;\n+    }\n+\n+    private SearchRequest buildSearchRequest(SourceConfig sourceConfig, Map<String, Object> position, int pageSize) {\n+        SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();\n+        buildSearchQuery(sourceBuilder, null, pageSize);\n+        sourceBuilder.query(sourceConfig.getQueryConfig().getQuery());\n+        SearchRequest searchRequest =\n+            new SearchRequest(sourceConfig.getIndex())\n+                .source(sourceBuilder)\n+                .indicesOptions(IndicesOptions.LENIENT_EXPAND_OPEN);\n+        logger.trace(\"Search request: {}\", searchRequest);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzMjI5NQ=="}, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTA0ODQyMQ==", "bodyText": "as a result of my other comment, I wonder if this trace is useless. We have much better logging in the indexer and that's what people should use for debugging a transform problem. This is only called in validation and preview.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535048421", "createdAt": "2020-12-03T10:10:35Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.latest;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesAction;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesRequest;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.search.SearchAction;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.query.BoolQueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.Aggregations;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.metrics.TopHits;\n+import org.elasticsearch.search.aggregations.metrics.TopHitsAggregationBuilder;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+import org.elasticsearch.xpack.core.transform.TransformMessages;\n+import org.elasticsearch.xpack.core.transform.transforms.SourceConfig;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformIndexerStats;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformProgress;\n+import org.elasticsearch.xpack.core.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.xpack.transform.transforms.Function;\n+import org.elasticsearch.xpack.transform.transforms.IDGenerator;\n+import org.elasticsearch.xpack.transform.transforms.pivot.SchemaUtil;\n+import org.elasticsearch.xpack.transform.transforms.common.DocumentConversionUtils;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.function.Predicate.not;\n+import static java.util.stream.Collectors.toMap;\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class LatestDoc implements Function {\n+\n+    public static final int DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE = 5000;\n+    public static final int TEST_QUERY_PAGE_SIZE = 50;\n+\n+    private static final String COMPOSITE_AGGREGATION_NAME = \"_transform\";\n+    private static final String TOP_HITS_AGGREGATION_NAME = \"_top_hits\";\n+    private static final Logger logger = LogManager.getLogger(LatestDoc.class);\n+\n+    private final LatestDocConfig config;\n+\n+    // objects for re-using\n+    private final CompositeAggregationBuilder cachedCompositeAggregation;\n+\n+    public LatestDoc(LatestDocConfig config) {\n+        this.config = config;\n+        this.cachedCompositeAggregation = createCompositeAggregation(config);\n+    }\n+\n+    private static CompositeAggregationBuilder createCompositeAggregation(LatestDocConfig config) {\n+        assert config.getSort().size() == 1 && config.getSort().get(0) instanceof FieldSortBuilder;\n+\n+        CompositeAggregationBuilder compositeAggregation;\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            config.toCompositeAggXContent(builder);\n+            XContentParser parser = builder.generator()\n+                .contentType()\n+                .xContent()\n+                .createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, BytesReference.bytes(builder).streamInput());\n+            compositeAggregation = CompositeAggregationBuilder.PARSER.parse(parser, COMPOSITE_AGGREGATION_NAME);\n+        } catch (IOException e) {\n+            throw new RuntimeException(\n+                TransformMessages.getMessage(TransformMessages.TRANSFORM_FAILED_TO_CREATE_COMPOSITE_AGGREGATION, \"latest_doc\"), e);\n+        }\n+        TopHitsAggregationBuilder topHitsAgg =\n+            AggregationBuilders.topHits(TOP_HITS_AGGREGATION_NAME)\n+                .size(1)  // we are only interested in the top-1\n+                .sorts(config.getSort());  // we copy the sort config directly from the function config\n+        compositeAggregation.subAggregation(topHitsAgg);\n+        return compositeAggregation;\n+    }\n+\n+    @Override\n+    public int getInitialPageSize() {\n+        return DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE;\n+    }\n+\n+    private SearchRequest buildSearchRequest(SourceConfig sourceConfig, Map<String, Object> position, int pageSize) {\n+        SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();\n+        buildSearchQuery(sourceBuilder, null, pageSize);\n+        sourceBuilder.query(sourceConfig.getQueryConfig().getQuery());\n+        SearchRequest searchRequest =\n+            new SearchRequest(sourceConfig.getIndex())\n+                .source(sourceBuilder)\n+                .indicesOptions(IndicesOptions.LENIENT_EXPAND_OPEN);\n+        logger.trace(\"Search request: {}\", searchRequest);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzMjI5NQ=="}, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE1OTkyNg==", "bodyText": "I've just removed this trace altogether.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535159926", "createdAt": "2020-12-03T11:55:58Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.latest;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesAction;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesRequest;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.search.SearchAction;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.query.BoolQueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.Aggregations;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.metrics.TopHits;\n+import org.elasticsearch.search.aggregations.metrics.TopHitsAggregationBuilder;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+import org.elasticsearch.xpack.core.transform.TransformMessages;\n+import org.elasticsearch.xpack.core.transform.transforms.SourceConfig;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformIndexerStats;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformProgress;\n+import org.elasticsearch.xpack.core.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.xpack.transform.transforms.Function;\n+import org.elasticsearch.xpack.transform.transforms.IDGenerator;\n+import org.elasticsearch.xpack.transform.transforms.pivot.SchemaUtil;\n+import org.elasticsearch.xpack.transform.transforms.common.DocumentConversionUtils;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.function.Predicate.not;\n+import static java.util.stream.Collectors.toMap;\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class LatestDoc implements Function {\n+\n+    public static final int DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE = 5000;\n+    public static final int TEST_QUERY_PAGE_SIZE = 50;\n+\n+    private static final String COMPOSITE_AGGREGATION_NAME = \"_transform\";\n+    private static final String TOP_HITS_AGGREGATION_NAME = \"_top_hits\";\n+    private static final Logger logger = LogManager.getLogger(LatestDoc.class);\n+\n+    private final LatestDocConfig config;\n+\n+    // objects for re-using\n+    private final CompositeAggregationBuilder cachedCompositeAggregation;\n+\n+    public LatestDoc(LatestDocConfig config) {\n+        this.config = config;\n+        this.cachedCompositeAggregation = createCompositeAggregation(config);\n+    }\n+\n+    private static CompositeAggregationBuilder createCompositeAggregation(LatestDocConfig config) {\n+        assert config.getSort().size() == 1 && config.getSort().get(0) instanceof FieldSortBuilder;\n+\n+        CompositeAggregationBuilder compositeAggregation;\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            config.toCompositeAggXContent(builder);\n+            XContentParser parser = builder.generator()\n+                .contentType()\n+                .xContent()\n+                .createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, BytesReference.bytes(builder).streamInput());\n+            compositeAggregation = CompositeAggregationBuilder.PARSER.parse(parser, COMPOSITE_AGGREGATION_NAME);\n+        } catch (IOException e) {\n+            throw new RuntimeException(\n+                TransformMessages.getMessage(TransformMessages.TRANSFORM_FAILED_TO_CREATE_COMPOSITE_AGGREGATION, \"latest_doc\"), e);\n+        }\n+        TopHitsAggregationBuilder topHitsAgg =\n+            AggregationBuilders.topHits(TOP_HITS_AGGREGATION_NAME)\n+                .size(1)  // we are only interested in the top-1\n+                .sorts(config.getSort());  // we copy the sort config directly from the function config\n+        compositeAggregation.subAggregation(topHitsAgg);\n+        return compositeAggregation;\n+    }\n+\n+    @Override\n+    public int getInitialPageSize() {\n+        return DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE;\n+    }\n+\n+    private SearchRequest buildSearchRequest(SourceConfig sourceConfig, Map<String, Object> position, int pageSize) {\n+        SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();\n+        buildSearchQuery(sourceBuilder, null, pageSize);\n+        sourceBuilder.query(sourceConfig.getQueryConfig().getQuery());\n+        SearchRequest searchRequest =\n+            new SearchRequest(sourceConfig.getIndex())\n+                .source(sourceBuilder)\n+                .indicesOptions(IndicesOptions.LENIENT_EXPAND_OPEN);\n+        logger.trace(\"Search request: {}\", searchRequest);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzMjI5NQ=="}, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 117}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1MTIzNjcyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxMjozNjoxNFrOH9Y7dg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxMzoxMzoxMFrOH9aS2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzMzYyMg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                    \"Unexpected status from response of test query: \" + response.status(),\n          \n          \n            \n                                    response.status()\n          \n          \n            \n                                    \"Unexpected status from response of test query: {}\",\n          \n          \n            \n                                    response.status(),\n          \n          \n            \n                                    response.status()\n          \n      \n    \n    \n  \n\nDoesn't this work?", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534133622", "createdAt": "2020-12-02T12:36:14Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.latest;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesAction;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesRequest;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.search.SearchAction;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.query.BoolQueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.Aggregations;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.metrics.TopHits;\n+import org.elasticsearch.search.aggregations.metrics.TopHitsAggregationBuilder;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+import org.elasticsearch.xpack.core.transform.TransformMessages;\n+import org.elasticsearch.xpack.core.transform.transforms.SourceConfig;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformIndexerStats;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformProgress;\n+import org.elasticsearch.xpack.core.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.xpack.transform.transforms.Function;\n+import org.elasticsearch.xpack.transform.transforms.IDGenerator;\n+import org.elasticsearch.xpack.transform.transforms.pivot.SchemaUtil;\n+import org.elasticsearch.xpack.transform.transforms.common.DocumentConversionUtils;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.function.Predicate.not;\n+import static java.util.stream.Collectors.toMap;\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class LatestDoc implements Function {\n+\n+    public static final int DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE = 5000;\n+    public static final int TEST_QUERY_PAGE_SIZE = 50;\n+\n+    private static final String COMPOSITE_AGGREGATION_NAME = \"_transform\";\n+    private static final String TOP_HITS_AGGREGATION_NAME = \"_top_hits\";\n+    private static final Logger logger = LogManager.getLogger(LatestDoc.class);\n+\n+    private final LatestDocConfig config;\n+\n+    // objects for re-using\n+    private final CompositeAggregationBuilder cachedCompositeAggregation;\n+\n+    public LatestDoc(LatestDocConfig config) {\n+        this.config = config;\n+        this.cachedCompositeAggregation = createCompositeAggregation(config);\n+    }\n+\n+    private static CompositeAggregationBuilder createCompositeAggregation(LatestDocConfig config) {\n+        assert config.getSort().size() == 1 && config.getSort().get(0) instanceof FieldSortBuilder;\n+\n+        CompositeAggregationBuilder compositeAggregation;\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            config.toCompositeAggXContent(builder);\n+            XContentParser parser = builder.generator()\n+                .contentType()\n+                .xContent()\n+                .createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, BytesReference.bytes(builder).streamInput());\n+            compositeAggregation = CompositeAggregationBuilder.PARSER.parse(parser, COMPOSITE_AGGREGATION_NAME);\n+        } catch (IOException e) {\n+            throw new RuntimeException(\n+                TransformMessages.getMessage(TransformMessages.TRANSFORM_FAILED_TO_CREATE_COMPOSITE_AGGREGATION, \"latest_doc\"), e);\n+        }\n+        TopHitsAggregationBuilder topHitsAgg =\n+            AggregationBuilders.topHits(TOP_HITS_AGGREGATION_NAME)\n+                .size(1)  // we are only interested in the top-1\n+                .sorts(config.getSort());  // we copy the sort config directly from the function config\n+        compositeAggregation.subAggregation(topHitsAgg);\n+        return compositeAggregation;\n+    }\n+\n+    @Override\n+    public int getInitialPageSize() {\n+        return DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE;\n+    }\n+\n+    private SearchRequest buildSearchRequest(SourceConfig sourceConfig, Map<String, Object> position, int pageSize) {\n+        SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();\n+        buildSearchQuery(sourceBuilder, null, pageSize);\n+        sourceBuilder.query(sourceConfig.getQueryConfig().getQuery());\n+        SearchRequest searchRequest =\n+            new SearchRequest(sourceConfig.getIndex())\n+                .source(sourceBuilder)\n+                .indicesOptions(IndicesOptions.LENIENT_EXPAND_OPEN);\n+        logger.trace(\"Search request: {}\", searchRequest);\n+        return searchRequest;\n+    }\n+\n+    @Override\n+    public SearchSourceBuilder buildSearchQuery(SearchSourceBuilder builder, Map<String, Object> position, int pageSize) {\n+        cachedCompositeAggregation.aggregateAfter(position);\n+        cachedCompositeAggregation.size(pageSize);\n+        return builder.size(0).aggregation(cachedCompositeAggregation);\n+    }\n+\n+    @Override\n+    public ChangeCollector buildChangeCollector(String synchronizationField) {\n+        return new LatestDocChangeCollector(synchronizationField);\n+    }\n+\n+    private Stream<Map<String, Object>> extractResults(CompositeAggregation compositeAgg, TransformIndexerStats transformIndexerStats) {\n+        return compositeAgg.getBuckets().stream()\n+            .map(bucket -> {\n+                transformIndexerStats.incrementNumDocuments(bucket.getDocCount());\n+                TopHits topHits = bucket.getAggregations().get(TOP_HITS_AGGREGATION_NAME);\n+                assert topHits.getHits().getHits().length == 1;\n+                Map<String, Object> document = topHits.getHits().getHits()[0].getSourceAsMap();\n+\n+                // generator to create unique but deterministic document ids, so we\n+                // - do not create duplicates if we re-run after failure\n+                // - update documents\n+                IDGenerator idGen = new IDGenerator();\n+                config.getUniqueKey().forEach(field -> idGen.add(field, bucket.getKey().get(field)));\n+\n+                document.put(TransformField.DOCUMENT_ID_FIELD, idGen.getID());\n+                return document;\n+            });\n+    }\n+\n+    @Override\n+    public Tuple<Stream<IndexRequest>, Map<String, Object>> processSearchResponse(\n+        SearchResponse searchResponse,\n+        String destinationIndex,\n+        String destinationPipeline,\n+        Map<String, String> fieldTypeMap,\n+        TransformIndexerStats stats\n+    ) {\n+        Aggregations aggregations = searchResponse.getAggregations();\n+\n+        // Treat this as a \"we reached the end\".\n+        // This should only happen when all underlying indices have gone away. Consequently, there is no more data to read.\n+        if (aggregations == null) {\n+            return null;\n+        }\n+\n+        CompositeAggregation compositeAgg = aggregations.get(COMPOSITE_AGGREGATION_NAME);\n+        if (compositeAgg == null || compositeAgg.getBuckets().isEmpty()) {\n+            return null;\n+        }\n+\n+        Stream<IndexRequest> indexRequestStream =\n+            extractResults(compositeAgg, stats)\n+                .map(document -> DocumentConversionUtils.convertDocumentToIndexRequest(document, destinationIndex, destinationPipeline));\n+        return Tuple.tuple(indexRequestStream, compositeAgg.afterKey());\n+    }\n+\n+    @Override\n+    public void validateQuery(Client client, SourceConfig sourceConfig, ActionListener<Boolean> listener) {\n+        SearchRequest searchRequest = buildSearchRequest(sourceConfig, null, TEST_QUERY_PAGE_SIZE);\n+\n+        client.execute(SearchAction.INSTANCE, searchRequest, ActionListener.wrap(response -> {\n+            if (response == null) {\n+                listener.onFailure(\n+                    new ElasticsearchStatusException(\"Unexpected null response from test query\", RestStatus.SERVICE_UNAVAILABLE)\n+                );\n+                return;\n+            }\n+            if (response.status() != RestStatus.OK) {\n+                listener.onFailure(\n+                    new ElasticsearchStatusException(\n+                        \"Unexpected status from response of test query: \" + response.status(),\n+                        response.status()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 194}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDE1NTk5NA==", "bodyText": "I've copied this line from Pivot. Your suggestion is perfectly valid.\nI've just changed it both here and in Pivot.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534155994", "createdAt": "2020-12-02T13:13:10Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.latest;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesAction;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesRequest;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.search.SearchAction;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.query.BoolQueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.Aggregations;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.metrics.TopHits;\n+import org.elasticsearch.search.aggregations.metrics.TopHitsAggregationBuilder;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+import org.elasticsearch.xpack.core.transform.TransformMessages;\n+import org.elasticsearch.xpack.core.transform.transforms.SourceConfig;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformIndexerStats;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformProgress;\n+import org.elasticsearch.xpack.core.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.xpack.transform.transforms.Function;\n+import org.elasticsearch.xpack.transform.transforms.IDGenerator;\n+import org.elasticsearch.xpack.transform.transforms.pivot.SchemaUtil;\n+import org.elasticsearch.xpack.transform.transforms.common.DocumentConversionUtils;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.function.Predicate.not;\n+import static java.util.stream.Collectors.toMap;\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class LatestDoc implements Function {\n+\n+    public static final int DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE = 5000;\n+    public static final int TEST_QUERY_PAGE_SIZE = 50;\n+\n+    private static final String COMPOSITE_AGGREGATION_NAME = \"_transform\";\n+    private static final String TOP_HITS_AGGREGATION_NAME = \"_top_hits\";\n+    private static final Logger logger = LogManager.getLogger(LatestDoc.class);\n+\n+    private final LatestDocConfig config;\n+\n+    // objects for re-using\n+    private final CompositeAggregationBuilder cachedCompositeAggregation;\n+\n+    public LatestDoc(LatestDocConfig config) {\n+        this.config = config;\n+        this.cachedCompositeAggregation = createCompositeAggregation(config);\n+    }\n+\n+    private static CompositeAggregationBuilder createCompositeAggregation(LatestDocConfig config) {\n+        assert config.getSort().size() == 1 && config.getSort().get(0) instanceof FieldSortBuilder;\n+\n+        CompositeAggregationBuilder compositeAggregation;\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            config.toCompositeAggXContent(builder);\n+            XContentParser parser = builder.generator()\n+                .contentType()\n+                .xContent()\n+                .createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, BytesReference.bytes(builder).streamInput());\n+            compositeAggregation = CompositeAggregationBuilder.PARSER.parse(parser, COMPOSITE_AGGREGATION_NAME);\n+        } catch (IOException e) {\n+            throw new RuntimeException(\n+                TransformMessages.getMessage(TransformMessages.TRANSFORM_FAILED_TO_CREATE_COMPOSITE_AGGREGATION, \"latest_doc\"), e);\n+        }\n+        TopHitsAggregationBuilder topHitsAgg =\n+            AggregationBuilders.topHits(TOP_HITS_AGGREGATION_NAME)\n+                .size(1)  // we are only interested in the top-1\n+                .sorts(config.getSort());  // we copy the sort config directly from the function config\n+        compositeAggregation.subAggregation(topHitsAgg);\n+        return compositeAggregation;\n+    }\n+\n+    @Override\n+    public int getInitialPageSize() {\n+        return DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE;\n+    }\n+\n+    private SearchRequest buildSearchRequest(SourceConfig sourceConfig, Map<String, Object> position, int pageSize) {\n+        SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();\n+        buildSearchQuery(sourceBuilder, null, pageSize);\n+        sourceBuilder.query(sourceConfig.getQueryConfig().getQuery());\n+        SearchRequest searchRequest =\n+            new SearchRequest(sourceConfig.getIndex())\n+                .source(sourceBuilder)\n+                .indicesOptions(IndicesOptions.LENIENT_EXPAND_OPEN);\n+        logger.trace(\"Search request: {}\", searchRequest);\n+        return searchRequest;\n+    }\n+\n+    @Override\n+    public SearchSourceBuilder buildSearchQuery(SearchSourceBuilder builder, Map<String, Object> position, int pageSize) {\n+        cachedCompositeAggregation.aggregateAfter(position);\n+        cachedCompositeAggregation.size(pageSize);\n+        return builder.size(0).aggregation(cachedCompositeAggregation);\n+    }\n+\n+    @Override\n+    public ChangeCollector buildChangeCollector(String synchronizationField) {\n+        return new LatestDocChangeCollector(synchronizationField);\n+    }\n+\n+    private Stream<Map<String, Object>> extractResults(CompositeAggregation compositeAgg, TransformIndexerStats transformIndexerStats) {\n+        return compositeAgg.getBuckets().stream()\n+            .map(bucket -> {\n+                transformIndexerStats.incrementNumDocuments(bucket.getDocCount());\n+                TopHits topHits = bucket.getAggregations().get(TOP_HITS_AGGREGATION_NAME);\n+                assert topHits.getHits().getHits().length == 1;\n+                Map<String, Object> document = topHits.getHits().getHits()[0].getSourceAsMap();\n+\n+                // generator to create unique but deterministic document ids, so we\n+                // - do not create duplicates if we re-run after failure\n+                // - update documents\n+                IDGenerator idGen = new IDGenerator();\n+                config.getUniqueKey().forEach(field -> idGen.add(field, bucket.getKey().get(field)));\n+\n+                document.put(TransformField.DOCUMENT_ID_FIELD, idGen.getID());\n+                return document;\n+            });\n+    }\n+\n+    @Override\n+    public Tuple<Stream<IndexRequest>, Map<String, Object>> processSearchResponse(\n+        SearchResponse searchResponse,\n+        String destinationIndex,\n+        String destinationPipeline,\n+        Map<String, String> fieldTypeMap,\n+        TransformIndexerStats stats\n+    ) {\n+        Aggregations aggregations = searchResponse.getAggregations();\n+\n+        // Treat this as a \"we reached the end\".\n+        // This should only happen when all underlying indices have gone away. Consequently, there is no more data to read.\n+        if (aggregations == null) {\n+            return null;\n+        }\n+\n+        CompositeAggregation compositeAgg = aggregations.get(COMPOSITE_AGGREGATION_NAME);\n+        if (compositeAgg == null || compositeAgg.getBuckets().isEmpty()) {\n+            return null;\n+        }\n+\n+        Stream<IndexRequest> indexRequestStream =\n+            extractResults(compositeAgg, stats)\n+                .map(document -> DocumentConversionUtils.convertDocumentToIndexRequest(document, destinationIndex, destinationPipeline));\n+        return Tuple.tuple(indexRequestStream, compositeAgg.afterKey());\n+    }\n+\n+    @Override\n+    public void validateQuery(Client client, SourceConfig sourceConfig, ActionListener<Boolean> listener) {\n+        SearchRequest searchRequest = buildSearchRequest(sourceConfig, null, TEST_QUERY_PAGE_SIZE);\n+\n+        client.execute(SearchAction.INSTANCE, searchRequest, ActionListener.wrap(response -> {\n+            if (response == null) {\n+                listener.onFailure(\n+                    new ElasticsearchStatusException(\"Unexpected null response from test query\", RestStatus.SERVICE_UNAVAILABLE)\n+                );\n+                return;\n+            }\n+            if (response.status() != RestStatus.OK) {\n+                listener.onFailure(\n+                    new ElasticsearchStatusException(\n+                        \"Unexpected status from response of test query: \" + response.status(),\n+                        response.status()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzMzYyMg=="}, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 194}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1MTIzOTYzOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxMjozNzowNlrOH9Y9Qg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQxMDo1MjoxMVrOH_LiXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzNDA4Mg==", "bodyText": "same concern as before around user defined fields that start with _", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534134082", "createdAt": "2020-12-02T12:37:06Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.latest;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesAction;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesRequest;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.search.SearchAction;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.query.BoolQueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.Aggregations;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.metrics.TopHits;\n+import org.elasticsearch.search.aggregations.metrics.TopHitsAggregationBuilder;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+import org.elasticsearch.xpack.core.transform.TransformMessages;\n+import org.elasticsearch.xpack.core.transform.transforms.SourceConfig;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformIndexerStats;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformProgress;\n+import org.elasticsearch.xpack.core.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.xpack.transform.transforms.Function;\n+import org.elasticsearch.xpack.transform.transforms.IDGenerator;\n+import org.elasticsearch.xpack.transform.transforms.pivot.SchemaUtil;\n+import org.elasticsearch.xpack.transform.transforms.common.DocumentConversionUtils;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.function.Predicate.not;\n+import static java.util.stream.Collectors.toMap;\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class LatestDoc implements Function {\n+\n+    public static final int DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE = 5000;\n+    public static final int TEST_QUERY_PAGE_SIZE = 50;\n+\n+    private static final String COMPOSITE_AGGREGATION_NAME = \"_transform\";\n+    private static final String TOP_HITS_AGGREGATION_NAME = \"_top_hits\";\n+    private static final Logger logger = LogManager.getLogger(LatestDoc.class);\n+\n+    private final LatestDocConfig config;\n+\n+    // objects for re-using\n+    private final CompositeAggregationBuilder cachedCompositeAggregation;\n+\n+    public LatestDoc(LatestDocConfig config) {\n+        this.config = config;\n+        this.cachedCompositeAggregation = createCompositeAggregation(config);\n+    }\n+\n+    private static CompositeAggregationBuilder createCompositeAggregation(LatestDocConfig config) {\n+        assert config.getSort().size() == 1 && config.getSort().get(0) instanceof FieldSortBuilder;\n+\n+        CompositeAggregationBuilder compositeAggregation;\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            config.toCompositeAggXContent(builder);\n+            XContentParser parser = builder.generator()\n+                .contentType()\n+                .xContent()\n+                .createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, BytesReference.bytes(builder).streamInput());\n+            compositeAggregation = CompositeAggregationBuilder.PARSER.parse(parser, COMPOSITE_AGGREGATION_NAME);\n+        } catch (IOException e) {\n+            throw new RuntimeException(\n+                TransformMessages.getMessage(TransformMessages.TRANSFORM_FAILED_TO_CREATE_COMPOSITE_AGGREGATION, \"latest_doc\"), e);\n+        }\n+        TopHitsAggregationBuilder topHitsAgg =\n+            AggregationBuilders.topHits(TOP_HITS_AGGREGATION_NAME)\n+                .size(1)  // we are only interested in the top-1\n+                .sorts(config.getSort());  // we copy the sort config directly from the function config\n+        compositeAggregation.subAggregation(topHitsAgg);\n+        return compositeAggregation;\n+    }\n+\n+    @Override\n+    public int getInitialPageSize() {\n+        return DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE;\n+    }\n+\n+    private SearchRequest buildSearchRequest(SourceConfig sourceConfig, Map<String, Object> position, int pageSize) {\n+        SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();\n+        buildSearchQuery(sourceBuilder, null, pageSize);\n+        sourceBuilder.query(sourceConfig.getQueryConfig().getQuery());\n+        SearchRequest searchRequest =\n+            new SearchRequest(sourceConfig.getIndex())\n+                .source(sourceBuilder)\n+                .indicesOptions(IndicesOptions.LENIENT_EXPAND_OPEN);\n+        logger.trace(\"Search request: {}\", searchRequest);\n+        return searchRequest;\n+    }\n+\n+    @Override\n+    public SearchSourceBuilder buildSearchQuery(SearchSourceBuilder builder, Map<String, Object> position, int pageSize) {\n+        cachedCompositeAggregation.aggregateAfter(position);\n+        cachedCompositeAggregation.size(pageSize);\n+        return builder.size(0).aggregation(cachedCompositeAggregation);\n+    }\n+\n+    @Override\n+    public ChangeCollector buildChangeCollector(String synchronizationField) {\n+        return new LatestDocChangeCollector(synchronizationField);\n+    }\n+\n+    private Stream<Map<String, Object>> extractResults(CompositeAggregation compositeAgg, TransformIndexerStats transformIndexerStats) {\n+        return compositeAgg.getBuckets().stream()\n+            .map(bucket -> {\n+                transformIndexerStats.incrementNumDocuments(bucket.getDocCount());\n+                TopHits topHits = bucket.getAggregations().get(TOP_HITS_AGGREGATION_NAME);\n+                assert topHits.getHits().getHits().length == 1;\n+                Map<String, Object> document = topHits.getHits().getHits()[0].getSourceAsMap();\n+\n+                // generator to create unique but deterministic document ids, so we\n+                // - do not create duplicates if we re-run after failure\n+                // - update documents\n+                IDGenerator idGen = new IDGenerator();\n+                config.getUniqueKey().forEach(field -> idGen.add(field, bucket.getKey().get(field)));\n+\n+                document.put(TransformField.DOCUMENT_ID_FIELD, idGen.getID());\n+                return document;\n+            });\n+    }\n+\n+    @Override\n+    public Tuple<Stream<IndexRequest>, Map<String, Object>> processSearchResponse(\n+        SearchResponse searchResponse,\n+        String destinationIndex,\n+        String destinationPipeline,\n+        Map<String, String> fieldTypeMap,\n+        TransformIndexerStats stats\n+    ) {\n+        Aggregations aggregations = searchResponse.getAggregations();\n+\n+        // Treat this as a \"we reached the end\".\n+        // This should only happen when all underlying indices have gone away. Consequently, there is no more data to read.\n+        if (aggregations == null) {\n+            return null;\n+        }\n+\n+        CompositeAggregation compositeAgg = aggregations.get(COMPOSITE_AGGREGATION_NAME);\n+        if (compositeAgg == null || compositeAgg.getBuckets().isEmpty()) {\n+            return null;\n+        }\n+\n+        Stream<IndexRequest> indexRequestStream =\n+            extractResults(compositeAgg, stats)\n+                .map(document -> DocumentConversionUtils.convertDocumentToIndexRequest(document, destinationIndex, destinationPipeline));\n+        return Tuple.tuple(indexRequestStream, compositeAgg.afterKey());\n+    }\n+\n+    @Override\n+    public void validateQuery(Client client, SourceConfig sourceConfig, ActionListener<Boolean> listener) {\n+        SearchRequest searchRequest = buildSearchRequest(sourceConfig, null, TEST_QUERY_PAGE_SIZE);\n+\n+        client.execute(SearchAction.INSTANCE, searchRequest, ActionListener.wrap(response -> {\n+            if (response == null) {\n+                listener.onFailure(\n+                    new ElasticsearchStatusException(\"Unexpected null response from test query\", RestStatus.SERVICE_UNAVAILABLE)\n+                );\n+                return;\n+            }\n+            if (response.status() != RestStatus.OK) {\n+                listener.onFailure(\n+                    new ElasticsearchStatusException(\n+                        \"Unexpected status from response of test query: \" + response.status(),\n+                        response.status()\n+                    )\n+                );\n+                return;\n+            }\n+            listener.onResponse(true);\n+        }, e -> {\n+            Throwable unwrapped = ExceptionsHelper.unwrapCause(e);\n+            RestStatus status = unwrapped instanceof ElasticsearchException\n+                ? ((ElasticsearchException) unwrapped).status()\n+                : RestStatus.SERVICE_UNAVAILABLE;\n+            listener.onFailure(new ElasticsearchStatusException(\"Failed to test query\", status, unwrapped));\n+        }));\n+    }\n+\n+    @Override\n+    public void validateConfig(ActionListener<Boolean> listener) {\n+        listener.onResponse(true);\n+    }\n+\n+    @Override\n+    public void deduceMappings(Client client, SourceConfig sourceConfig, ActionListener<Map<String, String>> listener) {\n+        FieldCapabilitiesRequest fieldCapabilitiesRequest =\n+            new FieldCapabilitiesRequest().indices(sourceConfig.getIndex())\n+                .fields(\"*\")\n+                .indicesOptions(IndicesOptions.LENIENT_EXPAND_OPEN);\n+        client.execute(\n+            FieldCapabilitiesAction.INSTANCE,\n+            fieldCapabilitiesRequest,\n+            ActionListener.wrap(\n+                response -> listener.onResponse(\n+                    SchemaUtil.extractFieldMappings(response).entrySet().stream()\n+                        .filter(not(e -> e.getKey().startsWith(\"_\")))\n+                        .collect(toMap(Map.Entry::getKey, Map.Entry::getValue))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 227}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjAxMTM1Nw==", "bodyText": "Needs investigation, added TODO in the DocumentConversionUtils.removeInternalFields method comment.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r536011357", "createdAt": "2020-12-04T10:52:11Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.latest;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesAction;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesRequest;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.search.SearchAction;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.query.BoolQueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.Aggregations;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.metrics.TopHits;\n+import org.elasticsearch.search.aggregations.metrics.TopHitsAggregationBuilder;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+import org.elasticsearch.xpack.core.transform.TransformMessages;\n+import org.elasticsearch.xpack.core.transform.transforms.SourceConfig;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformIndexerStats;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformProgress;\n+import org.elasticsearch.xpack.core.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.xpack.transform.transforms.Function;\n+import org.elasticsearch.xpack.transform.transforms.IDGenerator;\n+import org.elasticsearch.xpack.transform.transforms.pivot.SchemaUtil;\n+import org.elasticsearch.xpack.transform.transforms.common.DocumentConversionUtils;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.function.Predicate.not;\n+import static java.util.stream.Collectors.toMap;\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class LatestDoc implements Function {\n+\n+    public static final int DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE = 5000;\n+    public static final int TEST_QUERY_PAGE_SIZE = 50;\n+\n+    private static final String COMPOSITE_AGGREGATION_NAME = \"_transform\";\n+    private static final String TOP_HITS_AGGREGATION_NAME = \"_top_hits\";\n+    private static final Logger logger = LogManager.getLogger(LatestDoc.class);\n+\n+    private final LatestDocConfig config;\n+\n+    // objects for re-using\n+    private final CompositeAggregationBuilder cachedCompositeAggregation;\n+\n+    public LatestDoc(LatestDocConfig config) {\n+        this.config = config;\n+        this.cachedCompositeAggregation = createCompositeAggregation(config);\n+    }\n+\n+    private static CompositeAggregationBuilder createCompositeAggregation(LatestDocConfig config) {\n+        assert config.getSort().size() == 1 && config.getSort().get(0) instanceof FieldSortBuilder;\n+\n+        CompositeAggregationBuilder compositeAggregation;\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            config.toCompositeAggXContent(builder);\n+            XContentParser parser = builder.generator()\n+                .contentType()\n+                .xContent()\n+                .createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, BytesReference.bytes(builder).streamInput());\n+            compositeAggregation = CompositeAggregationBuilder.PARSER.parse(parser, COMPOSITE_AGGREGATION_NAME);\n+        } catch (IOException e) {\n+            throw new RuntimeException(\n+                TransformMessages.getMessage(TransformMessages.TRANSFORM_FAILED_TO_CREATE_COMPOSITE_AGGREGATION, \"latest_doc\"), e);\n+        }\n+        TopHitsAggregationBuilder topHitsAgg =\n+            AggregationBuilders.topHits(TOP_HITS_AGGREGATION_NAME)\n+                .size(1)  // we are only interested in the top-1\n+                .sorts(config.getSort());  // we copy the sort config directly from the function config\n+        compositeAggregation.subAggregation(topHitsAgg);\n+        return compositeAggregation;\n+    }\n+\n+    @Override\n+    public int getInitialPageSize() {\n+        return DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE;\n+    }\n+\n+    private SearchRequest buildSearchRequest(SourceConfig sourceConfig, Map<String, Object> position, int pageSize) {\n+        SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();\n+        buildSearchQuery(sourceBuilder, null, pageSize);\n+        sourceBuilder.query(sourceConfig.getQueryConfig().getQuery());\n+        SearchRequest searchRequest =\n+            new SearchRequest(sourceConfig.getIndex())\n+                .source(sourceBuilder)\n+                .indicesOptions(IndicesOptions.LENIENT_EXPAND_OPEN);\n+        logger.trace(\"Search request: {}\", searchRequest);\n+        return searchRequest;\n+    }\n+\n+    @Override\n+    public SearchSourceBuilder buildSearchQuery(SearchSourceBuilder builder, Map<String, Object> position, int pageSize) {\n+        cachedCompositeAggregation.aggregateAfter(position);\n+        cachedCompositeAggregation.size(pageSize);\n+        return builder.size(0).aggregation(cachedCompositeAggregation);\n+    }\n+\n+    @Override\n+    public ChangeCollector buildChangeCollector(String synchronizationField) {\n+        return new LatestDocChangeCollector(synchronizationField);\n+    }\n+\n+    private Stream<Map<String, Object>> extractResults(CompositeAggregation compositeAgg, TransformIndexerStats transformIndexerStats) {\n+        return compositeAgg.getBuckets().stream()\n+            .map(bucket -> {\n+                transformIndexerStats.incrementNumDocuments(bucket.getDocCount());\n+                TopHits topHits = bucket.getAggregations().get(TOP_HITS_AGGREGATION_NAME);\n+                assert topHits.getHits().getHits().length == 1;\n+                Map<String, Object> document = topHits.getHits().getHits()[0].getSourceAsMap();\n+\n+                // generator to create unique but deterministic document ids, so we\n+                // - do not create duplicates if we re-run after failure\n+                // - update documents\n+                IDGenerator idGen = new IDGenerator();\n+                config.getUniqueKey().forEach(field -> idGen.add(field, bucket.getKey().get(field)));\n+\n+                document.put(TransformField.DOCUMENT_ID_FIELD, idGen.getID());\n+                return document;\n+            });\n+    }\n+\n+    @Override\n+    public Tuple<Stream<IndexRequest>, Map<String, Object>> processSearchResponse(\n+        SearchResponse searchResponse,\n+        String destinationIndex,\n+        String destinationPipeline,\n+        Map<String, String> fieldTypeMap,\n+        TransformIndexerStats stats\n+    ) {\n+        Aggregations aggregations = searchResponse.getAggregations();\n+\n+        // Treat this as a \"we reached the end\".\n+        // This should only happen when all underlying indices have gone away. Consequently, there is no more data to read.\n+        if (aggregations == null) {\n+            return null;\n+        }\n+\n+        CompositeAggregation compositeAgg = aggregations.get(COMPOSITE_AGGREGATION_NAME);\n+        if (compositeAgg == null || compositeAgg.getBuckets().isEmpty()) {\n+            return null;\n+        }\n+\n+        Stream<IndexRequest> indexRequestStream =\n+            extractResults(compositeAgg, stats)\n+                .map(document -> DocumentConversionUtils.convertDocumentToIndexRequest(document, destinationIndex, destinationPipeline));\n+        return Tuple.tuple(indexRequestStream, compositeAgg.afterKey());\n+    }\n+\n+    @Override\n+    public void validateQuery(Client client, SourceConfig sourceConfig, ActionListener<Boolean> listener) {\n+        SearchRequest searchRequest = buildSearchRequest(sourceConfig, null, TEST_QUERY_PAGE_SIZE);\n+\n+        client.execute(SearchAction.INSTANCE, searchRequest, ActionListener.wrap(response -> {\n+            if (response == null) {\n+                listener.onFailure(\n+                    new ElasticsearchStatusException(\"Unexpected null response from test query\", RestStatus.SERVICE_UNAVAILABLE)\n+                );\n+                return;\n+            }\n+            if (response.status() != RestStatus.OK) {\n+                listener.onFailure(\n+                    new ElasticsearchStatusException(\n+                        \"Unexpected status from response of test query: \" + response.status(),\n+                        response.status()\n+                    )\n+                );\n+                return;\n+            }\n+            listener.onResponse(true);\n+        }, e -> {\n+            Throwable unwrapped = ExceptionsHelper.unwrapCause(e);\n+            RestStatus status = unwrapped instanceof ElasticsearchException\n+                ? ((ElasticsearchException) unwrapped).status()\n+                : RestStatus.SERVICE_UNAVAILABLE;\n+            listener.onFailure(new ElasticsearchStatusException(\"Failed to test query\", status, unwrapped));\n+        }));\n+    }\n+\n+    @Override\n+    public void validateConfig(ActionListener<Boolean> listener) {\n+        listener.onResponse(true);\n+    }\n+\n+    @Override\n+    public void deduceMappings(Client client, SourceConfig sourceConfig, ActionListener<Map<String, String>> listener) {\n+        FieldCapabilitiesRequest fieldCapabilitiesRequest =\n+            new FieldCapabilitiesRequest().indices(sourceConfig.getIndex())\n+                .fields(\"*\")\n+                .indicesOptions(IndicesOptions.LENIENT_EXPAND_OPEN);\n+        client.execute(\n+            FieldCapabilitiesAction.INSTANCE,\n+            fieldCapabilitiesRequest,\n+            ActionListener.wrap(\n+                response -> listener.onResponse(\n+                    SchemaUtil.extractFieldMappings(response).entrySet().stream()\n+                        .filter(not(e -> e.getKey().startsWith(\"_\")))\n+                        .collect(toMap(Map.Entry::getKey, Map.Entry::getValue))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzNDA4Mg=="}, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 227}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1MTI1MDYyOnYy", "diffSide": "LEFT", "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/pivot/Pivot.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxMjo0MDowMlrOH9ZD5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQxMDo1MjoyN1rOH_LjLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzNTc4MQ==", "bodyText": "Ah, I see the pivot was already doing this. But it is still a concern. Especially since now as we are copying the doc directly.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534135781", "createdAt": "2020-12-02T12:40:02Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/pivot/Pivot.java", "diffHunk": "@@ -142,17 +136,17 @@ public void preview(\n                     final Aggregations aggregations = r.getAggregations();\n                     if (aggregations == null) {\n                         listener.onFailure(\n-                            new ElasticsearchStatusException(\"Source indices have been deleted or closed.\", RestStatus.BAD_REQUEST)\n-                        );\n+                            new ElasticsearchStatusException(\"Source indices have been deleted or closed.\", RestStatus.BAD_REQUEST));\n                         return;\n                     }\n                     final CompositeAggregation agg = aggregations.get(COMPOSITE_AGGREGATION_NAME);\n                     TransformIndexerStats stats = new TransformIndexerStats();\n-                    // remove all internal fields\n \n-                    List<Map<String, Object>> docs = extractResults(agg, fieldTypeMap, stats).peek(\n-                        doc -> doc.keySet().removeIf(k -> k.startsWith(\"_\"))\n-                    ).collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjAxMTU2NQ==", "bodyText": "Needs investigation, added TODO in the DocumentConversionUtils.removeInternalFields method comment.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r536011565", "createdAt": "2020-12-04T10:52:27Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/pivot/Pivot.java", "diffHunk": "@@ -142,17 +136,17 @@ public void preview(\n                     final Aggregations aggregations = r.getAggregations();\n                     if (aggregations == null) {\n                         listener.onFailure(\n-                            new ElasticsearchStatusException(\"Source indices have been deleted or closed.\", RestStatus.BAD_REQUEST)\n-                        );\n+                            new ElasticsearchStatusException(\"Source indices have been deleted or closed.\", RestStatus.BAD_REQUEST));\n                         return;\n                     }\n                     final CompositeAggregation agg = aggregations.get(COMPOSITE_AGGREGATION_NAME);\n                     TransformIndexerStats stats = new TransformIndexerStats();\n-                    // remove all internal fields\n \n-                    List<Map<String, Object>> docs = extractResults(agg, fieldTypeMap, stats).peek(\n-                        doc -> doc.keySet().removeIf(k -> k.startsWith(\"_\"))\n-                    ).collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzNTc4MQ=="}, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 58}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1NjAwMzkzOnYy", "diffSide": "RIGHT", "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/transform/transforms/TransformConfig.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QwODoyMTowMVrOH-HiEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxMToyMDo0MlrOH-VbYg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDg5NzE2OQ==", "bodyText": "rename if we settle on latest", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534897169", "createdAt": "2020-12-03T08:21:01Z", "author": {"login": "hendrikmuhs"}, "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/transform/transforms/TransformConfig.java", "diffHunk": "@@ -61,6 +63,7 @@\n     private final SyncConfig syncConfig;\n     private final SettingsConfig settings;\n     private final PivotConfig pivotConfig;\n+    private final LatestDocConfig latestDocConfig;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTEyNDgzNA==", "bodyText": "Done (for variable names and method names).\nI'll rename classes (LatestDocConfig, LatestDoc) closer to the end of review not to break continuity of comments in GitHub history.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535124834", "createdAt": "2020-12-03T11:20:42Z", "author": {"login": "przemekwitek"}, "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/transform/transforms/TransformConfig.java", "diffHunk": "@@ -61,6 +63,7 @@\n     private final SyncConfig syncConfig;\n     private final SettingsConfig settings;\n     private final PivotConfig pivotConfig;\n+    private final LatestDocConfig latestDocConfig;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDg5NzE2OQ=="}, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1NjIwMDkyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/TransformConfig.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QwODo0MjoxN1rOH-JqCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxMTozNjozNlrOH-Wbpg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkzMTk3Ng==", "bodyText": "nit: although I think it will never be possible, it would be more correct to move this into the if below line 103.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534931976", "createdAt": "2020-12-03T08:42:17Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/TransformConfig.java", "diffHunk": "@@ -176,12 +183,13 @@ public static String documentId(String transformId) {\n         this.syncConfig = syncConfig;\n         this.setHeaders(headers == null ? Collections.emptyMap() : headers);\n         this.pivotConfig = pivotConfig;\n+        this.latestDocConfig = latestDocConfig;\n         this.description = description;\n         this.settings = settings == null ? new SettingsConfig() : settings;\n \n-        // at least one function must be defined\n-        if (this.pivotConfig == null) {\n-            throw new IllegalArgumentException(TransformMessages.TRANSFORM_CONFIGURATION_NO_TRANSFORM);\n+        // exactly one function must be defined\n+        if ((this.pivotConfig == null) == (this.latestDocConfig == null)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE0MTI4Ng==", "bodyText": "Done.\nBut what if lenient == true? Should I also add a validation in validate() method?", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535141286", "createdAt": "2020-12-03T11:36:36Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/TransformConfig.java", "diffHunk": "@@ -176,12 +183,13 @@ public static String documentId(String transformId) {\n         this.syncConfig = syncConfig;\n         this.setHeaders(headers == null ? Collections.emptyMap() : headers);\n         this.pivotConfig = pivotConfig;\n+        this.latestDocConfig = latestDocConfig;\n         this.description = description;\n         this.settings = settings == null ? new SettingsConfig() : settings;\n \n-        // at least one function must be defined\n-        if (this.pivotConfig == null) {\n-            throw new IllegalArgumentException(TransformMessages.TRANSFORM_CONFIGURATION_NO_TRANSFORM);\n+        // exactly one function must be defined\n+        if ((this.pivotConfig == null) == (this.latestDocConfig == null)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkzMTk3Ng=="}, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 97}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1NjIxNjAyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/latest/LatestDocConfig.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QwODo0Mzo1NFrOH-J0pg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQxMDowNzowMFrOIBRWOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkzNDY5NA==", "bodyText": "could be a set?", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534934694", "createdAt": "2020-12-03T08:43:54Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core.transform.transforms.latest;\n+\n+import org.elasticsearch.action.ActionRequestValidationException;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.bucket.terms.TermsAggregationBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+import org.elasticsearch.search.sort.SortBuilders;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.xpack.core.transform.utils.ExceptionsHelper;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.action.ValidateActions.addValidationError;\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+public class LatestDocConfig implements Writeable, ToXContentObject {\n+\n+    private static final String NAME = \"latest_config\";\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");\n+\n+    private final List<String> uniqueKey;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE0Mzc0MA==", "bodyText": "I'm wondering if there will be cases where the user will want to influence the order of fields in case they know composite aggregation is used internally by transform. Having deterministic order of items in this collection would help them achieve that.\nWDYT?", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535143740", "createdAt": "2020-12-03T11:39:11Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core.transform.transforms.latest;\n+\n+import org.elasticsearch.action.ActionRequestValidationException;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.bucket.terms.TermsAggregationBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+import org.elasticsearch.search.sort.SortBuilders;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.xpack.core.transform.utils.ExceptionsHelper;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.action.ValidateActions.addValidationError;\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+public class LatestDocConfig implements Writeable, ToXContentObject {\n+\n+    private static final String NAME = \"latest_config\";\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");\n+\n+    private final List<String> uniqueKey;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkzNDY5NA=="}, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODIwMzcwNg==", "bodyText": "good point, there is the case where index sort matters, so lets keep List", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r538203706", "createdAt": "2020-12-08T10:07:00Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core.transform.transforms.latest;\n+\n+import org.elasticsearch.action.ActionRequestValidationException;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.bucket.terms.TermsAggregationBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+import org.elasticsearch.search.sort.SortBuilders;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.xpack.core.transform.utils.ExceptionsHelper;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.action.ValidateActions.addValidationError;\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+public class LatestDocConfig implements Writeable, ToXContentObject {\n+\n+    private static final String NAME = \"latest_config\";\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");\n+\n+    private final List<String> uniqueKey;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkzNDY5NA=="}, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1NjMyMjUzOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/latest/LatestDocConfig.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QwODo1MzoyNFrOH-K-Ow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxNDowOTowOFrOH-dbRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDk1MzUzMQ==", "bodyText": "it should not be possible (for strict) to allow unique_key double entries (see my comment regarding using set). To be able to use a set, it seems ok to de-dedup on lenient and throw on strict.\n(same for sort)", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534953531", "createdAt": "2020-12-03T08:53:24Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core.transform.transforms.latest;\n+\n+import org.elasticsearch.action.ActionRequestValidationException;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.bucket.terms.TermsAggregationBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+import org.elasticsearch.search.sort.SortBuilders;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.xpack.core.transform.utils.ExceptionsHelper;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.action.ValidateActions.addValidationError;\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+public class LatestDocConfig implements Writeable, ToXContentObject {\n+\n+    private static final String NAME = \"latest_config\";\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");\n+\n+    private final List<String> uniqueKey;\n+    private final String sort;\n+\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> STRICT_PARSER = createParser(false);\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> LENIENT_PARSER = createParser(true);\n+\n+    private static ConstructingObjectParser<LatestDocConfig, Void> createParser(boolean lenient) {\n+        ConstructingObjectParser<LatestDocConfig, Void> parser =\n+            new ConstructingObjectParser<>(NAME, lenient, args -> new LatestDocConfig((List<String>) args[0], (String) args[1]));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTI1NTg3Ng==", "bodyText": "it should not be possible (for strict) to allow unique_key double entries (see my comment regarding using set). To be able to use a set, it seems ok to de-dedup on lenient and throw on strict.\n\nOk, Im a bit lost on what to consider a parsing failure (throw from fromXContent()) vs validation failure (throw from validate()).\nCurrently validate() method has the following checks:\n\nnon-empty unique_key array\nnon-empty unique_key elements\nnon-empty sort field\n\nI've just also added a check for duplicate elements to validate().\nWhich of the checks mentioned above should be moved to parser? Could you give me some guidance on how do I decide that on a per-check basis?\n\n(same for sort)\n\nsort is now a singular field (not an array) so I think this comment no longer applies.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535255876", "createdAt": "2020-12-03T14:09:08Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core.transform.transforms.latest;\n+\n+import org.elasticsearch.action.ActionRequestValidationException;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.bucket.terms.TermsAggregationBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+import org.elasticsearch.search.sort.SortBuilders;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.xpack.core.transform.utils.ExceptionsHelper;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.action.ValidateActions.addValidationError;\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+public class LatestDocConfig implements Writeable, ToXContentObject {\n+\n+    private static final String NAME = \"latest_config\";\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");\n+\n+    private final List<String> uniqueKey;\n+    private final String sort;\n+\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> STRICT_PARSER = createParser(false);\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> LENIENT_PARSER = createParser(true);\n+\n+    private static ConstructingObjectParser<LatestDocConfig, Void> createParser(boolean lenient) {\n+        ConstructingObjectParser<LatestDocConfig, Void> parser =\n+            new ConstructingObjectParser<>(NAME, lenient, args -> new LatestDocConfig((List<String>) args[0], (String) args[1]));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDk1MzUzMQ=="}, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1NjQzMDUzOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/latest/LatestDocConfig.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QwOTowNDowNVrOH-MHZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxMjoxNzo1M1rOH-Y2Fw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDk3MjI2MQ==", "bodyText": "add missing_bucket here", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534972261", "createdAt": "2020-12-03T09:04:05Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core.transform.transforms.latest;\n+\n+import org.elasticsearch.action.ActionRequestValidationException;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.bucket.terms.TermsAggregationBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+import org.elasticsearch.search.sort.SortBuilders;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.xpack.core.transform.utils.ExceptionsHelper;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.action.ValidateActions.addValidationError;\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+public class LatestDocConfig implements Writeable, ToXContentObject {\n+\n+    private static final String NAME = \"latest_config\";\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");\n+\n+    private final List<String> uniqueKey;\n+    private final String sort;\n+\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> STRICT_PARSER = createParser(false);\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> LENIENT_PARSER = createParser(true);\n+\n+    private static ConstructingObjectParser<LatestDocConfig, Void> createParser(boolean lenient) {\n+        ConstructingObjectParser<LatestDocConfig, Void> parser =\n+            new ConstructingObjectParser<>(NAME, lenient, args -> new LatestDocConfig((List<String>) args[0], (String) args[1]));\n+\n+        parser.declareStringArray(constructorArg(), UNIQUE_KEY);\n+        parser.declareString(constructorArg(), SORT);\n+\n+        return parser;\n+    }\n+\n+    public static LatestDocConfig fromXContent(final XContentParser parser, boolean lenient) throws IOException {\n+        return lenient ? LENIENT_PARSER.apply(parser, null) : STRICT_PARSER.apply(parser, null);\n+    }\n+\n+    public LatestDocConfig(List<String> uniqueKey, String sort) {\n+        this.uniqueKey = ExceptionsHelper.requireNonNull(uniqueKey, UNIQUE_KEY.getPreferredName());\n+        this.sort = ExceptionsHelper.requireNonNull(sort, SORT.getPreferredName());\n+    }\n+\n+    public LatestDocConfig(StreamInput in) throws IOException {\n+        this.uniqueKey = in.readStringList();\n+        this.sort = in.readString();\n+    }\n+\n+    public List<String> getUniqueKey() {\n+        return uniqueKey;\n+    }\n+\n+    public String getSort() {\n+        return sort;\n+    }\n+\n+    public List<SortBuilder<?>> getSorts() {\n+        return Collections.singletonList(SortBuilders.fieldSort(sort).order(SortOrder.DESC));\n+    }\n+\n+    public ActionRequestValidationException validate(ActionRequestValidationException validationException) {\n+        if (uniqueKey.isEmpty()) {\n+            validationException = addValidationError(\"latest.unique_key must be non-empty\", validationException);\n+        } else {\n+            for (int i = 0; i < uniqueKey.size(); ++i) {\n+                if (uniqueKey.get(i).isEmpty()) {\n+                    validationException =\n+                        addValidationError(\"latest.unique_key[\" + i + \"] element must be non-empty\", validationException);\n+                }\n+            }\n+        }\n+\n+        if (sort.isEmpty()) {\n+            validationException = addValidationError(\"latest.sort must be non-empty\", validationException);\n+        }\n+\n+        return validationException;\n+    }\n+\n+    @Override\n+    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n+        builder.startObject();\n+        builder.field(UNIQUE_KEY.getPreferredName(), uniqueKey);\n+        builder.field(SORT.getPreferredName(), sort);\n+        builder.endObject();\n+        return builder;\n+    }\n+\n+    public void toCompositeAggXContent(XContentBuilder builder) throws IOException {\n+        builder.startObject();\n+        builder.field(CompositeAggregationBuilder.SOURCES_FIELD_NAME.getPreferredName());\n+\n+        builder.startArray();\n+        for (String field : uniqueKey) {\n+            builder.startObject();\n+            builder.startObject(field);\n+            builder.startObject(TermsAggregationBuilder.NAME);\n+            builder.field(\"field\", field);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE4MDgyMw==", "bodyText": "Done.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535180823", "createdAt": "2020-12-03T12:17:53Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core.transform.transforms.latest;\n+\n+import org.elasticsearch.action.ActionRequestValidationException;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.bucket.terms.TermsAggregationBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+import org.elasticsearch.search.sort.SortBuilders;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.xpack.core.transform.utils.ExceptionsHelper;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.action.ValidateActions.addValidationError;\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+public class LatestDocConfig implements Writeable, ToXContentObject {\n+\n+    private static final String NAME = \"latest_config\";\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");\n+\n+    private final List<String> uniqueKey;\n+    private final String sort;\n+\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> STRICT_PARSER = createParser(false);\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> LENIENT_PARSER = createParser(true);\n+\n+    private static ConstructingObjectParser<LatestDocConfig, Void> createParser(boolean lenient) {\n+        ConstructingObjectParser<LatestDocConfig, Void> parser =\n+            new ConstructingObjectParser<>(NAME, lenient, args -> new LatestDocConfig((List<String>) args[0], (String) args[1]));\n+\n+        parser.declareStringArray(constructorArg(), UNIQUE_KEY);\n+        parser.declareString(constructorArg(), SORT);\n+\n+        return parser;\n+    }\n+\n+    public static LatestDocConfig fromXContent(final XContentParser parser, boolean lenient) throws IOException {\n+        return lenient ? LENIENT_PARSER.apply(parser, null) : STRICT_PARSER.apply(parser, null);\n+    }\n+\n+    public LatestDocConfig(List<String> uniqueKey, String sort) {\n+        this.uniqueKey = ExceptionsHelper.requireNonNull(uniqueKey, UNIQUE_KEY.getPreferredName());\n+        this.sort = ExceptionsHelper.requireNonNull(sort, SORT.getPreferredName());\n+    }\n+\n+    public LatestDocConfig(StreamInput in) throws IOException {\n+        this.uniqueKey = in.readStringList();\n+        this.sort = in.readString();\n+    }\n+\n+    public List<String> getUniqueKey() {\n+        return uniqueKey;\n+    }\n+\n+    public String getSort() {\n+        return sort;\n+    }\n+\n+    public List<SortBuilder<?>> getSorts() {\n+        return Collections.singletonList(SortBuilders.fieldSort(sort).order(SortOrder.DESC));\n+    }\n+\n+    public ActionRequestValidationException validate(ActionRequestValidationException validationException) {\n+        if (uniqueKey.isEmpty()) {\n+            validationException = addValidationError(\"latest.unique_key must be non-empty\", validationException);\n+        } else {\n+            for (int i = 0; i < uniqueKey.size(); ++i) {\n+                if (uniqueKey.get(i).isEmpty()) {\n+                    validationException =\n+                        addValidationError(\"latest.unique_key[\" + i + \"] element must be non-empty\", validationException);\n+                }\n+            }\n+        }\n+\n+        if (sort.isEmpty()) {\n+            validationException = addValidationError(\"latest.sort must be non-empty\", validationException);\n+        }\n+\n+        return validationException;\n+    }\n+\n+    @Override\n+    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n+        builder.startObject();\n+        builder.field(UNIQUE_KEY.getPreferredName(), uniqueKey);\n+        builder.field(SORT.getPreferredName(), sort);\n+        builder.endObject();\n+        return builder;\n+    }\n+\n+    public void toCompositeAggXContent(XContentBuilder builder) throws IOException {\n+        builder.startObject();\n+        builder.field(CompositeAggregationBuilder.SOURCES_FIELD_NAME.getPreferredName());\n+\n+        builder.startArray();\n+        for (String field : uniqueKey) {\n+            builder.startObject();\n+            builder.startObject(field);\n+            builder.startObject(TermsAggregationBuilder.NAME);\n+            builder.field(\"field\", field);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDk3MjI2MQ=="}, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 119}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1NjUzNjI0OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/TransformConfig.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QwOToyMDo1OFrOH-NLdQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxNDowMDozNlrOH-dDUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDk4OTY4NQ==", "bodyText": "see below, you also need to implement isValid(). This is some legacy code, #59588 is a todo to clean this up. The difference between the 2:\n\nvalidate is used for actions\nisValid is called when a transform starts as a check before the task runs, so this is not part of an action\n\nWe should consolidate this, for now try to reuse validate. Maybe you can just call validate and check for !null (no need to copy bad code). Long term we should change validate to return ValidationException and translate it to ActionRequestValidationException on the outer layer. ActionRequestValidationException is just a facade.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534989685", "createdAt": "2020-12-03T09:20:58Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/TransformConfig.java", "diffHunk": "@@ -297,8 +300,10 @@ public ActionRequestValidationException validate(ActionRequestValidationExceptio\n         if (pivotConfig != null) {\n             validationException = pivotConfig.validate(validationException);\n         }\n+        if (latestDocConfig != null) {\n+            validationException = latestDocConfig.validate(validationException);\n+        }\n         validationException = settings.validate(validationException);\n-\n         return validationException;\n     }\n ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 157}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTI0OTc0Nw==", "bodyText": "Done.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535249747", "createdAt": "2020-12-03T14:00:36Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/TransformConfig.java", "diffHunk": "@@ -297,8 +300,10 @@ public ActionRequestValidationException validate(ActionRequestValidationExceptio\n         if (pivotConfig != null) {\n             validationException = pivotConfig.validate(validationException);\n         }\n+        if (latestDocConfig != null) {\n+            validationException = latestDocConfig.validate(validationException);\n+        }\n         validationException = settings.validate(validationException);\n-\n         return validationException;\n     }\n ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDk4OTY4NQ=="}, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 157}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1NjU4NjI1OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/transform/qa/multi-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/transform/integration/LatestDocIT.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QwOToyNzoxNlrOH-NtCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxMjo0Mjo1NFrOH-ZywA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDk5ODI4MA==", "bodyText": "can you add sparse data, so we cover missing_bucket?", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534998280", "createdAt": "2020-12-03T09:27:16Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/transform/qa/multi-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/transform/integration/LatestDocIT.java", "diffHunk": "@@ -0,0 +1,167 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.integration;\n+\n+import org.elasticsearch.action.admin.indices.refresh.RefreshRequest;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.client.RequestOptions;\n+import org.elasticsearch.client.RestHighLevelClient;\n+import org.elasticsearch.client.indices.GetMappingsRequest;\n+import org.elasticsearch.client.indices.GetMappingsResponse;\n+import org.elasticsearch.client.transform.PreviewTransformRequest;\n+import org.elasticsearch.client.transform.PreviewTransformResponse;\n+import org.elasticsearch.client.transform.transforms.TransformConfig;\n+import org.elasticsearch.client.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.search.SearchHit;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.junit.After;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.stream.Stream;\n+\n+import static java.util.stream.Collectors.toList;\n+import static org.hamcrest.Matchers.containsInAnyOrder;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.is;\n+\n+public class LatestDocIT extends TransformIntegTestCase {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE5NjM1Mg==", "bodyText": "Done.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535196352", "createdAt": "2020-12-03T12:42:54Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/transform/qa/multi-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/transform/integration/LatestDocIT.java", "diffHunk": "@@ -0,0 +1,167 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.integration;\n+\n+import org.elasticsearch.action.admin.indices.refresh.RefreshRequest;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.client.RequestOptions;\n+import org.elasticsearch.client.RestHighLevelClient;\n+import org.elasticsearch.client.indices.GetMappingsRequest;\n+import org.elasticsearch.client.indices.GetMappingsResponse;\n+import org.elasticsearch.client.transform.PreviewTransformRequest;\n+import org.elasticsearch.client.transform.PreviewTransformResponse;\n+import org.elasticsearch.client.transform.transforms.TransformConfig;\n+import org.elasticsearch.client.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.search.SearchHit;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.junit.After;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.stream.Stream;\n+\n+import static java.util.stream.Collectors.toList;\n+import static org.hamcrest.Matchers.containsInAnyOrder;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.is;\n+\n+public class LatestDocIT extends TransformIntegTestCase {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDk5ODI4MA=="}, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1NjY1MzY4OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/transform/qa/single-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/transform/integration/continuous/ContinuousTestCase.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QwOTozNToyOVrOH-OaDQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxNDowNDowNVrOH-dMdA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTAwOTgwNQ==", "bodyText": "this conflicts with my PR, where I use addCommonSetings. Maybe it is better to remove addCommonBuilderParameters instead.\nHowever as we are working in parallel on this, I think it is best to avoid changing this for now, but in a follow up PR.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535009805", "createdAt": "2020-12-03T09:35:29Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/transform/qa/single-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/transform/integration/continuous/ContinuousTestCase.java", "diffHunk": "@@ -75,28 +76,29 @@\n      * Test results after 1 iteration in the test runner.\n      *\n      * @param iteration the current iteration\n+     * @param modifiedEvents set of events modified in the current iteration\n      */\n-    public abstract void testIteration(int iteration) throws IOException;\n+    public abstract void testIteration(int iteration, Set<String> modifiedEvents) throws IOException;\n \n     protected TransformConfig.Builder addCommonBuilderParameters(TransformConfig.Builder builder) {\n-        return builder.setSyncConfig(getSyncConfig())\n-            .setSettings(addCommonSetings(new SettingsConfig.Builder()).build())\n+        return builder\n+            .setSyncConfig(getSyncConfig())\n+            .setSettings(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTI1MjA4NA==", "bodyText": "Fair enough, reverted.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535252084", "createdAt": "2020-12-03T14:04:05Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/transform/qa/single-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/transform/integration/continuous/ContinuousTestCase.java", "diffHunk": "@@ -75,28 +76,29 @@\n      * Test results after 1 iteration in the test runner.\n      *\n      * @param iteration the current iteration\n+     * @param modifiedEvents set of events modified in the current iteration\n      */\n-    public abstract void testIteration(int iteration) throws IOException;\n+    public abstract void testIteration(int iteration, Set<String> modifiedEvents) throws IOException;\n \n     protected TransformConfig.Builder addCommonBuilderParameters(TransformConfig.Builder builder) {\n-        return builder.setSyncConfig(getSyncConfig())\n-            .setSettings(addCommonSetings(new SettingsConfig.Builder()).build())\n+        return builder\n+            .setSyncConfig(getSyncConfig())\n+            .setSettings(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTAwOTgwNQ=="}, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1NjY2NTA3OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/transform/qa/single-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/transform/integration/continuous/TransformContinuousIT.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QwOTozNzowOVrOH-Ohug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxMTo0MDozNlrOH-WqpQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTAxMTc3MA==", "bodyText": "good idea!", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535011770", "createdAt": "2020-12-03T09:37:09Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/transform/qa/single-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/transform/integration/continuous/TransformContinuousIT.java", "diffHunk": "@@ -208,10 +211,12 @@ public void testContinousEvents() throws Exception {\n             BulkRequest bulkRequest = new BulkRequest(sourceIndexName);\n \n             int numDocs = randomIntBetween(1000, 20000);\n+            Set<String> modifiedEvents = new HashSet<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE0NTEyNQ==", "bodyText": "Thanks!", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535145125", "createdAt": "2020-12-03T11:40:36Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/transform/qa/single-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/transform/integration/continuous/TransformContinuousIT.java", "diffHunk": "@@ -208,10 +211,12 @@ public void testContinousEvents() throws Exception {\n             BulkRequest bulkRequest = new BulkRequest(sourceIndexName);\n \n             int numDocs = randomIntBetween(1000, 20000);\n+            Set<String> modifiedEvents = new HashSet<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTAxMTc3MA=="}, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1NjgxMTY0OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QwOTo1OToxOVrOH-QBoA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxMTo0MTo0MVrOH-WviQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTAzNjMyMA==", "bodyText": "we could move this method into this class and make the config class more lightweight. It looks like a legacy code smell in pivot, we should not copy.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535036320", "createdAt": "2020-12-03T09:59:19Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.latest;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesAction;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesRequest;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.search.SearchAction;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.query.BoolQueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.Aggregations;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.metrics.TopHits;\n+import org.elasticsearch.search.aggregations.metrics.TopHitsAggregationBuilder;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+import org.elasticsearch.xpack.core.transform.TransformMessages;\n+import org.elasticsearch.xpack.core.transform.transforms.SourceConfig;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformIndexerStats;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformProgress;\n+import org.elasticsearch.xpack.core.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.xpack.transform.transforms.Function;\n+import org.elasticsearch.xpack.transform.transforms.IDGenerator;\n+import org.elasticsearch.xpack.transform.transforms.common.DocumentConversionUtils;\n+import org.elasticsearch.xpack.transform.transforms.pivot.SchemaUtil;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.function.Predicate.not;\n+import static java.util.stream.Collectors.toMap;\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class LatestDoc implements Function {\n+\n+    public static final int DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE = 5000;\n+    public static final int TEST_QUERY_PAGE_SIZE = 50;\n+\n+    private static final String COMPOSITE_AGGREGATION_NAME = \"_transform\";\n+    private static final String TOP_HITS_AGGREGATION_NAME = \"_top_hits\";\n+    private static final Logger logger = LogManager.getLogger(LatestDoc.class);\n+\n+    private final LatestDocConfig config;\n+\n+    // objects for re-using\n+    private final CompositeAggregationBuilder cachedCompositeAggregation;\n+\n+    public LatestDoc(LatestDocConfig config) {\n+        this.config = config;\n+        this.cachedCompositeAggregation = createCompositeAggregation(config);\n+    }\n+\n+    private static CompositeAggregationBuilder createCompositeAggregation(LatestDocConfig config) {\n+        CompositeAggregationBuilder compositeAggregation;\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            config.toCompositeAggXContent(builder);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE0NjM3Nw==", "bodyText": "Done.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535146377", "createdAt": "2020-12-03T11:41:41Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.latest;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesAction;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesRequest;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.search.SearchAction;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.query.BoolQueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.Aggregations;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.metrics.TopHits;\n+import org.elasticsearch.search.aggregations.metrics.TopHitsAggregationBuilder;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+import org.elasticsearch.xpack.core.transform.TransformMessages;\n+import org.elasticsearch.xpack.core.transform.transforms.SourceConfig;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformIndexerStats;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformProgress;\n+import org.elasticsearch.xpack.core.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.xpack.transform.transforms.Function;\n+import org.elasticsearch.xpack.transform.transforms.IDGenerator;\n+import org.elasticsearch.xpack.transform.transforms.common.DocumentConversionUtils;\n+import org.elasticsearch.xpack.transform.transforms.pivot.SchemaUtil;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.function.Predicate.not;\n+import static java.util.stream.Collectors.toMap;\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class LatestDoc implements Function {\n+\n+    public static final int DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE = 5000;\n+    public static final int TEST_QUERY_PAGE_SIZE = 50;\n+\n+    private static final String COMPOSITE_AGGREGATION_NAME = \"_transform\";\n+    private static final String TOP_HITS_AGGREGATION_NAME = \"_top_hits\";\n+    private static final Logger logger = LogManager.getLogger(LatestDoc.class);\n+\n+    private final LatestDocConfig config;\n+\n+    // objects for re-using\n+    private final CompositeAggregationBuilder cachedCompositeAggregation;\n+\n+    public LatestDoc(LatestDocConfig config) {\n+        this.config = config;\n+        this.cachedCompositeAggregation = createCompositeAggregation(config);\n+    }\n+\n+    private static CompositeAggregationBuilder createCompositeAggregation(LatestDocConfig config) {\n+        CompositeAggregationBuilder compositeAggregation;\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            config.toCompositeAggXContent(builder);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTAzNjMyMA=="}, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1NjgyMDY2OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxMDowMDozN1rOH-QHUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxMDowMDozN1rOH-QHUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTAzNzc3OQ==", "bodyText": "\ud83d\udc4d another indicator that config.toCompositeAggXContent should not exist", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535037779", "createdAt": "2020-12-03T10:00:37Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.latest;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesAction;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesRequest;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.search.SearchAction;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.query.BoolQueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.Aggregations;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.metrics.TopHits;\n+import org.elasticsearch.search.aggregations.metrics.TopHitsAggregationBuilder;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+import org.elasticsearch.xpack.core.transform.TransformMessages;\n+import org.elasticsearch.xpack.core.transform.transforms.SourceConfig;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformIndexerStats;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformProgress;\n+import org.elasticsearch.xpack.core.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.xpack.transform.transforms.Function;\n+import org.elasticsearch.xpack.transform.transforms.IDGenerator;\n+import org.elasticsearch.xpack.transform.transforms.common.DocumentConversionUtils;\n+import org.elasticsearch.xpack.transform.transforms.pivot.SchemaUtil;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.function.Predicate.not;\n+import static java.util.stream.Collectors.toMap;\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class LatestDoc implements Function {\n+\n+    public static final int DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE = 5000;\n+    public static final int TEST_QUERY_PAGE_SIZE = 50;\n+\n+    private static final String COMPOSITE_AGGREGATION_NAME = \"_transform\";\n+    private static final String TOP_HITS_AGGREGATION_NAME = \"_top_hits\";\n+    private static final Logger logger = LogManager.getLogger(LatestDoc.class);\n+\n+    private final LatestDocConfig config;\n+\n+    // objects for re-using\n+    private final CompositeAggregationBuilder cachedCompositeAggregation;\n+\n+    public LatestDoc(LatestDocConfig config) {\n+        this.config = config;\n+        this.cachedCompositeAggregation = createCompositeAggregation(config);\n+    }\n+\n+    private static CompositeAggregationBuilder createCompositeAggregation(LatestDocConfig config) {\n+        CompositeAggregationBuilder compositeAggregation;\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            config.toCompositeAggXContent(builder);\n+            XContentParser parser = builder.generator()\n+                .contentType()\n+                .xContent()\n+                .createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, BytesReference.bytes(builder).streamInput());\n+            compositeAggregation = CompositeAggregationBuilder.PARSER.parse(parser, COMPOSITE_AGGREGATION_NAME);\n+        } catch (IOException e) {\n+            throw new RuntimeException(\n+                TransformMessages.getMessage(TransformMessages.TRANSFORM_FAILED_TO_CREATE_COMPOSITE_AGGREGATION, \"latest\"), e);\n+        }\n+        TopHitsAggregationBuilder topHitsAgg =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 93}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1Njg2NTI2OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxMDowNzo0MVrOH-QkhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxMjowMjoyMFrOH-X5lg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTA0NTI1Mw==", "bodyText": "you might get rid of this method or at least rename it. Another example of legacy in pivot, better not to copy (in pivot we ended up with this after several re-factorings, it should be fixed there, too!).\nThe name is misleading, this is called for validation and preview, maybe you can name it accordingly. Or if you think re-usage makes no sense inline it.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535045253", "createdAt": "2020-12-03T10:07:41Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.latest;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesAction;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesRequest;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.search.SearchAction;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.query.BoolQueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.Aggregations;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.metrics.TopHits;\n+import org.elasticsearch.search.aggregations.metrics.TopHitsAggregationBuilder;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+import org.elasticsearch.xpack.core.transform.TransformMessages;\n+import org.elasticsearch.xpack.core.transform.transforms.SourceConfig;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformIndexerStats;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformProgress;\n+import org.elasticsearch.xpack.core.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.xpack.transform.transforms.Function;\n+import org.elasticsearch.xpack.transform.transforms.IDGenerator;\n+import org.elasticsearch.xpack.transform.transforms.common.DocumentConversionUtils;\n+import org.elasticsearch.xpack.transform.transforms.pivot.SchemaUtil;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.function.Predicate.not;\n+import static java.util.stream.Collectors.toMap;\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class LatestDoc implements Function {\n+\n+    public static final int DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE = 5000;\n+    public static final int TEST_QUERY_PAGE_SIZE = 50;\n+\n+    private static final String COMPOSITE_AGGREGATION_NAME = \"_transform\";\n+    private static final String TOP_HITS_AGGREGATION_NAME = \"_top_hits\";\n+    private static final Logger logger = LogManager.getLogger(LatestDoc.class);\n+\n+    private final LatestDocConfig config;\n+\n+    // objects for re-using\n+    private final CompositeAggregationBuilder cachedCompositeAggregation;\n+\n+    public LatestDoc(LatestDocConfig config) {\n+        this.config = config;\n+        this.cachedCompositeAggregation = createCompositeAggregation(config);\n+    }\n+\n+    private static CompositeAggregationBuilder createCompositeAggregation(LatestDocConfig config) {\n+        CompositeAggregationBuilder compositeAggregation;\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            config.toCompositeAggXContent(builder);\n+            XContentParser parser = builder.generator()\n+                .contentType()\n+                .xContent()\n+                .createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, BytesReference.bytes(builder).streamInput());\n+            compositeAggregation = CompositeAggregationBuilder.PARSER.parse(parser, COMPOSITE_AGGREGATION_NAME);\n+        } catch (IOException e) {\n+            throw new RuntimeException(\n+                TransformMessages.getMessage(TransformMessages.TRANSFORM_FAILED_TO_CREATE_COMPOSITE_AGGREGATION, \"latest\"), e);\n+        }\n+        TopHitsAggregationBuilder topHitsAgg =\n+            AggregationBuilders.topHits(TOP_HITS_AGGREGATION_NAME)\n+                .size(1)  // we are only interested in the top-1\n+                .sorts(config.getSorts());  // we copy the sort config directly from the function config\n+        compositeAggregation.subAggregation(topHitsAgg);\n+        return compositeAggregation;\n+    }\n+\n+    @Override\n+    public int getInitialPageSize() {\n+        return DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE;\n+    }\n+\n+    private SearchRequest buildSearchRequest(SourceConfig sourceConfig, Map<String, Object> position, int pageSize) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE2NTMzNA==", "bodyText": "The method turned out to only consist of 3 statements so I've inlined it.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535165334", "createdAt": "2020-12-03T12:02:20Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.latest;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesAction;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesRequest;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.search.SearchAction;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.query.BoolQueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.Aggregations;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.metrics.TopHits;\n+import org.elasticsearch.search.aggregations.metrics.TopHitsAggregationBuilder;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+import org.elasticsearch.xpack.core.transform.TransformMessages;\n+import org.elasticsearch.xpack.core.transform.transforms.SourceConfig;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformIndexerStats;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformProgress;\n+import org.elasticsearch.xpack.core.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.xpack.transform.transforms.Function;\n+import org.elasticsearch.xpack.transform.transforms.IDGenerator;\n+import org.elasticsearch.xpack.transform.transforms.common.DocumentConversionUtils;\n+import org.elasticsearch.xpack.transform.transforms.pivot.SchemaUtil;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.function.Predicate.not;\n+import static java.util.stream.Collectors.toMap;\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class LatestDoc implements Function {\n+\n+    public static final int DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE = 5000;\n+    public static final int TEST_QUERY_PAGE_SIZE = 50;\n+\n+    private static final String COMPOSITE_AGGREGATION_NAME = \"_transform\";\n+    private static final String TOP_HITS_AGGREGATION_NAME = \"_top_hits\";\n+    private static final Logger logger = LogManager.getLogger(LatestDoc.class);\n+\n+    private final LatestDocConfig config;\n+\n+    // objects for re-using\n+    private final CompositeAggregationBuilder cachedCompositeAggregation;\n+\n+    public LatestDoc(LatestDocConfig config) {\n+        this.config = config;\n+        this.cachedCompositeAggregation = createCompositeAggregation(config);\n+    }\n+\n+    private static CompositeAggregationBuilder createCompositeAggregation(LatestDocConfig config) {\n+        CompositeAggregationBuilder compositeAggregation;\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            config.toCompositeAggXContent(builder);\n+            XContentParser parser = builder.generator()\n+                .contentType()\n+                .xContent()\n+                .createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, BytesReference.bytes(builder).streamInput());\n+            compositeAggregation = CompositeAggregationBuilder.PARSER.parse(parser, COMPOSITE_AGGREGATION_NAME);\n+        } catch (IOException e) {\n+            throw new RuntimeException(\n+                TransformMessages.getMessage(TransformMessages.TRANSFORM_FAILED_TO_CREATE_COMPOSITE_AGGREGATION, \"latest\"), e);\n+        }\n+        TopHitsAggregationBuilder topHitsAgg =\n+            AggregationBuilders.topHits(TOP_HITS_AGGREGATION_NAME)\n+                .size(1)  // we are only interested in the top-1\n+                .sorts(config.getSorts());  // we copy the sort config directly from the function config\n+        compositeAggregation.subAggregation(topHitsAgg);\n+        return compositeAggregation;\n+    }\n+\n+    @Override\n+    public int getInitialPageSize() {\n+        return DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE;\n+    }\n+\n+    private SearchRequest buildSearchRequest(SourceConfig sourceConfig, Map<String, Object> position, int pageSize) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTA0NTI1Mw=="}, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 106}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM3ODkxNjcyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/pivot/Pivot.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQxMDoxNDo0M1rOIBRrzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQxMDoyNjowNlrOIBSJ8Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODIwOTIyOQ==", "bodyText": "lets remove that, too", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r538209229", "createdAt": "2020-12-08T10:14:43Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/pivot/Pivot.java", "diffHunk": "@@ -197,7 +191,7 @@ public SearchRequest buildSearchRequest(SourceConfig sourceConfig, Map<String, O\n         searchRequest.source(sourceBuilder);\n         searchRequest.indicesOptions(IndicesOptions.LENIENT_EXPAND_OPEN);\n \n-        logger.trace(\"Search request: {}\", searchRequest);\n+        logger.trace(() -> new ParameterizedMessage(\"Search request: {}\", searchRequest));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2439e957173adc701b0bfe6990aec87856540fc1"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODIxNjk0NQ==", "bodyText": "Done.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r538216945", "createdAt": "2020-12-08T10:26:06Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/pivot/Pivot.java", "diffHunk": "@@ -197,7 +191,7 @@ public SearchRequest buildSearchRequest(SourceConfig sourceConfig, Map<String, O\n         searchRequest.source(sourceBuilder);\n         searchRequest.indicesOptions(IndicesOptions.LENIENT_EXPAND_OPEN);\n \n-        logger.trace(\"Search request: {}\", searchRequest);\n+        logger.trace(() -> new ParameterizedMessage(\"Search request: {}\", searchRequest));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODIwOTIyOQ=="}, "originalCommit": {"oid": "2439e957173adc701b0bfe6990aec87856540fc1"}, "originalPosition": 93}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2891, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}