{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU4NTQ5ODkw", "number": 60408, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNjozNToyOVrOETVbnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNjozNToyOVrOETVbnA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NzA5NTMyOnYy", "diffSide": "RIGHT", "path": "README.asciidoc", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNjozNToyOVrOG5Av2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNjo0MjowMFrOG5A-1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQzNDI2NA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            curl -X PUT http://localhost:9200/my-index-000002?pretty -H 'Content-Type: application/json' -d '\n          \n          \n            \n            curl -X PUT 'http://localhost:9200/my-index-000002?pretty' -H 'Content-Type: application/json' -d '", "url": "https://github.com/elastic/elasticsearch/pull/60408#discussion_r462434264", "createdAt": "2020-07-29T16:35:29Z", "author": {"login": "lockewritesdocs"}, "path": "README.asciidoc", "diffHunk": "@@ -35,154 +35,148 @@ First of all, DON'T PANIC. It will take 5 minutes to get the gist of what Elasti\n \n * https://www.elastic.co/downloads/elasticsearch[Download] and unpack the Elasticsearch official distribution.\n * Run `bin/elasticsearch` on Linux or macOS. Run `bin\\elasticsearch.bat` on Windows.\n-* Run `curl -X GET http://localhost:9200/`.\n-* Start more servers ...\n+* Run `curl -X GET http://localhost:9200/` to verify Elasticsearch is running.\n \n === Indexing\n \n-Let's try and index some twitter like information. First, let's index some tweets (the `twitter` index will be created automatically):\n+First, index some sample JSON documents. The first request automatically creates\n+the `my-index-000001` index.\n \n ----\n-curl -XPUT 'http://localhost:9200/twitter/_doc/1?pretty' -H 'Content-Type: application/json' -d '\n+curl -X POST 'http://localhost:9200/my-index-000001/_doc?pretty' -H 'Content-Type: application/json' -d '\n {\n-  \"user\": \"kimchy\",\n-  \"post_date\": \"2009-11-15T13:12:00\",\n-  \"message\": \"Trying out Elasticsearch, so far so good?\"\n+  \"@timestamp\": \"2099-11-15T13:12:00\",\n+  \"message\": \"GET /search HTTP/1.1 200 1070000\",\n+  \"user\": {\n+    \"id\": \"kimchy\"\n+  }\n }'\n \n-curl -XPUT 'http://localhost:9200/twitter/_doc/2?pretty' -H 'Content-Type: application/json' -d '\n+curl -X POST 'http://localhost:9200/my-index-000001/_doc?pretty' -H 'Content-Type: application/json' -d '\n {\n-  \"user\": \"kimchy\",\n-  \"post_date\": \"2009-11-15T14:12:12\",\n-  \"message\": \"Another tweet, will it be indexed?\"\n+  \"@timestamp\": \"2099-11-15T14:12:12\",\n+  \"message\": \"GET /search HTTP/1.1 200 1070000\",\n+  \"user\": {\n+    \"id\": \"elkbee\"\n+  }\n }'\n \n-curl -XPUT 'http://localhost:9200/twitter/_doc/3?pretty' -H 'Content-Type: application/json' -d '\n+curl -X POST 'http://localhost:9200/my-index-000001/_doc?pretty' -H 'Content-Type: application/json' -d '\n {\n-  \"user\": \"elastic\",\n-  \"post_date\": \"2010-01-15T01:46:38\",\n-  \"message\": \"Building the site, should be kewl\"\n+  \"@timestamp\": \"2099-11-15T01:46:38\",\n+  \"message\": \"GET /search HTTP/1.1 200 1070000\",\n+  \"user\": {\n+    \"id\": \"elkbee\"\n+  }\n }'\n ----\n \n-Now, let's see if the information was added by GETting it:\n+=== Search\n \n-----\n-curl -XGET 'http://localhost:9200/twitter/_doc/1?pretty=true'\n-curl -XGET 'http://localhost:9200/twitter/_doc/2?pretty=true'\n-curl -XGET 'http://localhost:9200/twitter/_doc/3?pretty=true'\n-----\n-\n-=== Searching\n-\n-Mmm search..., shouldn't it be elastic?\n-Let's find all the tweets that `kimchy` posted:\n+Next, use a search request to find any documents with a `user.id` of `kimchy`.\n \n ----\n-curl -XGET 'http://localhost:9200/twitter/_search?q=user:kimchy&pretty=true'\n+curl -X GET 'http://localhost:9200/my-index-000001/_search?q=user.id:kimchy&pretty=true'\n ----\n \n-We can also use the JSON query language Elasticsearch provides instead of a query string:\n+Instead of a query string, you can use Elasticsearch's\n+https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html[Query\n+DSL] in the request body.\n \n ----\n-curl -XGET 'http://localhost:9200/twitter/_search?pretty=true' -H 'Content-Type: application/json' -d '\n+curl -X GET 'http://localhost:9200/my-index-000001/_search?pretty=true' -H 'Content-Type: application/json' -d '\n {\n   \"query\" : {\n-    \"match\" : { \"user\": \"kimchy\" }\n+    \"match\" : { \"user.id\": \"kimchy\" }\n   }\n }'\n ----\n \n-Just for kicks, let's get all the documents stored (we should see the tweet from `elastic` as well):\n+You can also retrieve all documents in `my-index-000001`.\n \n ----\n-curl -XGET 'http://localhost:9200/twitter/_search?pretty=true' -H 'Content-Type: application/json' -d '\n+curl -X GET 'http://localhost:9200/my-index-000001/_search?pretty=true' -H 'Content-Type: application/json' -d '\n {\n   \"query\" : {\n     \"match_all\" : {}\n   }\n }'\n ----\n \n-We can also do range search (the `post_date` was automatically identified as date)\n+During indexing, Elasticsearch automatically mapped the `@timestamp` field as a\n+date. This lets you run a range search.\n \n ----\n-curl -XGET 'http://localhost:9200/twitter/_search?pretty=true' -H 'Content-Type: application/json' -d '\n+curl -X GET 'http://localhost:9200/my-index-000001/_search?pretty=true' -H 'Content-Type: application/json' -d '\n {\n   \"query\" : {\n     \"range\" : {\n-      \"post_date\" : { \"from\" : \"2009-11-15T13:00:00\", \"to\" : \"2009-11-15T14:00:00\" }\n+      \"@timestamp\": {\n+        \"from\": \"2099-11-15T13:00:00\",\n+        \"to\": \"2099-11-15T14:00:00\"\n+      }\n     }\n   }\n }'\n ----\n \n-There are many more options to perform search, after all, it's a search product no? All the familiar Lucene queries are available through the JSON query language, or through the query parser.\n-\n-=== Multi Tenant and Indices\n-\n-Man, that twitter index might get big (in this case, index size == valuation). Let's see if we can structure our twitter system a bit differently in order to support such large amounts of data.\n+=== Multiple indices\n \n-Elasticsearch supports multiple indices. In the previous example we used an index called `twitter` that stored tweets for every user.\n+Elasticsearch supports multiple indices. The previous examples used an index\n+called `my-index-000001`. You can create another index, `my-index-000002`, to\n+store additional data when `my-index-000001` reaches a certain age or size. You\n+can also use separate indices to store different types of data.\n \n-Another way to define our simple twitter system is to have a different index per user (note, though that each index has an overhead). Here is the indexing curl's in this case:\n+You can configure each index differently. The following request\n+creates `my-index-000002` with two primary shards rather than the default of\n+one. This may be helpful for larger indices.\n \n ----\n-curl -XPUT 'http://localhost:9200/kimchy/_doc/1?pretty' -H 'Content-Type: application/json' -d '\n+curl -X PUT http://localhost:9200/my-index-000002?pretty -H 'Content-Type: application/json' -d '", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "be86b7353ce7d353c8a3bb46c04b08cc748da69f"}, "originalPosition": 144}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQzNTcxMA==", "bodyText": "Single quotes were removed but should be added back.", "url": "https://github.com/elastic/elasticsearch/pull/60408#discussion_r462435710", "createdAt": "2020-07-29T16:37:59Z", "author": {"login": "lockewritesdocs"}, "path": "README.asciidoc", "diffHunk": "@@ -35,154 +35,148 @@ First of all, DON'T PANIC. It will take 5 minutes to get the gist of what Elasti\n \n * https://www.elastic.co/downloads/elasticsearch[Download] and unpack the Elasticsearch official distribution.\n * Run `bin/elasticsearch` on Linux or macOS. Run `bin\\elasticsearch.bat` on Windows.\n-* Run `curl -X GET http://localhost:9200/`.\n-* Start more servers ...\n+* Run `curl -X GET http://localhost:9200/` to verify Elasticsearch is running.\n \n === Indexing\n \n-Let's try and index some twitter like information. First, let's index some tweets (the `twitter` index will be created automatically):\n+First, index some sample JSON documents. The first request automatically creates\n+the `my-index-000001` index.\n \n ----\n-curl -XPUT 'http://localhost:9200/twitter/_doc/1?pretty' -H 'Content-Type: application/json' -d '\n+curl -X POST 'http://localhost:9200/my-index-000001/_doc?pretty' -H 'Content-Type: application/json' -d '\n {\n-  \"user\": \"kimchy\",\n-  \"post_date\": \"2009-11-15T13:12:00\",\n-  \"message\": \"Trying out Elasticsearch, so far so good?\"\n+  \"@timestamp\": \"2099-11-15T13:12:00\",\n+  \"message\": \"GET /search HTTP/1.1 200 1070000\",\n+  \"user\": {\n+    \"id\": \"kimchy\"\n+  }\n }'\n \n-curl -XPUT 'http://localhost:9200/twitter/_doc/2?pretty' -H 'Content-Type: application/json' -d '\n+curl -X POST 'http://localhost:9200/my-index-000001/_doc?pretty' -H 'Content-Type: application/json' -d '\n {\n-  \"user\": \"kimchy\",\n-  \"post_date\": \"2009-11-15T14:12:12\",\n-  \"message\": \"Another tweet, will it be indexed?\"\n+  \"@timestamp\": \"2099-11-15T14:12:12\",\n+  \"message\": \"GET /search HTTP/1.1 200 1070000\",\n+  \"user\": {\n+    \"id\": \"elkbee\"\n+  }\n }'\n \n-curl -XPUT 'http://localhost:9200/twitter/_doc/3?pretty' -H 'Content-Type: application/json' -d '\n+curl -X POST 'http://localhost:9200/my-index-000001/_doc?pretty' -H 'Content-Type: application/json' -d '\n {\n-  \"user\": \"elastic\",\n-  \"post_date\": \"2010-01-15T01:46:38\",\n-  \"message\": \"Building the site, should be kewl\"\n+  \"@timestamp\": \"2099-11-15T01:46:38\",\n+  \"message\": \"GET /search HTTP/1.1 200 1070000\",\n+  \"user\": {\n+    \"id\": \"elkbee\"\n+  }\n }'\n ----\n \n-Now, let's see if the information was added by GETting it:\n+=== Search\n \n-----\n-curl -XGET 'http://localhost:9200/twitter/_doc/1?pretty=true'\n-curl -XGET 'http://localhost:9200/twitter/_doc/2?pretty=true'\n-curl -XGET 'http://localhost:9200/twitter/_doc/3?pretty=true'\n-----\n-\n-=== Searching\n-\n-Mmm search..., shouldn't it be elastic?\n-Let's find all the tweets that `kimchy` posted:\n+Next, use a search request to find any documents with a `user.id` of `kimchy`.\n \n ----\n-curl -XGET 'http://localhost:9200/twitter/_search?q=user:kimchy&pretty=true'\n+curl -X GET 'http://localhost:9200/my-index-000001/_search?q=user.id:kimchy&pretty=true'\n ----\n \n-We can also use the JSON query language Elasticsearch provides instead of a query string:\n+Instead of a query string, you can use Elasticsearch's\n+https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html[Query\n+DSL] in the request body.\n \n ----\n-curl -XGET 'http://localhost:9200/twitter/_search?pretty=true' -H 'Content-Type: application/json' -d '\n+curl -X GET 'http://localhost:9200/my-index-000001/_search?pretty=true' -H 'Content-Type: application/json' -d '\n {\n   \"query\" : {\n-    \"match\" : { \"user\": \"kimchy\" }\n+    \"match\" : { \"user.id\": \"kimchy\" }\n   }\n }'\n ----\n \n-Just for kicks, let's get all the documents stored (we should see the tweet from `elastic` as well):\n+You can also retrieve all documents in `my-index-000001`.\n \n ----\n-curl -XGET 'http://localhost:9200/twitter/_search?pretty=true' -H 'Content-Type: application/json' -d '\n+curl -X GET 'http://localhost:9200/my-index-000001/_search?pretty=true' -H 'Content-Type: application/json' -d '\n {\n   \"query\" : {\n     \"match_all\" : {}\n   }\n }'\n ----\n \n-We can also do range search (the `post_date` was automatically identified as date)\n+During indexing, Elasticsearch automatically mapped the `@timestamp` field as a\n+date. This lets you run a range search.\n \n ----\n-curl -XGET 'http://localhost:9200/twitter/_search?pretty=true' -H 'Content-Type: application/json' -d '\n+curl -X GET 'http://localhost:9200/my-index-000001/_search?pretty=true' -H 'Content-Type: application/json' -d '\n {\n   \"query\" : {\n     \"range\" : {\n-      \"post_date\" : { \"from\" : \"2009-11-15T13:00:00\", \"to\" : \"2009-11-15T14:00:00\" }\n+      \"@timestamp\": {\n+        \"from\": \"2099-11-15T13:00:00\",\n+        \"to\": \"2099-11-15T14:00:00\"\n+      }\n     }\n   }\n }'\n ----\n \n-There are many more options to perform search, after all, it's a search product no? All the familiar Lucene queries are available through the JSON query language, or through the query parser.\n-\n-=== Multi Tenant and Indices\n-\n-Man, that twitter index might get big (in this case, index size == valuation). Let's see if we can structure our twitter system a bit differently in order to support such large amounts of data.\n+=== Multiple indices\n \n-Elasticsearch supports multiple indices. In the previous example we used an index called `twitter` that stored tweets for every user.\n+Elasticsearch supports multiple indices. The previous examples used an index\n+called `my-index-000001`. You can create another index, `my-index-000002`, to\n+store additional data when `my-index-000001` reaches a certain age or size. You\n+can also use separate indices to store different types of data.\n \n-Another way to define our simple twitter system is to have a different index per user (note, though that each index has an overhead). Here is the indexing curl's in this case:\n+You can configure each index differently. The following request\n+creates `my-index-000002` with two primary shards rather than the default of\n+one. This may be helpful for larger indices.\n \n ----\n-curl -XPUT 'http://localhost:9200/kimchy/_doc/1?pretty' -H 'Content-Type: application/json' -d '\n+curl -X PUT http://localhost:9200/my-index-000002?pretty -H 'Content-Type: application/json' -d '", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQzNDI2NA=="}, "originalCommit": {"oid": "be86b7353ce7d353c8a3bb46c04b08cc748da69f"}, "originalPosition": 144}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQzODEwMg==", "bodyText": "Good catch. Thanks.", "url": "https://github.com/elastic/elasticsearch/pull/60408#discussion_r462438102", "createdAt": "2020-07-29T16:42:00Z", "author": {"login": "jrodewig"}, "path": "README.asciidoc", "diffHunk": "@@ -35,154 +35,148 @@ First of all, DON'T PANIC. It will take 5 minutes to get the gist of what Elasti\n \n * https://www.elastic.co/downloads/elasticsearch[Download] and unpack the Elasticsearch official distribution.\n * Run `bin/elasticsearch` on Linux or macOS. Run `bin\\elasticsearch.bat` on Windows.\n-* Run `curl -X GET http://localhost:9200/`.\n-* Start more servers ...\n+* Run `curl -X GET http://localhost:9200/` to verify Elasticsearch is running.\n \n === Indexing\n \n-Let's try and index some twitter like information. First, let's index some tweets (the `twitter` index will be created automatically):\n+First, index some sample JSON documents. The first request automatically creates\n+the `my-index-000001` index.\n \n ----\n-curl -XPUT 'http://localhost:9200/twitter/_doc/1?pretty' -H 'Content-Type: application/json' -d '\n+curl -X POST 'http://localhost:9200/my-index-000001/_doc?pretty' -H 'Content-Type: application/json' -d '\n {\n-  \"user\": \"kimchy\",\n-  \"post_date\": \"2009-11-15T13:12:00\",\n-  \"message\": \"Trying out Elasticsearch, so far so good?\"\n+  \"@timestamp\": \"2099-11-15T13:12:00\",\n+  \"message\": \"GET /search HTTP/1.1 200 1070000\",\n+  \"user\": {\n+    \"id\": \"kimchy\"\n+  }\n }'\n \n-curl -XPUT 'http://localhost:9200/twitter/_doc/2?pretty' -H 'Content-Type: application/json' -d '\n+curl -X POST 'http://localhost:9200/my-index-000001/_doc?pretty' -H 'Content-Type: application/json' -d '\n {\n-  \"user\": \"kimchy\",\n-  \"post_date\": \"2009-11-15T14:12:12\",\n-  \"message\": \"Another tweet, will it be indexed?\"\n+  \"@timestamp\": \"2099-11-15T14:12:12\",\n+  \"message\": \"GET /search HTTP/1.1 200 1070000\",\n+  \"user\": {\n+    \"id\": \"elkbee\"\n+  }\n }'\n \n-curl -XPUT 'http://localhost:9200/twitter/_doc/3?pretty' -H 'Content-Type: application/json' -d '\n+curl -X POST 'http://localhost:9200/my-index-000001/_doc?pretty' -H 'Content-Type: application/json' -d '\n {\n-  \"user\": \"elastic\",\n-  \"post_date\": \"2010-01-15T01:46:38\",\n-  \"message\": \"Building the site, should be kewl\"\n+  \"@timestamp\": \"2099-11-15T01:46:38\",\n+  \"message\": \"GET /search HTTP/1.1 200 1070000\",\n+  \"user\": {\n+    \"id\": \"elkbee\"\n+  }\n }'\n ----\n \n-Now, let's see if the information was added by GETting it:\n+=== Search\n \n-----\n-curl -XGET 'http://localhost:9200/twitter/_doc/1?pretty=true'\n-curl -XGET 'http://localhost:9200/twitter/_doc/2?pretty=true'\n-curl -XGET 'http://localhost:9200/twitter/_doc/3?pretty=true'\n-----\n-\n-=== Searching\n-\n-Mmm search..., shouldn't it be elastic?\n-Let's find all the tweets that `kimchy` posted:\n+Next, use a search request to find any documents with a `user.id` of `kimchy`.\n \n ----\n-curl -XGET 'http://localhost:9200/twitter/_search?q=user:kimchy&pretty=true'\n+curl -X GET 'http://localhost:9200/my-index-000001/_search?q=user.id:kimchy&pretty=true'\n ----\n \n-We can also use the JSON query language Elasticsearch provides instead of a query string:\n+Instead of a query string, you can use Elasticsearch's\n+https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html[Query\n+DSL] in the request body.\n \n ----\n-curl -XGET 'http://localhost:9200/twitter/_search?pretty=true' -H 'Content-Type: application/json' -d '\n+curl -X GET 'http://localhost:9200/my-index-000001/_search?pretty=true' -H 'Content-Type: application/json' -d '\n {\n   \"query\" : {\n-    \"match\" : { \"user\": \"kimchy\" }\n+    \"match\" : { \"user.id\": \"kimchy\" }\n   }\n }'\n ----\n \n-Just for kicks, let's get all the documents stored (we should see the tweet from `elastic` as well):\n+You can also retrieve all documents in `my-index-000001`.\n \n ----\n-curl -XGET 'http://localhost:9200/twitter/_search?pretty=true' -H 'Content-Type: application/json' -d '\n+curl -X GET 'http://localhost:9200/my-index-000001/_search?pretty=true' -H 'Content-Type: application/json' -d '\n {\n   \"query\" : {\n     \"match_all\" : {}\n   }\n }'\n ----\n \n-We can also do range search (the `post_date` was automatically identified as date)\n+During indexing, Elasticsearch automatically mapped the `@timestamp` field as a\n+date. This lets you run a range search.\n \n ----\n-curl -XGET 'http://localhost:9200/twitter/_search?pretty=true' -H 'Content-Type: application/json' -d '\n+curl -X GET 'http://localhost:9200/my-index-000001/_search?pretty=true' -H 'Content-Type: application/json' -d '\n {\n   \"query\" : {\n     \"range\" : {\n-      \"post_date\" : { \"from\" : \"2009-11-15T13:00:00\", \"to\" : \"2009-11-15T14:00:00\" }\n+      \"@timestamp\": {\n+        \"from\": \"2099-11-15T13:00:00\",\n+        \"to\": \"2099-11-15T14:00:00\"\n+      }\n     }\n   }\n }'\n ----\n \n-There are many more options to perform search, after all, it's a search product no? All the familiar Lucene queries are available through the JSON query language, or through the query parser.\n-\n-=== Multi Tenant and Indices\n-\n-Man, that twitter index might get big (in this case, index size == valuation). Let's see if we can structure our twitter system a bit differently in order to support such large amounts of data.\n+=== Multiple indices\n \n-Elasticsearch supports multiple indices. In the previous example we used an index called `twitter` that stored tweets for every user.\n+Elasticsearch supports multiple indices. The previous examples used an index\n+called `my-index-000001`. You can create another index, `my-index-000002`, to\n+store additional data when `my-index-000001` reaches a certain age or size. You\n+can also use separate indices to store different types of data.\n \n-Another way to define our simple twitter system is to have a different index per user (note, though that each index has an overhead). Here is the indexing curl's in this case:\n+You can configure each index differently. The following request\n+creates `my-index-000002` with two primary shards rather than the default of\n+one. This may be helpful for larger indices.\n \n ----\n-curl -XPUT 'http://localhost:9200/kimchy/_doc/1?pretty' -H 'Content-Type: application/json' -d '\n+curl -X PUT http://localhost:9200/my-index-000002?pretty -H 'Content-Type: application/json' -d '", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQzNDI2NA=="}, "originalCommit": {"oid": "be86b7353ce7d353c8a3bb46c04b08cc748da69f"}, "originalPosition": 144}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2736, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}