{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg2ODY3MDU1", "number": 53429, "title": "[ML] Start gathering and storing inference stats", "bodyText": "This PR enables stats on inference to be gathered and stored in the .ml-stats-* indices.\nEach node + model_id will have its own running stats document and these will later be summed together when returning _stats to the user.\n.ml-stats-* is ILM managed (when possible). So, at any point the underlying index could change. This means that a stats document that is read in and then later updated will actually be a new doc in a new index. This complicates matters as this means that having a running knowledge of seq_no and primary_term is complicated and almost impossible. This is because we don't know the latest index name.\nWe should also strive for throughput, as this code sits in the middle of an ingest pipeline (or even a query).", "createdAt": "2020-03-11T19:00:29Z", "url": "https://github.com/elastic/elasticsearch/pull/53429", "merged": true, "mergeCommit": {"oid": "c087ee1a72b717518cf6ad9a60c117949368a2f3"}, "closed": true, "closedAt": "2020-04-03T18:09:53Z", "author": {"login": "benwtrent"}, "timelineItems": {"totalCount": 29, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcMrrBcgH2gAyMzg2ODY3MDU1OmVlNDg2ODY1MmVjNTc5NDI1ZmY4NGQyZWZhMGM3N2VkMTUyMTYwOGQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcUC_juAH2gAyMzg2ODY3MDU1OjFkN2FiZDU3MGNmNjdhMDgzMjY1NGZmZjA4MGMyMTdiMmU1NWZjNGY=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "ee4868652ec579425ff84d2efa0c77ed1521608d", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/ee4868652ec579425ff84d2efa0c77ed1521608d", "committedDate": "2020-03-11T18:46:05Z", "message": "[ML] Gathering inference stats in localModel and loading service"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzczMDQ4MDc0", "url": "https://github.com/elastic/elasticsearch/pull/53429#pullrequestreview-373048074", "createdAt": "2020-03-11T19:09:04Z", "commit": {"oid": "ee4868652ec579425ff84d2efa0c77ed1521608d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxOTowOTowNVrOF1E_Xw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxOTowOTowNVrOF1E_Xw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTIwMDYwNw==", "bodyText": "We might actually want to fail completely if the unwrapped error is anything other than a ResourceNotFound. If .ml-stats-* exists but has unallocated primary shards, we may want to bail.", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r391200607", "createdAt": "2020-03-11T19:09:05Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/ModelLoadingService.java", "diffHunk": "@@ -336,11 +351,22 @@ private void loadModels(Set<String> modelIds) {\n         threadPool.executor(MachineLearning.UTILITY_THREAD_POOL_NAME).execute(() -> {\n             for (String modelId : modelIds) {\n                 auditNewReferencedModel(modelId);\n-                this.loadModel(modelId);\n+                loadStatsAndModel(modelId);\n             }\n         });\n     }\n \n+    private void loadStatsAndModel(String modelId) {\n+        this.provider.getInferenceStats(modelId,\n+            localNode,\n+            ActionListener.wrap(\n+                r -> this.loadModel(modelId, r),\n+                e -> {\n+                    logger.error(\"[{}] failed to get previous model stats\", modelId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ee4868652ec579425ff84d2efa0c77ed1521608d"}, "originalPosition": 199}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "01127055d1d33db45fe467849481eadb22f207a5", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/01127055d1d33db45fe467849481eadb22f207a5", "committedDate": "2020-03-12T12:03:04Z", "message": "Merge branch 'master' into feature/ml-inference-stats-collection"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6b45143212bae53972160f5c7bbb4ba873a0006a", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/6b45143212bae53972160f5c7bbb4ba873a0006a", "committedDate": "2020-03-12T12:09:38Z", "message": "making stats loading failure fail the listeners"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3afa69e437ac93478e5e15aa178c9a4c2d4cb5f8", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/3afa69e437ac93478e5e15aa178c9a4c2d4cb5f8", "committedDate": "2020-03-12T17:16:09Z", "message": "Merge branch 'master' into feature/ml-inference-stats-collection"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f", "committedDate": "2020-03-12T17:54:15Z", "message": "allowing missing stats index"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc3NTgxMjE2", "url": "https://github.com/elastic/elasticsearch/pull/53429#pullrequestreview-377581216", "createdAt": "2020-03-19T10:12:09Z", "commit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "state": "COMMENTED", "comments": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxMDoxMjowOVrOF4n2pw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxNzo1ODozNFrOF46K8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDkxNzU0Mw==", "bodyText": "Typo Inferece in function name and param", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r394917543", "createdAt": "2020-03-19T10:12:09Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/action/GetTrainedModelsStatsAction.java", "diffHunk": "@@ -191,13 +209,23 @@ public Builder setIngestStatsByModelId(Map<String, IngestStats> ingestStatsByMod\n                 return this;\n             }\n \n+            public Builder setInfereceStatsByModelId(Map<String, InferenceStats> infereceStatsByModelId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDkxOTg2Nw==", "bodyText": "Just this one is private? I'd make it public just so the fields line up", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r394919867", "createdAt": "2020-03-19T10:16:05Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/InferenceStats.java", "diffHunk": "@@ -0,0 +1,268 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.inference.trainedmodel;\n+\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+import java.util.concurrent.atomic.LongAdder;\n+\n+public class InferenceStats implements ToXContentObject, Writeable {\n+\n+    public static final String NAME = \"inference_stats\";\n+    public static final ParseField MISSING_ALL_FIELDS_COUNT = new ParseField(\"missing_all_fields_count\");\n+    public static final ParseField INFERENCE_COUNT = new ParseField(\"inference_count\");\n+    public static final ParseField MODEL_ID = new ParseField(\"model_id\");\n+    public static final ParseField NODE_ID = new ParseField(\"node_id\");\n+    public static final ParseField TOTAL_TIME_SPENT_MILLIS = new ParseField(\"total_time_spent_millis\");\n+    private static final ParseField TOTAL_TIME_SPENT = new ParseField(\"total_time_spent\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTAyMTI1Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        instant == null ? Instant.now() : Instant.ofEpochMilli(instant.toEpochMilli()));\n          \n          \n            \n                        instant);\n          \n      \n    \n    \n  \n\nThe public ctor has the null check", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395021252", "createdAt": "2020-03-19T13:24:29Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/InferenceStats.java", "diffHunk": "@@ -0,0 +1,268 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.inference.trainedmodel;\n+\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+import java.util.concurrent.atomic.LongAdder;\n+\n+public class InferenceStats implements ToXContentObject, Writeable {\n+\n+    public static final String NAME = \"inference_stats\";\n+    public static final ParseField MISSING_ALL_FIELDS_COUNT = new ParseField(\"missing_all_fields_count\");\n+    public static final ParseField INFERENCE_COUNT = new ParseField(\"inference_count\");\n+    public static final ParseField MODEL_ID = new ParseField(\"model_id\");\n+    public static final ParseField NODE_ID = new ParseField(\"node_id\");\n+    public static final ParseField TOTAL_TIME_SPENT_MILLIS = new ParseField(\"total_time_spent_millis\");\n+    private static final ParseField TOTAL_TIME_SPENT = new ParseField(\"total_time_spent\");\n+    public static final ParseField FAILURE_COUNT = new ParseField(\"failure_count\");\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"time_stamp\");\n+\n+    public static final ConstructingObjectParser<InferenceStats, Void> PARSER = new ConstructingObjectParser<>(\n+        NAME,\n+        true,\n+        a -> new InferenceStats((Long)a[0], (Long)a[1], (Long)a[2], (Long)a[3], (String)a[4], (String)a[5], (Instant) a[6])\n+    );\n+    static {\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), MISSING_ALL_FIELDS_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), INFERENCE_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), TOTAL_TIME_SPENT_MILLIS);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), FAILURE_COUNT);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), MODEL_ID);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), NODE_ID);\n+        PARSER.declareField(ConstructingObjectParser.constructorArg(),\n+            p -> TimeUtils.parseTimeFieldToInstant(p, TIMESTAMP.getPreferredName()),\n+            TIMESTAMP,\n+            ObjectParser.ValueType.VALUE);\n+    }\n+    public static InferenceStats emptyStats(String modelId, String nodeId) {\n+        return new InferenceStats(0L, 0L, 0L, 0L, modelId, nodeId, Instant.now());\n+    }\n+\n+    public static String docId(String modelId, String nodeId) {\n+        return NAME + \"-\" + modelId + \"-\" + nodeId;\n+    }\n+\n+    private final long missingAllFieldsCount;\n+    private final long inferenceCount;\n+    private final long totalTimeSpent;\n+    private final long failureCount;\n+    private final String modelId;\n+    private final String nodeId;\n+    private final Instant timeStamp;\n+\n+    private InferenceStats(Long missingAllFieldsCount,\n+                           Long inferenceCount,\n+                           Long totalTimeSpent,\n+                           Long failureCount,\n+                           String modelId,\n+                           String nodeId,\n+                           Instant instant) {\n+        this(unbox(missingAllFieldsCount),\n+            unbox(inferenceCount),\n+            unbox(totalTimeSpent),\n+            unbox(failureCount),\n+            modelId,\n+            nodeId,\n+            instant == null ? Instant.now() : Instant.ofEpochMilli(instant.toEpochMilli()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTAyMzc2Ng==", "bodyText": "Does converting to epoch then back to Instant serve a purpose?", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395023766", "createdAt": "2020-03-19T13:28:24Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/InferenceStats.java", "diffHunk": "@@ -0,0 +1,268 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.inference.trainedmodel;\n+\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+import java.util.concurrent.atomic.LongAdder;\n+\n+public class InferenceStats implements ToXContentObject, Writeable {\n+\n+    public static final String NAME = \"inference_stats\";\n+    public static final ParseField MISSING_ALL_FIELDS_COUNT = new ParseField(\"missing_all_fields_count\");\n+    public static final ParseField INFERENCE_COUNT = new ParseField(\"inference_count\");\n+    public static final ParseField MODEL_ID = new ParseField(\"model_id\");\n+    public static final ParseField NODE_ID = new ParseField(\"node_id\");\n+    public static final ParseField TOTAL_TIME_SPENT_MILLIS = new ParseField(\"total_time_spent_millis\");\n+    private static final ParseField TOTAL_TIME_SPENT = new ParseField(\"total_time_spent\");\n+    public static final ParseField FAILURE_COUNT = new ParseField(\"failure_count\");\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"time_stamp\");\n+\n+    public static final ConstructingObjectParser<InferenceStats, Void> PARSER = new ConstructingObjectParser<>(\n+        NAME,\n+        true,\n+        a -> new InferenceStats((Long)a[0], (Long)a[1], (Long)a[2], (Long)a[3], (String)a[4], (String)a[5], (Instant) a[6])\n+    );\n+    static {\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), MISSING_ALL_FIELDS_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), INFERENCE_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), TOTAL_TIME_SPENT_MILLIS);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), FAILURE_COUNT);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), MODEL_ID);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), NODE_ID);\n+        PARSER.declareField(ConstructingObjectParser.constructorArg(),\n+            p -> TimeUtils.parseTimeFieldToInstant(p, TIMESTAMP.getPreferredName()),\n+            TIMESTAMP,\n+            ObjectParser.ValueType.VALUE);\n+    }\n+    public static InferenceStats emptyStats(String modelId, String nodeId) {\n+        return new InferenceStats(0L, 0L, 0L, 0L, modelId, nodeId, Instant.now());\n+    }\n+\n+    public static String docId(String modelId, String nodeId) {\n+        return NAME + \"-\" + modelId + \"-\" + nodeId;\n+    }\n+\n+    private final long missingAllFieldsCount;\n+    private final long inferenceCount;\n+    private final long totalTimeSpent;\n+    private final long failureCount;\n+    private final String modelId;\n+    private final String nodeId;\n+    private final Instant timeStamp;\n+\n+    private InferenceStats(Long missingAllFieldsCount,\n+                           Long inferenceCount,\n+                           Long totalTimeSpent,\n+                           Long failureCount,\n+                           String modelId,\n+                           String nodeId,\n+                           Instant instant) {\n+        this(unbox(missingAllFieldsCount),\n+            unbox(inferenceCount),\n+            unbox(totalTimeSpent),\n+            unbox(failureCount),\n+            modelId,\n+            nodeId,\n+            instant == null ? Instant.now() : Instant.ofEpochMilli(instant.toEpochMilli()));\n+    }\n+\n+\n+    public InferenceStats(long missingAllFieldsCount,\n+                          long inferenceCount,\n+                          long totalTimeSpent,\n+                          long failureCount,\n+                          String modelId,\n+                          String nodeId,\n+                          Instant timeStamp) {\n+        this.missingAllFieldsCount = missingAllFieldsCount;\n+        this.inferenceCount = inferenceCount;\n+        this.totalTimeSpent = totalTimeSpent;\n+        this.failureCount = failureCount;\n+        this.modelId = modelId;\n+        this.nodeId = nodeId;\n+        this.timeStamp = timeStamp == null ?\n+            Instant.ofEpochMilli(Instant.now().toEpochMilli()) :\n+            Instant.ofEpochMilli(timeStamp.toEpochMilli());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTAyNzQxNw==", "bodyText": "Oh is it to trim the nanoseconds? Is that because of a failing equality check?", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395027417", "createdAt": "2020-03-19T13:33:55Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/InferenceStats.java", "diffHunk": "@@ -0,0 +1,268 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.inference.trainedmodel;\n+\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+import java.util.concurrent.atomic.LongAdder;\n+\n+public class InferenceStats implements ToXContentObject, Writeable {\n+\n+    public static final String NAME = \"inference_stats\";\n+    public static final ParseField MISSING_ALL_FIELDS_COUNT = new ParseField(\"missing_all_fields_count\");\n+    public static final ParseField INFERENCE_COUNT = new ParseField(\"inference_count\");\n+    public static final ParseField MODEL_ID = new ParseField(\"model_id\");\n+    public static final ParseField NODE_ID = new ParseField(\"node_id\");\n+    public static final ParseField TOTAL_TIME_SPENT_MILLIS = new ParseField(\"total_time_spent_millis\");\n+    private static final ParseField TOTAL_TIME_SPENT = new ParseField(\"total_time_spent\");\n+    public static final ParseField FAILURE_COUNT = new ParseField(\"failure_count\");\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"time_stamp\");\n+\n+    public static final ConstructingObjectParser<InferenceStats, Void> PARSER = new ConstructingObjectParser<>(\n+        NAME,\n+        true,\n+        a -> new InferenceStats((Long)a[0], (Long)a[1], (Long)a[2], (Long)a[3], (String)a[4], (String)a[5], (Instant) a[6])\n+    );\n+    static {\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), MISSING_ALL_FIELDS_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), INFERENCE_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), TOTAL_TIME_SPENT_MILLIS);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), FAILURE_COUNT);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), MODEL_ID);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), NODE_ID);\n+        PARSER.declareField(ConstructingObjectParser.constructorArg(),\n+            p -> TimeUtils.parseTimeFieldToInstant(p, TIMESTAMP.getPreferredName()),\n+            TIMESTAMP,\n+            ObjectParser.ValueType.VALUE);\n+    }\n+    public static InferenceStats emptyStats(String modelId, String nodeId) {\n+        return new InferenceStats(0L, 0L, 0L, 0L, modelId, nodeId, Instant.now());\n+    }\n+\n+    public static String docId(String modelId, String nodeId) {\n+        return NAME + \"-\" + modelId + \"-\" + nodeId;\n+    }\n+\n+    private final long missingAllFieldsCount;\n+    private final long inferenceCount;\n+    private final long totalTimeSpent;\n+    private final long failureCount;\n+    private final String modelId;\n+    private final String nodeId;\n+    private final Instant timeStamp;\n+\n+    private InferenceStats(Long missingAllFieldsCount,\n+                           Long inferenceCount,\n+                           Long totalTimeSpent,\n+                           Long failureCount,\n+                           String modelId,\n+                           String nodeId,\n+                           Instant instant) {\n+        this(unbox(missingAllFieldsCount),\n+            unbox(inferenceCount),\n+            unbox(totalTimeSpent),\n+            unbox(failureCount),\n+            modelId,\n+            nodeId,\n+            instant == null ? Instant.now() : Instant.ofEpochMilli(instant.toEpochMilli()));\n+    }\n+\n+\n+    public InferenceStats(long missingAllFieldsCount,\n+                          long inferenceCount,\n+                          long totalTimeSpent,\n+                          long failureCount,\n+                          String modelId,\n+                          String nodeId,\n+                          Instant timeStamp) {\n+        this.missingAllFieldsCount = missingAllFieldsCount;\n+        this.inferenceCount = inferenceCount;\n+        this.totalTimeSpent = totalTimeSpent;\n+        this.failureCount = failureCount;\n+        this.modelId = modelId;\n+        this.nodeId = nodeId;\n+        this.timeStamp = timeStamp == null ?\n+            Instant.ofEpochMilli(Instant.now().toEpochMilli()) :\n+            Instant.ofEpochMilli(timeStamp.toEpochMilli());\n+    }\n+\n+    public InferenceStats(StreamInput in) throws IOException {\n+        this.missingAllFieldsCount = in.readVLong();\n+        this.inferenceCount = in.readVLong();\n+        this.totalTimeSpent = in.readVLong();\n+        this.failureCount = in.readVLong();\n+        this.modelId = in.readOptionalString();\n+        this.nodeId = in.readOptionalString();\n+        this.timeStamp = Instant.ofEpochMilli(in.readInstant().toEpochMilli());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTAzMjgzMQ==", "bodyText": "Are node_id and model_id not of interest", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395032831", "createdAt": "2020-03-19T13:41:54Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/InferenceStats.java", "diffHunk": "@@ -0,0 +1,268 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.inference.trainedmodel;\n+\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+import java.util.concurrent.atomic.LongAdder;\n+\n+public class InferenceStats implements ToXContentObject, Writeable {\n+\n+    public static final String NAME = \"inference_stats\";\n+    public static final ParseField MISSING_ALL_FIELDS_COUNT = new ParseField(\"missing_all_fields_count\");\n+    public static final ParseField INFERENCE_COUNT = new ParseField(\"inference_count\");\n+    public static final ParseField MODEL_ID = new ParseField(\"model_id\");\n+    public static final ParseField NODE_ID = new ParseField(\"node_id\");\n+    public static final ParseField TOTAL_TIME_SPENT_MILLIS = new ParseField(\"total_time_spent_millis\");\n+    private static final ParseField TOTAL_TIME_SPENT = new ParseField(\"total_time_spent\");\n+    public static final ParseField FAILURE_COUNT = new ParseField(\"failure_count\");\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"time_stamp\");\n+\n+    public static final ConstructingObjectParser<InferenceStats, Void> PARSER = new ConstructingObjectParser<>(\n+        NAME,\n+        true,\n+        a -> new InferenceStats((Long)a[0], (Long)a[1], (Long)a[2], (Long)a[3], (String)a[4], (String)a[5], (Instant) a[6])\n+    );\n+    static {\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), MISSING_ALL_FIELDS_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), INFERENCE_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), TOTAL_TIME_SPENT_MILLIS);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), FAILURE_COUNT);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), MODEL_ID);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), NODE_ID);\n+        PARSER.declareField(ConstructingObjectParser.constructorArg(),\n+            p -> TimeUtils.parseTimeFieldToInstant(p, TIMESTAMP.getPreferredName()),\n+            TIMESTAMP,\n+            ObjectParser.ValueType.VALUE);\n+    }\n+    public static InferenceStats emptyStats(String modelId, String nodeId) {\n+        return new InferenceStats(0L, 0L, 0L, 0L, modelId, nodeId, Instant.now());\n+    }\n+\n+    public static String docId(String modelId, String nodeId) {\n+        return NAME + \"-\" + modelId + \"-\" + nodeId;\n+    }\n+\n+    private final long missingAllFieldsCount;\n+    private final long inferenceCount;\n+    private final long totalTimeSpent;\n+    private final long failureCount;\n+    private final String modelId;\n+    private final String nodeId;\n+    private final Instant timeStamp;\n+\n+    private InferenceStats(Long missingAllFieldsCount,\n+                           Long inferenceCount,\n+                           Long totalTimeSpent,\n+                           Long failureCount,\n+                           String modelId,\n+                           String nodeId,\n+                           Instant instant) {\n+        this(unbox(missingAllFieldsCount),\n+            unbox(inferenceCount),\n+            unbox(totalTimeSpent),\n+            unbox(failureCount),\n+            modelId,\n+            nodeId,\n+            instant == null ? Instant.now() : Instant.ofEpochMilli(instant.toEpochMilli()));\n+    }\n+\n+\n+    public InferenceStats(long missingAllFieldsCount,\n+                          long inferenceCount,\n+                          long totalTimeSpent,\n+                          long failureCount,\n+                          String modelId,\n+                          String nodeId,\n+                          Instant timeStamp) {\n+        this.missingAllFieldsCount = missingAllFieldsCount;\n+        this.inferenceCount = inferenceCount;\n+        this.totalTimeSpent = totalTimeSpent;\n+        this.failureCount = failureCount;\n+        this.modelId = modelId;\n+        this.nodeId = nodeId;\n+        this.timeStamp = timeStamp == null ?\n+            Instant.ofEpochMilli(Instant.now().toEpochMilli()) :\n+            Instant.ofEpochMilli(timeStamp.toEpochMilli());\n+    }\n+\n+    public InferenceStats(StreamInput in) throws IOException {\n+        this.missingAllFieldsCount = in.readVLong();\n+        this.inferenceCount = in.readVLong();\n+        this.totalTimeSpent = in.readVLong();\n+        this.failureCount = in.readVLong();\n+        this.modelId = in.readOptionalString();\n+        this.nodeId = in.readOptionalString();\n+        this.timeStamp = Instant.ofEpochMilli(in.readInstant().toEpochMilli());\n+    }\n+\n+    public long getMissingAllFieldsCount() {\n+        return missingAllFieldsCount;\n+    }\n+\n+    public long getInferenceCount() {\n+        return inferenceCount;\n+    }\n+\n+    public long getTotalTimeSpent() {\n+        return totalTimeSpent;\n+    }\n+\n+    public long getFailureCount() {\n+        return failureCount;\n+    }\n+\n+    public String getModelId() {\n+        return modelId;\n+    }\n+\n+    public String getNodeId() {\n+        return nodeId;\n+    }\n+\n+    public Instant getTimeStamp() {\n+        return timeStamp;\n+    }\n+\n+    @Override\n+    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n+        builder.startObject();\n+        if (params.paramAsBoolean(ToXContentParams.FOR_INTERNAL_STORAGE, false)) {\n+            assert modelId != null : \"model_id cannot be null when storing inference stats\";\n+            assert nodeId != null : \"node_id cannot be null when storing inference stats\";\n+            builder.field(TYPE.getPreferredName(), NAME);\n+            builder.field(MODEL_ID.getPreferredName(), modelId);\n+            builder.field(NODE_ID.getPreferredName(), nodeId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 154}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTE1ODU1OQ==", "bodyText": "maybe addTimeSpent", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395158559", "createdAt": "2020-03-19T16:30:08Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/InferenceStats.java", "diffHunk": "@@ -0,0 +1,268 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.inference.trainedmodel;\n+\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+import java.util.concurrent.atomic.LongAdder;\n+\n+public class InferenceStats implements ToXContentObject, Writeable {\n+\n+    public static final String NAME = \"inference_stats\";\n+    public static final ParseField MISSING_ALL_FIELDS_COUNT = new ParseField(\"missing_all_fields_count\");\n+    public static final ParseField INFERENCE_COUNT = new ParseField(\"inference_count\");\n+    public static final ParseField MODEL_ID = new ParseField(\"model_id\");\n+    public static final ParseField NODE_ID = new ParseField(\"node_id\");\n+    public static final ParseField TOTAL_TIME_SPENT_MILLIS = new ParseField(\"total_time_spent_millis\");\n+    private static final ParseField TOTAL_TIME_SPENT = new ParseField(\"total_time_spent\");\n+    public static final ParseField FAILURE_COUNT = new ParseField(\"failure_count\");\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"time_stamp\");\n+\n+    public static final ConstructingObjectParser<InferenceStats, Void> PARSER = new ConstructingObjectParser<>(\n+        NAME,\n+        true,\n+        a -> new InferenceStats((Long)a[0], (Long)a[1], (Long)a[2], (Long)a[3], (String)a[4], (String)a[5], (Instant) a[6])\n+    );\n+    static {\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), MISSING_ALL_FIELDS_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), INFERENCE_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), TOTAL_TIME_SPENT_MILLIS);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), FAILURE_COUNT);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), MODEL_ID);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), NODE_ID);\n+        PARSER.declareField(ConstructingObjectParser.constructorArg(),\n+            p -> TimeUtils.parseTimeFieldToInstant(p, TIMESTAMP.getPreferredName()),\n+            TIMESTAMP,\n+            ObjectParser.ValueType.VALUE);\n+    }\n+    public static InferenceStats emptyStats(String modelId, String nodeId) {\n+        return new InferenceStats(0L, 0L, 0L, 0L, modelId, nodeId, Instant.now());\n+    }\n+\n+    public static String docId(String modelId, String nodeId) {\n+        return NAME + \"-\" + modelId + \"-\" + nodeId;\n+    }\n+\n+    private final long missingAllFieldsCount;\n+    private final long inferenceCount;\n+    private final long totalTimeSpent;\n+    private final long failureCount;\n+    private final String modelId;\n+    private final String nodeId;\n+    private final Instant timeStamp;\n+\n+    private InferenceStats(Long missingAllFieldsCount,\n+                           Long inferenceCount,\n+                           Long totalTimeSpent,\n+                           Long failureCount,\n+                           String modelId,\n+                           String nodeId,\n+                           Instant instant) {\n+        this(unbox(missingAllFieldsCount),\n+            unbox(inferenceCount),\n+            unbox(totalTimeSpent),\n+            unbox(failureCount),\n+            modelId,\n+            nodeId,\n+            instant == null ? Instant.now() : Instant.ofEpochMilli(instant.toEpochMilli()));\n+    }\n+\n+\n+    public InferenceStats(long missingAllFieldsCount,\n+                          long inferenceCount,\n+                          long totalTimeSpent,\n+                          long failureCount,\n+                          String modelId,\n+                          String nodeId,\n+                          Instant timeStamp) {\n+        this.missingAllFieldsCount = missingAllFieldsCount;\n+        this.inferenceCount = inferenceCount;\n+        this.totalTimeSpent = totalTimeSpent;\n+        this.failureCount = failureCount;\n+        this.modelId = modelId;\n+        this.nodeId = nodeId;\n+        this.timeStamp = timeStamp == null ?\n+            Instant.ofEpochMilli(Instant.now().toEpochMilli()) :\n+            Instant.ofEpochMilli(timeStamp.toEpochMilli());\n+    }\n+\n+    public InferenceStats(StreamInput in) throws IOException {\n+        this.missingAllFieldsCount = in.readVLong();\n+        this.inferenceCount = in.readVLong();\n+        this.totalTimeSpent = in.readVLong();\n+        this.failureCount = in.readVLong();\n+        this.modelId = in.readOptionalString();\n+        this.nodeId = in.readOptionalString();\n+        this.timeStamp = Instant.ofEpochMilli(in.readInstant().toEpochMilli());\n+    }\n+\n+    public long getMissingAllFieldsCount() {\n+        return missingAllFieldsCount;\n+    }\n+\n+    public long getInferenceCount() {\n+        return inferenceCount;\n+    }\n+\n+    public long getTotalTimeSpent() {\n+        return totalTimeSpent;\n+    }\n+\n+    public long getFailureCount() {\n+        return failureCount;\n+    }\n+\n+    public String getModelId() {\n+        return modelId;\n+    }\n+\n+    public String getNodeId() {\n+        return nodeId;\n+    }\n+\n+    public Instant getTimeStamp() {\n+        return timeStamp;\n+    }\n+\n+    @Override\n+    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n+        builder.startObject();\n+        if (params.paramAsBoolean(ToXContentParams.FOR_INTERNAL_STORAGE, false)) {\n+            assert modelId != null : \"model_id cannot be null when storing inference stats\";\n+            assert nodeId != null : \"node_id cannot be null when storing inference stats\";\n+            builder.field(TYPE.getPreferredName(), NAME);\n+            builder.field(MODEL_ID.getPreferredName(), modelId);\n+            builder.field(NODE_ID.getPreferredName(), nodeId);\n+        }\n+        builder.field(FAILURE_COUNT.getPreferredName(), failureCount);\n+        builder.timeField(TOTAL_TIME_SPENT_MILLIS.getPreferredName(), TOTAL_TIME_SPENT.getPreferredName(), totalTimeSpent);\n+        builder.field(INFERENCE_COUNT.getPreferredName(), inferenceCount);\n+        builder.field(MISSING_ALL_FIELDS_COUNT.getPreferredName(), missingAllFieldsCount);\n+        builder.timeField(TIMESTAMP.getPreferredName(), TIMESTAMP.getPreferredName() + \"_string\", timeStamp.toEpochMilli());\n+        builder.endObject();\n+        return builder;\n+    }\n+\n+    @Override\n+    public boolean equals(Object o) {\n+        if (this == o) return true;\n+        if (o == null || getClass() != o.getClass()) return false;\n+        InferenceStats that = (InferenceStats) o;\n+        return missingAllFieldsCount == that.missingAllFieldsCount\n+            && inferenceCount == that.inferenceCount\n+            && totalTimeSpent == that.totalTimeSpent\n+            && failureCount == that.failureCount\n+            && Objects.equals(modelId, that.modelId)\n+            && Objects.equals(nodeId, that.nodeId)\n+            && Objects.equals(timeStamp, that.timeStamp);\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return Objects.hash(missingAllFieldsCount, inferenceCount, totalTimeSpent, failureCount, modelId, nodeId, timeStamp);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return Strings.toString(this);\n+    }\n+\n+    private static long unbox(@Nullable Long value) {\n+        return value == null ? 0L : value;\n+    }\n+\n+    public static Accumulator accumulator(String modelId, String nodeId) {\n+        return new Accumulator(modelId, nodeId);\n+    }\n+\n+    @Override\n+    public void writeTo(StreamOutput out) throws IOException {\n+        out.writeVLong(this.missingAllFieldsCount);\n+        out.writeVLong(this.inferenceCount);\n+        out.writeVLong(this.totalTimeSpent);\n+        out.writeVLong(this.failureCount);\n+        out.writeOptionalString(this.modelId);\n+        out.writeOptionalString(this.nodeId);\n+        out.writeInstant(timeStamp);\n+    }\n+\n+    public static class Accumulator {\n+\n+        private final LongAdder missingFieldsAccumulator = new LongAdder();\n+        private final LongAdder inferenceAccumulator = new LongAdder();\n+        private final LongAdder totalTimeSpentAccumulator = new LongAdder();\n+        private final LongAdder failureCountAccumulator = new LongAdder();\n+        private final String modelId;\n+        private final String nodeId;\n+\n+        public Accumulator(String modelId, String nodeId) {\n+            this.modelId = modelId;\n+            this.nodeId = nodeId;\n+        }\n+\n+        public Accumulator(InferenceStats previousStats) {\n+            this.modelId = previousStats.modelId;\n+            this.nodeId = previousStats.nodeId;\n+            this.missingFieldsAccumulator.add(previousStats.missingAllFieldsCount);\n+            this.inferenceAccumulator.add(previousStats.inferenceCount);\n+            this.totalTimeSpentAccumulator.add(TimeValue.timeValueMillis(previousStats.totalTimeSpent).nanos());\n+            this.failureCountAccumulator.add(previousStats.failureCount);\n+        }\n+\n+        public void merge(InferenceStats otherStats) {\n+            this.missingFieldsAccumulator.add(otherStats.missingAllFieldsCount);\n+            this.inferenceAccumulator.add(otherStats.inferenceCount);\n+            this.totalTimeSpentAccumulator.add(TimeValue.timeValueMillis(otherStats.totalTimeSpent).nanos());\n+            this.failureCountAccumulator.add(otherStats.failureCount);\n+        }\n+\n+        public void incMissingFields() {\n+            this.missingFieldsAccumulator.increment();\n+        }\n+\n+        public void incInference() {\n+            this.inferenceAccumulator.increment();\n+        }\n+\n+        public void incFailure() {\n+            this.failureCountAccumulator.increment();\n+        }\n+\n+        public void timeSpent(long value) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 250}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTE3Mjc1MQ==", "bodyText": "\ud83d\udc4d", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395172751", "createdAt": "2020-03-19T16:50:26Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportGetTrainedModelsStatsAction.java", "diffHunk": "@@ -102,8 +111,8 @@ protected void doExecute(Task task,\n             idsListener);\n     }\n \n-    static Map<String, IngestStats> inferenceIngestStatsByPipelineId(NodesStatsResponse response,\n-                                                                     Map<String, Set<String>> modelIdToPipelineId) {\n+    static Map<String, IngestStats> inferenceIngestStatsByModelId(NodesStatsResponse response,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTE3NTMxMg==", "bodyText": "I'm not sure about using the GENERIC threadpool \ud83e\udd14", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395175312", "createdAt": "2020-03-19T16:54:05Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.inference;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkRequest;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.action.update.UpdateRequest;\n+import org.elasticsearch.client.OriginSettingClient;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.component.LifecycleListener;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.script.Script;\n+import org.elasticsearch.script.ScriptType;\n+import org.elasticsearch.threadpool.Scheduler;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ml.MlStatsIndex;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.InferenceStats;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.elasticsearch.xpack.ml.utils.persistence.ResultsPersisterService;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+\n+\n+public class TrainedModelStatsService {\n+\n+    private static final Logger logger = LogManager.getLogger(TrainedModelStatsService.class);\n+\n+    // Script to only update if stats have increased since last persistence\n+    private static final String STATS_UPDATE_SCRIPT = \"\" +\n+        \"if (ctx._source.missing_all_fields_count >= params.missing_all_fields_count\\n\" +\n+        \"     && ctx._source.inference_count >= params.inference_count\\n\" +\n+        \"     && ctx._source.total_time_spent_millis >= params.total_time_spent_millis\\n\" +\n+        \"     && ctx._source.failure_count >= params.failure_count) {\\n\" +\n+        \"      ctx.op = 'none';\\n\" +\n+        \"      return;\\n\" +\n+        \"    }\\n\" +\n+        \"    ctx._source.missing_all_fields_count = params.missing_all_fields_count;\\n\" +\n+        \"    ctx._source.inference_count = params.inference_count;\\n\" +\n+        \"    ctx._source.total_time_spent_millis = params.total_time_spent_millis;\\n\" +\n+        \"    ctx._source.failure_count = params.failure_count;\\n\" +\n+        \"    ctx._source.time_stamp = params.time_stamp;\";\n+    private static final ToXContent.Params FOR_INTERNAL_STORAGE_PARAMS =\n+        new ToXContent.MapParams(Collections.singletonMap(ToXContentParams.FOR_INTERNAL_STORAGE, \"true\"));\n+\n+    private final Map<String, InferenceStats> statsQueue;\n+    private final ResultsPersisterService resultsPersisterService;\n+    private final OriginSettingClient client;\n+    private final IndexNameExpressionResolver indexNameExpressionResolver;\n+    private final ThreadPool threadPool;\n+    private volatile Scheduler.Cancellable scheduledFuture;\n+    private volatile boolean verifiedStatsIndexCreated;\n+    private volatile boolean stopped;\n+    private volatile ClusterState clusterState;\n+\n+    public TrainedModelStatsService(ResultsPersisterService resultsPersisterService,\n+                                    OriginSettingClient client,\n+                                    IndexNameExpressionResolver indexNameExpressionResolver,\n+                                    ClusterService clusterService,\n+                                    ThreadPool threadPool) {\n+        this.resultsPersisterService = resultsPersisterService;\n+        this.client = client;\n+        this.indexNameExpressionResolver = indexNameExpressionResolver;\n+        this.threadPool = threadPool;\n+        this.statsQueue = new ConcurrentHashMap<>();\n+\n+        clusterService.addLifecycleListener(new LifecycleListener() {\n+            @Override\n+            public void beforeStart() {\n+                start();\n+            }\n+\n+            @Override\n+            public void beforeStop() {\n+                stop();\n+            }\n+        });\n+        clusterService.addListener((event) -> this.clusterState = event.state());\n+    }\n+\n+    public void queueStats(InferenceStats stats) {\n+        statsQueue.put(InferenceStats.docId(stats.getModelId(), stats.getNodeId()), stats);\n+    }\n+\n+    void stop() {\n+        stopped = true;\n+        statsQueue.clear();\n+\n+        ThreadPool.Cancellable cancellable = this.scheduledFuture;\n+        if (cancellable != null) {\n+            cancellable.cancel();\n+        }\n+    }\n+\n+    void start() {\n+        stopped = false;\n+        scheduledFuture = threadPool.scheduleWithFixedDelay(this::persistStats, TimeValue.timeValueSeconds(1), ThreadPool.Names.GENERIC);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTE4MjI4NQ==", "bodyText": "\"failure creating ml stats index\"", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395182285", "createdAt": "2020-03-19T17:04:16Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.inference;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkRequest;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.action.update.UpdateRequest;\n+import org.elasticsearch.client.OriginSettingClient;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.component.LifecycleListener;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.script.Script;\n+import org.elasticsearch.script.ScriptType;\n+import org.elasticsearch.threadpool.Scheduler;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ml.MlStatsIndex;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.InferenceStats;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.elasticsearch.xpack.ml.utils.persistence.ResultsPersisterService;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+\n+\n+public class TrainedModelStatsService {\n+\n+    private static final Logger logger = LogManager.getLogger(TrainedModelStatsService.class);\n+\n+    // Script to only update if stats have increased since last persistence\n+    private static final String STATS_UPDATE_SCRIPT = \"\" +\n+        \"if (ctx._source.missing_all_fields_count >= params.missing_all_fields_count\\n\" +\n+        \"     && ctx._source.inference_count >= params.inference_count\\n\" +\n+        \"     && ctx._source.total_time_spent_millis >= params.total_time_spent_millis\\n\" +\n+        \"     && ctx._source.failure_count >= params.failure_count) {\\n\" +\n+        \"      ctx.op = 'none';\\n\" +\n+        \"      return;\\n\" +\n+        \"    }\\n\" +\n+        \"    ctx._source.missing_all_fields_count = params.missing_all_fields_count;\\n\" +\n+        \"    ctx._source.inference_count = params.inference_count;\\n\" +\n+        \"    ctx._source.total_time_spent_millis = params.total_time_spent_millis;\\n\" +\n+        \"    ctx._source.failure_count = params.failure_count;\\n\" +\n+        \"    ctx._source.time_stamp = params.time_stamp;\";\n+    private static final ToXContent.Params FOR_INTERNAL_STORAGE_PARAMS =\n+        new ToXContent.MapParams(Collections.singletonMap(ToXContentParams.FOR_INTERNAL_STORAGE, \"true\"));\n+\n+    private final Map<String, InferenceStats> statsQueue;\n+    private final ResultsPersisterService resultsPersisterService;\n+    private final OriginSettingClient client;\n+    private final IndexNameExpressionResolver indexNameExpressionResolver;\n+    private final ThreadPool threadPool;\n+    private volatile Scheduler.Cancellable scheduledFuture;\n+    private volatile boolean verifiedStatsIndexCreated;\n+    private volatile boolean stopped;\n+    private volatile ClusterState clusterState;\n+\n+    public TrainedModelStatsService(ResultsPersisterService resultsPersisterService,\n+                                    OriginSettingClient client,\n+                                    IndexNameExpressionResolver indexNameExpressionResolver,\n+                                    ClusterService clusterService,\n+                                    ThreadPool threadPool) {\n+        this.resultsPersisterService = resultsPersisterService;\n+        this.client = client;\n+        this.indexNameExpressionResolver = indexNameExpressionResolver;\n+        this.threadPool = threadPool;\n+        this.statsQueue = new ConcurrentHashMap<>();\n+\n+        clusterService.addLifecycleListener(new LifecycleListener() {\n+            @Override\n+            public void beforeStart() {\n+                start();\n+            }\n+\n+            @Override\n+            public void beforeStop() {\n+                stop();\n+            }\n+        });\n+        clusterService.addListener((event) -> this.clusterState = event.state());\n+    }\n+\n+    public void queueStats(InferenceStats stats) {\n+        statsQueue.put(InferenceStats.docId(stats.getModelId(), stats.getNodeId()), stats);\n+    }\n+\n+    void stop() {\n+        stopped = true;\n+        statsQueue.clear();\n+\n+        ThreadPool.Cancellable cancellable = this.scheduledFuture;\n+        if (cancellable != null) {\n+            cancellable.cancel();\n+        }\n+    }\n+\n+    void start() {\n+        stopped = false;\n+        scheduledFuture = threadPool.scheduleWithFixedDelay(this::persistStats, TimeValue.timeValueSeconds(1), ThreadPool.Names.GENERIC);\n+    }\n+\n+    void persistStats() {\n+        if (clusterState == null || statsQueue.isEmpty()) {\n+            return;\n+        }\n+\n+        List<InferenceStats> stats = new ArrayList<>(statsQueue.size());\n+        for(String k : statsQueue.keySet()) {\n+            InferenceStats inferenceStats = statsQueue.remove(k);\n+            if (inferenceStats != null) {\n+                stats.add(inferenceStats);\n+            }\n+        }\n+        if (stats.isEmpty()) {\n+            return;\n+        }\n+        if (verifiedStatsIndexCreated == false) {\n+            try {\n+                PlainActionFuture<Boolean> listener = new PlainActionFuture<>();\n+                MlStatsIndex.createStatsIndexAndAliasIfNecessary(client, clusterState, indexNameExpressionResolver, listener);\n+                listener.actionGet();\n+                verifiedStatsIndexCreated = true;\n+            } catch (Exception e) {\n+                logger.error(\n+                    new ParameterizedMessage(\"failure updating stats for models {}\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 142}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTE4MzgyMw==", "bodyText": "Will this be printed properly, what is toString() on a stream?", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395183823", "createdAt": "2020-03-19T17:06:36Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.inference;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkRequest;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.action.update.UpdateRequest;\n+import org.elasticsearch.client.OriginSettingClient;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.component.LifecycleListener;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.script.Script;\n+import org.elasticsearch.script.ScriptType;\n+import org.elasticsearch.threadpool.Scheduler;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ml.MlStatsIndex;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.InferenceStats;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.elasticsearch.xpack.ml.utils.persistence.ResultsPersisterService;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+\n+\n+public class TrainedModelStatsService {\n+\n+    private static final Logger logger = LogManager.getLogger(TrainedModelStatsService.class);\n+\n+    // Script to only update if stats have increased since last persistence\n+    private static final String STATS_UPDATE_SCRIPT = \"\" +\n+        \"if (ctx._source.missing_all_fields_count >= params.missing_all_fields_count\\n\" +\n+        \"     && ctx._source.inference_count >= params.inference_count\\n\" +\n+        \"     && ctx._source.total_time_spent_millis >= params.total_time_spent_millis\\n\" +\n+        \"     && ctx._source.failure_count >= params.failure_count) {\\n\" +\n+        \"      ctx.op = 'none';\\n\" +\n+        \"      return;\\n\" +\n+        \"    }\\n\" +\n+        \"    ctx._source.missing_all_fields_count = params.missing_all_fields_count;\\n\" +\n+        \"    ctx._source.inference_count = params.inference_count;\\n\" +\n+        \"    ctx._source.total_time_spent_millis = params.total_time_spent_millis;\\n\" +\n+        \"    ctx._source.failure_count = params.failure_count;\\n\" +\n+        \"    ctx._source.time_stamp = params.time_stamp;\";\n+    private static final ToXContent.Params FOR_INTERNAL_STORAGE_PARAMS =\n+        new ToXContent.MapParams(Collections.singletonMap(ToXContentParams.FOR_INTERNAL_STORAGE, \"true\"));\n+\n+    private final Map<String, InferenceStats> statsQueue;\n+    private final ResultsPersisterService resultsPersisterService;\n+    private final OriginSettingClient client;\n+    private final IndexNameExpressionResolver indexNameExpressionResolver;\n+    private final ThreadPool threadPool;\n+    private volatile Scheduler.Cancellable scheduledFuture;\n+    private volatile boolean verifiedStatsIndexCreated;\n+    private volatile boolean stopped;\n+    private volatile ClusterState clusterState;\n+\n+    public TrainedModelStatsService(ResultsPersisterService resultsPersisterService,\n+                                    OriginSettingClient client,\n+                                    IndexNameExpressionResolver indexNameExpressionResolver,\n+                                    ClusterService clusterService,\n+                                    ThreadPool threadPool) {\n+        this.resultsPersisterService = resultsPersisterService;\n+        this.client = client;\n+        this.indexNameExpressionResolver = indexNameExpressionResolver;\n+        this.threadPool = threadPool;\n+        this.statsQueue = new ConcurrentHashMap<>();\n+\n+        clusterService.addLifecycleListener(new LifecycleListener() {\n+            @Override\n+            public void beforeStart() {\n+                start();\n+            }\n+\n+            @Override\n+            public void beforeStop() {\n+                stop();\n+            }\n+        });\n+        clusterService.addListener((event) -> this.clusterState = event.state());\n+    }\n+\n+    public void queueStats(InferenceStats stats) {\n+        statsQueue.put(InferenceStats.docId(stats.getModelId(), stats.getNodeId()), stats);\n+    }\n+\n+    void stop() {\n+        stopped = true;\n+        statsQueue.clear();\n+\n+        ThreadPool.Cancellable cancellable = this.scheduledFuture;\n+        if (cancellable != null) {\n+            cancellable.cancel();\n+        }\n+    }\n+\n+    void start() {\n+        stopped = false;\n+        scheduledFuture = threadPool.scheduleWithFixedDelay(this::persistStats, TimeValue.timeValueSeconds(1), ThreadPool.Names.GENERIC);\n+    }\n+\n+    void persistStats() {\n+        if (clusterState == null || statsQueue.isEmpty()) {\n+            return;\n+        }\n+\n+        List<InferenceStats> stats = new ArrayList<>(statsQueue.size());\n+        for(String k : statsQueue.keySet()) {\n+            InferenceStats inferenceStats = statsQueue.remove(k);\n+            if (inferenceStats != null) {\n+                stats.add(inferenceStats);\n+            }\n+        }\n+        if (stats.isEmpty()) {\n+            return;\n+        }\n+        if (verifiedStatsIndexCreated == false) {\n+            try {\n+                PlainActionFuture<Boolean> listener = new PlainActionFuture<>();\n+                MlStatsIndex.createStatsIndexAndAliasIfNecessary(client, clusterState, indexNameExpressionResolver, listener);\n+                listener.actionGet();\n+                verifiedStatsIndexCreated = true;\n+            } catch (Exception e) {\n+                logger.error(\n+                    new ParameterizedMessage(\"failure updating stats for models {}\",\n+                        stats.stream().map(InferenceStats::getModelId)),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 143}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTE5NzYzNw==", "bodyText": "I thought the string replacement in the message parameter only occurred if trace is enabled", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395197637", "createdAt": "2020-03-19T17:27:15Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/ModelLoadingService.java", "diffHunk": "@@ -130,24 +141,26 @@ public void getModel(String modelId, ActionListener<Model> modelActionListener)\n         LocalModel cachedModel = localModelCache.get(modelId);\n         if (cachedModel != null) {\n             modelActionListener.onResponse(cachedModel);\n-            logger.trace(\"[{}] loaded from cache\", modelId);\n+            logger.trace(() -> new ParameterizedMessage(\"[{}] loaded from cache\", modelId));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTIwMjQyNA==", "bodyText": "This is a tricky one. When the model is done with how do we ensure it persists the latest stats. Could this implement closable and persist on close when the model is evicted from the cache?", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395202424", "createdAt": "2020-03-19T17:34:29Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/LocalModel.java", "diffHunk": "@@ -64,17 +100,45 @@ public String getResultsType() {\n         }\n     }\n \n+    void persistStats() {\n+        trainedModelStatsService.queueStats(getLatestStats());\n+        lastStatsQueue = nanoTimeSupplier.get();\n+        if (persistenceQuotient < 1000 && currentInferenceCount.sum() > 1000) {\n+            persistenceQuotient = 1000;\n+        }\n+        if (persistenceQuotient < 10_000 && currentInferenceCount.sum() > 10_000) {\n+            persistenceQuotient = 10_000;\n+        }\n+    }\n+\n     @Override\n     public void infer(Map<String, Object> fields, InferenceConfig config, ActionListener<InferenceResults> listener) {\n         try {\n+            statsAccumulator.incInference();\n+            currentInferenceCount.increment();\n+\n             Model.mapFieldsIfNecessary(fields, defaultFieldMap);\n+\n+            long startTimeInNanos = nanoTimeSupplier.get();\n+            boolean shouldPersistStats =\n+                (TimeUnit.NANOSECONDS.toMillis(startTimeInNanos - lastStatsQueue) > MIN_PERSISTENCE_INTERVAL)\n+                || ((currentInferenceCount.sum() + 1) % persistenceQuotient == 0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTIxMzQzOQ==", "bodyText": "\"search failed for model stats\"\nMaybe construct the string and use the same one for the logger and exception message", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395213439", "createdAt": "2020-03-19T17:51:45Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/persistence/TrainedModelProvider.java", "diffHunk": "@@ -453,6 +459,155 @@ public void expandIds(String idExpression,\n             client::search);\n     }\n \n+    public void getInferenceStats(String[] modelIds, ActionListener<List<InferenceStats>> listener) {\n+        MultiSearchRequest multiSearchRequest = new MultiSearchRequest();\n+        Arrays.stream(modelIds).map(this::buildStatsSearchRequest).forEach(multiSearchRequest::add);\n+        if (multiSearchRequest.requests().isEmpty()) {\n+            listener.onResponse(Collections.emptyList());\n+            return;\n+        }\n+        executeAsyncWithOrigin(client.threadPool().getThreadContext(),\n+            ML_ORIGIN,\n+            multiSearchRequest,\n+            ActionListener.<MultiSearchResponse>wrap(\n+                responses -> {\n+                    List<InferenceStats> allStats = new ArrayList<>(modelIds.length);\n+                    int modelIndex = 0;\n+                    assert responses.getResponses().length == modelIds.length :\n+                        \"mismatch between search response size and models requested\";\n+                    for (MultiSearchResponse.Item response : responses.getResponses()) {\n+                        if (response.isFailure()) {\n+                            if (ExceptionsHelper.unwrapCause(response.getFailure()) instanceof ResourceNotFoundException) {\n+                                continue;\n+                            }\n+                            logger.error(new ParameterizedMessage(\"search failed for models [{}]\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTIxNDMwNw==", "bodyText": "modelIndex++;", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395214307", "createdAt": "2020-03-19T17:53:12Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/persistence/TrainedModelProvider.java", "diffHunk": "@@ -453,6 +459,155 @@ public void expandIds(String idExpression,\n             client::search);\n     }\n \n+    public void getInferenceStats(String[] modelIds, ActionListener<List<InferenceStats>> listener) {\n+        MultiSearchRequest multiSearchRequest = new MultiSearchRequest();\n+        Arrays.stream(modelIds).map(this::buildStatsSearchRequest).forEach(multiSearchRequest::add);\n+        if (multiSearchRequest.requests().isEmpty()) {\n+            listener.onResponse(Collections.emptyList());\n+            return;\n+        }\n+        executeAsyncWithOrigin(client.threadPool().getThreadContext(),\n+            ML_ORIGIN,\n+            multiSearchRequest,\n+            ActionListener.<MultiSearchResponse>wrap(\n+                responses -> {\n+                    List<InferenceStats> allStats = new ArrayList<>(modelIds.length);\n+                    int modelIndex = 0;\n+                    assert responses.getResponses().length == modelIds.length :\n+                        \"mismatch between search response size and models requested\";\n+                    for (MultiSearchResponse.Item response : responses.getResponses()) {\n+                        if (response.isFailure()) {\n+                            if (ExceptionsHelper.unwrapCause(response.getFailure()) instanceof ResourceNotFoundException) {\n+                                continue;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTIxNzY1MQ==", "bodyText": "In theory the number of stats docs returned is the number of distinct count of nodes the model was ever open on? And there will be one document for every unique node/model id pair", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395217651", "createdAt": "2020-03-19T17:58:34Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/persistence/TrainedModelProvider.java", "diffHunk": "@@ -453,6 +459,155 @@ public void expandIds(String idExpression,\n             client::search);\n     }\n \n+    public void getInferenceStats(String[] modelIds, ActionListener<List<InferenceStats>> listener) {\n+        MultiSearchRequest multiSearchRequest = new MultiSearchRequest();\n+        Arrays.stream(modelIds).map(this::buildStatsSearchRequest).forEach(multiSearchRequest::add);\n+        if (multiSearchRequest.requests().isEmpty()) {\n+            listener.onResponse(Collections.emptyList());\n+            return;\n+        }\n+        executeAsyncWithOrigin(client.threadPool().getThreadContext(),\n+            ML_ORIGIN,\n+            multiSearchRequest,\n+            ActionListener.<MultiSearchResponse>wrap(\n+                responses -> {\n+                    List<InferenceStats> allStats = new ArrayList<>(modelIds.length);\n+                    int modelIndex = 0;\n+                    assert responses.getResponses().length == modelIds.length :\n+                        \"mismatch between search response size and models requested\";\n+                    for (MultiSearchResponse.Item response : responses.getResponses()) {\n+                        if (response.isFailure()) {\n+                            if (ExceptionsHelper.unwrapCause(response.getFailure()) instanceof ResourceNotFoundException) {\n+                                continue;\n+                            }\n+                            logger.error(new ParameterizedMessage(\"search failed for models [{}]\",\n+                                    Strings.arrayToCommaDelimitedString(modelIds)),\n+                                response.getFailure());\n+                            listener.onFailure(ExceptionsHelper.serverError(\"Searching for stats for models [{}] failed\",\n+                                response.getFailure(),\n+                                Strings.arrayToCommaDelimitedString(modelIds)));\n+                            return;\n+                        }\n+                        try {\n+                            InferenceStats inferenceStats = handleMultiNodeStatsResponse(response.getResponse(), modelIds[modelIndex++]);\n+                            if (inferenceStats != null) {\n+                                allStats.add(inferenceStats);\n+                            }\n+                        } catch (Exception e) {\n+                            listener.onFailure(e);\n+                            return;\n+                        }\n+                    }\n+                    listener.onResponse(allStats);\n+                },\n+                e -> {\n+                    Throwable unwrapped = ExceptionsHelper.unwrapCause(e);\n+                    if (unwrapped instanceof ResourceNotFoundException) {\n+                        listener.onResponse(Collections.emptyList());\n+                        return;\n+                    }\n+                    listener.onFailure((Exception)unwrapped);\n+                }\n+            ),\n+            client::multiSearch);\n+    }\n+\n+    private SearchRequest buildStatsSearchRequest(String modelId) {\n+        BoolQueryBuilder queryBuilder = QueryBuilders.boolQuery()\n+            .filter(QueryBuilders.termQuery(InferenceStats.MODEL_ID.getPreferredName(), modelId))\n+            .filter(QueryBuilders.termQuery(InferenceStats.TYPE.getPreferredName(), InferenceStats.NAME));\n+        return new SearchRequest(MlStatsIndex.indexPattern())\n+            .indicesOptions(IndicesOptions.lenientExpandOpen())\n+            .allowPartialSearchResults(false)\n+            .source(SearchSourceBuilder.searchSource()\n+                .size(MAX_NODE_STATS_SIZE)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 112}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b7bda48eee739bb4f730a7be564aec530b3c6333", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/b7bda48eee739bb4f730a7be564aec530b3c6333", "committedDate": "2020-03-20T14:55:55Z", "message": "addressing pr comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6bf2263eaf42762dd92df701ee5a77ce099f6815", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/6bf2263eaf42762dd92df701ee5a77ce099f6815", "committedDate": "2020-03-20T14:57:00Z", "message": "Merge branch 'master' into feature/ml-inference-stats-collection"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc5NzIyNDg3", "url": "https://github.com/elastic/elasticsearch/pull/53429#pullrequestreview-379722487", "createdAt": "2020-03-23T18:47:58Z", "commit": {"oid": "6bf2263eaf42762dd92df701ee5a77ce099f6815"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yM1QxODo0Nzo1OFrOF6Taig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yM1QxOTowODo1NlrOF6UJ3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjY3OTgxOA==", "bodyText": "I know we are using the utility threadpool but this should really be aysnc i think. Maybe use ThreadedActionListener to ensure the nexts steps are done on the ML utility thread pool", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r396679818", "createdAt": "2020-03-23T18:47:58Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.inference;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkRequest;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.action.update.UpdateRequest;\n+import org.elasticsearch.client.OriginSettingClient;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.component.LifecycleListener;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.script.Script;\n+import org.elasticsearch.script.ScriptType;\n+import org.elasticsearch.threadpool.Scheduler;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ml.MlStatsIndex;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.InferenceStats;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.elasticsearch.xpack.ml.MachineLearning;\n+import org.elasticsearch.xpack.ml.utils.persistence.ResultsPersisterService;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+\n+\n+public class TrainedModelStatsService {\n+\n+    private static final Logger logger = LogManager.getLogger(TrainedModelStatsService.class);\n+\n+    // Script to only update if stats have increased since last persistence\n+    private static final String STATS_UPDATE_SCRIPT = \"\" +\n+        \"if (ctx._source.missing_all_fields_count >= params.missing_all_fields_count\\n\" +\n+        \"     && ctx._source.inference_count >= params.inference_count\\n\" +\n+        \"     && ctx._source.total_time_spent_millis >= params.total_time_spent_millis\\n\" +\n+        \"     && ctx._source.failure_count >= params.failure_count) {\\n\" +\n+        \"      ctx.op = 'none';\\n\" +\n+        \"      return;\\n\" +\n+        \"    }\\n\" +\n+        \"    ctx._source.missing_all_fields_count = params.missing_all_fields_count;\\n\" +\n+        \"    ctx._source.inference_count = params.inference_count;\\n\" +\n+        \"    ctx._source.total_time_spent_millis = params.total_time_spent_millis;\\n\" +\n+        \"    ctx._source.failure_count = params.failure_count;\\n\" +\n+        \"    ctx._source.time_stamp = params.time_stamp;\";\n+    private static final ToXContent.Params FOR_INTERNAL_STORAGE_PARAMS =\n+        new ToXContent.MapParams(Collections.singletonMap(ToXContentParams.FOR_INTERNAL_STORAGE, \"true\"));\n+\n+    private final Map<String, InferenceStats> statsQueue;\n+    private final ResultsPersisterService resultsPersisterService;\n+    private final OriginSettingClient client;\n+    private final IndexNameExpressionResolver indexNameExpressionResolver;\n+    private final ThreadPool threadPool;\n+    private volatile Scheduler.Cancellable scheduledFuture;\n+    private volatile boolean verifiedStatsIndexCreated;\n+    private volatile boolean stopped;\n+    private volatile ClusterState clusterState;\n+\n+    public TrainedModelStatsService(ResultsPersisterService resultsPersisterService,\n+                                    OriginSettingClient client,\n+                                    IndexNameExpressionResolver indexNameExpressionResolver,\n+                                    ClusterService clusterService,\n+                                    ThreadPool threadPool) {\n+        this.resultsPersisterService = resultsPersisterService;\n+        this.client = client;\n+        this.indexNameExpressionResolver = indexNameExpressionResolver;\n+        this.threadPool = threadPool;\n+        this.statsQueue = new ConcurrentHashMap<>();\n+\n+        clusterService.addLifecycleListener(new LifecycleListener() {\n+            @Override\n+            public void beforeStart() {\n+                start();\n+            }\n+\n+            @Override\n+            public void beforeStop() {\n+                stop();\n+            }\n+        });\n+        clusterService.addListener((event) -> this.clusterState = event.state());\n+    }\n+\n+    public void queueStats(InferenceStats stats) {\n+        statsQueue.put(InferenceStats.docId(stats.getModelId(), stats.getNodeId()), stats);\n+    }\n+\n+    void stop() {\n+        stopped = true;\n+        statsQueue.clear();\n+\n+        ThreadPool.Cancellable cancellable = this.scheduledFuture;\n+        if (cancellable != null) {\n+            cancellable.cancel();\n+        }\n+    }\n+\n+    void start() {\n+        stopped = false;\n+        scheduledFuture = threadPool.scheduleWithFixedDelay(this::persistStats,\n+            TimeValue.timeValueSeconds(1),\n+            MachineLearning.UTILITY_THREAD_POOL_NAME);\n+    }\n+\n+    void persistStats() {\n+        if (clusterState == null || statsQueue.isEmpty()) {\n+            return;\n+        }\n+\n+        List<InferenceStats> stats = new ArrayList<>(statsQueue.size());\n+        for(String k : statsQueue.keySet()) {\n+            InferenceStats inferenceStats = statsQueue.remove(k);\n+            if (inferenceStats != null) {\n+                stats.add(inferenceStats);\n+            }\n+        }\n+        if (stats.isEmpty()) {\n+            return;\n+        }\n+        if (verifiedStatsIndexCreated == false) {\n+            try {\n+                PlainActionFuture<Boolean> listener = new PlainActionFuture<>();\n+                MlStatsIndex.createStatsIndexAndAliasIfNecessary(client, clusterState, indexNameExpressionResolver, listener);\n+                listener.actionGet();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6bf2263eaf42762dd92df701ee5a77ce099f6815"}, "originalPosition": 141}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjY5MDYyOQ==", "bodyText": "Even if is replaced it is replaced by a model that read the old persisted stats. Should it not always persist so changes are captured.", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r396690629", "createdAt": "2020-03-23T19:06:37Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/ModelLoadingService.java", "diffHunk": "@@ -235,17 +250,20 @@ private void handleLoadFailure(String modelId, Exception failure) {\n \n     private void cacheEvictionListener(RemovalNotification<String, LocalModel> notification) {\n         if (notification.getRemovalReason() == RemovalNotification.RemovalReason.EVICTED) {\n-            String msg = new ParameterizedMessage(\n+            MessageSupplier msg = () -> new ParameterizedMessage(\n                 \"model cache entry evicted.\" +\n                     \"current cache [{}] current max [{}] model size [{}]. \" +\n                     \"If this is undesired, consider updating setting [{}] or [{}].\",\n                 new ByteSizeValue(localModelCache.weight()).getStringRep(),\n                 maxCacheSize.getStringRep(),\n                 new ByteSizeValue(notification.getValue().ramBytesUsed()).getStringRep(),\n                 INFERENCE_MODEL_CACHE_SIZE.getKey(),\n-                INFERENCE_MODEL_CACHE_TTL.getKey()).getFormattedMessage();\n+                INFERENCE_MODEL_CACHE_TTL.getKey());\n             auditIfNecessary(notification.getKey(), msg);\n         }\n+        if (notification.getRemovalReason() != RemovalNotification.RemovalReason.REPLACED) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6bf2263eaf42762dd92df701ee5a77ce099f6815"}, "originalPosition": 153}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjY5MTkzMw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                void persistStats() {\n          \n          \n            \n                void updateStats() {\n          \n      \n    \n    \n  \n\nTo me persistStats() makes me think they are being overwritten and update is clearer. That's how I see it anyway many people may disagree", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r396691933", "createdAt": "2020-03-23T19:08:56Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.inference;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkRequest;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.action.update.UpdateRequest;\n+import org.elasticsearch.client.OriginSettingClient;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.component.LifecycleListener;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.script.Script;\n+import org.elasticsearch.script.ScriptType;\n+import org.elasticsearch.threadpool.Scheduler;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ml.MlStatsIndex;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.InferenceStats;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.elasticsearch.xpack.ml.MachineLearning;\n+import org.elasticsearch.xpack.ml.utils.persistence.ResultsPersisterService;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+\n+\n+public class TrainedModelStatsService {\n+\n+    private static final Logger logger = LogManager.getLogger(TrainedModelStatsService.class);\n+\n+    // Script to only update if stats have increased since last persistence\n+    private static final String STATS_UPDATE_SCRIPT = \"\" +\n+        \"if (ctx._source.missing_all_fields_count >= params.missing_all_fields_count\\n\" +\n+        \"     && ctx._source.inference_count >= params.inference_count\\n\" +\n+        \"     && ctx._source.total_time_spent_millis >= params.total_time_spent_millis\\n\" +\n+        \"     && ctx._source.failure_count >= params.failure_count) {\\n\" +\n+        \"      ctx.op = 'none';\\n\" +\n+        \"      return;\\n\" +\n+        \"    }\\n\" +\n+        \"    ctx._source.missing_all_fields_count = params.missing_all_fields_count;\\n\" +\n+        \"    ctx._source.inference_count = params.inference_count;\\n\" +\n+        \"    ctx._source.total_time_spent_millis = params.total_time_spent_millis;\\n\" +\n+        \"    ctx._source.failure_count = params.failure_count;\\n\" +\n+        \"    ctx._source.time_stamp = params.time_stamp;\";\n+    private static final ToXContent.Params FOR_INTERNAL_STORAGE_PARAMS =\n+        new ToXContent.MapParams(Collections.singletonMap(ToXContentParams.FOR_INTERNAL_STORAGE, \"true\"));\n+\n+    private final Map<String, InferenceStats> statsQueue;\n+    private final ResultsPersisterService resultsPersisterService;\n+    private final OriginSettingClient client;\n+    private final IndexNameExpressionResolver indexNameExpressionResolver;\n+    private final ThreadPool threadPool;\n+    private volatile Scheduler.Cancellable scheduledFuture;\n+    private volatile boolean verifiedStatsIndexCreated;\n+    private volatile boolean stopped;\n+    private volatile ClusterState clusterState;\n+\n+    public TrainedModelStatsService(ResultsPersisterService resultsPersisterService,\n+                                    OriginSettingClient client,\n+                                    IndexNameExpressionResolver indexNameExpressionResolver,\n+                                    ClusterService clusterService,\n+                                    ThreadPool threadPool) {\n+        this.resultsPersisterService = resultsPersisterService;\n+        this.client = client;\n+        this.indexNameExpressionResolver = indexNameExpressionResolver;\n+        this.threadPool = threadPool;\n+        this.statsQueue = new ConcurrentHashMap<>();\n+\n+        clusterService.addLifecycleListener(new LifecycleListener() {\n+            @Override\n+            public void beforeStart() {\n+                start();\n+            }\n+\n+            @Override\n+            public void beforeStop() {\n+                stop();\n+            }\n+        });\n+        clusterService.addListener((event) -> this.clusterState = event.state());\n+    }\n+\n+    public void queueStats(InferenceStats stats) {\n+        statsQueue.put(InferenceStats.docId(stats.getModelId(), stats.getNodeId()), stats);\n+    }\n+\n+    void stop() {\n+        stopped = true;\n+        statsQueue.clear();\n+\n+        ThreadPool.Cancellable cancellable = this.scheduledFuture;\n+        if (cancellable != null) {\n+            cancellable.cancel();\n+        }\n+    }\n+\n+    void start() {\n+        stopped = false;\n+        scheduledFuture = threadPool.scheduleWithFixedDelay(this::persistStats,\n+            TimeValue.timeValueSeconds(1),\n+            MachineLearning.UTILITY_THREAD_POOL_NAME);\n+    }\n+\n+    void persistStats() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6bf2263eaf42762dd92df701ee5a77ce099f6815"}, "originalPosition": 122}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bf4051a8a3d3a0537eba561997e22b448f623f31", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/bf4051a8a3d3a0537eba561997e22b448f623f31", "committedDate": "2020-03-31T11:45:42Z", "message": "Merge branch 'master' into feature/ml-inference-stats-collection"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0d6ba92c884398d97d4c004c4a684221748fdc50", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/0d6ba92c884398d97d4c004c4a684221748fdc50", "committedDate": "2020-03-31T15:04:54Z", "message": "addressing pr comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d2aecfaeaab36b7f2eba610ebfa54465cb8a3b41", "author": {"user": {"login": "elasticmachine", "name": "Elastic Machine"}}, "url": "https://github.com/elastic/elasticsearch/commit/d2aecfaeaab36b7f2eba610ebfa54465cb8a3b41", "committedDate": "2020-03-31T18:04:29Z", "message": "Merge branch 'master' into feature/ml-inference-stats-collection"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9faca62c3b6ffdf95106785b0568fe7c3f3efcb2", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/9faca62c3b6ffdf95106785b0568fe7c3f3efcb2", "committedDate": "2020-03-31T18:18:59Z", "message": "fixing style checks"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5b0cf39509e900762171fddb616fbc13a43d5492", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/5b0cf39509e900762171fddb616fbc13a43d5492", "committedDate": "2020-03-31T18:19:06Z", "message": "Merge branch 'feature/ml-inference-stats-collection' of github.com:benwtrent/elasticsearch into feature/ml-inference-stats-collection"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f5f2821b94dcc763fa884c11a127ecda82a3c885", "author": {"user": {"login": "elasticmachine", "name": "Elastic Machine"}}, "url": "https://github.com/elastic/elasticsearch/commit/f5f2821b94dcc763fa884c11a127ecda82a3c885", "committedDate": "2020-03-31T18:30:27Z", "message": "Merge branch 'master' into feature/ml-inference-stats-collection"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fe444885b7f8b906f1c093d7888f324b52eb127a", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/fe444885b7f8b906f1c093d7888f324b52eb127a", "committedDate": "2020-04-01T12:27:51Z", "message": "Update InferenceIngestIT.java"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "650947b4df331597595ce4ab1f553cd0e9ce484a", "author": {"user": {"login": "elasticmachine", "name": "Elastic Machine"}}, "url": "https://github.com/elastic/elasticsearch/commit/650947b4df331597595ce4ab1f553cd0e9ce484a", "committedDate": "2020-04-01T13:03:32Z", "message": "Merge branch 'master' into feature/ml-inference-stats-collection"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MzcyNjA1", "url": "https://github.com/elastic/elasticsearch/pull/53429#pullrequestreview-386372605", "createdAt": "2020-04-02T12:24:06Z", "commit": {"oid": "650947b4df331597595ce4ab1f553cd0e9ce484a"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjoyNDowN1rOF_ostQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNToyODoyOFrOF_w0Vw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI3MTQxMw==", "bodyText": "Can total_time_spent_millis be removed now?", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r402271413", "createdAt": "2020-04-02T12:24:07Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "diffHunk": "@@ -0,0 +1,184 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.inference;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkRequest;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.action.update.UpdateRequest;\n+import org.elasticsearch.client.OriginSettingClient;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.component.LifecycleListener;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.script.Script;\n+import org.elasticsearch.script.ScriptType;\n+import org.elasticsearch.threadpool.Scheduler;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ml.MlStatsIndex;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.InferenceStats;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.elasticsearch.xpack.ml.MachineLearning;\n+import org.elasticsearch.xpack.ml.utils.persistence.ResultsPersisterService;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+\n+\n+public class TrainedModelStatsService {\n+\n+    private static final Logger logger = LogManager.getLogger(TrainedModelStatsService.class);\n+\n+    // Script to only update if stats have increased since last persistence\n+    private static final String STATS_UPDATE_SCRIPT = \"\" +\n+        \"if (ctx._source.missing_all_fields_count >= params.missing_all_fields_count\\n\" +\n+        \"     && ctx._source.inference_count >= params.inference_count\\n\" +\n+        \"     && ctx._source.total_time_spent_millis >= params.total_time_spent_millis\\n\" +\n+        \"     && ctx._source.failure_count >= params.failure_count) {\\n\" +\n+        \"      ctx.op = 'none';\\n\" +\n+        \"      return;\\n\" +\n+        \"    }\\n\" +\n+        \"    ctx._source.missing_all_fields_count = params.missing_all_fields_count;\\n\" +\n+        \"    ctx._source.inference_count = params.inference_count;\\n\" +\n+        \"    ctx._source.total_time_spent_millis = params.total_time_spent_millis;\\n\" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "650947b4df331597595ce4ab1f553cd0e9ce484a"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI3MTkwNg==", "bodyText": "No longer required?", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r402271906", "createdAt": "2020-04-02T12:24:49Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/core/src/main/resources/org/elasticsearch/xpack/core/ml/stats_index_mappings.json", "diffHunk": "@@ -85,6 +85,24 @@\n       \"peak_usage_bytes\" : {\n         \"type\" : \"long\"\n       },\n+      \"model_id\": {\n+        \"type\": \"keyword\"\n+      },\n+      \"node_id\": {\n+        \"type\": \"keyword\"\n+      },\n+      \"inference_count\": {\n+        \"type\": \"long\"\n+      },\n+      \"total_time_spent_millis\": {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "650947b4df331597595ce4ab1f553cd0e9ce484a"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwNDQzOQ==", "bodyText": "I don't see how an update could be queued with at least one field having changed am I missing something?", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r402404439", "createdAt": "2020-04-02T15:28:28Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "diffHunk": "@@ -0,0 +1,184 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.inference;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkRequest;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.action.update.UpdateRequest;\n+import org.elasticsearch.client.OriginSettingClient;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.component.LifecycleListener;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.script.Script;\n+import org.elasticsearch.script.ScriptType;\n+import org.elasticsearch.threadpool.Scheduler;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ml.MlStatsIndex;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.InferenceStats;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.elasticsearch.xpack.ml.MachineLearning;\n+import org.elasticsearch.xpack.ml.utils.persistence.ResultsPersisterService;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+\n+\n+public class TrainedModelStatsService {\n+\n+    private static final Logger logger = LogManager.getLogger(TrainedModelStatsService.class);\n+\n+    // Script to only update if stats have increased since last persistence\n+    private static final String STATS_UPDATE_SCRIPT = \"\" +\n+        \"if (ctx._source.missing_all_fields_count >= params.missing_all_fields_count\\n\" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "650947b4df331597595ce4ab1f553cd0e9ce484a"}, "originalPosition": 51}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c2c1522c5c547cd080f1a9a72c3876ecff228661", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/c2c1522c5c547cd080f1a9a72c3876ecff228661", "committedDate": "2020-04-02T17:21:46Z", "message": "Merge branch 'master' into feature/ml-inference-stats-collection"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5f86f95ce011a667d509415a5fb3e5d3e627e698", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/5f86f95ce011a667d509415a5fb3e5d3e627e698", "committedDate": "2020-04-02T17:57:35Z", "message": "addressing PR comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg3MjM1NjIz", "url": "https://github.com/elastic/elasticsearch/pull/53429#pullrequestreview-387235623", "createdAt": "2020-04-03T13:04:39Z", "commit": {"oid": "5f86f95ce011a667d509415a5fb3e5d3e627e698"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0360c3b79da834b2ab01b3aff3cc3e2a4d38f812", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/0360c3b79da834b2ab01b3aff3cc3e2a4d38f812", "committedDate": "2020-04-03T14:00:51Z", "message": "incrementally updating stats instead of overwriting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8802fc40b67ab7236fb6a0447fe10b1aaa6dfaf8", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/8802fc40b67ab7236fb6a0447fe10b1aaa6dfaf8", "committedDate": "2020-04-03T14:02:40Z", "message": "Merge remote-tracking branch 'upstream/master' into feature/ml-inference-stats-collection"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0cca932fa83619e0f9f63cb8997d850d3d303e49", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/0cca932fa83619e0f9f63cb8997d850d3d303e49", "committedDate": "2020-04-03T14:11:48Z", "message": "fixing bwc serialization versions"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ff15e9726afda212a3d0c934c4d1d0a406e57477", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/ff15e9726afda212a3d0c934c4d1d0a406e57477", "committedDate": "2020-04-03T14:17:30Z", "message": "minor fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "74b95d54c952f8adccb8c1d8e51b29b1bbe0f14b", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/74b95d54c952f8adccb8c1d8e51b29b1bbe0f14b", "committedDate": "2020-04-03T14:54:27Z", "message": "handling situation where aggs are null"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg3MzQyNTIx", "url": "https://github.com/elastic/elasticsearch/pull/53429#pullrequestreview-387342521", "createdAt": "2020-04-03T15:08:07Z", "commit": {"oid": "0360c3b79da834b2ab01b3aff3cc3e2a4d38f812"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxNTowODowN1rOGAZoWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxNToxNjoxNVrOGAZ9LQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzA3MzExMw==", "bodyText": "Yikes! good catch", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r403073113", "createdAt": "2020-04-03T15:08:07Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "diffHunk": "@@ -97,7 +92,8 @@ public void beforeStop() {\n     }\n \n     public void queueStats(InferenceStats stats) {\n-        statsQueue.put(InferenceStats.docId(stats.getModelId(), stats.getNodeId()), stats);\n+        statsQueue.computeIfPresent(InferenceStats.docId(stats.getModelId(), stats.getNodeId()),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0360c3b79da834b2ab01b3aff3cc3e2a4d38f812"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzA3ODQ0NQ==", "bodyText": "\ud83d\udc4d", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r403078445", "createdAt": "2020-04-03T15:16:15Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/LocalModel.java", "diffHunk": "@@ -67,8 +70,9 @@ public String getModelId() {\n     }\n \n     @Override\n-    public InferenceStats getLatestStats() {\n-        return statsAccumulator.currentStats();\n+    public InferenceStats getLatestStatsAndReset() {\n+        InferenceStats.Accumulator toPersist = statsAccumulator.getAndSet(new InferenceStats.Accumulator(modelId, nodeId));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0360c3b79da834b2ab01b3aff3cc3e2a4d38f812"}, "originalPosition": 46}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1d7abd570cf67a0832654fff080c217b2e55fc4f", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/1d7abd570cf67a0832654fff080c217b2e55fc4f", "committedDate": "2020-04-03T15:53:48Z", "message": "fixing stats queueing"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1496, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}