{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM5OTc0NzA0", "number": 58536, "title": "EQL: Add Head/Tail pipe support", "bodyText": "Introduce pipe support, in particular head and tail\n(which can also be chained).\nReplaces #58326", "createdAt": "2020-06-25T12:02:45Z", "url": "https://github.com/elastic/elasticsearch/pull/58536", "merged": true, "mergeCommit": {"oid": "4521ca3367147d4d6531cf0ab975d8d705f400ea"}, "closed": true, "closedAt": "2020-06-27T06:08:04Z", "author": {"login": "costin"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcutZ4qAH2gAyNDM5OTc0NzA0OmM5MzBlM2Q4NzdhY2YxODk3NDRlYmQ0ZDk5ZDFjNjY5ZTliOTMxMDU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcvJfQ4gH2gAyNDM5OTc0NzA0OmY3ZDNlMWI2NWMzMTYwZGEzNGI5ZTVhYzQ2YjhiZTAzYjllZjA4MjQ=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "c930e3d877acf189744ebd4d99d1c669e9b93105", "author": {"user": {"login": "costin", "name": "Costin Leau"}}, "url": "https://github.com/elastic/elasticsearch/commit/c930e3d877acf189744ebd4d99d1c669e9b93105", "committedDate": "2020-06-25T12:00:36Z", "message": "EQL: Add Head/Tail pipe support\n\nIntroduce pipe support, in particular head and tail\n(which can also be chained)."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4551c7708f28344557271af07235be8bee57934b", "author": {"user": {"login": "costin", "name": "Costin Leau"}}, "url": "https://github.com/elastic/elasticsearch/commit/4551c7708f28344557271af07235be8bee57934b", "committedDate": "2020-06-25T17:58:32Z", "message": "Fix failing tests\n\nAdd Head and Tail to simplify verification and future identification of\nsaid nodes."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "86181b9c1911f695a0ee8aff447041e4e48089f0", "author": {"user": {"login": "costin", "name": "Costin Leau"}}, "url": "https://github.com/elastic/elasticsearch/commit/86181b9c1911f695a0ee8aff447041e4e48089f0", "committedDate": "2020-06-25T21:34:58Z", "message": "Update docs"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM3ODc3NjE3", "url": "https://github.com/elastic/elasticsearch/pull/58536#pullrequestreview-437877617", "createdAt": "2020-06-25T21:38:33Z", "commit": {"oid": "86181b9c1911f695a0ee8aff447041e4e48089f0"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQyMTozODozNFrOGpMugw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQyMTozODozNFrOGpMugw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg1MzMxNQ==", "bodyText": "@jrodewig is there a way to ignore the \"fields\" field? This data is used internally and it might be that in the future, we'll remove it from the final response (so only _source is included).", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r445853315", "createdAt": "2020-06-25T21:38:34Z", "author": {"login": "costin"}, "path": "docs/reference/eql/eql-search-api.asciidoc", "diffHunk": "@@ -534,7 +534,12 @@ in ascending order.\n         },\n         \"sort\": [\n           1607252647000\n-        ]\n+        ],\n+        \"fields\": {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "86181b9c1911f695a0ee8aff447041e4e48089f0"}, "originalPosition": 6}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259", "author": {"user": {"login": "costin", "name": "Costin Leau"}}, "url": "https://github.com/elastic/elasticsearch/commit/40ada655e5985a1a9bb8b32cfe42514dcc7c7259", "committedDate": "2020-06-25T21:44:11Z", "message": "fix checkstyle"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM4MDg0OTIy", "url": "https://github.com/elastic/elasticsearch/pull/58536#pullrequestreview-438084922", "createdAt": "2020-06-26T07:51:18Z", "commit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "state": "APPROVED", "comments": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQwNzo1MToxOVrOGpXOEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQwOTozNzozMFrOGpadZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAyNTIzNQ==", "bodyText": "Maybe name these with the plural variant, since they are arrays?", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446025235", "createdAt": "2020-06-26T07:51:19Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/assembler/Criterion.java", "diffHunk": "@@ -9,25 +9,35 @@\n import org.elasticsearch.search.SearchHit;\n import org.elasticsearch.search.builder.SearchSourceBuilder;\n import org.elasticsearch.xpack.eql.EqlIllegalArgumentException;\n+import org.elasticsearch.xpack.eql.execution.search.QueryRequest;\n import org.elasticsearch.xpack.ql.execution.search.extractor.HitExtractor;\n \n import java.util.List;\n \n-public class Criterion {\n+public class Criterion implements QueryRequest {\n \n     private final SearchSourceBuilder searchSource;\n     private final List<HitExtractor> keyExtractors;\n     private final HitExtractor timestampExtractor;\n     private final HitExtractor tiebreakerExtractor;\n \n+    // search after markers\n+    private Object[] startMarker;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAyOTg1OQ==", "bodyText": "Since the markers can only be a combination of timestamp and tiebreaker OR only the timestamp, maybe abstract these two variants away in a TiebreakerMarker and TimestampMarker or something around these lines?", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446029859", "createdAt": "2020-06-26T08:00:54Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/assembler/Criterion.java", "diffHunk": "@@ -64,8 +74,34 @@ public long timestamp(SearchHit hit) {\n         throw new EqlIllegalArgumentException(\"Expected tiebreaker to be Comparable but got {}\", tb);\n     }\n \n-    public void fromMarkers(Object[] markers) {\n-        // TODO: this is likely to be rewritten afterwards\n-        searchSource.searchAfter(markers);\n+    public Object[] startMarker() {\n+        return startMarker;\n+    }\n+\n+    public Object[] stopMarker() {\n+        return stopMarker;\n+    }\n+\n+    private Object[] marker(SearchHit hit) {\n+        long timestamp = timestamp(hit);\n+        Object tiebreaker = null;\n+        if (tiebreakerExtractor() != null) {\n+            tiebreaker = tiebreaker(hit);\n+        }\n+\n+        return tiebreaker != null ? new Object[] { timestamp, tiebreaker } : new Object[] { timestamp };", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA0NDQ3MQ==", "bodyText": "If the tiebreaker is not set, why still logging the square brackets?", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446044471", "createdAt": "2020-06-26T08:30:39Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/assembler/KeyAndOrdinal.java", "diffHunk": "@@ -18,4 +20,30 @@\n         this.timestamp = timestamp;\n         this.tiebreaker = tiebreaker;\n     }\n+\n+    @Override\n+    public int hashCode() {\n+        return Objects.hash(key, timestamp, tiebreaker);\n+    }\n+    \n+    @Override\n+    public boolean equals(Object obj) {\n+        if (this == obj) {\n+            return true;\n+        }\n+        \n+        if (obj == null || getClass() != obj.getClass()) {\n+            return false;\n+        }\n+        \n+        KeyAndOrdinal other = (KeyAndOrdinal) obj;\n+        return Objects.equals(key, other.key)\n+                && Objects.equals(timestamp, other.timestamp)\n+                && Objects.equals(tiebreaker, other.tiebreaker);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return key + \"[\" + timestamp + \"][\" + (tiebreaker != null ? Objects.toString(tiebreaker) : \"\") + \"]\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA0NzgyNg==", "bodyText": "while(iterator.hasNext())?", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446047826", "createdAt": "2020-06-26T08:37:04Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/assembler/SequenceRuntime.java", "diffHunk": "@@ -26,105 +31,103 @@\n  */\n class SequenceRuntime implements Executable {\n \n+    private final Logger log = LogManager.getLogger(SequenceRuntime.class);\n+\n     private final List<Criterion> criteria;\n     // NB: just like in a list, this represents the total number of stages yet counting starts at 0\n     private final int numberOfStages;\n     private final SequenceStateMachine stateMachine;\n     private final QueryClient queryClient;\n+    private final boolean descending;\n+\n     private long startTime;\n \n-    SequenceRuntime(List<Criterion> criteria, QueryClient queryClient) {\n+    SequenceRuntime(List<Criterion> criteria, QueryClient queryClient, boolean descending, Limit limit) {\n         this.criteria = criteria;\n         this.numberOfStages = criteria.size();\n         this.queryClient = queryClient;\n         boolean hasTiebreaker = criteria.get(0).tiebreakerExtractor() != null;\n-        this.stateMachine = new SequenceStateMachine(numberOfStages, hasTiebreaker);\n+        this.stateMachine = new SequenceStateMachine(numberOfStages, hasTiebreaker, limit);\n+\n+        this.descending = descending;\n     }\n \n     @Override\n-    public void execute(ActionListener<Results> resultsListener) {\n+    public void execute(ActionListener<Payload> listener) {\n         startTime = System.currentTimeMillis();\n-        startSequencing(resultsListener);\n-    }\n-\n-    private void startSequencing(ActionListener<Results> resultsListener) {\n-        Criterion firstStage = criteria.get(0);\n-        queryClient.query(firstStage.searchSource(), wrap(payload -> {\n-\n-            // 1. execute last stage (find keys)\n-            startTracking(payload, resultsListener);\n-\n-            // 2. go descending through the rest of the stages, while adjusting the query\n-            inspectStage(1, resultsListener);\n-\n-        }, resultsListener::onFailure));\n+        log.info(\"Starting sequencing\");\n+        queryStage(0, listener);\n     }\n \n-    private void startTracking(Payload<SearchHit> payload, ActionListener<Results> resultsListener) {\n-        Criterion lastCriterion = criteria.get(0);\n-        List<SearchHit> hits = payload.values();\n-\n-        // nothing matches the first query, bail out early\n-        if (hits.isEmpty()) {\n-            resultsListener.onResponse(assembleResults());\n-            return;\n-        }\n-        \n-        long tMin = Long.MAX_VALUE;\n-        long tMax = Long.MIN_VALUE;\n-        \n-        Comparable<Object> bMin = null;\n-        // we could have extracted that in the hit loop but that if would have been evaluated\n-        // for every document\n-        if (hits.isEmpty() == false) {\n-            tMin = lastCriterion.timestamp(hits.get(0));\n-            tMax = lastCriterion.timestamp(hits.get(hits.size() - 1));\n-            \n-            if (lastCriterion.tiebreakerExtractor() != null) {\n-               bMin = lastCriterion.tiebreaker(hits.get(0));\n-            }\n-        }\n-\n-        for (SearchHit hit : hits) {\n-            KeyAndOrdinal ko = findKey(hit, lastCriterion);\n-            Sequence seq = new Sequence(ko.key, numberOfStages, ko.timestamp, ko.tiebreaker, hit);\n-            stateMachine.trackSequence(seq, tMin, tMax);\n-        }\n-        stateMachine.setTimestampMarker(0, tMin);\n-        if (bMin != null) {\n-            stateMachine.setTiebreakerMarker(0, bMin);\n-        }\n-    }\n-\n-    private void inspectStage(int stage, ActionListener<Results> resultsListener) {\n+    private void queryStage(int stage, ActionListener<Payload> listener) {\n         // sequencing is done, return results\n-        if (stage == numberOfStages) {\n-            resultsListener.onResponse(assembleResults());\n+        if (hasFinished(stage)) {\n+            listener.onResponse(sequencePayload());\n             return;\n         }\n+\n         // else continue finding matches\n         Criterion currentCriterion = criteria.get(stage);\n-        // narrow by the previous stage timestamp marker\n-        currentCriterion.fromMarkers(stateMachine.getMarkers(stage - 1));\n+        if (stage > 0) {\n+            // FIXME: revisit this during pagination since the second criterion need to be limited to the range of the first one\n+            // narrow by the previous stage timestamp marker\n+\n+            Criterion previous = criteria.get(stage - 1);\n+            // if DESC, flip the markers (the stop becomes the start due to the reverse order), otherwise keep it accordingly\n+            Object[] marker = descending && stage == 1 ? previous.stopMarker() : previous.startMarker();\n+            currentCriterion.useMarker(marker);\n+        }\n         \n-        queryClient.query(currentCriterion.searchSource(), wrap(payload -> {\n-            findMatches(stage, payload);\n-            inspectStage(stage + 1, resultsListener);\n-        }, resultsListener::onFailure));\n+        log.info(\"Querying stage {}\", stage);\n+        queryClient.query(currentCriterion, wrap(payload -> {\n+            List<SearchHit> hits = payload.values();\n+\n+            // nothing matches the query -> bail out\n+            // FIXME: needs to be changed when doing pagination\n+            if (hits.isEmpty()) {\n+                listener.onResponse(sequencePayload());\n+                return;\n+            }\n+\n+            findMatches(stage, hits);\n+            queryStage(stage + 1, listener);\n+        }, listener::onFailure));\n     }\n \n-    private void findMatches(int currentStage, Payload<SearchHit> payload) {\n-        Criterion currentCriterion = criteria.get(currentStage);\n-        List<SearchHit> hits = payload.values();\n-        \n+    // hits are guaranteed to be non-empty\n+    private void findMatches(int currentStage, List<SearchHit> hits) {\n+        // update criterion\n+        Criterion criterion = criteria.get(currentStage);\n+        criterion.startMarker(hits.get(0));\n+        criterion.stopMarker(hits.get(hits.size() - 1));\n+\n         // break the results per key\n-        for (SearchHit hit : hits) {\n-            KeyAndOrdinal ko = findKey(hit, currentCriterion);\n-            stateMachine.match(currentStage, ko.key, ko.timestamp, ko.tiebreaker, hit);\n+        // when dealing with descending order, queries outside the base are ASC (search_before)\n+        // so look at the data in reverse (that is DESC)\n+        Iterator<SearchHit> iterator = descending ? new ReversedIterator<>(hits) : hits.iterator();\n+\n+        for (; iterator.hasNext();) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 174}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA0OTEyNA==", "bodyText": "Shouldn't this be an OR condition? Or am I missing something...", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446049124", "createdAt": "2020-06-26T08:39:44Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/assembler/SequenceRuntime.java", "diffHunk": "@@ -26,105 +31,103 @@\n  */\n class SequenceRuntime implements Executable {\n \n+    private final Logger log = LogManager.getLogger(SequenceRuntime.class);\n+\n     private final List<Criterion> criteria;\n     // NB: just like in a list, this represents the total number of stages yet counting starts at 0\n     private final int numberOfStages;\n     private final SequenceStateMachine stateMachine;\n     private final QueryClient queryClient;\n+    private final boolean descending;\n+\n     private long startTime;\n \n-    SequenceRuntime(List<Criterion> criteria, QueryClient queryClient) {\n+    SequenceRuntime(List<Criterion> criteria, QueryClient queryClient, boolean descending, Limit limit) {\n         this.criteria = criteria;\n         this.numberOfStages = criteria.size();\n         this.queryClient = queryClient;\n         boolean hasTiebreaker = criteria.get(0).tiebreakerExtractor() != null;\n-        this.stateMachine = new SequenceStateMachine(numberOfStages, hasTiebreaker);\n+        this.stateMachine = new SequenceStateMachine(numberOfStages, hasTiebreaker, limit);\n+\n+        this.descending = descending;\n     }\n \n     @Override\n-    public void execute(ActionListener<Results> resultsListener) {\n+    public void execute(ActionListener<Payload> listener) {\n         startTime = System.currentTimeMillis();\n-        startSequencing(resultsListener);\n-    }\n-\n-    private void startSequencing(ActionListener<Results> resultsListener) {\n-        Criterion firstStage = criteria.get(0);\n-        queryClient.query(firstStage.searchSource(), wrap(payload -> {\n-\n-            // 1. execute last stage (find keys)\n-            startTracking(payload, resultsListener);\n-\n-            // 2. go descending through the rest of the stages, while adjusting the query\n-            inspectStage(1, resultsListener);\n-\n-        }, resultsListener::onFailure));\n+        log.info(\"Starting sequencing\");\n+        queryStage(0, listener);\n     }\n \n-    private void startTracking(Payload<SearchHit> payload, ActionListener<Results> resultsListener) {\n-        Criterion lastCriterion = criteria.get(0);\n-        List<SearchHit> hits = payload.values();\n-\n-        // nothing matches the first query, bail out early\n-        if (hits.isEmpty()) {\n-            resultsListener.onResponse(assembleResults());\n-            return;\n-        }\n-        \n-        long tMin = Long.MAX_VALUE;\n-        long tMax = Long.MIN_VALUE;\n-        \n-        Comparable<Object> bMin = null;\n-        // we could have extracted that in the hit loop but that if would have been evaluated\n-        // for every document\n-        if (hits.isEmpty() == false) {\n-            tMin = lastCriterion.timestamp(hits.get(0));\n-            tMax = lastCriterion.timestamp(hits.get(hits.size() - 1));\n-            \n-            if (lastCriterion.tiebreakerExtractor() != null) {\n-               bMin = lastCriterion.tiebreaker(hits.get(0));\n-            }\n-        }\n-\n-        for (SearchHit hit : hits) {\n-            KeyAndOrdinal ko = findKey(hit, lastCriterion);\n-            Sequence seq = new Sequence(ko.key, numberOfStages, ko.timestamp, ko.tiebreaker, hit);\n-            stateMachine.trackSequence(seq, tMin, tMax);\n-        }\n-        stateMachine.setTimestampMarker(0, tMin);\n-        if (bMin != null) {\n-            stateMachine.setTiebreakerMarker(0, bMin);\n-        }\n-    }\n-\n-    private void inspectStage(int stage, ActionListener<Results> resultsListener) {\n+    private void queryStage(int stage, ActionListener<Payload> listener) {\n         // sequencing is done, return results\n-        if (stage == numberOfStages) {\n-            resultsListener.onResponse(assembleResults());\n+        if (hasFinished(stage)) {\n+            listener.onResponse(sequencePayload());\n             return;\n         }\n+\n         // else continue finding matches\n         Criterion currentCriterion = criteria.get(stage);\n-        // narrow by the previous stage timestamp marker\n-        currentCriterion.fromMarkers(stateMachine.getMarkers(stage - 1));\n+        if (stage > 0) {\n+            // FIXME: revisit this during pagination since the second criterion need to be limited to the range of the first one\n+            // narrow by the previous stage timestamp marker\n+\n+            Criterion previous = criteria.get(stage - 1);\n+            // if DESC, flip the markers (the stop becomes the start due to the reverse order), otherwise keep it accordingly\n+            Object[] marker = descending && stage == 1 ? previous.stopMarker() : previous.startMarker();\n+            currentCriterion.useMarker(marker);\n+        }\n         \n-        queryClient.query(currentCriterion.searchSource(), wrap(payload -> {\n-            findMatches(stage, payload);\n-            inspectStage(stage + 1, resultsListener);\n-        }, resultsListener::onFailure));\n+        log.info(\"Querying stage {}\", stage);\n+        queryClient.query(currentCriterion, wrap(payload -> {\n+            List<SearchHit> hits = payload.values();\n+\n+            // nothing matches the query -> bail out\n+            // FIXME: needs to be changed when doing pagination\n+            if (hits.isEmpty()) {\n+                listener.onResponse(sequencePayload());\n+                return;\n+            }\n+\n+            findMatches(stage, hits);\n+            queryStage(stage + 1, listener);\n+        }, listener::onFailure));\n     }\n \n-    private void findMatches(int currentStage, Payload<SearchHit> payload) {\n-        Criterion currentCriterion = criteria.get(currentStage);\n-        List<SearchHit> hits = payload.values();\n-        \n+    // hits are guaranteed to be non-empty\n+    private void findMatches(int currentStage, List<SearchHit> hits) {\n+        // update criterion\n+        Criterion criterion = criteria.get(currentStage);\n+        criterion.startMarker(hits.get(0));\n+        criterion.stopMarker(hits.get(hits.size() - 1));\n+\n         // break the results per key\n-        for (SearchHit hit : hits) {\n-            KeyAndOrdinal ko = findKey(hit, currentCriterion);\n-            stateMachine.match(currentStage, ko.key, ko.timestamp, ko.tiebreaker, hit);\n+        // when dealing with descending order, queries outside the base are ASC (search_before)\n+        // so look at the data in reverse (that is DESC)\n+        Iterator<SearchHit> iterator = descending ? new ReversedIterator<>(hits) : hits.iterator();\n+\n+        for (; iterator.hasNext();) {\n+            SearchHit hit = iterator.next();\n+\n+            // early skip in case of reaching the limit\n+            // check the last stage to avoid calling the state machine in other stages\n+            if (isLast(currentStage) && stateMachine.reachedLimit()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 179}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA1MjY2OQ==", "bodyText": "I find indexAsWildcard naming not reflecting what it actually does. Not sure where the wildcard comes from, I would name it commaDelimitedIndices or something similar.", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446052669", "createdAt": "2020-06-26T08:46:52Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/search/BasicQueryClient.java", "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.eql.execution.search;\n+\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.tasks.TaskCancelledException;\n+import org.elasticsearch.xpack.eql.session.EqlConfiguration;\n+import org.elasticsearch.xpack.eql.session.EqlSession;\n+import org.elasticsearch.xpack.eql.session.Payload;\n+import org.elasticsearch.xpack.ql.util.StringUtils;\n+\n+import static org.elasticsearch.xpack.eql.execution.search.RuntimeUtils.prepareRequest;\n+\n+public class BasicQueryClient implements QueryClient {\n+\n+    private static final Logger log = RuntimeUtils.QUERY_LOG;\n+\n+    private final EqlConfiguration cfg;\n+    private final Client client;\n+    private final String indices;\n+\n+    public BasicQueryClient(EqlSession eqlSession) {\n+        this.cfg = eqlSession.configuration();\n+        this.client = eqlSession.client();\n+        this.indices = cfg.indexAsWildcard();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA2MTAzNw==", "bodyText": "if (limit.child() instanceof LimitWithOffset == false) {\n   return limit;\n}", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446061037", "createdAt": "2020-06-26T09:03:17Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/optimizer/Optimizer.java", "diffHunk": "@@ -154,14 +174,168 @@ protected LogicalPlan rule(UnaryPlan plan) {\n             return plan;\n         }\n     }\n-    \n+\n+    static class SkipQueryOnLimitZero extends org.elasticsearch.xpack.ql.optimizer.OptimizerRules.SkipQueryOnLimitZero {\n+\n+        @Override\n+        protected LogicalPlan skipPlan(Limit limit) {\n+            return Optimizer.skipPlan(limit);\n+        }\n+    }\n+\n+    private static LogicalPlan skipPlan(UnaryPlan plan) {\n+        return new LocalRelation(plan.source(), plan.output());\n+    }\n+\n+    /**\n+     * Combine tail and head into one limit.\n+     * The rules moves up since the first limit is the one that defines whether it's the head (positive) or\n+     * the tail (negative) limit of the data and the rest simply work in this space.\n+     */\n+    static final class CombineLimits extends OptimizerRule<LimitWithOffset> {\n+\n+        CombineLimits() {\n+            super(TransformDirection.UP);\n+        }\n+\n+        @Override\n+        protected LogicalPlan rule(LimitWithOffset limit) {\n+            if (limit.child() instanceof LimitWithOffset) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA2NzQ5Mw==", "bodyText": "Leftover comment?", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446067493", "createdAt": "2020-06-26T09:16:11Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/optimizer/Optimizer.java", "diffHunk": "@@ -154,14 +174,168 @@ protected LogicalPlan rule(UnaryPlan plan) {\n             return plan;\n         }\n     }\n-    \n+\n+    static class SkipQueryOnLimitZero extends org.elasticsearch.xpack.ql.optimizer.OptimizerRules.SkipQueryOnLimitZero {\n+\n+        @Override\n+        protected LogicalPlan skipPlan(Limit limit) {\n+            return Optimizer.skipPlan(limit);\n+        }\n+    }\n+\n+    private static LogicalPlan skipPlan(UnaryPlan plan) {\n+        return new LocalRelation(plan.source(), plan.output());\n+    }\n+\n+    /**\n+     * Combine tail and head into one limit.\n+     * The rules moves up since the first limit is the one that defines whether it's the head (positive) or\n+     * the tail (negative) limit of the data and the rest simply work in this space.\n+     */\n+    static final class CombineLimits extends OptimizerRule<LimitWithOffset> {\n+\n+        CombineLimits() {\n+            super(TransformDirection.UP);\n+        }\n+\n+        @Override\n+        protected LogicalPlan rule(LimitWithOffset limit) {\n+            if (limit.child() instanceof LimitWithOffset) {\n+                LimitWithOffset primary = (LimitWithOffset) limit.child();\n+\n+                int primaryLimit = (Integer) primary.limit().fold();\n+                int primaryOffset = primary.offset();\n+                // +1 means ASC, -1 descending and 0 if there are no results\n+                int sign = Integer.signum(primaryLimit);\n+\n+                int secondaryLimit = (Integer) limit.limit().fold();\n+                if (limit.offset() != 0) {\n+                    throw new EqlIllegalArgumentException(\"Limits with different offset not implemented yet\");\n+                }\n+\n+                // for the same direction\n+                if (primaryLimit > 0 && secondaryLimit > 0) {\n+                    // consider the minimum\n+                    primaryLimit = Math.min(primaryLimit, secondaryLimit);\n+                } else if (primaryLimit < 0 && secondaryLimit < 0) {\n+                    primaryLimit = Math.max(primaryLimit, secondaryLimit);\n+                } else {\n+                    // the secondary limit cannot go beyond the primary - if it does it gets ignored\n+                    if (MathUtils.abs(secondaryLimit) < MathUtils.abs(primaryLimit)) {\n+                        primaryOffset += MathUtils.abs(primaryLimit + secondaryLimit);\n+                        // preserve order\n+                        primaryLimit = MathUtils.abs(secondaryLimit) * sign;\n+                    }\n+                }\n+\n+                Literal literal = new Literal(primary.limit().source(), primaryLimit, DataTypes.INTEGER);\n+                return new LimitWithOffset(primary.source(), literal, primaryOffset, primary.child());\n+            }\n+\n+            return limit;\n+        }\n+    }\n+\n+    /**\n+     * Align the implicit order with the limit (head means ASC or tail means DESC).\n+     */\n+    static final class SortByLimit extends OptimizerRule<LimitWithOffset> {\n+\n+        @Override\n+        protected LogicalPlan rule(LimitWithOffset limit) {\n+            // only care if the limit is negative (tail)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 167}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA2OTMzNw==", "bodyText": "?", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446069337", "createdAt": "2020-06-26T09:19:41Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/parser/LogicalPlanBuilder.java", "diffHunk": "@@ -262,4 +290,53 @@ public TimeValue visitSequenceParams(SequenceParamsContext ctx) {\n                     text(numberCtx));\n         }\n     }\n-}\n+\n+    private LogicalPlan pipe(PipeContext ctx, LogicalPlan plan) {\n+        String name = text(ctx.IDENTIFIER());\n+\n+        if (SUPPORTED_PIPES.contains(name) == false) {\n+            List<String> potentialMatches = StringUtils.findSimilar(name, SUPPORTED_PIPES);\n+            \n+            String msg = \"Unrecognized pipe [{}]\";\n+            if (potentialMatches.isEmpty() == false) {\n+                String matchString = potentialMatches.toString();\n+                msg += \", did you mean \" + (potentialMatches.size() == 1\n+                        ? matchString\n+                        : \"any of \" + matchString) + \"?\";\n+            }\n+            throw new ParsingException(source(ctx.IDENTIFIER()), msg, name);\n+        }\n+\n+        switch (name) {\n+            case \"head\":\n+                Expression headLimit = pipeIntArgument(source(ctx), name, ctx.booleanExpression());\n+                return new Head(source(ctx), headLimit, plan);\n+            //new LimitWithOffset(source(ctx), headLimit, 0, plan)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 179}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA3MTI3Nw==", "bodyText": "Where is the positive check taking place?", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446071277", "createdAt": "2020-06-26T09:23:20Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/parser/LogicalPlanBuilder.java", "diffHunk": "@@ -262,4 +290,53 @@ public TimeValue visitSequenceParams(SequenceParamsContext ctx) {\n                     text(numberCtx));\n         }\n     }\n-}\n+\n+    private LogicalPlan pipe(PipeContext ctx, LogicalPlan plan) {\n+        String name = text(ctx.IDENTIFIER());\n+\n+        if (SUPPORTED_PIPES.contains(name) == false) {\n+            List<String> potentialMatches = StringUtils.findSimilar(name, SUPPORTED_PIPES);\n+            \n+            String msg = \"Unrecognized pipe [{}]\";\n+            if (potentialMatches.isEmpty() == false) {\n+                String matchString = potentialMatches.toString();\n+                msg += \", did you mean \" + (potentialMatches.size() == 1\n+                        ? matchString\n+                        : \"any of \" + matchString) + \"?\";\n+            }\n+            throw new ParsingException(source(ctx.IDENTIFIER()), msg, name);\n+        }\n+\n+        switch (name) {\n+            case \"head\":\n+                Expression headLimit = pipeIntArgument(source(ctx), name, ctx.booleanExpression());\n+                return new Head(source(ctx), headLimit, plan);\n+            //new LimitWithOffset(source(ctx), headLimit, 0, plan)\n+\n+            case \"tail\":\n+                Expression tailLimit = pipeIntArgument(source(ctx), name, ctx.booleanExpression());\n+                // negate the limit\n+                return new Tail(source(ctx), tailLimit, plan);\n+            //return new LimitWithOffset(source(ctx), new Neg(tailLimit.source(), tailLimit), plan);\n+\n+            default:\n+                throw new ParsingException(source(ctx), \"Pipe [{}] is not supported yet\", name);\n+        }\n+    }\n+\n+    private Expression pipeIntArgument(Source source, String pipeName, List<BooleanExpressionContext> exps) {\n+        int size = CollectionUtils.isEmpty(exps) ? 0 : exps.size();\n+        if (size != 1) {\n+            throw new ParsingException(source, \"Pipe [{}] expects exactly one argument but found [{}]\", pipeName, size);\n+        }\n+        BooleanExpressionContext limitCtx = exps.get(0);\n+        Expression expression = expression(limitCtx);\n+\n+        if (expression.dataType().isInteger() == false || expression.foldable() == false) {\n+            throw new ParsingException(source(limitCtx), \"Pipe [{}] expects a positive integer but found [{}]\", pipeName, expression", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 201}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA3Mzc4MQ==", "bodyText": "Is this being used anywhere?", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446073781", "createdAt": "2020-06-26T09:28:12Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/planner/QueryFolder.java", "diffHunk": "@@ -139,4 +162,18 @@ public final PhysicalPlan apply(PhysicalPlan plan) {\n         @Override\n         protected abstract PhysicalPlan rule(SubPlan plan);\n     }\n-}\n+\n+    abstract static class QueryFoldingRule<SubPlan extends UnaryExec> extends FoldingRule<SubPlan> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA3ODMwOQ==", "bodyText": "Is the offset here 5 or 4?", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446078309", "createdAt": "2020-06-26T09:37:30Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/test/java/org/elasticsearch/xpack/eql/optimizer/OptimizerTests.java", "diffHunk": "@@ -175,4 +178,51 @@ public void testWildcardEscapes() {\n         assertEquals(like.pattern().asLuceneWildcard(), \"* %bar_ * \\\\\\\\ \\n \\r \\t\");\n         assertEquals(like.pattern().asIndexNameWildcard(), \"* %bar_ * \\\\ \\n \\r \\t\");\n     }\n+\n+    public void testCombineHeadBigHeadSmall() {\n+        checkOffsetAndLimit(accept(\"process where true | head 10 | head 1\"), 0, 1);\n+    }\n+\n+    public void testCombineHeadSmallHeadBig() {\n+        checkOffsetAndLimit(accept(\"process where true | head 1 | head 12\"), 0, 1);\n+    }\n+\n+    public void testCombineTailBigTailSmall() {\n+        checkOffsetAndLimit(accept(\"process where true | tail 10 | tail 1\"), 0, -1);\n+    }\n+\n+    public void testCombineTailSmallTailBig() {\n+        checkOffsetAndLimit(accept(\"process where true | tail 1 | tail 12\"), 0, -1);\n+    }\n+\n+    public void testCombineHeadBigTailSmall() {\n+        checkOffsetAndLimit(accept(\"process where true | head 10 | tail 7\"), 3, 7);\n+    }\n+\n+    public void testCombineTailBigHeadSmall() {\n+        checkOffsetAndLimit(accept(\"process where true | tail 10 | head 7\"), 3, -7);\n+    }\n+\n+    public void testCombineTailSmallHeadBig() {\n+        checkOffsetAndLimit(accept(\"process where true | tail 7 | head 10\"), 0, -7);\n+    }\n+\n+    public void testCombineHeadBigTailBig() {\n+        checkOffsetAndLimit(accept(\"process where true | head 1 | tail 7\"), 0, 1);\n+    }\n+\n+    public void testCombineHeadTailWithHeadAndTail() {\n+        checkOffsetAndLimit(accept(\"process where true | head 10 | tail 7 | head 5 | tail 3\"), 5, 3);\n+    }\n+\n+    public void testCombineTailHeadWithTailAndHead() {\n+        checkOffsetAndLimit(accept(\"process where true | tail 10 | head 7 | tail 5 | head 3\"), 5, -3);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 117}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM4MTkxMDIw", "url": "https://github.com/elastic/elasticsearch/pull/58536#pullrequestreview-438191020", "createdAt": "2020-06-26T10:35:37Z", "commit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMDozNTozN1rOGpcIFA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMjoxMTo0MFrOGpejbg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwNTYyMA==", "bodyText": "Myself, I wouldn't mind to have [] when there is no tiebreaker.", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446105620", "createdAt": "2020-06-26T10:35:37Z", "author": {"login": "matriv"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/assembler/KeyAndOrdinal.java", "diffHunk": "@@ -18,4 +20,30 @@\n         this.timestamp = timestamp;\n         this.tiebreaker = tiebreaker;\n     }\n+\n+    @Override\n+    public int hashCode() {\n+        return Objects.hash(key, timestamp, tiebreaker);\n+    }\n+    \n+    @Override\n+    public boolean equals(Object obj) {\n+        if (this == obj) {\n+            return true;\n+        }\n+        \n+        if (obj == null || getClass() != obj.getClass()) {\n+            return false;\n+        }\n+        \n+        KeyAndOrdinal other = (KeyAndOrdinal) obj;\n+        return Objects.equals(key, other.key)\n+                && Objects.equals(timestamp, other.timestamp)\n+                && Objects.equals(tiebreaker, other.tiebreaker);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return key + \"[\" + timestamp + \"][\" + (tiebreaker != null ? Objects.toString(tiebreaker) : \"\") + \"]\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA0NDQ3MQ=="}, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0NDA5Nw==", "bodyText": "also leftover here.", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446144097", "createdAt": "2020-06-26T12:08:43Z", "author": {"login": "matriv"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/parser/LogicalPlanBuilder.java", "diffHunk": "@@ -262,4 +290,53 @@ public TimeValue visitSequenceParams(SequenceParamsContext ctx) {\n                     text(numberCtx));\n         }\n     }\n-}\n+\n+    private LogicalPlan pipe(PipeContext ctx, LogicalPlan plan) {\n+        String name = text(ctx.IDENTIFIER());\n+\n+        if (SUPPORTED_PIPES.contains(name) == false) {\n+            List<String> potentialMatches = StringUtils.findSimilar(name, SUPPORTED_PIPES);\n+            \n+            String msg = \"Unrecognized pipe [{}]\";\n+            if (potentialMatches.isEmpty() == false) {\n+                String matchString = potentialMatches.toString();\n+                msg += \", did you mean \" + (potentialMatches.size() == 1\n+                        ? matchString\n+                        : \"any of \" + matchString) + \"?\";\n+            }\n+            throw new ParsingException(source(ctx.IDENTIFIER()), msg, name);\n+        }\n+\n+        switch (name) {\n+            case \"head\":\n+                Expression headLimit = pipeIntArgument(source(ctx), name, ctx.booleanExpression());\n+                return new Head(source(ctx), headLimit, plan);\n+            //new LimitWithOffset(source(ctx), headLimit, 0, plan)\n+\n+            case \"tail\":\n+                Expression tailLimit = pipeIntArgument(source(ctx), name, ctx.booleanExpression());\n+                // negate the limit\n+                return new Tail(source(ctx), tailLimit, plan);\n+            //return new LimitWithOffset(source(ctx), new Neg(tailLimit.source(), tailLimit), plan);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 185}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0NTA0MQ==", "bodyText": "Minor: code formatting for consistency:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                    Attribute tiebreaker, OrderDirection direction) {\n          \n          \n            \n                                    Attribute tiebreaker, \n          \n          \n            \n                                    OrderDirection direction) {", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446145041", "createdAt": "2020-06-26T12:10:47Z", "author": {"login": "matriv"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/plan/physical/SequenceExec.java", "diffHunk": "@@ -29,27 +31,37 @@\n     private final List<List<Attribute>> keys;\n     private final Attribute timestamp;\n     private final Attribute tiebreaker;\n+    private final Limit limit;\n+    private final OrderDirection direction;\n \n     public SequenceExec(Source source,\n                         List<List<Attribute>> keys,\n                         List<PhysicalPlan> matches,\n                         List<Attribute> untilKeys,\n                         PhysicalPlan until,\n                         Attribute timestamp,\n-                        Attribute tiebreaker) {\n-        this(source, combine(matches, until), combine(keys, singletonList(untilKeys)), timestamp, tiebreaker);\n+                        Attribute tiebreaker, OrderDirection direction) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0NTM5MA==", "bodyText": "minor: empty line", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446145390", "createdAt": "2020-06-26T12:11:40Z", "author": {"login": "matriv"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/querydsl/container/QueryContainer.java", "diffHunk": "@@ -45,18 +46,27 @@\n     private final boolean trackHits;\n     private final boolean includeFrozen;\n \n+    private final Limit limit;\n+\n     public QueryContainer() {\n-        this(null, emptyList(), AttributeMap.emptyAttributeMap(), emptyMap(), false, false);\n+        this(null, emptyList(), AttributeMap.emptyAttributeMap(), emptyMap(), false, false, null);\n     }\n \n-    private QueryContainer(Query query, List<Tuple<FieldExtraction, String>> fields, AttributeMap<Expression> attributes,\n-                           Map<String, Sort> sort, boolean trackHits, boolean includeFrozen) {\n+    private QueryContainer(Query query,\n+                           List<Tuple<FieldExtraction, String>> fields,\n+                           AttributeMap<Expression> attributes,\n+                           Map<String, Sort> sort,\n+                           boolean trackHits,\n+                           boolean includeFrozen,\n+                           Limit limit) {\n         this.query = query;\n         this.fields = fields;\n         this.sort = sort;\n         this.attributes = attributes;\n         this.trackHits = trackHits;\n         this.includeFrozen = includeFrozen;\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 34}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f7d3e1b65c3160da34b9e5ac46b8be03b9ef0824", "author": {"user": {"login": "costin", "name": "Costin Leau"}}, "url": "https://github.com/elastic/elasticsearch/commit/f7d3e1b65c3160da34b9e5ac46b8be03b9ef0824", "committedDate": "2020-06-26T20:43:49Z", "message": "Address feedback"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2623, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}