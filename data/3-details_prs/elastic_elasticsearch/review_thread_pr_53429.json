{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg2ODY3MDU1", "number": 53429, "reviewThreads": {"totalCount": 25, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxOTowOTowNFrODnNfFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxNToxNjoxNVrODua9JQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyNDQyMDA3OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/ModelLoadingService.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxOTowOTowNVrOF1E_Xw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxOTowOTowNVrOF1E_Xw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTIwMDYwNw==", "bodyText": "We might actually want to fail completely if the unwrapped error is anything other than a ResourceNotFound. If .ml-stats-* exists but has unallocated primary shards, we may want to bail.", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r391200607", "createdAt": "2020-03-11T19:09:05Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/ModelLoadingService.java", "diffHunk": "@@ -336,11 +351,22 @@ private void loadModels(Set<String> modelIds) {\n         threadPool.executor(MachineLearning.UTILITY_THREAD_POOL_NAME).execute(() -> {\n             for (String modelId : modelIds) {\n                 auditNewReferencedModel(modelId);\n-                this.loadModel(modelId);\n+                loadStatsAndModel(modelId);\n             }\n         });\n     }\n \n+    private void loadStatsAndModel(String modelId) {\n+        this.provider.getInferenceStats(modelId,\n+            localNode,\n+            ActionListener.wrap(\n+                r -> this.loadModel(modelId, r),\n+                e -> {\n+                    logger.error(\"[{}] failed to get previous model stats\", modelId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ee4868652ec579425ff84d2efa0c77ed1521608d"}, "originalPosition": 199}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0Nzg0MjMxOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/action/GetTrainedModelsStatsAction.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxMDoxMjowOVrOF4n2pw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxMDoxMjowOVrOF4n2pw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDkxNzU0Mw==", "bodyText": "Typo Inferece in function name and param", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r394917543", "createdAt": "2020-03-19T10:12:09Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/action/GetTrainedModelsStatsAction.java", "diffHunk": "@@ -191,13 +209,23 @@ public Builder setIngestStatsByModelId(Map<String, IngestStats> ingestStatsByMod\n                 return this;\n             }\n \n+            public Builder setInfereceStatsByModelId(Map<String, InferenceStats> infereceStatsByModelId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 106}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0Nzg1NjUxOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/InferenceStats.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxMDoxNjowNVrOF4n_uw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxMDoxNjowNVrOF4n_uw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDkxOTg2Nw==", "bodyText": "Just this one is private? I'd make it public just so the fields line up", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r394919867", "createdAt": "2020-03-19T10:16:05Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/InferenceStats.java", "diffHunk": "@@ -0,0 +1,268 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.inference.trainedmodel;\n+\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+import java.util.concurrent.atomic.LongAdder;\n+\n+public class InferenceStats implements ToXContentObject, Writeable {\n+\n+    public static final String NAME = \"inference_stats\";\n+    public static final ParseField MISSING_ALL_FIELDS_COUNT = new ParseField(\"missing_all_fields_count\");\n+    public static final ParseField INFERENCE_COUNT = new ParseField(\"inference_count\");\n+    public static final ParseField MODEL_ID = new ParseField(\"model_id\");\n+    public static final ParseField NODE_ID = new ParseField(\"node_id\");\n+    public static final ParseField TOTAL_TIME_SPENT_MILLIS = new ParseField(\"total_time_spent_millis\");\n+    private static final ParseField TOTAL_TIME_SPENT = new ParseField(\"total_time_spent\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0ODQ3NzU4OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/InferenceStats.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxMzoyNDoyOVrOF4uLxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxMzoyNDoyOVrOF4uLxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTAyMTI1Mg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        instant == null ? Instant.now() : Instant.ofEpochMilli(instant.toEpochMilli()));\n          \n          \n            \n                        instant);\n          \n      \n    \n    \n  \n\nThe public ctor has the null check", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395021252", "createdAt": "2020-03-19T13:24:29Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/InferenceStats.java", "diffHunk": "@@ -0,0 +1,268 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.inference.trainedmodel;\n+\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+import java.util.concurrent.atomic.LongAdder;\n+\n+public class InferenceStats implements ToXContentObject, Writeable {\n+\n+    public static final String NAME = \"inference_stats\";\n+    public static final ParseField MISSING_ALL_FIELDS_COUNT = new ParseField(\"missing_all_fields_count\");\n+    public static final ParseField INFERENCE_COUNT = new ParseField(\"inference_count\");\n+    public static final ParseField MODEL_ID = new ParseField(\"model_id\");\n+    public static final ParseField NODE_ID = new ParseField(\"node_id\");\n+    public static final ParseField TOTAL_TIME_SPENT_MILLIS = new ParseField(\"total_time_spent_millis\");\n+    private static final ParseField TOTAL_TIME_SPENT = new ParseField(\"total_time_spent\");\n+    public static final ParseField FAILURE_COUNT = new ParseField(\"failure_count\");\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"time_stamp\");\n+\n+    public static final ConstructingObjectParser<InferenceStats, Void> PARSER = new ConstructingObjectParser<>(\n+        NAME,\n+        true,\n+        a -> new InferenceStats((Long)a[0], (Long)a[1], (Long)a[2], (Long)a[3], (String)a[4], (String)a[5], (Instant) a[6])\n+    );\n+    static {\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), MISSING_ALL_FIELDS_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), INFERENCE_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), TOTAL_TIME_SPENT_MILLIS);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), FAILURE_COUNT);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), MODEL_ID);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), NODE_ID);\n+        PARSER.declareField(ConstructingObjectParser.constructorArg(),\n+            p -> TimeUtils.parseTimeFieldToInstant(p, TIMESTAMP.getPreferredName()),\n+            TIMESTAMP,\n+            ObjectParser.ValueType.VALUE);\n+    }\n+    public static InferenceStats emptyStats(String modelId, String nodeId) {\n+        return new InferenceStats(0L, 0L, 0L, 0L, modelId, nodeId, Instant.now());\n+    }\n+\n+    public static String docId(String modelId, String nodeId) {\n+        return NAME + \"-\" + modelId + \"-\" + nodeId;\n+    }\n+\n+    private final long missingAllFieldsCount;\n+    private final long inferenceCount;\n+    private final long totalTimeSpent;\n+    private final long failureCount;\n+    private final String modelId;\n+    private final String nodeId;\n+    private final Instant timeStamp;\n+\n+    private InferenceStats(Long missingAllFieldsCount,\n+                           Long inferenceCount,\n+                           Long totalTimeSpent,\n+                           Long failureCount,\n+                           String modelId,\n+                           String nodeId,\n+                           Instant instant) {\n+        this(unbox(missingAllFieldsCount),\n+            unbox(inferenceCount),\n+            unbox(totalTimeSpent),\n+            unbox(failureCount),\n+            modelId,\n+            nodeId,\n+            instant == null ? Instant.now() : Instant.ofEpochMilli(instant.toEpochMilli()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 86}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0ODQ5Mjg4OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/InferenceStats.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxMzoyODoyNFrOF4uVlg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNDozNjozMlrOF5WT1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTAyMzc2Ng==", "bodyText": "Does converting to epoch then back to Instant serve a purpose?", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395023766", "createdAt": "2020-03-19T13:28:24Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/InferenceStats.java", "diffHunk": "@@ -0,0 +1,268 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.inference.trainedmodel;\n+\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+import java.util.concurrent.atomic.LongAdder;\n+\n+public class InferenceStats implements ToXContentObject, Writeable {\n+\n+    public static final String NAME = \"inference_stats\";\n+    public static final ParseField MISSING_ALL_FIELDS_COUNT = new ParseField(\"missing_all_fields_count\");\n+    public static final ParseField INFERENCE_COUNT = new ParseField(\"inference_count\");\n+    public static final ParseField MODEL_ID = new ParseField(\"model_id\");\n+    public static final ParseField NODE_ID = new ParseField(\"node_id\");\n+    public static final ParseField TOTAL_TIME_SPENT_MILLIS = new ParseField(\"total_time_spent_millis\");\n+    private static final ParseField TOTAL_TIME_SPENT = new ParseField(\"total_time_spent\");\n+    public static final ParseField FAILURE_COUNT = new ParseField(\"failure_count\");\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"time_stamp\");\n+\n+    public static final ConstructingObjectParser<InferenceStats, Void> PARSER = new ConstructingObjectParser<>(\n+        NAME,\n+        true,\n+        a -> new InferenceStats((Long)a[0], (Long)a[1], (Long)a[2], (Long)a[3], (String)a[4], (String)a[5], (Instant) a[6])\n+    );\n+    static {\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), MISSING_ALL_FIELDS_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), INFERENCE_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), TOTAL_TIME_SPENT_MILLIS);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), FAILURE_COUNT);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), MODEL_ID);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), NODE_ID);\n+        PARSER.declareField(ConstructingObjectParser.constructorArg(),\n+            p -> TimeUtils.parseTimeFieldToInstant(p, TIMESTAMP.getPreferredName()),\n+            TIMESTAMP,\n+            ObjectParser.ValueType.VALUE);\n+    }\n+    public static InferenceStats emptyStats(String modelId, String nodeId) {\n+        return new InferenceStats(0L, 0L, 0L, 0L, modelId, nodeId, Instant.now());\n+    }\n+\n+    public static String docId(String modelId, String nodeId) {\n+        return NAME + \"-\" + modelId + \"-\" + nodeId;\n+    }\n+\n+    private final long missingAllFieldsCount;\n+    private final long inferenceCount;\n+    private final long totalTimeSpent;\n+    private final long failureCount;\n+    private final String modelId;\n+    private final String nodeId;\n+    private final Instant timeStamp;\n+\n+    private InferenceStats(Long missingAllFieldsCount,\n+                           Long inferenceCount,\n+                           Long totalTimeSpent,\n+                           Long failureCount,\n+                           String modelId,\n+                           String nodeId,\n+                           Instant instant) {\n+        this(unbox(missingAllFieldsCount),\n+            unbox(inferenceCount),\n+            unbox(totalTimeSpent),\n+            unbox(failureCount),\n+            modelId,\n+            nodeId,\n+            instant == null ? Instant.now() : Instant.ofEpochMilli(instant.toEpochMilli()));\n+    }\n+\n+\n+    public InferenceStats(long missingAllFieldsCount,\n+                          long inferenceCount,\n+                          long totalTimeSpent,\n+                          long failureCount,\n+                          String modelId,\n+                          String nodeId,\n+                          Instant timeStamp) {\n+        this.missingAllFieldsCount = missingAllFieldsCount;\n+        this.inferenceCount = inferenceCount;\n+        this.totalTimeSpent = totalTimeSpent;\n+        this.failureCount = failureCount;\n+        this.modelId = modelId;\n+        this.nodeId = nodeId;\n+        this.timeStamp = timeStamp == null ?\n+            Instant.ofEpochMilli(Instant.now().toEpochMilli()) :\n+            Instant.ofEpochMilli(timeStamp.toEpochMilli());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTIyNzc4MA==", "bodyText": "It's because the convention is for the XContent representation to be at millisecond accuracy and it's painful if the internal representation is more accurate.  As I said in #52778 (comment) I think it's worth adding a comment to say this.  We used to have about 3 different ways of solving this problem but now we're standardising on rounding in the constructor.", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395227780", "createdAt": "2020-03-19T18:15:56Z", "author": {"login": "droberts195"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/InferenceStats.java", "diffHunk": "@@ -0,0 +1,268 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.inference.trainedmodel;\n+\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+import java.util.concurrent.atomic.LongAdder;\n+\n+public class InferenceStats implements ToXContentObject, Writeable {\n+\n+    public static final String NAME = \"inference_stats\";\n+    public static final ParseField MISSING_ALL_FIELDS_COUNT = new ParseField(\"missing_all_fields_count\");\n+    public static final ParseField INFERENCE_COUNT = new ParseField(\"inference_count\");\n+    public static final ParseField MODEL_ID = new ParseField(\"model_id\");\n+    public static final ParseField NODE_ID = new ParseField(\"node_id\");\n+    public static final ParseField TOTAL_TIME_SPENT_MILLIS = new ParseField(\"total_time_spent_millis\");\n+    private static final ParseField TOTAL_TIME_SPENT = new ParseField(\"total_time_spent\");\n+    public static final ParseField FAILURE_COUNT = new ParseField(\"failure_count\");\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"time_stamp\");\n+\n+    public static final ConstructingObjectParser<InferenceStats, Void> PARSER = new ConstructingObjectParser<>(\n+        NAME,\n+        true,\n+        a -> new InferenceStats((Long)a[0], (Long)a[1], (Long)a[2], (Long)a[3], (String)a[4], (String)a[5], (Instant) a[6])\n+    );\n+    static {\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), MISSING_ALL_FIELDS_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), INFERENCE_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), TOTAL_TIME_SPENT_MILLIS);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), FAILURE_COUNT);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), MODEL_ID);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), NODE_ID);\n+        PARSER.declareField(ConstructingObjectParser.constructorArg(),\n+            p -> TimeUtils.parseTimeFieldToInstant(p, TIMESTAMP.getPreferredName()),\n+            TIMESTAMP,\n+            ObjectParser.ValueType.VALUE);\n+    }\n+    public static InferenceStats emptyStats(String modelId, String nodeId) {\n+        return new InferenceStats(0L, 0L, 0L, 0L, modelId, nodeId, Instant.now());\n+    }\n+\n+    public static String docId(String modelId, String nodeId) {\n+        return NAME + \"-\" + modelId + \"-\" + nodeId;\n+    }\n+\n+    private final long missingAllFieldsCount;\n+    private final long inferenceCount;\n+    private final long totalTimeSpent;\n+    private final long failureCount;\n+    private final String modelId;\n+    private final String nodeId;\n+    private final Instant timeStamp;\n+\n+    private InferenceStats(Long missingAllFieldsCount,\n+                           Long inferenceCount,\n+                           Long totalTimeSpent,\n+                           Long failureCount,\n+                           String modelId,\n+                           String nodeId,\n+                           Instant instant) {\n+        this(unbox(missingAllFieldsCount),\n+            unbox(inferenceCount),\n+            unbox(totalTimeSpent),\n+            unbox(failureCount),\n+            modelId,\n+            nodeId,\n+            instant == null ? Instant.now() : Instant.ofEpochMilli(instant.toEpochMilli()));\n+    }\n+\n+\n+    public InferenceStats(long missingAllFieldsCount,\n+                          long inferenceCount,\n+                          long totalTimeSpent,\n+                          long failureCount,\n+                          String modelId,\n+                          String nodeId,\n+                          Instant timeStamp) {\n+        this.missingAllFieldsCount = missingAllFieldsCount;\n+        this.inferenceCount = inferenceCount;\n+        this.totalTimeSpent = totalTimeSpent;\n+        this.failureCount = failureCount;\n+        this.modelId = modelId;\n+        this.nodeId = nodeId;\n+        this.timeStamp = timeStamp == null ?\n+            Instant.ofEpochMilli(Instant.now().toEpochMilli()) :\n+            Instant.ofEpochMilli(timeStamp.toEpochMilli());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTAyMzc2Ng=="}, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY3ODY3Nw==", "bodyText": "Rounding in the ctor is the standard way. I will remove the rounding from the stream input :)", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395678677", "createdAt": "2020-03-20T14:36:32Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/InferenceStats.java", "diffHunk": "@@ -0,0 +1,268 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.inference.trainedmodel;\n+\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+import java.util.concurrent.atomic.LongAdder;\n+\n+public class InferenceStats implements ToXContentObject, Writeable {\n+\n+    public static final String NAME = \"inference_stats\";\n+    public static final ParseField MISSING_ALL_FIELDS_COUNT = new ParseField(\"missing_all_fields_count\");\n+    public static final ParseField INFERENCE_COUNT = new ParseField(\"inference_count\");\n+    public static final ParseField MODEL_ID = new ParseField(\"model_id\");\n+    public static final ParseField NODE_ID = new ParseField(\"node_id\");\n+    public static final ParseField TOTAL_TIME_SPENT_MILLIS = new ParseField(\"total_time_spent_millis\");\n+    private static final ParseField TOTAL_TIME_SPENT = new ParseField(\"total_time_spent\");\n+    public static final ParseField FAILURE_COUNT = new ParseField(\"failure_count\");\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"time_stamp\");\n+\n+    public static final ConstructingObjectParser<InferenceStats, Void> PARSER = new ConstructingObjectParser<>(\n+        NAME,\n+        true,\n+        a -> new InferenceStats((Long)a[0], (Long)a[1], (Long)a[2], (Long)a[3], (String)a[4], (String)a[5], (Instant) a[6])\n+    );\n+    static {\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), MISSING_ALL_FIELDS_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), INFERENCE_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), TOTAL_TIME_SPENT_MILLIS);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), FAILURE_COUNT);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), MODEL_ID);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), NODE_ID);\n+        PARSER.declareField(ConstructingObjectParser.constructorArg(),\n+            p -> TimeUtils.parseTimeFieldToInstant(p, TIMESTAMP.getPreferredName()),\n+            TIMESTAMP,\n+            ObjectParser.ValueType.VALUE);\n+    }\n+    public static InferenceStats emptyStats(String modelId, String nodeId) {\n+        return new InferenceStats(0L, 0L, 0L, 0L, modelId, nodeId, Instant.now());\n+    }\n+\n+    public static String docId(String modelId, String nodeId) {\n+        return NAME + \"-\" + modelId + \"-\" + nodeId;\n+    }\n+\n+    private final long missingAllFieldsCount;\n+    private final long inferenceCount;\n+    private final long totalTimeSpent;\n+    private final long failureCount;\n+    private final String modelId;\n+    private final String nodeId;\n+    private final Instant timeStamp;\n+\n+    private InferenceStats(Long missingAllFieldsCount,\n+                           Long inferenceCount,\n+                           Long totalTimeSpent,\n+                           Long failureCount,\n+                           String modelId,\n+                           String nodeId,\n+                           Instant instant) {\n+        this(unbox(missingAllFieldsCount),\n+            unbox(inferenceCount),\n+            unbox(totalTimeSpent),\n+            unbox(failureCount),\n+            modelId,\n+            nodeId,\n+            instant == null ? Instant.now() : Instant.ofEpochMilli(instant.toEpochMilli()));\n+    }\n+\n+\n+    public InferenceStats(long missingAllFieldsCount,\n+                          long inferenceCount,\n+                          long totalTimeSpent,\n+                          long failureCount,\n+                          String modelId,\n+                          String nodeId,\n+                          Instant timeStamp) {\n+        this.missingAllFieldsCount = missingAllFieldsCount;\n+        this.inferenceCount = inferenceCount;\n+        this.totalTimeSpent = totalTimeSpent;\n+        this.failureCount = failureCount;\n+        this.modelId = modelId;\n+        this.nodeId = nodeId;\n+        this.timeStamp = timeStamp == null ?\n+            Instant.ofEpochMilli(Instant.now().toEpochMilli()) :\n+            Instant.ofEpochMilli(timeStamp.toEpochMilli());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTAyMzc2Ng=="}, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 105}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0ODUxNDkwOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/InferenceStats.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxMzozMzo1NVrOF4uj2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNDozNjo1MVrOF5WUzg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTAyNzQxNw==", "bodyText": "Oh is it to trim the nanoseconds? Is that because of a failing equality check?", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395027417", "createdAt": "2020-03-19T13:33:55Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/InferenceStats.java", "diffHunk": "@@ -0,0 +1,268 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.inference.trainedmodel;\n+\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+import java.util.concurrent.atomic.LongAdder;\n+\n+public class InferenceStats implements ToXContentObject, Writeable {\n+\n+    public static final String NAME = \"inference_stats\";\n+    public static final ParseField MISSING_ALL_FIELDS_COUNT = new ParseField(\"missing_all_fields_count\");\n+    public static final ParseField INFERENCE_COUNT = new ParseField(\"inference_count\");\n+    public static final ParseField MODEL_ID = new ParseField(\"model_id\");\n+    public static final ParseField NODE_ID = new ParseField(\"node_id\");\n+    public static final ParseField TOTAL_TIME_SPENT_MILLIS = new ParseField(\"total_time_spent_millis\");\n+    private static final ParseField TOTAL_TIME_SPENT = new ParseField(\"total_time_spent\");\n+    public static final ParseField FAILURE_COUNT = new ParseField(\"failure_count\");\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"time_stamp\");\n+\n+    public static final ConstructingObjectParser<InferenceStats, Void> PARSER = new ConstructingObjectParser<>(\n+        NAME,\n+        true,\n+        a -> new InferenceStats((Long)a[0], (Long)a[1], (Long)a[2], (Long)a[3], (String)a[4], (String)a[5], (Instant) a[6])\n+    );\n+    static {\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), MISSING_ALL_FIELDS_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), INFERENCE_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), TOTAL_TIME_SPENT_MILLIS);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), FAILURE_COUNT);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), MODEL_ID);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), NODE_ID);\n+        PARSER.declareField(ConstructingObjectParser.constructorArg(),\n+            p -> TimeUtils.parseTimeFieldToInstant(p, TIMESTAMP.getPreferredName()),\n+            TIMESTAMP,\n+            ObjectParser.ValueType.VALUE);\n+    }\n+    public static InferenceStats emptyStats(String modelId, String nodeId) {\n+        return new InferenceStats(0L, 0L, 0L, 0L, modelId, nodeId, Instant.now());\n+    }\n+\n+    public static String docId(String modelId, String nodeId) {\n+        return NAME + \"-\" + modelId + \"-\" + nodeId;\n+    }\n+\n+    private final long missingAllFieldsCount;\n+    private final long inferenceCount;\n+    private final long totalTimeSpent;\n+    private final long failureCount;\n+    private final String modelId;\n+    private final String nodeId;\n+    private final Instant timeStamp;\n+\n+    private InferenceStats(Long missingAllFieldsCount,\n+                           Long inferenceCount,\n+                           Long totalTimeSpent,\n+                           Long failureCount,\n+                           String modelId,\n+                           String nodeId,\n+                           Instant instant) {\n+        this(unbox(missingAllFieldsCount),\n+            unbox(inferenceCount),\n+            unbox(totalTimeSpent),\n+            unbox(failureCount),\n+            modelId,\n+            nodeId,\n+            instant == null ? Instant.now() : Instant.ofEpochMilli(instant.toEpochMilli()));\n+    }\n+\n+\n+    public InferenceStats(long missingAllFieldsCount,\n+                          long inferenceCount,\n+                          long totalTimeSpent,\n+                          long failureCount,\n+                          String modelId,\n+                          String nodeId,\n+                          Instant timeStamp) {\n+        this.missingAllFieldsCount = missingAllFieldsCount;\n+        this.inferenceCount = inferenceCount;\n+        this.totalTimeSpent = totalTimeSpent;\n+        this.failureCount = failureCount;\n+        this.modelId = modelId;\n+        this.nodeId = nodeId;\n+        this.timeStamp = timeStamp == null ?\n+            Instant.ofEpochMilli(Instant.now().toEpochMilli()) :\n+            Instant.ofEpochMilli(timeStamp.toEpochMilli());\n+    }\n+\n+    public InferenceStats(StreamInput in) throws IOException {\n+        this.missingAllFieldsCount = in.readVLong();\n+        this.inferenceCount = in.readVLong();\n+        this.totalTimeSpent = in.readVLong();\n+        this.failureCount = in.readVLong();\n+        this.modelId = in.readOptionalString();\n+        this.nodeId = in.readOptionalString();\n+        this.timeStamp = Instant.ofEpochMilli(in.readInstant().toEpochMilli());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTIyODgzOA==", "bodyText": "We haven't rounded when receiving off the wire in other places, for example https://github.com/elastic/elasticsearch/pull/52778/files#diff-e7461e3bf8c7e61722aecccd3d4c3a99R65.  There shouldn't be any need if we've always rounded in the other constructors.", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395228838", "createdAt": "2020-03-19T18:17:47Z", "author": {"login": "droberts195"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/InferenceStats.java", "diffHunk": "@@ -0,0 +1,268 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.inference.trainedmodel;\n+\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+import java.util.concurrent.atomic.LongAdder;\n+\n+public class InferenceStats implements ToXContentObject, Writeable {\n+\n+    public static final String NAME = \"inference_stats\";\n+    public static final ParseField MISSING_ALL_FIELDS_COUNT = new ParseField(\"missing_all_fields_count\");\n+    public static final ParseField INFERENCE_COUNT = new ParseField(\"inference_count\");\n+    public static final ParseField MODEL_ID = new ParseField(\"model_id\");\n+    public static final ParseField NODE_ID = new ParseField(\"node_id\");\n+    public static final ParseField TOTAL_TIME_SPENT_MILLIS = new ParseField(\"total_time_spent_millis\");\n+    private static final ParseField TOTAL_TIME_SPENT = new ParseField(\"total_time_spent\");\n+    public static final ParseField FAILURE_COUNT = new ParseField(\"failure_count\");\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"time_stamp\");\n+\n+    public static final ConstructingObjectParser<InferenceStats, Void> PARSER = new ConstructingObjectParser<>(\n+        NAME,\n+        true,\n+        a -> new InferenceStats((Long)a[0], (Long)a[1], (Long)a[2], (Long)a[3], (String)a[4], (String)a[5], (Instant) a[6])\n+    );\n+    static {\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), MISSING_ALL_FIELDS_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), INFERENCE_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), TOTAL_TIME_SPENT_MILLIS);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), FAILURE_COUNT);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), MODEL_ID);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), NODE_ID);\n+        PARSER.declareField(ConstructingObjectParser.constructorArg(),\n+            p -> TimeUtils.parseTimeFieldToInstant(p, TIMESTAMP.getPreferredName()),\n+            TIMESTAMP,\n+            ObjectParser.ValueType.VALUE);\n+    }\n+    public static InferenceStats emptyStats(String modelId, String nodeId) {\n+        return new InferenceStats(0L, 0L, 0L, 0L, modelId, nodeId, Instant.now());\n+    }\n+\n+    public static String docId(String modelId, String nodeId) {\n+        return NAME + \"-\" + modelId + \"-\" + nodeId;\n+    }\n+\n+    private final long missingAllFieldsCount;\n+    private final long inferenceCount;\n+    private final long totalTimeSpent;\n+    private final long failureCount;\n+    private final String modelId;\n+    private final String nodeId;\n+    private final Instant timeStamp;\n+\n+    private InferenceStats(Long missingAllFieldsCount,\n+                           Long inferenceCount,\n+                           Long totalTimeSpent,\n+                           Long failureCount,\n+                           String modelId,\n+                           String nodeId,\n+                           Instant instant) {\n+        this(unbox(missingAllFieldsCount),\n+            unbox(inferenceCount),\n+            unbox(totalTimeSpent),\n+            unbox(failureCount),\n+            modelId,\n+            nodeId,\n+            instant == null ? Instant.now() : Instant.ofEpochMilli(instant.toEpochMilli()));\n+    }\n+\n+\n+    public InferenceStats(long missingAllFieldsCount,\n+                          long inferenceCount,\n+                          long totalTimeSpent,\n+                          long failureCount,\n+                          String modelId,\n+                          String nodeId,\n+                          Instant timeStamp) {\n+        this.missingAllFieldsCount = missingAllFieldsCount;\n+        this.inferenceCount = inferenceCount;\n+        this.totalTimeSpent = totalTimeSpent;\n+        this.failureCount = failureCount;\n+        this.modelId = modelId;\n+        this.nodeId = nodeId;\n+        this.timeStamp = timeStamp == null ?\n+            Instant.ofEpochMilli(Instant.now().toEpochMilli()) :\n+            Instant.ofEpochMilli(timeStamp.toEpochMilli());\n+    }\n+\n+    public InferenceStats(StreamInput in) throws IOException {\n+        this.missingAllFieldsCount = in.readVLong();\n+        this.inferenceCount = in.readVLong();\n+        this.totalTimeSpent = in.readVLong();\n+        this.failureCount = in.readVLong();\n+        this.modelId = in.readOptionalString();\n+        this.nodeId = in.readOptionalString();\n+        this.timeStamp = Instant.ofEpochMilli(in.readInstant().toEpochMilli());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTAyNzQxNw=="}, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY3ODkyNg==", "bodyText": "This isn't necessary. I will remove this since I am rounding in the ctor", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395678926", "createdAt": "2020-03-20T14:36:51Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/InferenceStats.java", "diffHunk": "@@ -0,0 +1,268 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.inference.trainedmodel;\n+\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+import java.util.concurrent.atomic.LongAdder;\n+\n+public class InferenceStats implements ToXContentObject, Writeable {\n+\n+    public static final String NAME = \"inference_stats\";\n+    public static final ParseField MISSING_ALL_FIELDS_COUNT = new ParseField(\"missing_all_fields_count\");\n+    public static final ParseField INFERENCE_COUNT = new ParseField(\"inference_count\");\n+    public static final ParseField MODEL_ID = new ParseField(\"model_id\");\n+    public static final ParseField NODE_ID = new ParseField(\"node_id\");\n+    public static final ParseField TOTAL_TIME_SPENT_MILLIS = new ParseField(\"total_time_spent_millis\");\n+    private static final ParseField TOTAL_TIME_SPENT = new ParseField(\"total_time_spent\");\n+    public static final ParseField FAILURE_COUNT = new ParseField(\"failure_count\");\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"time_stamp\");\n+\n+    public static final ConstructingObjectParser<InferenceStats, Void> PARSER = new ConstructingObjectParser<>(\n+        NAME,\n+        true,\n+        a -> new InferenceStats((Long)a[0], (Long)a[1], (Long)a[2], (Long)a[3], (String)a[4], (String)a[5], (Instant) a[6])\n+    );\n+    static {\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), MISSING_ALL_FIELDS_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), INFERENCE_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), TOTAL_TIME_SPENT_MILLIS);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), FAILURE_COUNT);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), MODEL_ID);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), NODE_ID);\n+        PARSER.declareField(ConstructingObjectParser.constructorArg(),\n+            p -> TimeUtils.parseTimeFieldToInstant(p, TIMESTAMP.getPreferredName()),\n+            TIMESTAMP,\n+            ObjectParser.ValueType.VALUE);\n+    }\n+    public static InferenceStats emptyStats(String modelId, String nodeId) {\n+        return new InferenceStats(0L, 0L, 0L, 0L, modelId, nodeId, Instant.now());\n+    }\n+\n+    public static String docId(String modelId, String nodeId) {\n+        return NAME + \"-\" + modelId + \"-\" + nodeId;\n+    }\n+\n+    private final long missingAllFieldsCount;\n+    private final long inferenceCount;\n+    private final long totalTimeSpent;\n+    private final long failureCount;\n+    private final String modelId;\n+    private final String nodeId;\n+    private final Instant timeStamp;\n+\n+    private InferenceStats(Long missingAllFieldsCount,\n+                           Long inferenceCount,\n+                           Long totalTimeSpent,\n+                           Long failureCount,\n+                           String modelId,\n+                           String nodeId,\n+                           Instant instant) {\n+        this(unbox(missingAllFieldsCount),\n+            unbox(inferenceCount),\n+            unbox(totalTimeSpent),\n+            unbox(failureCount),\n+            modelId,\n+            nodeId,\n+            instant == null ? Instant.now() : Instant.ofEpochMilli(instant.toEpochMilli()));\n+    }\n+\n+\n+    public InferenceStats(long missingAllFieldsCount,\n+                          long inferenceCount,\n+                          long totalTimeSpent,\n+                          long failureCount,\n+                          String modelId,\n+                          String nodeId,\n+                          Instant timeStamp) {\n+        this.missingAllFieldsCount = missingAllFieldsCount;\n+        this.inferenceCount = inferenceCount;\n+        this.totalTimeSpent = totalTimeSpent;\n+        this.failureCount = failureCount;\n+        this.modelId = modelId;\n+        this.nodeId = nodeId;\n+        this.timeStamp = timeStamp == null ?\n+            Instant.ofEpochMilli(Instant.now().toEpochMilli()) :\n+            Instant.ofEpochMilli(timeStamp.toEpochMilli());\n+    }\n+\n+    public InferenceStats(StreamInput in) throws IOException {\n+        this.missingAllFieldsCount = in.readVLong();\n+        this.inferenceCount = in.readVLong();\n+        this.totalTimeSpent = in.readVLong();\n+        this.failureCount = in.readVLong();\n+        this.modelId = in.readOptionalString();\n+        this.nodeId = in.readOptionalString();\n+        this.timeStamp = Instant.ofEpochMilli(in.readInstant().toEpochMilli());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTAyNzQxNw=="}, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 115}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0ODU0Nzk5OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/InferenceStats.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxMzo0MTo1NFrOF4u4_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNDozODowMFrOF5WX6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTAzMjgzMQ==", "bodyText": "Are node_id and model_id not of interest", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395032831", "createdAt": "2020-03-19T13:41:54Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/InferenceStats.java", "diffHunk": "@@ -0,0 +1,268 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.inference.trainedmodel;\n+\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+import java.util.concurrent.atomic.LongAdder;\n+\n+public class InferenceStats implements ToXContentObject, Writeable {\n+\n+    public static final String NAME = \"inference_stats\";\n+    public static final ParseField MISSING_ALL_FIELDS_COUNT = new ParseField(\"missing_all_fields_count\");\n+    public static final ParseField INFERENCE_COUNT = new ParseField(\"inference_count\");\n+    public static final ParseField MODEL_ID = new ParseField(\"model_id\");\n+    public static final ParseField NODE_ID = new ParseField(\"node_id\");\n+    public static final ParseField TOTAL_TIME_SPENT_MILLIS = new ParseField(\"total_time_spent_millis\");\n+    private static final ParseField TOTAL_TIME_SPENT = new ParseField(\"total_time_spent\");\n+    public static final ParseField FAILURE_COUNT = new ParseField(\"failure_count\");\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"time_stamp\");\n+\n+    public static final ConstructingObjectParser<InferenceStats, Void> PARSER = new ConstructingObjectParser<>(\n+        NAME,\n+        true,\n+        a -> new InferenceStats((Long)a[0], (Long)a[1], (Long)a[2], (Long)a[3], (String)a[4], (String)a[5], (Instant) a[6])\n+    );\n+    static {\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), MISSING_ALL_FIELDS_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), INFERENCE_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), TOTAL_TIME_SPENT_MILLIS);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), FAILURE_COUNT);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), MODEL_ID);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), NODE_ID);\n+        PARSER.declareField(ConstructingObjectParser.constructorArg(),\n+            p -> TimeUtils.parseTimeFieldToInstant(p, TIMESTAMP.getPreferredName()),\n+            TIMESTAMP,\n+            ObjectParser.ValueType.VALUE);\n+    }\n+    public static InferenceStats emptyStats(String modelId, String nodeId) {\n+        return new InferenceStats(0L, 0L, 0L, 0L, modelId, nodeId, Instant.now());\n+    }\n+\n+    public static String docId(String modelId, String nodeId) {\n+        return NAME + \"-\" + modelId + \"-\" + nodeId;\n+    }\n+\n+    private final long missingAllFieldsCount;\n+    private final long inferenceCount;\n+    private final long totalTimeSpent;\n+    private final long failureCount;\n+    private final String modelId;\n+    private final String nodeId;\n+    private final Instant timeStamp;\n+\n+    private InferenceStats(Long missingAllFieldsCount,\n+                           Long inferenceCount,\n+                           Long totalTimeSpent,\n+                           Long failureCount,\n+                           String modelId,\n+                           String nodeId,\n+                           Instant instant) {\n+        this(unbox(missingAllFieldsCount),\n+            unbox(inferenceCount),\n+            unbox(totalTimeSpent),\n+            unbox(failureCount),\n+            modelId,\n+            nodeId,\n+            instant == null ? Instant.now() : Instant.ofEpochMilli(instant.toEpochMilli()));\n+    }\n+\n+\n+    public InferenceStats(long missingAllFieldsCount,\n+                          long inferenceCount,\n+                          long totalTimeSpent,\n+                          long failureCount,\n+                          String modelId,\n+                          String nodeId,\n+                          Instant timeStamp) {\n+        this.missingAllFieldsCount = missingAllFieldsCount;\n+        this.inferenceCount = inferenceCount;\n+        this.totalTimeSpent = totalTimeSpent;\n+        this.failureCount = failureCount;\n+        this.modelId = modelId;\n+        this.nodeId = nodeId;\n+        this.timeStamp = timeStamp == null ?\n+            Instant.ofEpochMilli(Instant.now().toEpochMilli()) :\n+            Instant.ofEpochMilli(timeStamp.toEpochMilli());\n+    }\n+\n+    public InferenceStats(StreamInput in) throws IOException {\n+        this.missingAllFieldsCount = in.readVLong();\n+        this.inferenceCount = in.readVLong();\n+        this.totalTimeSpent = in.readVLong();\n+        this.failureCount = in.readVLong();\n+        this.modelId = in.readOptionalString();\n+        this.nodeId = in.readOptionalString();\n+        this.timeStamp = Instant.ofEpochMilli(in.readInstant().toEpochMilli());\n+    }\n+\n+    public long getMissingAllFieldsCount() {\n+        return missingAllFieldsCount;\n+    }\n+\n+    public long getInferenceCount() {\n+        return inferenceCount;\n+    }\n+\n+    public long getTotalTimeSpent() {\n+        return totalTimeSpent;\n+    }\n+\n+    public long getFailureCount() {\n+        return failureCount;\n+    }\n+\n+    public String getModelId() {\n+        return modelId;\n+    }\n+\n+    public String getNodeId() {\n+        return nodeId;\n+    }\n+\n+    public Instant getTimeStamp() {\n+        return timeStamp;\n+    }\n+\n+    @Override\n+    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n+        builder.startObject();\n+        if (params.paramAsBoolean(ToXContentParams.FOR_INTERNAL_STORAGE, false)) {\n+            assert modelId != null : \"model_id cannot be null when storing inference stats\";\n+            assert nodeId != null : \"node_id cannot be null when storing inference stats\";\n+            builder.field(TYPE.getPreferredName(), NAME);\n+            builder.field(MODEL_ID.getPreferredName(), modelId);\n+            builder.field(NODE_ID.getPreferredName(), nodeId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 154}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY3OTcyMw==", "bodyText": "strictly speaking, no. They are only interesting in that the caller needs them when gathering the stats from the index.\nDocs are collapsed together before being sent back to the user and the overall object keeps tabs on the model_id.", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395679723", "createdAt": "2020-03-20T14:38:00Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/InferenceStats.java", "diffHunk": "@@ -0,0 +1,268 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.inference.trainedmodel;\n+\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+import java.util.concurrent.atomic.LongAdder;\n+\n+public class InferenceStats implements ToXContentObject, Writeable {\n+\n+    public static final String NAME = \"inference_stats\";\n+    public static final ParseField MISSING_ALL_FIELDS_COUNT = new ParseField(\"missing_all_fields_count\");\n+    public static final ParseField INFERENCE_COUNT = new ParseField(\"inference_count\");\n+    public static final ParseField MODEL_ID = new ParseField(\"model_id\");\n+    public static final ParseField NODE_ID = new ParseField(\"node_id\");\n+    public static final ParseField TOTAL_TIME_SPENT_MILLIS = new ParseField(\"total_time_spent_millis\");\n+    private static final ParseField TOTAL_TIME_SPENT = new ParseField(\"total_time_spent\");\n+    public static final ParseField FAILURE_COUNT = new ParseField(\"failure_count\");\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"time_stamp\");\n+\n+    public static final ConstructingObjectParser<InferenceStats, Void> PARSER = new ConstructingObjectParser<>(\n+        NAME,\n+        true,\n+        a -> new InferenceStats((Long)a[0], (Long)a[1], (Long)a[2], (Long)a[3], (String)a[4], (String)a[5], (Instant) a[6])\n+    );\n+    static {\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), MISSING_ALL_FIELDS_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), INFERENCE_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), TOTAL_TIME_SPENT_MILLIS);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), FAILURE_COUNT);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), MODEL_ID);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), NODE_ID);\n+        PARSER.declareField(ConstructingObjectParser.constructorArg(),\n+            p -> TimeUtils.parseTimeFieldToInstant(p, TIMESTAMP.getPreferredName()),\n+            TIMESTAMP,\n+            ObjectParser.ValueType.VALUE);\n+    }\n+    public static InferenceStats emptyStats(String modelId, String nodeId) {\n+        return new InferenceStats(0L, 0L, 0L, 0L, modelId, nodeId, Instant.now());\n+    }\n+\n+    public static String docId(String modelId, String nodeId) {\n+        return NAME + \"-\" + modelId + \"-\" + nodeId;\n+    }\n+\n+    private final long missingAllFieldsCount;\n+    private final long inferenceCount;\n+    private final long totalTimeSpent;\n+    private final long failureCount;\n+    private final String modelId;\n+    private final String nodeId;\n+    private final Instant timeStamp;\n+\n+    private InferenceStats(Long missingAllFieldsCount,\n+                           Long inferenceCount,\n+                           Long totalTimeSpent,\n+                           Long failureCount,\n+                           String modelId,\n+                           String nodeId,\n+                           Instant instant) {\n+        this(unbox(missingAllFieldsCount),\n+            unbox(inferenceCount),\n+            unbox(totalTimeSpent),\n+            unbox(failureCount),\n+            modelId,\n+            nodeId,\n+            instant == null ? Instant.now() : Instant.ofEpochMilli(instant.toEpochMilli()));\n+    }\n+\n+\n+    public InferenceStats(long missingAllFieldsCount,\n+                          long inferenceCount,\n+                          long totalTimeSpent,\n+                          long failureCount,\n+                          String modelId,\n+                          String nodeId,\n+                          Instant timeStamp) {\n+        this.missingAllFieldsCount = missingAllFieldsCount;\n+        this.inferenceCount = inferenceCount;\n+        this.totalTimeSpent = totalTimeSpent;\n+        this.failureCount = failureCount;\n+        this.modelId = modelId;\n+        this.nodeId = nodeId;\n+        this.timeStamp = timeStamp == null ?\n+            Instant.ofEpochMilli(Instant.now().toEpochMilli()) :\n+            Instant.ofEpochMilli(timeStamp.toEpochMilli());\n+    }\n+\n+    public InferenceStats(StreamInput in) throws IOException {\n+        this.missingAllFieldsCount = in.readVLong();\n+        this.inferenceCount = in.readVLong();\n+        this.totalTimeSpent = in.readVLong();\n+        this.failureCount = in.readVLong();\n+        this.modelId = in.readOptionalString();\n+        this.nodeId = in.readOptionalString();\n+        this.timeStamp = Instant.ofEpochMilli(in.readInstant().toEpochMilli());\n+    }\n+\n+    public long getMissingAllFieldsCount() {\n+        return missingAllFieldsCount;\n+    }\n+\n+    public long getInferenceCount() {\n+        return inferenceCount;\n+    }\n+\n+    public long getTotalTimeSpent() {\n+        return totalTimeSpent;\n+    }\n+\n+    public long getFailureCount() {\n+        return failureCount;\n+    }\n+\n+    public String getModelId() {\n+        return modelId;\n+    }\n+\n+    public String getNodeId() {\n+        return nodeId;\n+    }\n+\n+    public Instant getTimeStamp() {\n+        return timeStamp;\n+    }\n+\n+    @Override\n+    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n+        builder.startObject();\n+        if (params.paramAsBoolean(ToXContentParams.FOR_INTERNAL_STORAGE, false)) {\n+            assert modelId != null : \"model_id cannot be null when storing inference stats\";\n+            assert nodeId != null : \"node_id cannot be null when storing inference stats\";\n+            builder.field(TYPE.getPreferredName(), NAME);\n+            builder.field(MODEL_ID.getPreferredName(), modelId);\n+            builder.field(NODE_ID.getPreferredName(), nodeId);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTAzMjgzMQ=="}, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 154}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0OTMwNjg2OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/InferenceStats.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxNjozMDowOFrOF42kHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxNjozMDowOFrOF42kHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTE1ODU1OQ==", "bodyText": "maybe addTimeSpent", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395158559", "createdAt": "2020-03-19T16:30:08Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/InferenceStats.java", "diffHunk": "@@ -0,0 +1,268 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.inference.trainedmodel;\n+\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+import java.util.concurrent.atomic.LongAdder;\n+\n+public class InferenceStats implements ToXContentObject, Writeable {\n+\n+    public static final String NAME = \"inference_stats\";\n+    public static final ParseField MISSING_ALL_FIELDS_COUNT = new ParseField(\"missing_all_fields_count\");\n+    public static final ParseField INFERENCE_COUNT = new ParseField(\"inference_count\");\n+    public static final ParseField MODEL_ID = new ParseField(\"model_id\");\n+    public static final ParseField NODE_ID = new ParseField(\"node_id\");\n+    public static final ParseField TOTAL_TIME_SPENT_MILLIS = new ParseField(\"total_time_spent_millis\");\n+    private static final ParseField TOTAL_TIME_SPENT = new ParseField(\"total_time_spent\");\n+    public static final ParseField FAILURE_COUNT = new ParseField(\"failure_count\");\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"time_stamp\");\n+\n+    public static final ConstructingObjectParser<InferenceStats, Void> PARSER = new ConstructingObjectParser<>(\n+        NAME,\n+        true,\n+        a -> new InferenceStats((Long)a[0], (Long)a[1], (Long)a[2], (Long)a[3], (String)a[4], (String)a[5], (Instant) a[6])\n+    );\n+    static {\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), MISSING_ALL_FIELDS_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), INFERENCE_COUNT);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), TOTAL_TIME_SPENT_MILLIS);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), FAILURE_COUNT);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), MODEL_ID);\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), NODE_ID);\n+        PARSER.declareField(ConstructingObjectParser.constructorArg(),\n+            p -> TimeUtils.parseTimeFieldToInstant(p, TIMESTAMP.getPreferredName()),\n+            TIMESTAMP,\n+            ObjectParser.ValueType.VALUE);\n+    }\n+    public static InferenceStats emptyStats(String modelId, String nodeId) {\n+        return new InferenceStats(0L, 0L, 0L, 0L, modelId, nodeId, Instant.now());\n+    }\n+\n+    public static String docId(String modelId, String nodeId) {\n+        return NAME + \"-\" + modelId + \"-\" + nodeId;\n+    }\n+\n+    private final long missingAllFieldsCount;\n+    private final long inferenceCount;\n+    private final long totalTimeSpent;\n+    private final long failureCount;\n+    private final String modelId;\n+    private final String nodeId;\n+    private final Instant timeStamp;\n+\n+    private InferenceStats(Long missingAllFieldsCount,\n+                           Long inferenceCount,\n+                           Long totalTimeSpent,\n+                           Long failureCount,\n+                           String modelId,\n+                           String nodeId,\n+                           Instant instant) {\n+        this(unbox(missingAllFieldsCount),\n+            unbox(inferenceCount),\n+            unbox(totalTimeSpent),\n+            unbox(failureCount),\n+            modelId,\n+            nodeId,\n+            instant == null ? Instant.now() : Instant.ofEpochMilli(instant.toEpochMilli()));\n+    }\n+\n+\n+    public InferenceStats(long missingAllFieldsCount,\n+                          long inferenceCount,\n+                          long totalTimeSpent,\n+                          long failureCount,\n+                          String modelId,\n+                          String nodeId,\n+                          Instant timeStamp) {\n+        this.missingAllFieldsCount = missingAllFieldsCount;\n+        this.inferenceCount = inferenceCount;\n+        this.totalTimeSpent = totalTimeSpent;\n+        this.failureCount = failureCount;\n+        this.modelId = modelId;\n+        this.nodeId = nodeId;\n+        this.timeStamp = timeStamp == null ?\n+            Instant.ofEpochMilli(Instant.now().toEpochMilli()) :\n+            Instant.ofEpochMilli(timeStamp.toEpochMilli());\n+    }\n+\n+    public InferenceStats(StreamInput in) throws IOException {\n+        this.missingAllFieldsCount = in.readVLong();\n+        this.inferenceCount = in.readVLong();\n+        this.totalTimeSpent = in.readVLong();\n+        this.failureCount = in.readVLong();\n+        this.modelId = in.readOptionalString();\n+        this.nodeId = in.readOptionalString();\n+        this.timeStamp = Instant.ofEpochMilli(in.readInstant().toEpochMilli());\n+    }\n+\n+    public long getMissingAllFieldsCount() {\n+        return missingAllFieldsCount;\n+    }\n+\n+    public long getInferenceCount() {\n+        return inferenceCount;\n+    }\n+\n+    public long getTotalTimeSpent() {\n+        return totalTimeSpent;\n+    }\n+\n+    public long getFailureCount() {\n+        return failureCount;\n+    }\n+\n+    public String getModelId() {\n+        return modelId;\n+    }\n+\n+    public String getNodeId() {\n+        return nodeId;\n+    }\n+\n+    public Instant getTimeStamp() {\n+        return timeStamp;\n+    }\n+\n+    @Override\n+    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n+        builder.startObject();\n+        if (params.paramAsBoolean(ToXContentParams.FOR_INTERNAL_STORAGE, false)) {\n+            assert modelId != null : \"model_id cannot be null when storing inference stats\";\n+            assert nodeId != null : \"node_id cannot be null when storing inference stats\";\n+            builder.field(TYPE.getPreferredName(), NAME);\n+            builder.field(MODEL_ID.getPreferredName(), modelId);\n+            builder.field(NODE_ID.getPreferredName(), nodeId);\n+        }\n+        builder.field(FAILURE_COUNT.getPreferredName(), failureCount);\n+        builder.timeField(TOTAL_TIME_SPENT_MILLIS.getPreferredName(), TOTAL_TIME_SPENT.getPreferredName(), totalTimeSpent);\n+        builder.field(INFERENCE_COUNT.getPreferredName(), inferenceCount);\n+        builder.field(MISSING_ALL_FIELDS_COUNT.getPreferredName(), missingAllFieldsCount);\n+        builder.timeField(TIMESTAMP.getPreferredName(), TIMESTAMP.getPreferredName() + \"_string\", timeStamp.toEpochMilli());\n+        builder.endObject();\n+        return builder;\n+    }\n+\n+    @Override\n+    public boolean equals(Object o) {\n+        if (this == o) return true;\n+        if (o == null || getClass() != o.getClass()) return false;\n+        InferenceStats that = (InferenceStats) o;\n+        return missingAllFieldsCount == that.missingAllFieldsCount\n+            && inferenceCount == that.inferenceCount\n+            && totalTimeSpent == that.totalTimeSpent\n+            && failureCount == that.failureCount\n+            && Objects.equals(modelId, that.modelId)\n+            && Objects.equals(nodeId, that.nodeId)\n+            && Objects.equals(timeStamp, that.timeStamp);\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return Objects.hash(missingAllFieldsCount, inferenceCount, totalTimeSpent, failureCount, modelId, nodeId, timeStamp);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return Strings.toString(this);\n+    }\n+\n+    private static long unbox(@Nullable Long value) {\n+        return value == null ? 0L : value;\n+    }\n+\n+    public static Accumulator accumulator(String modelId, String nodeId) {\n+        return new Accumulator(modelId, nodeId);\n+    }\n+\n+    @Override\n+    public void writeTo(StreamOutput out) throws IOException {\n+        out.writeVLong(this.missingAllFieldsCount);\n+        out.writeVLong(this.inferenceCount);\n+        out.writeVLong(this.totalTimeSpent);\n+        out.writeVLong(this.failureCount);\n+        out.writeOptionalString(this.modelId);\n+        out.writeOptionalString(this.nodeId);\n+        out.writeInstant(timeStamp);\n+    }\n+\n+    public static class Accumulator {\n+\n+        private final LongAdder missingFieldsAccumulator = new LongAdder();\n+        private final LongAdder inferenceAccumulator = new LongAdder();\n+        private final LongAdder totalTimeSpentAccumulator = new LongAdder();\n+        private final LongAdder failureCountAccumulator = new LongAdder();\n+        private final String modelId;\n+        private final String nodeId;\n+\n+        public Accumulator(String modelId, String nodeId) {\n+            this.modelId = modelId;\n+            this.nodeId = nodeId;\n+        }\n+\n+        public Accumulator(InferenceStats previousStats) {\n+            this.modelId = previousStats.modelId;\n+            this.nodeId = previousStats.nodeId;\n+            this.missingFieldsAccumulator.add(previousStats.missingAllFieldsCount);\n+            this.inferenceAccumulator.add(previousStats.inferenceCount);\n+            this.totalTimeSpentAccumulator.add(TimeValue.timeValueMillis(previousStats.totalTimeSpent).nanos());\n+            this.failureCountAccumulator.add(previousStats.failureCount);\n+        }\n+\n+        public void merge(InferenceStats otherStats) {\n+            this.missingFieldsAccumulator.add(otherStats.missingAllFieldsCount);\n+            this.inferenceAccumulator.add(otherStats.inferenceCount);\n+            this.totalTimeSpentAccumulator.add(TimeValue.timeValueMillis(otherStats.totalTimeSpent).nanos());\n+            this.failureCountAccumulator.add(otherStats.failureCount);\n+        }\n+\n+        public void incMissingFields() {\n+            this.missingFieldsAccumulator.increment();\n+        }\n+\n+        public void incInference() {\n+            this.inferenceAccumulator.increment();\n+        }\n+\n+        public void incFailure() {\n+            this.failureCountAccumulator.increment();\n+        }\n+\n+        public void timeSpent(long value) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 250}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0OTM5MTc5OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportGetTrainedModelsStatsAction.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxNjo1MDoyNlrOF43bjw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxNjo1MDoyNlrOF43bjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTE3Mjc1MQ==", "bodyText": "\ud83d\udc4d", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395172751", "createdAt": "2020-03-19T16:50:26Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportGetTrainedModelsStatsAction.java", "diffHunk": "@@ -102,8 +111,8 @@ protected void doExecute(Task task,\n             idsListener);\n     }\n \n-    static Map<String, IngestStats> inferenceIngestStatsByPipelineId(NodesStatsResponse response,\n-                                                                     Map<String, Set<String>> modelIdToPipelineId) {\n+    static Map<String, IngestStats> inferenceIngestStatsByModelId(NodesStatsResponse response,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0OTQwNzM1OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxNjo1NDowNVrOF43lkA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxODozNzowMFrOF47isQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTE3NTMxMg==", "bodyText": "I'm not sure about using the GENERIC threadpool \ud83e\udd14", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395175312", "createdAt": "2020-03-19T16:54:05Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.inference;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkRequest;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.action.update.UpdateRequest;\n+import org.elasticsearch.client.OriginSettingClient;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.component.LifecycleListener;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.script.Script;\n+import org.elasticsearch.script.ScriptType;\n+import org.elasticsearch.threadpool.Scheduler;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ml.MlStatsIndex;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.InferenceStats;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.elasticsearch.xpack.ml.utils.persistence.ResultsPersisterService;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+\n+\n+public class TrainedModelStatsService {\n+\n+    private static final Logger logger = LogManager.getLogger(TrainedModelStatsService.class);\n+\n+    // Script to only update if stats have increased since last persistence\n+    private static final String STATS_UPDATE_SCRIPT = \"\" +\n+        \"if (ctx._source.missing_all_fields_count >= params.missing_all_fields_count\\n\" +\n+        \"     && ctx._source.inference_count >= params.inference_count\\n\" +\n+        \"     && ctx._source.total_time_spent_millis >= params.total_time_spent_millis\\n\" +\n+        \"     && ctx._source.failure_count >= params.failure_count) {\\n\" +\n+        \"      ctx.op = 'none';\\n\" +\n+        \"      return;\\n\" +\n+        \"    }\\n\" +\n+        \"    ctx._source.missing_all_fields_count = params.missing_all_fields_count;\\n\" +\n+        \"    ctx._source.inference_count = params.inference_count;\\n\" +\n+        \"    ctx._source.total_time_spent_millis = params.total_time_spent_millis;\\n\" +\n+        \"    ctx._source.failure_count = params.failure_count;\\n\" +\n+        \"    ctx._source.time_stamp = params.time_stamp;\";\n+    private static final ToXContent.Params FOR_INTERNAL_STORAGE_PARAMS =\n+        new ToXContent.MapParams(Collections.singletonMap(ToXContentParams.FOR_INTERNAL_STORAGE, \"true\"));\n+\n+    private final Map<String, InferenceStats> statsQueue;\n+    private final ResultsPersisterService resultsPersisterService;\n+    private final OriginSettingClient client;\n+    private final IndexNameExpressionResolver indexNameExpressionResolver;\n+    private final ThreadPool threadPool;\n+    private volatile Scheduler.Cancellable scheduledFuture;\n+    private volatile boolean verifiedStatsIndexCreated;\n+    private volatile boolean stopped;\n+    private volatile ClusterState clusterState;\n+\n+    public TrainedModelStatsService(ResultsPersisterService resultsPersisterService,\n+                                    OriginSettingClient client,\n+                                    IndexNameExpressionResolver indexNameExpressionResolver,\n+                                    ClusterService clusterService,\n+                                    ThreadPool threadPool) {\n+        this.resultsPersisterService = resultsPersisterService;\n+        this.client = client;\n+        this.indexNameExpressionResolver = indexNameExpressionResolver;\n+        this.threadPool = threadPool;\n+        this.statsQueue = new ConcurrentHashMap<>();\n+\n+        clusterService.addLifecycleListener(new LifecycleListener() {\n+            @Override\n+            public void beforeStart() {\n+                start();\n+            }\n+\n+            @Override\n+            public void beforeStop() {\n+                stop();\n+            }\n+        });\n+        clusterService.addListener((event) -> this.clusterState = event.state());\n+    }\n+\n+    public void queueStats(InferenceStats stats) {\n+        statsQueue.put(InferenceStats.docId(stats.getModelId(), stats.getNodeId()), stats);\n+    }\n+\n+    void stop() {\n+        stopped = true;\n+        statsQueue.clear();\n+\n+        ThreadPool.Cancellable cancellable = this.scheduledFuture;\n+        if (cancellable != null) {\n+            cancellable.cancel();\n+        }\n+    }\n+\n+    void start() {\n+        stopped = false;\n+        scheduledFuture = threadPool.scheduleWithFixedDelay(this::persistStats, TimeValue.timeValueSeconds(1), ThreadPool.Names.GENERIC);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI0MDExMw==", "bodyText": "We could use the ML utility one?", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395240113", "createdAt": "2020-03-19T18:37:00Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.inference;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkRequest;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.action.update.UpdateRequest;\n+import org.elasticsearch.client.OriginSettingClient;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.component.LifecycleListener;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.script.Script;\n+import org.elasticsearch.script.ScriptType;\n+import org.elasticsearch.threadpool.Scheduler;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ml.MlStatsIndex;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.InferenceStats;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.elasticsearch.xpack.ml.utils.persistence.ResultsPersisterService;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+\n+\n+public class TrainedModelStatsService {\n+\n+    private static final Logger logger = LogManager.getLogger(TrainedModelStatsService.class);\n+\n+    // Script to only update if stats have increased since last persistence\n+    private static final String STATS_UPDATE_SCRIPT = \"\" +\n+        \"if (ctx._source.missing_all_fields_count >= params.missing_all_fields_count\\n\" +\n+        \"     && ctx._source.inference_count >= params.inference_count\\n\" +\n+        \"     && ctx._source.total_time_spent_millis >= params.total_time_spent_millis\\n\" +\n+        \"     && ctx._source.failure_count >= params.failure_count) {\\n\" +\n+        \"      ctx.op = 'none';\\n\" +\n+        \"      return;\\n\" +\n+        \"    }\\n\" +\n+        \"    ctx._source.missing_all_fields_count = params.missing_all_fields_count;\\n\" +\n+        \"    ctx._source.inference_count = params.inference_count;\\n\" +\n+        \"    ctx._source.total_time_spent_millis = params.total_time_spent_millis;\\n\" +\n+        \"    ctx._source.failure_count = params.failure_count;\\n\" +\n+        \"    ctx._source.time_stamp = params.time_stamp;\";\n+    private static final ToXContent.Params FOR_INTERNAL_STORAGE_PARAMS =\n+        new ToXContent.MapParams(Collections.singletonMap(ToXContentParams.FOR_INTERNAL_STORAGE, \"true\"));\n+\n+    private final Map<String, InferenceStats> statsQueue;\n+    private final ResultsPersisterService resultsPersisterService;\n+    private final OriginSettingClient client;\n+    private final IndexNameExpressionResolver indexNameExpressionResolver;\n+    private final ThreadPool threadPool;\n+    private volatile Scheduler.Cancellable scheduledFuture;\n+    private volatile boolean verifiedStatsIndexCreated;\n+    private volatile boolean stopped;\n+    private volatile ClusterState clusterState;\n+\n+    public TrainedModelStatsService(ResultsPersisterService resultsPersisterService,\n+                                    OriginSettingClient client,\n+                                    IndexNameExpressionResolver indexNameExpressionResolver,\n+                                    ClusterService clusterService,\n+                                    ThreadPool threadPool) {\n+        this.resultsPersisterService = resultsPersisterService;\n+        this.client = client;\n+        this.indexNameExpressionResolver = indexNameExpressionResolver;\n+        this.threadPool = threadPool;\n+        this.statsQueue = new ConcurrentHashMap<>();\n+\n+        clusterService.addLifecycleListener(new LifecycleListener() {\n+            @Override\n+            public void beforeStart() {\n+                start();\n+            }\n+\n+            @Override\n+            public void beforeStop() {\n+                stop();\n+            }\n+        });\n+        clusterService.addListener((event) -> this.clusterState = event.state());\n+    }\n+\n+    public void queueStats(InferenceStats stats) {\n+        statsQueue.put(InferenceStats.docId(stats.getModelId(), stats.getNodeId()), stats);\n+    }\n+\n+    void stop() {\n+        stopped = true;\n+        statsQueue.clear();\n+\n+        ThreadPool.Cancellable cancellable = this.scheduledFuture;\n+        if (cancellable != null) {\n+            cancellable.cancel();\n+        }\n+    }\n+\n+    void start() {\n+        stopped = false;\n+        scheduledFuture = threadPool.scheduleWithFixedDelay(this::persistStats, TimeValue.timeValueSeconds(1), ThreadPool.Names.GENERIC);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTE3NTMxMg=="}, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 116}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0OTQ0OTY5OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxNzowNDoxNlrOF44AzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxNzowNDoxNlrOF44AzQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTE4MjI4NQ==", "bodyText": "\"failure creating ml stats index\"", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395182285", "createdAt": "2020-03-19T17:04:16Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.inference;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkRequest;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.action.update.UpdateRequest;\n+import org.elasticsearch.client.OriginSettingClient;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.component.LifecycleListener;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.script.Script;\n+import org.elasticsearch.script.ScriptType;\n+import org.elasticsearch.threadpool.Scheduler;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ml.MlStatsIndex;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.InferenceStats;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.elasticsearch.xpack.ml.utils.persistence.ResultsPersisterService;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+\n+\n+public class TrainedModelStatsService {\n+\n+    private static final Logger logger = LogManager.getLogger(TrainedModelStatsService.class);\n+\n+    // Script to only update if stats have increased since last persistence\n+    private static final String STATS_UPDATE_SCRIPT = \"\" +\n+        \"if (ctx._source.missing_all_fields_count >= params.missing_all_fields_count\\n\" +\n+        \"     && ctx._source.inference_count >= params.inference_count\\n\" +\n+        \"     && ctx._source.total_time_spent_millis >= params.total_time_spent_millis\\n\" +\n+        \"     && ctx._source.failure_count >= params.failure_count) {\\n\" +\n+        \"      ctx.op = 'none';\\n\" +\n+        \"      return;\\n\" +\n+        \"    }\\n\" +\n+        \"    ctx._source.missing_all_fields_count = params.missing_all_fields_count;\\n\" +\n+        \"    ctx._source.inference_count = params.inference_count;\\n\" +\n+        \"    ctx._source.total_time_spent_millis = params.total_time_spent_millis;\\n\" +\n+        \"    ctx._source.failure_count = params.failure_count;\\n\" +\n+        \"    ctx._source.time_stamp = params.time_stamp;\";\n+    private static final ToXContent.Params FOR_INTERNAL_STORAGE_PARAMS =\n+        new ToXContent.MapParams(Collections.singletonMap(ToXContentParams.FOR_INTERNAL_STORAGE, \"true\"));\n+\n+    private final Map<String, InferenceStats> statsQueue;\n+    private final ResultsPersisterService resultsPersisterService;\n+    private final OriginSettingClient client;\n+    private final IndexNameExpressionResolver indexNameExpressionResolver;\n+    private final ThreadPool threadPool;\n+    private volatile Scheduler.Cancellable scheduledFuture;\n+    private volatile boolean verifiedStatsIndexCreated;\n+    private volatile boolean stopped;\n+    private volatile ClusterState clusterState;\n+\n+    public TrainedModelStatsService(ResultsPersisterService resultsPersisterService,\n+                                    OriginSettingClient client,\n+                                    IndexNameExpressionResolver indexNameExpressionResolver,\n+                                    ClusterService clusterService,\n+                                    ThreadPool threadPool) {\n+        this.resultsPersisterService = resultsPersisterService;\n+        this.client = client;\n+        this.indexNameExpressionResolver = indexNameExpressionResolver;\n+        this.threadPool = threadPool;\n+        this.statsQueue = new ConcurrentHashMap<>();\n+\n+        clusterService.addLifecycleListener(new LifecycleListener() {\n+            @Override\n+            public void beforeStart() {\n+                start();\n+            }\n+\n+            @Override\n+            public void beforeStop() {\n+                stop();\n+            }\n+        });\n+        clusterService.addListener((event) -> this.clusterState = event.state());\n+    }\n+\n+    public void queueStats(InferenceStats stats) {\n+        statsQueue.put(InferenceStats.docId(stats.getModelId(), stats.getNodeId()), stats);\n+    }\n+\n+    void stop() {\n+        stopped = true;\n+        statsQueue.clear();\n+\n+        ThreadPool.Cancellable cancellable = this.scheduledFuture;\n+        if (cancellable != null) {\n+            cancellable.cancel();\n+        }\n+    }\n+\n+    void start() {\n+        stopped = false;\n+        scheduledFuture = threadPool.scheduleWithFixedDelay(this::persistStats, TimeValue.timeValueSeconds(1), ThreadPool.Names.GENERIC);\n+    }\n+\n+    void persistStats() {\n+        if (clusterState == null || statsQueue.isEmpty()) {\n+            return;\n+        }\n+\n+        List<InferenceStats> stats = new ArrayList<>(statsQueue.size());\n+        for(String k : statsQueue.keySet()) {\n+            InferenceStats inferenceStats = statsQueue.remove(k);\n+            if (inferenceStats != null) {\n+                stats.add(inferenceStats);\n+            }\n+        }\n+        if (stats.isEmpty()) {\n+            return;\n+        }\n+        if (verifiedStatsIndexCreated == false) {\n+            try {\n+                PlainActionFuture<Boolean> listener = new PlainActionFuture<>();\n+                MlStatsIndex.createStatsIndexAndAliasIfNecessary(client, clusterState, indexNameExpressionResolver, listener);\n+                listener.actionGet();\n+                verifiedStatsIndexCreated = true;\n+            } catch (Exception e) {\n+                logger.error(\n+                    new ParameterizedMessage(\"failure updating stats for models {}\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 142}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0OTQ1OTEyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxNzowNjozNlrOF44Gzw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNDo0MzoyOFrOF5Wlcw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTE4MzgyMw==", "bodyText": "Will this be printed properly, what is toString() on a stream?", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395183823", "createdAt": "2020-03-19T17:06:36Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.inference;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkRequest;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.action.update.UpdateRequest;\n+import org.elasticsearch.client.OriginSettingClient;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.component.LifecycleListener;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.script.Script;\n+import org.elasticsearch.script.ScriptType;\n+import org.elasticsearch.threadpool.Scheduler;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ml.MlStatsIndex;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.InferenceStats;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.elasticsearch.xpack.ml.utils.persistence.ResultsPersisterService;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+\n+\n+public class TrainedModelStatsService {\n+\n+    private static final Logger logger = LogManager.getLogger(TrainedModelStatsService.class);\n+\n+    // Script to only update if stats have increased since last persistence\n+    private static final String STATS_UPDATE_SCRIPT = \"\" +\n+        \"if (ctx._source.missing_all_fields_count >= params.missing_all_fields_count\\n\" +\n+        \"     && ctx._source.inference_count >= params.inference_count\\n\" +\n+        \"     && ctx._source.total_time_spent_millis >= params.total_time_spent_millis\\n\" +\n+        \"     && ctx._source.failure_count >= params.failure_count) {\\n\" +\n+        \"      ctx.op = 'none';\\n\" +\n+        \"      return;\\n\" +\n+        \"    }\\n\" +\n+        \"    ctx._source.missing_all_fields_count = params.missing_all_fields_count;\\n\" +\n+        \"    ctx._source.inference_count = params.inference_count;\\n\" +\n+        \"    ctx._source.total_time_spent_millis = params.total_time_spent_millis;\\n\" +\n+        \"    ctx._source.failure_count = params.failure_count;\\n\" +\n+        \"    ctx._source.time_stamp = params.time_stamp;\";\n+    private static final ToXContent.Params FOR_INTERNAL_STORAGE_PARAMS =\n+        new ToXContent.MapParams(Collections.singletonMap(ToXContentParams.FOR_INTERNAL_STORAGE, \"true\"));\n+\n+    private final Map<String, InferenceStats> statsQueue;\n+    private final ResultsPersisterService resultsPersisterService;\n+    private final OriginSettingClient client;\n+    private final IndexNameExpressionResolver indexNameExpressionResolver;\n+    private final ThreadPool threadPool;\n+    private volatile Scheduler.Cancellable scheduledFuture;\n+    private volatile boolean verifiedStatsIndexCreated;\n+    private volatile boolean stopped;\n+    private volatile ClusterState clusterState;\n+\n+    public TrainedModelStatsService(ResultsPersisterService resultsPersisterService,\n+                                    OriginSettingClient client,\n+                                    IndexNameExpressionResolver indexNameExpressionResolver,\n+                                    ClusterService clusterService,\n+                                    ThreadPool threadPool) {\n+        this.resultsPersisterService = resultsPersisterService;\n+        this.client = client;\n+        this.indexNameExpressionResolver = indexNameExpressionResolver;\n+        this.threadPool = threadPool;\n+        this.statsQueue = new ConcurrentHashMap<>();\n+\n+        clusterService.addLifecycleListener(new LifecycleListener() {\n+            @Override\n+            public void beforeStart() {\n+                start();\n+            }\n+\n+            @Override\n+            public void beforeStop() {\n+                stop();\n+            }\n+        });\n+        clusterService.addListener((event) -> this.clusterState = event.state());\n+    }\n+\n+    public void queueStats(InferenceStats stats) {\n+        statsQueue.put(InferenceStats.docId(stats.getModelId(), stats.getNodeId()), stats);\n+    }\n+\n+    void stop() {\n+        stopped = true;\n+        statsQueue.clear();\n+\n+        ThreadPool.Cancellable cancellable = this.scheduledFuture;\n+        if (cancellable != null) {\n+            cancellable.cancel();\n+        }\n+    }\n+\n+    void start() {\n+        stopped = false;\n+        scheduledFuture = threadPool.scheduleWithFixedDelay(this::persistStats, TimeValue.timeValueSeconds(1), ThreadPool.Names.GENERIC);\n+    }\n+\n+    void persistStats() {\n+        if (clusterState == null || statsQueue.isEmpty()) {\n+            return;\n+        }\n+\n+        List<InferenceStats> stats = new ArrayList<>(statsQueue.size());\n+        for(String k : statsQueue.keySet()) {\n+            InferenceStats inferenceStats = statsQueue.remove(k);\n+            if (inferenceStats != null) {\n+                stats.add(inferenceStats);\n+            }\n+        }\n+        if (stats.isEmpty()) {\n+            return;\n+        }\n+        if (verifiedStatsIndexCreated == false) {\n+            try {\n+                PlainActionFuture<Boolean> listener = new PlainActionFuture<>();\n+                MlStatsIndex.createStatsIndexAndAliasIfNecessary(client, clusterState, indexNameExpressionResolver, listener);\n+                listener.actionGet();\n+                verifiedStatsIndexCreated = true;\n+            } catch (Exception e) {\n+                logger.error(\n+                    new ParameterizedMessage(\"failure updating stats for models {}\",\n+                        stats.stream().map(InferenceStats::getModelId)),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 143}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY4MzE4Nw==", "bodyText": "Nope, it won't, I am added a collector.", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395683187", "createdAt": "2020-03-20T14:43:28Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.inference;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkRequest;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.action.update.UpdateRequest;\n+import org.elasticsearch.client.OriginSettingClient;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.component.LifecycleListener;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.script.Script;\n+import org.elasticsearch.script.ScriptType;\n+import org.elasticsearch.threadpool.Scheduler;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ml.MlStatsIndex;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.InferenceStats;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.elasticsearch.xpack.ml.utils.persistence.ResultsPersisterService;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+\n+\n+public class TrainedModelStatsService {\n+\n+    private static final Logger logger = LogManager.getLogger(TrainedModelStatsService.class);\n+\n+    // Script to only update if stats have increased since last persistence\n+    private static final String STATS_UPDATE_SCRIPT = \"\" +\n+        \"if (ctx._source.missing_all_fields_count >= params.missing_all_fields_count\\n\" +\n+        \"     && ctx._source.inference_count >= params.inference_count\\n\" +\n+        \"     && ctx._source.total_time_spent_millis >= params.total_time_spent_millis\\n\" +\n+        \"     && ctx._source.failure_count >= params.failure_count) {\\n\" +\n+        \"      ctx.op = 'none';\\n\" +\n+        \"      return;\\n\" +\n+        \"    }\\n\" +\n+        \"    ctx._source.missing_all_fields_count = params.missing_all_fields_count;\\n\" +\n+        \"    ctx._source.inference_count = params.inference_count;\\n\" +\n+        \"    ctx._source.total_time_spent_millis = params.total_time_spent_millis;\\n\" +\n+        \"    ctx._source.failure_count = params.failure_count;\\n\" +\n+        \"    ctx._source.time_stamp = params.time_stamp;\";\n+    private static final ToXContent.Params FOR_INTERNAL_STORAGE_PARAMS =\n+        new ToXContent.MapParams(Collections.singletonMap(ToXContentParams.FOR_INTERNAL_STORAGE, \"true\"));\n+\n+    private final Map<String, InferenceStats> statsQueue;\n+    private final ResultsPersisterService resultsPersisterService;\n+    private final OriginSettingClient client;\n+    private final IndexNameExpressionResolver indexNameExpressionResolver;\n+    private final ThreadPool threadPool;\n+    private volatile Scheduler.Cancellable scheduledFuture;\n+    private volatile boolean verifiedStatsIndexCreated;\n+    private volatile boolean stopped;\n+    private volatile ClusterState clusterState;\n+\n+    public TrainedModelStatsService(ResultsPersisterService resultsPersisterService,\n+                                    OriginSettingClient client,\n+                                    IndexNameExpressionResolver indexNameExpressionResolver,\n+                                    ClusterService clusterService,\n+                                    ThreadPool threadPool) {\n+        this.resultsPersisterService = resultsPersisterService;\n+        this.client = client;\n+        this.indexNameExpressionResolver = indexNameExpressionResolver;\n+        this.threadPool = threadPool;\n+        this.statsQueue = new ConcurrentHashMap<>();\n+\n+        clusterService.addLifecycleListener(new LifecycleListener() {\n+            @Override\n+            public void beforeStart() {\n+                start();\n+            }\n+\n+            @Override\n+            public void beforeStop() {\n+                stop();\n+            }\n+        });\n+        clusterService.addListener((event) -> this.clusterState = event.state());\n+    }\n+\n+    public void queueStats(InferenceStats stats) {\n+        statsQueue.put(InferenceStats.docId(stats.getModelId(), stats.getNodeId()), stats);\n+    }\n+\n+    void stop() {\n+        stopped = true;\n+        statsQueue.clear();\n+\n+        ThreadPool.Cancellable cancellable = this.scheduledFuture;\n+        if (cancellable != null) {\n+            cancellable.cancel();\n+        }\n+    }\n+\n+    void start() {\n+        stopped = false;\n+        scheduledFuture = threadPool.scheduleWithFixedDelay(this::persistStats, TimeValue.timeValueSeconds(1), ThreadPool.Names.GENERIC);\n+    }\n+\n+    void persistStats() {\n+        if (clusterState == null || statsQueue.isEmpty()) {\n+            return;\n+        }\n+\n+        List<InferenceStats> stats = new ArrayList<>(statsQueue.size());\n+        for(String k : statsQueue.keySet()) {\n+            InferenceStats inferenceStats = statsQueue.remove(k);\n+            if (inferenceStats != null) {\n+                stats.add(inferenceStats);\n+            }\n+        }\n+        if (stats.isEmpty()) {\n+            return;\n+        }\n+        if (verifiedStatsIndexCreated == false) {\n+            try {\n+                PlainActionFuture<Boolean> listener = new PlainActionFuture<>();\n+                MlStatsIndex.createStatsIndexAndAliasIfNecessary(client, clusterState, indexNameExpressionResolver, listener);\n+                listener.actionGet();\n+                verifiedStatsIndexCreated = true;\n+            } catch (Exception e) {\n+                logger.error(\n+                    new ParameterizedMessage(\"failure updating stats for models {}\",\n+                        stats.stream().map(InferenceStats::getModelId)),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTE4MzgyMw=="}, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 143}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0OTU0MTkyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/ModelLoadingService.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxNzoyNzoxNVrOF448xQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNDo1MzowOVrOF5W_dg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTE5NzYzNw==", "bodyText": "I thought the string replacement in the message parameter only occurred if trace is enabled", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395197637", "createdAt": "2020-03-19T17:27:15Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/ModelLoadingService.java", "diffHunk": "@@ -130,24 +141,26 @@ public void getModel(String modelId, ActionListener<Model> modelActionListener)\n         LocalModel cachedModel = localModelCache.get(modelId);\n         if (cachedModel != null) {\n             modelActionListener.onResponse(cachedModel);\n-            logger.trace(\"[{}] loaded from cache\", modelId);\n+            logger.trace(() -> new ParameterizedMessage(\"[{}] loaded from cache\", modelId));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY4NTAyNQ==", "bodyText": "I don't know. I do know that using a message supplier is common in other logging code.", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395685025", "createdAt": "2020-03-20T14:46:14Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/ModelLoadingService.java", "diffHunk": "@@ -130,24 +141,26 @@ public void getModel(String modelId, ActionListener<Model> modelActionListener)\n         LocalModel cachedModel = localModelCache.get(modelId);\n         if (cachedModel != null) {\n             modelActionListener.onResponse(cachedModel);\n-            logger.trace(\"[{}] loaded from cache\", modelId);\n+            logger.trace(() -> new ParameterizedMessage(\"[{}] loaded from cache\", modelId));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTE5NzYzNw=="}, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY4OTg0Ng==", "bodyText": "OK, looking at https://logging.apache.org/log4j/2.x/log4j-api/apidocs/org/apache/logging/log4j/Logger.html\nIt seems the parameters are for sure read, no matter the level (unless a supplier is used).\nThis seems to indicate that the string is formatted eagerly unless parameters are suppliers or a message supplier is passed.", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395689846", "createdAt": "2020-03-20T14:53:09Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/ModelLoadingService.java", "diffHunk": "@@ -130,24 +141,26 @@ public void getModel(String modelId, ActionListener<Model> modelActionListener)\n         LocalModel cachedModel = localModelCache.get(modelId);\n         if (cachedModel != null) {\n             modelActionListener.onResponse(cachedModel);\n-            logger.trace(\"[{}] loaded from cache\", modelId);\n+            logger.trace(() -> new ParameterizedMessage(\"[{}] loaded from cache\", modelId));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTE5NzYzNw=="}, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0OTU3MDI3OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/LocalModel.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxNzozNDoyOVrOF45PeA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNDo1NTozM1rOF5XGig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTIwMjQyNA==", "bodyText": "This is a tricky one. When the model is done with how do we ensure it persists the latest stats. Could this implement closable and persist on close when the model is evicted from the cache?", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395202424", "createdAt": "2020-03-19T17:34:29Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/LocalModel.java", "diffHunk": "@@ -64,17 +100,45 @@ public String getResultsType() {\n         }\n     }\n \n+    void persistStats() {\n+        trainedModelStatsService.queueStats(getLatestStats());\n+        lastStatsQueue = nanoTimeSupplier.get();\n+        if (persistenceQuotient < 1000 && currentInferenceCount.sum() > 1000) {\n+            persistenceQuotient = 1000;\n+        }\n+        if (persistenceQuotient < 10_000 && currentInferenceCount.sum() > 10_000) {\n+            persistenceQuotient = 10_000;\n+        }\n+    }\n+\n     @Override\n     public void infer(Map<String, Object> fields, InferenceConfig config, ActionListener<InferenceResults> listener) {\n         try {\n+            statsAccumulator.incInference();\n+            currentInferenceCount.increment();\n+\n             Model.mapFieldsIfNecessary(fields, defaultFieldMap);\n+\n+            long startTimeInNanos = nanoTimeSupplier.get();\n+            boolean shouldPersistStats =\n+                (TimeUnit.NANOSECONDS.toMillis(startTimeInNanos - lastStatsQueue) > MIN_PERSISTENCE_INTERVAL)\n+                || ((currentInferenceCount.sum() + 1) % persistenceQuotient == 0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY4NDA0OQ==", "bodyText": "Potentially, but what catastrophic events?\nThe reason for this is so we periodically update stats and if the node crashes, we have some stored.", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395684049", "createdAt": "2020-03-20T14:44:48Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/LocalModel.java", "diffHunk": "@@ -64,17 +100,45 @@ public String getResultsType() {\n         }\n     }\n \n+    void persistStats() {\n+        trainedModelStatsService.queueStats(getLatestStats());\n+        lastStatsQueue = nanoTimeSupplier.get();\n+        if (persistenceQuotient < 1000 && currentInferenceCount.sum() > 1000) {\n+            persistenceQuotient = 1000;\n+        }\n+        if (persistenceQuotient < 10_000 && currentInferenceCount.sum() > 10_000) {\n+            persistenceQuotient = 10_000;\n+        }\n+    }\n+\n     @Override\n     public void infer(Map<String, Object> fields, InferenceConfig config, ActionListener<InferenceResults> listener) {\n         try {\n+            statsAccumulator.incInference();\n+            currentInferenceCount.increment();\n+\n             Model.mapFieldsIfNecessary(fields, defaultFieldMap);\n+\n+            long startTimeInNanos = nanoTimeSupplier.get();\n+            boolean shouldPersistStats =\n+                (TimeUnit.NANOSECONDS.toMillis(startTimeInNanos - lastStatsQueue) > MIN_PERSISTENCE_INTERVAL)\n+                || ((currentInferenceCount.sum() + 1) % persistenceQuotient == 0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTIwMjQyNA=="}, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY5MTY1OA==", "bodyText": "I think it is inevitable to lose some stats on a node failure. But I try my best to lose as little as possible while keeping performance in mind.\nI am sure there is a better solution. I welcome better suggestions on how to handle this.", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395691658", "createdAt": "2020-03-20T14:55:33Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/LocalModel.java", "diffHunk": "@@ -64,17 +100,45 @@ public String getResultsType() {\n         }\n     }\n \n+    void persistStats() {\n+        trainedModelStatsService.queueStats(getLatestStats());\n+        lastStatsQueue = nanoTimeSupplier.get();\n+        if (persistenceQuotient < 1000 && currentInferenceCount.sum() > 1000) {\n+            persistenceQuotient = 1000;\n+        }\n+        if (persistenceQuotient < 10_000 && currentInferenceCount.sum() > 10_000) {\n+            persistenceQuotient = 10_000;\n+        }\n+    }\n+\n     @Override\n     public void infer(Map<String, Object> fields, InferenceConfig config, ActionListener<InferenceResults> listener) {\n         try {\n+            statsAccumulator.incInference();\n+            currentInferenceCount.increment();\n+\n             Model.mapFieldsIfNecessary(fields, defaultFieldMap);\n+\n+            long startTimeInNanos = nanoTimeSupplier.get();\n+            boolean shouldPersistStats =\n+                (TimeUnit.NANOSECONDS.toMillis(startTimeInNanos - lastStatsQueue) > MIN_PERSISTENCE_INTERVAL)\n+                || ((currentInferenceCount.sum() + 1) % persistenceQuotient == 0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTIwMjQyNA=="}, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 110}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0OTYzNjkxOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/persistence/TrainedModelProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxNzo1MTo0NVrOF456fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxNzo1MTo0NVrOF456fw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTIxMzQzOQ==", "bodyText": "\"search failed for model stats\"\nMaybe construct the string and use the same one for the logger and exception message", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395213439", "createdAt": "2020-03-19T17:51:45Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/persistence/TrainedModelProvider.java", "diffHunk": "@@ -453,6 +459,155 @@ public void expandIds(String idExpression,\n             client::search);\n     }\n \n+    public void getInferenceStats(String[] modelIds, ActionListener<List<InferenceStats>> listener) {\n+        MultiSearchRequest multiSearchRequest = new MultiSearchRequest();\n+        Arrays.stream(modelIds).map(this::buildStatsSearchRequest).forEach(multiSearchRequest::add);\n+        if (multiSearchRequest.requests().isEmpty()) {\n+            listener.onResponse(Collections.emptyList());\n+            return;\n+        }\n+        executeAsyncWithOrigin(client.threadPool().getThreadContext(),\n+            ML_ORIGIN,\n+            multiSearchRequest,\n+            ActionListener.<MultiSearchResponse>wrap(\n+                responses -> {\n+                    List<InferenceStats> allStats = new ArrayList<>(modelIds.length);\n+                    int modelIndex = 0;\n+                    assert responses.getResponses().length == modelIds.length :\n+                        \"mismatch between search response size and models requested\";\n+                    for (MultiSearchResponse.Item response : responses.getResponses()) {\n+                        if (response.isFailure()) {\n+                            if (ExceptionsHelper.unwrapCause(response.getFailure()) instanceof ResourceNotFoundException) {\n+                                continue;\n+                            }\n+                            logger.error(new ParameterizedMessage(\"search failed for models [{}]\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0OTY0MjE0OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/persistence/TrainedModelProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxNzo1MzoxMlrOF4594w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxNzo1MzoxMlrOF4594w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTIxNDMwNw==", "bodyText": "modelIndex++;", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395214307", "createdAt": "2020-03-19T17:53:12Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/persistence/TrainedModelProvider.java", "diffHunk": "@@ -453,6 +459,155 @@ public void expandIds(String idExpression,\n             client::search);\n     }\n \n+    public void getInferenceStats(String[] modelIds, ActionListener<List<InferenceStats>> listener) {\n+        MultiSearchRequest multiSearchRequest = new MultiSearchRequest();\n+        Arrays.stream(modelIds).map(this::buildStatsSearchRequest).forEach(multiSearchRequest::add);\n+        if (multiSearchRequest.requests().isEmpty()) {\n+            listener.onResponse(Collections.emptyList());\n+            return;\n+        }\n+        executeAsyncWithOrigin(client.threadPool().getThreadContext(),\n+            ML_ORIGIN,\n+            multiSearchRequest,\n+            ActionListener.<MultiSearchResponse>wrap(\n+                responses -> {\n+                    List<InferenceStats> allStats = new ArrayList<>(modelIds.length);\n+                    int modelIndex = 0;\n+                    assert responses.getResponses().length == modelIds.length :\n+                        \"mismatch between search response size and models requested\";\n+                    for (MultiSearchResponse.Item response : responses.getResponses()) {\n+                        if (response.isFailure()) {\n+                            if (ExceptionsHelper.unwrapCause(response.getFailure()) instanceof ResourceNotFoundException) {\n+                                continue;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0OTY2MjA3OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/persistence/TrainedModelProvider.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxNzo1ODozNFrOF46K8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxODozOTowMFrOF47nJw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTIxNzY1MQ==", "bodyText": "In theory the number of stats docs returned is the number of distinct count of nodes the model was ever open on? And there will be one document for every unique node/model id pair", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395217651", "createdAt": "2020-03-19T17:58:34Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/persistence/TrainedModelProvider.java", "diffHunk": "@@ -453,6 +459,155 @@ public void expandIds(String idExpression,\n             client::search);\n     }\n \n+    public void getInferenceStats(String[] modelIds, ActionListener<List<InferenceStats>> listener) {\n+        MultiSearchRequest multiSearchRequest = new MultiSearchRequest();\n+        Arrays.stream(modelIds).map(this::buildStatsSearchRequest).forEach(multiSearchRequest::add);\n+        if (multiSearchRequest.requests().isEmpty()) {\n+            listener.onResponse(Collections.emptyList());\n+            return;\n+        }\n+        executeAsyncWithOrigin(client.threadPool().getThreadContext(),\n+            ML_ORIGIN,\n+            multiSearchRequest,\n+            ActionListener.<MultiSearchResponse>wrap(\n+                responses -> {\n+                    List<InferenceStats> allStats = new ArrayList<>(modelIds.length);\n+                    int modelIndex = 0;\n+                    assert responses.getResponses().length == modelIds.length :\n+                        \"mismatch between search response size and models requested\";\n+                    for (MultiSearchResponse.Item response : responses.getResponses()) {\n+                        if (response.isFailure()) {\n+                            if (ExceptionsHelper.unwrapCause(response.getFailure()) instanceof ResourceNotFoundException) {\n+                                continue;\n+                            }\n+                            logger.error(new ParameterizedMessage(\"search failed for models [{}]\",\n+                                    Strings.arrayToCommaDelimitedString(modelIds)),\n+                                response.getFailure());\n+                            listener.onFailure(ExceptionsHelper.serverError(\"Searching for stats for models [{}] failed\",\n+                                response.getFailure(),\n+                                Strings.arrayToCommaDelimitedString(modelIds)));\n+                            return;\n+                        }\n+                        try {\n+                            InferenceStats inferenceStats = handleMultiNodeStatsResponse(response.getResponse(), modelIds[modelIndex++]);\n+                            if (inferenceStats != null) {\n+                                allStats.add(inferenceStats);\n+                            }\n+                        } catch (Exception e) {\n+                            listener.onFailure(e);\n+                            return;\n+                        }\n+                    }\n+                    listener.onResponse(allStats);\n+                },\n+                e -> {\n+                    Throwable unwrapped = ExceptionsHelper.unwrapCause(e);\n+                    if (unwrapped instanceof ResourceNotFoundException) {\n+                        listener.onResponse(Collections.emptyList());\n+                        return;\n+                    }\n+                    listener.onFailure((Exception)unwrapped);\n+                }\n+            ),\n+            client::multiSearch);\n+    }\n+\n+    private SearchRequest buildStatsSearchRequest(String modelId) {\n+        BoolQueryBuilder queryBuilder = QueryBuilders.boolQuery()\n+            .filter(QueryBuilders.termQuery(InferenceStats.MODEL_ID.getPreferredName(), modelId))\n+            .filter(QueryBuilders.termQuery(InferenceStats.TYPE.getPreferredName(), InferenceStats.NAME));\n+        return new SearchRequest(MlStatsIndex.indexPattern())\n+            .indicesOptions(IndicesOptions.lenientExpandOpen())\n+            .allowPartialSearchResults(false)\n+            .source(SearchSourceBuilder.searchSource()\n+                .size(MAX_NODE_STATS_SIZE)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI0MTI1NQ==", "bodyText": "Correct, in theory. The issue comes down to how greedy ILM is + the scale of the deployment. If there are 10x previous indices and the model has been deployed on 1000x separate nodes, we would hit the limit.", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r395241255", "createdAt": "2020-03-19T18:39:00Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/persistence/TrainedModelProvider.java", "diffHunk": "@@ -453,6 +459,155 @@ public void expandIds(String idExpression,\n             client::search);\n     }\n \n+    public void getInferenceStats(String[] modelIds, ActionListener<List<InferenceStats>> listener) {\n+        MultiSearchRequest multiSearchRequest = new MultiSearchRequest();\n+        Arrays.stream(modelIds).map(this::buildStatsSearchRequest).forEach(multiSearchRequest::add);\n+        if (multiSearchRequest.requests().isEmpty()) {\n+            listener.onResponse(Collections.emptyList());\n+            return;\n+        }\n+        executeAsyncWithOrigin(client.threadPool().getThreadContext(),\n+            ML_ORIGIN,\n+            multiSearchRequest,\n+            ActionListener.<MultiSearchResponse>wrap(\n+                responses -> {\n+                    List<InferenceStats> allStats = new ArrayList<>(modelIds.length);\n+                    int modelIndex = 0;\n+                    assert responses.getResponses().length == modelIds.length :\n+                        \"mismatch between search response size and models requested\";\n+                    for (MultiSearchResponse.Item response : responses.getResponses()) {\n+                        if (response.isFailure()) {\n+                            if (ExceptionsHelper.unwrapCause(response.getFailure()) instanceof ResourceNotFoundException) {\n+                                continue;\n+                            }\n+                            logger.error(new ParameterizedMessage(\"search failed for models [{}]\",\n+                                    Strings.arrayToCommaDelimitedString(modelIds)),\n+                                response.getFailure());\n+                            listener.onFailure(ExceptionsHelper.serverError(\"Searching for stats for models [{}] failed\",\n+                                response.getFailure(),\n+                                Strings.arrayToCommaDelimitedString(modelIds)));\n+                            return;\n+                        }\n+                        try {\n+                            InferenceStats inferenceStats = handleMultiNodeStatsResponse(response.getResponse(), modelIds[modelIndex++]);\n+                            if (inferenceStats != null) {\n+                                allStats.add(inferenceStats);\n+                            }\n+                        } catch (Exception e) {\n+                            listener.onFailure(e);\n+                            return;\n+                        }\n+                    }\n+                    listener.onResponse(allStats);\n+                },\n+                e -> {\n+                    Throwable unwrapped = ExceptionsHelper.unwrapCause(e);\n+                    if (unwrapped instanceof ResourceNotFoundException) {\n+                        listener.onResponse(Collections.emptyList());\n+                        return;\n+                    }\n+                    listener.onFailure((Exception)unwrapped);\n+                }\n+            ),\n+            client::multiSearch);\n+    }\n+\n+    private SearchRequest buildStatsSearchRequest(String modelId) {\n+        BoolQueryBuilder queryBuilder = QueryBuilders.boolQuery()\n+            .filter(QueryBuilders.termQuery(InferenceStats.MODEL_ID.getPreferredName(), modelId))\n+            .filter(QueryBuilders.termQuery(InferenceStats.TYPE.getPreferredName(), InferenceStats.NAME));\n+        return new SearchRequest(MlStatsIndex.indexPattern())\n+            .indicesOptions(IndicesOptions.lenientExpandOpen())\n+            .allowPartialSearchResults(false)\n+            .source(SearchSourceBuilder.searchSource()\n+                .size(MAX_NODE_STATS_SIZE)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTIxNzY1MQ=="}, "originalCommit": {"oid": "c406e8e542dd6ad4e503c0cb4dd75ffdb5c4988f"}, "originalPosition": 112}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1OTAyMzQ1OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yM1QxODo0Nzo1OFrOF6Taig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxMTo1OToyOFrOF-SQKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjY3OTgxOA==", "bodyText": "I know we are using the utility threadpool but this should really be aysnc i think. Maybe use ThreadedActionListener to ensure the nexts steps are done on the ML utility thread pool", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r396679818", "createdAt": "2020-03-23T18:47:58Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.inference;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkRequest;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.action.update.UpdateRequest;\n+import org.elasticsearch.client.OriginSettingClient;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.component.LifecycleListener;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.script.Script;\n+import org.elasticsearch.script.ScriptType;\n+import org.elasticsearch.threadpool.Scheduler;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ml.MlStatsIndex;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.InferenceStats;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.elasticsearch.xpack.ml.MachineLearning;\n+import org.elasticsearch.xpack.ml.utils.persistence.ResultsPersisterService;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+\n+\n+public class TrainedModelStatsService {\n+\n+    private static final Logger logger = LogManager.getLogger(TrainedModelStatsService.class);\n+\n+    // Script to only update if stats have increased since last persistence\n+    private static final String STATS_UPDATE_SCRIPT = \"\" +\n+        \"if (ctx._source.missing_all_fields_count >= params.missing_all_fields_count\\n\" +\n+        \"     && ctx._source.inference_count >= params.inference_count\\n\" +\n+        \"     && ctx._source.total_time_spent_millis >= params.total_time_spent_millis\\n\" +\n+        \"     && ctx._source.failure_count >= params.failure_count) {\\n\" +\n+        \"      ctx.op = 'none';\\n\" +\n+        \"      return;\\n\" +\n+        \"    }\\n\" +\n+        \"    ctx._source.missing_all_fields_count = params.missing_all_fields_count;\\n\" +\n+        \"    ctx._source.inference_count = params.inference_count;\\n\" +\n+        \"    ctx._source.total_time_spent_millis = params.total_time_spent_millis;\\n\" +\n+        \"    ctx._source.failure_count = params.failure_count;\\n\" +\n+        \"    ctx._source.time_stamp = params.time_stamp;\";\n+    private static final ToXContent.Params FOR_INTERNAL_STORAGE_PARAMS =\n+        new ToXContent.MapParams(Collections.singletonMap(ToXContentParams.FOR_INTERNAL_STORAGE, \"true\"));\n+\n+    private final Map<String, InferenceStats> statsQueue;\n+    private final ResultsPersisterService resultsPersisterService;\n+    private final OriginSettingClient client;\n+    private final IndexNameExpressionResolver indexNameExpressionResolver;\n+    private final ThreadPool threadPool;\n+    private volatile Scheduler.Cancellable scheduledFuture;\n+    private volatile boolean verifiedStatsIndexCreated;\n+    private volatile boolean stopped;\n+    private volatile ClusterState clusterState;\n+\n+    public TrainedModelStatsService(ResultsPersisterService resultsPersisterService,\n+                                    OriginSettingClient client,\n+                                    IndexNameExpressionResolver indexNameExpressionResolver,\n+                                    ClusterService clusterService,\n+                                    ThreadPool threadPool) {\n+        this.resultsPersisterService = resultsPersisterService;\n+        this.client = client;\n+        this.indexNameExpressionResolver = indexNameExpressionResolver;\n+        this.threadPool = threadPool;\n+        this.statsQueue = new ConcurrentHashMap<>();\n+\n+        clusterService.addLifecycleListener(new LifecycleListener() {\n+            @Override\n+            public void beforeStart() {\n+                start();\n+            }\n+\n+            @Override\n+            public void beforeStop() {\n+                stop();\n+            }\n+        });\n+        clusterService.addListener((event) -> this.clusterState = event.state());\n+    }\n+\n+    public void queueStats(InferenceStats stats) {\n+        statsQueue.put(InferenceStats.docId(stats.getModelId(), stats.getNodeId()), stats);\n+    }\n+\n+    void stop() {\n+        stopped = true;\n+        statsQueue.clear();\n+\n+        ThreadPool.Cancellable cancellable = this.scheduledFuture;\n+        if (cancellable != null) {\n+            cancellable.cancel();\n+        }\n+    }\n+\n+    void start() {\n+        stopped = false;\n+        scheduledFuture = threadPool.scheduleWithFixedDelay(this::persistStats,\n+            TimeValue.timeValueSeconds(1),\n+            MachineLearning.UTILITY_THREAD_POOL_NAME);\n+    }\n+\n+    void persistStats() {\n+        if (clusterState == null || statsQueue.isEmpty()) {\n+            return;\n+        }\n+\n+        List<InferenceStats> stats = new ArrayList<>(statsQueue.size());\n+        for(String k : statsQueue.keySet()) {\n+            InferenceStats inferenceStats = statsQueue.remove(k);\n+            if (inferenceStats != null) {\n+                stats.add(inferenceStats);\n+            }\n+        }\n+        if (stats.isEmpty()) {\n+            return;\n+        }\n+        if (verifiedStatsIndexCreated == false) {\n+            try {\n+                PlainActionFuture<Boolean> listener = new PlainActionFuture<>();\n+                MlStatsIndex.createStatsIndexAndAliasIfNecessary(client, clusterState, indexNameExpressionResolver, listener);\n+                listener.actionGet();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6bf2263eaf42762dd92df701ee5a77ce099f6815"}, "originalPosition": 141}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg1NTA4Mg==", "bodyText": "If this was async, the calling thread would exit before it finished. It could get triggered again before this update has completed.", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r400855082", "createdAt": "2020-03-31T11:59:28Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.inference;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkRequest;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.action.update.UpdateRequest;\n+import org.elasticsearch.client.OriginSettingClient;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.component.LifecycleListener;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.script.Script;\n+import org.elasticsearch.script.ScriptType;\n+import org.elasticsearch.threadpool.Scheduler;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ml.MlStatsIndex;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.InferenceStats;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.elasticsearch.xpack.ml.MachineLearning;\n+import org.elasticsearch.xpack.ml.utils.persistence.ResultsPersisterService;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+\n+\n+public class TrainedModelStatsService {\n+\n+    private static final Logger logger = LogManager.getLogger(TrainedModelStatsService.class);\n+\n+    // Script to only update if stats have increased since last persistence\n+    private static final String STATS_UPDATE_SCRIPT = \"\" +\n+        \"if (ctx._source.missing_all_fields_count >= params.missing_all_fields_count\\n\" +\n+        \"     && ctx._source.inference_count >= params.inference_count\\n\" +\n+        \"     && ctx._source.total_time_spent_millis >= params.total_time_spent_millis\\n\" +\n+        \"     && ctx._source.failure_count >= params.failure_count) {\\n\" +\n+        \"      ctx.op = 'none';\\n\" +\n+        \"      return;\\n\" +\n+        \"    }\\n\" +\n+        \"    ctx._source.missing_all_fields_count = params.missing_all_fields_count;\\n\" +\n+        \"    ctx._source.inference_count = params.inference_count;\\n\" +\n+        \"    ctx._source.total_time_spent_millis = params.total_time_spent_millis;\\n\" +\n+        \"    ctx._source.failure_count = params.failure_count;\\n\" +\n+        \"    ctx._source.time_stamp = params.time_stamp;\";\n+    private static final ToXContent.Params FOR_INTERNAL_STORAGE_PARAMS =\n+        new ToXContent.MapParams(Collections.singletonMap(ToXContentParams.FOR_INTERNAL_STORAGE, \"true\"));\n+\n+    private final Map<String, InferenceStats> statsQueue;\n+    private final ResultsPersisterService resultsPersisterService;\n+    private final OriginSettingClient client;\n+    private final IndexNameExpressionResolver indexNameExpressionResolver;\n+    private final ThreadPool threadPool;\n+    private volatile Scheduler.Cancellable scheduledFuture;\n+    private volatile boolean verifiedStatsIndexCreated;\n+    private volatile boolean stopped;\n+    private volatile ClusterState clusterState;\n+\n+    public TrainedModelStatsService(ResultsPersisterService resultsPersisterService,\n+                                    OriginSettingClient client,\n+                                    IndexNameExpressionResolver indexNameExpressionResolver,\n+                                    ClusterService clusterService,\n+                                    ThreadPool threadPool) {\n+        this.resultsPersisterService = resultsPersisterService;\n+        this.client = client;\n+        this.indexNameExpressionResolver = indexNameExpressionResolver;\n+        this.threadPool = threadPool;\n+        this.statsQueue = new ConcurrentHashMap<>();\n+\n+        clusterService.addLifecycleListener(new LifecycleListener() {\n+            @Override\n+            public void beforeStart() {\n+                start();\n+            }\n+\n+            @Override\n+            public void beforeStop() {\n+                stop();\n+            }\n+        });\n+        clusterService.addListener((event) -> this.clusterState = event.state());\n+    }\n+\n+    public void queueStats(InferenceStats stats) {\n+        statsQueue.put(InferenceStats.docId(stats.getModelId(), stats.getNodeId()), stats);\n+    }\n+\n+    void stop() {\n+        stopped = true;\n+        statsQueue.clear();\n+\n+        ThreadPool.Cancellable cancellable = this.scheduledFuture;\n+        if (cancellable != null) {\n+            cancellable.cancel();\n+        }\n+    }\n+\n+    void start() {\n+        stopped = false;\n+        scheduledFuture = threadPool.scheduleWithFixedDelay(this::persistStats,\n+            TimeValue.timeValueSeconds(1),\n+            MachineLearning.UTILITY_THREAD_POOL_NAME);\n+    }\n+\n+    void persistStats() {\n+        if (clusterState == null || statsQueue.isEmpty()) {\n+            return;\n+        }\n+\n+        List<InferenceStats> stats = new ArrayList<>(statsQueue.size());\n+        for(String k : statsQueue.keySet()) {\n+            InferenceStats inferenceStats = statsQueue.remove(k);\n+            if (inferenceStats != null) {\n+                stats.add(inferenceStats);\n+            }\n+        }\n+        if (stats.isEmpty()) {\n+            return;\n+        }\n+        if (verifiedStatsIndexCreated == false) {\n+            try {\n+                PlainActionFuture<Boolean> listener = new PlainActionFuture<>();\n+                MlStatsIndex.createStatsIndexAndAliasIfNecessary(client, clusterState, indexNameExpressionResolver, listener);\n+                listener.actionGet();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjY3OTgxOA=="}, "originalCommit": {"oid": "6bf2263eaf42762dd92df701ee5a77ce099f6815"}, "originalPosition": 141}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1OTA4ODE0OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/ModelLoadingService.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yM1QxOTowNjozN1rOF6UExQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxMjoxMjowOFrOF-Sr-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjY5MDYyOQ==", "bodyText": "Even if is replaced it is replaced by a model that read the old persisted stats. Should it not always persist so changes are captured.", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r396690629", "createdAt": "2020-03-23T19:06:37Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/ModelLoadingService.java", "diffHunk": "@@ -235,17 +250,20 @@ private void handleLoadFailure(String modelId, Exception failure) {\n \n     private void cacheEvictionListener(RemovalNotification<String, LocalModel> notification) {\n         if (notification.getRemovalReason() == RemovalNotification.RemovalReason.EVICTED) {\n-            String msg = new ParameterizedMessage(\n+            MessageSupplier msg = () -> new ParameterizedMessage(\n                 \"model cache entry evicted.\" +\n                     \"current cache [{}] current max [{}] model size [{}]. \" +\n                     \"If this is undesired, consider updating setting [{}] or [{}].\",\n                 new ByteSizeValue(localModelCache.weight()).getStringRep(),\n                 maxCacheSize.getStringRep(),\n                 new ByteSizeValue(notification.getValue().ramBytesUsed()).getStringRep(),\n                 INFERENCE_MODEL_CACHE_SIZE.getKey(),\n-                INFERENCE_MODEL_CACHE_TTL.getKey()).getFormattedMessage();\n+                INFERENCE_MODEL_CACHE_TTL.getKey());\n             auditIfNecessary(notification.getKey(), msg);\n         }\n+        if (notification.getRemovalReason() != RemovalNotification.RemovalReason.REPLACED) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6bf2263eaf42762dd92df701ee5a77ce099f6815"}, "originalPosition": 153}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg2MjIwMw==", "bodyText": "True.\nI also don't see where in the code a cache replace is even possible. But, persisting even on replace protects us some from losing stats.", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r400862203", "createdAt": "2020-03-31T12:12:08Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/ModelLoadingService.java", "diffHunk": "@@ -235,17 +250,20 @@ private void handleLoadFailure(String modelId, Exception failure) {\n \n     private void cacheEvictionListener(RemovalNotification<String, LocalModel> notification) {\n         if (notification.getRemovalReason() == RemovalNotification.RemovalReason.EVICTED) {\n-            String msg = new ParameterizedMessage(\n+            MessageSupplier msg = () -> new ParameterizedMessage(\n                 \"model cache entry evicted.\" +\n                     \"current cache [{}] current max [{}] model size [{}]. \" +\n                     \"If this is undesired, consider updating setting [{}] or [{}].\",\n                 new ByteSizeValue(localModelCache.weight()).getStringRep(),\n                 maxCacheSize.getStringRep(),\n                 new ByteSizeValue(notification.getValue().ramBytesUsed()).getStringRep(),\n                 INFERENCE_MODEL_CACHE_SIZE.getKey(),\n-                INFERENCE_MODEL_CACHE_TTL.getKey()).getFormattedMessage();\n+                INFERENCE_MODEL_CACHE_TTL.getKey());\n             auditIfNecessary(notification.getKey(), msg);\n         }\n+        if (notification.getRemovalReason() != RemovalNotification.RemovalReason.REPLACED) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjY5MDYyOQ=="}, "originalCommit": {"oid": "6bf2263eaf42762dd92df701ee5a77ce099f6815"}, "originalPosition": 153}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1OTA5NjAzOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yM1QxOTowODo1NlrOF6UJ3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yM1QxOTowODo1NlrOF6UJ3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjY5MTkzMw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                void persistStats() {\n          \n          \n            \n                void updateStats() {\n          \n      \n    \n    \n  \n\nTo me persistStats() makes me think they are being overwritten and update is clearer. That's how I see it anyway many people may disagree", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r396691933", "createdAt": "2020-03-23T19:08:56Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.inference;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkRequest;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.action.update.UpdateRequest;\n+import org.elasticsearch.client.OriginSettingClient;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.component.LifecycleListener;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.script.Script;\n+import org.elasticsearch.script.ScriptType;\n+import org.elasticsearch.threadpool.Scheduler;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ml.MlStatsIndex;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.InferenceStats;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.elasticsearch.xpack.ml.MachineLearning;\n+import org.elasticsearch.xpack.ml.utils.persistence.ResultsPersisterService;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+\n+\n+public class TrainedModelStatsService {\n+\n+    private static final Logger logger = LogManager.getLogger(TrainedModelStatsService.class);\n+\n+    // Script to only update if stats have increased since last persistence\n+    private static final String STATS_UPDATE_SCRIPT = \"\" +\n+        \"if (ctx._source.missing_all_fields_count >= params.missing_all_fields_count\\n\" +\n+        \"     && ctx._source.inference_count >= params.inference_count\\n\" +\n+        \"     && ctx._source.total_time_spent_millis >= params.total_time_spent_millis\\n\" +\n+        \"     && ctx._source.failure_count >= params.failure_count) {\\n\" +\n+        \"      ctx.op = 'none';\\n\" +\n+        \"      return;\\n\" +\n+        \"    }\\n\" +\n+        \"    ctx._source.missing_all_fields_count = params.missing_all_fields_count;\\n\" +\n+        \"    ctx._source.inference_count = params.inference_count;\\n\" +\n+        \"    ctx._source.total_time_spent_millis = params.total_time_spent_millis;\\n\" +\n+        \"    ctx._source.failure_count = params.failure_count;\\n\" +\n+        \"    ctx._source.time_stamp = params.time_stamp;\";\n+    private static final ToXContent.Params FOR_INTERNAL_STORAGE_PARAMS =\n+        new ToXContent.MapParams(Collections.singletonMap(ToXContentParams.FOR_INTERNAL_STORAGE, \"true\"));\n+\n+    private final Map<String, InferenceStats> statsQueue;\n+    private final ResultsPersisterService resultsPersisterService;\n+    private final OriginSettingClient client;\n+    private final IndexNameExpressionResolver indexNameExpressionResolver;\n+    private final ThreadPool threadPool;\n+    private volatile Scheduler.Cancellable scheduledFuture;\n+    private volatile boolean verifiedStatsIndexCreated;\n+    private volatile boolean stopped;\n+    private volatile ClusterState clusterState;\n+\n+    public TrainedModelStatsService(ResultsPersisterService resultsPersisterService,\n+                                    OriginSettingClient client,\n+                                    IndexNameExpressionResolver indexNameExpressionResolver,\n+                                    ClusterService clusterService,\n+                                    ThreadPool threadPool) {\n+        this.resultsPersisterService = resultsPersisterService;\n+        this.client = client;\n+        this.indexNameExpressionResolver = indexNameExpressionResolver;\n+        this.threadPool = threadPool;\n+        this.statsQueue = new ConcurrentHashMap<>();\n+\n+        clusterService.addLifecycleListener(new LifecycleListener() {\n+            @Override\n+            public void beforeStart() {\n+                start();\n+            }\n+\n+            @Override\n+            public void beforeStop() {\n+                stop();\n+            }\n+        });\n+        clusterService.addListener((event) -> this.clusterState = event.state());\n+    }\n+\n+    public void queueStats(InferenceStats stats) {\n+        statsQueue.put(InferenceStats.docId(stats.getModelId(), stats.getNodeId()), stats);\n+    }\n+\n+    void stop() {\n+        stopped = true;\n+        statsQueue.clear();\n+\n+        ThreadPool.Cancellable cancellable = this.scheduledFuture;\n+        if (cancellable != null) {\n+            cancellable.cancel();\n+        }\n+    }\n+\n+    void start() {\n+        stopped = false;\n+        scheduledFuture = threadPool.scheduleWithFixedDelay(this::persistStats,\n+            TimeValue.timeValueSeconds(1),\n+            MachineLearning.UTILITY_THREAD_POOL_NAME);\n+    }\n+\n+    void persistStats() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6bf2263eaf42762dd92df701ee5a77ce099f6815"}, "originalPosition": 122}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NDg1NzMxOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjoyNDowN1rOF_ostQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjoyNDowN1rOF_ostQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI3MTQxMw==", "bodyText": "Can total_time_spent_millis be removed now?", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r402271413", "createdAt": "2020-04-02T12:24:07Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "diffHunk": "@@ -0,0 +1,184 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.inference;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkRequest;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.action.update.UpdateRequest;\n+import org.elasticsearch.client.OriginSettingClient;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.component.LifecycleListener;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.script.Script;\n+import org.elasticsearch.script.ScriptType;\n+import org.elasticsearch.threadpool.Scheduler;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ml.MlStatsIndex;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.InferenceStats;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.elasticsearch.xpack.ml.MachineLearning;\n+import org.elasticsearch.xpack.ml.utils.persistence.ResultsPersisterService;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+\n+\n+public class TrainedModelStatsService {\n+\n+    private static final Logger logger = LogManager.getLogger(TrainedModelStatsService.class);\n+\n+    // Script to only update if stats have increased since last persistence\n+    private static final String STATS_UPDATE_SCRIPT = \"\" +\n+        \"if (ctx._source.missing_all_fields_count >= params.missing_all_fields_count\\n\" +\n+        \"     && ctx._source.inference_count >= params.inference_count\\n\" +\n+        \"     && ctx._source.total_time_spent_millis >= params.total_time_spent_millis\\n\" +\n+        \"     && ctx._source.failure_count >= params.failure_count) {\\n\" +\n+        \"      ctx.op = 'none';\\n\" +\n+        \"      return;\\n\" +\n+        \"    }\\n\" +\n+        \"    ctx._source.missing_all_fields_count = params.missing_all_fields_count;\\n\" +\n+        \"    ctx._source.inference_count = params.inference_count;\\n\" +\n+        \"    ctx._source.total_time_spent_millis = params.total_time_spent_millis;\\n\" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "650947b4df331597595ce4ab1f553cd0e9ce484a"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NDg2MDcyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/main/resources/org/elasticsearch/xpack/core/ml/stats_index_mappings.json", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjoyNDo0OVrOF_ouog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjoyNDo0OVrOF_ouog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI3MTkwNg==", "bodyText": "No longer required?", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r402271906", "createdAt": "2020-04-02T12:24:49Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/core/src/main/resources/org/elasticsearch/xpack/core/ml/stats_index_mappings.json", "diffHunk": "@@ -85,6 +85,24 @@\n       \"peak_usage_bytes\" : {\n         \"type\" : \"long\"\n       },\n+      \"model_id\": {\n+        \"type\": \"keyword\"\n+      },\n+      \"node_id\": {\n+        \"type\": \"keyword\"\n+      },\n+      \"inference_count\": {\n+        \"type\": \"long\"\n+      },\n+      \"total_time_spent_millis\": {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "650947b4df331597595ce4ab1f553cd0e9ce484a"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NTY4NDQyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "isResolved": true, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNToyODoyOFrOF_w0Vw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxMjoyODo0N1rOGATUEw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwNDQzOQ==", "bodyText": "I don't see how an update could be queued with at least one field having changed am I missing something?", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r402404439", "createdAt": "2020-04-02T15:28:28Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "diffHunk": "@@ -0,0 +1,184 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.inference;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkRequest;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.action.update.UpdateRequest;\n+import org.elasticsearch.client.OriginSettingClient;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.component.LifecycleListener;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.script.Script;\n+import org.elasticsearch.script.ScriptType;\n+import org.elasticsearch.threadpool.Scheduler;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ml.MlStatsIndex;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.InferenceStats;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.elasticsearch.xpack.ml.MachineLearning;\n+import org.elasticsearch.xpack.ml.utils.persistence.ResultsPersisterService;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+\n+\n+public class TrainedModelStatsService {\n+\n+    private static final Logger logger = LogManager.getLogger(TrainedModelStatsService.class);\n+\n+    // Script to only update if stats have increased since last persistence\n+    private static final String STATS_UPDATE_SCRIPT = \"\" +\n+        \"if (ctx._source.missing_all_fields_count >= params.missing_all_fields_count\\n\" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "650947b4df331597595ce4ab1f553cd0e9ce484a"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjUwNjM2OQ==", "bodyText": "This is to protect against non-monotonically increasing stats.\nThere is a pathological scenario where:\n\nmodel is loaded\nwrites stats\nunloaded\nreloaded before previous stats write occurs and starts at the previous values\nattempts to write stats again, but the new values could be lower than the previously written ones.\n\nScenarios like this one are where I wish I could use optimistic concurrency, but since the underlying indices are ILM managed, I don't know when an index switches out from under the process :/. This FEELS like a fundamental flaw with optimistic concurrency and ILM. I really wish there was a POST where it either HAS to match the seq_no and primary_term OR if the doc doesn't exist, create it.", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r402506369", "createdAt": "2020-04-02T17:57:24Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "diffHunk": "@@ -0,0 +1,184 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.inference;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkRequest;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.action.update.UpdateRequest;\n+import org.elasticsearch.client.OriginSettingClient;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.component.LifecycleListener;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.script.Script;\n+import org.elasticsearch.script.ScriptType;\n+import org.elasticsearch.threadpool.Scheduler;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ml.MlStatsIndex;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.InferenceStats;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.elasticsearch.xpack.ml.MachineLearning;\n+import org.elasticsearch.xpack.ml.utils.persistence.ResultsPersisterService;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+\n+\n+public class TrainedModelStatsService {\n+\n+    private static final Logger logger = LogManager.getLogger(TrainedModelStatsService.class);\n+\n+    // Script to only update if stats have increased since last persistence\n+    private static final String STATS_UPDATE_SCRIPT = \"\" +\n+        \"if (ctx._source.missing_all_fields_count >= params.missing_all_fields_count\\n\" +", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwNDQzOQ=="}, "originalCommit": {"oid": "650947b4df331597595ce4ab1f553cd0e9ce484a"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjUyNjMyNg==", "bodyText": "This complexity makes me think that one of the following might have to be done\n\n\nstats should be append only for inference some how (sum aggs to pull them together). This feels like we could have tons of docs being written to the .ml-stats index, but is the easiest solution for now...\n\n\nwe don't use the .ml-stats index and do something similar to transforms (keeping track of the original underlying index name). This adds complexity as we now have yet another index, alias woes, and we will have to add optimistic concurrency controls between the stats persister and the thing persisting the stats.", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r402526326", "createdAt": "2020-04-02T18:31:35Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "diffHunk": "@@ -0,0 +1,184 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.inference;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkRequest;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.action.update.UpdateRequest;\n+import org.elasticsearch.client.OriginSettingClient;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.component.LifecycleListener;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.script.Script;\n+import org.elasticsearch.script.ScriptType;\n+import org.elasticsearch.threadpool.Scheduler;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ml.MlStatsIndex;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.InferenceStats;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.elasticsearch.xpack.ml.MachineLearning;\n+import org.elasticsearch.xpack.ml.utils.persistence.ResultsPersisterService;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+\n+\n+public class TrainedModelStatsService {\n+\n+    private static final Logger logger = LogManager.getLogger(TrainedModelStatsService.class);\n+\n+    // Script to only update if stats have increased since last persistence\n+    private static final String STATS_UPDATE_SCRIPT = \"\" +\n+        \"if (ctx._source.missing_all_fields_count >= params.missing_all_fields_count\\n\" +", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwNDQzOQ=="}, "originalCommit": {"oid": "650947b4df331597595ce4ab1f553cd0e9ce484a"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjg0MTYzMw==", "bodyText": "Silly question why can't you increment the fields in the upsert, that way it doesn't matter if the updates arrive out of order. The stats accumulator would have to change track only the changes since the last persist but that is simple enough\nctx._source.missing_all_fields_count += params.missing_all_fields_count;", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r402841633", "createdAt": "2020-04-03T08:41:36Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "diffHunk": "@@ -0,0 +1,184 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.inference;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkRequest;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.action.update.UpdateRequest;\n+import org.elasticsearch.client.OriginSettingClient;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.component.LifecycleListener;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.script.Script;\n+import org.elasticsearch.script.ScriptType;\n+import org.elasticsearch.threadpool.Scheduler;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ml.MlStatsIndex;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.InferenceStats;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.elasticsearch.xpack.ml.MachineLearning;\n+import org.elasticsearch.xpack.ml.utils.persistence.ResultsPersisterService;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+\n+\n+public class TrainedModelStatsService {\n+\n+    private static final Logger logger = LogManager.getLogger(TrainedModelStatsService.class);\n+\n+    // Script to only update if stats have increased since last persistence\n+    private static final String STATS_UPDATE_SCRIPT = \"\" +\n+        \"if (ctx._source.missing_all_fields_count >= params.missing_all_fields_count\\n\" +", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwNDQzOQ=="}, "originalCommit": {"oid": "650947b4df331597595ce4ab1f553cd0e9ce484a"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjk0MjYzMg==", "bodyText": "\ud83e\udd14\nI will work on it. I think this SHOULD work, my original design was not assuming a single input queue. Here, we do have a single persistence queue that guarantees order.", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r402942632", "createdAt": "2020-04-03T11:34:01Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "diffHunk": "@@ -0,0 +1,184 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.inference;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkRequest;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.action.update.UpdateRequest;\n+import org.elasticsearch.client.OriginSettingClient;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.component.LifecycleListener;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.script.Script;\n+import org.elasticsearch.script.ScriptType;\n+import org.elasticsearch.threadpool.Scheduler;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ml.MlStatsIndex;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.InferenceStats;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.elasticsearch.xpack.ml.MachineLearning;\n+import org.elasticsearch.xpack.ml.utils.persistence.ResultsPersisterService;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+\n+\n+public class TrainedModelStatsService {\n+\n+    private static final Logger logger = LogManager.getLogger(TrainedModelStatsService.class);\n+\n+    // Script to only update if stats have increased since last persistence\n+    private static final String STATS_UPDATE_SCRIPT = \"\" +\n+        \"if (ctx._source.missing_all_fields_count >= params.missing_all_fields_count\\n\" +", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwNDQzOQ=="}, "originalCommit": {"oid": "650947b4df331597595ce4ab1f553cd0e9ce484a"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjk2OTYxOQ==", "bodyText": "The counters are not thread safe when reset to 0\nThe way to address this would be to keep track of the inference stats in LocalModel with an atomic reference. Then when stats are persisted to swap it out with a new one. I am not 100% of the performance impact.\nRight now performance is not really measured. So \ud83e\udd37\u200d\u2642", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r402969619", "createdAt": "2020-04-03T12:28:47Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "diffHunk": "@@ -0,0 +1,184 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.inference;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkRequest;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.action.update.UpdateRequest;\n+import org.elasticsearch.client.OriginSettingClient;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.component.LifecycleListener;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.script.Script;\n+import org.elasticsearch.script.ScriptType;\n+import org.elasticsearch.threadpool.Scheduler;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ml.MlStatsIndex;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.InferenceStats;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.elasticsearch.xpack.ml.MachineLearning;\n+import org.elasticsearch.xpack.ml.utils.persistence.ResultsPersisterService;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+\n+\n+public class TrainedModelStatsService {\n+\n+    private static final Logger logger = LogManager.getLogger(TrainedModelStatsService.class);\n+\n+    // Script to only update if stats have increased since last persistence\n+    private static final String STATS_UPDATE_SCRIPT = \"\" +\n+        \"if (ctx._source.missing_all_fields_count >= params.missing_all_fields_count\\n\" +", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwNDQzOQ=="}, "originalCommit": {"oid": "650947b4df331597595ce4ab1f553cd0e9ce484a"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5OTk5NDA4OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxNTowODowN1rOGAZoWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxNTowODowN1rOGAZoWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzA3MzExMw==", "bodyText": "Yikes! good catch", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r403073113", "createdAt": "2020-04-03T15:08:07Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/TrainedModelStatsService.java", "diffHunk": "@@ -97,7 +92,8 @@ public void beforeStop() {\n     }\n \n     public void queueStats(InferenceStats stats) {\n-        statsQueue.put(InferenceStats.docId(stats.getModelId(), stats.getNodeId()), stats);\n+        statsQueue.computeIfPresent(InferenceStats.docId(stats.getModelId(), stats.getNodeId()),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0360c3b79da834b2ab01b3aff3cc3e2a4d38f812"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwMDAyNzI1OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/LocalModel.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxNToxNjoxNVrOGAZ9LQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxNToxNjoxNVrOGAZ9LQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzA3ODQ0NQ==", "bodyText": "\ud83d\udc4d", "url": "https://github.com/elastic/elasticsearch/pull/53429#discussion_r403078445", "createdAt": "2020-04-03T15:16:15Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/LocalModel.java", "diffHunk": "@@ -67,8 +70,9 @@ public String getModelId() {\n     }\n \n     @Override\n-    public InferenceStats getLatestStats() {\n-        return statsAccumulator.currentStats();\n+    public InferenceStats getLatestStatsAndReset() {\n+        InferenceStats.Accumulator toPersist = statsAccumulator.getAndSet(new InferenceStats.Accumulator(modelId, nodeId));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0360c3b79da834b2ab01b3aff3cc3e2a4d38f812"}, "originalPosition": 46}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3298, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}