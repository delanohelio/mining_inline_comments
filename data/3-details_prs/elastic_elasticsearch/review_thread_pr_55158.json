{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDAzMjE1MDcy", "number": 55158, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QwOTo0MjoyMVrODy1iAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QxNjo0MDoyN1rODy-HQA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0NjMyNDQ5OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/index/search/QueryStringQueryParser.java", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QwOTo0MjoyMVrOGHHRxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QxMjo1NDo0OFrOGHMxyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDExMjQ1NQ==", "bodyText": "I don't think this is needed. We can check the limit in QueryStringQueryParser#extractMultiFields, which is called every time we parse a block.", "url": "https://github.com/elastic/elasticsearch/pull/55158#discussion_r410112455", "createdAt": "2020-04-17T09:42:21Z", "author": {"login": "jimczi"}, "path": "server/src/main/java/org/elasticsearch/index/search/QueryStringQueryParser.java", "diffHunk": "@@ -97,6 +100,9 @@\n     private MultiTermQuery.RewriteMethod fuzzyRewriteMethod;\n     private boolean fuzzyTranspositions = FuzzyQuery.defaultTranspositions;\n \n+    // set of field names this parser targets, used to check limits on expanded field names\n+    private Set<String> queriedFields = new HashSet<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7710744d0d37f208dd0244ba7addf120b18c8cbc"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDEzNTIwNg==", "bodyText": "My understanding might be off here, but my assumption was that \"extractMultiFields\" gets called for every block, so e.g. for a query string like \"f1:foo f2:bar f3:baz\" it gets called three different times for one field each call. In order to get the number of fields really queried we'd need to at least have a counter somewhere, and in oder to check for duplicates (e.g. \"f1:foo f1:bar f2:baz\" which should only count for two fields) we'd need something to store the field names already used. This is why I introduced this string set here thats filled with each call to extractMultiFields. Does this make sense or what am I missing?", "url": "https://github.com/elastic/elasticsearch/pull/55158#discussion_r410135206", "createdAt": "2020-04-17T10:26:57Z", "author": {"login": "cbuescher"}, "path": "server/src/main/java/org/elasticsearch/index/search/QueryStringQueryParser.java", "diffHunk": "@@ -97,6 +100,9 @@\n     private MultiTermQuery.RewriteMethod fuzzyRewriteMethod;\n     private boolean fuzzyTranspositions = FuzzyQuery.defaultTranspositions;\n \n+    // set of field names this parser targets, used to check limits on expanded field names\n+    private Set<String> queriedFields = new HashSet<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDExMjQ1NQ=="}, "originalCommit": {"oid": "7710744d0d37f208dd0244ba7addf120b18c8cbc"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDEzOTE4OA==", "bodyText": "I see what you mean but I am not sure that we need to sum all fields. We want to check the limit on each block eagerly, not the total of clauses.", "url": "https://github.com/elastic/elasticsearch/pull/55158#discussion_r410139188", "createdAt": "2020-04-17T10:35:23Z", "author": {"login": "jimczi"}, "path": "server/src/main/java/org/elasticsearch/index/search/QueryStringQueryParser.java", "diffHunk": "@@ -97,6 +100,9 @@\n     private MultiTermQuery.RewriteMethod fuzzyRewriteMethod;\n     private boolean fuzzyTranspositions = FuzzyQuery.defaultTranspositions;\n \n+    // set of field names this parser targets, used to check limits on expanded field names\n+    private Set<String> queriedFields = new HashSet<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDExMjQ1NQ=="}, "originalCommit": {"oid": "7710744d0d37f208dd0244ba7addf120b18c8cbc"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDE5MDM5MQ==", "bodyText": "Ok, just to re-check my understanding, because I might have thought about a different goal in this fix. Assuming we have indices.query.bool.max_clause_count set to 50 and query string like \"foo*:somevalue bar*:otherValue\", and both expressions expand to 40 mapped fields, would we want to accept or reject that? In the end we are targetting 80 fields, so my assumption was that we'd want to sum here, but I'm also fine with another interpretation. Although that can easily lead to the number of fields that are hit by a search can be much larger than the limit?", "url": "https://github.com/elastic/elasticsearch/pull/55158#discussion_r410190391", "createdAt": "2020-04-17T12:31:10Z", "author": {"login": "cbuescher"}, "path": "server/src/main/java/org/elasticsearch/index/search/QueryStringQueryParser.java", "diffHunk": "@@ -97,6 +100,9 @@\n     private MultiTermQuery.RewriteMethod fuzzyRewriteMethod;\n     private boolean fuzzyTranspositions = FuzzyQuery.defaultTranspositions;\n \n+    // set of field names this parser targets, used to check limits on expanded field names\n+    private Set<String> queriedFields = new HashSet<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDExMjQ1NQ=="}, "originalCommit": {"oid": "7710744d0d37f208dd0244ba7addf120b18c8cbc"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDE5Nzk1Nw==", "bodyText": "The goal of this change is to only check the limit per block. So in your case, if the limit is 50 then the parsing would not throw any error since all blocks are within the limit.", "url": "https://github.com/elastic/elasticsearch/pull/55158#discussion_r410197957", "createdAt": "2020-04-17T12:46:03Z", "author": {"login": "jimczi"}, "path": "server/src/main/java/org/elasticsearch/index/search/QueryStringQueryParser.java", "diffHunk": "@@ -97,6 +100,9 @@\n     private MultiTermQuery.RewriteMethod fuzzyRewriteMethod;\n     private boolean fuzzyTranspositions = FuzzyQuery.defaultTranspositions;\n \n+    // set of field names this parser targets, used to check limits on expanded field names\n+    private Set<String> queriedFields = new HashSet<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDExMjQ1NQ=="}, "originalCommit": {"oid": "7710744d0d37f208dd0244ba7addf120b18c8cbc"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDIwMjU2OQ==", "bodyText": "Thanks for the clarification, this is indeed different from what I was aiming at. I will adapt the approach and the testing consequently.", "url": "https://github.com/elastic/elasticsearch/pull/55158#discussion_r410202569", "createdAt": "2020-04-17T12:54:48Z", "author": {"login": "cbuescher"}, "path": "server/src/main/java/org/elasticsearch/index/search/QueryStringQueryParser.java", "diffHunk": "@@ -97,6 +100,9 @@\n     private MultiTermQuery.RewriteMethod fuzzyRewriteMethod;\n     private boolean fuzzyTranspositions = FuzzyQuery.defaultTranspositions;\n \n+    // set of field names this parser targets, used to check limits on expanded field names\n+    private Set<String> queriedFields = new HashSet<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDExMjQ1NQ=="}, "originalCommit": {"oid": "7710744d0d37f208dd0244ba7addf120b18c8cbc"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0NjMzMTk5OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/index/search/QueryStringQueryParser.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QwOTo0NDo0OFrOGHHWqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QxMjo1NTo1OVrOGHM0Zg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDExMzcwNA==", "bodyText": "This is not enough, we should check every field expansion not just the last one (when extractMultiFields is called).", "url": "https://github.com/elastic/elasticsearch/pull/55158#discussion_r410113704", "createdAt": "2020-04-17T09:44:48Z", "author": {"login": "jimczi"}, "path": "server/src/main/java/org/elasticsearch/index/search/QueryStringQueryParser.java", "diffHunk": "@@ -789,6 +798,8 @@ public Query parse(String query) throws ParseException {\n         if (query.trim().isEmpty()) {\n             return Queries.newMatchNoDocsQuery(\"Matching no documents because no terms present\");\n         }\n-        return super.parse(query);\n+        Query result = super.parse(query);\n+        checkForTooManyFields(this.queriedFields.size(), this.context);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7710744d0d37f208dd0244ba7addf120b18c8cbc"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDE1OTEzOA==", "bodyText": "My hope with putting this check later here was that we can report something close to the real number of fields used in the query to the user with the error message. I had the check in extractMultiFields earlier but then we throw an error whenever the parsing process exceeds the limit. I was looking for a way to get a more accurate could of the total number of used fields, but I see now that this is too late here. Need to rethink this a bit and adapt tests.", "url": "https://github.com/elastic/elasticsearch/pull/55158#discussion_r410159138", "createdAt": "2020-04-17T11:21:13Z", "author": {"login": "cbuescher"}, "path": "server/src/main/java/org/elasticsearch/index/search/QueryStringQueryParser.java", "diffHunk": "@@ -789,6 +798,8 @@ public Query parse(String query) throws ParseException {\n         if (query.trim().isEmpty()) {\n             return Queries.newMatchNoDocsQuery(\"Matching no documents because no terms present\");\n         }\n-        return super.parse(query);\n+        Query result = super.parse(query);\n+        checkForTooManyFields(this.queriedFields.size(), this.context);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDExMzcwNA=="}, "originalCommit": {"oid": "7710744d0d37f208dd0244ba7addf120b18c8cbc"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDE5ODg0Ng==", "bodyText": "If we do that, I'd prefer to do it in a follow up since that would be breaking (we don't check the sum of unique fields at the moment). Lucene 9 will also check the number of clauses globally so this is probably not needed to implement such checks at this level.", "url": "https://github.com/elastic/elasticsearch/pull/55158#discussion_r410198846", "createdAt": "2020-04-17T12:47:43Z", "author": {"login": "jimczi"}, "path": "server/src/main/java/org/elasticsearch/index/search/QueryStringQueryParser.java", "diffHunk": "@@ -789,6 +798,8 @@ public Query parse(String query) throws ParseException {\n         if (query.trim().isEmpty()) {\n             return Queries.newMatchNoDocsQuery(\"Matching no documents because no terms present\");\n         }\n-        return super.parse(query);\n+        Query result = super.parse(query);\n+        checkForTooManyFields(this.queriedFields.size(), this.context);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDExMzcwNA=="}, "originalCommit": {"oid": "7710744d0d37f208dd0244ba7addf120b18c8cbc"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDIwMzIzOA==", "bodyText": "Agreed, if there are other clause checks internal to Lucene this isn't needed. I thought it was achievable but see how thats not the case now.", "url": "https://github.com/elastic/elasticsearch/pull/55158#discussion_r410203238", "createdAt": "2020-04-17T12:55:59Z", "author": {"login": "cbuescher"}, "path": "server/src/main/java/org/elasticsearch/index/search/QueryStringQueryParser.java", "diffHunk": "@@ -789,6 +798,8 @@ public Query parse(String query) throws ParseException {\n         if (query.trim().isEmpty()) {\n             return Queries.newMatchNoDocsQuery(\"Matching no documents because no terms present\");\n         }\n-        return super.parse(query);\n+        Query result = super.parse(query);\n+        checkForTooManyFields(this.queriedFields.size(), this.context);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDExMzcwNA=="}, "originalCommit": {"oid": "7710744d0d37f208dd0244ba7addf120b18c8cbc"}, "originalPosition": 77}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0NzczMDU2OnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/search/query/QueryStringIT.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QxNjo0MDoyN1rOGHVP9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QxNjo0MDoyN1rOGHVP9Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDM0MTM2NQ==", "bodyText": "Just out of curiosity: this test shows what to me is a bit counter-intuitive. When we check breaching the limit once per expansion but not in its sum we can easily hit more than indices.query.bool.max_clause_count with a query.", "url": "https://github.com/elastic/elasticsearch/pull/55158#discussion_r410341365", "createdAt": "2020-04-17T16:40:27Z", "author": {"login": "cbuescher"}, "path": "server/src/test/java/org/elasticsearch/search/query/QueryStringIT.java", "diffHunk": "@@ -324,6 +292,74 @@ public void testLimitOnExpandedFieldsButIgnoreUnmappedFields() throws Exception\n         client().prepareSearch(\"ignoreunmappedfields\").setQuery(qb).get();\n     }\n \n+    public void testLimitOnExpandedFields() throws Exception {\n+        XContentBuilder builder = jsonBuilder();\n+        builder.startObject();\n+        {\n+            builder.startObject(\"_doc\");\n+            {\n+                builder.startObject(\"properties\");\n+                {\n+                    for (int i = 0; i < CLUSTER_MAX_CLAUSE_COUNT; i++) {\n+                        builder.startObject(\"field_A\" + i).field(\"type\", \"text\").endObject();\n+                        builder.startObject(\"field_B\" + i).field(\"type\", \"text\").endObject();\n+                    }\n+                    builder.endObject();\n+                }\n+                builder.endObject();\n+            }\n+            builder.endObject();\n+        }\n+\n+        assertAcked(prepareCreate(\"testindex\")\n+                .setSettings(Settings.builder().put(MapperService.INDEX_MAPPING_TOTAL_FIELDS_LIMIT_SETTING.getKey(),\n+                        CLUSTER_MAX_CLAUSE_COUNT + 100))\n+                .setMapping(builder));\n+\n+        client().prepareIndex(\"testindex\").setId(\"1\").setSource(\"field_A0\", \"foo bar baz\").get();\n+        refresh();\n+\n+        // single field shouldn't trigger the limit\n+        doAssertOneHitForQueryString(\"field_A0:foo\");\n+        // expanding to the limit should work\n+        doAssertOneHitForQueryString(\"field_A\\\\*:foo\");\n+        // expanding two blocks to the limit still works\n+        doAssertOneHitForQueryString(\"field_A\\\\*:foo field_B\\\\*:bar\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8606ae4cd0102e5b73d8f2da336162c1541acbb4"}, "originalPosition": 75}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1152, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}