{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDc3ODk5MDg1", "number": 61860, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wN1QxMzoyNjoxM1rOEg74xA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wN1QxMzoyODowMFrOEg77Kg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyOTcxMDc2OnYy", "diffSide": "RIGHT", "path": "plugins/mapper-annotated-text/src/main/java/org/elasticsearch/search/fetch/subphase/highlight/AnnotatedTextHighlighter.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wN1QxMzoyNjoxM1rOHN_Upw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wN1QxMzoyNjoxM1rOHN_Upw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDQzMTAxNQ==", "bodyText": "I think this change means we can remove hitContext from the method sig here as well - we only added it in to access the cache.", "url": "https://github.com/elastic/elasticsearch/pull/61860#discussion_r484431015", "createdAt": "2020-09-07T13:26:13Z", "author": {"login": "romseygeek"}, "path": "plugins/mapper-annotated-text/src/main/java/org/elasticsearch/search/fetch/subphase/highlight/AnnotatedTextHighlighter.java", "diffHunk": "@@ -37,39 +38,37 @@\n \n     public static final String NAME = \"annotated\";\n \n-    @Override\n-    protected Analyzer getAnalyzer(DocumentMapper docMapper, HitContext hitContext) {\n-        return new AnnotatedHighlighterAnalyzer(super.getAnalyzer(docMapper, hitContext), hitContext);\n-    }\n-\n     // Convert the marked-up values held on-disk to plain-text versions for highlighting\n     @Override\n-    protected List<Object> loadFieldValues(MappedFieldType fieldType,\n-                                           Field field,\n-                                           HitContext hitContext,\n-                                           boolean forceSource) throws IOException {\n-        List<Object> fieldValues = super.loadFieldValues(fieldType, field, hitContext, forceSource);\n-        String[] fieldValuesAsString = fieldValues.toArray(new String[fieldValues.size()]);\n+    protected List<Object> loadFieldValues(\n+        CustomUnifiedHighlighter highlighter,\n+        MappedFieldType fieldType,\n+        Field field,\n+        HitContext hitContext,\n+        boolean forceSource\n+    ) throws IOException {\n+        List<Object> fieldValues = super.loadFieldValues(highlighter, fieldType, field, hitContext, forceSource);\n \n-        AnnotatedText[] annotations = new AnnotatedText[fieldValuesAsString.length];\n-        for (int i = 0; i < fieldValuesAsString.length; i++) {\n-            annotations[i] = AnnotatedText.parse(fieldValuesAsString[i]);\n+        List<Object> strings = new ArrayList<>(fieldValues.size());\n+        AnnotatedText[] annotations = new AnnotatedText[fieldValues.size()];\n+        for (int i = 0; i < fieldValues.size(); i++) {\n+            annotations[i] = AnnotatedText.parse(fieldValues.get(i).toString());\n+            strings.add(annotations[i].textMinusMarkup);\n         }\n-        // Store the annotations in the hitContext\n-        hitContext.cache().put(AnnotatedText.class.getName(), annotations);\n+        // Store the annotations in the formatter and analyzer\n+        ((AnnotatedPassageFormatter) highlighter.getFormatter()).setAnnotations(annotations);\n+        ((AnnotatedHighlighterAnalyzer) highlighter.getIndexAnalyzer()).setAnnotations(annotations);\n+        return strings;\n+    }\n \n-        ArrayList<Object> result = new ArrayList<>(annotations.length);\n-        for (int i = 0; i < annotations.length; i++) {\n-            result.add(annotations[i].textMinusMarkup);\n-        }\n-        return result;\n+    @Override", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58d0b87543f644bac00237345b1249dfca849da1"}, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyOTcxMjA1OnYy", "diffSide": "LEFT", "path": "plugins/mapper-annotated-text/src/test/java/org/elasticsearch/search/fetch/subphase/highlight/AnnotatedTextHighlighterTests.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wN1QxMzoyNjozNVrOHN_VWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wN1QxMzoyNjozNVrOHN_VWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDQzMTE5Mg==", "bodyText": "\u2764\ufe0f", "url": "https://github.com/elastic/elasticsearch/pull/61860#discussion_r484431192", "createdAt": "2020-09-07T13:26:35Z", "author": {"login": "romseygeek"}, "path": "plugins/mapper-annotated-text/src/test/java/org/elasticsearch/search/fetch/subphase/highlight/AnnotatedTextHighlighterTests.java", "diffHunk": "@@ -93,17 +88,14 @@ private void assertHighlightOneDoc(String fieldName, String []markedUpInputs,\n         IndexSearcher searcher = newSearcher(reader);\n         iw.close();\n \n-        LeafReaderContext context = searcher.getIndexReader().leaves().get(0);\n-        HitContext mockHitContext = new HitContext(null, context, 0, null, new HashMap<>());\n-        AnnotatedHighlighterAnalyzer hiliteAnalyzer = new AnnotatedHighlighterAnalyzer(wrapperAnalyzer, mockHitContext);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58d0b87543f644bac00237345b1249dfca849da1"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyOTcxNjkwOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/search/fetch/subphase/highlight/UnifiedHighlighter.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wN1QxMzoyODowMFrOHN_YKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNDoxMzoyOFrOHOfMyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDQzMTkxMw==", "bodyText": "Pretty sure we can rework the highlighter API now to remove the need for this dumb cache, which would be a really nice cleanup.", "url": "https://github.com/elastic/elasticsearch/pull/61860#discussion_r484431913", "createdAt": "2020-09-07T13:28:00Z", "author": {"login": "romseygeek"}, "path": "server/src/main/java/org/elasticsearch/search/fetch/subphase/highlight/UnifiedHighlighter.java", "diffHunk": "@@ -60,84 +62,97 @@ public boolean canHighlight(MappedFieldType fieldType) {\n \n     @Override\n     public HighlightField highlight(FieldHighlightContext fieldContext) {\n-        MappedFieldType fieldType = fieldContext.fieldType;\n-        SearchHighlightContext.Field field = fieldContext.field;\n-        QueryShardContext context = fieldContext.context;\n-        FetchSubPhase.HitContext hitContext = fieldContext.hitContext;\n-        Encoder encoder = field.fieldOptions().encoder().equals(\"html\") ? HighlightUtils.Encoders.HTML : HighlightUtils.Encoders.DEFAULT;\n-        final int maxAnalyzedOffset = context.getIndexSettings().getHighlightMaxAnalyzedOffset();\n-        Integer keywordIgnoreAbove = null;\n-        if (fieldType instanceof KeywordFieldMapper.KeywordFieldType) {\n-            KeywordFieldMapper mapper = (KeywordFieldMapper) context.getMapperService().documentMapper()\n-                .mappers().getMapper(fieldContext.fieldName);\n-            keywordIgnoreAbove = mapper.ignoreAbove();\n-        }\n-\n-        List<Snippet> snippets = new ArrayList<>();\n-        int numberOfFragments = field.fieldOptions().numberOfFragments();\n-        try {\n-            final Analyzer analyzer = getAnalyzer(context.getMapperService().documentMapper(), hitContext);\n-            List<Object> fieldValues = loadFieldValues(fieldType, field, hitContext, fieldContext.forceSource);\n-            if (fieldValues.size() == 0) {\n-                return null;\n-            }\n-            final PassageFormatter passageFormatter = getPassageFormatter(hitContext, field, encoder);\n-            final IndexSearcher searcher = new IndexSearcher(hitContext.reader());\n-            final CustomUnifiedHighlighter highlighter;\n-            final String fieldValue = mergeFieldValues(fieldValues, MULTIVAL_SEP_CHAR);\n-            final OffsetSource offsetSource = getOffsetSource(fieldType);\n-            int fieldValueLength = fieldValue.length();\n-            if (keywordIgnoreAbove != null  && fieldValueLength > keywordIgnoreAbove) {\n-                return null; // skip highlighting keyword terms that were ignored during indexing\n-            }\n-            if ((offsetSource == OffsetSource.ANALYSIS) && (fieldValueLength > maxAnalyzedOffset)) {\n-                throw new IllegalArgumentException(\n-                    \"The length of [\" + fieldContext.fieldName + \"] field of [\" + hitContext.hit().getId() +\n-                        \"] doc of [\" + context.index().getName() + \"] index \" + \"has exceeded [\" +\n-                        maxAnalyzedOffset + \"] - maximum allowed to be analyzed for highlighting. \" +\n-                        \"This maximum can be set by changing the [\" + IndexSettings.MAX_ANALYZED_OFFSET_SETTING.getKey() +\n-                        \"] index level setting. \" + \"For large texts, indexing with offsets or term vectors is recommended!\");\n+        @SuppressWarnings(\"unchecked\")\n+        Map<String, CustomUnifiedHighlighter> cache = (Map<String, CustomUnifiedHighlighter>) fieldContext.hitContext.cache()\n+            .computeIfAbsent(UnifiedHighlighter.class.getName(), k -> new HashMap<>());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58d0b87543f644bac00237345b1249dfca849da1"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDk1MzI4OA==", "bodyText": "It totally would be!", "url": "https://github.com/elastic/elasticsearch/pull/61860#discussion_r484953288", "createdAt": "2020-09-08T14:13:28Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/search/fetch/subphase/highlight/UnifiedHighlighter.java", "diffHunk": "@@ -60,84 +62,97 @@ public boolean canHighlight(MappedFieldType fieldType) {\n \n     @Override\n     public HighlightField highlight(FieldHighlightContext fieldContext) {\n-        MappedFieldType fieldType = fieldContext.fieldType;\n-        SearchHighlightContext.Field field = fieldContext.field;\n-        QueryShardContext context = fieldContext.context;\n-        FetchSubPhase.HitContext hitContext = fieldContext.hitContext;\n-        Encoder encoder = field.fieldOptions().encoder().equals(\"html\") ? HighlightUtils.Encoders.HTML : HighlightUtils.Encoders.DEFAULT;\n-        final int maxAnalyzedOffset = context.getIndexSettings().getHighlightMaxAnalyzedOffset();\n-        Integer keywordIgnoreAbove = null;\n-        if (fieldType instanceof KeywordFieldMapper.KeywordFieldType) {\n-            KeywordFieldMapper mapper = (KeywordFieldMapper) context.getMapperService().documentMapper()\n-                .mappers().getMapper(fieldContext.fieldName);\n-            keywordIgnoreAbove = mapper.ignoreAbove();\n-        }\n-\n-        List<Snippet> snippets = new ArrayList<>();\n-        int numberOfFragments = field.fieldOptions().numberOfFragments();\n-        try {\n-            final Analyzer analyzer = getAnalyzer(context.getMapperService().documentMapper(), hitContext);\n-            List<Object> fieldValues = loadFieldValues(fieldType, field, hitContext, fieldContext.forceSource);\n-            if (fieldValues.size() == 0) {\n-                return null;\n-            }\n-            final PassageFormatter passageFormatter = getPassageFormatter(hitContext, field, encoder);\n-            final IndexSearcher searcher = new IndexSearcher(hitContext.reader());\n-            final CustomUnifiedHighlighter highlighter;\n-            final String fieldValue = mergeFieldValues(fieldValues, MULTIVAL_SEP_CHAR);\n-            final OffsetSource offsetSource = getOffsetSource(fieldType);\n-            int fieldValueLength = fieldValue.length();\n-            if (keywordIgnoreAbove != null  && fieldValueLength > keywordIgnoreAbove) {\n-                return null; // skip highlighting keyword terms that were ignored during indexing\n-            }\n-            if ((offsetSource == OffsetSource.ANALYSIS) && (fieldValueLength > maxAnalyzedOffset)) {\n-                throw new IllegalArgumentException(\n-                    \"The length of [\" + fieldContext.fieldName + \"] field of [\" + hitContext.hit().getId() +\n-                        \"] doc of [\" + context.index().getName() + \"] index \" + \"has exceeded [\" +\n-                        maxAnalyzedOffset + \"] - maximum allowed to be analyzed for highlighting. \" +\n-                        \"This maximum can be set by changing the [\" + IndexSettings.MAX_ANALYZED_OFFSET_SETTING.getKey() +\n-                        \"] index level setting. \" + \"For large texts, indexing with offsets or term vectors is recommended!\");\n+        @SuppressWarnings(\"unchecked\")\n+        Map<String, CustomUnifiedHighlighter> cache = (Map<String, CustomUnifiedHighlighter>) fieldContext.hitContext.cache()\n+            .computeIfAbsent(UnifiedHighlighter.class.getName(), k -> new HashMap<>());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDQzMTkxMw=="}, "originalCommit": {"oid": "58d0b87543f644bac00237345b1249dfca849da1"}, "originalPosition": 72}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1850, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}