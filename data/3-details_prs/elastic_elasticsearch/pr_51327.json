{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY1OTgwNjY1", "number": 51327, "title": "Upgrade to lucene-8.5.0-snapshot-3333ce7da6d", "bodyText": "", "createdAt": "2020-01-22T17:40:36Z", "url": "https://github.com/elastic/elasticsearch/pull/51327", "merged": true, "mergeCommit": {"oid": "3d53c48509ce2cbca2c0431e68d83df382742f3f"}, "closed": true, "closedAt": "2020-01-30T15:08:49Z", "author": {"login": "mayya-sharipova"}, "timelineItems": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb85L-LgH2gAyMzY1OTgwNjY1OjJhZTEyMTM2ZmVhMWY0YjVhMTMxYmEwNjJkNTgwODFiNGZlMmJjNjM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABb_ZziwgFqTM1MDc4OTkyNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "2ae12136fea1f4b5a131ba062d58081b4fe2bc63", "author": {"user": {"login": "mayya-sharipova", "name": "Mayya Sharipova"}}, "url": "https://github.com/elastic/elasticsearch/commit/2ae12136fea1f4b5a131ba062d58081b4fe2bc63", "committedDate": "2020-01-22T17:28:03Z", "message": "Upgrade to lucene-8.5.0-snapshot-3333ce7da6d"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a9f0c999292e7e05429907ca30d415ad9e3a870b", "author": {"user": {"login": "mayya-sharipova", "name": "Mayya Sharipova"}}, "url": "https://github.com/elastic/elasticsearch/commit/a9f0c999292e7e05429907ca30d415ad9e3a870b", "committedDate": "2020-01-23T14:31:55Z", "message": "Keep previous behaviour of FieldHighlighter::highlightOffsetsEnums\n\nLUCENE-9093 modified how FieldHighlighter breaks texts into passages,\nwhich doesn't work well with elasticsearch custome BoundedBreakIteratorScanner.\nThis commit for now keeps previous behaviour of FieldHighlighter."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ3ODIwODI5", "url": "https://github.com/elastic/elasticsearch/pull/51327#pullrequestreview-347820829", "createdAt": "2020-01-24T09:07:12Z", "commit": {"oid": "a9f0c999292e7e05429907ca30d415ad9e3a870b"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNFQwOTowNzoxM1rOFhXahg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNFQwOToxMDoxMVrOFhXeig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDUzMDk1MA==", "bodyText": "I think we can remove XIntervals now that LUCENE-9050 is released - just use plain Intervals instead.", "url": "https://github.com/elastic/elasticsearch/pull/51327#discussion_r370530950", "createdAt": "2020-01-24T09:07:13Z", "author": {"login": "romseygeek"}, "path": "server/src/main/java/org/elasticsearch/index/query/IntervalsSourceProvider.java", "diffHunk": "@@ -797,8 +797,8 @@ public IntervalsSource getSource(QueryShardContext context, MappedFieldType fiel\n             BytesRef normalizedTerm = analyzer.normalize(fieldType.name(), term);\n             FuzzyQuery fq = new FuzzyQuery(new Term(fieldType.name(), normalizedTerm),\n                 fuzziness.asDistance(term), prefixLength, 128, transpositions);\n-            CompiledAutomaton ca = new CompiledAutomaton(fq.toAutomaton());\n-            source = XIntervals.multiterm(ca, term);\n+            CompiledAutomaton[] automata = fq.getAutomata();\n+            source = XIntervals.multiterm(automata[automata.length - 1], term);\n             if (useField != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a9f0c999292e7e05429907ca30d415ad9e3a870b"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDUzMTk3OA==", "bodyText": "This just overrides LUCENE-9093 and preserves the previous behaviour, correct? +1 if so", "url": "https://github.com/elastic/elasticsearch/pull/51327#discussion_r370531978", "createdAt": "2020-01-24T09:10:11Z", "author": {"login": "romseygeek"}, "path": "server/src/main/java/org/apache/lucene/search/uhighlight/CustomFieldHighlighter.java", "diffHunk": "@@ -76,4 +82,84 @@\n         }\n         return EMPTY_PASSAGE;\n     }\n+\n+    // TODO: use FieldHighlighter::highlightOffsetsEnums and modify BoundedBreakIteratorScanner to work with it\n+    // LUCENE-9093 modified how FieldHighlighter breaks texts into passages,\n+    // which doesn't work well with BoundedBreakIteratorScanner\n+    // This is the copy of highlightOffsetsEnums before LUCENE-9093.\n+    @Override\n+    protected Passage[] highlightOffsetsEnums(OffsetsEnum off)\n+        throws IOException {\n+\n+        final int contentLength = this.breakIterator.getText().getEndIndex();\n+\n+        if (off.nextPosition() == false) {\n+            return new Passage[0];\n+        }\n+\n+        PriorityQueue<Passage> passageQueue = new PriorityQueue<>(Math.min(64, maxPassages + 1), (left, right) -> {\n+            if (left.getScore() < right.getScore()) {\n+                return -1;\n+            } else if (left.getScore() > right.getScore()) {\n+                return 1;\n+            } else {\n+                return left.getStartOffset() - right.getStartOffset();\n+            }\n+        });\n+        Passage passage = new Passage(); // the current passage in-progress.  Will either get reset or added to queue.\n+\n+        do {\n+            int start = off.startOffset();\n+            if (start == -1) {\n+                throw new IllegalArgumentException(\"field '\" + field + \"' was indexed without offsets, cannot highlight\");\n+            }\n+            int end = off.endOffset();\n+            if (start < contentLength && end > contentLength) {\n+                continue;\n+            }\n+            // See if this term should be part of a new passage.\n+            if (start >= passage.getEndOffset()) {\n+                passage = maybeAddPassage(passageQueue, passageScorer, passage, contentLength);\n+                // if we exceed limit, we are done\n+                if (start >= contentLength) {\n+                    break;\n+                }\n+                passage.setStartOffset(Math.max(this.breakIterator.preceding(start + 1), 0));\n+                passage.setEndOffset(Math.min(this.breakIterator.following(start), contentLength));\n+            }\n+            // Add this term to the passage.\n+            BytesRef term = off.getTerm();// a reference; safe to refer to\n+            assert term != null;\n+            passage.addMatch(start, end, term, off.freq());\n+        } while (off.nextPosition());\n+        maybeAddPassage(passageQueue, passageScorer, passage, contentLength);\n+\n+        Passage[] passages = passageQueue.toArray(new Passage[passageQueue.size()]);\n+        // sort in ascending order\n+        Arrays.sort(passages, Comparator.comparingInt(Passage::getStartOffset));\n+        return passages;\n+    }\n+\n+    // TODO: use FieldHighlighter::maybeAddPassage\n+    // After removing CustomFieldHighlighter::highlightOffsetsEnums, remove this method as well.\n+    private Passage maybeAddPassage(PriorityQueue<Passage> passageQueue, PassageScorer scorer, Passage passage, int contentLength) {\n+        if (passage.getStartOffset() == -1) {\n+            // empty passage, we can ignore it\n+            return passage;\n+        }\n+        passage.setScore(scorer.score(passage, contentLength));\n+        // new sentence: first add 'passage' to queue\n+        if (passageQueue.size() == maxPassages && passage.getScore() < passageQueue.peek().getScore()) {\n+            passage.reset(); // can't compete, just reset it\n+        } else {\n+            passageQueue.offer(passage);\n+            if (passageQueue.size() > maxPassages) {\n+                passage = passageQueue.poll();\n+                passage.reset();\n+            } else {\n+                passage = new Passage();\n+            }\n+        }\n+        return passage;\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a9f0c999292e7e05429907ca30d415ad9e3a870b"}, "originalPosition": 98}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUwNzg5OTI0", "url": "https://github.com/elastic/elasticsearch/pull/51327#pullrequestreview-350789924", "createdAt": "2020-01-30T12:36:05Z", "commit": {"oid": "a9f0c999292e7e05429907ca30d415ad9e3a870b"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2862, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}