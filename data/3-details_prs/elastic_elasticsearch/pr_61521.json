{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDczMTc2ODU2", "number": 61521, "title": "[ML] refactor ml job node selection into its own class", "bodyText": "This is a minor refactor where the job node load logic (node availability, etc.) is refactored into its own class.\nThis will allow future things (i.e. autoscaling decisions) to use the same node load detection class.", "createdAt": "2020-08-25T12:42:04Z", "url": "https://github.com/elastic/elasticsearch/pull/61521", "merged": true, "mergeCommit": {"oid": "0501bfdd2a14ef4553f1e19e9aaaa993124f4626"}, "closed": true, "closedAt": "2020-08-27T17:22:16Z", "author": {"login": "benwtrent"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdCWhpmgH2gAyNDczMTc2ODU2OjdiNzA0MmRlNTk0NDRlNTM5YzZmNjc2NDBhMWExNzI4NjU5YjQ5NWI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdDCcHuAFqTQ3Njg1Njk4Mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "7b7042de59444e539c6f67640a1a1728659b495b", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/7b7042de59444e539c6f67640a1a1728659b495b", "committedDate": "2020-08-25T12:39:45Z", "message": "[ML] refactor ml job node selection into its own class"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc1MTg1MTg1", "url": "https://github.com/elastic/elasticsearch/pull/61521#pullrequestreview-475185185", "createdAt": "2020-08-26T06:27:05Z", "commit": {"oid": "7b7042de59444e539c6f67640a1a1728659b495b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQwNjoyNzowNVrOHG9lJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQwNjoyNzowNVrOHG9lJw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzA2MjQzOQ==", "bodyText": "Should this class have its own unit tests now that it's separated?", "url": "https://github.com/elastic/elasticsearch/pull/61521#discussion_r477062439", "createdAt": "2020-08-26T06:27:05Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/job/NodeLoadDetector.java", "diffHunk": "@@ -0,0 +1,216 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.job;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.persistent.PersistentTasksCustomMetadata;\n+import org.elasticsearch.xpack.core.ml.MlTasks;\n+import org.elasticsearch.xpack.core.ml.action.OpenJobAction;\n+import org.elasticsearch.xpack.core.ml.action.StartDataFrameAnalyticsAction;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsState;\n+import org.elasticsearch.xpack.core.ml.job.config.JobState;\n+import org.elasticsearch.xpack.ml.MachineLearning;\n+import org.elasticsearch.xpack.ml.process.MlMemoryTracker;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+\n+\n+public class NodeLoadDetector {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b7042de59444e539c6f67640a1a1728659b495b"}, "originalPosition": 30}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ce6f7a2b7316d1af98c347e81b1d148be28be8d5", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/ce6f7a2b7316d1af98c347e81b1d148be28be8d5", "committedDate": "2020-08-27T12:48:08Z", "message": "adding nodeload tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc2NjExMTM5", "url": "https://github.com/elastic/elasticsearch/pull/61521#pullrequestreview-476611139", "createdAt": "2020-08-27T11:05:17Z", "commit": {"oid": "7b7042de59444e539c6f67640a1a1728659b495b"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxMTowNToxN1rOHILP8Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxMzoyMzozMVrOHIQKww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODMzNDk2MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                     * @return Returns a comma delimited string of errors if any where encountered.\n          \n          \n            \n                     * @return Returns a comma delimited string of errors if any were encountered.", "url": "https://github.com/elastic/elasticsearch/pull/61521#discussion_r478334961", "createdAt": "2020-08-27T11:05:17Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/job/NodeLoadDetector.java", "diffHunk": "@@ -0,0 +1,216 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.job;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.persistent.PersistentTasksCustomMetadata;\n+import org.elasticsearch.xpack.core.ml.MlTasks;\n+import org.elasticsearch.xpack.core.ml.action.OpenJobAction;\n+import org.elasticsearch.xpack.core.ml.action.StartDataFrameAnalyticsAction;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsState;\n+import org.elasticsearch.xpack.core.ml.job.config.JobState;\n+import org.elasticsearch.xpack.ml.MachineLearning;\n+import org.elasticsearch.xpack.ml.process.MlMemoryTracker;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+\n+\n+public class NodeLoadDetector {\n+    private static final Logger logger = LogManager.getLogger(NodeLoadDetector.class);\n+\n+    private final MlMemoryTracker mlMemoryTracker;\n+\n+    public NodeLoadDetector(MlMemoryTracker memoryTracker) {\n+        this.mlMemoryTracker = memoryTracker;\n+    }\n+\n+    public MlMemoryTracker getMlMemoryTracker() {\n+        return mlMemoryTracker;\n+    }\n+\n+    public NodeLoad detectNodeLoad(ClusterState clusterState,\n+                                   boolean allNodesHaveDynamicMaxWorkers,\n+                                   DiscoveryNode node,\n+                                   int dynamicMaxOpenJobs,\n+                                   int maxMachineMemoryPercent,\n+                                   boolean isMemoryTrackerRecentlyRefreshed) {\n+        PersistentTasksCustomMetadata persistentTasks = clusterState.getMetadata().custom(PersistentTasksCustomMetadata.TYPE);\n+        Map<String, String> nodeAttributes = node.getAttributes();\n+        List<String> errors = new ArrayList<>();\n+        int maxNumberOfOpenJobs = dynamicMaxOpenJobs;\n+        // TODO: remove this in 8.0.0\n+        if (allNodesHaveDynamicMaxWorkers == false) {\n+            String maxNumberOfOpenJobsStr = nodeAttributes.get(MachineLearning.MAX_OPEN_JOBS_NODE_ATTR);\n+            try {\n+                maxNumberOfOpenJobs = Integer.parseInt(maxNumberOfOpenJobsStr);\n+            } catch (NumberFormatException e) {\n+                errors.add(MachineLearning.MAX_OPEN_JOBS_NODE_ATTR + \" attribute [\" + maxNumberOfOpenJobsStr + \"] is not an integer\");\n+                maxNumberOfOpenJobs = -1;\n+            }\n+        }\n+        String machineMemoryStr = nodeAttributes.get(MachineLearning.MACHINE_MEMORY_NODE_ATTR);\n+        long machineMemory = -1;\n+        try {\n+            machineMemory = Long.parseLong(machineMemoryStr);\n+        } catch (NumberFormatException e) {\n+            errors.add(MachineLearning.MACHINE_MEMORY_NODE_ATTR + \" attribute [\" + machineMemoryStr + \"] is not a long\");\n+        }\n+        long maxMlMemory = machineMemory * maxMachineMemoryPercent / 100;\n+\n+        NodeLoad nodeLoad = new NodeLoad(node.getId(), maxMlMemory, maxNumberOfOpenJobs, isMemoryTrackerRecentlyRefreshed);\n+        if (errors.isEmpty() == false) {\n+            nodeLoad.error = Strings.collectionToCommaDelimitedString(errors);\n+            return nodeLoad;\n+        }\n+        updateLoadGivenTasks(nodeLoad, persistentTasks);\n+        return nodeLoad;\n+    }\n+\n+    private void updateLoadGivenTasks(NodeLoad nodeLoad, PersistentTasksCustomMetadata persistentTasks) {\n+        if (persistentTasks != null) {\n+            // find all the anomaly detector job tasks assigned to this node\n+            Collection<PersistentTasksCustomMetadata.PersistentTask<?>> assignedAnomalyDetectorTasks = persistentTasks.findTasks(\n+                MlTasks.JOB_TASK_NAME, task -> nodeLoad.getNodeId().equals(task.getExecutorNode()));\n+            for (PersistentTasksCustomMetadata.PersistentTask<?> assignedTask : assignedAnomalyDetectorTasks) {\n+                JobState jobState = MlTasks.getJobStateModifiedForReassignments(assignedTask);\n+                if (jobState.isAnyOf(JobState.CLOSED, JobState.FAILED) == false) {\n+                    // Don't count CLOSED or FAILED jobs, as they don't consume native memory\n+                    ++nodeLoad.numAssignedJobs;\n+                    if (jobState == JobState.OPENING) {\n+                        ++nodeLoad.numAllocatingJobs;\n+                    }\n+                    OpenJobAction.JobParams params = (OpenJobAction.JobParams) assignedTask.getParams();\n+                    Long jobMemoryRequirement = mlMemoryTracker.getAnomalyDetectorJobMemoryRequirement(params.getJobId());\n+                    if (jobMemoryRequirement == null) {\n+                        nodeLoad.useMemory = false;\n+                        logger.debug(() -> new ParameterizedMessage(\n+                            \"[{}] memory requirement was not available. Calculating load by number of assigned jobs.\",\n+                            params.getJobId()\n+                        ));\n+                    } else {\n+                        nodeLoad.assignedJobMemory += jobMemoryRequirement;\n+                    }\n+                }\n+            }\n+            // find all the data frame analytics job tasks assigned to this node\n+            Collection<PersistentTasksCustomMetadata.PersistentTask<?>> assignedAnalyticsTasks = persistentTasks.findTasks(\n+                MlTasks.DATA_FRAME_ANALYTICS_TASK_NAME, task -> nodeLoad.getNodeId().equals(task.getExecutorNode()));\n+            for (PersistentTasksCustomMetadata.PersistentTask<?> assignedTask : assignedAnalyticsTasks) {\n+                DataFrameAnalyticsState dataFrameAnalyticsState = MlTasks.getDataFrameAnalyticsState(assignedTask);\n+\n+                // Don't count stopped and failed df-analytics tasks as they don't consume native memory\n+                if (dataFrameAnalyticsState.isAnyOf(DataFrameAnalyticsState.STOPPED, DataFrameAnalyticsState.FAILED) == false) {\n+                    // The native process is only running in the ANALYZING and STOPPING states, but in the STARTED\n+                    // and REINDEXING states we're committed to using the memory soon, so account for it here\n+                    ++nodeLoad.numAssignedJobs;\n+                    StartDataFrameAnalyticsAction.TaskParams params =\n+                        (StartDataFrameAnalyticsAction.TaskParams) assignedTask.getParams();\n+                    Long jobMemoryRequirement = mlMemoryTracker.getDataFrameAnalyticsJobMemoryRequirement(params.getId());\n+                    if (jobMemoryRequirement == null) {\n+                        nodeLoad.useMemory = false;\n+                        logger.debug(() -> new ParameterizedMessage(\n+                            \"[{}] memory requirement was not available. Calculating load by number of assigned jobs.\",\n+                            params.getId()\n+                        ));\n+                    } else {\n+                        nodeLoad.assignedJobMemory += jobMemoryRequirement;\n+                    }\n+                }\n+            }\n+            // if any jobs are running then the native code will be loaded, but shared between all jobs,\n+            // so increase the total memory usage of the assigned jobs to account for this\n+            if (nodeLoad.numAssignedJobs > 0) {\n+                nodeLoad.assignedJobMemory += MachineLearning.NATIVE_EXECUTABLE_CODE_OVERHEAD.getBytes();\n+            }\n+        }\n+    }\n+\n+\n+    public static class NodeLoad {\n+        private final long maxMemory;\n+        private final int maxJobs;\n+        private final String nodeId;\n+        private boolean useMemory;\n+        private String error;\n+        private long numAssignedJobs;\n+        private long assignedJobMemory;\n+        private long numAllocatingJobs;\n+\n+        private NodeLoad(String nodeId, long maxMemory, int maxJobs, boolean useMemory) {\n+            this.maxJobs = maxJobs;\n+            this.maxMemory = maxMemory;\n+            this.nodeId = nodeId;\n+            this.useMemory = useMemory;\n+        }\n+\n+        /**\n+         * @return The total number of assigned jobs\n+         */\n+        public long getNumAssignedJobs() {\n+            return numAssignedJobs;\n+        }\n+\n+        /**\n+         * @return The total memory in bytes used by the assigned jobs.\n+         */\n+        public long getAssignedJobMemory() {\n+            return assignedJobMemory;\n+        }\n+\n+        /**\n+         * @return The maximum memory on this node for jobs\n+         */\n+        public long getMaxMlMemory() {\n+            return maxMemory;\n+        }\n+\n+        /**\n+         * @return The maximum number of jobs allowed on the node\n+         */\n+        public int getMaxJobs() {\n+            return maxJobs;\n+        }\n+\n+        /**\n+         * @return returns `true` if the assignedJobMemory number is accurate\n+         */\n+        public boolean isUseMemory() {\n+            return useMemory;\n+        }\n+\n+        /**\n+         * @return The node ID\n+         */\n+        public String getNodeId() {\n+            return nodeId;\n+        }\n+\n+        /**\n+         * @return Returns a comma delimited string of errors if any where encountered.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b7042de59444e539c6f67640a1a1728659b495b"}, "originalPosition": 201}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODQxNTU1NQ==", "bodyText": "Anyway, since you are adding a new class, I would also add a unit test class. Even if it has one very simple test case.\nThe reasoning is that when the class grows (and you expect it to grow with autoscaling logic for example), there will already be a place to put more tests into.", "url": "https://github.com/elastic/elasticsearch/pull/61521#discussion_r478415555", "createdAt": "2020-08-27T13:23:31Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/job/NodeLoadDetector.java", "diffHunk": "@@ -0,0 +1,216 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.job;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.persistent.PersistentTasksCustomMetadata;\n+import org.elasticsearch.xpack.core.ml.MlTasks;\n+import org.elasticsearch.xpack.core.ml.action.OpenJobAction;\n+import org.elasticsearch.xpack.core.ml.action.StartDataFrameAnalyticsAction;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsState;\n+import org.elasticsearch.xpack.core.ml.job.config.JobState;\n+import org.elasticsearch.xpack.ml.MachineLearning;\n+import org.elasticsearch.xpack.ml.process.MlMemoryTracker;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+\n+\n+public class NodeLoadDetector {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzA2MjQzOQ=="}, "originalCommit": {"oid": "7b7042de59444e539c6f67640a1a1728659b495b"}, "originalPosition": 30}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2b0b7c92599c33a34a0b7e159fe426e54ee4bea4", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/2b0b7c92599c33a34a0b7e159fe426e54ee4bea4", "committedDate": "2020-08-27T13:39:17Z", "message": "Update x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/job/NodeLoadDetector.java\n\nCo-authored-by: Przemys\u0142aw Witek <przemyslaw.witek@elastic.co>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9e9bc47162b3bf4061cd14d0ac1b13c7b8021b8b", "author": {"user": {"login": "elasticmachine", "name": "Elastic Machine"}}, "url": "https://github.com/elastic/elasticsearch/commit/9e9bc47162b3bf4061cd14d0ac1b13c7b8021b8b", "committedDate": "2020-08-27T14:09:10Z", "message": "Merge branch 'master' into feature/ml-job-node-selector-refactor"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc2ODU2OTgz", "url": "https://github.com/elastic/elasticsearch/pull/61521#pullrequestreview-476856983", "createdAt": "2020-08-27T15:49:32Z", "commit": {"oid": "9e9bc47162b3bf4061cd14d0ac1b13c7b8021b8b"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4718, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}