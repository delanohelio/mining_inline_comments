{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg2ODI0NTk5", "number": 53423, "title": "Stop using round-tripped PipelineAggregators", "bodyText": "This begins to clean up how PipelineAggregators and executed.\nPreviously, we would create the PipelineAggregators on the data nodes\nand embed them in the aggregation tree. When it came time to execute the\npipeline aggregation we'd use the PipelineAggregators that were on the\nfirst shard's results. This is inefficient because:\n\nThe data node needs to make the PipelineAggregator only to\nserialize it and then throw it away.\nThe coordinating node needs to deserialize all of the\nPipelineAggregators even though it only needs one of them.\nYou end up with many PipelineAggregator instances when you only\nreally need one per pipeline.\nPipelineAggregator needs to implement serialization.\n\nThis begins to undo these by building the PipelineAggregators directly\non the coordinating node and using those instead of the\nPipelineAggregators in the aggregtion tree. In a follow up change\nwe'll stop serializing the PipelineAggregators to node versions that\nsupport this behavior. And, one day, we'll be able to remove\nPipelineAggregator from the aggregation result tree entirely.\nImportantly, this doesn't change how pipeline aggregations are declared\nor parsed or requested. They are still part of the AggregationBuilder\ntree because that makes sense.", "createdAt": "2020-03-11T17:28:08Z", "url": "https://github.com/elastic/elasticsearch/pull/53423", "merged": true, "mergeCommit": {"oid": "4d81edb6257732a73adc3e5bc5157ad01d1a42c4"}, "closed": true, "closedAt": "2020-03-16T18:51:55Z", "author": {"login": "nik9000"}, "timelineItems": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcMqhw-AH2gAyMzg2ODI0NTk5OjIwNWNiZTJkZmNmY2M0ZjA2Zjk0Y2ViYTdkNGY3YTU1ZjY0Y2E1NzA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcOR0b-gH2gAyMzg2ODI0NTk5OmZlZDZhZjY1YWI3NzJjOGFhMzQzMDJkZDE3MzFlN2E0Y2JlZGEzYzI=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "205cbe2dfcfcc4f06f94ceba7d4f7a55f64ca570", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/205cbe2dfcfcc4f06f94ceba7d4f7a55f64ca570", "committedDate": "2020-03-11T17:26:04Z", "message": "Stop using round-tripped PipelineAggregators\n\nThis begins to clean up how `PipelineAggregator`s and executed.\nPreviously, we would create the `PipelineAggregator`s on the data nodes\nand embed them in the aggregation tree. When it came time to execute the\npipeline aggregation we'd use the `PipelineAggregator`s that were on the\nfirst shard's results. This is inefficient because:\n1. The data node needs to make the `PipelineAggregator` only to\n   serialize it and then throw it away.\n2. The coordinating node needs to deserialize all of the\n   `PipelineAggregator`s even though it only needs one of them.\n3. You end up with many `PipelineAggregator` instances when you only\n   really *need* one per pipeline.\n4. `PipelineAggregator` needs to implement serialization.\n\nThis begins to undo these by building the `PipelineAggregator`s directly\non the coordinating node and using those instead of the\n`PipelineAggregator`s in the aggregtion tree. In a follow up change\nwe'll stop serializing the `PipelineAggregator`s to node versions that\nsupport this behavior. And, one day, we'll be able to remove\n`PipelineAggregator` from the aggregation result tree entirely.\n\nImportantly, this doesn't change how pipeline aggregations are declared\nor parsed or requested. They are still part of the `AggregationBuilder`\ntree because *that* makes sense."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "229c479a4940b1842b9c509663a827d22e154412", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/229c479a4940b1842b9c509663a827d22e154412", "committedDate": "2020-03-11T17:41:10Z", "message": "Merge branch 'master' into no_round_pipelines"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "63045b8c1a8ca4cd19de85313951de914aa5783f", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/63045b8c1a8ca4cd19de85313951de914aa5783f", "committedDate": "2020-03-11T18:17:23Z", "message": "Javadoc"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5b8ba7803c189c848ebcc70dd07104862ec058fc", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/5b8ba7803c189c848ebcc70dd07104862ec058fc", "committedDate": "2020-03-11T20:42:52Z", "message": "WIP"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "04fac9b63eca7fddad3464a49824523f5ffa5962", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/04fac9b63eca7fddad3464a49824523f5ffa5962", "committedDate": "2020-03-11T23:26:31Z", "message": "Merge branch 'master' into no_round_pipelines"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8f429776fd20e4cdf508c5ed1022608db3e61971", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/8f429776fd20e4cdf508c5ed1022608db3e61971", "committedDate": "2020-03-12T19:49:55Z", "message": "Sneaky sneaky"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "abf6fc10a0cd56e55c1215249bae9ed130a6ffc0", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/abf6fc10a0cd56e55c1215249bae9ed130a6ffc0", "committedDate": "2020-03-12T21:18:17Z", "message": "Merge branch 'master' into no_round_pipelines"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzczOTE4MTIw", "url": "https://github.com/elastic/elasticsearch/pull/53423#pullrequestreview-373918120", "createdAt": "2020-03-12T21:33:40Z", "commit": {"oid": "abf6fc10a0cd56e55c1215249bae9ed130a6ffc0"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQyMTozMzo0MFrOF1wQxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQyMTozMzo0MFrOF1wQxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTkwOTU3NQ==", "bodyText": "@jimczi, I remember us trying not to hold on to references to the SearchRequest because it could be big. Or something like that. Is that still a thing? It looks like we keep the SearchRequest around for a while during the search right now.", "url": "https://github.com/elastic/elasticsearch/pull/53423#discussion_r391909575", "createdAt": "2020-03-12T21:33:40Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/search/SearchService.java", "diffHunk": "@@ -1200,9 +1203,31 @@ public IndicesService getIndicesService() {\n         return indicesService;\n     }\n \n-    public InternalAggregation.ReduceContext createReduceContext(boolean finalReduce) {\n-        return new InternalAggregation.ReduceContext(bigArrays, scriptService,\n-            finalReduce ? multiBucketConsumerService.create() : bucketCount -> {}, finalReduce);\n+    /**\n+     * Returns a builder for {@link InternalAggregation.ReduceContext}. This\n+     * builder retains a reference to the provided {@link SearchRequest}.\n+     */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "abf6fc10a0cd56e55c1215249bae9ed130a6ffc0"}, "originalPosition": 42}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzczOTI0NTYw", "url": "https://github.com/elastic/elasticsearch/pull/53423#pullrequestreview-373924560", "createdAt": "2020-03-12T21:47:00Z", "commit": {"oid": "abf6fc10a0cd56e55c1215249bae9ed130a6ffc0"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQyMTo0NzowMFrOF1w38w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQyMjowMDoxNlrOF1xeQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTkxOTYwMw==", "bodyText": "\u2764\ufe0f", "url": "https://github.com/elastic/elasticsearch/pull/53423#discussion_r391919603", "createdAt": "2020-03-12T21:47:00Z", "author": {"login": "jimczi"}, "path": "server/src/main/java/org/elasticsearch/action/search/SearchPhaseController.java", "diffHunk": "@@ -394,17 +391,30 @@ private SearchHits getHits(ReducedQueryPhase reducedQueryPhase, boolean ignoreFr\n      * @param queryResults a list of non-null query shard results\n      */\n     ReducedQueryPhase reducedScrollQueryPhase(Collection<? extends SearchPhaseResult> queryResults) {\n-        return reducedQueryPhase(queryResults, true, SearchContext.TRACK_TOTAL_HITS_ACCURATE, true);\n+        InternalAggregation.ReduceContextBuilder aggReduceContextBuilder = new InternalAggregation.ReduceContextBuilder() {\n+            @Override\n+            public ReduceContext forPartialReduction() {\n+                throw new UnsupportedOperationException(\"Scroll requests don't have aggs\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "abf6fc10a0cd56e55c1215249bae9ed130a6ffc0"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTkyNzUyNw==", "bodyText": "That's totally ok since you refer to the original request which is unique per search. You also build the pipeline tree lazily which seems like a nice win to me.", "url": "https://github.com/elastic/elasticsearch/pull/53423#discussion_r391927527", "createdAt": "2020-03-12T21:57:01Z", "author": {"login": "jimczi"}, "path": "server/src/main/java/org/elasticsearch/search/SearchService.java", "diffHunk": "@@ -1200,9 +1203,31 @@ public IndicesService getIndicesService() {\n         return indicesService;\n     }\n \n-    public InternalAggregation.ReduceContext createReduceContext(boolean finalReduce) {\n-        return new InternalAggregation.ReduceContext(bigArrays, scriptService,\n-            finalReduce ? multiBucketConsumerService.create() : bucketCount -> {}, finalReduce);\n+    /**\n+     * Returns a builder for {@link InternalAggregation.ReduceContext}. This\n+     * builder retains a reference to the provided {@link SearchRequest}.\n+     */", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTkwOTU3NQ=="}, "originalCommit": {"oid": "abf6fc10a0cd56e55c1215249bae9ed130a6ffc0"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTkyOTQwOQ==", "bodyText": "Good catch, let's open an issue since it seems easy to fix rather than a TODO ?", "url": "https://github.com/elastic/elasticsearch/pull/53423#discussion_r391929409", "createdAt": "2020-03-12T22:00:16Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/rollup/src/main/java/org/elasticsearch/xpack/rollup/RollupResponseTranslator.java", "diffHunk": "@@ -289,14 +292,14 @@ private static SearchResponse doCombineResponse(SearchResponse liveResponse, Lis\n             // Iteratively merge in each new set of unrolled aggs, so that we can identify/fix overlapping doc_counts\n             // in the next round of unrolling\n             InternalAggregations finalUnrolledAggs = new InternalAggregations(unrolledAggs);\n-            currentTree = InternalAggregations.reduce(Arrays.asList(currentTree, finalUnrolledAggs),\n-                    new InternalAggregation.ReduceContext(reduceContext.bigArrays(), reduceContext.scriptService(), true));\n+            currentTree = InternalAggregations.reduce(Arrays.asList(currentTree, finalUnrolledAggs), finalReduceContext);\n         }\n \n         // Add in the live aggregations if they exist\n         if (liveAggs.asList().size() != 0) {\n-            currentTree = InternalAggregations.reduce(Arrays.asList(currentTree, liveAggs),\n-                    new InternalAggregation.ReduceContext(reduceContext.bigArrays(), reduceContext.scriptService(), true));\n+            // TODO it looks like this passes the \"final\" reduce context more than once.\n+            // Once here and once in the for above. That is bound to cause trouble.\n+            currentTree = InternalAggregations.reduce(Arrays.asList(currentTree, liveAggs), finalReduceContext);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "abf6fc10a0cd56e55c1215249bae9ed130a6ffc0"}, "originalPosition": 32}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc0NDg3OTg2", "url": "https://github.com/elastic/elasticsearch/pull/53423#pullrequestreview-374487986", "createdAt": "2020-03-13T17:32:22Z", "commit": {"oid": "abf6fc10a0cd56e55c1215249bae9ed130a6ffc0"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xM1QxNzozMjoyMlrOF2Mhzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xM1QxNzo0MjowMFrOF2M1og==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjM3MjY4Ng==", "bodyText": "While we're here, is it possible to nuke skipResolveOrder too?  I believe it's only used by BasePipelineAggregationTestCase, and that doesn't even invoke build() so this is basically \"dead\" testing code.  I think.\nNot a problem to leave if there's a complication... I just particularly dislike this little tidbit and wouldn't mind seeing it go if we're already touching this :)", "url": "https://github.com/elastic/elasticsearch/pull/53423#discussion_r392372686", "createdAt": "2020-03-13T17:32:22Z", "author": {"login": "polyfractal"}, "path": "server/src/main/java/org/elasticsearch/search/aggregations/AggregatorFactories.java", "diffHunk": "@@ -311,8 +315,10 @@ public AggregatorFactories build(QueryShardContext queryShardContext, Aggregator\n             if (skipResolveOrder) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "abf6fc10a0cd56e55c1215249bae9ed130a6ffc0"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjM3Nzc2Mg==", "bodyText": "\ud83d\udc4d indeed.  Rollup doesn't work with pipelines anyhow (mostly due to the serialization issue, with different aggs being sent to rollup vs live indices, it messes up how pipelines operate).... but I could see multiple final reductions potentially hurting accuracy on certain aggs that care like terms", "url": "https://github.com/elastic/elasticsearch/pull/53423#discussion_r392377762", "createdAt": "2020-03-13T17:42:00Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/rollup/src/main/java/org/elasticsearch/xpack/rollup/RollupResponseTranslator.java", "diffHunk": "@@ -289,14 +292,14 @@ private static SearchResponse doCombineResponse(SearchResponse liveResponse, Lis\n             // Iteratively merge in each new set of unrolled aggs, so that we can identify/fix overlapping doc_counts\n             // in the next round of unrolling\n             InternalAggregations finalUnrolledAggs = new InternalAggregations(unrolledAggs);\n-            currentTree = InternalAggregations.reduce(Arrays.asList(currentTree, finalUnrolledAggs),\n-                    new InternalAggregation.ReduceContext(reduceContext.bigArrays(), reduceContext.scriptService(), true));\n+            currentTree = InternalAggregations.reduce(Arrays.asList(currentTree, finalUnrolledAggs), finalReduceContext);\n         }\n \n         // Add in the live aggregations if they exist\n         if (liveAggs.asList().size() != 0) {\n-            currentTree = InternalAggregations.reduce(Arrays.asList(currentTree, liveAggs),\n-                    new InternalAggregation.ReduceContext(reduceContext.bigArrays(), reduceContext.scriptService(), true));\n+            // TODO it looks like this passes the \"final\" reduce context more than once.\n+            // Once here and once in the for above. That is bound to cause trouble.\n+            currentTree = InternalAggregations.reduce(Arrays.asList(currentTree, liveAggs), finalReduceContext);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTkyOTQwOQ=="}, "originalCommit": {"oid": "abf6fc10a0cd56e55c1215249bae9ed130a6ffc0"}, "originalPosition": 32}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9e5025612bc5a33515eca21593d8a70b583c1056", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/9e5025612bc5a33515eca21593d8a70b583c1056", "committedDate": "2020-03-16T17:25:09Z", "message": "Merge branch 'master' into no_round_pipelines"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fed6af65ab772c8aa34302dd1731e7a4cbeda3c2", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/fed6af65ab772c8aa34302dd1731e7a4cbeda3c2", "committedDate": "2020-03-16T17:46:41Z", "message": "Drop skip resolve order"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1486, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}