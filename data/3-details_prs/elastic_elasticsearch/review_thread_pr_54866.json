{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDAwMTMzMDgy", "number": 54866, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNDowOToxNFrODvlDyw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNToxNToyM1rODwChhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMjE2ODQzOnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/snapshots/SnapshotResiliencyTests.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNDowOToxNFrOGCFX9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQwNzozOTo0NFrOGDNGtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDgzODM5MQ==", "bodyText": "Shouldn't it be always hasSize(0) when waitForSnapshot is true?", "url": "https://github.com/elastic/elasticsearch/pull/54866#discussion_r404838391", "createdAt": "2020-04-07T14:09:14Z", "author": {"login": "tlrx"}, "path": "server/src/test/java/org/elasticsearch/snapshots/SnapshotResiliencyTests.java", "diffHunk": "@@ -407,6 +408,49 @@ public void testSnapshotWithNodeDisconnects() {\n         assertThat(snapshotIds, hasSize(1));\n     }\n \n+    public void testSnapshotDeleteWithMasterFailOvers() {\n+        final int dataNodes = randomIntBetween(2, 10);\n+        final int masterNodes = randomFrom(3, 5);\n+        setupTestCluster(masterNodes, dataNodes);\n+\n+        String repoName = \"repo\";\n+        String snapshotName = \"snapshot\";\n+        final String index = \"test\";\n+        final int shards = randomIntBetween(1, 10);\n+\n+        final boolean waitForSnapshot = randomBoolean();\n+        final StepListener<CreateSnapshotResponse> createSnapshotResponseStepListener = new StepListener<>();\n+        continueOrDie(createRepoAndIndex(repoName, index, shards), createIndexResponse ->\n+            testClusterNodes.randomMasterNodeSafe().client.admin().cluster().prepareCreateSnapshot(repoName, snapshotName)\n+                .setWaitForCompletion(waitForSnapshot).execute(createSnapshotResponseStepListener));\n+\n+        final AtomicBoolean snapshotDeleteResponded = new AtomicBoolean(false);\n+        continueOrDie(createSnapshotResponseStepListener, createSnapshotResponse -> {\n+            scheduleNow(this::disconnectOrRestartMasterNode);\n+            testClusterNodes.randomDataNodeSafe().client.admin().cluster()\n+                .prepareDeleteSnapshot(repoName, snapshotName).execute(ActionListener.wrap(() -> snapshotDeleteResponded.set(true)));\n+        });\n+\n+        runUntil(() -> testClusterNodes.randomMasterNode().map(master -> {\n+            if (snapshotDeleteResponded.get() == false) {\n+                return false;\n+            }\n+            final SnapshotDeletionsInProgress snapshotDeletionsInProgress =\n+                master.clusterService.state().custom(SnapshotDeletionsInProgress.TYPE);\n+            return snapshotDeletionsInProgress == null || snapshotDeletionsInProgress.getEntries().isEmpty();\n+        }).orElse(false), TimeUnit.MINUTES.toMillis(1L));\n+\n+        clearDisruptionsAndAwaitSync();\n+\n+        final TestClusterNodes.TestClusterNode randomMaster = testClusterNodes.randomMasterNode()\n+            .orElseThrow(() -> new AssertionError(\"expected to find at least one active master node\"));\n+        SnapshotsInProgress finalSnapshotsInProgress = randomMaster.clusterService.state().custom(SnapshotsInProgress.TYPE);\n+        assertThat(finalSnapshotsInProgress.entries(), empty());\n+        final Repository repository = randomMaster.repositoriesService.repository(repoName);\n+        Collection<SnapshotId> snapshotIds = getRepositoryData(repository).getSnapshotIds();\n+        assertThat(snapshotIds, either(hasSize(1)).or(hasSize(0)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c34b37b11aec1978959713ee1315341be171425"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDg0MDc5Nw==", "bodyText": "Right :) I shouldn't have mindlessly copied that from the concurrent snapshots branch.  Thanks for spotting :)", "url": "https://github.com/elastic/elasticsearch/pull/54866#discussion_r404840797", "createdAt": "2020-04-07T14:12:31Z", "author": {"login": "original-brownbear"}, "path": "server/src/test/java/org/elasticsearch/snapshots/SnapshotResiliencyTests.java", "diffHunk": "@@ -407,6 +408,49 @@ public void testSnapshotWithNodeDisconnects() {\n         assertThat(snapshotIds, hasSize(1));\n     }\n \n+    public void testSnapshotDeleteWithMasterFailOvers() {\n+        final int dataNodes = randomIntBetween(2, 10);\n+        final int masterNodes = randomFrom(3, 5);\n+        setupTestCluster(masterNodes, dataNodes);\n+\n+        String repoName = \"repo\";\n+        String snapshotName = \"snapshot\";\n+        final String index = \"test\";\n+        final int shards = randomIntBetween(1, 10);\n+\n+        final boolean waitForSnapshot = randomBoolean();\n+        final StepListener<CreateSnapshotResponse> createSnapshotResponseStepListener = new StepListener<>();\n+        continueOrDie(createRepoAndIndex(repoName, index, shards), createIndexResponse ->\n+            testClusterNodes.randomMasterNodeSafe().client.admin().cluster().prepareCreateSnapshot(repoName, snapshotName)\n+                .setWaitForCompletion(waitForSnapshot).execute(createSnapshotResponseStepListener));\n+\n+        final AtomicBoolean snapshotDeleteResponded = new AtomicBoolean(false);\n+        continueOrDie(createSnapshotResponseStepListener, createSnapshotResponse -> {\n+            scheduleNow(this::disconnectOrRestartMasterNode);\n+            testClusterNodes.randomDataNodeSafe().client.admin().cluster()\n+                .prepareDeleteSnapshot(repoName, snapshotName).execute(ActionListener.wrap(() -> snapshotDeleteResponded.set(true)));\n+        });\n+\n+        runUntil(() -> testClusterNodes.randomMasterNode().map(master -> {\n+            if (snapshotDeleteResponded.get() == false) {\n+                return false;\n+            }\n+            final SnapshotDeletionsInProgress snapshotDeletionsInProgress =\n+                master.clusterService.state().custom(SnapshotDeletionsInProgress.TYPE);\n+            return snapshotDeletionsInProgress == null || snapshotDeletionsInProgress.getEntries().isEmpty();\n+        }).orElse(false), TimeUnit.MINUTES.toMillis(1L));\n+\n+        clearDisruptionsAndAwaitSync();\n+\n+        final TestClusterNodes.TestClusterNode randomMaster = testClusterNodes.randomMasterNode()\n+            .orElseThrow(() -> new AssertionError(\"expected to find at least one active master node\"));\n+        SnapshotsInProgress finalSnapshotsInProgress = randomMaster.clusterService.state().custom(SnapshotsInProgress.TYPE);\n+        assertThat(finalSnapshotsInProgress.entries(), empty());\n+        final Repository repository = randomMaster.repositoriesService.repository(repoName);\n+        Collection<SnapshotId> snapshotIds = getRepositoryData(repository).getSnapshotIds();\n+        assertThat(snapshotIds, either(hasSize(1)).or(hasSize(0)));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDgzODM5MQ=="}, "originalCommit": {"oid": "7c34b37b11aec1978959713ee1315341be171425"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDkzMjcwNQ==", "bodyText": "As a matter of fact, thanks to recent fixes this is always 0. Even on master fail-over the deletes are now properly retried :) Adjusted tests accordingly. Interestingly enough, this created one strange spot for one, one in a million seed where the cleanup logic would take multiple minutes to complete on the fake threadpool (so it's just fake minutes) but still interesting => that's why I had to up the timeout there.\nI'm investigating why that is now.", "url": "https://github.com/elastic/elasticsearch/pull/54866#discussion_r404932705", "createdAt": "2020-04-07T16:09:52Z", "author": {"login": "original-brownbear"}, "path": "server/src/test/java/org/elasticsearch/snapshots/SnapshotResiliencyTests.java", "diffHunk": "@@ -407,6 +408,49 @@ public void testSnapshotWithNodeDisconnects() {\n         assertThat(snapshotIds, hasSize(1));\n     }\n \n+    public void testSnapshotDeleteWithMasterFailOvers() {\n+        final int dataNodes = randomIntBetween(2, 10);\n+        final int masterNodes = randomFrom(3, 5);\n+        setupTestCluster(masterNodes, dataNodes);\n+\n+        String repoName = \"repo\";\n+        String snapshotName = \"snapshot\";\n+        final String index = \"test\";\n+        final int shards = randomIntBetween(1, 10);\n+\n+        final boolean waitForSnapshot = randomBoolean();\n+        final StepListener<CreateSnapshotResponse> createSnapshotResponseStepListener = new StepListener<>();\n+        continueOrDie(createRepoAndIndex(repoName, index, shards), createIndexResponse ->\n+            testClusterNodes.randomMasterNodeSafe().client.admin().cluster().prepareCreateSnapshot(repoName, snapshotName)\n+                .setWaitForCompletion(waitForSnapshot).execute(createSnapshotResponseStepListener));\n+\n+        final AtomicBoolean snapshotDeleteResponded = new AtomicBoolean(false);\n+        continueOrDie(createSnapshotResponseStepListener, createSnapshotResponse -> {\n+            scheduleNow(this::disconnectOrRestartMasterNode);\n+            testClusterNodes.randomDataNodeSafe().client.admin().cluster()\n+                .prepareDeleteSnapshot(repoName, snapshotName).execute(ActionListener.wrap(() -> snapshotDeleteResponded.set(true)));\n+        });\n+\n+        runUntil(() -> testClusterNodes.randomMasterNode().map(master -> {\n+            if (snapshotDeleteResponded.get() == false) {\n+                return false;\n+            }\n+            final SnapshotDeletionsInProgress snapshotDeletionsInProgress =\n+                master.clusterService.state().custom(SnapshotDeletionsInProgress.TYPE);\n+            return snapshotDeletionsInProgress == null || snapshotDeletionsInProgress.getEntries().isEmpty();\n+        }).orElse(false), TimeUnit.MINUTES.toMillis(1L));\n+\n+        clearDisruptionsAndAwaitSync();\n+\n+        final TestClusterNodes.TestClusterNode randomMaster = testClusterNodes.randomMasterNode()\n+            .orElseThrow(() -> new AssertionError(\"expected to find at least one active master node\"));\n+        SnapshotsInProgress finalSnapshotsInProgress = randomMaster.clusterService.state().custom(SnapshotsInProgress.TYPE);\n+        assertThat(finalSnapshotsInProgress.entries(), empty());\n+        final Repository repository = randomMaster.repositoriesService.repository(repoName);\n+        Collection<SnapshotId> snapshotIds = getRepositoryData(repository).getSnapshotIds();\n+        assertThat(snapshotIds, either(hasSize(1)).or(hasSize(0)));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDgzODM5MQ=="}, "originalCommit": {"oid": "7c34b37b11aec1978959713ee1315341be171425"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQ5OTgxMg==", "bodyText": "@tlrx This was a really stupid bug ... forgot to start the node connections service. This had some strange side effects since it resulted in some transport handlers never failing, causing some CS publications on the failing over master to never complete, causing this test to only move on once the failing master was again removed from the cluster after the 1.5m publication timeout ... behaves much better now.\nShould be good for review with 3370c84 now :)", "url": "https://github.com/elastic/elasticsearch/pull/54866#discussion_r405499812", "createdAt": "2020-04-08T12:51:59Z", "author": {"login": "original-brownbear"}, "path": "server/src/test/java/org/elasticsearch/snapshots/SnapshotResiliencyTests.java", "diffHunk": "@@ -407,6 +408,49 @@ public void testSnapshotWithNodeDisconnects() {\n         assertThat(snapshotIds, hasSize(1));\n     }\n \n+    public void testSnapshotDeleteWithMasterFailOvers() {\n+        final int dataNodes = randomIntBetween(2, 10);\n+        final int masterNodes = randomFrom(3, 5);\n+        setupTestCluster(masterNodes, dataNodes);\n+\n+        String repoName = \"repo\";\n+        String snapshotName = \"snapshot\";\n+        final String index = \"test\";\n+        final int shards = randomIntBetween(1, 10);\n+\n+        final boolean waitForSnapshot = randomBoolean();\n+        final StepListener<CreateSnapshotResponse> createSnapshotResponseStepListener = new StepListener<>();\n+        continueOrDie(createRepoAndIndex(repoName, index, shards), createIndexResponse ->\n+            testClusterNodes.randomMasterNodeSafe().client.admin().cluster().prepareCreateSnapshot(repoName, snapshotName)\n+                .setWaitForCompletion(waitForSnapshot).execute(createSnapshotResponseStepListener));\n+\n+        final AtomicBoolean snapshotDeleteResponded = new AtomicBoolean(false);\n+        continueOrDie(createSnapshotResponseStepListener, createSnapshotResponse -> {\n+            scheduleNow(this::disconnectOrRestartMasterNode);\n+            testClusterNodes.randomDataNodeSafe().client.admin().cluster()\n+                .prepareDeleteSnapshot(repoName, snapshotName).execute(ActionListener.wrap(() -> snapshotDeleteResponded.set(true)));\n+        });\n+\n+        runUntil(() -> testClusterNodes.randomMasterNode().map(master -> {\n+            if (snapshotDeleteResponded.get() == false) {\n+                return false;\n+            }\n+            final SnapshotDeletionsInProgress snapshotDeletionsInProgress =\n+                master.clusterService.state().custom(SnapshotDeletionsInProgress.TYPE);\n+            return snapshotDeletionsInProgress == null || snapshotDeletionsInProgress.getEntries().isEmpty();\n+        }).orElse(false), TimeUnit.MINUTES.toMillis(1L));\n+\n+        clearDisruptionsAndAwaitSync();\n+\n+        final TestClusterNodes.TestClusterNode randomMaster = testClusterNodes.randomMasterNode()\n+            .orElseThrow(() -> new AssertionError(\"expected to find at least one active master node\"));\n+        SnapshotsInProgress finalSnapshotsInProgress = randomMaster.clusterService.state().custom(SnapshotsInProgress.TYPE);\n+        assertThat(finalSnapshotsInProgress.entries(), empty());\n+        final Repository repository = randomMaster.repositoriesService.repository(repoName);\n+        Collection<SnapshotId> snapshotIds = getRepositoryData(repository).getSnapshotIds();\n+        assertThat(snapshotIds, either(hasSize(1)).or(hasSize(0)));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDgzODM5MQ=="}, "originalCommit": {"oid": "7c34b37b11aec1978959713ee1315341be171425"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjAxMzYyMQ==", "bodyText": "LGTM :) Thanks Armin", "url": "https://github.com/elastic/elasticsearch/pull/54866#discussion_r406013621", "createdAt": "2020-04-09T07:39:44Z", "author": {"login": "tlrx"}, "path": "server/src/test/java/org/elasticsearch/snapshots/SnapshotResiliencyTests.java", "diffHunk": "@@ -407,6 +408,49 @@ public void testSnapshotWithNodeDisconnects() {\n         assertThat(snapshotIds, hasSize(1));\n     }\n \n+    public void testSnapshotDeleteWithMasterFailOvers() {\n+        final int dataNodes = randomIntBetween(2, 10);\n+        final int masterNodes = randomFrom(3, 5);\n+        setupTestCluster(masterNodes, dataNodes);\n+\n+        String repoName = \"repo\";\n+        String snapshotName = \"snapshot\";\n+        final String index = \"test\";\n+        final int shards = randomIntBetween(1, 10);\n+\n+        final boolean waitForSnapshot = randomBoolean();\n+        final StepListener<CreateSnapshotResponse> createSnapshotResponseStepListener = new StepListener<>();\n+        continueOrDie(createRepoAndIndex(repoName, index, shards), createIndexResponse ->\n+            testClusterNodes.randomMasterNodeSafe().client.admin().cluster().prepareCreateSnapshot(repoName, snapshotName)\n+                .setWaitForCompletion(waitForSnapshot).execute(createSnapshotResponseStepListener));\n+\n+        final AtomicBoolean snapshotDeleteResponded = new AtomicBoolean(false);\n+        continueOrDie(createSnapshotResponseStepListener, createSnapshotResponse -> {\n+            scheduleNow(this::disconnectOrRestartMasterNode);\n+            testClusterNodes.randomDataNodeSafe().client.admin().cluster()\n+                .prepareDeleteSnapshot(repoName, snapshotName).execute(ActionListener.wrap(() -> snapshotDeleteResponded.set(true)));\n+        });\n+\n+        runUntil(() -> testClusterNodes.randomMasterNode().map(master -> {\n+            if (snapshotDeleteResponded.get() == false) {\n+                return false;\n+            }\n+            final SnapshotDeletionsInProgress snapshotDeletionsInProgress =\n+                master.clusterService.state().custom(SnapshotDeletionsInProgress.TYPE);\n+            return snapshotDeletionsInProgress == null || snapshotDeletionsInProgress.getEntries().isEmpty();\n+        }).orElse(false), TimeUnit.MINUTES.toMillis(1L));\n+\n+        clearDisruptionsAndAwaitSync();\n+\n+        final TestClusterNodes.TestClusterNode randomMaster = testClusterNodes.randomMasterNode()\n+            .orElseThrow(() -> new AssertionError(\"expected to find at least one active master node\"));\n+        SnapshotsInProgress finalSnapshotsInProgress = randomMaster.clusterService.state().custom(SnapshotsInProgress.TYPE);\n+        assertThat(finalSnapshotsInProgress.entries(), empty());\n+        final Repository repository = randomMaster.repositoriesService.repository(repoName);\n+        Collection<SnapshotId> snapshotIds = getRepositoryData(repository).getSnapshotIds();\n+        assertThat(snapshotIds, either(hasSize(1)).or(hasSize(0)));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDgzODM5MQ=="}, "originalCommit": {"oid": "7c34b37b11aec1978959713ee1315341be171425"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMjc1NTcwOnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/snapshots/SnapshotResiliencyTests.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNjoxMDo0NlrOGCLLAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNjoxMDo0NlrOGCLLAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDkzMzM3Nw==", "bodyText": "I'm investigating why this is taking so long, until then upping the value here to because even though I found a seed that fails here now I bet there's one where this could fail in one of the other master failover tests.", "url": "https://github.com/elastic/elasticsearch/pull/54866#discussion_r404933377", "createdAt": "2020-04-07T16:10:46Z", "author": {"login": "original-brownbear"}, "path": "server/src/test/java/org/elasticsearch/snapshots/SnapshotResiliencyTests.java", "diffHunk": "@@ -266,7 +267,7 @@ public void verifyReposThenStopServices() {\n             final AtomicBoolean cleanedUp = new AtomicBoolean(false);\n             continueOrDie(cleanupResponse, r -> cleanedUp.set(true));\n \n-            runUntil(cleanedUp::get, TimeUnit.MINUTES.toMillis(1L));\n+            runUntil(cleanedUp::get, TimeUnit.MINUTES.toMillis(5L));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "50088b6622cc1df39b03632f436ab3f5ab91647d"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNjk4MDMxOnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/snapshots/SnapshotResiliencyTests.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNToxMjoxMVrOGCz4Sg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNzowMDo1MFrOGC4fXA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYwMDMzMA==", "bodyText": "Should we also call close in the stop method?", "url": "https://github.com/elastic/elasticsearch/pull/54866#discussion_r405600330", "createdAt": "2020-04-08T15:12:11Z", "author": {"login": "ywelsch"}, "path": "server/src/test/java/org/elasticsearch/snapshots/SnapshotResiliencyTests.java", "diffHunk": "@@ -1477,10 +1525,9 @@ public void start(ClusterState initialState) {\n                     new BatchedRerouteService(clusterService, allocationService::reroute), ElectionStrategy.DEFAULT_INSTANCE);\n                 masterService.setClusterStatePublisher(coordinator);\n                 coordinator.start();\n-                masterService.start();\n-                clusterService.getClusterApplierService().setNodeConnectionsService(\n-                    new NodeConnectionsService(clusterService.getSettings(), threadPool, transportService));\n-                clusterService.getClusterApplierService().start();\n+                clusterService.getClusterApplierService().setNodeConnectionsService(nodeConnectionsService);\n+                nodeConnectionsService.start();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3370c84c53249d81414e2ee29900d6537e7b713a"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTY3NTg2OA==", "bodyText": "Yea let's do it to prevent stray connection checks.", "url": "https://github.com/elastic/elasticsearch/pull/54866#discussion_r405675868", "createdAt": "2020-04-08T17:00:50Z", "author": {"login": "original-brownbear"}, "path": "server/src/test/java/org/elasticsearch/snapshots/SnapshotResiliencyTests.java", "diffHunk": "@@ -1477,10 +1525,9 @@ public void start(ClusterState initialState) {\n                     new BatchedRerouteService(clusterService, allocationService::reroute), ElectionStrategy.DEFAULT_INSTANCE);\n                 masterService.setClusterStatePublisher(coordinator);\n                 coordinator.start();\n-                masterService.start();\n-                clusterService.getClusterApplierService().setNodeConnectionsService(\n-                    new NodeConnectionsService(clusterService.getSettings(), threadPool, transportService));\n-                clusterService.getClusterApplierService().start();\n+                clusterService.getClusterApplierService().setNodeConnectionsService(nodeConnectionsService);\n+                nodeConnectionsService.start();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYwMDMzMA=="}, "originalCommit": {"oid": "3370c84c53249d81414e2ee29900d6537e7b713a"}, "originalPosition": 85}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNjk5NTg5OnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/snapshots/SnapshotResiliencyTests.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNToxNToyM1rOGC0Bog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNToxNToyM1rOGC0Bog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYwMjcyMg==", "bodyText": "Failover", "url": "https://github.com/elastic/elasticsearch/pull/54866#discussion_r405602722", "createdAt": "2020-04-08T15:15:23Z", "author": {"login": "ywelsch"}, "path": "server/src/test/java/org/elasticsearch/snapshots/SnapshotResiliencyTests.java", "diffHunk": "@@ -407,6 +408,49 @@ public void testSnapshotWithNodeDisconnects() {\n         assertThat(snapshotIds, hasSize(1));\n     }\n \n+    public void testSnapshotDeleteWithMasterFailOvers() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3370c84c53249d81414e2ee29900d6537e7b713a"}, "originalPosition": 12}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1282, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}