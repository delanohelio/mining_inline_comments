{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY0MTQzODA1", "number": 51155, "title": "Implement top_metrics agg", "bodyText": "The top_metrics agg is kind of like top_hits but it only works on\ndoc values so it should be faster.\nAt this point it is fairly limited in that it only supports a single,\nnumeric sort and a single, numeric metric. And it only fetches the \"very\ntopest\" document worth of metric. We plan to support returning a\nconfigurable number of top metrics, requesting more than one metric and\nmore than one sort. And, eventually, non-numeric sorts and metrics. The\ntrick is doing those things fairly efficiently.\nCloses #48069\nCo-Authored by: Zachary Tong zach@elastic.co", "createdAt": "2020-01-17T13:33:41Z", "url": "https://github.com/elastic/elasticsearch/pull/51155", "merged": true, "mergeCommit": {"oid": "5b2266601bea9de8082891ee4fcdf5171c1a9084"}, "closed": true, "closedAt": "2020-02-14T12:13:53Z", "author": {"login": "nik9000"}, "timelineItems": {"totalCount": 88, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb7O1BpgH2gAyMzY0MTQzODA1OjBmYjM3YjUzZWZhODY0ZDY1MDU0YmVkY2Q2ZjVkZWJkMzg0NzA4NjU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcENbzlgH2gAyMzY0MTQzODA1Ojg5NmUwOGFhMzNiMmIxZjcwYThmNzA2ZTQ0NjE3OThmN2JjMGIyODI=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "0fb37b53efa864d65054bedcd6f5debd38470865", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/0fb37b53efa864d65054bedcd6f5debd38470865", "committedDate": "2020-01-17T13:33:03Z", "message": "Implement top_metrics agg\n\nThe `top_metrics` agg is kind of like `top_hits` but it only works on\ndoc values so it *should* be faster.\n\nAt this point it is fairly limited in that it only supports a single,\nnumeric sort and a single, numeric metric. And it only fetches the \"very\ntopest\" document worth of metric. We plan to support returning a\nconfigurable number of top metrics, requesting more than one metric and\nmore than one sort. And, eventually, non-numeric sorts and metrics. The\ntrick is doing those things fairly efficiently.\n\nCo-Authored by: Zachary Tong <zach@elastic.co>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a105a6351ea8f0f23817ac6e9ae77785a4cf2858", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/a105a6351ea8f0f23817ac6e9ae77785a4cf2858", "committedDate": "2020-01-17T14:10:17Z", "message": "Moar tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4d2557d4c89fbfd6aa211780e2ea4f85cf5f0f0b", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/4d2557d4c89fbfd6aa211780e2ea4f85cf5f0f0b", "committedDate": "2020-01-17T14:19:23Z", "message": "Better"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5146563423e13c3199b335b274d528de0c2fba4a", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/5146563423e13c3199b335b274d528de0c2fba4a", "committedDate": "2020-01-17T14:24:26Z", "message": "Checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "12abffde5614ccd005252ebd7e33b942e084d662", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/12abffde5614ccd005252ebd7e33b942e084d662", "committedDate": "2020-01-17T14:28:02Z", "message": "Fixup docs compile"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a685e2936b9328c1b21c4d606f5aacc640dcffcd", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/a685e2936b9328c1b21c4d606f5aacc640dcffcd", "committedDate": "2020-01-17T14:41:12Z", "message": "Explain"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0f130d4ac9909f5a201cc6455cce643382260371", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/0f130d4ac9909f5a201cc6455cce643382260371", "committedDate": "2020-01-17T15:40:23Z", "message": "Sneaky sneaky"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ0NzExODQx", "url": "https://github.com/elastic/elasticsearch/pull/51155#pullrequestreview-344711841", "createdAt": "2020-01-17T16:55:03Z", "commit": {"oid": "0fb37b53efa864d65054bedcd6f5debd38470865"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxNjo1NTowM1rOFe_Mmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxNjo1NTowM1rOFe_Mmw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODAzNzAxOQ==", "bodyText": "Note to self: this should blow up on the default case.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r368037019", "createdAt": "2020-01-17T16:55:03Z", "author": {"login": "nik9000"}, "path": "x-pack/plugin/analytics/src/test/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetricsWireTests.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.elasticsearch.common.io.stream.NamedWriteableRegistry;\n+import org.elasticsearch.common.io.stream.Writeable.Reader;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.test.AbstractWireSerializingTestCase;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static java.util.Collections.emptyList;\n+import static java.util.Collections.unmodifiableList;\n+import static java.util.stream.Collectors.toList;\n+\n+public class InternalTopMetricsWireTests extends AbstractWireSerializingTestCase<InternalTopMetrics> {\n+    private static final List<DocValueFormat> RANDOM_FORMATS = unmodifiableList(Arrays.asList(\n+            DocValueFormat.RAW, DocValueFormat.BINARY, DocValueFormat.BOOLEAN\n+    ));\n+\n+    @Override\n+    protected NamedWriteableRegistry getNamedWriteableRegistry() {\n+        return new NamedWriteableRegistry(RANDOM_FORMATS.stream()\n+                .map(f -> new NamedWriteableRegistry.Entry(DocValueFormat.class, f.getWriteableName(), in -> f))\n+                .collect(toList())); \n+    }\n+\n+    @Override\n+    protected InternalTopMetrics createTestInstance() {\n+        String name = randomAlphaOfLength(5);\n+        DocValueFormat sortFormat = randomFrom(RANDOM_FORMATS);\n+        SortOrder sortOrder = randomFrom(SortOrder.values());\n+        double sortValue = randomDouble();\n+        String metricName = randomAlphaOfLength(5);\n+        double metricValue = randomDouble();\n+        return new InternalTopMetrics(name, sortFormat, sortOrder, sortValue, metricName, metricValue, emptyList(), null);\n+    }\n+    \n+    @Override\n+    protected InternalTopMetrics mutateInstance(InternalTopMetrics instance) throws IOException {\n+        String name = instance.getName();\n+        DocValueFormat sortFormat = instance.getSortFormat();\n+        SortOrder sortOrder = instance.getSortOrder();\n+        double sortValue = instance.getSortValue();\n+        String metricName = instance.getMetricName();\n+        double metricValue = instance.getMetricValue();\n+        switch (randomInt(5)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fb37b53efa864d65054bedcd6f5debd38470865"}, "originalPosition": 54}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eacddb520c738500def6dbcdbe9c19cf0f2a2057", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/eacddb520c738500def6dbcdbe9c19cf0f2a2057", "committedDate": "2020-01-17T17:16:35Z", "message": "Merge branch 'master' into top_metrics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c", "committedDate": "2020-01-17T17:17:48Z", "message": "Throw"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ2MDU5Mzk0", "url": "https://github.com/elastic/elasticsearch/pull/51155#pullrequestreview-346059394", "createdAt": "2020-01-21T17:29:46Z", "commit": {"oid": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c"}, "state": "COMMENTED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQxNzoyOTo0NlrOFgCj2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQxOTo0NTo1MlrOFgGk0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE0MDY5Ng==", "bodyText": "Typo?  Should be \"smallest value of s\" ?", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369140696", "createdAt": "2020-01-21T17:29:46Z", "author": {"login": "polyfractal"}, "path": "docs/reference/aggregations/metrics/top-metrics-aggregation.asciidoc", "diffHunk": "@@ -0,0 +1,206 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[[search-aggregations-metrics-top-metrics]]\n+=== Top Metrics Aggregation\n+\n+experimental[We expect to change the response format of this aggregation as we add more features.]\n+\n+The `top_metrics` aggregation selects metrics from the document with the largest or smallest \"sort\" value. This gets\n+the value of the `v` field on the document with the largest value of `s`:\n+\n+[source,console,id=search-aggregations-metrics-top-metrics-simple]\n+----\n+POST /test/_bulk?refresh\n+{\"index\": {}}\n+{\"s\": 1, \"v\": 3.1415}\n+{\"index\": {}}\n+{\"s\": 2, \"v\": 1}\n+{\"index\": {}}\n+{\"s\": 3, \"v\": 2.71828}\n+POST /test/_search?filter_path=aggregations\n+{\n+  \"aggs\": {\n+    \"tm\": {\n+      \"top_metrics\": {\n+        \"metric\": {\"field\": \"v\"},\n+        \"sort\": {\"s\": \"desc\"}\n+      }\n+    }\n+  }\n+}\n+----\n+\n+Which returns:\n+\n+[source,js]\n+----\n+{\n+  \"aggregations\": {\n+    \"tm\": {\n+      \"top\": [ {\"sort\": [3.0], \"metrics\": {\"v\": 2.718280076980591 } } ]\n+    }\n+  }\n+}\n+----\n+// TESTRESPONSE\n+\n+And this gets the value of `v` on the document with the smallest value of `v`:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE1NTA5MQ==", "bodyText": "Hmm, should we be extending MultiValuesSourceAggregationBuilder instead?  I worry about aggs that implement AbstractAggBuilder directly.  They'll probably be harder to convert to the new VS framework, and tend to get ignored during refactoring/wide changes because they don't extend the main VS classes.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369155091", "createdAt": "2020-01-21T17:59:59Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.apache.lucene.search.FieldComparator;\n+import org.apache.lucene.search.Sort;\n+import org.apache.lucene.search.SortField;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ContextParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AbstractAggregationBuilder;\n+import org.elasticsearch.search.aggregations.AggregationBuilder;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.AggregatorFactories;\n+import org.elasticsearch.search.aggregations.AggregatorFactories.Builder;\n+import org.elasticsearch.search.aggregations.AggregatorFactory;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.MultiValuesSourceFieldConfig;\n+import org.elasticsearch.search.aggregations.support.ValueType;\n+import org.elasticsearch.search.aggregations.support.ValuesSource;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.search.sort.SortAndFormats;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+import static org.elasticsearch.search.builder.SearchSourceBuilder.SORT_FIELD;\n+\n+public class TopMetricsAggregationBuilder extends AbstractAggregationBuilder<TopMetricsAggregationBuilder> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE3MjcyNw==", "bodyText": "Maybe we can just resolve the sort field via the usual mechanism and check the ValuesSource to make sure it's what we want?  That would be more inline with how the VS refactor will do things too.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369172727", "createdAt": "2020-01-21T18:36:14Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.apache.lucene.search.FieldComparator;\n+import org.apache.lucene.search.Sort;\n+import org.apache.lucene.search.SortField;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ContextParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AbstractAggregationBuilder;\n+import org.elasticsearch.search.aggregations.AggregationBuilder;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.AggregatorFactories;\n+import org.elasticsearch.search.aggregations.AggregatorFactories.Builder;\n+import org.elasticsearch.search.aggregations.AggregatorFactory;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.MultiValuesSourceFieldConfig;\n+import org.elasticsearch.search.aggregations.support.ValueType;\n+import org.elasticsearch.search.aggregations.support.ValuesSource;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.search.sort.SortAndFormats;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+import static org.elasticsearch.search.builder.SearchSourceBuilder.SORT_FIELD;\n+\n+public class TopMetricsAggregationBuilder extends AbstractAggregationBuilder<TopMetricsAggregationBuilder> {\n+    public static final String NAME = \"top_metrics\";\n+    public static final ParseField METRIC_FIELD = new ParseField(\"metric\");\n+\n+    private final List<SortBuilder<?>> sortBuilders;\n+    // TODO MultiValuesSourceFieldConfig has more things than we support and less things than we want to support\n+    private final MultiValuesSourceFieldConfig metricField;\n+\n+    /**\n+     * Ctor for parsing.\n+     */\n+    public TopMetricsAggregationBuilder(String name, List<SortBuilder<?>> sortBuilders, MultiValuesSourceFieldConfig metricField) {\n+        super(name);\n+        if (sortBuilders.size() != 1) {\n+            throw new IllegalArgumentException(\"[sort] must contain exactly one sort\");\n+        }\n+        this.sortBuilders = sortBuilders;\n+        this.metricField = metricField;\n+    }\n+\n+    /**\n+     * Cloning ctor for reducing.\n+     */\n+    public TopMetricsAggregationBuilder(TopMetricsAggregationBuilder clone, AggregatorFactories.Builder factoriesBuilder,\n+            Map<String, Object> metaData) {\n+        super(clone, factoriesBuilder, metaData);\n+        this.sortBuilders = clone.sortBuilders;\n+        this.metricField = clone.metricField;\n+    }\n+\n+    /**\n+     * Read from a stream.\n+     */\n+    public TopMetricsAggregationBuilder(StreamInput in) throws IOException {\n+        super(in);\n+        @SuppressWarnings(\"unchecked\")\n+        List<SortBuilder<?>> sortBuilders = (List<SortBuilder<?>>) (List<?>) in.readNamedWriteableList(SortBuilder.class); \n+        this.sortBuilders = sortBuilders;\n+        this.metricField = new MultiValuesSourceFieldConfig(in);\n+    }\n+\n+    @Override\n+    protected void doWriteTo(StreamOutput out) throws IOException {\n+        out.writeNamedWriteableList(sortBuilders);\n+        metricField.writeTo(out);\n+    }\n+\n+    @Override\n+    protected AggregationBuilder shallowCopy(AggregatorFactories.Builder factoriesBuilder, Map<String, Object> metaData) {\n+        return new TopMetricsAggregationBuilder(this, factoriesBuilder, metaData);\n+    }\n+\n+    @Override\n+    protected AggregatorFactory doBuild(QueryShardContext queryShardContext, AggregatorFactory parent, Builder subFactoriesBuilder)\n+            throws IOException {\n+        ValuesSourceConfig<ValuesSource.Numeric> metricFieldSource = ValuesSourceConfig.resolve(queryShardContext, ValueType.NUMERIC,\n+                metricField.getFieldName(), metricField.getScript(), metricField.getMissing(), metricField.getTimeZone(), null);\n+        ValuesSource.Numeric metricValueSource = metricFieldSource.toValuesSource(queryShardContext);\n+        SortAndFormats sort = SortBuilder.buildSort(sortBuilders, queryShardContext).orElseGet(() ->\n+                // Empty in this case means that the we attempted to sort on score descending\n+                new SortAndFormats(new Sort(SortField.FIELD_SCORE), new DocValueFormat[] {DocValueFormat.RAW}));\n+        if (sort.sort.getSort().length != 1) {\n+            throw new IllegalArgumentException(\"[top_metrics] only supports sorting on a single field\");\n+        }\n+        SortField sortField = sort.sort.getSort()[0];\n+        FieldComparator<?> untypedCmp = sortField.getComparator(1, 0);\n+        /* This check is kind of nasty, but it is the only way we have of making sure we're getting numerics.\n+         * We would like to drop that requirement but we'll likely do that by getting *more* information\n+         * about the type, not less. */\n+        if (false == untypedCmp instanceof FieldComparator.NumericComparator &&", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE3NDk5Nw==", "bodyText": "Let's create a new AggFactory class rather than anonymous, to stay consistent with other aggs (and to make debugging easier).", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369174997", "createdAt": "2020-01-21T18:40:44Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.apache.lucene.search.FieldComparator;\n+import org.apache.lucene.search.Sort;\n+import org.apache.lucene.search.SortField;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ContextParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AbstractAggregationBuilder;\n+import org.elasticsearch.search.aggregations.AggregationBuilder;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.AggregatorFactories;\n+import org.elasticsearch.search.aggregations.AggregatorFactories.Builder;\n+import org.elasticsearch.search.aggregations.AggregatorFactory;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.MultiValuesSourceFieldConfig;\n+import org.elasticsearch.search.aggregations.support.ValueType;\n+import org.elasticsearch.search.aggregations.support.ValuesSource;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.search.sort.SortAndFormats;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+import static org.elasticsearch.search.builder.SearchSourceBuilder.SORT_FIELD;\n+\n+public class TopMetricsAggregationBuilder extends AbstractAggregationBuilder<TopMetricsAggregationBuilder> {\n+    public static final String NAME = \"top_metrics\";\n+    public static final ParseField METRIC_FIELD = new ParseField(\"metric\");\n+\n+    private final List<SortBuilder<?>> sortBuilders;\n+    // TODO MultiValuesSourceFieldConfig has more things than we support and less things than we want to support\n+    private final MultiValuesSourceFieldConfig metricField;\n+\n+    /**\n+     * Ctor for parsing.\n+     */\n+    public TopMetricsAggregationBuilder(String name, List<SortBuilder<?>> sortBuilders, MultiValuesSourceFieldConfig metricField) {\n+        super(name);\n+        if (sortBuilders.size() != 1) {\n+            throw new IllegalArgumentException(\"[sort] must contain exactly one sort\");\n+        }\n+        this.sortBuilders = sortBuilders;\n+        this.metricField = metricField;\n+    }\n+\n+    /**\n+     * Cloning ctor for reducing.\n+     */\n+    public TopMetricsAggregationBuilder(TopMetricsAggregationBuilder clone, AggregatorFactories.Builder factoriesBuilder,\n+            Map<String, Object> metaData) {\n+        super(clone, factoriesBuilder, metaData);\n+        this.sortBuilders = clone.sortBuilders;\n+        this.metricField = clone.metricField;\n+    }\n+\n+    /**\n+     * Read from a stream.\n+     */\n+    public TopMetricsAggregationBuilder(StreamInput in) throws IOException {\n+        super(in);\n+        @SuppressWarnings(\"unchecked\")\n+        List<SortBuilder<?>> sortBuilders = (List<SortBuilder<?>>) (List<?>) in.readNamedWriteableList(SortBuilder.class); \n+        this.sortBuilders = sortBuilders;\n+        this.metricField = new MultiValuesSourceFieldConfig(in);\n+    }\n+\n+    @Override\n+    protected void doWriteTo(StreamOutput out) throws IOException {\n+        out.writeNamedWriteableList(sortBuilders);\n+        metricField.writeTo(out);\n+    }\n+\n+    @Override\n+    protected AggregationBuilder shallowCopy(AggregatorFactories.Builder factoriesBuilder, Map<String, Object> metaData) {\n+        return new TopMetricsAggregationBuilder(this, factoriesBuilder, metaData);\n+    }\n+\n+    @Override\n+    protected AggregatorFactory doBuild(QueryShardContext queryShardContext, AggregatorFactory parent, Builder subFactoriesBuilder)\n+            throws IOException {\n+        ValuesSourceConfig<ValuesSource.Numeric> metricFieldSource = ValuesSourceConfig.resolve(queryShardContext, ValueType.NUMERIC,\n+                metricField.getFieldName(), metricField.getScript(), metricField.getMissing(), metricField.getTimeZone(), null);\n+        ValuesSource.Numeric metricValueSource = metricFieldSource.toValuesSource(queryShardContext);\n+        SortAndFormats sort = SortBuilder.buildSort(sortBuilders, queryShardContext).orElseGet(() ->\n+                // Empty in this case means that the we attempted to sort on score descending\n+                new SortAndFormats(new Sort(SortField.FIELD_SCORE), new DocValueFormat[] {DocValueFormat.RAW}));\n+        if (sort.sort.getSort().length != 1) {\n+            throw new IllegalArgumentException(\"[top_metrics] only supports sorting on a single field\");\n+        }\n+        SortField sortField = sort.sort.getSort()[0];\n+        FieldComparator<?> untypedCmp = sortField.getComparator(1, 0);\n+        /* This check is kind of nasty, but it is the only way we have of making sure we're getting numerics.\n+         * We would like to drop that requirement but we'll likely do that by getting *more* information\n+         * about the type, not less. */\n+        if (false == untypedCmp instanceof FieldComparator.NumericComparator &&\n+                false == untypedCmp instanceof FieldComparator.RelevanceComparator) {\n+            throw new IllegalArgumentException(\"[top_metrics] only supports sorting on numeric values\");\n+        }\n+        @SuppressWarnings(\"unchecked\") // We checked this with instanceof above\n+        FieldComparator<? extends Number> sortComparator = (FieldComparator<? extends Number>) untypedCmp;\n+        return new AggregatorFactory(name, queryShardContext, parent, subFactoriesBuilder, metaData) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE3NTQ0NQ==", "bodyText": "Let's move this to the top of the AggBuilder for consistency w/ other aggs.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369175445", "createdAt": "2020-01-21T18:41:36Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.apache.lucene.search.FieldComparator;\n+import org.apache.lucene.search.Sort;\n+import org.apache.lucene.search.SortField;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ContextParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AbstractAggregationBuilder;\n+import org.elasticsearch.search.aggregations.AggregationBuilder;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.AggregatorFactories;\n+import org.elasticsearch.search.aggregations.AggregatorFactories.Builder;\n+import org.elasticsearch.search.aggregations.AggregatorFactory;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.MultiValuesSourceFieldConfig;\n+import org.elasticsearch.search.aggregations.support.ValueType;\n+import org.elasticsearch.search.aggregations.support.ValuesSource;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.search.sort.SortAndFormats;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+import static org.elasticsearch.search.builder.SearchSourceBuilder.SORT_FIELD;\n+\n+public class TopMetricsAggregationBuilder extends AbstractAggregationBuilder<TopMetricsAggregationBuilder> {\n+    public static final String NAME = \"top_metrics\";\n+    public static final ParseField METRIC_FIELD = new ParseField(\"metric\");\n+\n+    private final List<SortBuilder<?>> sortBuilders;\n+    // TODO MultiValuesSourceFieldConfig has more things than we support and less things than we want to support\n+    private final MultiValuesSourceFieldConfig metricField;\n+\n+    /**\n+     * Ctor for parsing.\n+     */\n+    public TopMetricsAggregationBuilder(String name, List<SortBuilder<?>> sortBuilders, MultiValuesSourceFieldConfig metricField) {\n+        super(name);\n+        if (sortBuilders.size() != 1) {\n+            throw new IllegalArgumentException(\"[sort] must contain exactly one sort\");\n+        }\n+        this.sortBuilders = sortBuilders;\n+        this.metricField = metricField;\n+    }\n+\n+    /**\n+     * Cloning ctor for reducing.\n+     */\n+    public TopMetricsAggregationBuilder(TopMetricsAggregationBuilder clone, AggregatorFactories.Builder factoriesBuilder,\n+            Map<String, Object> metaData) {\n+        super(clone, factoriesBuilder, metaData);\n+        this.sortBuilders = clone.sortBuilders;\n+        this.metricField = clone.metricField;\n+    }\n+\n+    /**\n+     * Read from a stream.\n+     */\n+    public TopMetricsAggregationBuilder(StreamInput in) throws IOException {\n+        super(in);\n+        @SuppressWarnings(\"unchecked\")\n+        List<SortBuilder<?>> sortBuilders = (List<SortBuilder<?>>) (List<?>) in.readNamedWriteableList(SortBuilder.class); \n+        this.sortBuilders = sortBuilders;\n+        this.metricField = new MultiValuesSourceFieldConfig(in);\n+    }\n+\n+    @Override\n+    protected void doWriteTo(StreamOutput out) throws IOException {\n+        out.writeNamedWriteableList(sortBuilders);\n+        metricField.writeTo(out);\n+    }\n+\n+    @Override\n+    protected AggregationBuilder shallowCopy(AggregatorFactories.Builder factoriesBuilder, Map<String, Object> metaData) {\n+        return new TopMetricsAggregationBuilder(this, factoriesBuilder, metaData);\n+    }\n+\n+    @Override\n+    protected AggregatorFactory doBuild(QueryShardContext queryShardContext, AggregatorFactory parent, Builder subFactoriesBuilder)\n+            throws IOException {\n+        ValuesSourceConfig<ValuesSource.Numeric> metricFieldSource = ValuesSourceConfig.resolve(queryShardContext, ValueType.NUMERIC,\n+                metricField.getFieldName(), metricField.getScript(), metricField.getMissing(), metricField.getTimeZone(), null);\n+        ValuesSource.Numeric metricValueSource = metricFieldSource.toValuesSource(queryShardContext);\n+        SortAndFormats sort = SortBuilder.buildSort(sortBuilders, queryShardContext).orElseGet(() ->\n+                // Empty in this case means that the we attempted to sort on score descending\n+                new SortAndFormats(new Sort(SortField.FIELD_SCORE), new DocValueFormat[] {DocValueFormat.RAW}));\n+        if (sort.sort.getSort().length != 1) {\n+            throw new IllegalArgumentException(\"[top_metrics] only supports sorting on a single field\");\n+        }\n+        SortField sortField = sort.sort.getSort()[0];\n+        FieldComparator<?> untypedCmp = sortField.getComparator(1, 0);\n+        /* This check is kind of nasty, but it is the only way we have of making sure we're getting numerics.\n+         * We would like to drop that requirement but we'll likely do that by getting *more* information\n+         * about the type, not less. */\n+        if (false == untypedCmp instanceof FieldComparator.NumericComparator &&\n+                false == untypedCmp instanceof FieldComparator.RelevanceComparator) {\n+            throw new IllegalArgumentException(\"[top_metrics] only supports sorting on numeric values\");\n+        }\n+        @SuppressWarnings(\"unchecked\") // We checked this with instanceof above\n+        FieldComparator<? extends Number> sortComparator = (FieldComparator<? extends Number>) untypedCmp;\n+        return new AggregatorFactory(name, queryShardContext, parent, subFactoriesBuilder, metaData) {\n+            @Override\n+            protected TopMetricsAggregator createInternal(SearchContext searchContext, Aggregator parent, boolean collectsFromSingleBucket,\n+                    List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) throws IOException {\n+                return new TopMetricsAggregator(name, searchContext, parent, pipelineAggregators, metaData, sortComparator,\n+                        sortBuilders.get(0).order(), sort.formats[0], sortField.needsScores(), metricField.getFieldName(),\n+                        metricValueSource);\n+            }\n+        };\n+    }\n+\n+    public static final ConstructingObjectParser<TopMetricsAggregationBuilder, String> PARSER = new ConstructingObjectParser<>(NAME,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c"}, "originalPosition": 128}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE3NTU4Nw==", "bodyText": "Is it possible to constrain the sort parser to just object arrays?  Switching the JSON type (objects or strings) makes life hard for clients, albeit less on the request side than the response.  Still would be nice if it were consistent.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369175587", "createdAt": "2020-01-21T18:41:55Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.apache.lucene.search.FieldComparator;\n+import org.apache.lucene.search.Sort;\n+import org.apache.lucene.search.SortField;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ContextParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AbstractAggregationBuilder;\n+import org.elasticsearch.search.aggregations.AggregationBuilder;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.AggregatorFactories;\n+import org.elasticsearch.search.aggregations.AggregatorFactories.Builder;\n+import org.elasticsearch.search.aggregations.AggregatorFactory;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.MultiValuesSourceFieldConfig;\n+import org.elasticsearch.search.aggregations.support.ValueType;\n+import org.elasticsearch.search.aggregations.support.ValuesSource;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.search.sort.SortAndFormats;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+import static org.elasticsearch.search.builder.SearchSourceBuilder.SORT_FIELD;\n+\n+public class TopMetricsAggregationBuilder extends AbstractAggregationBuilder<TopMetricsAggregationBuilder> {\n+    public static final String NAME = \"top_metrics\";\n+    public static final ParseField METRIC_FIELD = new ParseField(\"metric\");\n+\n+    private final List<SortBuilder<?>> sortBuilders;\n+    // TODO MultiValuesSourceFieldConfig has more things than we support and less things than we want to support\n+    private final MultiValuesSourceFieldConfig metricField;\n+\n+    /**\n+     * Ctor for parsing.\n+     */\n+    public TopMetricsAggregationBuilder(String name, List<SortBuilder<?>> sortBuilders, MultiValuesSourceFieldConfig metricField) {\n+        super(name);\n+        if (sortBuilders.size() != 1) {\n+            throw new IllegalArgumentException(\"[sort] must contain exactly one sort\");\n+        }\n+        this.sortBuilders = sortBuilders;\n+        this.metricField = metricField;\n+    }\n+\n+    /**\n+     * Cloning ctor for reducing.\n+     */\n+    public TopMetricsAggregationBuilder(TopMetricsAggregationBuilder clone, AggregatorFactories.Builder factoriesBuilder,\n+            Map<String, Object> metaData) {\n+        super(clone, factoriesBuilder, metaData);\n+        this.sortBuilders = clone.sortBuilders;\n+        this.metricField = clone.metricField;\n+    }\n+\n+    /**\n+     * Read from a stream.\n+     */\n+    public TopMetricsAggregationBuilder(StreamInput in) throws IOException {\n+        super(in);\n+        @SuppressWarnings(\"unchecked\")\n+        List<SortBuilder<?>> sortBuilders = (List<SortBuilder<?>>) (List<?>) in.readNamedWriteableList(SortBuilder.class); \n+        this.sortBuilders = sortBuilders;\n+        this.metricField = new MultiValuesSourceFieldConfig(in);\n+    }\n+\n+    @Override\n+    protected void doWriteTo(StreamOutput out) throws IOException {\n+        out.writeNamedWriteableList(sortBuilders);\n+        metricField.writeTo(out);\n+    }\n+\n+    @Override\n+    protected AggregationBuilder shallowCopy(AggregatorFactories.Builder factoriesBuilder, Map<String, Object> metaData) {\n+        return new TopMetricsAggregationBuilder(this, factoriesBuilder, metaData);\n+    }\n+\n+    @Override\n+    protected AggregatorFactory doBuild(QueryShardContext queryShardContext, AggregatorFactory parent, Builder subFactoriesBuilder)\n+            throws IOException {\n+        ValuesSourceConfig<ValuesSource.Numeric> metricFieldSource = ValuesSourceConfig.resolve(queryShardContext, ValueType.NUMERIC,\n+                metricField.getFieldName(), metricField.getScript(), metricField.getMissing(), metricField.getTimeZone(), null);\n+        ValuesSource.Numeric metricValueSource = metricFieldSource.toValuesSource(queryShardContext);\n+        SortAndFormats sort = SortBuilder.buildSort(sortBuilders, queryShardContext).orElseGet(() ->\n+                // Empty in this case means that the we attempted to sort on score descending\n+                new SortAndFormats(new Sort(SortField.FIELD_SCORE), new DocValueFormat[] {DocValueFormat.RAW}));\n+        if (sort.sort.getSort().length != 1) {\n+            throw new IllegalArgumentException(\"[top_metrics] only supports sorting on a single field\");\n+        }\n+        SortField sortField = sort.sort.getSort()[0];\n+        FieldComparator<?> untypedCmp = sortField.getComparator(1, 0);\n+        /* This check is kind of nasty, but it is the only way we have of making sure we're getting numerics.\n+         * We would like to drop that requirement but we'll likely do that by getting *more* information\n+         * about the type, not less. */\n+        if (false == untypedCmp instanceof FieldComparator.NumericComparator &&\n+                false == untypedCmp instanceof FieldComparator.RelevanceComparator) {\n+            throw new IllegalArgumentException(\"[top_metrics] only supports sorting on numeric values\");\n+        }\n+        @SuppressWarnings(\"unchecked\") // We checked this with instanceof above\n+        FieldComparator<? extends Number> sortComparator = (FieldComparator<? extends Number>) untypedCmp;\n+        return new AggregatorFactory(name, queryShardContext, parent, subFactoriesBuilder, metaData) {\n+            @Override\n+            protected TopMetricsAggregator createInternal(SearchContext searchContext, Aggregator parent, boolean collectsFromSingleBucket,\n+                    List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) throws IOException {\n+                return new TopMetricsAggregator(name, searchContext, parent, pipelineAggregators, metaData, sortComparator,\n+                        sortBuilders.get(0).order(), sort.formats[0], sortField.needsScores(), metricField.getFieldName(),\n+                        metricValueSource);\n+            }\n+        };\n+    }\n+\n+    public static final ConstructingObjectParser<TopMetricsAggregationBuilder, String> PARSER = new ConstructingObjectParser<>(NAME,\n+            false, (args, name) -> {\n+                @SuppressWarnings(\"unchecked\")\n+                List<SortBuilder<?>> sorts = (List<SortBuilder<?>>) args[0];\n+                MultiValuesSourceFieldConfig metricField = (MultiValuesSourceFieldConfig) args[1];\n+                return new TopMetricsAggregationBuilder(name, sorts, metricField);\n+            });\n+    static {\n+        PARSER.declareField(constructorArg(), (p, n) -> SortBuilder.fromXContent(p), SORT_FIELD, \n+                ObjectParser.ValueType.OBJECT_ARRAY_OR_STRING);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c"}, "originalPosition": 137}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE4Mjc2Ng==", "bodyText": "So there's an agg-specific form of AbstractWireSerializingTestCase called InternalAggregationTestCase which you'll probably want to use instead.  It includes some agg-specific tests, generates random instances and mutates them, checks reductions, parsing, etc.\nI think you can probably use that in place of InternalTopMetricsWireTests and InternalTopMetricsXContentTests.  Could probably roll the reduction logic from InternalTopMetricsReduceTests into it as well if you wanted.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369182766", "createdAt": "2020-01-21T18:56:13Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/analytics/src/test/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetricsWireTests.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.elasticsearch.common.io.stream.NamedWriteableRegistry;\n+import org.elasticsearch.common.io.stream.Writeable.Reader;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.test.AbstractWireSerializingTestCase;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static java.util.Collections.emptyList;\n+import static java.util.Collections.unmodifiableList;\n+import static java.util.stream.Collectors.toList;\n+\n+public class InternalTopMetricsWireTests extends AbstractWireSerializingTestCase<InternalTopMetrics> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE4MzkwMg==", "bodyText": "AggregatorTestCase has helper methods called search() and searchAndReduce() which are preferred over calling search on the indexSearcher directly.  The helper methods on the test class do things like incremental reductions, scripting, pipeline aggs etc which are missed if you execute the search directly.\nIt's unfortunately a bit variable over the test codebase, so depending where you look there are a few different styles.  But using one of the forms of searchAndReduce() in particular is preferred.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369183902", "createdAt": "2020-01-21T18:58:33Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/analytics/src/test/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregatorTests.java", "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.index.DirectoryReader;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.IndexableField;\n+import org.apache.lucene.index.RandomIndexWriter;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.MatchAllDocsQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.store.Directory;\n+import org.apache.lucene.util.NumericUtils;\n+import org.elasticsearch.common.CheckedConsumer;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AggregatorTestCase;\n+import org.elasticsearch.search.aggregations.support.MultiValuesSourceFieldConfig;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.search.sort.SortOrder;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+\n+import static java.util.Collections.singletonList;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.notANumber;\n+\n+public class TopMetricsAggregatorTests extends AggregatorTestCase {\n+    public void testNoDocs() throws IOException {\n+        InternalTopMetrics result = collect(simpleBuilder(), new MatchAllDocsQuery(), writer -> {},\n+                numberField(NumberType.DOUBLE, \"s\"), numberField(NumberType.DOUBLE, \"m\"));\n+        assertThat(result.getSortFormat(), equalTo(DocValueFormat.RAW));\n+        assertThat(result.getSortOrder(), equalTo(SortOrder.ASC));\n+        assertThat(result.getSortValue(), notANumber());\n+        assertThat(result.getMetricValue(), notANumber());\n+    }\n+\n+    public void testUnmappedMetric() throws IOException {\n+        InternalTopMetrics result = collect(simpleBuilder(), new MatchAllDocsQuery(), writer -> {\n+                    writer.addDocument(singletonList(doubleField(\"s\", 1.0)));\n+                },\n+                numberField(NumberType.DOUBLE, \"s\"));\n+        assertThat(result.getSortValue(), notANumber());\n+        assertThat(result.getMetricValue(), notANumber());\n+    }\n+\n+    public void testMissingValueForMetric() throws IOException {\n+        InternalTopMetrics result = collect(simpleBuilder(), new MatchAllDocsQuery(), writer -> {\n+                    writer.addDocument(singletonList(doubleField(\"s\", 1.0)));\n+                },\n+                numberField(NumberType.DOUBLE, \"s\"), numberField(NumberType.DOUBLE, \"m\"));\n+        assertThat(result.getSortValue(), equalTo(1.0d));\n+        assertThat(result.getMetricValue(), notANumber());\n+    }\n+\n+    public void testActualValueForMetric() throws IOException {\n+        InternalTopMetrics result = collect(simpleBuilder(), new MatchAllDocsQuery(), writer -> {\n+                    writer.addDocument(Arrays.asList(doubleField(\"s\", 1.0), doubleField(\"m\", 2.0)));\n+                },\n+                numberField(NumberType.DOUBLE, \"s\"), numberField(NumberType.DOUBLE, \"m\"));\n+        assertThat(result.getSortValue(), equalTo(1.0d));\n+        assertThat(result.getMetricValue(), equalTo(2.0d));\n+    }\n+\n+    public void testAscending() throws IOException {\n+        TopMetricsAggregationBuilder builder = simpleBuilder();\n+        builder.getSortBuilders().get(0).order(SortOrder.ASC);\n+        InternalTopMetrics empty = collect(builder, new MatchAllDocsQuery(), writer -> {\n+                    writer.addDocument(Arrays.asList(doubleField(\"s\", 1.0), doubleField(\"m\", 2.0)));\n+                    writer.addDocument(Arrays.asList(doubleField(\"s\", 2.0), doubleField(\"m\", 3.0)));\n+                },\n+                numberField(NumberType.DOUBLE, \"s\"), numberField(NumberType.DOUBLE, \"m\"));\n+        assertThat(empty.getSortValue(), equalTo(1.0d));\n+        assertThat(empty.getMetricValue(), equalTo(2.0d));\n+    }\n+\n+    public void testDescending() throws IOException {\n+        TopMetricsAggregationBuilder builder = simpleBuilder();\n+        builder.getSortBuilders().get(0).order(SortOrder.DESC);\n+        InternalTopMetrics empty = collect(builder, new MatchAllDocsQuery(), writer -> {\n+                    writer.addDocument(Arrays.asList(doubleField(\"s\", 1.0), doubleField(\"m\", 2.0)));\n+                    writer.addDocument(Arrays.asList(doubleField(\"s\", 2.0), doubleField(\"m\", 3.0)));\n+                },\n+                numberField(NumberType.DOUBLE, \"s\"), numberField(NumberType.DOUBLE, \"m\"));\n+        assertThat(empty.getSortValue(), equalTo(2.0d));\n+        assertThat(empty.getMetricValue(), equalTo(3.0d));\n+    }\n+\n+    private TopMetricsAggregationBuilder simpleBuilder() {\n+        return new TopMetricsAggregationBuilder(\"test\", singletonList(new FieldSortBuilder(\"s\")),\n+                new MultiValuesSourceFieldConfig.Builder().setFieldName(\"m\").build());\n+    }\n+\n+    private MappedFieldType numberField(NumberType numberType, String name) {\n+        NumberFieldMapper.NumberFieldType type = new NumberFieldMapper.NumberFieldType(numberType);\n+        type.setName(name);\n+        return type;\n+    }\n+\n+    private IndexableField doubleField(String name, double value) {\n+        return new SortedNumericDocValuesField(name, NumericUtils.doubleToSortableLong(value));\n+    }\n+\n+    private InternalTopMetrics collect(TopMetricsAggregationBuilder builder, Query query,\n+            CheckedConsumer<RandomIndexWriter, IOException> buildIndex, MappedFieldType... fields) throws IOException {\n+        try (Directory directory = newDirectory()) {\n+            try (RandomIndexWriter indexWriter = new RandomIndexWriter(random(), directory)) {\n+                buildIndex.accept(indexWriter);\n+            }\n+\n+            try (IndexReader indexReader = DirectoryReader.open(directory)) {\n+                IndexSearcher indexSearcher = newSearcher(indexReader, true, true);\n+                TopMetricsAggregator aggregator = createAggregator(builder, indexSearcher, fields);\n+                aggregator.preCollection();\n+                indexSearcher.search(query, aggregator);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE5NTQ4Nw==", "bodyText": "So toValuesSource() typically happens in the factory (as well as field type checking/validation).  I think there are some technical reasons for the arrangement, but another reason is so that the factory can return mapped vs unmapped aggregator results.\nE.g. if either metricValueSource or sort are unmapped fields we'll need to handle that somehow, which is typically done with a createUnmapped() method on the factory to generate an unmapped, placeholder agg.\nSee ValuesSourceAggregatorFactory#createInternal() as an example of how the regular VS aggs do this.  VSAggFactory calls createUnmapped on the agg sub-class which then knows how to generate an \"empty\" unmapped aggregator.  This varies a little depending on the agg, some handle it internal to the agg while others have a dedicated unmapped aggregator.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369195487", "createdAt": "2020-01-21T19:22:43Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.apache.lucene.search.FieldComparator;\n+import org.apache.lucene.search.Sort;\n+import org.apache.lucene.search.SortField;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ContextParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AbstractAggregationBuilder;\n+import org.elasticsearch.search.aggregations.AggregationBuilder;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.AggregatorFactories;\n+import org.elasticsearch.search.aggregations.AggregatorFactories.Builder;\n+import org.elasticsearch.search.aggregations.AggregatorFactory;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.MultiValuesSourceFieldConfig;\n+import org.elasticsearch.search.aggregations.support.ValueType;\n+import org.elasticsearch.search.aggregations.support.ValuesSource;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.search.sort.SortAndFormats;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+import static org.elasticsearch.search.builder.SearchSourceBuilder.SORT_FIELD;\n+\n+public class TopMetricsAggregationBuilder extends AbstractAggregationBuilder<TopMetricsAggregationBuilder> {\n+    public static final String NAME = \"top_metrics\";\n+    public static final ParseField METRIC_FIELD = new ParseField(\"metric\");\n+\n+    private final List<SortBuilder<?>> sortBuilders;\n+    // TODO MultiValuesSourceFieldConfig has more things than we support and less things than we want to support\n+    private final MultiValuesSourceFieldConfig metricField;\n+\n+    /**\n+     * Ctor for parsing.\n+     */\n+    public TopMetricsAggregationBuilder(String name, List<SortBuilder<?>> sortBuilders, MultiValuesSourceFieldConfig metricField) {\n+        super(name);\n+        if (sortBuilders.size() != 1) {\n+            throw new IllegalArgumentException(\"[sort] must contain exactly one sort\");\n+        }\n+        this.sortBuilders = sortBuilders;\n+        this.metricField = metricField;\n+    }\n+\n+    /**\n+     * Cloning ctor for reducing.\n+     */\n+    public TopMetricsAggregationBuilder(TopMetricsAggregationBuilder clone, AggregatorFactories.Builder factoriesBuilder,\n+            Map<String, Object> metaData) {\n+        super(clone, factoriesBuilder, metaData);\n+        this.sortBuilders = clone.sortBuilders;\n+        this.metricField = clone.metricField;\n+    }\n+\n+    /**\n+     * Read from a stream.\n+     */\n+    public TopMetricsAggregationBuilder(StreamInput in) throws IOException {\n+        super(in);\n+        @SuppressWarnings(\"unchecked\")\n+        List<SortBuilder<?>> sortBuilders = (List<SortBuilder<?>>) (List<?>) in.readNamedWriteableList(SortBuilder.class); \n+        this.sortBuilders = sortBuilders;\n+        this.metricField = new MultiValuesSourceFieldConfig(in);\n+    }\n+\n+    @Override\n+    protected void doWriteTo(StreamOutput out) throws IOException {\n+        out.writeNamedWriteableList(sortBuilders);\n+        metricField.writeTo(out);\n+    }\n+\n+    @Override\n+    protected AggregationBuilder shallowCopy(AggregatorFactories.Builder factoriesBuilder, Map<String, Object> metaData) {\n+        return new TopMetricsAggregationBuilder(this, factoriesBuilder, metaData);\n+    }\n+\n+    @Override\n+    protected AggregatorFactory doBuild(QueryShardContext queryShardContext, AggregatorFactory parent, Builder subFactoriesBuilder)\n+            throws IOException {\n+        ValuesSourceConfig<ValuesSource.Numeric> metricFieldSource = ValuesSourceConfig.resolve(queryShardContext, ValueType.NUMERIC,\n+                metricField.getFieldName(), metricField.getScript(), metricField.getMissing(), metricField.getTimeZone(), null);\n+        ValuesSource.Numeric metricValueSource = metricFieldSource.toValuesSource(queryShardContext);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIwNjMzNQ==", "bodyText": "I think this might be a bit of a dealbreaker unfortunately?  E.g. the predominant use-case for this agg is fetching the most recent value as defined by a timestamp, so date formatting is relatively important.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369206335", "createdAt": "2020-01-21T19:45:36Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetrics.java", "diffHunk": "@@ -0,0 +1,175 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.SearchSortValues;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.sort.SortOrder;\n+\n+import java.io.IOException;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+public class InternalTopMetrics extends InternalAggregation {\n+    private final DocValueFormat sortFormat;\n+    private final SortOrder sortOrder;\n+    private final double sortValue;\n+    private final String metricName;\n+    private final double metricValue;\n+\n+    InternalTopMetrics(String name, DocValueFormat sortFormat, SortOrder sortOrder, double sortValue, String metricName,\n+            double metricValue, List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) {\n+        super(name, pipelineAggregators, metaData);\n+        this.sortFormat = sortFormat;\n+        this.sortOrder = sortOrder;\n+        this.sortValue = sortValue;\n+        this.metricName = metricName;\n+        this.metricValue = metricValue;\n+    }\n+\n+    static InternalTopMetrics buildEmptyAggregation(String name, DocValueFormat sortFormat, SortOrder sortOrder, String metricField,\n+            List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) {\n+        return new InternalTopMetrics(name, sortFormat, sortOrder, Double.NaN, metricField, Double.NaN, pipelineAggregators, metaData);\n+    }\n+\n+    /**\n+     * Read from a stream.\n+     */\n+    public InternalTopMetrics(StreamInput in) throws IOException {\n+        super(in);\n+        sortFormat = in.readNamedWriteable(DocValueFormat.class);\n+        sortOrder = SortOrder.readFromStream(in);\n+        sortValue = in.readDouble();\n+        metricName = in.readString();\n+        metricValue = in.readDouble();\n+    }\n+\n+    @Override\n+    protected void doWriteTo(StreamOutput out) throws IOException {\n+        out.writeNamedWriteable(sortFormat);\n+        sortOrder.writeTo(out);\n+        out.writeDouble(sortValue);\n+        out.writeString(metricName);\n+        out.writeDouble(metricValue);\n+    }\n+\n+    @Override\n+    public String getWriteableName() {\n+        return TopMetricsAggregationBuilder.NAME;\n+    }\n+\n+    @Override\n+    public Object getProperty(List<String> path) {\n+        if (path.isEmpty()) {\n+            return this;\n+        }\n+        if (path.size() == 1 && metricName.contentEquals(path.get(1))) {\n+            return metricValue;\n+        }\n+        throw new IllegalArgumentException(\"path not supported for [\" + getName() + \"]: \" + path);\n+    }\n+\n+    @Override\n+    public InternalTopMetrics reduce(List<InternalAggregation> aggregations, ReduceContext reduceContext) {\n+        Iterator<InternalAggregation> itr = aggregations.iterator();\n+        InternalTopMetrics first;\n+        while (true) {\n+            if (false == itr.hasNext()) {\n+                // Reducing a bunch of empty aggregations\n+                return buildReduced(DocValueFormat.RAW, Double.NaN, Double.NaN);\n+            }\n+            first = (InternalTopMetrics) itr.next();\n+            // Results with NaN sorts are empty\n+            if (false == Double.isNaN(first.sortValue)) {\n+                break;\n+            }\n+        }\n+        DocValueFormat bestSortFormat = first.sortFormat;\n+        double bestSortValue = first.sortValue;\n+        double bestMetricValue = first.metricValue;\n+        int reverseMul = sortOrder == SortOrder.DESC ? -1 : 1;\n+        while (itr.hasNext()) {\n+            InternalTopMetrics result = (InternalTopMetrics) itr.next();\n+            // Results with NaN sorts are empty\n+            if (Double.isNaN(result.sortValue)) {\n+                continue;\n+            }\n+            if (reverseMul * Double.compare(bestSortValue, result.sortValue) > 0) {\n+                bestSortFormat = result.sortFormat;\n+                bestSortValue = result.sortValue;\n+                bestMetricValue = result.metricValue;\n+            }\n+        }\n+        return buildReduced(bestSortFormat, bestSortValue, bestMetricValue);\n+    }\n+\n+    private InternalTopMetrics buildReduced(DocValueFormat bestSortFormat, double bestSortValue, double bestMetricValue) {\n+        return new InternalTopMetrics(getName(), bestSortFormat, sortOrder, bestSortValue, metricName, bestMetricValue,\n+                pipelineAggregators(), getMetaData());\n+    }\n+\n+    @Override\n+    public XContentBuilder doXContentBody(XContentBuilder builder, Params params) throws IOException {\n+        builder.startArray(\"top\");\n+        builder.startObject();\n+        {\n+            // Sadly, this won't output dates correctly because they always come back as doubles. We \n+            SearchSortValues sortValues = new SearchSortValues(new Object[] {sortValue}, new DocValueFormat[] {sortFormat});", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIwNjQ4MQ==", "bodyText": "Hmm, I'm not sure about this.  I know why it was done this way (so sort and value can go in one array), but since the predominant use-case is dates, floating point error/rounding is not ideal.  Would be very confusing for customers to see a returned date that doesn't match the date in their document, or potentially mismatch with a date_histo bucket that it resides in.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369206481", "createdAt": "2020-01-21T19:45:52Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregator.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.FieldComparator;\n+import org.apache.lucene.search.LeafFieldComparator;\n+import org.apache.lucene.search.Scorable;\n+import org.apache.lucene.search.ScoreMode;\n+import org.elasticsearch.common.lease.Releasables;\n+import org.elasticsearch.common.util.DoubleArray;\n+import org.elasticsearch.index.fielddata.NumericDoubleValues;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.MultiValueMode;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.elasticsearch.search.aggregations.LeafBucketCollectorBase;\n+import org.elasticsearch.search.aggregations.metrics.MetricsAggregator;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.ValuesSource;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.search.sort.SortOrder;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+class TopMetricsAggregator extends MetricsAggregator {\n+    /**\n+     * Field comparator for doing the sort. This comes from Lucene and it isn't quite what we need\n+     * but it is pretty close. We'll likely revisit this but for now it is very good at letting us\n+     * use the normal sorting infrastructure.\n+     */\n+    private final FieldComparator<? extends Number> sortComparator;\n+    private final SortOrder sortOrder;\n+    private final DocValueFormat sortFormat;\n+    private final boolean sortNeedsScores;\n+    private final String metricName;\n+    private final ValuesSource.Numeric metricValueSource;\n+    private DoubleArray values;\n+\n+    TopMetricsAggregator(String name, SearchContext context, Aggregator parent, List<PipelineAggregator> pipelineAggregators,\n+            Map<String, Object> metaData,\n+            FieldComparator<? extends Number> sortComparator, SortOrder sortOrder, DocValueFormat sortFormat, boolean sortNeedsScores,\n+            String metricName, ValuesSource.Numeric metricValueSource) throws IOException {\n+        super(name, context, parent, pipelineAggregators, metaData);\n+        this.sortComparator = sortComparator;\n+        this.sortOrder = sortOrder;\n+        this.sortFormat = sortFormat;\n+        this.sortNeedsScores = sortNeedsScores;\n+        this.metricName = metricName;\n+        this.metricValueSource = metricValueSource;\n+        if (metricValueSource != null) {\n+            values = context.bigArrays().newDoubleArray(2, false);\n+            values.fill(0, values.size(), Double.NaN);\n+        }\n+    }\n+\n+    @Override\n+    public ScoreMode scoreMode() {\n+        boolean needs = sortNeedsScores || (metricValueSource != null && metricValueSource.needsScores());\n+        return needs ? ScoreMode.COMPLETE : ScoreMode.COMPLETE_NO_SCORES;\n+    }\n+\n+    @Override\n+    public LeafBucketCollector getLeafCollector(LeafReaderContext ctx, LeafBucketCollector sub) throws IOException {\n+        if (metricValueSource == null) {\n+            return LeafBucketCollector.NO_OP_COLLECTOR;\n+        }\n+        // TODO allow configuration of value mode\n+        NumericDoubleValues metricValues = MultiValueMode.AVG.select(metricValueSource.doubleValues(ctx));\n+\n+        LeafFieldComparator leafCmp = sortComparator.getLeafComparator(ctx);\n+        int reverseMul = sortOrder == SortOrder.DESC ? -1 : 1;\n+        return new LeafBucketCollectorBase(sub, metricValues) {\n+            @Override\n+            public void collect(int doc, long bucket) throws IOException {\n+                long offset = bucket * 2;\n+                if (offset + 2 > values.size()) {\n+                    long oldSize = values.size();\n+                    values = context.bigArrays().grow(values, offset + 2);\n+                    values.fill(oldSize, values.size(), Double.NaN);\n+                }\n+\n+                double bestSort = values.get(offset);\n+                // This generates a Double instance and throws it away. Sad, but it is the price we pay for using Lucene APIs.\n+                leafCmp.copy(0, doc);\n+                double sort = sortComparator.value(0).doubleValue();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c"}, "originalPosition": 93}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ2MTYyMDEw", "url": "https://github.com/elastic/elasticsearch/pull/51155#pullrequestreview-346162010", "createdAt": "2020-01-21T20:15:30Z", "commit": {"oid": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQyMDoxNTozMFrOFgHb0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQyMDoxNzowOFrOFgHesg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIyMDU2MA==", "bodyText": "MultiValuesSourceAggregationBuilder dictates a bunch of stuff about the xcontent layout that don't make sense for this agg. To be honest I'm a little suspect of anything that does inherit from it.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369220560", "createdAt": "2020-01-21T20:15:30Z", "author": {"login": "nik9000"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.apache.lucene.search.FieldComparator;\n+import org.apache.lucene.search.Sort;\n+import org.apache.lucene.search.SortField;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ContextParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AbstractAggregationBuilder;\n+import org.elasticsearch.search.aggregations.AggregationBuilder;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.AggregatorFactories;\n+import org.elasticsearch.search.aggregations.AggregatorFactories.Builder;\n+import org.elasticsearch.search.aggregations.AggregatorFactory;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.MultiValuesSourceFieldConfig;\n+import org.elasticsearch.search.aggregations.support.ValueType;\n+import org.elasticsearch.search.aggregations.support.ValuesSource;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.search.sort.SortAndFormats;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+import static org.elasticsearch.search.builder.SearchSourceBuilder.SORT_FIELD;\n+\n+public class TopMetricsAggregationBuilder extends AbstractAggregationBuilder<TopMetricsAggregationBuilder> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE1NTA5MQ=="}, "originalCommit": {"oid": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIyMDk2NA==", "bodyText": "I can certainly do that. I kind of figured we wanted fewer of these classes and this one seemed like a simple enough place to save. I'm happy to switch back.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369220964", "createdAt": "2020-01-21T20:16:21Z", "author": {"login": "nik9000"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.apache.lucene.search.FieldComparator;\n+import org.apache.lucene.search.Sort;\n+import org.apache.lucene.search.SortField;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ContextParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AbstractAggregationBuilder;\n+import org.elasticsearch.search.aggregations.AggregationBuilder;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.AggregatorFactories;\n+import org.elasticsearch.search.aggregations.AggregatorFactories.Builder;\n+import org.elasticsearch.search.aggregations.AggregatorFactory;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.MultiValuesSourceFieldConfig;\n+import org.elasticsearch.search.aggregations.support.ValueType;\n+import org.elasticsearch.search.aggregations.support.ValuesSource;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.search.sort.SortAndFormats;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+import static org.elasticsearch.search.builder.SearchSourceBuilder.SORT_FIELD;\n+\n+public class TopMetricsAggregationBuilder extends AbstractAggregationBuilder<TopMetricsAggregationBuilder> {\n+    public static final String NAME = \"top_metrics\";\n+    public static final ParseField METRIC_FIELD = new ParseField(\"metric\");\n+\n+    private final List<SortBuilder<?>> sortBuilders;\n+    // TODO MultiValuesSourceFieldConfig has more things than we support and less things than we want to support\n+    private final MultiValuesSourceFieldConfig metricField;\n+\n+    /**\n+     * Ctor for parsing.\n+     */\n+    public TopMetricsAggregationBuilder(String name, List<SortBuilder<?>> sortBuilders, MultiValuesSourceFieldConfig metricField) {\n+        super(name);\n+        if (sortBuilders.size() != 1) {\n+            throw new IllegalArgumentException(\"[sort] must contain exactly one sort\");\n+        }\n+        this.sortBuilders = sortBuilders;\n+        this.metricField = metricField;\n+    }\n+\n+    /**\n+     * Cloning ctor for reducing.\n+     */\n+    public TopMetricsAggregationBuilder(TopMetricsAggregationBuilder clone, AggregatorFactories.Builder factoriesBuilder,\n+            Map<String, Object> metaData) {\n+        super(clone, factoriesBuilder, metaData);\n+        this.sortBuilders = clone.sortBuilders;\n+        this.metricField = clone.metricField;\n+    }\n+\n+    /**\n+     * Read from a stream.\n+     */\n+    public TopMetricsAggregationBuilder(StreamInput in) throws IOException {\n+        super(in);\n+        @SuppressWarnings(\"unchecked\")\n+        List<SortBuilder<?>> sortBuilders = (List<SortBuilder<?>>) (List<?>) in.readNamedWriteableList(SortBuilder.class); \n+        this.sortBuilders = sortBuilders;\n+        this.metricField = new MultiValuesSourceFieldConfig(in);\n+    }\n+\n+    @Override\n+    protected void doWriteTo(StreamOutput out) throws IOException {\n+        out.writeNamedWriteableList(sortBuilders);\n+        metricField.writeTo(out);\n+    }\n+\n+    @Override\n+    protected AggregationBuilder shallowCopy(AggregatorFactories.Builder factoriesBuilder, Map<String, Object> metaData) {\n+        return new TopMetricsAggregationBuilder(this, factoriesBuilder, metaData);\n+    }\n+\n+    @Override\n+    protected AggregatorFactory doBuild(QueryShardContext queryShardContext, AggregatorFactory parent, Builder subFactoriesBuilder)\n+            throws IOException {\n+        ValuesSourceConfig<ValuesSource.Numeric> metricFieldSource = ValuesSourceConfig.resolve(queryShardContext, ValueType.NUMERIC,\n+                metricField.getFieldName(), metricField.getScript(), metricField.getMissing(), metricField.getTimeZone(), null);\n+        ValuesSource.Numeric metricValueSource = metricFieldSource.toValuesSource(queryShardContext);\n+        SortAndFormats sort = SortBuilder.buildSort(sortBuilders, queryShardContext).orElseGet(() ->\n+                // Empty in this case means that the we attempted to sort on score descending\n+                new SortAndFormats(new Sort(SortField.FIELD_SCORE), new DocValueFormat[] {DocValueFormat.RAW}));\n+        if (sort.sort.getSort().length != 1) {\n+            throw new IllegalArgumentException(\"[top_metrics] only supports sorting on a single field\");\n+        }\n+        SortField sortField = sort.sort.getSort()[0];\n+        FieldComparator<?> untypedCmp = sortField.getComparator(1, 0);\n+        /* This check is kind of nasty, but it is the only way we have of making sure we're getting numerics.\n+         * We would like to drop that requirement but we'll likely do that by getting *more* information\n+         * about the type, not less. */\n+        if (false == untypedCmp instanceof FieldComparator.NumericComparator &&\n+                false == untypedCmp instanceof FieldComparator.RelevanceComparator) {\n+            throw new IllegalArgumentException(\"[top_metrics] only supports sorting on numeric values\");\n+        }\n+        @SuppressWarnings(\"unchecked\") // We checked this with instanceof above\n+        FieldComparator<? extends Number> sortComparator = (FieldComparator<? extends Number>) untypedCmp;\n+        return new AggregatorFactory(name, queryShardContext, parent, subFactoriesBuilder, metaData) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE3NDk5Nw=="}, "originalCommit": {"oid": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIyMTI5OA==", "bodyText": "Our traditional sort takes all of these so I declared it this way to be consistent with everything else. I can keep it just object array.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369221298", "createdAt": "2020-01-21T20:17:08Z", "author": {"login": "nik9000"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.apache.lucene.search.FieldComparator;\n+import org.apache.lucene.search.Sort;\n+import org.apache.lucene.search.SortField;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ContextParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AbstractAggregationBuilder;\n+import org.elasticsearch.search.aggregations.AggregationBuilder;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.AggregatorFactories;\n+import org.elasticsearch.search.aggregations.AggregatorFactories.Builder;\n+import org.elasticsearch.search.aggregations.AggregatorFactory;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.MultiValuesSourceFieldConfig;\n+import org.elasticsearch.search.aggregations.support.ValueType;\n+import org.elasticsearch.search.aggregations.support.ValuesSource;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.search.sort.SortAndFormats;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+import static org.elasticsearch.search.builder.SearchSourceBuilder.SORT_FIELD;\n+\n+public class TopMetricsAggregationBuilder extends AbstractAggregationBuilder<TopMetricsAggregationBuilder> {\n+    public static final String NAME = \"top_metrics\";\n+    public static final ParseField METRIC_FIELD = new ParseField(\"metric\");\n+\n+    private final List<SortBuilder<?>> sortBuilders;\n+    // TODO MultiValuesSourceFieldConfig has more things than we support and less things than we want to support\n+    private final MultiValuesSourceFieldConfig metricField;\n+\n+    /**\n+     * Ctor for parsing.\n+     */\n+    public TopMetricsAggregationBuilder(String name, List<SortBuilder<?>> sortBuilders, MultiValuesSourceFieldConfig metricField) {\n+        super(name);\n+        if (sortBuilders.size() != 1) {\n+            throw new IllegalArgumentException(\"[sort] must contain exactly one sort\");\n+        }\n+        this.sortBuilders = sortBuilders;\n+        this.metricField = metricField;\n+    }\n+\n+    /**\n+     * Cloning ctor for reducing.\n+     */\n+    public TopMetricsAggregationBuilder(TopMetricsAggregationBuilder clone, AggregatorFactories.Builder factoriesBuilder,\n+            Map<String, Object> metaData) {\n+        super(clone, factoriesBuilder, metaData);\n+        this.sortBuilders = clone.sortBuilders;\n+        this.metricField = clone.metricField;\n+    }\n+\n+    /**\n+     * Read from a stream.\n+     */\n+    public TopMetricsAggregationBuilder(StreamInput in) throws IOException {\n+        super(in);\n+        @SuppressWarnings(\"unchecked\")\n+        List<SortBuilder<?>> sortBuilders = (List<SortBuilder<?>>) (List<?>) in.readNamedWriteableList(SortBuilder.class); \n+        this.sortBuilders = sortBuilders;\n+        this.metricField = new MultiValuesSourceFieldConfig(in);\n+    }\n+\n+    @Override\n+    protected void doWriteTo(StreamOutput out) throws IOException {\n+        out.writeNamedWriteableList(sortBuilders);\n+        metricField.writeTo(out);\n+    }\n+\n+    @Override\n+    protected AggregationBuilder shallowCopy(AggregatorFactories.Builder factoriesBuilder, Map<String, Object> metaData) {\n+        return new TopMetricsAggregationBuilder(this, factoriesBuilder, metaData);\n+    }\n+\n+    @Override\n+    protected AggregatorFactory doBuild(QueryShardContext queryShardContext, AggregatorFactory parent, Builder subFactoriesBuilder)\n+            throws IOException {\n+        ValuesSourceConfig<ValuesSource.Numeric> metricFieldSource = ValuesSourceConfig.resolve(queryShardContext, ValueType.NUMERIC,\n+                metricField.getFieldName(), metricField.getScript(), metricField.getMissing(), metricField.getTimeZone(), null);\n+        ValuesSource.Numeric metricValueSource = metricFieldSource.toValuesSource(queryShardContext);\n+        SortAndFormats sort = SortBuilder.buildSort(sortBuilders, queryShardContext).orElseGet(() ->\n+                // Empty in this case means that the we attempted to sort on score descending\n+                new SortAndFormats(new Sort(SortField.FIELD_SCORE), new DocValueFormat[] {DocValueFormat.RAW}));\n+        if (sort.sort.getSort().length != 1) {\n+            throw new IllegalArgumentException(\"[top_metrics] only supports sorting on a single field\");\n+        }\n+        SortField sortField = sort.sort.getSort()[0];\n+        FieldComparator<?> untypedCmp = sortField.getComparator(1, 0);\n+        /* This check is kind of nasty, but it is the only way we have of making sure we're getting numerics.\n+         * We would like to drop that requirement but we'll likely do that by getting *more* information\n+         * about the type, not less. */\n+        if (false == untypedCmp instanceof FieldComparator.NumericComparator &&\n+                false == untypedCmp instanceof FieldComparator.RelevanceComparator) {\n+            throw new IllegalArgumentException(\"[top_metrics] only supports sorting on numeric values\");\n+        }\n+        @SuppressWarnings(\"unchecked\") // We checked this with instanceof above\n+        FieldComparator<? extends Number> sortComparator = (FieldComparator<? extends Number>) untypedCmp;\n+        return new AggregatorFactory(name, queryShardContext, parent, subFactoriesBuilder, metaData) {\n+            @Override\n+            protected TopMetricsAggregator createInternal(SearchContext searchContext, Aggregator parent, boolean collectsFromSingleBucket,\n+                    List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) throws IOException {\n+                return new TopMetricsAggregator(name, searchContext, parent, pipelineAggregators, metaData, sortComparator,\n+                        sortBuilders.get(0).order(), sort.formats[0], sortField.needsScores(), metricField.getFieldName(),\n+                        metricValueSource);\n+            }\n+        };\n+    }\n+\n+    public static final ConstructingObjectParser<TopMetricsAggregationBuilder, String> PARSER = new ConstructingObjectParser<>(NAME,\n+            false, (args, name) -> {\n+                @SuppressWarnings(\"unchecked\")\n+                List<SortBuilder<?>> sorts = (List<SortBuilder<?>>) args[0];\n+                MultiValuesSourceFieldConfig metricField = (MultiValuesSourceFieldConfig) args[1];\n+                return new TopMetricsAggregationBuilder(name, sorts, metricField);\n+            });\n+    static {\n+        PARSER.declareField(constructorArg(), (p, n) -> SortBuilder.fromXContent(p), SORT_FIELD, \n+                ObjectParser.ValueType.OBJECT_ARRAY_OR_STRING);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE3NTU4Nw=="}, "originalCommit": {"oid": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c"}, "originalPosition": 137}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "caf10048bf13f3b8f2fa205ee9a63bafbf217800", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/caf10048bf13f3b8f2fa205ee9a63bafbf217800", "committedDate": "2020-01-21T20:22:44Z", "message": "Merge branch 'master' into top_metrics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9f12a5e1354823ccc2a9bc365d871cbb1f65bb78", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/9f12a5e1354823ccc2a9bc365d871cbb1f65bb78", "committedDate": "2020-01-21T20:33:20Z", "message": "Factory time"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "845a8e79a9e29cc76ab5e6599a6375a2e8a13bd4", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/845a8e79a9e29cc76ab5e6599a6375a2e8a13bd4", "committedDate": "2020-01-21T20:38:35Z", "message": "Move"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "390c4c5dd0c7fe12d18270c7756eb5c9ab2f6bab", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/390c4c5dd0c7fe12d18270c7756eb5c9ab2f6bab", "committedDate": "2020-01-21T20:46:49Z", "message": "Use fancy test methods"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "21a2387a2ab23de462bf40b10bed7ebf540388ea", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/21a2387a2ab23de462bf40b10bed7ebf540388ea", "committedDate": "2020-01-23T15:26:39Z", "message": "Bucketed sort"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "feeca63c29f704fd30e00a52a5ddabc85ca62a75", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/feeca63c29f704fd30e00a52a5ddabc85ca62a75", "committedDate": "2020-01-23T15:35:11Z", "message": "Squish nocommits"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "228ccc9e7fa9cf2f6929bb61beca552e7ca79f7c", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/228ccc9e7fa9cf2f6929bb61beca552e7ca79f7c", "committedDate": "2020-01-23T16:05:45Z", "message": "Merge branch 'master' into top_metrics"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "93a93001f0cf7a55c6c055f913abfbbb783f57f5", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/93a93001f0cf7a55c6c055f913abfbbb783f57f5", "committedDate": "2020-01-23T15:34:58Z", "message": "Squish nocommits"}, "afterCommit": {"oid": "228ccc9e7fa9cf2f6929bb61beca552e7ca79f7c", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/228ccc9e7fa9cf2f6929bb61beca552e7ca79f7c", "committedDate": "2020-01-23T16:05:45Z", "message": "Merge branch 'master' into top_metrics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5f71b84c6d3ddcd87ea1b8f4cf64140788b2c19b", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/5f71b84c6d3ddcd87ea1b8f4cf64140788b2c19b", "committedDate": "2020-01-27T15:19:12Z", "message": "Merge branch 'master' into top_metrics"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ4NzIyODIw", "url": "https://github.com/elastic/elasticsearch/pull/51155#pullrequestreview-348722820", "createdAt": "2020-01-27T14:55:21Z", "commit": {"oid": "228ccc9e7fa9cf2f6929bb61beca552e7ca79f7c"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yN1QxNDo1NToyMVrOFiFhig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yN1QxNjoyMDoyNVrOFiIwDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTI4NjQxMA==", "bodyText": "I believe bigArrays.grow() does this size check so we could skip here.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r371286410", "createdAt": "2020-01-27T14:55:21Z", "author": {"login": "polyfractal"}, "path": "server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java", "diffHunk": "@@ -0,0 +1,281 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.search.sort;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.Scorable;\n+import org.elasticsearch.common.lease.Releasable;\n+import org.elasticsearch.common.lucene.ScorerAware;\n+import org.elasticsearch.common.util.BigArray;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.util.DoubleArray;\n+import org.elasticsearch.common.util.FloatArray;\n+import org.elasticsearch.common.util.LongArray;\n+import org.elasticsearch.search.DocValueFormat;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Type specialized sort implementations designed for use in aggregations.\n+ */\n+public abstract class BucketedSort implements Releasable {\n+    // TODO priority queue semantics to support mulitiple hits in the buckets\n+    protected final BigArrays bigArrays;\n+    private final SortOrder order;\n+    private final DocValueFormat format;\n+    private long maxBucket = -1;\n+\n+    public BucketedSort(BigArrays bigArrays, SortOrder order, DocValueFormat format) {\n+        this.bigArrays = bigArrays;\n+        this.order = order;\n+        this.format = format;\n+    }\n+\n+    /**\n+     * The order of the sort.\n+     */\n+    public final SortOrder getOrder() {\n+        return order;\n+    }\n+\n+    /**\n+     * The format to use when presenting the results.\n+     */\n+    public final DocValueFormat getFormat() {\n+        return format;\n+    }\n+\n+    /**\n+     * Get the value for a bucket.\n+     */\n+    public final Object getValue(long bucket) {\n+        if (bucket > maxBucket) {\n+            return null;\n+        }\n+        return getValueForBucket(bucket);\n+    }\n+\n+    /**\n+     * Get the {@linkplain Leaf} implementation that'll do that actual collecting.\n+     */\n+    public abstract Leaf forLeaf(LeafReaderContext ctx) throws IOException;\n+\n+    /**\n+     * Does this sort need scores? Most don't, but sorting on {@code _score} does.\n+     */\n+    public abstract boolean needsScores();\n+\n+    /**\n+     * The {@linkplain BigArray} backing this sort.\n+     */\n+    protected abstract BigArray buckets();\n+\n+    /**\n+     * Grow the {@linkplain BigArray} backing this sort to account for new buckets.\n+     */\n+    protected abstract void grow(long minSize);\n+\n+    /**\n+     * Get the value for a bucket. This will only be called if the bucket was hit.\n+     */\n+    protected abstract Object getValueForBucket(long bucket);\n+\n+    @Override\n+    public void close() {\n+        buckets().close();\n+    }\n+\n+    /**\n+     * Performs the actual collection against a {@linkplain LeafReaderContext}.\n+     */\n+    public abstract class Leaf implements ScorerAware {\n+        /**\n+         * Collect this doc, returning {@code true} if it is competitive.\n+         */\n+        public final boolean hit(int doc, long bucket) throws IOException {\n+            if (false == advanceExact(doc)) {\n+                return false;\n+            }\n+            if (bucket > maxBucket) {\n+                assert maxBucket + 1 == bucket :\"expected bucket to be [\" + (maxBucket + 1) + \"] but was [\" + bucket + \"]\";\n+                maxBucket = bucket;\n+                if (bucket >= buckets().size()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "228ccc9e7fa9cf2f6929bb61beca552e7ca79f7c"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTI5MDUwNA==", "bodyText": "I don't believe this assertion holds true in all scenarios, e.g. it's not required that buckets are incremented in a dense fashion.  For example an auto-date-histo can merge buckets together during collection, which will introduce gaps in the ordinals that sub-aggs see.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r371290504", "createdAt": "2020-01-27T15:01:57Z", "author": {"login": "polyfractal"}, "path": "server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java", "diffHunk": "@@ -0,0 +1,281 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.search.sort;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.Scorable;\n+import org.elasticsearch.common.lease.Releasable;\n+import org.elasticsearch.common.lucene.ScorerAware;\n+import org.elasticsearch.common.util.BigArray;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.util.DoubleArray;\n+import org.elasticsearch.common.util.FloatArray;\n+import org.elasticsearch.common.util.LongArray;\n+import org.elasticsearch.search.DocValueFormat;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Type specialized sort implementations designed for use in aggregations.\n+ */\n+public abstract class BucketedSort implements Releasable {\n+    // TODO priority queue semantics to support mulitiple hits in the buckets\n+    protected final BigArrays bigArrays;\n+    private final SortOrder order;\n+    private final DocValueFormat format;\n+    private long maxBucket = -1;\n+\n+    public BucketedSort(BigArrays bigArrays, SortOrder order, DocValueFormat format) {\n+        this.bigArrays = bigArrays;\n+        this.order = order;\n+        this.format = format;\n+    }\n+\n+    /**\n+     * The order of the sort.\n+     */\n+    public final SortOrder getOrder() {\n+        return order;\n+    }\n+\n+    /**\n+     * The format to use when presenting the results.\n+     */\n+    public final DocValueFormat getFormat() {\n+        return format;\n+    }\n+\n+    /**\n+     * Get the value for a bucket.\n+     */\n+    public final Object getValue(long bucket) {\n+        if (bucket > maxBucket) {\n+            return null;\n+        }\n+        return getValueForBucket(bucket);\n+    }\n+\n+    /**\n+     * Get the {@linkplain Leaf} implementation that'll do that actual collecting.\n+     */\n+    public abstract Leaf forLeaf(LeafReaderContext ctx) throws IOException;\n+\n+    /**\n+     * Does this sort need scores? Most don't, but sorting on {@code _score} does.\n+     */\n+    public abstract boolean needsScores();\n+\n+    /**\n+     * The {@linkplain BigArray} backing this sort.\n+     */\n+    protected abstract BigArray buckets();\n+\n+    /**\n+     * Grow the {@linkplain BigArray} backing this sort to account for new buckets.\n+     */\n+    protected abstract void grow(long minSize);\n+\n+    /**\n+     * Get the value for a bucket. This will only be called if the bucket was hit.\n+     */\n+    protected abstract Object getValueForBucket(long bucket);\n+\n+    @Override\n+    public void close() {\n+        buckets().close();\n+    }\n+\n+    /**\n+     * Performs the actual collection against a {@linkplain LeafReaderContext}.\n+     */\n+    public abstract class Leaf implements ScorerAware {\n+        /**\n+         * Collect this doc, returning {@code true} if it is competitive.\n+         */\n+        public final boolean hit(int doc, long bucket) throws IOException {\n+            if (false == advanceExact(doc)) {\n+                return false;\n+            }\n+            if (bucket > maxBucket) {\n+                assert maxBucket + 1 == bucket :\"expected bucket to be [\" + (maxBucket + 1) + \"] but was [\" + bucket + \"]\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "228ccc9e7fa9cf2f6929bb61beca552e7ca79f7c"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTMwODM1OA==", "bodyText": "Out of curiosity, why do we need a ctor that accepts Object sortValue?  E.g. we'll always know it's at least a SortValue object right?", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r371308358", "createdAt": "2020-01-27T15:30:51Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetrics.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.elasticsearch.common.io.stream.NamedWriteable;\n+import org.elasticsearch.common.io.stream.NamedWriteableRegistry;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.sort.SortOrder;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+public class InternalTopMetrics extends InternalAggregation {\n+    public static List<NamedWriteableRegistry.Entry> writeables() {\n+        return Arrays.asList(\n+                new NamedWriteableRegistry.Entry(SortValue.class, DoubleSortValue.NAME, DoubleSortValue::new),\n+                new NamedWriteableRegistry.Entry(SortValue.class, LongSortValue.NAME, LongSortValue::new));\n+    }\n+\n+    private final DocValueFormat sortFormat;\n+    private final SortOrder sortOrder;\n+    private final SortValue sortValue;\n+    private final String metricName;\n+    private final double metricValue;\n+\n+    private InternalTopMetrics(String name, DocValueFormat sortFormat, SortOrder sortOrder, SortValue sortValue, String metricName,\n+            double metricValue, List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) {\n+        super(name, pipelineAggregators, metaData);\n+        this.sortFormat = sortFormat;\n+        this.sortOrder = sortOrder;\n+        this.sortValue = sortValue;\n+        this.metricName = metricName;\n+        this.metricValue = metricValue;\n+    }\n+\n+    InternalTopMetrics(String name, DocValueFormat sortFormat, SortOrder sortOrder, Object sortValue, String metricName,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5f71b84c6d3ddcd87ea1b8f4cf64140788b2c19b"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTMyNzQ1MA==", "bodyText": "Is the \"hit\" naming following a search/lucene convention?  If not, I wonder if we should call it collect() to mirror the agg conventions?  It's obviously not quite the same since it returns a bool, but it does \"collect\" at the same time too.  Dunno, no strong opinion.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r371327450", "createdAt": "2020-01-27T16:00:59Z", "author": {"login": "polyfractal"}, "path": "server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java", "diffHunk": "@@ -0,0 +1,281 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.search.sort;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.Scorable;\n+import org.elasticsearch.common.lease.Releasable;\n+import org.elasticsearch.common.lucene.ScorerAware;\n+import org.elasticsearch.common.util.BigArray;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.util.DoubleArray;\n+import org.elasticsearch.common.util.FloatArray;\n+import org.elasticsearch.common.util.LongArray;\n+import org.elasticsearch.search.DocValueFormat;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Type specialized sort implementations designed for use in aggregations.\n+ */\n+public abstract class BucketedSort implements Releasable {\n+    // TODO priority queue semantics to support mulitiple hits in the buckets\n+    protected final BigArrays bigArrays;\n+    private final SortOrder order;\n+    private final DocValueFormat format;\n+    private long maxBucket = -1;\n+\n+    public BucketedSort(BigArrays bigArrays, SortOrder order, DocValueFormat format) {\n+        this.bigArrays = bigArrays;\n+        this.order = order;\n+        this.format = format;\n+    }\n+\n+    /**\n+     * The order of the sort.\n+     */\n+    public final SortOrder getOrder() {\n+        return order;\n+    }\n+\n+    /**\n+     * The format to use when presenting the results.\n+     */\n+    public final DocValueFormat getFormat() {\n+        return format;\n+    }\n+\n+    /**\n+     * Get the value for a bucket.\n+     */\n+    public final Object getValue(long bucket) {\n+        if (bucket > maxBucket) {\n+            return null;\n+        }\n+        return getValueForBucket(bucket);\n+    }\n+\n+    /**\n+     * Get the {@linkplain Leaf} implementation that'll do that actual collecting.\n+     */\n+    public abstract Leaf forLeaf(LeafReaderContext ctx) throws IOException;\n+\n+    /**\n+     * Does this sort need scores? Most don't, but sorting on {@code _score} does.\n+     */\n+    public abstract boolean needsScores();\n+\n+    /**\n+     * The {@linkplain BigArray} backing this sort.\n+     */\n+    protected abstract BigArray buckets();\n+\n+    /**\n+     * Grow the {@linkplain BigArray} backing this sort to account for new buckets.\n+     */\n+    protected abstract void grow(long minSize);\n+\n+    /**\n+     * Get the value for a bucket. This will only be called if the bucket was hit.\n+     */\n+    protected abstract Object getValueForBucket(long bucket);\n+\n+    @Override\n+    public void close() {\n+        buckets().close();\n+    }\n+\n+    /**\n+     * Performs the actual collection against a {@linkplain LeafReaderContext}.\n+     */\n+    public abstract class Leaf implements ScorerAware {\n+        /**\n+         * Collect this doc, returning {@code true} if it is competitive.\n+         */\n+        public final boolean hit(int doc, long bucket) throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5f71b84c6d3ddcd87ea1b8f4cf64140788b2c19b"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTMzMDMyOA==", "bodyText": "Just for my understanding/clarification, the way the SortValues are setup is basically:\n\nIf the types differ (Long compared to Double, it does a comparison on the class name and uses that for ordering)\nOtherwise, if the types are the same it does the type-specific comparison\n\nThat correct?", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r371330328", "createdAt": "2020-01-27T16:05:38Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetrics.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.elasticsearch.common.io.stream.NamedWriteable;\n+import org.elasticsearch.common.io.stream.NamedWriteableRegistry;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.sort.SortOrder;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+public class InternalTopMetrics extends InternalAggregation {\n+    public static List<NamedWriteableRegistry.Entry> writeables() {\n+        return Arrays.asList(\n+                new NamedWriteableRegistry.Entry(SortValue.class, DoubleSortValue.NAME, DoubleSortValue::new),\n+                new NamedWriteableRegistry.Entry(SortValue.class, LongSortValue.NAME, LongSortValue::new));\n+    }\n+\n+    private final DocValueFormat sortFormat;\n+    private final SortOrder sortOrder;\n+    private final SortValue sortValue;\n+    private final String metricName;\n+    private final double metricValue;\n+\n+    private InternalTopMetrics(String name, DocValueFormat sortFormat, SortOrder sortOrder, SortValue sortValue, String metricName,\n+            double metricValue, List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) {\n+        super(name, pipelineAggregators, metaData);\n+        this.sortFormat = sortFormat;\n+        this.sortOrder = sortOrder;\n+        this.sortValue = sortValue;\n+        this.metricName = metricName;\n+        this.metricValue = metricValue;\n+    }\n+\n+    InternalTopMetrics(String name, DocValueFormat sortFormat, SortOrder sortOrder, Object sortValue, String metricName,\n+            double metricValue, List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) {\n+        this(name, sortFormat, sortOrder, sortValueFor(sortValue), metricName, metricValue, pipelineAggregators, metaData);\n+    }\n+\n+    static InternalTopMetrics buildEmptyAggregation(String name, String metricField,\n+            List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) {\n+        return new InternalTopMetrics(name, DocValueFormat.RAW, SortOrder.ASC, null, metricField, Double.NaN, pipelineAggregators,\n+                metaData);\n+    }\n+\n+    /**\n+     * Read from a stream.\n+     */\n+    public InternalTopMetrics(StreamInput in) throws IOException {\n+        super(in);\n+        sortFormat = in.readNamedWriteable(DocValueFormat.class);\n+        sortOrder = SortOrder.readFromStream(in);\n+        sortValue = in.readOptionalNamedWriteable(SortValue.class);\n+        metricName = in.readString();\n+        metricValue = in.readDouble();\n+    }\n+\n+    @Override\n+    protected void doWriteTo(StreamOutput out) throws IOException {\n+        out.writeNamedWriteable(sortFormat);\n+        sortOrder.writeTo(out);\n+        out.writeOptionalNamedWriteable(sortValue);\n+        out.writeString(metricName);\n+        out.writeDouble(metricValue);\n+    }\n+\n+    @Override\n+    public String getWriteableName() {\n+        return TopMetricsAggregationBuilder.NAME;\n+    }\n+\n+    @Override\n+    public Object getProperty(List<String> path) {\n+        if (path.isEmpty()) {\n+            return this;\n+        }\n+        if (path.size() == 1 && metricName.contentEquals(path.get(1))) {\n+            return metricValue;\n+        }\n+        throw new IllegalArgumentException(\"path not supported for [\" + getName() + \"]: \" + path);\n+    }\n+\n+    @Override\n+    public InternalTopMetrics reduce(List<InternalAggregation> aggregations, ReduceContext reduceContext) {\n+        Iterator<InternalAggregation> itr = aggregations.iterator();\n+        InternalTopMetrics first;\n+        do {\n+            if (false == itr.hasNext()) {\n+                // All of the aggregations are empty.\n+                return buildEmptyAggregation(name, metricName, pipelineAggregators(), getMetaData());\n+            }\n+            first = (InternalTopMetrics) itr.next();\n+        } while (first.sortValue == null);\n+        DocValueFormat bestSortFormat = first.sortFormat;\n+        SortValue bestSortValue = first.sortValue;\n+        double bestMetricValue = first.metricValue;\n+        int reverseMul = first.sortOrder.reverseMul();\n+        while (itr.hasNext()) {\n+            InternalTopMetrics result = (InternalTopMetrics) itr.next();\n+            if (result.sortValue == null) {\n+                // Don't bother checking empty results.\n+                continue;\n+            }\n+            if (reverseMul * bestSortValue.compareTo(result.sortValue) > 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5f71b84c6d3ddcd87ea1b8f4cf64140788b2c19b"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTMzOTI3OQ==", "bodyText": "Oh I see, we don't actually know the SortValue.  BucketedSort only gives us back an object, because we don't know which \"ForFoo\" was used for the sort value (ForLong, etc).\nHmm.  I wonder if we should do this conversion on the other end?  Something like toSortValue() on BucketedSort, which each implementation knows how to turn into an implementation of SortValue and then serialize that?\nIt feels a little cleaner since we don't need instance-of checks to resolve the SortValue, and would protect against situations where two types serialize the same data type  but should be interpreted as something different on the receiving end.  I think the various Bytes implementations might run into this (string bytes != range bytes for example).  Dunno if we'll ever implement situations where we'd run into it though.\nOTOH, it adds extra serialization code to all the SortValues.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r371339279", "createdAt": "2020-01-27T16:20:25Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetrics.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.elasticsearch.common.io.stream.NamedWriteable;\n+import org.elasticsearch.common.io.stream.NamedWriteableRegistry;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.sort.SortOrder;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+public class InternalTopMetrics extends InternalAggregation {\n+    public static List<NamedWriteableRegistry.Entry> writeables() {\n+        return Arrays.asList(\n+                new NamedWriteableRegistry.Entry(SortValue.class, DoubleSortValue.NAME, DoubleSortValue::new),\n+                new NamedWriteableRegistry.Entry(SortValue.class, LongSortValue.NAME, LongSortValue::new));\n+    }\n+\n+    private final DocValueFormat sortFormat;\n+    private final SortOrder sortOrder;\n+    private final SortValue sortValue;\n+    private final String metricName;\n+    private final double metricValue;\n+\n+    private InternalTopMetrics(String name, DocValueFormat sortFormat, SortOrder sortOrder, SortValue sortValue, String metricName,\n+            double metricValue, List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) {\n+        super(name, pipelineAggregators, metaData);\n+        this.sortFormat = sortFormat;\n+        this.sortOrder = sortOrder;\n+        this.sortValue = sortValue;\n+        this.metricName = metricName;\n+        this.metricValue = metricValue;\n+    }\n+\n+    InternalTopMetrics(String name, DocValueFormat sortFormat, SortOrder sortOrder, Object sortValue, String metricName,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTMwODM1OA=="}, "originalCommit": {"oid": "5f71b84c6d3ddcd87ea1b8f4cf64140788b2c19b"}, "originalPosition": 48}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aa33abba8faf536d89a3c16742100e3dc4cabd03", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/aa33abba8faf536d89a3c16742100e3dc4cabd03", "committedDate": "2020-01-27T17:44:57Z", "message": "Merge branch 'master' into top_metrics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a2569ded9edd24b8275701f11d00862fd85214e6", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/a2569ded9edd24b8275701f11d00862fd85214e6", "committedDate": "2020-01-27T20:27:43Z", "message": "Move SortValue to core"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e2925e3ec4d3348ba45945c9f85707eae0e2638f", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/e2925e3ec4d3348ba45945c9f85707eae0e2638f", "committedDate": "2020-01-28T14:04:08Z", "message": "moar sort"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "98091fa562c99f58d65f8d1d2c4e144b3d8c0d4c", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/98091fa562c99f58d65f8d1d2c4e144b3d8c0d4c", "committedDate": "2020-01-28T14:08:25Z", "message": "Rename"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b9d80852727474a8b303eb38412aef2a9ee3bc38", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/b9d80852727474a8b303eb38412aef2a9ee3bc38", "committedDate": "2020-01-28T14:16:58Z", "message": "Cleanup"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "935c755c13a7676b7dc31f8594d1ad146d2ffe52", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/935c755c13a7676b7dc31f8594d1ad146d2ffe52", "committedDate": "2020-01-28T15:21:52Z", "message": "Drop method from SortValue"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fb7f1226912956f90a0f88a990fcb2ba1b2b08d0", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/fb7f1226912956f90a0f88a990fcb2ba1b2b08d0", "committedDate": "2020-01-28T15:27:22Z", "message": "last test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a6c69d85663208d02b34a5f96532ed89d47e2e08", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/a6c69d85663208d02b34a5f96532ed89d47e2e08", "committedDate": "2020-01-28T15:39:01Z", "message": "Smaller collector?"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9544c15e3a8aec6b075b11ed80f55cb65974f31a", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/9544c15e3a8aec6b075b11ed80f55cb65974f31a", "committedDate": "2020-01-28T20:37:46Z", "message": "Move to InternalAggregationTestCase"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6efdd1423c3bb4da77a38a28762a8db497814260", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/6efdd1423c3bb4da77a38a28762a8db497814260", "committedDate": "2020-01-29T15:26:58Z", "message": "high level client support"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0a44b09a47cd72600430cfd319eed5d76a290241", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/0a44b09a47cd72600430cfd319eed5d76a290241", "committedDate": "2020-01-29T15:52:40Z", "message": "A little better docs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ef8afc3773530ee4e7c866075b26275e07c77413", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/ef8afc3773530ee4e7c866075b26275e07c77413", "committedDate": "2020-01-29T16:50:40Z", "message": "Merge branch 'master' into top_metrics"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUwMzIyNzEx", "url": "https://github.com/elastic/elasticsearch/pull/51155#pullrequestreview-350322711", "createdAt": "2020-01-29T18:18:51Z", "commit": {"oid": "8304db1e98b374385468d1319a47b2bd0b3a01a3"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQxODoxODo1MVrOFjSpHA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQxODoyNDoyMFrOFjS0dQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjU0OTkxNg==", "bodyText": "Could we have a default implementation based on the sortField implementation? My understanding is that SortField provides anything we need, BucketedSort is just nice because it has the concept of buckets that SortField doesn't have?", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r372549916", "createdAt": "2020-01-29T18:18:51Z", "author": {"login": "jpountz"}, "path": "server/src/main/java/org/elasticsearch/index/fielddata/IndexFieldData.java", "diffHunk": "@@ -72,6 +76,12 @@\n      */\n     SortField sortField(@Nullable Object missingValue, MultiValueMode sortMode, Nested nested, boolean reverse);\n \n+    default BucketedSort newBucketedSort(BigArrays bigArrays, @Nullable Object missingValue, MultiValueMode sortMode, Nested nested,\n+            SortOrder sortOrder, DocValueFormat format) {\n+        // TODO implement all the fields.\n+        throw new IllegalArgumentException(\"Unsupported field type\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8304db1e98b374385468d1319a47b2bd0b3a01a3"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjU1MjgyMQ==", "bodyText": "Do we expect most use-cases to select a single metric of multiple ones? If a single metric is the main use case, we could just take a field or a script and this would give a more consistent experience with other aggregations? If we expect the main use-case to want to retrieve multiple metrics, ignore this comment.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r372552821", "createdAt": "2020-01-29T18:24:20Z", "author": {"login": "jpountz"}, "path": "docs/reference/aggregations/metrics/top-metrics-aggregation.asciidoc", "diffHunk": "@@ -0,0 +1,206 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[[search-aggregations-metrics-top-metrics]]\n+=== Top Metrics Aggregation\n+\n+experimental[We expect to change the response format of this aggregation as we add more features.]\n+\n+The `top_metrics` aggregation selects metrics from the document with the largest or smallest \"sort\"\n+value. This gets the value of the `v` field on the document with the largest value of `s`:\n+\n+[source,console,id=search-aggregations-metrics-top-metrics-simple]\n+----\n+POST /test/_bulk?refresh\n+{\"index\": {}}\n+{\"s\": 1, \"v\": 3.1415}\n+{\"index\": {}}\n+{\"s\": 2, \"v\": 1}\n+{\"index\": {}}\n+{\"s\": 3, \"v\": 2.71828}\n+POST /test/_search?filter_path=aggregations\n+{\n+  \"aggs\": {\n+    \"tm\": {\n+      \"top_metrics\": {\n+        \"metric\": {\"field\": \"v\"},", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8304db1e98b374385468d1319a47b2bd0b3a01a3"}, "originalPosition": 25}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0b191f8db23808a570f3116477c7baeec3a97fc9", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/0b191f8db23808a570f3116477c7baeec3a97fc9", "committedDate": "2020-01-30T16:19:25Z", "message": "Test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUwOTI2MTY3", "url": "https://github.com/elastic/elasticsearch/pull/51155#pullrequestreview-350926167", "createdAt": "2020-01-30T15:45:07Z", "commit": {"oid": "8304db1e98b374385468d1319a47b2bd0b3a01a3"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMFQxNTo0NTowN1rOFjvzlw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMFQxNjoyNjozMFrOFjxX9Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzAyNzczNQ==", "bodyText": "I was confused by this, since usually things that descend from AbstractAggregationBuilder are the entry points for that aggregation.  In this case, it looks like we're just using the XContentBuilder aspect of this, presumably for the HLRC to build out requests?  If that's the case, I think it would help to make clear in the javadoc that this is not the main builder for this aggregation, and be explicit about its intended use.\nI don't think I'm alone in thinking our aggregation builders do too much, and this seems symptomatic of that.   Maybe at some point, we can talk about breaking up those roles.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373027735", "createdAt": "2020-01-30T15:45:07Z", "author": {"login": "not-napoleon"}, "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/analytics/TopMetricsAggregationBuilder.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.client.analytics;\n+\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.search.aggregations.AbstractAggregationBuilder;\n+import org.elasticsearch.search.aggregations.AggregationBuilder;\n+import org.elasticsearch.search.aggregations.AggregatorFactories.Builder;\n+import org.elasticsearch.search.aggregations.AggregatorFactory;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.Map;\n+\n+/**\n+ * Builds the Top Metrics aggregation request.\n+ */\n+public class TopMetricsAggregationBuilder extends AbstractAggregationBuilder<TopMetricsAggregationBuilder> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8304db1e98b374385468d1319a47b2bd0b3a01a3"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA1MzQyOQ==", "bodyText": "I understand why we're not using MultiValuesSourceAggregationBuilder, but I don't understand why we aren't using ValuesSourceAggregationBuilder (and ValuesSourceAggregatorFactory).  We have one field that we want to get a ValuesSource for, which is what ValuesSourceAggregationBuilder does.  Maybe there's some reason I'm missing here?  Using VSAB will also make my life easier when it comes time to wire this up to the registry ;)", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373053429", "createdAt": "2020-01-30T16:26:30Z", "author": {"login": "not-napoleon"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregatorFactory.java", "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.AggregatorFactories.Builder;\n+import org.elasticsearch.search.aggregations.AggregatorFactory;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.MultiValuesSourceFieldConfig;\n+import org.elasticsearch.search.aggregations.support.ValueType;\n+import org.elasticsearch.search.aggregations.support.ValuesSource;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.search.sort.BucketedSort;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+public class TopMetricsAggregatorFactory extends AggregatorFactory {\n+    private final List<SortBuilder<?>> sortBuilders;\n+    private final MultiValuesSourceFieldConfig metricField;\n+\n+    public TopMetricsAggregatorFactory(String name, QueryShardContext queryShardContext, AggregatorFactory parent,\n+            Builder subFactoriesBuilder, Map<String, Object> metaData, List<SortBuilder<?>> sortBuilders,\n+            MultiValuesSourceFieldConfig metricField) throws IOException {\n+        super(name, queryShardContext, parent, subFactoriesBuilder, metaData);\n+        this.sortBuilders = sortBuilders;\n+        this.metricField = metricField;\n+    }\n+\n+    @Override\n+    protected TopMetricsAggregator createInternal(SearchContext searchContext, Aggregator parent, boolean collectsFromSingleBucket,\n+            List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) throws IOException {\n+        ValuesSourceConfig<ValuesSource.Numeric> metricFieldSource = ValuesSourceConfig.resolve(queryShardContext, ValueType.NUMERIC,\n+                metricField.getFieldName(), metricField.getScript(), metricField.getMissing(), metricField.getTimeZone(), null);\n+        ValuesSource.Numeric metricValueSource = metricFieldSource.toValuesSource(queryShardContext);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8304db1e98b374385468d1319a47b2bd0b3a01a3"}, "originalPosition": 43}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "49ee3c7ec6a2fba8bd4b78a4a3264aa88124d9ee", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/49ee3c7ec6a2fba8bd4b78a4a3264aa88124d9ee", "committedDate": "2020-01-30T17:39:38Z", "message": "Javadoc"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6d83a2ac1dc67c305d048d8a743f121d8a15b647", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/6d83a2ac1dc67c305d048d8a743f121d8a15b647", "committedDate": "2020-01-30T19:31:12Z", "message": "yaml"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "80bf931e07eca3c6b1b75648ffcb373086499dd7", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/80bf931e07eca3c6b1b75648ffcb373086499dd7", "committedDate": "2020-01-30T22:33:14Z", "message": "Force define"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7f46898f458c6c4161e847d23438bd5f9dc13619", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/7f46898f458c6c4161e847d23438bd5f9dc13619", "committedDate": "2020-01-31T13:41:29Z", "message": "Script"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c", "committedDate": "2020-01-31T17:07:56Z", "message": "geo_distance"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8304db1e98b374385468d1319a47b2bd0b3a01a3", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/8304db1e98b374385468d1319a47b2bd0b3a01a3", "committedDate": "2020-01-29T17:21:55Z", "message": "Test"}, "afterCommit": {"oid": "c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c", "committedDate": "2020-01-31T17:07:56Z", "message": "geo_distance"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUxNjUyMDI2", "url": "https://github.com/elastic/elasticsearch/pull/51155#pullrequestreview-351652026", "createdAt": "2020-01-31T17:14:33Z", "commit": {"oid": "c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMVQxNzoxNDozM1rOFkSGVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMVQxNzoxNDozM1rOFkSGVg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU4OTU5MA==", "bodyText": "I haven't written tests for plugging in these abstractions other than the tests for top_metrics itself. I'd love some advice on what is worth it. This one probably isn't, but DoubleValuesComparatorSource probably is. Same for the sort implementations, I guess. Thoughts?", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373589590", "createdAt": "2020-01-31T17:14:33Z", "author": {"login": "nik9000"}, "path": "modules/mapper-extras/src/main/java/org/elasticsearch/index/mapper/ScaledFloatFieldMapper.java", "diffHunk": "@@ -522,6 +525,12 @@ public SortField sortField(@Nullable Object missingValue, MultiValueMode sortMod\n             return new SortField(getFieldName(), source, reverse);\n         }\n \n+        @Override\n+        public BucketedSort newBucketedSort(BigArrays bigArrays, Object missingValue, MultiValueMode sortMode, Nested nested,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c"}, "originalPosition": 22}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUxNjUyNjY1", "url": "https://github.com/elastic/elasticsearch/pull/51155#pullrequestreview-351652665", "createdAt": "2020-01-31T17:15:39Z", "commit": {"oid": "c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMVQxNzoxNTozOVrOFkSIPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMVQxNzoxNTozOVrOFkSIPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU5MDA3OA==", "bodyText": "I'm using a ConstructingObjectParser to build ParsedTopHits, thus the change here.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373590078", "createdAt": "2020-01-31T17:15:39Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/search/aggregations/ParsedAggregation.java", "diffHunk": "@@ -36,7 +36,7 @@\n  */\n public abstract class ParsedAggregation implements Aggregation, ToXContentFragment {\n \n-    protected static void declareAggregationFields(ObjectParser<? extends ParsedAggregation, Void> objectParser) {\n+    protected static void declareAggregationFields(AbstractObjectParser<? extends ParsedAggregation, ?> objectParser) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c"}, "originalPosition": 14}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUxNjUzOTM1", "url": "https://github.com/elastic/elasticsearch/pull/51155#pullrequestreview-351653935", "createdAt": "2020-01-31T17:17:52Z", "commit": {"oid": "c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMVQxNzoxNzo1M1rOFkSMEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMVQxNzoxNzo1M1rOFkSMEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU5MTA1Ng==", "bodyText": "Hmmm - this looks like it should have been a nocommit for me. I don't believe you can get here now but I need to double check on it.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373591056", "createdAt": "2020-01-31T17:17:53Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/search/sort/FieldSortBuilder.java", "diffHunk": "@@ -368,13 +348,57 @@ public SortFieldAndFormat build(QueryShardContext context) throws IOException {\n             }\n             SortedNumericDVIndexFieldData numericFieldData = (SortedNumericDVIndexFieldData) fieldData;\n             NumericType resolvedType = resolveNumericType(numericType);\n-            field = numericFieldData.sortField(resolvedType, missing, localSortMode, nested, reverse);\n+            field = numericFieldData.sortField(resolvedType, missing, localSortMode(), nested, reverse);\n         } else {\n-            field = fieldData.sortField(missing, localSortMode, nested, reverse);\n+            field = fieldData.sortField(missing, localSortMode(), nested, reverse);\n         }\n         return new SortFieldAndFormat(field, fieldType.docValueFormat(null, null));\n     }\n \n+    @Override\n+    public BucketedSort buildBucketedSort(QueryShardContext context) throws IOException {\n+        MappedFieldType fieldType = context.fieldMapper(fieldName);\n+        Nested nested = nested(context, fieldType);\n+        if (fieldType == null) {\n+            if (unmappedType != null) {\n+                fieldType = context.getMapperService().unmappedFieldType(unmappedType);\n+            } else {\n+                throw new QueryShardException(context, \"No mapping found for [\" + fieldName + \"] in order to sort on\");\n+            }\n+        }\n+\n+        IndexFieldData<?> fieldData = context.getForField(fieldType);\n+        if (fieldData instanceof IndexNumericFieldData == false\n+                && (sortMode == SortMode.SUM || sortMode == SortMode.AVG || sortMode == SortMode.MEDIAN)) {\n+            throw new QueryShardException(context, \"we only support AVG, MEDIAN and SUM on number based fields\");\n+        }\n+        if (numericType != null) {\n+            throw new IllegalArgumentException(\"not yet supported\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c"}, "originalPosition": 71}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUxNjU0NTk1", "url": "https://github.com/elastic/elasticsearch/pull/51155#pullrequestreview-351654595", "createdAt": "2020-01-31T17:19:06Z", "commit": {"oid": "c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMVQxNzoxOTowNlrOFkSOIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMVQxNzoxOTowNlrOFkSOIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU5MTU4NQ==", "bodyText": "These are all extracted into private methods to make building the BucketedSort simpler.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373591585", "createdAt": "2020-01-31T17:19:06Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortBuilder.java", "diffHunk": "@@ -489,8 +490,43 @@ public static GeoDistanceSortBuilder fromXContent(XContentParser parser, String\n \n     @Override\n     public SortFieldAndFormat build(QueryShardContext context) throws IOException {\n+        GeoPoint[] localPoints = localPoints();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c"}, "originalPosition": 12}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUxNjU1ODM4", "url": "https://github.com/elastic/elasticsearch/pull/51155#pullrequestreview-351655838", "createdAt": "2020-01-31T17:21:16Z", "commit": {"oid": "c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMVQxNzoyMToxNlrOFkSRvA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMVQxNzoyMToxNlrOFkSRvA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU5MjUwOA==", "bodyText": "It looks like we actually have three ways to do geo distance - the optimization above and a single point to single point optimization inside GeoUtils.distanceValues. It isn't clear to me that it is worth doing a bunch of work to mimic the optimization above without benchmarks. Which I will write eventually.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373592508", "createdAt": "2020-01-31T17:21:16Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortBuilder.java", "diffHunk": "@@ -489,8 +490,43 @@ public static GeoDistanceSortBuilder fromXContent(XContentParser parser, String\n \n     @Override\n     public SortFieldAndFormat build(QueryShardContext context) throws IOException {\n+        GeoPoint[] localPoints = localPoints();\n+        boolean reverse = order == SortOrder.DESC;\n+        MultiValueMode localSortMode = localSortMode();\n+        IndexGeoPointFieldData geoIndexFieldData = fieldData(context);\n+        Nested nested = nested(context);\n \n-        // validation was not available prior to 2.x, so to support bwc percolation queries we only ignore_malformed\n+        if (geoIndexFieldData.getClass() == LatLonPointDVIndexFieldData.class // only works with 5.x geo_point\n+                && nested == null\n+                && localSortMode == MultiValueMode.MIN // LatLonDocValuesField internally picks the closest point\n+                && unit == DistanceUnit.METERS\n+                && reverse == false\n+                && localPoints.length == 1) {\n+            return new SortFieldAndFormat(\n+                    LatLonDocValuesField.newDistanceSort(fieldName, localPoints[0].lat(), localPoints[0].lon()),\n+                    DocValueFormat.RAW);\n+        }\n+\n+        return new SortFieldAndFormat(\n+                new SortField(fieldName, comparatorSource(localPoints, localSortMode, geoIndexFieldData, nested), reverse),\n+                DocValueFormat.RAW);\n+    }\n+\n+    @Override\n+    public BucketedSort buildBucketedSort(QueryShardContext context) throws IOException {\n+        GeoPoint[] localPoints = localPoints();\n+        MultiValueMode localSortMode = localSortMode();\n+        IndexGeoPointFieldData geoIndexFieldData = fieldData(context);\n+        Nested nested = nested(context);\n+\n+        // TODO implement the single point optimization above ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c"}, "originalPosition": 42}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e846862865a20ecb3594508cdcab7acbdcc4be37", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/e846862865a20ecb3594508cdcab7acbdcc4be37", "committedDate": "2020-01-31T17:21:30Z", "message": "Fix indentation"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUxNjU2MzYw", "url": "https://github.com/elastic/elasticsearch/pull/51155#pullrequestreview-351656360", "createdAt": "2020-01-31T17:22:17Z", "commit": {"oid": "c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMVQxNzoyMjoxOFrOFkSTZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMVQxNzoyMjoxOFrOFkSTZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU5MjkzNQ==", "bodyText": "These seem like candidates for a follow up.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373592935", "createdAt": "2020-01-31T17:22:18Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortBuilder.java", "diffHunk": "@@ -515,15 +551,19 @@ public SortFieldAndFormat build(QueryShardContext context) throws IOException {\n                 GeoUtils.normalizePoint(point, true, true);\n             }\n         }\n+        return localPoints;\n+    }\n \n-        boolean reverse = (order == SortOrder.DESC);\n-        final MultiValueMode finalSortMode;\n-        if (sortMode == null) {\n-            finalSortMode = reverse ? MultiValueMode.MAX : MultiValueMode.MIN;\n-        } else {\n-            finalSortMode = MultiValueMode.fromString(sortMode.toString());\n+    private MultiValueMode localSortMode() {\n+        // TODO this lines up with FieldSortBuilder. Share?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c"}, "originalPosition": 67}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUxNjY5MjMy", "url": "https://github.com/elastic/elasticsearch/pull/51155#pullrequestreview-351669232", "createdAt": "2020-01-31T17:46:02Z", "commit": {"oid": "e846862865a20ecb3594508cdcab7acbdcc4be37"}, "state": "APPROVED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMVQxNzo0NjowM1rOFkS6Kg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMVQxODowOToyMlrOFkTf2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzYwMjg1OA==", "bodyText": "Side-note: there's an ask from ES leads that we open tracking issues whenever we add experimental/beta features.  So after this merges we should open an issue and make a note about what needs to be done / what needs to be discovered before we mark the feature GA.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373602858", "createdAt": "2020-01-31T17:46:03Z", "author": {"login": "polyfractal"}, "path": "docs/reference/aggregations/metrics/top-metrics-aggregation.asciidoc", "diffHunk": "@@ -0,0 +1,146 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[[search-aggregations-metrics-top-metrics]]\n+=== Top Metrics Aggregation\n+\n+experimental[We expect to change the response format of this aggregation as we add more features.]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e846862865a20ecb3594508cdcab7acbdcc4be37"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzYwMzUwOA==", "bodyText": "It's neat this works :)", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373603508", "createdAt": "2020-01-31T17:47:34Z", "author": {"login": "polyfractal"}, "path": "docs/reference/aggregations/metrics/top-metrics-aggregation.asciidoc", "diffHunk": "@@ -0,0 +1,146 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[[search-aggregations-metrics-top-metrics]]\n+=== Top Metrics Aggregation\n+\n+experimental[We expect to change the response format of this aggregation as we add more features.]\n+\n+The `top_metrics` aggregation selects metrics from the document with the largest or smallest \"sort\"\n+value. For example, This gets the value of the `v` field on the document with the largest value of `s`:\n+\n+[source,console,id=search-aggregations-metrics-top-metrics-simple]\n+----\n+POST /test/_bulk?refresh\n+{\"index\": {}}\n+{\"s\": 1, \"v\": 3.1415}\n+{\"index\": {}}\n+{\"s\": 2, \"v\": 1}\n+{\"index\": {}}\n+{\"s\": 3, \"v\": 2.71828}\n+POST /test/_search?filter_path=aggregations\n+{\n+  \"aggs\": {\n+    \"tm\": {\n+      \"top_metrics\": {\n+        \"metric\": {\"field\": \"v\"},\n+        \"sort\": {\"s\": \"desc\"}\n+      }\n+    }\n+  }\n+}\n+----\n+\n+Which returns:\n+\n+[source,js]\n+----\n+{\n+  \"aggregations\": {\n+    \"tm\": {\n+      \"top\": [ {\"sort\": [3], \"metrics\": {\"v\": 2.718280076980591 } } ]\n+    }\n+  }\n+}\n+----\n+// TESTRESPONSE\n+\n+`top_metrics` is fairly similar to <<search-aggregations-metrics-top-hits-aggregation, `top_hits`>>\n+in spirit but it should be faster in most cases because it can do its job entirely with <<doc-values>>\n+which are **much** faster to access than the `_source` which `top_hits` needs. \n+\n+==== `sort`\n+\n+The `sort` field in the metric request functions exactly the same as the `sort` field in the\n+<<request-body-search-sort, search>> request except:\n+* It can't be used on <<binary,binary>>, <<flattened,flattened>, <<ip,ip>>,\n+<<keyword,keyword>>, or <<text,text>> fields.\n+* It only supports a single sort value.\n+\n+The metrics that the aggregation returns is the first hit that would be returned by the search\n+request. So,\n+\n+`\"sort\": {\"s\": \"desc\"}`:: gets metrics from the document with the highest `s`\n+`\"sort\": {\"s\": \"asc\"}`:: gets the metrics from the document with the lowest `s`\n+`\"sort\": {\"_geo_distance\": {\"location\": \"35.7796, 78.6382\"}}`::", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e846862865a20ecb3594508cdcab7acbdcc4be37"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzYwNTMwMQ==", "bodyText": "Curiosity question: the other exceptions just say \"can only sort on numerics\", but this one is formatted a bit different, is there a reason the CONTENT_TYPE is helpful here but not elsewhere?", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373605301", "createdAt": "2020-01-31T17:51:50Z", "author": {"login": "polyfractal"}, "path": "server/src/main/java/org/elasticsearch/index/mapper/IdFieldMapper.java", "diffHunk": "@@ -203,6 +207,12 @@ public SortField sortField(Object missingValue, MultiValueMode sortMode, Nested\n                             return new SortField(getFieldName(), source, reverse);\n                         }\n \n+                        @Override\n+                        public BucketedSort newBucketedSort(BigArrays bigArrays, Object missingValue, MultiValueMode sortMode,\n+                                Nested nested, SortOrder sortOrder, DocValueFormat format) {\n+                            throw new UnsupportedOperationException(\"can't sort on the [\" + CONTENT_TYPE + \"] field\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e846862865a20ecb3594508cdcab7acbdcc4be37"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzYwNjYyMg==", "bodyText": "\ud83d\udc4d", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373606622", "createdAt": "2020-01-31T17:55:03Z", "author": {"login": "polyfractal"}, "path": "server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java", "diffHunk": "@@ -0,0 +1,361 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.search.sort;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.Scorable;\n+import org.elasticsearch.common.lease.Releasable;\n+import org.elasticsearch.common.lease.Releasables;\n+import org.elasticsearch.common.lucene.ScorerAware;\n+import org.elasticsearch.common.util.BigArray;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.util.BitArray;\n+import org.elasticsearch.common.util.DoubleArray;\n+import org.elasticsearch.common.util.FloatArray;\n+import org.elasticsearch.common.util.LongArray;\n+import org.elasticsearch.search.DocValueFormat;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Type specialized sort implementations designed for use in aggregations.\n+ */\n+public abstract class BucketedSort implements Releasable {\n+    // TODO priority queue semantics to support multiple hits in the buckets\n+    protected final BigArrays bigArrays;\n+    private final SortOrder order;\n+    private final DocValueFormat format;\n+\n+    public BucketedSort(BigArrays bigArrays, SortOrder order, DocValueFormat format) {\n+        this.bigArrays = bigArrays;\n+        this.order = order;\n+        this.format = format;\n+    }\n+\n+    /**\n+     * The order of the sort.\n+     */\n+    public final SortOrder getOrder() {\n+        return order;\n+    }\n+\n+    /**\n+     * The format to use when presenting the values.\n+     */\n+    public final DocValueFormat getFormat() {\n+        return format;\n+    }\n+\n+    /**\n+     * Get the value for a bucket if it has been collected, null otherwise.\n+     */\n+    public final SortValue getValue(long bucket) {\n+        if (bucket >= buckets().size()) {\n+            return null;\n+        }\n+        return getValueForBucket(bucket);\n+    }\n+\n+    /**\n+     * Get the {@linkplain Leaf} implementation that'll do that actual collecting.\n+     */\n+    public abstract Leaf forLeaf(LeafReaderContext ctx) throws IOException;\n+\n+    /**\n+     * Does this sort need scores? Most don't, but sorting on {@code _score} does.\n+     */\n+    public abstract boolean needsScores();\n+\n+    /**\n+     * The {@linkplain BigArray} backing this sort.\n+     */\n+    protected abstract BigArray buckets();\n+\n+    /**\n+     * Grow the {@linkplain BigArray} backing this sort to account for new buckets.\n+     * This will only be called if the array is too small.\n+     */\n+    protected abstract void grow(long minSize);\n+\n+    /**\n+     * Get the value for a bucket. This will only be called if the bucket was collected.\n+     */\n+    protected abstract SortValue getValueForBucket(long bucket);\n+\n+    /**\n+     * Performs the actual collection against a {@linkplain LeafReaderContext}.\n+     */\n+    public abstract class Leaf implements ScorerAware {\n+        /**\n+         * Collect this doc, returning {@code true} if it is competitive.\n+         */\n+        public final boolean collectIfCompetitive(int doc, long bucket) throws IOException {\n+            if (false == advanceExact(doc)) {\n+                return false;\n+            }\n+            if (bucket >= buckets().size()) {\n+                grow(bucket + 1);\n+                setValue(bucket);\n+                return true;\n+            }\n+            return setIfCompetitive(bucket);\n+        }\n+\n+        /**\n+         * Move the underlying data source reader to the doc and return\n+         * {@code true} if there is data for the sort value.\n+         */\n+        protected abstract boolean advanceExact(int doc) throws IOException;\n+\n+        /**\n+         * Set the value for a particular bucket to the value that doc has for the sort.\n+         * This is called when we're *sure* we haven't yet seen the bucket.\n+         */\n+        protected abstract void setValue(long bucket) throws IOException;\n+\n+        /**\n+         * If the value that doc has for the sort is competitive with the other values\n+         * then set it. This is called for buckets we *might* have already seen. So\n+         * implementers will have to check for \"empty\" buckets in their own way. The\n+         * vaguery here is for two reasons:\n+         * <ul>\n+         * <li>When we see a bucket that won't fit in our arrays we oversize them so\n+         *     we don't have to grow them by 1 every time.</li>\n+         * <li>Buckets don't always arrive in order and our storage is \"dense\" on the\n+         *     bucket ordinal. For example, we might get bucket number 4 grow the array\n+         *     to fit it, and *then* get bucket number 3.</li>\n+         * </ul>\n+         */\n+        protected abstract boolean setIfCompetitive(long bucket) throws IOException;\n+    }\n+\n+    /**\n+     * Superclass for implementations of {@linkplain BucketedSort} for {@code double} keys.\n+     */\n+    public abstract static class ForDoubles extends BucketedSort {\n+        private DoubleArray buckets = bigArrays.newDoubleArray(1);\n+\n+        public ForDoubles(BigArrays bigArrays, SortOrder sortOrder, DocValueFormat format) {\n+            super(bigArrays, sortOrder, format);\n+            // NaN is a sentinel value for \"unused\"\n+            buckets.set(0, Double.NaN);\n+        }\n+\n+        @Override\n+        public boolean needsScores() { return false; }\n+\n+        @Override\n+        protected final BigArray buckets() { return buckets; }\n+\n+        @Override\n+        protected final void grow(long minSize) {\n+            long oldSize = buckets.size();\n+            buckets = bigArrays.grow(buckets, minSize);\n+            buckets.fill(oldSize, buckets.size(), Double.NaN);\n+        }\n+\n+        @Override\n+        public final SortValue getValueForBucket(long bucket) {\n+            double val = buckets.get(bucket);\n+            if (Double.isNaN(val)) {\n+                return null;\n+            }\n+            return SortValue.from(val);\n+        }\n+\n+        @Override\n+        public final void close() {\n+            buckets.close();\n+        }\n+\n+        protected abstract class Leaf extends BucketedSort.Leaf {\n+            protected abstract double docValue() throws IOException;\n+\n+            @Override\n+            public final void setScorer(Scorable scorer) {}\n+\n+            @Override\n+            protected final void setValue(long bucket) throws IOException {\n+                buckets.set(bucket, docValue());\n+            }\n+\n+            @Override\n+            protected final boolean setIfCompetitive(long bucket) throws IOException {\n+                double docSort = docValue();\n+                double bestSort = buckets.get(bucket);\n+                // The NaN check is important here because it needs to always lose.\n+                if (false == Double.isNaN(bestSort) && getOrder().reverseMul() * Double.compare(bestSort, docSort) <= 0) {\n+                    return false;\n+                }\n+                buckets.set(bucket, docSort);\n+                return true;\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Superclass for implementations of {@linkplain BucketedSort} for {@code float} keys.\n+     */\n+    public abstract static class ForFloats extends BucketedSort {\n+        private FloatArray buckets = bigArrays.newFloatArray(1);\n+\n+        public ForFloats(BigArrays bigArrays, SortOrder sortOrder, DocValueFormat format) {\n+            super(bigArrays, sortOrder, format);\n+            // NaN is a sentinel value for \"unused\"\n+            buckets.set(0, Float.NaN);\n+        }\n+\n+        @Override\n+        protected final BigArray buckets() { return buckets; }\n+\n+        @Override\n+        protected final void grow(long minSize) {\n+            long oldSize = buckets.size();\n+            buckets = bigArrays.grow(buckets, minSize);\n+            buckets.fill(oldSize, buckets.size(), Float.NaN);\n+        }\n+\n+        @Override\n+        public final SortValue getValueForBucket(long bucket) {\n+            float val = buckets.get(bucket);\n+            if (Float.isNaN(val)) {\n+                return null;\n+            }\n+            return SortValue.from(val);\n+        }\n+\n+        @Override\n+        public final void close() {\n+            buckets.close();\n+        }\n+\n+        protected abstract class Leaf extends BucketedSort.Leaf {\n+            protected abstract float docValue() throws IOException;\n+\n+            @Override\n+            protected final void setValue(long bucket) throws IOException {\n+                buckets.set(bucket, docValue());\n+            }\n+\n+            @Override\n+            protected final boolean setIfCompetitive(long bucket) throws IOException {\n+                float docSort = docValue();\n+                float bestSort = buckets.get(bucket);\n+                // The NaN check is important here because it needs to always lose.\n+                if (false == Float.isNaN(bestSort) && getOrder().reverseMul() * Float.compare(bestSort, docSort) <= 0) {\n+                    return false;\n+                }\n+                buckets.set(bucket, docSort);\n+                return true;\n+            }\n+\n+        }\n+    }\n+\n+    /**\n+     * Superclass for implementations of {@linkplain BucketedSort} for {@code long} keys.\n+     */\n+    public abstract static class ForLongs extends BucketedSort {\n+        /**\n+         * Tracks which buckets have been seen before so we can *always*\n+         * set the value in that case. We need this because there isn't a\n+         * sentinel value in the {@code long} type that we can use for this\n+         * like NaN in {@code double} or {@code float}.\n+         */\n+        private BitArray seen = new BitArray(1, bigArrays);\n+        /**\n+         * The actual values.\n+         */\n+        private LongArray buckets = bigArrays.newLongArray(1);\n+\n+        public ForLongs(BigArrays bigArrays, SortOrder sortOrder, DocValueFormat format) {\n+            super(bigArrays, sortOrder, format);\n+        }\n+\n+        @Override\n+        public boolean needsScores() { return false; }\n+\n+        @Override\n+        protected final BigArray buckets() { return buckets; }\n+\n+        @Override\n+        protected final void grow(long minSize) {\n+            buckets = bigArrays.grow(buckets, minSize);\n+        }\n+\n+        @Override\n+        public final SortValue getValueForBucket(long bucket) {\n+            if (bucket > Integer.MAX_VALUE) {\n+                /* We throw exceptions if we try to collect buckets bigger\n+                 * than an int so we *can't* have seen any of these. */\n+                return null;\n+            }\n+            if (false == seen.get((int) bucket)) {\n+                /* Buckets we haven't seen must be null here so we can\n+                 * skip \"gaps\" in seen buckets. */\n+                return null;\n+            }\n+            return SortValue.from(buckets.get(bucket));\n+        }\n+\n+        @Override\n+        public final void close() {\n+            Releasables.close(seen, buckets);\n+        }\n+\n+        protected abstract class Leaf extends BucketedSort.Leaf {\n+            protected abstract long docValue() throws IOException;\n+\n+            @Override\n+            public final void setScorer(Scorable scorer) {}\n+\n+            @Override\n+            protected final void setValue(long bucket) throws IOException {\n+                seen.set(bucketIsInt(bucket));\n+                buckets.set(bucket, docValue());\n+            }\n+\n+            @Override\n+            protected final boolean setIfCompetitive(long bucket) throws IOException {\n+                long docSort = docValue();\n+                int intBucket = bucketIsInt(bucket);\n+                if (false == seen.get(intBucket)) {\n+                    seen.set(intBucket);\n+                    buckets.set(bucket, docSort);\n+                    return true;\n+                }\n+                long bestSort = buckets.get(bucket); \n+                if (getOrder().reverseMul() * Double.compare(bestSort, docSort) <= 0) {\n+                    return false;\n+                }\n+                buckets.set(bucket, docSort);\n+                return true;\n+            }\n+\n+            private int bucketIsInt(long bucket) {\n+                if (bucket > Integer.MAX_VALUE) {\n+                    throw new UnsupportedOperationException(\"Long sort keys don't support more than [\" + Integer.MAX_VALUE + \"] buckets\");\n+                    // I don't feel too bad about that because it'd take about 16 GB of memory....", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e846862865a20ecb3594508cdcab7acbdcc4be37"}, "originalPosition": 355}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzYwNzkxNw==", "bodyText": "Couldn't this be set if the user supplies a numeric_type type hint on the sort object?", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373607917", "createdAt": "2020-01-31T17:58:03Z", "author": {"login": "polyfractal"}, "path": "server/src/main/java/org/elasticsearch/search/sort/FieldSortBuilder.java", "diffHunk": "@@ -368,13 +348,57 @@ public SortFieldAndFormat build(QueryShardContext context) throws IOException {\n             }\n             SortedNumericDVIndexFieldData numericFieldData = (SortedNumericDVIndexFieldData) fieldData;\n             NumericType resolvedType = resolveNumericType(numericType);\n-            field = numericFieldData.sortField(resolvedType, missing, localSortMode, nested, reverse);\n+            field = numericFieldData.sortField(resolvedType, missing, localSortMode(), nested, reverse);\n         } else {\n-            field = fieldData.sortField(missing, localSortMode, nested, reverse);\n+            field = fieldData.sortField(missing, localSortMode(), nested, reverse);\n         }\n         return new SortFieldAndFormat(field, fieldType.docValueFormat(null, null));\n     }\n \n+    @Override\n+    public BucketedSort buildBucketedSort(QueryShardContext context) throws IOException {\n+        MappedFieldType fieldType = context.fieldMapper(fieldName);\n+        Nested nested = nested(context, fieldType);\n+        if (fieldType == null) {\n+            if (unmappedType != null) {\n+                fieldType = context.getMapperService().unmappedFieldType(unmappedType);\n+            } else {\n+                throw new QueryShardException(context, \"No mapping found for [\" + fieldName + \"] in order to sort on\");\n+            }\n+        }\n+\n+        IndexFieldData<?> fieldData = context.getForField(fieldType);\n+        if (fieldData instanceof IndexNumericFieldData == false\n+                && (sortMode == SortMode.SUM || sortMode == SortMode.AVG || sortMode == SortMode.MEDIAN)) {\n+            throw new QueryShardException(context, \"we only support AVG, MEDIAN and SUM on number based fields\");\n+        }\n+        if (numericType != null) {\n+            throw new IllegalArgumentException(\"not yet supported\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU5MTA1Ng=="}, "originalCommit": {"oid": "c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzYwODYyMQ==", "bodyText": "++ I think this is fine to start", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373608621", "createdAt": "2020-01-31T17:59:40Z", "author": {"login": "polyfractal"}, "path": "server/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortBuilder.java", "diffHunk": "@@ -489,8 +490,43 @@ public static GeoDistanceSortBuilder fromXContent(XContentParser parser, String\n \n     @Override\n     public SortFieldAndFormat build(QueryShardContext context) throws IOException {\n+        GeoPoint[] localPoints = localPoints();\n+        boolean reverse = order == SortOrder.DESC;\n+        MultiValueMode localSortMode = localSortMode();\n+        IndexGeoPointFieldData geoIndexFieldData = fieldData(context);\n+        Nested nested = nested(context);\n \n-        // validation was not available prior to 2.x, so to support bwc percolation queries we only ignore_malformed\n+        if (geoIndexFieldData.getClass() == LatLonPointDVIndexFieldData.class // only works with 5.x geo_point\n+                && nested == null\n+                && localSortMode == MultiValueMode.MIN // LatLonDocValuesField internally picks the closest point\n+                && unit == DistanceUnit.METERS\n+                && reverse == false\n+                && localPoints.length == 1) {\n+            return new SortFieldAndFormat(\n+                    LatLonDocValuesField.newDistanceSort(fieldName, localPoints[0].lat(), localPoints[0].lon()),\n+                    DocValueFormat.RAW);\n+        }\n+\n+        return new SortFieldAndFormat(\n+                new SortField(fieldName, comparatorSource(localPoints, localSortMode, geoIndexFieldData, nested), reverse),\n+                DocValueFormat.RAW);\n+    }\n+\n+    @Override\n+    public BucketedSort buildBucketedSort(QueryShardContext context) throws IOException {\n+        GeoPoint[] localPoints = localPoints();\n+        MultiValueMode localSortMode = localSortMode();\n+        IndexGeoPointFieldData geoIndexFieldData = fieldData(context);\n+        Nested nested = nested(context);\n+\n+        // TODO implement the single point optimization above ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU5MjUwOA=="}, "originalCommit": {"oid": "c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzYxMDU3Nw==", "bodyText": "Not sure I understand the comment.  Extend \"Base\"?", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373610577", "createdAt": "2020-01-31T18:04:33Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregator.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.Scorable;\n+import org.apache.lucene.search.ScoreMode;\n+import org.elasticsearch.common.lease.Releasables;\n+import org.elasticsearch.common.util.DoubleArray;\n+import org.elasticsearch.index.fielddata.NumericDoubleValues;\n+import org.elasticsearch.search.MultiValueMode;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.elasticsearch.search.aggregations.metrics.MetricsAggregator;\n+import org.elasticsearch.search.aggregations.metrics.NumericMetricsAggregator;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.ValuesSource;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.search.sort.BucketedSort;\n+import org.elasticsearch.search.sort.SortValue;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * Collects the {@code top_metrics} aggregation.\n+ *\n+ * This extends {@linkplain NumericMetricsAggregator.MultiValue} as a compromise\n+ * to allow sorting on the metric. Right now it only collects a single metric\n+ * but we expect it to collect a list of them in the future. Also in the future\n+ * we expect it to allow collecting non-string metrics which'll change how we\n+ * do the inheritance. Finally, we also expect it to allow collecting more than\n+ * one document worth of metrics. Once that happens we'll need to come up with\n+ * some way to pick which document's metrics to use for the sort.\n+ */\n+class TopMetricsAggregator extends MetricsAggregator {\n+    private final BucketedSort sort;\n+    private final String metricName;\n+    private final ValuesSource.Numeric metricValueSource;\n+    private DoubleArray values;\n+\n+    TopMetricsAggregator(String name, SearchContext context, Aggregator parent, List<PipelineAggregator> pipelineAggregators,\n+            Map<String, Object> metaData, BucketedSort sort,\n+            String metricName, ValuesSource.Numeric metricValueSource) throws IOException {\n+        super(name, context, parent, pipelineAggregators, metaData);\n+        this.sort = sort;\n+        this.metricName = metricName;\n+        this.metricValueSource = metricValueSource;\n+        if (metricValueSource != null) {\n+            values = context.bigArrays().newDoubleArray(2, false);\n+            values.fill(0, values.size(), Double.NaN);\n+        }\n+    }\n+\n+    @Override\n+    public ScoreMode scoreMode() {\n+        boolean needs = (sort != null && sort.needsScores()) || (metricValueSource != null && metricValueSource.needsScores());\n+        return needs ? ScoreMode.COMPLETE : ScoreMode.COMPLETE_NO_SCORES;\n+    }\n+\n+    @Override\n+    public LeafBucketCollector getLeafCollector(LeafReaderContext ctx, LeafBucketCollector sub) throws IOException {\n+        assert sub == LeafBucketCollector.NO_OP_COLLECTOR : \"Expected noop but was \" + sub.toString();\n+\n+        if (metricValueSource == null) {\n+            return LeafBucketCollector.NO_OP_COLLECTOR;\n+        }\n+        BucketedSort.Leaf leafSort = sort.forLeaf(ctx);\n+        // TODO allow configuration of value mode\n+        NumericDoubleValues metricValues = MultiValueMode.AVG.select(metricValueSource.doubleValues(ctx));\n+\n+        return new LeafBucketCollector() { // TODO do we need to extend *Base*? It doesn't look like we use it.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e846862865a20ecb3594508cdcab7acbdcc4be37"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzYxMTA4NA==", "bodyText": "This is much cleaner, thanks for rewiring it to send the SortValue (despite making that class comparatively a lot larger b/c of all the serialization)", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373611084", "createdAt": "2020-01-31T18:05:53Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregator.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.Scorable;\n+import org.apache.lucene.search.ScoreMode;\n+import org.elasticsearch.common.lease.Releasables;\n+import org.elasticsearch.common.util.DoubleArray;\n+import org.elasticsearch.index.fielddata.NumericDoubleValues;\n+import org.elasticsearch.search.MultiValueMode;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.elasticsearch.search.aggregations.metrics.MetricsAggregator;\n+import org.elasticsearch.search.aggregations.metrics.NumericMetricsAggregator;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.ValuesSource;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.search.sort.BucketedSort;\n+import org.elasticsearch.search.sort.SortValue;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * Collects the {@code top_metrics} aggregation.\n+ *\n+ * This extends {@linkplain NumericMetricsAggregator.MultiValue} as a compromise\n+ * to allow sorting on the metric. Right now it only collects a single metric\n+ * but we expect it to collect a list of them in the future. Also in the future\n+ * we expect it to allow collecting non-string metrics which'll change how we\n+ * do the inheritance. Finally, we also expect it to allow collecting more than\n+ * one document worth of metrics. Once that happens we'll need to come up with\n+ * some way to pick which document's metrics to use for the sort.\n+ */\n+class TopMetricsAggregator extends MetricsAggregator {\n+    private final BucketedSort sort;\n+    private final String metricName;\n+    private final ValuesSource.Numeric metricValueSource;\n+    private DoubleArray values;\n+\n+    TopMetricsAggregator(String name, SearchContext context, Aggregator parent, List<PipelineAggregator> pipelineAggregators,\n+            Map<String, Object> metaData, BucketedSort sort,\n+            String metricName, ValuesSource.Numeric metricValueSource) throws IOException {\n+        super(name, context, parent, pipelineAggregators, metaData);\n+        this.sort = sort;\n+        this.metricName = metricName;\n+        this.metricValueSource = metricValueSource;\n+        if (metricValueSource != null) {\n+            values = context.bigArrays().newDoubleArray(2, false);\n+            values.fill(0, values.size(), Double.NaN);\n+        }\n+    }\n+\n+    @Override\n+    public ScoreMode scoreMode() {\n+        boolean needs = (sort != null && sort.needsScores()) || (metricValueSource != null && metricValueSource.needsScores());\n+        return needs ? ScoreMode.COMPLETE : ScoreMode.COMPLETE_NO_SCORES;\n+    }\n+\n+    @Override\n+    public LeafBucketCollector getLeafCollector(LeafReaderContext ctx, LeafBucketCollector sub) throws IOException {\n+        assert sub == LeafBucketCollector.NO_OP_COLLECTOR : \"Expected noop but was \" + sub.toString();\n+\n+        if (metricValueSource == null) {\n+            return LeafBucketCollector.NO_OP_COLLECTOR;\n+        }\n+        BucketedSort.Leaf leafSort = sort.forLeaf(ctx);\n+        // TODO allow configuration of value mode\n+        NumericDoubleValues metricValues = MultiValueMode.AVG.select(metricValueSource.doubleValues(ctx));\n+\n+        return new LeafBucketCollector() { // TODO do we need to extend *Base*? It doesn't look like we use it.\n+            @Override\n+            public void collect(int doc, long bucket) throws IOException {\n+                if (leafSort.collectIfCompetitive(doc, bucket)) {\n+                    if (bucket >= values.size()) {\n+                        long oldSize = values.size();\n+                        values = context.bigArrays().grow(values, bucket + 1);\n+                        values.fill(oldSize, values.size(), Double.NaN);\n+                    }\n+                    double metricValue = metricValues.advanceExact(doc) ? metricValues.doubleValue() : Double.NaN; \n+                    values.set(bucket, metricValue);\n+                }\n+            }\n+\n+            @Override\n+            public void setScorer(Scorable s) throws IOException {\n+                leafSort.setScorer(s);\n+            }\n+        };\n+    }\n+\n+    @Override\n+    public InternalAggregation buildAggregation(long bucket) throws IOException {\n+        if (metricValueSource == null) {\n+            return buildEmptyAggregation();\n+        }\n+        double metricValue = values.get(bucket);\n+        SortValue sortValue = sort.getValue(bucket);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e846862865a20ecb3594508cdcab7acbdcc4be37"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzYxMjUwNA==", "bodyText": "I'm not sure tbh.  I'm inclined to say that since top_metrics is the only consumer at the moment, the current testing is sufficient.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373612504", "createdAt": "2020-01-31T18:09:22Z", "author": {"login": "polyfractal"}, "path": "modules/mapper-extras/src/main/java/org/elasticsearch/index/mapper/ScaledFloatFieldMapper.java", "diffHunk": "@@ -522,6 +525,12 @@ public SortField sortField(@Nullable Object missingValue, MultiValueMode sortMod\n             return new SortField(getFieldName(), source, reverse);\n         }\n \n+        @Override\n+        public BucketedSort newBucketedSort(BigArrays bigArrays, Object missingValue, MultiValueMode sortMode, Nested nested,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU4OTU5MA=="}, "originalCommit": {"oid": "c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c"}, "originalPosition": 22}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "af3fe9d7ee440a28adbb550ba18b5ad82641522e", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/af3fe9d7ee440a28adbb550ba18b5ad82641522e", "committedDate": "2020-01-31T18:39:02Z", "message": "Merge branch 'master' into top_metrics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "05c64643c578120ec405e68101a0b3cd2ef3c0fd", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/05c64643c578120ec405e68101a0b3cd2ef3c0fd", "committedDate": "2020-01-31T21:36:52Z", "message": "WIP"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0a9e3cce0dec822789217873325367fd2ec18683", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/0a9e3cce0dec822789217873325367fd2ec18683", "committedDate": "2020-01-31T21:37:08Z", "message": "Merge branch 'master' into top_metrics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "36eb495a894077c852bb35ce9c65e68d3687ead8", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/36eb495a894077c852bb35ce9c65e68d3687ead8", "committedDate": "2020-01-31T21:43:41Z", "message": "Fixup casting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "290cc279154b5850946cb7c6089b574400b78855", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/290cc279154b5850946cb7c6089b574400b78855", "committedDate": "2020-01-31T21:59:58Z", "message": "Cleanup"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6dbc02b7398d28d19504de7ce5138753ee000fe6", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/6dbc02b7398d28d19504de7ce5138753ee000fe6", "committedDate": "2020-02-03T12:55:07Z", "message": "Drop out of date comment"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5902e6c3871073de21fe04e16422b465a3335d87", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/5902e6c3871073de21fe04e16422b465a3335d87", "committedDate": "2020-02-03T13:04:38Z", "message": "Merge branch 'master' into top_metrics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ca3acf20d65175d5706f1bfbd9e1f545bb9213a6", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/ca3acf20d65175d5706f1bfbd9e1f545bb9213a6", "committedDate": "2020-02-03T14:24:29Z", "message": "Update docs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1fc6a2a86b38aac74ac1e853db18fcaf2bf1efec", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/1fc6a2a86b38aac74ac1e853db18fcaf2bf1efec", "committedDate": "2020-02-03T15:24:08Z", "message": "numeric_type examples"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a06ca3c2c05afed4e6db1fffe9b192646dca544f", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/a06ca3c2c05afed4e6db1fffe9b192646dca544f", "committedDate": "2020-02-04T15:02:06Z", "message": "Merge branch 'master' into top_metrics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7762c4fce9fa8cba24500614a9e2878053c51944", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/7762c4fce9fa8cba24500614a9e2878053c51944", "committedDate": "2020-02-04T20:44:02Z", "message": "Ooops"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0b7871595b15779b36d0e154f7b9f32205a25d2a", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/0b7871595b15779b36d0e154f7b9f32205a25d2a", "committedDate": "2020-02-04T21:49:30Z", "message": "Implement sorting by top_metrics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ea2e9974cef8da15804382d1f84764094aa50c48", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/ea2e9974cef8da15804382d1f84764094aa50c48", "committedDate": "2020-02-05T13:19:22Z", "message": "Better shuffle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bdd067631a18f196185d709392ebd205082ffd84", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/bdd067631a18f196185d709392ebd205082ffd84", "committedDate": "2020-02-05T14:51:46Z", "message": "Checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "09d969b297eb94a58a6eaeae26a48566edb4e32a", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/09d969b297eb94a58a6eaeae26a48566edb4e32a", "committedDate": "2020-02-05T14:54:25Z", "message": "Merge branch 'master' into top_metrics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d7429b6c556550600b4d5df79b38154b8d5720af", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/d7429b6c556550600b4d5df79b38154b8d5720af", "committedDate": "2020-02-05T17:21:02Z", "message": "Merge branch 'master' into top_metrics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d1b90e2bc0a4d875bd9220879d3003f2a005ac3d", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/d1b90e2bc0a4d875bd9220879d3003f2a005ac3d", "committedDate": "2020-02-05T19:25:45Z", "message": "Merge branch 'master' into top_metrics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c7b63177a8fc891b98d287360997652031e9e96a", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/c7b63177a8fc891b98d287360997652031e9e96a", "committedDate": "2020-02-05T21:36:37Z", "message": "Docs and test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ba6e21f7f50bab21d13eb382f7438c0fd0173602", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/ba6e21f7f50bab21d13eb382f7438c0fd0173602", "committedDate": "2020-02-05T21:47:29Z", "message": "Tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fdada3cf70cadb43e1155ec11acd6d24e05c649f", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/fdada3cf70cadb43e1155ec11acd6d24e05c649f", "committedDate": "2020-02-05T23:43:33Z", "message": "Merge branch 'master' into top_metrics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e47d6c64dc775912f8bce25d91ea0770df4171aa", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/e47d6c64dc775912f8bce25d91ea0770df4171aa", "committedDate": "2020-02-10T18:54:43Z", "message": "Merge branch 'master' into top_metrics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "abfc012a779540d95290f32fd1b05a97a6efd6a1", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/abfc012a779540d95290f32fd1b05a97a6efd6a1", "committedDate": "2020-02-10T18:55:57Z", "message": "Fix javadoc"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "03ff2b5cec336200738e37823829587cf93be0e3", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/03ff2b5cec336200738e37823829587cf93be0e3", "committedDate": "2020-02-10T19:02:01Z", "message": "Javadoc"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "04c2fcd4fd6fe888e906e2db54f4b44151a32f00", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/04c2fcd4fd6fe888e906e2db54f4b44151a32f00", "committedDate": "2020-02-11T18:02:04Z", "message": "Merge!"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9752139c9eb0ae4ddb6da39037e2233617159c82", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/9752139c9eb0ae4ddb6da39037e2233617159c82", "committedDate": "2020-02-11T18:20:40Z", "message": "Merge branch 'master' into top_metrics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4240a53a62f9ad891982aa6791b07b889c26836f", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/4240a53a62f9ad891982aa6791b07b889c26836f", "committedDate": "2020-02-11T20:53:39Z", "message": "Merge branch 'master' into top_metrics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ca6e52d6fc9ed17e0176546ed9d84edf7cd5c149", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/ca6e52d6fc9ed17e0176546ed9d84edf7cd5c149", "committedDate": "2020-02-11T20:59:34Z", "message": "Test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "792da85be72714f486271336b49948e797c6d850", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/792da85be72714f486271336b49948e797c6d850", "committedDate": "2020-02-13T13:04:47Z", "message": "Merge branch 'master' into top_metrics"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU4NDU3NDM1", "url": "https://github.com/elastic/elasticsearch/pull/51155#pullrequestreview-358457435", "createdAt": "2020-02-13T18:37:51Z", "commit": {"oid": "792da85be72714f486271336b49948e797c6d850"}, "state": "APPROVED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QxODozNzo1MVrOFpfGNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QxODo1MjozMlrOFpfkVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTA0NTQzMA==", "bodyText": "Should we mention this is an implementation detail so that we feel free to change this behavior in the future?", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r379045430", "createdAt": "2020-02-13T18:37:51Z", "author": {"login": "jpountz"}, "path": "docs/reference/aggregations/metrics/top-metrics-aggregation.asciidoc", "diffHunk": "@@ -0,0 +1,281 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[[search-aggregations-metrics-top-metrics]]\n+=== Top Metrics Aggregation\n+\n+experimental[We expect to change the response format of this aggregation as we add more features., https://github.com/elastic/elasticsearch/issues/51813]\n+\n+The `top_metrics` aggregation selects metrics from the document with the largest or smallest \"sort\"\n+value. For example, This gets the value of the `v` field on the document with the largest value of `s`:\n+\n+[source,console,id=search-aggregations-metrics-top-metrics-simple]\n+----\n+POST /test/_bulk?refresh\n+{\"index\": {}}\n+{\"s\": 1, \"v\": 3.1415}\n+{\"index\": {}}\n+{\"s\": 2, \"v\": 1}\n+{\"index\": {}}\n+{\"s\": 3, \"v\": 2.71828}\n+POST /test/_search?filter_path=aggregations\n+{\n+  \"aggs\": {\n+    \"tm\": {\n+      \"top_metrics\": {\n+        \"metric\": {\"field\": \"v\"},\n+        \"sort\": {\"s\": \"desc\"}\n+      }\n+    }\n+  }\n+}\n+----\n+\n+Which returns:\n+\n+[source,js]\n+----\n+{\n+  \"aggregations\": {\n+    \"tm\": {\n+      \"top\": [ {\"sort\": [3], \"metrics\": {\"v\": 2.718280076980591 } } ]\n+    }\n+  }\n+}\n+----\n+// TESTRESPONSE\n+\n+`top_metrics` is fairly similar to <<search-aggregations-metrics-top-hits-aggregation, `top_hits`>>\n+in spirit but because it is more limited it is able to do its job using less memory and is often\n+faster.\n+\n+==== `sort`\n+\n+The `sort` field in the metric request functions exactly the same as the `sort` field in the\n+<<request-body-search-sort, search>> request except:\n+* It can't be used on <<binary,binary>>, <<flattened,flattened>, <<ip,ip>>,\n+<<keyword,keyword>>, or <<text,text>> fields.\n+* It only supports a single sort value.\n+\n+The metrics that the aggregation returns is the first hit that would be returned by the search\n+request. So,\n+\n+`\"sort\": {\"s\": \"desc\"}`:: gets metrics from the document with the highest `s`\n+`\"sort\": {\"s\": \"asc\"}`:: gets the metrics from the document with the lowest `s`\n+`\"sort\": {\"_geo_distance\": {\"location\": \"35.7796, -78.6382\"}}`::\n+  gets metrics from the documents with `location` *closest* to `35.7796, -78.6382`\n+`\"sort\": \"_score\"`:: gets metrics from the document with the highest score\n+\n+==== `metric`\n+\n+At this point `metric` supports only `{\"field\": \"field_name\"}` and all metrics\n+are returned as double precision floating point numbers. Expect more to\n+come here.\n+\n+==== Examples\n+\n+===== Use with terms\n+\n+This aggregation should be quite useful inside of <<search-aggregations-bucket-terms-aggregation, `terms`>>\n+aggregation, to, say, find the last value reported by each server.\n+\n+[source,console,id=search-aggregations-metrics-top-metrics-terms]\n+----\n+PUT /node\n+{\n+  \"mappings\": {\n+    \"properties\": {\n+      \"ip\": {\"type\": \"ip\"},\n+      \"date\": {\"type\": \"date\"}\n+    }\n+  }\n+}\n+POST /node/_bulk?refresh\n+{\"index\": {}}\n+{\"ip\": \"192.168.0.1\", \"date\": \"2020-01-01T01:01:01\", \"v\": 1}\n+{\"index\": {}}\n+{\"ip\": \"192.168.0.1\", \"date\": \"2020-01-01T02:01:01\", \"v\": 2}\n+{\"index\": {}}\n+{\"ip\": \"192.168.0.2\", \"date\": \"2020-01-01T02:01:01\", \"v\": 3}\n+POST /node/_search?filter_path=aggregations\n+{\n+  \"aggs\": {\n+    \"ip\": {\n+      \"terms\": {\n+        \"field\": \"ip\"\n+      },\n+      \"aggs\": {\n+        \"tm\": {\n+          \"top_metrics\": {\n+            \"metric\": {\"field\": \"v\"},\n+            \"sort\": {\"date\": \"desc\"}\n+          }\n+        }\n+      }\n+    }\n+  }\n+}\n+----\n+\n+Which returns:\n+\n+[source,js]\n+----\n+{\n+  \"aggregations\": {\n+    \"ip\": {\n+      \"buckets\": [\n+        {\n+          \"key\": \"192.168.0.1\",\n+          \"doc_count\": 2,\n+          \"tm\": {\n+            \"top\": [ {\"sort\": [\"2020-01-01T02:01:01.000Z\"], \"metrics\": {\"v\": 2.0 } } ]\n+          }\n+        },\n+        {\n+          \"key\": \"192.168.0.2\",\n+          \"doc_count\": 1,\n+          \"tm\": {\n+            \"top\": [ {\"sort\": [\"2020-01-01T02:01:01.000Z\"], \"metrics\": {\"v\": 3.0 } } ]\n+          }\n+        }\n+      ],\n+      \"doc_count_error_upper_bound\": 0,\n+      \"sum_other_doc_count\": 0\n+    }\n+  }\n+}\n+----\n+// TESTRESPONSE\n+\n+Unlike `top_hits`, you can sort buckets by the results of this metric:\n+\n+[source,console]\n+----\n+POST /node/_search?filter_path=aggregations\n+{\n+  \"aggs\": {\n+    \"ip\": {\n+      \"terms\": {\n+        \"field\": \"ip\",\n+        \"order\": {\"tm.v\": \"desc\"}\n+      },\n+      \"aggs\": {\n+        \"tm\": {\n+          \"top_metrics\": {\n+            \"metric\": {\"field\": \"v\"},\n+            \"sort\": {\"date\": \"desc\"}\n+          }\n+        }\n+      }\n+    }\n+  }\n+}\n+----\n+// TEST[continued]\n+\n+Which returns:\n+\n+[source,js]\n+----\n+{\n+  \"aggregations\": {\n+    \"ip\": {\n+      \"buckets\": [\n+        {\n+          \"key\": \"192.168.0.2\",\n+          \"doc_count\": 1,\n+          \"tm\": {\n+            \"top\": [ {\"sort\": [\"2020-01-01T02:01:01.000Z\"], \"metrics\": {\"v\": 3.0 } } ]\n+          }\n+        },\n+        {\n+          \"key\": \"192.168.0.1\",\n+          \"doc_count\": 2,\n+          \"tm\": {\n+            \"top\": [ {\"sort\": [\"2020-01-01T02:01:01.000Z\"], \"metrics\": {\"v\": 2.0 } } ]\n+          }\n+        }\n+      ],\n+      \"doc_count_error_upper_bound\": 0,\n+      \"sum_other_doc_count\": 0\n+    }\n+  }\n+}\n+----\n+// TESTRESPONSE\n+\n+===== Mixed sort types\n+\n+Sorting `top_metrics` by a field that has different types across different\n+indices producs somewhat suprising results: floating point fields are\n+always sorted *before* whole number fields.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "792da85be72714f486271336b49948e797c6d850"}, "originalPosition": 211}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTA0NjMxNg==", "bodyText": "When mixing floats and integers, wouldn't users more often want to cast integers to floats, which is a lossless conversion for small integers?", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r379046316", "createdAt": "2020-02-13T18:39:34Z", "author": {"login": "jpountz"}, "path": "docs/reference/aggregations/metrics/top-metrics-aggregation.asciidoc", "diffHunk": "@@ -0,0 +1,281 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[[search-aggregations-metrics-top-metrics]]\n+=== Top Metrics Aggregation\n+\n+experimental[We expect to change the response format of this aggregation as we add more features., https://github.com/elastic/elasticsearch/issues/51813]\n+\n+The `top_metrics` aggregation selects metrics from the document with the largest or smallest \"sort\"\n+value. For example, This gets the value of the `v` field on the document with the largest value of `s`:\n+\n+[source,console,id=search-aggregations-metrics-top-metrics-simple]\n+----\n+POST /test/_bulk?refresh\n+{\"index\": {}}\n+{\"s\": 1, \"v\": 3.1415}\n+{\"index\": {}}\n+{\"s\": 2, \"v\": 1}\n+{\"index\": {}}\n+{\"s\": 3, \"v\": 2.71828}\n+POST /test/_search?filter_path=aggregations\n+{\n+  \"aggs\": {\n+    \"tm\": {\n+      \"top_metrics\": {\n+        \"metric\": {\"field\": \"v\"},\n+        \"sort\": {\"s\": \"desc\"}\n+      }\n+    }\n+  }\n+}\n+----\n+\n+Which returns:\n+\n+[source,js]\n+----\n+{\n+  \"aggregations\": {\n+    \"tm\": {\n+      \"top\": [ {\"sort\": [3], \"metrics\": {\"v\": 2.718280076980591 } } ]\n+    }\n+  }\n+}\n+----\n+// TESTRESPONSE\n+\n+`top_metrics` is fairly similar to <<search-aggregations-metrics-top-hits-aggregation, `top_hits`>>\n+in spirit but because it is more limited it is able to do its job using less memory and is often\n+faster.\n+\n+==== `sort`\n+\n+The `sort` field in the metric request functions exactly the same as the `sort` field in the\n+<<request-body-search-sort, search>> request except:\n+* It can't be used on <<binary,binary>>, <<flattened,flattened>, <<ip,ip>>,\n+<<keyword,keyword>>, or <<text,text>> fields.\n+* It only supports a single sort value.\n+\n+The metrics that the aggregation returns is the first hit that would be returned by the search\n+request. So,\n+\n+`\"sort\": {\"s\": \"desc\"}`:: gets metrics from the document with the highest `s`\n+`\"sort\": {\"s\": \"asc\"}`:: gets the metrics from the document with the lowest `s`\n+`\"sort\": {\"_geo_distance\": {\"location\": \"35.7796, -78.6382\"}}`::\n+  gets metrics from the documents with `location` *closest* to `35.7796, -78.6382`\n+`\"sort\": \"_score\"`:: gets metrics from the document with the highest score\n+\n+==== `metric`\n+\n+At this point `metric` supports only `{\"field\": \"field_name\"}` and all metrics\n+are returned as double precision floating point numbers. Expect more to\n+come here.\n+\n+==== Examples\n+\n+===== Use with terms\n+\n+This aggregation should be quite useful inside of <<search-aggregations-bucket-terms-aggregation, `terms`>>\n+aggregation, to, say, find the last value reported by each server.\n+\n+[source,console,id=search-aggregations-metrics-top-metrics-terms]\n+----\n+PUT /node\n+{\n+  \"mappings\": {\n+    \"properties\": {\n+      \"ip\": {\"type\": \"ip\"},\n+      \"date\": {\"type\": \"date\"}\n+    }\n+  }\n+}\n+POST /node/_bulk?refresh\n+{\"index\": {}}\n+{\"ip\": \"192.168.0.1\", \"date\": \"2020-01-01T01:01:01\", \"v\": 1}\n+{\"index\": {}}\n+{\"ip\": \"192.168.0.1\", \"date\": \"2020-01-01T02:01:01\", \"v\": 2}\n+{\"index\": {}}\n+{\"ip\": \"192.168.0.2\", \"date\": \"2020-01-01T02:01:01\", \"v\": 3}\n+POST /node/_search?filter_path=aggregations\n+{\n+  \"aggs\": {\n+    \"ip\": {\n+      \"terms\": {\n+        \"field\": \"ip\"\n+      },\n+      \"aggs\": {\n+        \"tm\": {\n+          \"top_metrics\": {\n+            \"metric\": {\"field\": \"v\"},\n+            \"sort\": {\"date\": \"desc\"}\n+          }\n+        }\n+      }\n+    }\n+  }\n+}\n+----\n+\n+Which returns:\n+\n+[source,js]\n+----\n+{\n+  \"aggregations\": {\n+    \"ip\": {\n+      \"buckets\": [\n+        {\n+          \"key\": \"192.168.0.1\",\n+          \"doc_count\": 2,\n+          \"tm\": {\n+            \"top\": [ {\"sort\": [\"2020-01-01T02:01:01.000Z\"], \"metrics\": {\"v\": 2.0 } } ]\n+          }\n+        },\n+        {\n+          \"key\": \"192.168.0.2\",\n+          \"doc_count\": 1,\n+          \"tm\": {\n+            \"top\": [ {\"sort\": [\"2020-01-01T02:01:01.000Z\"], \"metrics\": {\"v\": 3.0 } } ]\n+          }\n+        }\n+      ],\n+      \"doc_count_error_upper_bound\": 0,\n+      \"sum_other_doc_count\": 0\n+    }\n+  }\n+}\n+----\n+// TESTRESPONSE\n+\n+Unlike `top_hits`, you can sort buckets by the results of this metric:\n+\n+[source,console]\n+----\n+POST /node/_search?filter_path=aggregations\n+{\n+  \"aggs\": {\n+    \"ip\": {\n+      \"terms\": {\n+        \"field\": \"ip\",\n+        \"order\": {\"tm.v\": \"desc\"}\n+      },\n+      \"aggs\": {\n+        \"tm\": {\n+          \"top_metrics\": {\n+            \"metric\": {\"field\": \"v\"},\n+            \"sort\": {\"date\": \"desc\"}\n+          }\n+        }\n+      }\n+    }\n+  }\n+}\n+----\n+// TEST[continued]\n+\n+Which returns:\n+\n+[source,js]\n+----\n+{\n+  \"aggregations\": {\n+    \"ip\": {\n+      \"buckets\": [\n+        {\n+          \"key\": \"192.168.0.2\",\n+          \"doc_count\": 1,\n+          \"tm\": {\n+            \"top\": [ {\"sort\": [\"2020-01-01T02:01:01.000Z\"], \"metrics\": {\"v\": 3.0 } } ]\n+          }\n+        },\n+        {\n+          \"key\": \"192.168.0.1\",\n+          \"doc_count\": 2,\n+          \"tm\": {\n+            \"top\": [ {\"sort\": [\"2020-01-01T02:01:01.000Z\"], \"metrics\": {\"v\": 2.0 } } ]\n+          }\n+        }\n+      ],\n+      \"doc_count_error_upper_bound\": 0,\n+      \"sum_other_doc_count\": 0\n+    }\n+  }\n+}\n+----\n+// TESTRESPONSE\n+\n+===== Mixed sort types\n+\n+Sorting `top_metrics` by a field that has different types across different\n+indices producs somewhat suprising results: floating point fields are\n+always sorted *before* whole number fields.\n+\n+[source,console,id=search-aggregations-metrics-top-metrics-mixed-sort]\n+----\n+POST /test/_bulk?refresh\n+{\"index\": {\"_index\": \"test1\"}}\n+{\"s\": 1, \"v\": 3.1415}\n+{\"index\": {\"_index\": \"test1\"}}\n+{\"s\": 2, \"v\": 1}\n+{\"index\": {\"_index\": \"test2\"}}\n+{\"s\": 3.1, \"v\": 2.71828}\n+POST /test*/_search?filter_path=aggregations\n+{\n+  \"aggs\": {\n+    \"tm\": {\n+      \"top_metrics\": {\n+        \"metric\": {\"field\": \"v\"},\n+        \"sort\": {\"s\": \"asc\"}\n+      }\n+    }\n+  }\n+}\n+----\n+\n+Which returns:\n+\n+[source,js]\n+----\n+{\n+  \"aggregations\": {\n+    \"tm\": {\n+      \"top\": [ {\"sort\": [3.0999999046325684], \"metrics\": {\"v\": 2.718280076980591 } } ]\n+    }\n+  }\n+}\n+----\n+// TESTRESPONSE\n+\n+While this is better than an error it *probably* isn't what you were going for.\n+You can explictly cast the floating point fields to integers or the way around", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "792da85be72714f486271336b49948e797c6d850"}, "originalPosition": 250}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTA0NzA0Mg==", "bodyText": "Can we add more information to this error message, e.g. index name, field name, field type?", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r379047042", "createdAt": "2020-02-13T18:40:59Z", "author": {"login": "jpountz"}, "path": "server/src/main/java/org/elasticsearch/index/fielddata/fieldcomparator/BytesRefFieldComparatorSource.java", "diffHunk": "@@ -135,6 +139,11 @@ public void setScorer(Scorable scorer) {\n         };\n     }\n \n+    @Override\n+    public BucketedSort newBucketedSort(BigArrays bigArrays, SortOrder sortOrder, DocValueFormat format) {\n+        throw new IllegalArgumentException(\"only supported on numeric values\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "792da85be72714f486271336b49948e797c6d850"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTA0Nzc2NQ==", "bodyText": "This comment might be embarassing if it is still here in 10 years :)", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r379047765", "createdAt": "2020-02-13T18:42:23Z", "author": {"login": "jpountz"}, "path": "docs/reference/aggregations/metrics/top-metrics-aggregation.asciidoc", "diffHunk": "@@ -0,0 +1,281 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[[search-aggregations-metrics-top-metrics]]\n+=== Top Metrics Aggregation\n+\n+experimental[We expect to change the response format of this aggregation as we add more features., https://github.com/elastic/elasticsearch/issues/51813]\n+\n+The `top_metrics` aggregation selects metrics from the document with the largest or smallest \"sort\"\n+value. For example, This gets the value of the `v` field on the document with the largest value of `s`:\n+\n+[source,console,id=search-aggregations-metrics-top-metrics-simple]\n+----\n+POST /test/_bulk?refresh\n+{\"index\": {}}\n+{\"s\": 1, \"v\": 3.1415}\n+{\"index\": {}}\n+{\"s\": 2, \"v\": 1}\n+{\"index\": {}}\n+{\"s\": 3, \"v\": 2.71828}\n+POST /test/_search?filter_path=aggregations\n+{\n+  \"aggs\": {\n+    \"tm\": {\n+      \"top_metrics\": {\n+        \"metric\": {\"field\": \"v\"},\n+        \"sort\": {\"s\": \"desc\"}\n+      }\n+    }\n+  }\n+}\n+----\n+\n+Which returns:\n+\n+[source,js]\n+----\n+{\n+  \"aggregations\": {\n+    \"tm\": {\n+      \"top\": [ {\"sort\": [3], \"metrics\": {\"v\": 2.718280076980591 } } ]\n+    }\n+  }\n+}\n+----\n+// TESTRESPONSE\n+\n+`top_metrics` is fairly similar to <<search-aggregations-metrics-top-hits-aggregation, `top_hits`>>\n+in spirit but because it is more limited it is able to do its job using less memory and is often\n+faster.\n+\n+==== `sort`\n+\n+The `sort` field in the metric request functions exactly the same as the `sort` field in the\n+<<request-body-search-sort, search>> request except:\n+* It can't be used on <<binary,binary>>, <<flattened,flattened>, <<ip,ip>>,\n+<<keyword,keyword>>, or <<text,text>> fields.\n+* It only supports a single sort value.\n+\n+The metrics that the aggregation returns is the first hit that would be returned by the search\n+request. So,\n+\n+`\"sort\": {\"s\": \"desc\"}`:: gets metrics from the document with the highest `s`\n+`\"sort\": {\"s\": \"asc\"}`:: gets the metrics from the document with the lowest `s`\n+`\"sort\": {\"_geo_distance\": {\"location\": \"35.7796, -78.6382\"}}`::\n+  gets metrics from the documents with `location` *closest* to `35.7796, -78.6382`\n+`\"sort\": \"_score\"`:: gets metrics from the document with the highest score\n+\n+==== `metric`\n+\n+At this point `metric` supports only `{\"field\": \"field_name\"}` and all metrics\n+are returned as double precision floating point numbers. Expect more to\n+come here.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "792da85be72714f486271336b49948e797c6d850"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTA0ODAyOQ==", "bodyText": "I'm not seeing anything about ties, which I expect is something users will wonder?", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r379048029", "createdAt": "2020-02-13T18:42:56Z", "author": {"login": "jpountz"}, "path": "docs/reference/aggregations/metrics/top-metrics-aggregation.asciidoc", "diffHunk": "@@ -0,0 +1,281 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[[search-aggregations-metrics-top-metrics]]\n+=== Top Metrics Aggregation\n+\n+experimental[We expect to change the response format of this aggregation as we add more features., https://github.com/elastic/elasticsearch/issues/51813]\n+\n+The `top_metrics` aggregation selects metrics from the document with the largest or smallest \"sort\"\n+value. For example, This gets the value of the `v` field on the document with the largest value of `s`:\n+\n+[source,console,id=search-aggregations-metrics-top-metrics-simple]\n+----\n+POST /test/_bulk?refresh\n+{\"index\": {}}\n+{\"s\": 1, \"v\": 3.1415}\n+{\"index\": {}}\n+{\"s\": 2, \"v\": 1}\n+{\"index\": {}}\n+{\"s\": 3, \"v\": 2.71828}\n+POST /test/_search?filter_path=aggregations\n+{\n+  \"aggs\": {\n+    \"tm\": {\n+      \"top_metrics\": {\n+        \"metric\": {\"field\": \"v\"},\n+        \"sort\": {\"s\": \"desc\"}\n+      }\n+    }\n+  }\n+}\n+----\n+\n+Which returns:\n+\n+[source,js]\n+----\n+{\n+  \"aggregations\": {\n+    \"tm\": {\n+      \"top\": [ {\"sort\": [3], \"metrics\": {\"v\": 2.718280076980591 } } ]\n+    }\n+  }\n+}\n+----\n+// TESTRESPONSE\n+\n+`top_metrics` is fairly similar to <<search-aggregations-metrics-top-hits-aggregation, `top_hits`>>\n+in spirit but because it is more limited it is able to do its job using less memory and is often\n+faster.\n+\n+==== `sort`\n+\n+The `sort` field in the metric request functions exactly the same as the `sort` field in the\n+<<request-body-search-sort, search>> request except:\n+* It can't be used on <<binary,binary>>, <<flattened,flattened>, <<ip,ip>>,\n+<<keyword,keyword>>, or <<text,text>> fields.\n+* It only supports a single sort value.\n+\n+The metrics that the aggregation returns is the first hit that would be returned by the search\n+request. So,\n+\n+`\"sort\": {\"s\": \"desc\"}`:: gets metrics from the document with the highest `s`\n+`\"sort\": {\"s\": \"asc\"}`:: gets the metrics from the document with the lowest `s`\n+`\"sort\": {\"_geo_distance\": {\"location\": \"35.7796, -78.6382\"}}`::\n+  gets metrics from the documents with `location` *closest* to `35.7796, -78.6382`\n+`\"sort\": \"_score\"`:: gets metrics from the document with the highest score\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "792da85be72714f486271336b49948e797c6d850"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTA1MzE0MQ==", "bodyText": "Please ignore if this would make the API horrible due to the need to propagate the required information.", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r379053141", "createdAt": "2020-02-13T18:52:32Z", "author": {"login": "jpountz"}, "path": "server/src/main/java/org/elasticsearch/index/fielddata/fieldcomparator/BytesRefFieldComparatorSource.java", "diffHunk": "@@ -135,6 +139,11 @@ public void setScorer(Scorable scorer) {\n         };\n     }\n \n+    @Override\n+    public BucketedSort newBucketedSort(BigArrays bigArrays, SortOrder sortOrder, DocValueFormat format) {\n+        throw new IllegalArgumentException(\"only supported on numeric values\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTA0NzA0Mg=="}, "originalCommit": {"oid": "792da85be72714f486271336b49948e797c6d850"}, "originalPosition": 22}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6577077ed0a5fb4303f467426f753f51e21b57c0", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/6577077ed0a5fb4303f467426f753f51e21b57c0", "committedDate": "2020-02-13T20:56:32Z", "message": "Merge branch 'master' into top_metrics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "43c705b9342132869124105139049cc276e8048d", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/43c705b9342132869124105139049cc276e8048d", "committedDate": "2020-02-13T20:58:39Z", "message": "Merge tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5f46829bfcbd6267bd312cc177e8679aac4786e0", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/5f46829bfcbd6267bd312cc177e8679aac4786e0", "committedDate": "2020-02-13T21:03:52Z", "message": "Flip example"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2b5dca14bd82fe36972005c0b4c5fc28c20d276d", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/2b5dca14bd82fe36972005c0b4c5fc28c20d276d", "committedDate": "2020-02-13T21:20:01Z", "message": "No tie breaking"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e6fd60142e2c5aa9b89614a84543990f3a53ad6f", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/e6fd60142e2c5aa9b89614a84543990f3a53ad6f", "committedDate": "2020-02-13T22:35:49Z", "message": "Error message"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4305681bcf46f5a54d235d61da5cebc83d77c7c9", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/4305681bcf46f5a54d235d61da5cebc83d77c7c9", "committedDate": "2020-02-13T21:40:55Z", "message": "Error message"}, "afterCommit": {"oid": "e6fd60142e2c5aa9b89614a84543990f3a53ad6f", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/e6fd60142e2c5aa9b89614a84543990f3a53ad6f", "committedDate": "2020-02-13T22:35:49Z", "message": "Error message"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "134d99b842afab240c4e230f4ebc5aca7b3d9cfb", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/134d99b842afab240c4e230f4ebc5aca7b3d9cfb", "committedDate": "2020-02-13T23:37:07Z", "message": "Word"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "896e08aa33b2b1f70a8f706e4461798f7bc0b282", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/896e08aa33b2b1f70a8f706e4461798f7bc0b282", "committedDate": "2020-02-14T11:00:55Z", "message": "Another word"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2981, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}