{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA5Mzk1MTY0", "number": 55795, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QxMDo0MDowNlrOD2nKSw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QxMjoxMzo1MFrOD2piZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU4NTkxMzA3OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QxMDo0MDowNlrOGMcgnQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQwODo1MzoyM1rOGNJwtA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTcwMzE5Nw==", "bodyText": "I don't think there's a problem with the very fine-grained locking done here, but if it turns out to be a bottleneck then we can instead lock larger chunks, maybe ~1MB or so, rather than locking for each individual call to read(). That makes it a bit more complicated since we must worry about aligning reads to the chunk size too, but it's still feasible.", "url": "https://github.com/elastic/elasticsearch/pull/55795#discussion_r415703197", "createdAt": "2020-04-27T10:40:06Z", "author": {"login": "DaveCTurner"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java", "diffHunk": "@@ -174,29 +174,130 @@ protected void readInternal(final byte[] buffer, final int offset, final int len\n     /**\n      * Prefetches a complete part and writes it in cache. This method is used to prewarm the cache.\n      */\n-    public int prefetchPart(final int part) throws IOException {\n+    public void prefetchPart(final int part) throws IOException {\n         ensureContext(ctx -> ctx == CACHE_WARMING_CONTEXT);\n         if (part >= fileInfo.numberOfParts()) {\n             throw new IllegalArgumentException(\"Unexpected part number [\" + part + \"]\");\n         }\n-        final Tuple<Long, Long> range = computeRange(IntStream.range(0, part).mapToLong(fileInfo::partBytes).sum());\n-        assert assertRangeIsAlignedWithPart(range);\n+        final Tuple<Long, Long> partRange = computeRange(IntStream.range(0, part).mapToLong(fileInfo::partBytes).sum());\n+        assert assertRangeIsAlignedWithPart(partRange);\n+\n         try {\n             final CacheFile cacheFile = getCacheFileSafe();\n             try (ReleasableLock ignored = cacheFile.fileLock()) {\n-                final int bytesRead = cacheFile.fetchRange(range.v1(), range.v2(), (start, end) -> {\n-                    logger.trace(\"range [{}-{}] of file [{}] is now available in cache\", start, end, fileInfo.physicalName());\n-                    return Math.toIntExact(end - start);\n-                }, (start, end) -> writeCacheFile(cacheFile.getChannel(), start, end)).get();\n \n-                assert bytesRead == (range.v2() - range.v1());\n-                return bytesRead;\n+                final Tuple<Long, Long> range = cacheFile.getAbsentRangeWithin(partRange.v1(), partRange.v2());\n+                if (range == null) {\n+                    logger.trace(\n+                        \"prefetchPart: part [{}] bytes [{}-{}] is already fully available for cache file [{}]\",\n+                        part,\n+                        partRange.v1(),\n+                        partRange.v2(),\n+                        cacheFileReference\n+                    );\n+                    return;\n+                }\n+\n+                final long rangeStart = range.v1();\n+                final long rangeEnd = range.v2();\n+                final long rangeLength = rangeEnd - rangeStart;\n+\n+                logger.trace(\n+                    \"prefetchPart: prewarming part [{}] bytes [{}-{}] by fetching bytes [{}-{}] for cache file [{}]\",\n+                    part,\n+                    partRange.v1(),\n+                    partRange.v2(),\n+                    rangeStart,\n+                    rangeEnd,\n+                    cacheFileReference\n+                );\n+\n+                final FileChannel fc = cacheFile.getChannel();\n+                assert assertFileChannelOpen(fc);\n+                final byte[] copyBuffer = new byte[Math.toIntExact(Math.min(COPY_BUFFER_SIZE, rangeLength))];\n+\n+                long totalBytesRead = 0L;\n+                long remaining = rangeEnd - rangeStart;\n+                final long startTimeNanos = stats.currentTimeNanos();\n+                try (InputStream input = openInputStream(rangeStart, rangeLength)) {\n+                    while (remaining > 0L) {\n+                        assert totalBytesRead + remaining == rangeLength;\n+                        final int bytesRead = readSafe(input, copyBuffer, rangeStart, rangeEnd, remaining, cacheFileReference);\n+                        final long readStart = rangeStart + totalBytesRead;\n+                        cacheFile.fetchRange(readStart, readStart + bytesRead, (start, end) -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6fd6f903274cce215808bcc4b14bb2481feb2553"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTg4Njc3OA==", "bodyText": "I think this will have an impact as it introduces more things to do every COPY_BUFFER_SIZE bytes to write, but I'm not sure it will be a big impact. I'm not sure also this is something we want to optimize.\nIf we have a doubt I can spend some time to benchmark this otherwise we could maybe just add a comment in the code.", "url": "https://github.com/elastic/elasticsearch/pull/55795#discussion_r415886778", "createdAt": "2020-04-27T14:58:24Z", "author": {"login": "tlrx"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java", "diffHunk": "@@ -174,29 +174,130 @@ protected void readInternal(final byte[] buffer, final int offset, final int len\n     /**\n      * Prefetches a complete part and writes it in cache. This method is used to prewarm the cache.\n      */\n-    public int prefetchPart(final int part) throws IOException {\n+    public void prefetchPart(final int part) throws IOException {\n         ensureContext(ctx -> ctx == CACHE_WARMING_CONTEXT);\n         if (part >= fileInfo.numberOfParts()) {\n             throw new IllegalArgumentException(\"Unexpected part number [\" + part + \"]\");\n         }\n-        final Tuple<Long, Long> range = computeRange(IntStream.range(0, part).mapToLong(fileInfo::partBytes).sum());\n-        assert assertRangeIsAlignedWithPart(range);\n+        final Tuple<Long, Long> partRange = computeRange(IntStream.range(0, part).mapToLong(fileInfo::partBytes).sum());\n+        assert assertRangeIsAlignedWithPart(partRange);\n+\n         try {\n             final CacheFile cacheFile = getCacheFileSafe();\n             try (ReleasableLock ignored = cacheFile.fileLock()) {\n-                final int bytesRead = cacheFile.fetchRange(range.v1(), range.v2(), (start, end) -> {\n-                    logger.trace(\"range [{}-{}] of file [{}] is now available in cache\", start, end, fileInfo.physicalName());\n-                    return Math.toIntExact(end - start);\n-                }, (start, end) -> writeCacheFile(cacheFile.getChannel(), start, end)).get();\n \n-                assert bytesRead == (range.v2() - range.v1());\n-                return bytesRead;\n+                final Tuple<Long, Long> range = cacheFile.getAbsentRangeWithin(partRange.v1(), partRange.v2());\n+                if (range == null) {\n+                    logger.trace(\n+                        \"prefetchPart: part [{}] bytes [{}-{}] is already fully available for cache file [{}]\",\n+                        part,\n+                        partRange.v1(),\n+                        partRange.v2(),\n+                        cacheFileReference\n+                    );\n+                    return;\n+                }\n+\n+                final long rangeStart = range.v1();\n+                final long rangeEnd = range.v2();\n+                final long rangeLength = rangeEnd - rangeStart;\n+\n+                logger.trace(\n+                    \"prefetchPart: prewarming part [{}] bytes [{}-{}] by fetching bytes [{}-{}] for cache file [{}]\",\n+                    part,\n+                    partRange.v1(),\n+                    partRange.v2(),\n+                    rangeStart,\n+                    rangeEnd,\n+                    cacheFileReference\n+                );\n+\n+                final FileChannel fc = cacheFile.getChannel();\n+                assert assertFileChannelOpen(fc);\n+                final byte[] copyBuffer = new byte[Math.toIntExact(Math.min(COPY_BUFFER_SIZE, rangeLength))];\n+\n+                long totalBytesRead = 0L;\n+                long remaining = rangeEnd - rangeStart;\n+                final long startTimeNanos = stats.currentTimeNanos();\n+                try (InputStream input = openInputStream(rangeStart, rangeLength)) {\n+                    while (remaining > 0L) {\n+                        assert totalBytesRead + remaining == rangeLength;\n+                        final int bytesRead = readSafe(input, copyBuffer, rangeStart, rangeEnd, remaining, cacheFileReference);\n+                        final long readStart = rangeStart + totalBytesRead;\n+                        cacheFile.fetchRange(readStart, readStart + bytesRead, (start, end) -> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTcwMzE5Nw=="}, "originalCommit": {"oid": "6fd6f903274cce215808bcc4b14bb2481feb2553"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQ0NDU5Ng==", "bodyText": "I will leave it as-is, we'll be doing some more general benchmarking that will tell us if it needs further optimisation.", "url": "https://github.com/elastic/elasticsearch/pull/55795#discussion_r416444596", "createdAt": "2020-04-28T08:53:23Z", "author": {"login": "DaveCTurner"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java", "diffHunk": "@@ -174,29 +174,130 @@ protected void readInternal(final byte[] buffer, final int offset, final int len\n     /**\n      * Prefetches a complete part and writes it in cache. This method is used to prewarm the cache.\n      */\n-    public int prefetchPart(final int part) throws IOException {\n+    public void prefetchPart(final int part) throws IOException {\n         ensureContext(ctx -> ctx == CACHE_WARMING_CONTEXT);\n         if (part >= fileInfo.numberOfParts()) {\n             throw new IllegalArgumentException(\"Unexpected part number [\" + part + \"]\");\n         }\n-        final Tuple<Long, Long> range = computeRange(IntStream.range(0, part).mapToLong(fileInfo::partBytes).sum());\n-        assert assertRangeIsAlignedWithPart(range);\n+        final Tuple<Long, Long> partRange = computeRange(IntStream.range(0, part).mapToLong(fileInfo::partBytes).sum());\n+        assert assertRangeIsAlignedWithPart(partRange);\n+\n         try {\n             final CacheFile cacheFile = getCacheFileSafe();\n             try (ReleasableLock ignored = cacheFile.fileLock()) {\n-                final int bytesRead = cacheFile.fetchRange(range.v1(), range.v2(), (start, end) -> {\n-                    logger.trace(\"range [{}-{}] of file [{}] is now available in cache\", start, end, fileInfo.physicalName());\n-                    return Math.toIntExact(end - start);\n-                }, (start, end) -> writeCacheFile(cacheFile.getChannel(), start, end)).get();\n \n-                assert bytesRead == (range.v2() - range.v1());\n-                return bytesRead;\n+                final Tuple<Long, Long> range = cacheFile.getAbsentRangeWithin(partRange.v1(), partRange.v2());\n+                if (range == null) {\n+                    logger.trace(\n+                        \"prefetchPart: part [{}] bytes [{}-{}] is already fully available for cache file [{}]\",\n+                        part,\n+                        partRange.v1(),\n+                        partRange.v2(),\n+                        cacheFileReference\n+                    );\n+                    return;\n+                }\n+\n+                final long rangeStart = range.v1();\n+                final long rangeEnd = range.v2();\n+                final long rangeLength = rangeEnd - rangeStart;\n+\n+                logger.trace(\n+                    \"prefetchPart: prewarming part [{}] bytes [{}-{}] by fetching bytes [{}-{}] for cache file [{}]\",\n+                    part,\n+                    partRange.v1(),\n+                    partRange.v2(),\n+                    rangeStart,\n+                    rangeEnd,\n+                    cacheFileReference\n+                );\n+\n+                final FileChannel fc = cacheFile.getChannel();\n+                assert assertFileChannelOpen(fc);\n+                final byte[] copyBuffer = new byte[Math.toIntExact(Math.min(COPY_BUFFER_SIZE, rangeLength))];\n+\n+                long totalBytesRead = 0L;\n+                long remaining = rangeEnd - rangeStart;\n+                final long startTimeNanos = stats.currentTimeNanos();\n+                try (InputStream input = openInputStream(rangeStart, rangeLength)) {\n+                    while (remaining > 0L) {\n+                        assert totalBytesRead + remaining == rangeLength;\n+                        final int bytesRead = readSafe(input, copyBuffer, rangeStart, rangeEnd, remaining, cacheFileReference);\n+                        final long readStart = rangeStart + totalBytesRead;\n+                        cacheFile.fetchRange(readStart, readStart + bytesRead, (start, end) -> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTcwMzE5Nw=="}, "originalCommit": {"oid": "6fd6f903274cce215808bcc4b14bb2481feb2553"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU4NjI3MTU3OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QxMjowNjoyNVrOGMftSw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QxNDoyMToyOVrOGMlwpg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTc1NTU5NQ==", "bodyText": "Maybe remove  the \"now\" word. Technically the range might have been already available before this got called?", "url": "https://github.com/elastic/elasticsearch/pull/55795#discussion_r415755595", "createdAt": "2020-04-27T12:06:25Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java", "diffHunk": "@@ -174,29 +174,130 @@ protected void readInternal(final byte[] buffer, final int offset, final int len\n     /**\n      * Prefetches a complete part and writes it in cache. This method is used to prewarm the cache.\n      */\n-    public int prefetchPart(final int part) throws IOException {\n+    public void prefetchPart(final int part) throws IOException {\n         ensureContext(ctx -> ctx == CACHE_WARMING_CONTEXT);\n         if (part >= fileInfo.numberOfParts()) {\n             throw new IllegalArgumentException(\"Unexpected part number [\" + part + \"]\");\n         }\n-        final Tuple<Long, Long> range = computeRange(IntStream.range(0, part).mapToLong(fileInfo::partBytes).sum());\n-        assert assertRangeIsAlignedWithPart(range);\n+        final Tuple<Long, Long> partRange = computeRange(IntStream.range(0, part).mapToLong(fileInfo::partBytes).sum());\n+        assert assertRangeIsAlignedWithPart(partRange);\n+\n         try {\n             final CacheFile cacheFile = getCacheFileSafe();\n             try (ReleasableLock ignored = cacheFile.fileLock()) {\n-                final int bytesRead = cacheFile.fetchRange(range.v1(), range.v2(), (start, end) -> {\n-                    logger.trace(\"range [{}-{}] of file [{}] is now available in cache\", start, end, fileInfo.physicalName());\n-                    return Math.toIntExact(end - start);\n-                }, (start, end) -> writeCacheFile(cacheFile.getChannel(), start, end)).get();\n \n-                assert bytesRead == (range.v2() - range.v1());\n-                return bytesRead;\n+                final Tuple<Long, Long> range = cacheFile.getAbsentRangeWithin(partRange.v1(), partRange.v2());\n+                if (range == null) {\n+                    logger.trace(\n+                        \"prefetchPart: part [{}] bytes [{}-{}] is already fully available for cache file [{}]\",\n+                        part,\n+                        partRange.v1(),\n+                        partRange.v2(),\n+                        cacheFileReference\n+                    );\n+                    return;\n+                }\n+\n+                final long rangeStart = range.v1();\n+                final long rangeEnd = range.v2();\n+                final long rangeLength = rangeEnd - rangeStart;\n+\n+                logger.trace(\n+                    \"prefetchPart: prewarming part [{}] bytes [{}-{}] by fetching bytes [{}-{}] for cache file [{}]\",\n+                    part,\n+                    partRange.v1(),\n+                    partRange.v2(),\n+                    rangeStart,\n+                    rangeEnd,\n+                    cacheFileReference\n+                );\n+\n+                final FileChannel fc = cacheFile.getChannel();\n+                assert assertFileChannelOpen(fc);\n+                final byte[] copyBuffer = new byte[Math.toIntExact(Math.min(COPY_BUFFER_SIZE, rangeLength))];\n+\n+                long totalBytesRead = 0L;\n+                long remaining = rangeEnd - rangeStart;\n+                final long startTimeNanos = stats.currentTimeNanos();\n+                try (InputStream input = openInputStream(rangeStart, rangeLength)) {\n+                    while (remaining > 0L) {\n+                        assert totalBytesRead + remaining == rangeLength;\n+                        final int bytesRead = readSafe(input, copyBuffer, rangeStart, rangeEnd, remaining, cacheFileReference);\n+                        final long readStart = rangeStart + totalBytesRead;\n+                        cacheFile.fetchRange(readStart, readStart + bytesRead, (start, end) -> {\n+                            logger.trace(\n+                                \"prefetchPart: range [{}-{}] of file [{}] is now available in cache\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6fd6f903274cce215808bcc4b14bb2481feb2553"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTg1NDc1OA==", "bodyText": "Sure, done.", "url": "https://github.com/elastic/elasticsearch/pull/55795#discussion_r415854758", "createdAt": "2020-04-27T14:21:29Z", "author": {"login": "DaveCTurner"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java", "diffHunk": "@@ -174,29 +174,130 @@ protected void readInternal(final byte[] buffer, final int offset, final int len\n     /**\n      * Prefetches a complete part and writes it in cache. This method is used to prewarm the cache.\n      */\n-    public int prefetchPart(final int part) throws IOException {\n+    public void prefetchPart(final int part) throws IOException {\n         ensureContext(ctx -> ctx == CACHE_WARMING_CONTEXT);\n         if (part >= fileInfo.numberOfParts()) {\n             throw new IllegalArgumentException(\"Unexpected part number [\" + part + \"]\");\n         }\n-        final Tuple<Long, Long> range = computeRange(IntStream.range(0, part).mapToLong(fileInfo::partBytes).sum());\n-        assert assertRangeIsAlignedWithPart(range);\n+        final Tuple<Long, Long> partRange = computeRange(IntStream.range(0, part).mapToLong(fileInfo::partBytes).sum());\n+        assert assertRangeIsAlignedWithPart(partRange);\n+\n         try {\n             final CacheFile cacheFile = getCacheFileSafe();\n             try (ReleasableLock ignored = cacheFile.fileLock()) {\n-                final int bytesRead = cacheFile.fetchRange(range.v1(), range.v2(), (start, end) -> {\n-                    logger.trace(\"range [{}-{}] of file [{}] is now available in cache\", start, end, fileInfo.physicalName());\n-                    return Math.toIntExact(end - start);\n-                }, (start, end) -> writeCacheFile(cacheFile.getChannel(), start, end)).get();\n \n-                assert bytesRead == (range.v2() - range.v1());\n-                return bytesRead;\n+                final Tuple<Long, Long> range = cacheFile.getAbsentRangeWithin(partRange.v1(), partRange.v2());\n+                if (range == null) {\n+                    logger.trace(\n+                        \"prefetchPart: part [{}] bytes [{}-{}] is already fully available for cache file [{}]\",\n+                        part,\n+                        partRange.v1(),\n+                        partRange.v2(),\n+                        cacheFileReference\n+                    );\n+                    return;\n+                }\n+\n+                final long rangeStart = range.v1();\n+                final long rangeEnd = range.v2();\n+                final long rangeLength = rangeEnd - rangeStart;\n+\n+                logger.trace(\n+                    \"prefetchPart: prewarming part [{}] bytes [{}-{}] by fetching bytes [{}-{}] for cache file [{}]\",\n+                    part,\n+                    partRange.v1(),\n+                    partRange.v2(),\n+                    rangeStart,\n+                    rangeEnd,\n+                    cacheFileReference\n+                );\n+\n+                final FileChannel fc = cacheFile.getChannel();\n+                assert assertFileChannelOpen(fc);\n+                final byte[] copyBuffer = new byte[Math.toIntExact(Math.min(COPY_BUFFER_SIZE, rangeLength))];\n+\n+                long totalBytesRead = 0L;\n+                long remaining = rangeEnd - rangeStart;\n+                final long startTimeNanos = stats.currentTimeNanos();\n+                try (InputStream input = openInputStream(rangeStart, rangeLength)) {\n+                    while (remaining > 0L) {\n+                        assert totalBytesRead + remaining == rangeLength;\n+                        final int bytesRead = readSafe(input, copyBuffer, rangeStart, rangeEnd, remaining, cacheFileReference);\n+                        final long readStart = rangeStart + totalBytesRead;\n+                        cacheFile.fetchRange(readStart, readStart + bytesRead, (start, end) -> {\n+                            logger.trace(\n+                                \"prefetchPart: range [{}-{}] of file [{}] is now available in cache\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTc1NTU5NQ=="}, "originalCommit": {"oid": "6fd6f903274cce215808bcc4b14bb2481feb2553"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU4NjI3NTg5OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QxMjowNzozNVrOGMfv3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QxNDoyNDowMlrOGMl4ug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTc1NjI1NQ==", "bodyText": "Can we capture the returned Future here and assert in the next line that future.isDone?", "url": "https://github.com/elastic/elasticsearch/pull/55795#discussion_r415756255", "createdAt": "2020-04-27T12:07:35Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java", "diffHunk": "@@ -174,29 +174,130 @@ protected void readInternal(final byte[] buffer, final int offset, final int len\n     /**\n      * Prefetches a complete part and writes it in cache. This method is used to prewarm the cache.\n      */\n-    public int prefetchPart(final int part) throws IOException {\n+    public void prefetchPart(final int part) throws IOException {\n         ensureContext(ctx -> ctx == CACHE_WARMING_CONTEXT);\n         if (part >= fileInfo.numberOfParts()) {\n             throw new IllegalArgumentException(\"Unexpected part number [\" + part + \"]\");\n         }\n-        final Tuple<Long, Long> range = computeRange(IntStream.range(0, part).mapToLong(fileInfo::partBytes).sum());\n-        assert assertRangeIsAlignedWithPart(range);\n+        final Tuple<Long, Long> partRange = computeRange(IntStream.range(0, part).mapToLong(fileInfo::partBytes).sum());\n+        assert assertRangeIsAlignedWithPart(partRange);\n+\n         try {\n             final CacheFile cacheFile = getCacheFileSafe();\n             try (ReleasableLock ignored = cacheFile.fileLock()) {\n-                final int bytesRead = cacheFile.fetchRange(range.v1(), range.v2(), (start, end) -> {\n-                    logger.trace(\"range [{}-{}] of file [{}] is now available in cache\", start, end, fileInfo.physicalName());\n-                    return Math.toIntExact(end - start);\n-                }, (start, end) -> writeCacheFile(cacheFile.getChannel(), start, end)).get();\n \n-                assert bytesRead == (range.v2() - range.v1());\n-                return bytesRead;\n+                final Tuple<Long, Long> range = cacheFile.getAbsentRangeWithin(partRange.v1(), partRange.v2());\n+                if (range == null) {\n+                    logger.trace(\n+                        \"prefetchPart: part [{}] bytes [{}-{}] is already fully available for cache file [{}]\",\n+                        part,\n+                        partRange.v1(),\n+                        partRange.v2(),\n+                        cacheFileReference\n+                    );\n+                    return;\n+                }\n+\n+                final long rangeStart = range.v1();\n+                final long rangeEnd = range.v2();\n+                final long rangeLength = rangeEnd - rangeStart;\n+\n+                logger.trace(\n+                    \"prefetchPart: prewarming part [{}] bytes [{}-{}] by fetching bytes [{}-{}] for cache file [{}]\",\n+                    part,\n+                    partRange.v1(),\n+                    partRange.v2(),\n+                    rangeStart,\n+                    rangeEnd,\n+                    cacheFileReference\n+                );\n+\n+                final FileChannel fc = cacheFile.getChannel();\n+                assert assertFileChannelOpen(fc);\n+                final byte[] copyBuffer = new byte[Math.toIntExact(Math.min(COPY_BUFFER_SIZE, rangeLength))];\n+\n+                long totalBytesRead = 0L;\n+                long remaining = rangeEnd - rangeStart;\n+                final long startTimeNanos = stats.currentTimeNanos();\n+                try (InputStream input = openInputStream(rangeStart, rangeLength)) {\n+                    while (remaining > 0L) {\n+                        assert totalBytesRead + remaining == rangeLength;\n+                        final int bytesRead = readSafe(input, copyBuffer, rangeStart, rangeEnd, remaining, cacheFileReference);\n+                        final long readStart = rangeStart + totalBytesRead;\n+                        cacheFile.fetchRange(readStart, readStart + bytesRead, (start, end) -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6fd6f903274cce215808bcc4b14bb2481feb2553"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTg1NjgyNg==", "bodyText": "No, the future might not be done on return if another thread already acquired the target range and hasn't filled it in yet. That's ok, tho, we assume it'll succeed eventually and keep on consuming the blob until we find a range that hasn't already been acquired by anyone else.", "url": "https://github.com/elastic/elasticsearch/pull/55795#discussion_r415856826", "createdAt": "2020-04-27T14:24:02Z", "author": {"login": "DaveCTurner"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java", "diffHunk": "@@ -174,29 +174,130 @@ protected void readInternal(final byte[] buffer, final int offset, final int len\n     /**\n      * Prefetches a complete part and writes it in cache. This method is used to prewarm the cache.\n      */\n-    public int prefetchPart(final int part) throws IOException {\n+    public void prefetchPart(final int part) throws IOException {\n         ensureContext(ctx -> ctx == CACHE_WARMING_CONTEXT);\n         if (part >= fileInfo.numberOfParts()) {\n             throw new IllegalArgumentException(\"Unexpected part number [\" + part + \"]\");\n         }\n-        final Tuple<Long, Long> range = computeRange(IntStream.range(0, part).mapToLong(fileInfo::partBytes).sum());\n-        assert assertRangeIsAlignedWithPart(range);\n+        final Tuple<Long, Long> partRange = computeRange(IntStream.range(0, part).mapToLong(fileInfo::partBytes).sum());\n+        assert assertRangeIsAlignedWithPart(partRange);\n+\n         try {\n             final CacheFile cacheFile = getCacheFileSafe();\n             try (ReleasableLock ignored = cacheFile.fileLock()) {\n-                final int bytesRead = cacheFile.fetchRange(range.v1(), range.v2(), (start, end) -> {\n-                    logger.trace(\"range [{}-{}] of file [{}] is now available in cache\", start, end, fileInfo.physicalName());\n-                    return Math.toIntExact(end - start);\n-                }, (start, end) -> writeCacheFile(cacheFile.getChannel(), start, end)).get();\n \n-                assert bytesRead == (range.v2() - range.v1());\n-                return bytesRead;\n+                final Tuple<Long, Long> range = cacheFile.getAbsentRangeWithin(partRange.v1(), partRange.v2());\n+                if (range == null) {\n+                    logger.trace(\n+                        \"prefetchPart: part [{}] bytes [{}-{}] is already fully available for cache file [{}]\",\n+                        part,\n+                        partRange.v1(),\n+                        partRange.v2(),\n+                        cacheFileReference\n+                    );\n+                    return;\n+                }\n+\n+                final long rangeStart = range.v1();\n+                final long rangeEnd = range.v2();\n+                final long rangeLength = rangeEnd - rangeStart;\n+\n+                logger.trace(\n+                    \"prefetchPart: prewarming part [{}] bytes [{}-{}] by fetching bytes [{}-{}] for cache file [{}]\",\n+                    part,\n+                    partRange.v1(),\n+                    partRange.v2(),\n+                    rangeStart,\n+                    rangeEnd,\n+                    cacheFileReference\n+                );\n+\n+                final FileChannel fc = cacheFile.getChannel();\n+                assert assertFileChannelOpen(fc);\n+                final byte[] copyBuffer = new byte[Math.toIntExact(Math.min(COPY_BUFFER_SIZE, rangeLength))];\n+\n+                long totalBytesRead = 0L;\n+                long remaining = rangeEnd - rangeStart;\n+                final long startTimeNanos = stats.currentTimeNanos();\n+                try (InputStream input = openInputStream(rangeStart, rangeLength)) {\n+                    while (remaining > 0L) {\n+                        assert totalBytesRead + remaining == rangeLength;\n+                        final int bytesRead = readSafe(input, copyBuffer, rangeStart, rangeEnd, remaining, cacheFileReference);\n+                        final long readStart = rangeStart + totalBytesRead;\n+                        cacheFile.fetchRange(readStart, readStart + bytesRead, (start, end) -> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTc1NjI1NQ=="}, "originalCommit": {"oid": "6fd6f903274cce215808bcc4b14bb2481feb2553"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU4NjMwMjQ0OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QxMjoxMzo1MFrOGMf-3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQwODo1MTowMFrOGNJqYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTc2MDA5Mg==", "bodyText": "I'm confused by the stat accounting here as I thought that not all totalBytesRead have been written to filechannel (when other searches have filled the bytes e.g.)?", "url": "https://github.com/elastic/elasticsearch/pull/55795#discussion_r415760092", "createdAt": "2020-04-27T12:13:50Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java", "diffHunk": "@@ -174,29 +174,130 @@ protected void readInternal(final byte[] buffer, final int offset, final int len\n     /**\n      * Prefetches a complete part and writes it in cache. This method is used to prewarm the cache.\n      */\n-    public int prefetchPart(final int part) throws IOException {\n+    public void prefetchPart(final int part) throws IOException {\n         ensureContext(ctx -> ctx == CACHE_WARMING_CONTEXT);\n         if (part >= fileInfo.numberOfParts()) {\n             throw new IllegalArgumentException(\"Unexpected part number [\" + part + \"]\");\n         }\n-        final Tuple<Long, Long> range = computeRange(IntStream.range(0, part).mapToLong(fileInfo::partBytes).sum());\n-        assert assertRangeIsAlignedWithPart(range);\n+        final Tuple<Long, Long> partRange = computeRange(IntStream.range(0, part).mapToLong(fileInfo::partBytes).sum());\n+        assert assertRangeIsAlignedWithPart(partRange);\n+\n         try {\n             final CacheFile cacheFile = getCacheFileSafe();\n             try (ReleasableLock ignored = cacheFile.fileLock()) {\n-                final int bytesRead = cacheFile.fetchRange(range.v1(), range.v2(), (start, end) -> {\n-                    logger.trace(\"range [{}-{}] of file [{}] is now available in cache\", start, end, fileInfo.physicalName());\n-                    return Math.toIntExact(end - start);\n-                }, (start, end) -> writeCacheFile(cacheFile.getChannel(), start, end)).get();\n \n-                assert bytesRead == (range.v2() - range.v1());\n-                return bytesRead;\n+                final Tuple<Long, Long> range = cacheFile.getAbsentRangeWithin(partRange.v1(), partRange.v2());\n+                if (range == null) {\n+                    logger.trace(\n+                        \"prefetchPart: part [{}] bytes [{}-{}] is already fully available for cache file [{}]\",\n+                        part,\n+                        partRange.v1(),\n+                        partRange.v2(),\n+                        cacheFileReference\n+                    );\n+                    return;\n+                }\n+\n+                final long rangeStart = range.v1();\n+                final long rangeEnd = range.v2();\n+                final long rangeLength = rangeEnd - rangeStart;\n+\n+                logger.trace(\n+                    \"prefetchPart: prewarming part [{}] bytes [{}-{}] by fetching bytes [{}-{}] for cache file [{}]\",\n+                    part,\n+                    partRange.v1(),\n+                    partRange.v2(),\n+                    rangeStart,\n+                    rangeEnd,\n+                    cacheFileReference\n+                );\n+\n+                final FileChannel fc = cacheFile.getChannel();\n+                assert assertFileChannelOpen(fc);\n+                final byte[] copyBuffer = new byte[Math.toIntExact(Math.min(COPY_BUFFER_SIZE, rangeLength))];\n+\n+                long totalBytesRead = 0L;\n+                long remaining = rangeEnd - rangeStart;\n+                final long startTimeNanos = stats.currentTimeNanos();\n+                try (InputStream input = openInputStream(rangeStart, rangeLength)) {\n+                    while (remaining > 0L) {\n+                        assert totalBytesRead + remaining == rangeLength;\n+                        final int bytesRead = readSafe(input, copyBuffer, rangeStart, rangeEnd, remaining, cacheFileReference);\n+                        final long readStart = rangeStart + totalBytesRead;\n+                        cacheFile.fetchRange(readStart, readStart + bytesRead, (start, end) -> {\n+                            logger.trace(\n+                                \"prefetchPart: range [{}-{}] of file [{}] is now available in cache\",\n+                                start,\n+                                end,\n+                                fileInfo.physicalName()\n+                            );\n+                            return Math.toIntExact(end - start);\n+                        }, (start, end) -> {\n+                            final ByteBuffer byteBuffer = ByteBuffer.wrap(\n+                                copyBuffer,\n+                                Math.toIntExact(start - readStart),\n+                                Math.toIntExact(end - start)\n+                            );\n+                            final int writtenBytes = positionalWrite(fc, start, byteBuffer);\n+                            logger.trace(\n+                                \"prefetchPart: writing range [{}-{}] of file [{}], [{}] bytes written\",\n+                                start,\n+                                end,\n+                                fileInfo.physicalName(),\n+                                writtenBytes\n+                            );\n+                        });\n+                        totalBytesRead += bytesRead;\n+                        remaining -= bytesRead;\n+                    }\n+                    final long endTimeNanos = stats.currentTimeNanos();\n+                    stats.addCachedBytesWritten(totalBytesRead, endTimeNanos - startTimeNanos);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6fd6f903274cce215808bcc4b14bb2481feb2553"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTg2MTE1Nw==", "bodyText": "\ud83d\ude15 I thought the intention is for this stat to record the bytes we downloaded from the blob store and so I intended not to account solely for the bytes we actually wrote to the cache file. But I think it's not an accurate count of the bytes downloaded either. I can make it account only for the bytes written by the prewarmer. @tlrx WDYT?", "url": "https://github.com/elastic/elasticsearch/pull/55795#discussion_r415861157", "createdAt": "2020-04-27T14:29:04Z", "author": {"login": "DaveCTurner"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java", "diffHunk": "@@ -174,29 +174,130 @@ protected void readInternal(final byte[] buffer, final int offset, final int len\n     /**\n      * Prefetches a complete part and writes it in cache. This method is used to prewarm the cache.\n      */\n-    public int prefetchPart(final int part) throws IOException {\n+    public void prefetchPart(final int part) throws IOException {\n         ensureContext(ctx -> ctx == CACHE_WARMING_CONTEXT);\n         if (part >= fileInfo.numberOfParts()) {\n             throw new IllegalArgumentException(\"Unexpected part number [\" + part + \"]\");\n         }\n-        final Tuple<Long, Long> range = computeRange(IntStream.range(0, part).mapToLong(fileInfo::partBytes).sum());\n-        assert assertRangeIsAlignedWithPart(range);\n+        final Tuple<Long, Long> partRange = computeRange(IntStream.range(0, part).mapToLong(fileInfo::partBytes).sum());\n+        assert assertRangeIsAlignedWithPart(partRange);\n+\n         try {\n             final CacheFile cacheFile = getCacheFileSafe();\n             try (ReleasableLock ignored = cacheFile.fileLock()) {\n-                final int bytesRead = cacheFile.fetchRange(range.v1(), range.v2(), (start, end) -> {\n-                    logger.trace(\"range [{}-{}] of file [{}] is now available in cache\", start, end, fileInfo.physicalName());\n-                    return Math.toIntExact(end - start);\n-                }, (start, end) -> writeCacheFile(cacheFile.getChannel(), start, end)).get();\n \n-                assert bytesRead == (range.v2() - range.v1());\n-                return bytesRead;\n+                final Tuple<Long, Long> range = cacheFile.getAbsentRangeWithin(partRange.v1(), partRange.v2());\n+                if (range == null) {\n+                    logger.trace(\n+                        \"prefetchPart: part [{}] bytes [{}-{}] is already fully available for cache file [{}]\",\n+                        part,\n+                        partRange.v1(),\n+                        partRange.v2(),\n+                        cacheFileReference\n+                    );\n+                    return;\n+                }\n+\n+                final long rangeStart = range.v1();\n+                final long rangeEnd = range.v2();\n+                final long rangeLength = rangeEnd - rangeStart;\n+\n+                logger.trace(\n+                    \"prefetchPart: prewarming part [{}] bytes [{}-{}] by fetching bytes [{}-{}] for cache file [{}]\",\n+                    part,\n+                    partRange.v1(),\n+                    partRange.v2(),\n+                    rangeStart,\n+                    rangeEnd,\n+                    cacheFileReference\n+                );\n+\n+                final FileChannel fc = cacheFile.getChannel();\n+                assert assertFileChannelOpen(fc);\n+                final byte[] copyBuffer = new byte[Math.toIntExact(Math.min(COPY_BUFFER_SIZE, rangeLength))];\n+\n+                long totalBytesRead = 0L;\n+                long remaining = rangeEnd - rangeStart;\n+                final long startTimeNanos = stats.currentTimeNanos();\n+                try (InputStream input = openInputStream(rangeStart, rangeLength)) {\n+                    while (remaining > 0L) {\n+                        assert totalBytesRead + remaining == rangeLength;\n+                        final int bytesRead = readSafe(input, copyBuffer, rangeStart, rangeEnd, remaining, cacheFileReference);\n+                        final long readStart = rangeStart + totalBytesRead;\n+                        cacheFile.fetchRange(readStart, readStart + bytesRead, (start, end) -> {\n+                            logger.trace(\n+                                \"prefetchPart: range [{}-{}] of file [{}] is now available in cache\",\n+                                start,\n+                                end,\n+                                fileInfo.physicalName()\n+                            );\n+                            return Math.toIntExact(end - start);\n+                        }, (start, end) -> {\n+                            final ByteBuffer byteBuffer = ByteBuffer.wrap(\n+                                copyBuffer,\n+                                Math.toIntExact(start - readStart),\n+                                Math.toIntExact(end - start)\n+                            );\n+                            final int writtenBytes = positionalWrite(fc, start, byteBuffer);\n+                            logger.trace(\n+                                \"prefetchPart: writing range [{}-{}] of file [{}], [{}] bytes written\",\n+                                start,\n+                                end,\n+                                fileInfo.physicalName(),\n+                                writtenBytes\n+                            );\n+                        });\n+                        totalBytesRead += bytesRead;\n+                        remaining -= bytesRead;\n+                    }\n+                    final long endTimeNanos = stats.currentTimeNanos();\n+                    stats.addCachedBytesWritten(totalBytesRead, endTimeNanos - startTimeNanos);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTc2MDA5Mg=="}, "originalCommit": {"oid": "6fd6f903274cce215808bcc4b14bb2481feb2553"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTg5MTUzNg==", "bodyText": "I think that cached_bytes_written should reflect the number of bytes effectively written in cache. It reflected the number of bytes downloaded (only when the cache range size and the readBlobPreferredLength have the same value) but I think we should compute the download stats differently.", "url": "https://github.com/elastic/elasticsearch/pull/55795#discussion_r415891536", "createdAt": "2020-04-27T15:03:52Z", "author": {"login": "tlrx"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java", "diffHunk": "@@ -174,29 +174,130 @@ protected void readInternal(final byte[] buffer, final int offset, final int len\n     /**\n      * Prefetches a complete part and writes it in cache. This method is used to prewarm the cache.\n      */\n-    public int prefetchPart(final int part) throws IOException {\n+    public void prefetchPart(final int part) throws IOException {\n         ensureContext(ctx -> ctx == CACHE_WARMING_CONTEXT);\n         if (part >= fileInfo.numberOfParts()) {\n             throw new IllegalArgumentException(\"Unexpected part number [\" + part + \"]\");\n         }\n-        final Tuple<Long, Long> range = computeRange(IntStream.range(0, part).mapToLong(fileInfo::partBytes).sum());\n-        assert assertRangeIsAlignedWithPart(range);\n+        final Tuple<Long, Long> partRange = computeRange(IntStream.range(0, part).mapToLong(fileInfo::partBytes).sum());\n+        assert assertRangeIsAlignedWithPart(partRange);\n+\n         try {\n             final CacheFile cacheFile = getCacheFileSafe();\n             try (ReleasableLock ignored = cacheFile.fileLock()) {\n-                final int bytesRead = cacheFile.fetchRange(range.v1(), range.v2(), (start, end) -> {\n-                    logger.trace(\"range [{}-{}] of file [{}] is now available in cache\", start, end, fileInfo.physicalName());\n-                    return Math.toIntExact(end - start);\n-                }, (start, end) -> writeCacheFile(cacheFile.getChannel(), start, end)).get();\n \n-                assert bytesRead == (range.v2() - range.v1());\n-                return bytesRead;\n+                final Tuple<Long, Long> range = cacheFile.getAbsentRangeWithin(partRange.v1(), partRange.v2());\n+                if (range == null) {\n+                    logger.trace(\n+                        \"prefetchPart: part [{}] bytes [{}-{}] is already fully available for cache file [{}]\",\n+                        part,\n+                        partRange.v1(),\n+                        partRange.v2(),\n+                        cacheFileReference\n+                    );\n+                    return;\n+                }\n+\n+                final long rangeStart = range.v1();\n+                final long rangeEnd = range.v2();\n+                final long rangeLength = rangeEnd - rangeStart;\n+\n+                logger.trace(\n+                    \"prefetchPart: prewarming part [{}] bytes [{}-{}] by fetching bytes [{}-{}] for cache file [{}]\",\n+                    part,\n+                    partRange.v1(),\n+                    partRange.v2(),\n+                    rangeStart,\n+                    rangeEnd,\n+                    cacheFileReference\n+                );\n+\n+                final FileChannel fc = cacheFile.getChannel();\n+                assert assertFileChannelOpen(fc);\n+                final byte[] copyBuffer = new byte[Math.toIntExact(Math.min(COPY_BUFFER_SIZE, rangeLength))];\n+\n+                long totalBytesRead = 0L;\n+                long remaining = rangeEnd - rangeStart;\n+                final long startTimeNanos = stats.currentTimeNanos();\n+                try (InputStream input = openInputStream(rangeStart, rangeLength)) {\n+                    while (remaining > 0L) {\n+                        assert totalBytesRead + remaining == rangeLength;\n+                        final int bytesRead = readSafe(input, copyBuffer, rangeStart, rangeEnd, remaining, cacheFileReference);\n+                        final long readStart = rangeStart + totalBytesRead;\n+                        cacheFile.fetchRange(readStart, readStart + bytesRead, (start, end) -> {\n+                            logger.trace(\n+                                \"prefetchPart: range [{}-{}] of file [{}] is now available in cache\",\n+                                start,\n+                                end,\n+                                fileInfo.physicalName()\n+                            );\n+                            return Math.toIntExact(end - start);\n+                        }, (start, end) -> {\n+                            final ByteBuffer byteBuffer = ByteBuffer.wrap(\n+                                copyBuffer,\n+                                Math.toIntExact(start - readStart),\n+                                Math.toIntExact(end - start)\n+                            );\n+                            final int writtenBytes = positionalWrite(fc, start, byteBuffer);\n+                            logger.trace(\n+                                \"prefetchPart: writing range [{}-{}] of file [{}], [{}] bytes written\",\n+                                start,\n+                                end,\n+                                fileInfo.physicalName(),\n+                                writtenBytes\n+                            );\n+                        });\n+                        totalBytesRead += bytesRead;\n+                        remaining -= bytesRead;\n+                    }\n+                    final long endTimeNanos = stats.currentTimeNanos();\n+                    stats.addCachedBytesWritten(totalBytesRead, endTimeNanos - startTimeNanos);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTc2MDA5Mg=="}, "originalCommit": {"oid": "6fd6f903274cce215808bcc4b14bb2481feb2553"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQ0Mjk3OQ==", "bodyText": "Ok, I adjusted this in cd793b3 and am checking that the tests are still solid now.", "url": "https://github.com/elastic/elasticsearch/pull/55795#discussion_r416442979", "createdAt": "2020-04-28T08:51:00Z", "author": {"login": "DaveCTurner"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java", "diffHunk": "@@ -174,29 +174,130 @@ protected void readInternal(final byte[] buffer, final int offset, final int len\n     /**\n      * Prefetches a complete part and writes it in cache. This method is used to prewarm the cache.\n      */\n-    public int prefetchPart(final int part) throws IOException {\n+    public void prefetchPart(final int part) throws IOException {\n         ensureContext(ctx -> ctx == CACHE_WARMING_CONTEXT);\n         if (part >= fileInfo.numberOfParts()) {\n             throw new IllegalArgumentException(\"Unexpected part number [\" + part + \"]\");\n         }\n-        final Tuple<Long, Long> range = computeRange(IntStream.range(0, part).mapToLong(fileInfo::partBytes).sum());\n-        assert assertRangeIsAlignedWithPart(range);\n+        final Tuple<Long, Long> partRange = computeRange(IntStream.range(0, part).mapToLong(fileInfo::partBytes).sum());\n+        assert assertRangeIsAlignedWithPart(partRange);\n+\n         try {\n             final CacheFile cacheFile = getCacheFileSafe();\n             try (ReleasableLock ignored = cacheFile.fileLock()) {\n-                final int bytesRead = cacheFile.fetchRange(range.v1(), range.v2(), (start, end) -> {\n-                    logger.trace(\"range [{}-{}] of file [{}] is now available in cache\", start, end, fileInfo.physicalName());\n-                    return Math.toIntExact(end - start);\n-                }, (start, end) -> writeCacheFile(cacheFile.getChannel(), start, end)).get();\n \n-                assert bytesRead == (range.v2() - range.v1());\n-                return bytesRead;\n+                final Tuple<Long, Long> range = cacheFile.getAbsentRangeWithin(partRange.v1(), partRange.v2());\n+                if (range == null) {\n+                    logger.trace(\n+                        \"prefetchPart: part [{}] bytes [{}-{}] is already fully available for cache file [{}]\",\n+                        part,\n+                        partRange.v1(),\n+                        partRange.v2(),\n+                        cacheFileReference\n+                    );\n+                    return;\n+                }\n+\n+                final long rangeStart = range.v1();\n+                final long rangeEnd = range.v2();\n+                final long rangeLength = rangeEnd - rangeStart;\n+\n+                logger.trace(\n+                    \"prefetchPart: prewarming part [{}] bytes [{}-{}] by fetching bytes [{}-{}] for cache file [{}]\",\n+                    part,\n+                    partRange.v1(),\n+                    partRange.v2(),\n+                    rangeStart,\n+                    rangeEnd,\n+                    cacheFileReference\n+                );\n+\n+                final FileChannel fc = cacheFile.getChannel();\n+                assert assertFileChannelOpen(fc);\n+                final byte[] copyBuffer = new byte[Math.toIntExact(Math.min(COPY_BUFFER_SIZE, rangeLength))];\n+\n+                long totalBytesRead = 0L;\n+                long remaining = rangeEnd - rangeStart;\n+                final long startTimeNanos = stats.currentTimeNanos();\n+                try (InputStream input = openInputStream(rangeStart, rangeLength)) {\n+                    while (remaining > 0L) {\n+                        assert totalBytesRead + remaining == rangeLength;\n+                        final int bytesRead = readSafe(input, copyBuffer, rangeStart, rangeEnd, remaining, cacheFileReference);\n+                        final long readStart = rangeStart + totalBytesRead;\n+                        cacheFile.fetchRange(readStart, readStart + bytesRead, (start, end) -> {\n+                            logger.trace(\n+                                \"prefetchPart: range [{}-{}] of file [{}] is now available in cache\",\n+                                start,\n+                                end,\n+                                fileInfo.physicalName()\n+                            );\n+                            return Math.toIntExact(end - start);\n+                        }, (start, end) -> {\n+                            final ByteBuffer byteBuffer = ByteBuffer.wrap(\n+                                copyBuffer,\n+                                Math.toIntExact(start - readStart),\n+                                Math.toIntExact(end - start)\n+                            );\n+                            final int writtenBytes = positionalWrite(fc, start, byteBuffer);\n+                            logger.trace(\n+                                \"prefetchPart: writing range [{}-{}] of file [{}], [{}] bytes written\",\n+                                start,\n+                                end,\n+                                fileInfo.physicalName(),\n+                                writtenBytes\n+                            );\n+                        });\n+                        totalBytesRead += bytesRead;\n+                        remaining -= bytesRead;\n+                    }\n+                    final long endTimeNanos = stats.currentTimeNanos();\n+                    stats.addCachedBytesWritten(totalBytesRead, endTimeNanos - startTimeNanos);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTc2MDA5Mg=="}, "originalCommit": {"oid": "6fd6f903274cce215808bcc4b14bb2481feb2553"}, "originalPosition": 90}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2609, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}