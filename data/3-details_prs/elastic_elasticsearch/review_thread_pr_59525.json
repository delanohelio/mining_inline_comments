{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ4ODQ3MTQ1", "number": 59525, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxMzozODoyMlrOEOQxWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNToyMzozOVrOEOTxYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzMzkwMjk5OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/data-streams/src/test/java/org/elasticsearch/xpack/datastreams/action/DeleteDataStreamTransportActionTests.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxMzozODoyMlrOGxUEEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxMzo0MjozOFrOGxUQPw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM2MjEyOA==", "bodyText": "I suggest moving this method to DataStreamTestHelper since it's used in a lot of tests in the server module.", "url": "https://github.com/elastic/elasticsearch/pull/59525#discussion_r454362128", "createdAt": "2020-07-14T13:38:22Z", "author": {"login": "danhermann"}, "path": "x-pack/plugin/data-streams/src/test/java/org/elasticsearch/xpack/datastreams/action/DeleteDataStreamTransportActionTests.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.datastreams.action;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.cluster.ClusterName;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.SnapshotsInProgress;\n+import org.elasticsearch.cluster.metadata.DataStream;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.metadata.MetadataDeleteIndexService;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.snapshots.Snapshot;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.SnapshotInProgressException;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.xpack.core.action.DeleteDataStreamAction;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import static org.elasticsearch.cluster.DataStreamTestHelper.createTimestampField;\n+import static org.hamcrest.Matchers.containsInAnyOrder;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+public class DeleteDataStreamTransportActionTests extends ESTestCase {\n+\n+    public void testDeleteDataStream() {\n+        final String dataStreamName = \"my-data-stream\";\n+        final List<String> otherIndices = randomSubsetOf(List.of(\"foo\", \"bar\", \"baz\"));\n+\n+        ClusterState cs = getClusterStateWithDataStreams(List.of(new Tuple<>(dataStreamName, 2)), otherIndices);\n+        DeleteDataStreamAction.Request req = new DeleteDataStreamAction.Request(new String[] { dataStreamName });\n+        ClusterState newState = DeleteDataStreamTransportAction.removeDataStream(getMetadataDeleteIndexService(), cs, req);\n+        assertThat(newState.metadata().dataStreams().size(), equalTo(0));\n+        assertThat(newState.metadata().indices().size(), equalTo(otherIndices.size()));\n+        for (String indexName : otherIndices) {\n+            assertThat(newState.metadata().indices().get(indexName).getIndex().getName(), equalTo(indexName));\n+        }\n+    }\n+\n+    public void testDeleteMultipleDataStreams() {\n+        String[] dataStreamNames = { \"foo\", \"bar\", \"baz\", \"eggplant\" };\n+        ClusterState cs = getClusterStateWithDataStreams(\n+            List.of(\n+                new Tuple<>(dataStreamNames[0], randomIntBetween(1, 3)),\n+                new Tuple<>(dataStreamNames[1], randomIntBetween(1, 3)),\n+                new Tuple<>(dataStreamNames[2], randomIntBetween(1, 3)),\n+                new Tuple<>(dataStreamNames[3], randomIntBetween(1, 3))\n+            ),\n+            List.of()\n+        );\n+\n+        DeleteDataStreamAction.Request req = new DeleteDataStreamAction.Request(new String[] { \"ba*\", \"eggplant\" });\n+        ClusterState newState = DeleteDataStreamTransportAction.removeDataStream(getMetadataDeleteIndexService(), cs, req);\n+        assertThat(newState.metadata().dataStreams().size(), equalTo(1));\n+        DataStream remainingDataStream = newState.metadata().dataStreams().get(dataStreamNames[0]);\n+        assertNotNull(remainingDataStream);\n+        assertThat(newState.metadata().indices().size(), equalTo(remainingDataStream.getIndices().size()));\n+        for (Index i : remainingDataStream.getIndices()) {\n+            assertThat(newState.metadata().indices().get(i.getName()).getIndex(), equalTo(i));\n+        }\n+    }\n+\n+    public void testDeleteSnapshottingDataStream() {\n+        final String dataStreamName = \"my-data-stream1\";\n+        final String dataStreamName2 = \"my-data-stream2\";\n+        final List<String> otherIndices = randomSubsetOf(List.of(\"foo\", \"bar\", \"baz\"));\n+\n+        ClusterState cs = getClusterStateWithDataStreams(\n+            List.of(new Tuple<>(dataStreamName, 2), new Tuple<>(dataStreamName2, 2)),\n+            otherIndices\n+        );\n+        SnapshotsInProgress snapshotsInProgress = SnapshotsInProgress.of(\n+            List.of(createEntry(dataStreamName, \"repo1\", false), createEntry(dataStreamName2, \"repo2\", true))\n+        );\n+        ClusterState snapshotCs = ClusterState.builder(cs).putCustom(SnapshotsInProgress.TYPE, snapshotsInProgress).build();\n+\n+        DeleteDataStreamAction.Request req = new DeleteDataStreamAction.Request(new String[] { dataStreamName });\n+        SnapshotInProgressException e = expectThrows(\n+            SnapshotInProgressException.class,\n+            () -> DeleteDataStreamTransportAction.removeDataStream(getMetadataDeleteIndexService(), snapshotCs, req)\n+        );\n+\n+        assertThat(\n+            e.getMessage(),\n+            equalTo(\n+                \"Cannot delete data streams that are being snapshotted: [my-data-stream1]. Try again after \"\n+                    + \"snapshot finishes or cancel the currently running snapshot.\"\n+            )\n+        );\n+    }\n+\n+    private SnapshotsInProgress.Entry createEntry(String dataStreamName, String repo, boolean partial) {\n+        return new SnapshotsInProgress.Entry(\n+            new Snapshot(repo, new SnapshotId(\"\", \"\")),\n+            false,\n+            partial,\n+            SnapshotsInProgress.State.STARTED,\n+            Collections.emptyList(),\n+            List.of(dataStreamName),\n+            0,\n+            1,\n+            ImmutableOpenMap.of(),\n+            null,\n+            null,\n+            null\n+        );\n+    }\n+\n+    public void testDeleteNonexistentDataStream() {\n+        final String dataStreamName = \"my-data-stream\";\n+        String[] dataStreamNames = { \"foo\", \"bar\", \"baz\", \"eggplant\" };\n+        ClusterState cs = getClusterStateWithDataStreams(\n+            List.of(\n+                new Tuple<>(dataStreamNames[0], randomIntBetween(1, 3)),\n+                new Tuple<>(dataStreamNames[1], randomIntBetween(1, 3)),\n+                new Tuple<>(dataStreamNames[2], randomIntBetween(1, 3)),\n+                new Tuple<>(dataStreamNames[3], randomIntBetween(1, 3))\n+            ),\n+            List.of()\n+        );\n+        DeleteDataStreamAction.Request req = new DeleteDataStreamAction.Request(new String[] { dataStreamName });\n+        ClusterState newState = DeleteDataStreamTransportAction.removeDataStream(getMetadataDeleteIndexService(), cs, req);\n+        assertThat(newState.metadata().dataStreams().size(), equalTo(cs.metadata().dataStreams().size()));\n+        assertThat(\n+            newState.metadata().dataStreams().keySet(),\n+            containsInAnyOrder(cs.metadata().dataStreams().keySet().toArray(Strings.EMPTY_ARRAY))\n+        );\n+    }\n+\n+    @SuppressWarnings(\"unchecked\")\n+    private static MetadataDeleteIndexService getMetadataDeleteIndexService() {\n+        MetadataDeleteIndexService s = mock(MetadataDeleteIndexService.class);\n+        when(s.deleteIndices(any(ClusterState.class), any(Set.class))).thenAnswer(mockInvocation -> {\n+            ClusterState currentState = (ClusterState) mockInvocation.getArguments()[0];\n+            Set<Index> indices = (Set<Index>) mockInvocation.getArguments()[1];\n+\n+            final Metadata.Builder b = Metadata.builder(currentState.metadata());\n+            for (Index index : indices) {\n+                b.remove(index.getName());\n+            }\n+\n+            return ClusterState.builder(currentState).metadata(b.build()).build();\n+        });\n+\n+        return s;\n+    }\n+\n+    /**\n+     * Constructs {@code ClusterState} with the specified data streams and indices.\n+     *\n+     * @param dataStreams The names of the data streams to create with their respective number of backing indices\n+     * @param indexNames  The names of indices to create that do not back any data streams\n+     */\n+    public static ClusterState getClusterStateWithDataStreams(List<Tuple<String, Integer>> dataStreams, List<String> indexNames) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65d77f6df1d9bec4eadc742f9e13a04c2a0cf8c4"}, "originalPosition": 171}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM2NTI0Nw==", "bodyText": "Good point. This is why ci/1 failed. I've addressed this.", "url": "https://github.com/elastic/elasticsearch/pull/59525#discussion_r454365247", "createdAt": "2020-07-14T13:42:38Z", "author": {"login": "martijnvg"}, "path": "x-pack/plugin/data-streams/src/test/java/org/elasticsearch/xpack/datastreams/action/DeleteDataStreamTransportActionTests.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.datastreams.action;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.cluster.ClusterName;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.SnapshotsInProgress;\n+import org.elasticsearch.cluster.metadata.DataStream;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.metadata.MetadataDeleteIndexService;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.snapshots.Snapshot;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.SnapshotInProgressException;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.xpack.core.action.DeleteDataStreamAction;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import static org.elasticsearch.cluster.DataStreamTestHelper.createTimestampField;\n+import static org.hamcrest.Matchers.containsInAnyOrder;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+public class DeleteDataStreamTransportActionTests extends ESTestCase {\n+\n+    public void testDeleteDataStream() {\n+        final String dataStreamName = \"my-data-stream\";\n+        final List<String> otherIndices = randomSubsetOf(List.of(\"foo\", \"bar\", \"baz\"));\n+\n+        ClusterState cs = getClusterStateWithDataStreams(List.of(new Tuple<>(dataStreamName, 2)), otherIndices);\n+        DeleteDataStreamAction.Request req = new DeleteDataStreamAction.Request(new String[] { dataStreamName });\n+        ClusterState newState = DeleteDataStreamTransportAction.removeDataStream(getMetadataDeleteIndexService(), cs, req);\n+        assertThat(newState.metadata().dataStreams().size(), equalTo(0));\n+        assertThat(newState.metadata().indices().size(), equalTo(otherIndices.size()));\n+        for (String indexName : otherIndices) {\n+            assertThat(newState.metadata().indices().get(indexName).getIndex().getName(), equalTo(indexName));\n+        }\n+    }\n+\n+    public void testDeleteMultipleDataStreams() {\n+        String[] dataStreamNames = { \"foo\", \"bar\", \"baz\", \"eggplant\" };\n+        ClusterState cs = getClusterStateWithDataStreams(\n+            List.of(\n+                new Tuple<>(dataStreamNames[0], randomIntBetween(1, 3)),\n+                new Tuple<>(dataStreamNames[1], randomIntBetween(1, 3)),\n+                new Tuple<>(dataStreamNames[2], randomIntBetween(1, 3)),\n+                new Tuple<>(dataStreamNames[3], randomIntBetween(1, 3))\n+            ),\n+            List.of()\n+        );\n+\n+        DeleteDataStreamAction.Request req = new DeleteDataStreamAction.Request(new String[] { \"ba*\", \"eggplant\" });\n+        ClusterState newState = DeleteDataStreamTransportAction.removeDataStream(getMetadataDeleteIndexService(), cs, req);\n+        assertThat(newState.metadata().dataStreams().size(), equalTo(1));\n+        DataStream remainingDataStream = newState.metadata().dataStreams().get(dataStreamNames[0]);\n+        assertNotNull(remainingDataStream);\n+        assertThat(newState.metadata().indices().size(), equalTo(remainingDataStream.getIndices().size()));\n+        for (Index i : remainingDataStream.getIndices()) {\n+            assertThat(newState.metadata().indices().get(i.getName()).getIndex(), equalTo(i));\n+        }\n+    }\n+\n+    public void testDeleteSnapshottingDataStream() {\n+        final String dataStreamName = \"my-data-stream1\";\n+        final String dataStreamName2 = \"my-data-stream2\";\n+        final List<String> otherIndices = randomSubsetOf(List.of(\"foo\", \"bar\", \"baz\"));\n+\n+        ClusterState cs = getClusterStateWithDataStreams(\n+            List.of(new Tuple<>(dataStreamName, 2), new Tuple<>(dataStreamName2, 2)),\n+            otherIndices\n+        );\n+        SnapshotsInProgress snapshotsInProgress = SnapshotsInProgress.of(\n+            List.of(createEntry(dataStreamName, \"repo1\", false), createEntry(dataStreamName2, \"repo2\", true))\n+        );\n+        ClusterState snapshotCs = ClusterState.builder(cs).putCustom(SnapshotsInProgress.TYPE, snapshotsInProgress).build();\n+\n+        DeleteDataStreamAction.Request req = new DeleteDataStreamAction.Request(new String[] { dataStreamName });\n+        SnapshotInProgressException e = expectThrows(\n+            SnapshotInProgressException.class,\n+            () -> DeleteDataStreamTransportAction.removeDataStream(getMetadataDeleteIndexService(), snapshotCs, req)\n+        );\n+\n+        assertThat(\n+            e.getMessage(),\n+            equalTo(\n+                \"Cannot delete data streams that are being snapshotted: [my-data-stream1]. Try again after \"\n+                    + \"snapshot finishes or cancel the currently running snapshot.\"\n+            )\n+        );\n+    }\n+\n+    private SnapshotsInProgress.Entry createEntry(String dataStreamName, String repo, boolean partial) {\n+        return new SnapshotsInProgress.Entry(\n+            new Snapshot(repo, new SnapshotId(\"\", \"\")),\n+            false,\n+            partial,\n+            SnapshotsInProgress.State.STARTED,\n+            Collections.emptyList(),\n+            List.of(dataStreamName),\n+            0,\n+            1,\n+            ImmutableOpenMap.of(),\n+            null,\n+            null,\n+            null\n+        );\n+    }\n+\n+    public void testDeleteNonexistentDataStream() {\n+        final String dataStreamName = \"my-data-stream\";\n+        String[] dataStreamNames = { \"foo\", \"bar\", \"baz\", \"eggplant\" };\n+        ClusterState cs = getClusterStateWithDataStreams(\n+            List.of(\n+                new Tuple<>(dataStreamNames[0], randomIntBetween(1, 3)),\n+                new Tuple<>(dataStreamNames[1], randomIntBetween(1, 3)),\n+                new Tuple<>(dataStreamNames[2], randomIntBetween(1, 3)),\n+                new Tuple<>(dataStreamNames[3], randomIntBetween(1, 3))\n+            ),\n+            List.of()\n+        );\n+        DeleteDataStreamAction.Request req = new DeleteDataStreamAction.Request(new String[] { dataStreamName });\n+        ClusterState newState = DeleteDataStreamTransportAction.removeDataStream(getMetadataDeleteIndexService(), cs, req);\n+        assertThat(newState.metadata().dataStreams().size(), equalTo(cs.metadata().dataStreams().size()));\n+        assertThat(\n+            newState.metadata().dataStreams().keySet(),\n+            containsInAnyOrder(cs.metadata().dataStreams().keySet().toArray(Strings.EMPTY_ARRAY))\n+        );\n+    }\n+\n+    @SuppressWarnings(\"unchecked\")\n+    private static MetadataDeleteIndexService getMetadataDeleteIndexService() {\n+        MetadataDeleteIndexService s = mock(MetadataDeleteIndexService.class);\n+        when(s.deleteIndices(any(ClusterState.class), any(Set.class))).thenAnswer(mockInvocation -> {\n+            ClusterState currentState = (ClusterState) mockInvocation.getArguments()[0];\n+            Set<Index> indices = (Set<Index>) mockInvocation.getArguments()[1];\n+\n+            final Metadata.Builder b = Metadata.builder(currentState.metadata());\n+            for (Index index : indices) {\n+                b.remove(index.getName());\n+            }\n+\n+            return ClusterState.builder(currentState).metadata(b.build()).build();\n+        });\n+\n+        return s;\n+    }\n+\n+    /**\n+     * Constructs {@code ClusterState} with the specified data streams and indices.\n+     *\n+     * @param dataStreams The names of the data streams to create with their respective number of backing indices\n+     * @param indexNames  The names of indices to create that do not back any data streams\n+     */\n+    public static ClusterState getClusterStateWithDataStreams(List<Tuple<String, Integer>> dataStreams, List<String> indexNames) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM2MjEyOA=="}, "originalCommit": {"oid": "65d77f6df1d9bec4eadc742f9e13a04c2a0cf8c4"}, "originalPosition": 171}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNDM5MjM0OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/data-streams/src/main/java/org/elasticsearch/xpack/datastreams/rest/RestDeleteDataStreamAction.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNToyMzoxMFrOGxYzKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNTo0NzoyMFrOGxZ2lQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQzOTcyMQ==", "bodyText": "This license needs to be removed", "url": "https://github.com/elastic/elasticsearch/pull/59525#discussion_r454439721", "createdAt": "2020-07-14T15:23:10Z", "author": {"login": "dakrone"}, "path": "x-pack/plugin/data-streams/src/main/java/org/elasticsearch/xpack/datastreams/rest/RestDeleteDataStreamAction.java", "diffHunk": "@@ -1,3 +1,9 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n /*\n  * Licensed to Elasticsearch under one or more contributor\n  * license agreements. See the NOTICE file distributed with", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78826fc1ad1b572432c445203f702f374895df81"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ1Njk4MQ==", "bodyText": "whoops \ud83d\ude2c\ndual licensing was not the intent of this change :)", "url": "https://github.com/elastic/elasticsearch/pull/59525#discussion_r454456981", "createdAt": "2020-07-14T15:47:20Z", "author": {"login": "martijnvg"}, "path": "x-pack/plugin/data-streams/src/main/java/org/elasticsearch/xpack/datastreams/rest/RestDeleteDataStreamAction.java", "diffHunk": "@@ -1,3 +1,9 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n /*\n  * Licensed to Elasticsearch under one or more contributor\n  * license agreements. See the NOTICE file distributed with", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQzOTcyMQ=="}, "originalCommit": {"oid": "78826fc1ad1b572432c445203f702f374895df81"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNDM5MzIwOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/data-streams/src/main/java/org/elasticsearch/xpack/datastreams/rest/RestCreateDataStreamAction.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNToyMzoyMlrOGxYzwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNToyMzoyMlrOGxYzwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQzOTg3Mw==", "bodyText": "This license needs to be removed", "url": "https://github.com/elastic/elasticsearch/pull/59525#discussion_r454439873", "createdAt": "2020-07-14T15:23:22Z", "author": {"login": "dakrone"}, "path": "x-pack/plugin/data-streams/src/main/java/org/elasticsearch/xpack/datastreams/rest/RestCreateDataStreamAction.java", "diffHunk": "@@ -1,3 +1,9 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n /*\n  * Licensed to Elasticsearch under one or more contributor\n  * license agreements. See the NOTICE file distributed with", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78826fc1ad1b572432c445203f702f374895df81"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNDM5NDU3OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/data-streams/src/main/java/org/elasticsearch/xpack/datastreams/rest/RestGetDataStreamsAction.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNToyMzozOVrOGxY0mA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNToyMzozOVrOGxY0mA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ0MDA4OA==", "bodyText": "Same here", "url": "https://github.com/elastic/elasticsearch/pull/59525#discussion_r454440088", "createdAt": "2020-07-14T15:23:39Z", "author": {"login": "dakrone"}, "path": "x-pack/plugin/data-streams/src/main/java/org/elasticsearch/xpack/datastreams/rest/RestGetDataStreamsAction.java", "diffHunk": "@@ -1,3 +1,9 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n /*\n  * Licensed to Elasticsearch under one or more contributor\n  * license agreements. See the NOTICE file distributed with", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78826fc1ad1b572432c445203f702f374895df81"}, "originalPosition": 9}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2392, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}