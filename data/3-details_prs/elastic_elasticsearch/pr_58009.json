{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMzMjgzODY5", "number": 58009, "title": "[ML] handles compressed model stream from native process", "bodyText": "This moves model storage from handling the fully parsed JSON string to handling two separate types of documents.\n\nModelSizeInfo which contains model size information\nTrainedModelDefinitionChunk which contains a particular chunk of the compressed model definition string.\n\nmodel_size_info is assumed to be handled first. This will generate the model_id and store the initial trained model config object. Then each chunk is assumed to be in correct order for concatenating the chunks to get a compressed definition.\nNative side change: elastic/ml-cpp#1349", "createdAt": "2020-06-11T19:24:12Z", "url": "https://github.com/elastic/elasticsearch/pull/58009", "merged": true, "mergeCommit": {"oid": "e881ea41646232519eed7f5a3dab4005edb2cbc6"}, "closed": true, "closedAt": "2020-07-01T13:01:31Z", "author": {"login": "benwtrent"}, "timelineItems": {"totalCount": 21, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcqTQMRgH2gAyNDMzMjgzODY5OmYzY2NkMTk1Y2NiMDJiZDJhZTYxN2Y5OTc0ZDBhNjY3ZjA0ZDA0OGY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcwozMZAFqTQ0MDc4Njc1OQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "f3ccd195ccb02bd2ae617f9974d0a667f04d048f", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/f3ccd195ccb02bd2ae617f9974d0a667f04d048f", "committedDate": "2020-06-11T19:16:47Z", "message": "[ML] handles compressed model stream from native process"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c77243330041beac619f9f0185887bfea874a45d", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/c77243330041beac619f9f0185887bfea874a45d", "committedDate": "2020-06-11T16:59:20Z", "message": "[ML] handles compressed model stream from native process"}, "afterCommit": {"oid": "f3ccd195ccb02bd2ae617f9974d0a667f04d048f", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/f3ccd195ccb02bd2ae617f9974d0a667f04d048f", "committedDate": "2020-06-11T19:16:47Z", "message": "[ML] handles compressed model stream from native process"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7082531824b0775c6a06204b06359e3372c2cb55", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/7082531824b0775c6a06204b06359e3372c2cb55", "committedDate": "2020-06-26T11:54:50Z", "message": "Merge remote-tracking branch 'upstream/master' into feature/ml-analytics-handle-compressed-model-stream"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3a5ce9301d227876ea178c118b8b97b7cd1bc6c5", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/3a5ce9301d227876ea178c118b8b97b7cd1bc6c5", "committedDate": "2020-06-26T13:55:10Z", "message": "fixing after merge"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "354fc25be4b26de9d1625d69e7b7f75f26099eb4", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/354fc25be4b26de9d1625d69e7b7f75f26099eb4", "committedDate": "2020-06-26T15:27:47Z", "message": "adjusting doc storage format"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ff192a4704a855cd5aa0b6a8e2e5b0ac9d8df351", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/ff192a4704a855cd5aa0b6a8e2e5b0ac9d8df351", "committedDate": "2020-06-26T17:58:45Z", "message": "fixing model storage"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ad877b075dbe1aae50aa64e2745ba3ab923563b8", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/ad877b075dbe1aae50aa64e2745ba3ab923563b8", "committedDate": "2020-06-26T19:29:52Z", "message": "Merge remote-tracking branch 'upstream/master' into feature/ml-analytics-handle-compressed-model-stream"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "40571e2ad2daa05eda3f1130f7c923a8f65bae5b", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/40571e2ad2daa05eda3f1130f7c923a8f65bae5b", "committedDate": "2020-06-26T19:30:09Z", "message": "unmuting tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/8a340bfac24b19cbb32170f16a8d7323ae296854", "committedDate": "2020-06-26T19:30:33Z", "message": "unmuting tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM5OTEwMjQ3", "url": "https://github.com/elastic/elasticsearch/pull/58009#pullrequestreview-439910247", "createdAt": "2020-06-30T11:09:20Z", "commit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMTowOToyMFrOGq3bwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMTo0NTozM1rOGq4imA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYwMTYwMA==", "bodyText": "nice name, but I guess moodel -> model ;-)", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447601600", "createdAt": "2020-06-30T11:09:20Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/ml/src/internalClusterTest/java/org/elasticsearch/xpack/ml/integration/ChunkedTrainedMoodelPersisterIT.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.integration;\n+\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.action.util.PageParams;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsDest;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsSource;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.MlInferenceNamedXContentProvider;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinition;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinitionTests;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInputTests;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.TargetType;\n+import org.elasticsearch.xpack.ml.MlSingleNodeTestCase;\n+import org.elasticsearch.xpack.ml.dataframe.process.ChunkedTrainedModelPersister;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.DocValueField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.inference.modelsize.MlModelSizeNamedXContentProvider;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfoTests;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+import org.junit.Before;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Set;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+\n+public class ChunkedTrainedMoodelPersisterIT extends MlSingleNodeTestCase {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYwNjI0MA==", "bodyText": "nit: abbreviation looks strange if everything else is written out", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447606240", "createdAt": "2020-06-30T11:18:44Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/persistence/TrainedModelDefinitionDoc.java", "diffHunk": "@@ -48,6 +49,7 @@\n         parser.declareInt(TrainedModelDefinitionDoc.Builder::setCompressionVersion, COMPRESSION_VERSION);\n         parser.declareLong(TrainedModelDefinitionDoc.Builder::setDefinitionLength, DEFINITION_LENGTH);\n         parser.declareLong(TrainedModelDefinitionDoc.Builder::setTotalDefinitionLength, TOTAL_DEFINITION_LENGTH);\n+        parser.declareBoolean(TrainedModelDefinitionDoc.Builder::setEos, EOS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYxMzUwOQ==", "bodyText": "should currentModelId be reset, too (after LOGGER.info)?", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447613509", "createdAt": "2020-06-30T11:33:05Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYxMzg5Mg==", "bodyText": "why not initialize it empty?", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447613892", "createdAt": "2020-06-30T11:33:56Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYxNTM0OA==", "bodyText": "I wonder if AtomicBoolean would be nicer with things like updateAndGet", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447615348", "createdAt": "2020-06-30T11:36:50Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYxNjE0OQ==", "bodyText": "consider a constant for the timeout", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447616149", "createdAt": "2020-06-30T11:38:30Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;\n+                    LOGGER.info(\n+                        \"[{}] finished stored trained model definition chunks with id [{}]\",\n+                        analytics.getId(),\n+                        this.currentModelId.get());\n+                    auditor.info(analytics.getId(), \"Stored trained model with id [\" + this.currentModelId.get() + \"]\");\n+                    CountDownLatch refreshLatch = new CountDownLatch(1);\n+                    provider.refreshInferenceIndex(\n+                        new LatchedActionListener<>(ActionListener.wrap(\n+                            refreshResponse -> LOGGER.debug(() -> new ParameterizedMessage(\n+                                \"[{}] refreshed inference index after model store\",\n+                                analytics.getId()\n+                            )),\n+                            e -> LOGGER.warn(\"[{}] failed to refresh inference index after model store\", analytics.getId())),\n+                            refreshLatch));\n+                    try {\n+                        if (refreshLatch.await(30, TimeUnit.SECONDS) == false) {\n+                            LOGGER.error(\"[{}] Timed out (30s) waiting for index refresh\", analytics.getId());\n+                        }\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                }\n+            },\n+            e -> failureHandler.accept(ExceptionsHelper.serverError(\"error storing trained model definition chunk [{}] with id [{}]\", e,\n+                trainedModelDefinitionDoc.getModelId(), trainedModelDefinitionDoc.getDocNum()))\n+        );\n+        provider.storeTrainedModelDefinitionDoc(trainedModelDefinitionDoc, new LatchedActionListener<>(storeListener, latch));\n+        try {\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for chunked inference definition to be stored\", analytics.getId());\n+            }\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            failureHandler.accept(ExceptionsHelper.serverError(\"interrupted waiting for chunked inference definition to be stored\"));\n+        }\n+    }\n+\n+    public void createAndIndexInferenceModelMetadata(ModelSizeInfo inferenceModelSize) {\n+        if (readyToStoreNewModel == false) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"new inference model is attempting to be stored before completion previous model storage\"\n+            ));\n+            return;\n+        }\n+        TrainedModelConfig trainedModelConfig = createTrainedModelConfig(inferenceModelSize);\n+        CountDownLatch latch = storeTrainedModelMetadata(trainedModelConfig);\n+        try {\n+            readyToStoreNewModel = false;\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 139}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYxOTczNg==", "bodyText": "if this happens, it seems the persister can get stuck, because the doc gets never be stored and readyToStoreNewModel is never reset? Correct me if I am wrong.", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447619736", "createdAt": "2020-06-30T11:45:33Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;\n+                    LOGGER.info(\n+                        \"[{}] finished stored trained model definition chunks with id [{}]\",\n+                        analytics.getId(),\n+                        this.currentModelId.get());\n+                    auditor.info(analytics.getId(), \"Stored trained model with id [\" + this.currentModelId.get() + \"]\");\n+                    CountDownLatch refreshLatch = new CountDownLatch(1);\n+                    provider.refreshInferenceIndex(\n+                        new LatchedActionListener<>(ActionListener.wrap(\n+                            refreshResponse -> LOGGER.debug(() -> new ParameterizedMessage(\n+                                \"[{}] refreshed inference index after model store\",\n+                                analytics.getId()\n+                            )),\n+                            e -> LOGGER.warn(\"[{}] failed to refresh inference index after model store\", analytics.getId())),\n+                            refreshLatch));\n+                    try {\n+                        if (refreshLatch.await(30, TimeUnit.SECONDS) == false) {\n+                            LOGGER.error(\"[{}] Timed out (30s) waiting for index refresh\", analytics.getId());\n+                        }\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                }\n+            },\n+            e -> failureHandler.accept(ExceptionsHelper.serverError(\"error storing trained model definition chunk [{}] with id [{}]\", e,\n+                trainedModelDefinitionDoc.getModelId(), trainedModelDefinitionDoc.getDocNum()))\n+        );\n+        provider.storeTrainedModelDefinitionDoc(trainedModelDefinitionDoc, new LatchedActionListener<>(storeListener, latch));\n+        try {\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for chunked inference definition to be stored\", analytics.getId());\n+            }\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            failureHandler.accept(ExceptionsHelper.serverError(\"interrupted waiting for chunked inference definition to be stored\"));\n+        }\n+    }\n+\n+    public void createAndIndexInferenceModelMetadata(ModelSizeInfo inferenceModelSize) {\n+        if (readyToStoreNewModel == false) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"new inference model is attempting to be stored before completion previous model storage\"\n+            ));\n+            return;\n+        }\n+        TrainedModelConfig trainedModelConfig = createTrainedModelConfig(inferenceModelSize);\n+        CountDownLatch latch = storeTrainedModelMetadata(trainedModelConfig);\n+        try {\n+            readyToStoreNewModel = false;\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for inference model metadata to be stored\", analytics.getId());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 140}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM5OTE2NjEy", "url": "https://github.com/elastic/elasticsearch/pull/58009#pullrequestreview-439916612", "createdAt": "2020-06-30T11:19:29Z", "commit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMToxOTozMFrOGq3vbA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMjoyMjo0OVrOGq5ykQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYwNjYzNg==", "bodyText": "Note there's a simple way to do ceil with integer arithmetic: (str.length() + chunkSize - 1) / chunkSize.", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447606636", "createdAt": "2020-06-30T11:19:30Z", "author": {"login": "tveasey"}, "path": "x-pack/plugin/ml/src/internalClusterTest/java/org/elasticsearch/xpack/ml/integration/ChunkedTrainedMoodelPersisterIT.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.integration;\n+\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.action.util.PageParams;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsDest;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsSource;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.MlInferenceNamedXContentProvider;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinition;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinitionTests;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInputTests;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.TargetType;\n+import org.elasticsearch.xpack.ml.MlSingleNodeTestCase;\n+import org.elasticsearch.xpack.ml.dataframe.process.ChunkedTrainedModelPersister;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.DocValueField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.inference.modelsize.MlModelSizeNamedXContentProvider;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfoTests;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+import org.junit.Before;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Set;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+\n+public class ChunkedTrainedMoodelPersisterIT extends MlSingleNodeTestCase {\n+\n+    private TrainedModelProvider trainedModelProvider;\n+\n+    @Before\n+    public void createComponents() throws Exception {\n+        trainedModelProvider = new TrainedModelProvider(client(), xContentRegistry());\n+        waitForMlTemplates();\n+    }\n+\n+    public void testStoreModelViaChunkedPersister() throws IOException {\n+        String modelId = \"stored-chunked-model\";\n+        DataFrameAnalyticsConfig analyticsConfig = new DataFrameAnalyticsConfig.Builder()\n+            .setId(modelId)\n+            .setSource(new DataFrameAnalyticsSource(new String[] {\"my_source\"}, null, null))\n+            .setDest(new DataFrameAnalyticsDest(\"my_dest\", null))\n+            .setAnalysis(new Regression(\"foo\"))\n+            .build();\n+        List<ExtractedField> extractedFieldList = Collections.singletonList(new DocValueField(\"foo\", Collections.emptySet()));\n+        TrainedModelConfig.Builder configBuilder = buildTrainedModelConfigBuilder(modelId);\n+        String compressedDefinition = configBuilder.build().getCompressedDefinition();\n+        int totalSize = compressedDefinition.length();\n+        List<String> chunks = chunkStringWithSize(compressedDefinition, totalSize/3);\n+\n+        ChunkedTrainedModelPersister persister = new ChunkedTrainedModelPersister(trainedModelProvider,\n+            analyticsConfig,\n+            new DataFrameAnalyticsAuditor(client(), \"test-node\"),\n+            (ex) -> { throw new ElasticsearchException(ex); },\n+            new ExtractedFields(extractedFieldList, Collections.emptyMap())\n+        );\n+\n+        //Accuracy for size is not tested here\n+        ModelSizeInfo modelSizeInfo = ModelSizeInfoTests.createRandom();\n+        persister.createAndIndexInferenceModelMetadata(modelSizeInfo);\n+        for (int i = 0; i < chunks.size(); i++) {\n+            persister.createAndIndexInferenceModelDoc(new TrainedModelDefinitionChunk(chunks.get(i), i, i == (chunks.size() - 1)));\n+        }\n+\n+        PlainActionFuture<Tuple<Long, Set<String>>> getIdsFuture = new PlainActionFuture<>();\n+        trainedModelProvider.expandIds(modelId + \"*\", false, PageParams.defaultParams(), Collections.emptySet(), getIdsFuture);\n+        Tuple<Long, Set<String>> ids = getIdsFuture.actionGet();\n+        assertThat(ids.v1(), equalTo(1L));\n+\n+        PlainActionFuture<TrainedModelConfig> getTrainedModelFuture = new PlainActionFuture<>();\n+        trainedModelProvider.getTrainedModel(ids.v2().iterator().next(), true, getTrainedModelFuture);\n+\n+        TrainedModelConfig storedConfig = getTrainedModelFuture.actionGet();\n+        assertThat(storedConfig.getCompressedDefinition(), equalTo(compressedDefinition));\n+        assertThat(storedConfig.getEstimatedOperations(), equalTo((long)modelSizeInfo.numOperations()));\n+        assertThat(storedConfig.getEstimatedHeapMemory(), equalTo(modelSizeInfo.ramBytesUsed()));\n+    }\n+\n+    private static TrainedModelConfig.Builder buildTrainedModelConfigBuilder(String modelId) {\n+        TrainedModelDefinition.Builder definitionBuilder = TrainedModelDefinitionTests.createRandomBuilder();\n+        long bytesUsed = definitionBuilder.build().ramBytesUsed();\n+        long operations = definitionBuilder.build().getTrainedModel().estimatedNumOperations();\n+        return TrainedModelConfig.builder()\n+            .setCreatedBy(\"ml_test\")\n+            .setParsedDefinition(TrainedModelDefinitionTests.createRandomBuilder(TargetType.REGRESSION))\n+            .setDescription(\"trained model config for test\")\n+            .setModelId(modelId)\n+            .setVersion(Version.CURRENT)\n+            .setLicenseLevel(License.OperationMode.PLATINUM.description())\n+            .setEstimatedHeapMemory(bytesUsed)\n+            .setEstimatedOperations(operations)\n+            .setInput(TrainedModelInputTests.createRandomInput());\n+    }\n+\n+    private static List<String> chunkStringWithSize(String str, int chunkSize) {\n+        List<String> subStrings = new ArrayList<>((int)Math.ceil(str.length()/(double)chunkSize));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYwNzQ1MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    for (int i = 0; i < str.length();i += chunkSize) {\n          \n          \n            \n                    for (int i = 0; i < str.length(); i += chunkSize) {", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447607451", "createdAt": "2020-06-30T11:20:52Z", "author": {"login": "tveasey"}, "path": "x-pack/plugin/ml/src/internalClusterTest/java/org/elasticsearch/xpack/ml/integration/ChunkedTrainedMoodelPersisterIT.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.integration;\n+\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.action.util.PageParams;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsDest;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsSource;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.MlInferenceNamedXContentProvider;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinition;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinitionTests;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInputTests;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.TargetType;\n+import org.elasticsearch.xpack.ml.MlSingleNodeTestCase;\n+import org.elasticsearch.xpack.ml.dataframe.process.ChunkedTrainedModelPersister;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.DocValueField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.inference.modelsize.MlModelSizeNamedXContentProvider;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfoTests;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+import org.junit.Before;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Set;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+\n+public class ChunkedTrainedMoodelPersisterIT extends MlSingleNodeTestCase {\n+\n+    private TrainedModelProvider trainedModelProvider;\n+\n+    @Before\n+    public void createComponents() throws Exception {\n+        trainedModelProvider = new TrainedModelProvider(client(), xContentRegistry());\n+        waitForMlTemplates();\n+    }\n+\n+    public void testStoreModelViaChunkedPersister() throws IOException {\n+        String modelId = \"stored-chunked-model\";\n+        DataFrameAnalyticsConfig analyticsConfig = new DataFrameAnalyticsConfig.Builder()\n+            .setId(modelId)\n+            .setSource(new DataFrameAnalyticsSource(new String[] {\"my_source\"}, null, null))\n+            .setDest(new DataFrameAnalyticsDest(\"my_dest\", null))\n+            .setAnalysis(new Regression(\"foo\"))\n+            .build();\n+        List<ExtractedField> extractedFieldList = Collections.singletonList(new DocValueField(\"foo\", Collections.emptySet()));\n+        TrainedModelConfig.Builder configBuilder = buildTrainedModelConfigBuilder(modelId);\n+        String compressedDefinition = configBuilder.build().getCompressedDefinition();\n+        int totalSize = compressedDefinition.length();\n+        List<String> chunks = chunkStringWithSize(compressedDefinition, totalSize/3);\n+\n+        ChunkedTrainedModelPersister persister = new ChunkedTrainedModelPersister(trainedModelProvider,\n+            analyticsConfig,\n+            new DataFrameAnalyticsAuditor(client(), \"test-node\"),\n+            (ex) -> { throw new ElasticsearchException(ex); },\n+            new ExtractedFields(extractedFieldList, Collections.emptyMap())\n+        );\n+\n+        //Accuracy for size is not tested here\n+        ModelSizeInfo modelSizeInfo = ModelSizeInfoTests.createRandom();\n+        persister.createAndIndexInferenceModelMetadata(modelSizeInfo);\n+        for (int i = 0; i < chunks.size(); i++) {\n+            persister.createAndIndexInferenceModelDoc(new TrainedModelDefinitionChunk(chunks.get(i), i, i == (chunks.size() - 1)));\n+        }\n+\n+        PlainActionFuture<Tuple<Long, Set<String>>> getIdsFuture = new PlainActionFuture<>();\n+        trainedModelProvider.expandIds(modelId + \"*\", false, PageParams.defaultParams(), Collections.emptySet(), getIdsFuture);\n+        Tuple<Long, Set<String>> ids = getIdsFuture.actionGet();\n+        assertThat(ids.v1(), equalTo(1L));\n+\n+        PlainActionFuture<TrainedModelConfig> getTrainedModelFuture = new PlainActionFuture<>();\n+        trainedModelProvider.getTrainedModel(ids.v2().iterator().next(), true, getTrainedModelFuture);\n+\n+        TrainedModelConfig storedConfig = getTrainedModelFuture.actionGet();\n+        assertThat(storedConfig.getCompressedDefinition(), equalTo(compressedDefinition));\n+        assertThat(storedConfig.getEstimatedOperations(), equalTo((long)modelSizeInfo.numOperations()));\n+        assertThat(storedConfig.getEstimatedHeapMemory(), equalTo(modelSizeInfo.ramBytesUsed()));\n+    }\n+\n+    private static TrainedModelConfig.Builder buildTrainedModelConfigBuilder(String modelId) {\n+        TrainedModelDefinition.Builder definitionBuilder = TrainedModelDefinitionTests.createRandomBuilder();\n+        long bytesUsed = definitionBuilder.build().ramBytesUsed();\n+        long operations = definitionBuilder.build().getTrainedModel().estimatedNumOperations();\n+        return TrainedModelConfig.builder()\n+            .setCreatedBy(\"ml_test\")\n+            .setParsedDefinition(TrainedModelDefinitionTests.createRandomBuilder(TargetType.REGRESSION))\n+            .setDescription(\"trained model config for test\")\n+            .setModelId(modelId)\n+            .setVersion(Version.CURRENT)\n+            .setLicenseLevel(License.OperationMode.PLATINUM.description())\n+            .setEstimatedHeapMemory(bytesUsed)\n+            .setEstimatedOperations(operations)\n+            .setInput(TrainedModelInputTests.createRandomInput());\n+    }\n+\n+    private static List<String> chunkStringWithSize(String str, int chunkSize) {\n+        List<String> subStrings = new ArrayList<>((int)Math.ceil(str.length()/(double)chunkSize));\n+        for (int i = 0; i < str.length();i += chunkSize) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYyOTc1Ng==", "bodyText": "There's an asymmetry here with createAndIndexInferenceModelMetadata , which nicely separates setup and teardown from logic to write the docs, maybe it would be worth factoring this out into a storeTrainedModel function?", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447629756", "createdAt": "2020-06-30T12:04:24Z", "author": {"login": "tveasey"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;\n+                    LOGGER.info(\n+                        \"[{}] finished stored trained model definition chunks with id [{}]\",\n+                        analytics.getId(),\n+                        this.currentModelId.get());\n+                    auditor.info(analytics.getId(), \"Stored trained model with id [\" + this.currentModelId.get() + \"]\");\n+                    CountDownLatch refreshLatch = new CountDownLatch(1);\n+                    provider.refreshInferenceIndex(\n+                        new LatchedActionListener<>(ActionListener.wrap(\n+                            refreshResponse -> LOGGER.debug(() -> new ParameterizedMessage(\n+                                \"[{}] refreshed inference index after model store\",\n+                                analytics.getId()\n+                            )),\n+                            e -> LOGGER.warn(\"[{}] failed to refresh inference index after model store\", analytics.getId())),\n+                            refreshLatch));\n+                    try {\n+                        if (refreshLatch.await(30, TimeUnit.SECONDS) == false) {\n+                            LOGGER.error(\"[{}] Timed out (30s) waiting for index refresh\", analytics.getId());\n+                        }\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                }\n+            },\n+            e -> failureHandler.accept(ExceptionsHelper.serverError(\"error storing trained model definition chunk [{}] with id [{}]\", e,\n+                trainedModelDefinitionDoc.getModelId(), trainedModelDefinitionDoc.getDocNum()))\n+        );", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY0MDIwOQ==", "bodyText": "Maybe I missed them, but I don't see any tests for missing or truncated state. Maybe worth testing these error cases?", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447640209", "createdAt": "2020-06-30T12:22:49Z", "author": {"login": "tveasey"}, "path": "x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersisterTests.java", "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsDest;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsSource;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.DocValueField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfoTests;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+import org.junit.Before;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Mockito;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.hamcrest.Matchers.contains;\n+import static org.hamcrest.Matchers.containsString;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasKey;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Matchers.eq;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+\n+public class ChunkedTrainedModelPersisterTests extends ESTestCase {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 52}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM5OTQ2NjY5", "url": "https://github.com/elastic/elasticsearch/pull/58009#pullrequestreview-439946669", "createdAt": "2020-06-30T12:05:52Z", "commit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMjowNTo1M1rOGq5NBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMzo1NToxNVrOGq9jJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYzMDU5Nw==", "bodyText": "FYI you can achieve the same with integer maths\n(str.length() + chunkSize -1) / chunkSize", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447630597", "createdAt": "2020-06-30T12:05:53Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/internalClusterTest/java/org/elasticsearch/xpack/ml/integration/ChunkedTrainedMoodelPersisterIT.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.integration;\n+\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.action.util.PageParams;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsDest;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsSource;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.MlInferenceNamedXContentProvider;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinition;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinitionTests;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInputTests;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.TargetType;\n+import org.elasticsearch.xpack.ml.MlSingleNodeTestCase;\n+import org.elasticsearch.xpack.ml.dataframe.process.ChunkedTrainedModelPersister;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.DocValueField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.inference.modelsize.MlModelSizeNamedXContentProvider;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfoTests;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+import org.junit.Before;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Set;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+\n+public class ChunkedTrainedMoodelPersisterIT extends MlSingleNodeTestCase {\n+\n+    private TrainedModelProvider trainedModelProvider;\n+\n+    @Before\n+    public void createComponents() throws Exception {\n+        trainedModelProvider = new TrainedModelProvider(client(), xContentRegistry());\n+        waitForMlTemplates();\n+    }\n+\n+    public void testStoreModelViaChunkedPersister() throws IOException {\n+        String modelId = \"stored-chunked-model\";\n+        DataFrameAnalyticsConfig analyticsConfig = new DataFrameAnalyticsConfig.Builder()\n+            .setId(modelId)\n+            .setSource(new DataFrameAnalyticsSource(new String[] {\"my_source\"}, null, null))\n+            .setDest(new DataFrameAnalyticsDest(\"my_dest\", null))\n+            .setAnalysis(new Regression(\"foo\"))\n+            .build();\n+        List<ExtractedField> extractedFieldList = Collections.singletonList(new DocValueField(\"foo\", Collections.emptySet()));\n+        TrainedModelConfig.Builder configBuilder = buildTrainedModelConfigBuilder(modelId);\n+        String compressedDefinition = configBuilder.build().getCompressedDefinition();\n+        int totalSize = compressedDefinition.length();\n+        List<String> chunks = chunkStringWithSize(compressedDefinition, totalSize/3);\n+\n+        ChunkedTrainedModelPersister persister = new ChunkedTrainedModelPersister(trainedModelProvider,\n+            analyticsConfig,\n+            new DataFrameAnalyticsAuditor(client(), \"test-node\"),\n+            (ex) -> { throw new ElasticsearchException(ex); },\n+            new ExtractedFields(extractedFieldList, Collections.emptyMap())\n+        );\n+\n+        //Accuracy for size is not tested here\n+        ModelSizeInfo modelSizeInfo = ModelSizeInfoTests.createRandom();\n+        persister.createAndIndexInferenceModelMetadata(modelSizeInfo);\n+        for (int i = 0; i < chunks.size(); i++) {\n+            persister.createAndIndexInferenceModelDoc(new TrainedModelDefinitionChunk(chunks.get(i), i, i == (chunks.size() - 1)));\n+        }\n+\n+        PlainActionFuture<Tuple<Long, Set<String>>> getIdsFuture = new PlainActionFuture<>();\n+        trainedModelProvider.expandIds(modelId + \"*\", false, PageParams.defaultParams(), Collections.emptySet(), getIdsFuture);\n+        Tuple<Long, Set<String>> ids = getIdsFuture.actionGet();\n+        assertThat(ids.v1(), equalTo(1L));\n+\n+        PlainActionFuture<TrainedModelConfig> getTrainedModelFuture = new PlainActionFuture<>();\n+        trainedModelProvider.getTrainedModel(ids.v2().iterator().next(), true, getTrainedModelFuture);\n+\n+        TrainedModelConfig storedConfig = getTrainedModelFuture.actionGet();\n+        assertThat(storedConfig.getCompressedDefinition(), equalTo(compressedDefinition));\n+        assertThat(storedConfig.getEstimatedOperations(), equalTo((long)modelSizeInfo.numOperations()));\n+        assertThat(storedConfig.getEstimatedHeapMemory(), equalTo(modelSizeInfo.ramBytesUsed()));\n+    }\n+\n+    private static TrainedModelConfig.Builder buildTrainedModelConfigBuilder(String modelId) {\n+        TrainedModelDefinition.Builder definitionBuilder = TrainedModelDefinitionTests.createRandomBuilder();\n+        long bytesUsed = definitionBuilder.build().ramBytesUsed();\n+        long operations = definitionBuilder.build().getTrainedModel().estimatedNumOperations();\n+        return TrainedModelConfig.builder()\n+            .setCreatedBy(\"ml_test\")\n+            .setParsedDefinition(TrainedModelDefinitionTests.createRandomBuilder(TargetType.REGRESSION))\n+            .setDescription(\"trained model config for test\")\n+            .setModelId(modelId)\n+            .setVersion(Version.CURRENT)\n+            .setLicenseLevel(License.OperationMode.PLATINUM.description())\n+            .setEstimatedHeapMemory(bytesUsed)\n+            .setEstimatedOperations(operations)\n+            .setInput(TrainedModelInputTests.createRandomInput());\n+    }\n+\n+    private static List<String> chunkStringWithSize(String str, int chunkSize) {\n+        List<String> subStrings = new ArrayList<>((int)Math.ceil(str.length()/(double)chunkSize));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY0ODIyMA==", "bodyText": "Log the exception also\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                        refreshLatch));\n          \n          \n            \n            e -> LOGGER.warn(\"new ParameterizedMessage([{}] failed to refresh inference index after model store\", analytics.getId()), e),", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447648220", "createdAt": "2020-06-30T12:37:03Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;\n+                    LOGGER.info(\n+                        \"[{}] finished stored trained model definition chunks with id [{}]\",\n+                        analytics.getId(),\n+                        this.currentModelId.get());\n+                    auditor.info(analytics.getId(), \"Stored trained model with id [\" + this.currentModelId.get() + \"]\");\n+                    CountDownLatch refreshLatch = new CountDownLatch(1);\n+                    provider.refreshInferenceIndex(\n+                        new LatchedActionListener<>(ActionListener.wrap(\n+                            refreshResponse -> LOGGER.debug(() -> new ParameterizedMessage(\n+                                \"[{}] refreshed inference index after model store\",\n+                                analytics.getId()\n+                            )),\n+                            e -> LOGGER.warn(\"[{}] failed to refresh inference index after model store\", analytics.getId())),\n+                            refreshLatch));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY1NTM1Mg==", "bodyText": "The log level shouldn't be any higher than debug.\nSame for the finished stored trained model definition chunks with id  message above", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447655352", "createdAt": "2020-06-30T12:48:48Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;\n+                    LOGGER.info(\n+                        \"[{}] finished stored trained model definition chunks with id [{}]\",\n+                        analytics.getId(),\n+                        this.currentModelId.get());\n+                    auditor.info(analytics.getId(), \"Stored trained model with id [\" + this.currentModelId.get() + \"]\");\n+                    CountDownLatch refreshLatch = new CountDownLatch(1);\n+                    provider.refreshInferenceIndex(\n+                        new LatchedActionListener<>(ActionListener.wrap(\n+                            refreshResponse -> LOGGER.debug(() -> new ParameterizedMessage(\n+                                \"[{}] refreshed inference index after model store\",\n+                                analytics.getId()\n+                            )),\n+                            e -> LOGGER.warn(\"[{}] failed to refresh inference index after model store\", analytics.getId())),\n+                            refreshLatch));\n+                    try {\n+                        if (refreshLatch.await(30, TimeUnit.SECONDS) == false) {\n+                            LOGGER.error(\"[{}] Timed out (30s) waiting for index refresh\", analytics.getId());\n+                        }\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                }\n+            },\n+            e -> failureHandler.accept(ExceptionsHelper.serverError(\"error storing trained model definition chunk [{}] with id [{}]\", e,\n+                trainedModelDefinitionDoc.getModelId(), trainedModelDefinitionDoc.getDocNum()))\n+        );\n+        provider.storeTrainedModelDefinitionDoc(trainedModelDefinitionDoc, new LatchedActionListener<>(storeListener, latch));\n+        try {\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for chunked inference definition to be stored\", analytics.getId());\n+            }\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            failureHandler.accept(ExceptionsHelper.serverError(\"interrupted waiting for chunked inference definition to be stored\"));\n+        }\n+    }\n+\n+    public void createAndIndexInferenceModelMetadata(ModelSizeInfo inferenceModelSize) {\n+        if (readyToStoreNewModel == false) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"new inference model is attempting to be stored before completion previous model storage\"\n+            ));\n+            return;\n+        }\n+        TrainedModelConfig trainedModelConfig = createTrainedModelConfig(inferenceModelSize);\n+        CountDownLatch latch = storeTrainedModelMetadata(trainedModelConfig);\n+        try {\n+            readyToStoreNewModel = false;\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for inference model metadata to be stored\", analytics.getId());\n+            }\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            failureHandler.accept(ExceptionsHelper.serverError(\"interrupted waiting for inference model metadata to be stored\"));\n+        }\n+    }\n+\n+    private CountDownLatch storeTrainedModelMetadata(TrainedModelConfig trainedModelConfig) {\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Boolean> storeListener = ActionListener.wrap(\n+            aBoolean -> {\n+                if (aBoolean == false) {\n+                    LOGGER.error(\"[{}] Storing trained model metadata responded false\", analytics.getId());\n+                    failureHandler.accept(ExceptionsHelper.serverError(\"storing trained model responded false\"));\n+                } else {\n+                    LOGGER.info(\"[{}] Stored trained model metadata with id [{}]\", analytics.getId(), trainedModelConfig.getModelId());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 156}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY4MTExMw==", "bodyText": "Add a boolean parameter here to refresh the index when the last doc is indexed that way you don't have to call  provider.refreshInferenceIndex() in the listener", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447681113", "createdAt": "2020-06-30T13:27:41Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;\n+                    LOGGER.info(\n+                        \"[{}] finished stored trained model definition chunks with id [{}]\",\n+                        analytics.getId(),\n+                        this.currentModelId.get());\n+                    auditor.info(analytics.getId(), \"Stored trained model with id [\" + this.currentModelId.get() + \"]\");\n+                    CountDownLatch refreshLatch = new CountDownLatch(1);\n+                    provider.refreshInferenceIndex(\n+                        new LatchedActionListener<>(ActionListener.wrap(\n+                            refreshResponse -> LOGGER.debug(() -> new ParameterizedMessage(\n+                                \"[{}] refreshed inference index after model store\",\n+                                analytics.getId()\n+                            )),\n+                            e -> LOGGER.warn(\"[{}] failed to refresh inference index after model store\", analytics.getId())),\n+                            refreshLatch));\n+                    try {\n+                        if (refreshLatch.await(30, TimeUnit.SECONDS) == false) {\n+                            LOGGER.error(\"[{}] Timed out (30s) waiting for index refresh\", analytics.getId());\n+                        }\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                }\n+            },\n+            e -> failureHandler.accept(ExceptionsHelper.serverError(\"error storing trained model definition chunk [{}] with id [{}]\", e,\n+                trainedModelDefinitionDoc.getModelId(), trainedModelDefinitionDoc.getDocNum()))\n+        );\n+        provider.storeTrainedModelDefinitionDoc(trainedModelDefinitionDoc, new LatchedActionListener<>(storeListener, latch));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY4NzYzMw==", "bodyText": "Ok the equivalent message before was logged at info but lets consider if this is necessary", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447687633", "createdAt": "2020-06-30T13:36:18Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;\n+                    LOGGER.info(\n+                        \"[{}] finished stored trained model definition chunks with id [{}]\",\n+                        analytics.getId(),\n+                        this.currentModelId.get());\n+                    auditor.info(analytics.getId(), \"Stored trained model with id [\" + this.currentModelId.get() + \"]\");\n+                    CountDownLatch refreshLatch = new CountDownLatch(1);\n+                    provider.refreshInferenceIndex(\n+                        new LatchedActionListener<>(ActionListener.wrap(\n+                            refreshResponse -> LOGGER.debug(() -> new ParameterizedMessage(\n+                                \"[{}] refreshed inference index after model store\",\n+                                analytics.getId()\n+                            )),\n+                            e -> LOGGER.warn(\"[{}] failed to refresh inference index after model store\", analytics.getId())),\n+                            refreshLatch));\n+                    try {\n+                        if (refreshLatch.await(30, TimeUnit.SECONDS) == false) {\n+                            LOGGER.error(\"[{}] Timed out (30s) waiting for index refresh\", analytics.getId());\n+                        }\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                }\n+            },\n+            e -> failureHandler.accept(ExceptionsHelper.serverError(\"error storing trained model definition chunk [{}] with id [{}]\", e,\n+                trainedModelDefinitionDoc.getModelId(), trainedModelDefinitionDoc.getDocNum()))\n+        );\n+        provider.storeTrainedModelDefinitionDoc(trainedModelDefinitionDoc, new LatchedActionListener<>(storeListener, latch));\n+        try {\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for chunked inference definition to be stored\", analytics.getId());\n+            }\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            failureHandler.accept(ExceptionsHelper.serverError(\"interrupted waiting for chunked inference definition to be stored\"));\n+        }\n+    }\n+\n+    public void createAndIndexInferenceModelMetadata(ModelSizeInfo inferenceModelSize) {\n+        if (readyToStoreNewModel == false) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"new inference model is attempting to be stored before completion previous model storage\"\n+            ));\n+            return;\n+        }\n+        TrainedModelConfig trainedModelConfig = createTrainedModelConfig(inferenceModelSize);\n+        CountDownLatch latch = storeTrainedModelMetadata(trainedModelConfig);\n+        try {\n+            readyToStoreNewModel = false;\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for inference model metadata to be stored\", analytics.getId());\n+            }\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            failureHandler.accept(ExceptionsHelper.serverError(\"interrupted waiting for inference model metadata to be stored\"));\n+        }\n+    }\n+\n+    private CountDownLatch storeTrainedModelMetadata(TrainedModelConfig trainedModelConfig) {\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Boolean> storeListener = ActionListener.wrap(\n+            aBoolean -> {\n+                if (aBoolean == false) {\n+                    LOGGER.error(\"[{}] Storing trained model metadata responded false\", analytics.getId());\n+                    failureHandler.accept(ExceptionsHelper.serverError(\"storing trained model responded false\"));\n+                } else {\n+                    LOGGER.info(\"[{}] Stored trained model metadata with id [{}]\", analytics.getId(), trainedModelConfig.getModelId());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY1NTM1Mg=="}, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 156}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzcwMTc5OA==", "bodyText": "Can the methods getTrainedModelForInference and getTrainedModel be refactored to avoid this duplication?", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447701798", "createdAt": "2020-06-30T13:55:15Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/persistence/TrainedModelProvider.java", "diffHunk": "@@ -363,10 +452,22 @@ public void getTrainedModel(final String modelId, final boolean includeDefinitio\n                         String compressedString = docs.stream()\n                             .map(TrainedModelDefinitionDoc::getCompressedString)\n                             .collect(Collectors.joining());\n-                        if (compressedString.length() != docs.get(0).getTotalDefinitionLength()) {\n-                            listener.onFailure(ExceptionsHelper.serverError(\n-                                Messages.getMessage(Messages.MODEL_DEFINITION_TRUNCATED, modelId)));\n-                            return;\n+                        // BWC for when we tracked the total definition length\n+                        // TODO: remove in 9\n+                        if (docs.get(0).getTotalDefinitionLength() != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 149}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b20fb0586874ab6bdd92e4ccda019245c25a708a", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/b20fb0586874ab6bdd92e4ccda019245c25a708a", "committedDate": "2020-06-30T14:36:45Z", "message": "addressing pr comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3ad327ef45cacc5c4b63b62d33a6ea799359f34d", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/3ad327ef45cacc5c4b63b62d33a6ea799359f34d", "committedDate": "2020-06-30T14:36:58Z", "message": "Merge remote-tracking branch 'upstream/master' into feature/ml-analytics-handle-compressed-model-stream"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQwMDk5NTEx", "url": "https://github.com/elastic/elasticsearch/pull/58009#pullrequestreview-440099511", "createdAt": "2020-06-30T14:53:37Z", "commit": {"oid": "b20fb0586874ab6bdd92e4ccda019245c25a708a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxNDo1MzozN1rOGrAVqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxNDo1MzozN1rOGrAVqA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc0NzQ5Ng==", "bodyText": "Is this valid here? i.e. should you be allowing this to start storing new models before logging, etc. Seems like there is a race to reset the currentModelId.", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447747496", "createdAt": "2020-06-30T14:53:37Z", "author": {"login": "tveasey"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -135,29 +105,86 @@ public void createAndIndexInferenceModelMetadata(ModelSizeInfo inferenceModelSiz\n         TrainedModelConfig trainedModelConfig = createTrainedModelConfig(inferenceModelSize);\n         CountDownLatch latch = storeTrainedModelMetadata(trainedModelConfig);\n         try {\n-            readyToStoreNewModel = false;\n-            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+            if (latch.await(STORE_TIMEOUT_SEC, TimeUnit.SECONDS) == false) {\n                 LOGGER.error(\"[{}] Timed out (30s) waiting for inference model metadata to be stored\", analytics.getId());\n             }\n         } catch (InterruptedException e) {\n             Thread.currentThread().interrupt();\n+            this.readyToStoreNewModel.set(true);\n             failureHandler.accept(ExceptionsHelper.serverError(\"interrupted waiting for inference model metadata to be stored\"));\n         }\n     }\n \n+    private CountDownLatch storeTrainedModelDoc(TrainedModelDefinitionDoc trainedModelDefinitionDoc) {\n+        CountDownLatch latch = new CountDownLatch(1);\n+\n+        // Latch is attached to this action as it is the last one to execute.\n+        ActionListener<RefreshResponse> refreshListener = new LatchedActionListener<>(ActionListener.wrap(\n+            refreshed -> {\n+                if (refreshed != null) {\n+                    LOGGER.debug(() -> new ParameterizedMessage(\n+                        \"[{}] refreshed inference index after model store\",\n+                        analytics.getId()\n+                    ));\n+                }\n+            },\n+            e -> LOGGER.warn(\n+                new ParameterizedMessage(\"[{}] failed to refresh inference index after model store\", analytics.getId()),\n+                e)\n+        ), latch);\n+\n+        // First, store the model and refresh is necessary\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+                if (trainedModelDefinitionDoc.isEos() == false) {\n+                    refreshListener.onResponse(null);\n+                    return;\n+                }\n+                readyToStoreNewModel.set(true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b20fb0586874ab6bdd92e4ccda019245c25a708a"}, "originalPosition": 142}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "398d9f94f7e200f968f9f5411c690c62cd7bd711", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/398d9f94f7e200f968f9f5411c690c62cd7bd711", "committedDate": "2020-06-30T14:58:40Z", "message": "moving boolean flag"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQwMTA3NDA3", "url": "https://github.com/elastic/elasticsearch/pull/58009#pullrequestreview-440107407", "createdAt": "2020-06-30T15:01:24Z", "commit": {"oid": "398d9f94f7e200f968f9f5411c690c62cd7bd711"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQwNjYzNzk4", "url": "https://github.com/elastic/elasticsearch/pull/58009#pullrequestreview-440663798", "createdAt": "2020-07-01T08:39:16Z", "commit": {"oid": "398d9f94f7e200f968f9f5411c690c62cd7bd711"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQwODozOToxNlrOGrcgeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQwODozOToxNlrOGrcgeQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODIwOTAxNw==", "bodyText": "IntStream.range is end exclusive so we will never get to i == chunks.size() - 1\nShould it be set to false as Eos is set on the last doc in the list in line 223", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r448209017", "createdAt": "2020-07-01T08:39:16Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/internalClusterTest/java/org/elasticsearch/xpack/ml/integration/TrainedModelProviderIT.java", "diffHunk": "@@ -195,6 +198,51 @@ public void testGetTruncatedModelDefinition() throws Exception {\n         assertThat(exceptionHolder.get().getMessage(), equalTo(Messages.getMessage(Messages.MODEL_DEFINITION_TRUNCATED, modelId)));\n     }\n \n+    public void testGetTruncatedModelDefinition() throws Exception {\n+        String modelId = \"test-get-truncated-model-config\";\n+        TrainedModelConfig config = buildTrainedModelConfig(modelId);\n+        AtomicReference<Boolean> putConfigHolder = new AtomicReference<>();\n+        AtomicReference<Exception> exceptionHolder = new AtomicReference<>();\n+\n+        blockingCall(listener -> trainedModelProvider.storeTrainedModel(config, listener), putConfigHolder, exceptionHolder);\n+        assertThat(putConfigHolder.get(), is(true));\n+        assertThat(exceptionHolder.get(), is(nullValue()));\n+\n+        List<String> chunks = chunkStringWithSize(config.getCompressedDefinition(), config.getCompressedDefinition().length()/3);\n+\n+        List<TrainedModelDefinitionDoc.Builder> docBuilders = IntStream.range(0, chunks.size() - 1)\n+            .mapToObj(i -> new TrainedModelDefinitionDoc.Builder()\n+                .setDocNum(i)\n+                .setCompressedString(chunks.get(i))\n+                .setCompressionVersion(TrainedModelConfig.CURRENT_DEFINITION_COMPRESSION_VERSION)\n+                .setDefinitionLength(chunks.get(i).length())\n+                .setEos(i == chunks.size() - 1)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "398d9f94f7e200f968f9f5411c690c62cd7bd711"}, "originalPosition": 45}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "caed31555c00c2060cfb0530ce3ed0647660d076", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/caed31555c00c2060cfb0530ce3ed0647660d076", "committedDate": "2020-07-01T10:52:37Z", "message": "fixing test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dc25e38cba9eee95b97c7952ef6a2c2efa9e394c", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/dc25e38cba9eee95b97c7952ef6a2c2efa9e394c", "committedDate": "2020-07-01T11:15:38Z", "message": "Merge remote-tracking branch 'upstream/master' into feature/ml-analytics-handle-compressed-model-stream"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQwNzg2NzU5", "url": "https://github.com/elastic/elasticsearch/pull/58009#pullrequestreview-440786759", "createdAt": "2020-07-01T11:33:35Z", "commit": {"oid": "dc25e38cba9eee95b97c7952ef6a2c2efa9e394c"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMTozMzozNVrOGriJLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMTo0Mjo0NlrOGriZ3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMwMTM1OQ==", "bodyText": "nit: now that STORE_TIMEOUT_SEC is a constant, the log message can use it as argument (in other places, too)", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r448301359", "createdAt": "2020-07-01T11:33:35Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.action.admin.indices.refresh.RefreshResponse;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private static final int STORE_TIMEOUT_SEC = 30;\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private final AtomicBoolean readyToStoreNewModel = new AtomicBoolean(true);\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = storeTrainedModelDoc(trainedModelDefinitionDoc);\n+        try {\n+            if (latch.await(STORE_TIMEOUT_SEC, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for chunked inference definition to be stored\", analytics.getId());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dc25e38cba9eee95b97c7952ef6a2c2efa9e394c"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMwNTYyOQ==", "bodyText": "do we need a 3rd state (null)?\nin code it looks like null and false are false.\nit seems simpler to me to use boolean and handle null as part of parsing", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r448305629", "createdAt": "2020-07-01T11:42:46Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/results/TrainedModelDefinitionChunk.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process.results;\n+\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+\n+import java.io.IOException;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.optionalConstructorArg;\n+\n+public class TrainedModelDefinitionChunk implements ToXContentObject {\n+\n+    private static final ParseField DEFINITION = new ParseField(\"definition\");\n+    private static final ParseField DOC_NUM = new ParseField(\"doc_num\");\n+    private static final ParseField EOS = new ParseField(\"eos\");\n+\n+    public static final ConstructingObjectParser<TrainedModelDefinitionChunk, Void> PARSER = new ConstructingObjectParser<>(\n+        \"chunked_trained_model_definition\",\n+        a -> new TrainedModelDefinitionChunk((String) a[0], (Integer) a[1], (Boolean) a[2]));\n+\n+    static {\n+        PARSER.declareString(constructorArg(), DEFINITION);\n+        PARSER.declareInt(constructorArg(), DOC_NUM);\n+        PARSER.declareBoolean(optionalConstructorArg(), EOS);\n+    }\n+\n+    private final String definition;\n+    private final int docNum;\n+    private final Boolean eos;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dc25e38cba9eee95b97c7952ef6a2c2efa9e394c"}, "originalPosition": 40}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 795, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}