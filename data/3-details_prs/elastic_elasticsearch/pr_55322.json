{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA0NDkzOTMy", "number": 55322, "title": "Allow to prewarm the cache for searchable snapshot shards", "bodyText": "This pull requests adds a way to prewarm the cache for searchable snapshot shard files.\nIt relies on a new index setting named index.store.snapshot.cache.load.eagerly (defaults to false) that can be passed when mounting a snapshot as an index. This setting is detected during the pre-recovery step before the snapshot files are exposed to the other components of the system. The method prewarmCache() of the SearchableSnapshotDirectory instance is executed, which builds the list of all parts of snapshot files that needs to be prefetched in cache (excluding the files that are stored in metadata hash and the ones explicitly excluded by the excluded_file_types setting).\nThen parts are prefetched in cache in parallel using the SNAPSHOT thread pool. If a snapshot file is composed of multiple parts (or chunks) then the parts can potentially be downloaded and written in cache concurrently. The implementation relies on a new prefetchPart() method added to the  CachedBlobContainerIndexInput class. This method allows to fetch a complete part of a file (or the whole file if the snapshot file is composed of a single part) in order to write it in cache. This is possible because CacheFile has been modified to work with configurable cache range sizes depending on the IOContext the IndexInput has been opened with.\nWhen the IndexInput is opened using the specific CACHE_WARMING_CONTEXT context then the file is cached on disk using large ranges of bytes aligned on the beginning and the end of each part (or chunk) of the file. When using a different context then the fill is cached on disk using the normal cache range size defined through the range_size setting. This implementation allows to reuse the existing cache eviction mechanism if something goes wrong when reading or writing the part. It also simplifies the logic if the recovering shard is closed while prewarming the cache.", "createdAt": "2020-04-16T15:57:42Z", "url": "https://github.com/elastic/elasticsearch/pull/55322", "merged": true, "mergeCommit": {"oid": "bd40d06648b6149dcbea583973f5e2d8979ea1cd"}, "closed": true, "closedAt": "2020-04-24T15:47:51Z", "author": {"login": "tlrx"}, "timelineItems": {"totalCount": 24, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcYOHdagH2gAyNDA0NDkzOTMyOjI1N2EwMGE3NGU3NjUxOTExMmRkZTkxOTU0ZWQyZTc5MWYwODYzOWQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcay23vAH2gAyNDA0NDkzOTMyOmJhYTgyNTgyODNlYjkxYTQ1ZDNmYzQzMzMyMGJjZTBhOGFhY2ExOTE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "257a00a74e76519112dde91954ed2e791f08639d", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/257a00a74e76519112dde91954ed2e791f08639d", "committedDate": "2020-04-16T15:07:05Z", "message": "Add cache prewarming"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk0Nzc3MTgy", "url": "https://github.com/elastic/elasticsearch/pull/55322#pullrequestreview-394777182", "createdAt": "2020-04-16T15:58:23Z", "commit": {"oid": "257a00a74e76519112dde91954ed2e791f08639d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNTo1ODoyNFrOGGsQQA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNTo1ODoyNFrOGGsQQA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY2OTY5Ng==", "bodyText": "Better name suggestions are welcome", "url": "https://github.com/elastic/elasticsearch/pull/55322#discussion_r409669696", "createdAt": "2020-04-16T15:58:24Z", "author": {"login": "tlrx"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -115,8 +135,10 @@ public SearchableSnapshotDirectory(\n         this.cacheDir = Objects.requireNonNull(cacheDir);\n         this.closed = new AtomicBoolean(false);\n         this.useCache = SNAPSHOT_CACHE_ENABLED_SETTING.get(indexSettings);\n+        this.loadCacheEagerly = useCache ? SNAPSHOT_CACHE_LOAD_EAGERLY_SETTING.get(indexSettings) : false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "257a00a74e76519112dde91954ed2e791f08639d"}, "originalPosition": 84}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk0Nzc4Mzgy", "url": "https://github.com/elastic/elasticsearch/pull/55322#pullrequestreview-394778382", "createdAt": "2020-04-16T15:59:46Z", "commit": {"oid": "257a00a74e76519112dde91954ed2e791f08639d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNTo1OTo0N1rOGGsUAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNTo1OTo0N1rOGGsUAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY3MDY1Ng==", "bodyText": "This methods blocks until the cache is fully prewarmed. It must be done before loaded is set to true so that other components of the system are not likely to trigger some caching on this directory files.", "url": "https://github.com/elastic/elasticsearch/pull/55322#discussion_r409670656", "createdAt": "2020-04-16T15:59:47Z", "author": {"login": "tlrx"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -142,18 +164,21 @@ protected final boolean assertCurrentThreadMayLoadSnapshot() {\n      * @return true if the snapshot was loaded by executing this method, false otherwise\n      */\n     public boolean loadSnapshot() {\n+        assert assertCurrentThreadMayLoadSnapshot();\n         boolean alreadyLoaded = this.loaded;\n         if (alreadyLoaded == false) {\n             synchronized (this) {\n                 alreadyLoaded = this.loaded;\n                 if (alreadyLoaded == false) {\n                     this.blobContainer = blobContainerSupplier.get();\n                     this.snapshot = snapshotSupplier.get();\n+                    if (loadCacheEagerly) {\n+                        prewarmCache();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "257a00a74e76519112dde91954ed2e791f08639d"}, "originalPosition": 104}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk0Nzc5MDM4", "url": "https://github.com/elastic/elasticsearch/pull/55322#pullrequestreview-394779038", "createdAt": "2020-04-16T16:00:32Z", "commit": {"oid": "257a00a74e76519112dde91954ed2e791f08639d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNjowMDozMlrOGGsWIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNjowMDozMlrOGGsWIA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY3MTIwMA==", "bodyText": "Splitting this method into two allows to open an IndexInput even if the snapshot is not marked as loaded yet", "url": "https://github.com/elastic/elasticsearch/pull/55322#discussion_r409671200", "createdAt": "2020-04-16T16:00:32Z", "author": {"login": "tlrx"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -290,17 +315,20 @@ public CacheFile getCacheFile(CacheKey cacheKey, long fileLength) throws Excepti\n \n     @Override\n     public IndexInput openInput(final String name, final IOContext context) throws IOException {\n-        ensureOpen();\n+        return openInput(fileInfo(name), context);\n+    }\n \n-        final BlobStoreIndexShardSnapshot.FileInfo fileInfo = fileInfo(name);\n+    private IndexInput openInput(final BlobStoreIndexShardSnapshot.FileInfo fileInfo, final IOContext context) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "257a00a74e76519112dde91954ed2e791f08639d"}, "originalPosition": 123}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk0NzgxMDQw", "url": "https://github.com/elastic/elasticsearch/pull/55322#pullrequestreview-394781040", "createdAt": "2020-04-16T16:02:51Z", "commit": {"oid": "257a00a74e76519112dde91954ed2e791f08639d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNjowMjo1MVrOGGscQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNjowMjo1MVrOGGscQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY3Mjc3MA==", "bodyText": "This method uses an IndexInput with a specific IOContext to prewarm the cache for the given Lucene file. The IndexInput will be cloned for each part to write in cache later and closed once all parts are processed.", "url": "https://github.com/elastic/elasticsearch/pull/55322#discussion_r409672770", "createdAt": "2020-04-16T16:02:51Z", "author": {"login": "tlrx"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -331,12 +359,133 @@ public String toString() {\n         return this.getClass().getSimpleName() + \"@snapshotId=\" + snapshotId + \" lockFactory=\" + lockFactory;\n     }\n \n+    private void prewarmCache() {\n+        assert Thread.holdsLock(this);\n+        assert loadCacheEagerly;\n+        assert useCache;\n+\n+        final BlockingQueue<CheckedRunnable<Exception>> queue = new SizeBlockingQueue<>(new LinkedBlockingQueue<>(), Integer.MAX_VALUE);\n+        for (BlobStoreIndexShardSnapshot.FileInfo file : snapshot().indexFiles()) {\n+            final String fileName = file.physicalName();\n+            if (isExcludedFromCache(fileName) == false && file.metadata().hashEqualsContents() == false) {\n+                final long numberOfParts = file.numberOfParts();\n+                if (queue.remainingCapacity() > numberOfParts) {\n+                    logger.debug(\n+                        \"{} prewarming cache for file [{}] of length [{}] and [{}] parts\",\n+                        shardId,\n+                        fileName,\n+                        file.length(),\n+                        numberOfParts\n+                    );\n+                    final long startTimeInNanos = statsCurrentTimeNanosSupplier.getAsLong();\n+                    try {\n+                        final IndexInput input = openInput(file, CachedBlobContainerIndexInput.CACHE_WARMING_CONTEXT);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "257a00a74e76519112dde91954ed2e791f08639d"}, "originalPosition": 162}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk0NzgxNjA2", "url": "https://github.com/elastic/elasticsearch/pull/55322#pullrequestreview-394781606", "createdAt": "2020-04-16T16:03:31Z", "commit": {"oid": "257a00a74e76519112dde91954ed2e791f08639d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNjowMzozMVrOGGseFA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNjowMzozMVrOGGseFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY3MzIzNg==", "bodyText": "This can happen in case of cache evictions or if the shard is closing", "url": "https://github.com/elastic/elasticsearch/pull/55322#discussion_r409673236", "createdAt": "2020-04-16T16:03:31Z", "author": {"login": "tlrx"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -331,12 +359,133 @@ public String toString() {\n         return this.getClass().getSimpleName() + \"@snapshotId=\" + snapshotId + \" lockFactory=\" + lockFactory;\n     }\n \n+    private void prewarmCache() {\n+        assert Thread.holdsLock(this);\n+        assert loadCacheEagerly;\n+        assert useCache;\n+\n+        final BlockingQueue<CheckedRunnable<Exception>> queue = new SizeBlockingQueue<>(new LinkedBlockingQueue<>(), Integer.MAX_VALUE);\n+        for (BlobStoreIndexShardSnapshot.FileInfo file : snapshot().indexFiles()) {\n+            final String fileName = file.physicalName();\n+            if (isExcludedFromCache(fileName) == false && file.metadata().hashEqualsContents() == false) {\n+                final long numberOfParts = file.numberOfParts();\n+                if (queue.remainingCapacity() > numberOfParts) {\n+                    logger.debug(\n+                        \"{} prewarming cache for file [{}] of length [{}] and [{}] parts\",\n+                        shardId,\n+                        fileName,\n+                        file.length(),\n+                        numberOfParts\n+                    );\n+                    final long startTimeInNanos = statsCurrentTimeNanosSupplier.getAsLong();\n+                    try {\n+                        final IndexInput input = openInput(file, CachedBlobContainerIndexInput.CACHE_WARMING_CONTEXT);\n+                        assert input instanceof CachedBlobContainerIndexInput : \"expected cached index input but got \" + input.getClass();\n+\n+                        final CountDown countDown = new CountDown(Math.toIntExact(numberOfParts));\n+                        for (long p = 0; p < numberOfParts; p++) {\n+                            final int part = Math.toIntExact(p);\n+                            queue.add(() -> {\n+                                try {\n+                                    final long partStartTimeInNanos = statsCurrentTimeNanosSupplier.getAsLong();\n+                                    final CachedBlobContainerIndexInput cachedIndexInput = (CachedBlobContainerIndexInput) input.clone();\n+                                    assert loaded == false : \"snapshot should not be fully loaded until all prewarming tasks are completed\";\n+\n+                                    final int bytesRead = cachedIndexInput.prefetchPart(part); // TODO does not include any rate limitation\n+                                    assert bytesRead == file.partBytes(part);\n+\n+                                    logger.trace(\n+                                        () -> new ParameterizedMessage(\n+                                            \"{} part [{}/{}] of length [{}] prewarmed in cache for file [{}] in [{}] ms\",\n+                                            shardId,\n+                                            part,\n+                                            numberOfParts,\n+                                            file.partBytes(part),\n+                                            fileName,\n+                                            TimeUnit.NANOSECONDS.toMillis(statsCurrentTimeNanosSupplier.getAsLong() - partStartTimeInNanos)\n+                                        )\n+                                    );\n+                                } finally {\n+                                    if (countDown.countDown()) {\n+                                        IOUtils.closeWhileHandlingException(input);\n+                                        logger.debug(\n+                                            \"{} cache prewarmed for file [{}] in [{}] ms\",\n+                                            shardId,\n+                                            fileName,\n+                                            TimeUnit.NANOSECONDS.toMillis(statsCurrentTimeNanosSupplier.getAsLong() - startTimeInNanos)\n+                                        );\n+                                    }\n+                                }\n+                            });\n+                        }\n+                    } catch (Exception e) {\n+                        logger.warn(() -> new ParameterizedMessage(\"{} failed to prewarm cache for file [{}]\", shardId, fileName), e);\n+                    }\n+                }\n+            }\n+        }\n+\n+        final String threadPoolName = ThreadPool.Names.SNAPSHOT;\n+        final Executor executor = threadPool.executor(threadPoolName);\n+        final int workers = Math.min(threadPool.info(threadPoolName).getMax(), queue.size());\n+\n+        final CountDownLatch latch = new CountDownLatch(workers);\n+        for (int i = 0; i < workers; ++i) {\n+            executor.execute(new AbstractRunnable() {\n+                @Override\n+                protected void doRun() throws Exception {\n+                    CheckedRunnable<Exception> loader;\n+                    while (isOpen && (loader = queue.poll(0L, TimeUnit.MILLISECONDS)) != null) {\n+                        try {\n+                            loader.run();\n+                        } catch (Exception e) {\n+                            if (e instanceof AlreadyClosedException\n+                                || (e.getCause() != null && e.getCause() instanceof AlreadyClosedException)) {\n+                                continue;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "257a00a74e76519112dde91954ed2e791f08639d"}, "originalPosition": 224}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk0NzgyOTAz", "url": "https://github.com/elastic/elasticsearch/pull/55322#pullrequestreview-394782903", "createdAt": "2020-04-16T16:04:57Z", "commit": {"oid": "257a00a74e76519112dde91954ed2e791f08639d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNjowNDo1N1rOGGsiKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNjowNDo1N1rOGGsiKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY3NDI4Mg==", "bodyText": "We included the rangeSize in the CacheFile to compute the range to fetch given a specific position, but we were never asserting that the fetched ranges really matched the size.", "url": "https://github.com/elastic/elasticsearch/pull/55322#discussion_r409674282", "createdAt": "2020-04-16T16:04:57Z", "author": {"login": "tlrx"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java", "diffHunk": "@@ -61,12 +61,11 @@ protected void closeInternal() {\n     @Nullable // if evicted, or there are no listeners\n     private volatile FileChannel channel;\n \n-    public CacheFile(String description, long length, Path file, int rangeSize) {\n+    public CacheFile(String description, long length, Path file) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "257a00a74e76519112dde91954ed2e791f08639d"}, "originalPosition": 21}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk0NzgzODk1", "url": "https://github.com/elastic/elasticsearch/pull/55322#pullrequestreview-394783895", "createdAt": "2020-04-16T16:06:04Z", "commit": {"oid": "257a00a74e76519112dde91954ed2e791f08639d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNjowNjowNFrOGGslHA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNjowNjowNFrOGGslHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY3NTAzNg==", "bodyText": "This asserts the size of the ranges written in cache, depending of the IOContext.", "url": "https://github.com/elastic/elasticsearch/pull/55322#discussion_r409675036", "createdAt": "2020-04-16T16:06:04Z", "author": {"login": "tlrx"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java", "diffHunk": "@@ -144,6 +208,7 @@ private void writeCacheFile(FileChannel fc, long start, long end) throws IOExcep\n         final long length = end - start;\n         final byte[] copyBuffer = new byte[Math.toIntExact(Math.min(COPY_BUFFER_SIZE, length))];\n         logger.trace(() -> new ParameterizedMessage(\"writing range [{}-{}] to cache file [{}]\", start, end, cacheFileReference));\n+        assert assertRangeOfBytesAlignment(start, end);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "257a00a74e76519112dde91954ed2e791f08639d"}, "originalPosition": 160}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk0ODU1Mzkw", "url": "https://github.com/elastic/elasticsearch/pull/55322#pullrequestreview-394855390", "createdAt": "2020-04-16T17:35:53Z", "commit": {"oid": "257a00a74e76519112dde91954ed2e791f08639d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNzozNTo1M1rOGGwEuQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNzozNTo1M1rOGGwEuQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTczMjI4MQ==", "bodyText": "I'm wondering if this is a source of contention; I'll investigate further.", "url": "https://github.com/elastic/elasticsearch/pull/55322#discussion_r409732281", "createdAt": "2020-04-16T17:35:53Z", "author": {"login": "tlrx"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java", "diffHunk": "@@ -131,6 +170,31 @@ protected void readInternal(final byte[] buffer, final int offset, final int len\n         lastSeekPosition = lastReadPosition;\n     }\n \n+    /**\n+     * Prefetches a complete part and writes it in cache. This method is used to prewarm the cache.\n+     */\n+    public int prefetchPart(final int part) throws IOException {\n+        ensureContext(ctx -> ctx == CACHE_WARMING_CONTEXT);\n+        if (part >= fileInfo.numberOfParts()) {\n+            throw new IllegalArgumentException(\"Unexpected part number [\" + part + \"]\");\n+        }\n+        final Tuple<Long, Long> range = computeRange(IntStream.range(0, part).mapToLong(fileInfo::partBytes).sum());\n+        try {\n+            final CacheFile cacheFile = getCacheFileSafe();\n+            try (ReleasableLock ignored = cacheFile.fileLock()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "257a00a74e76519112dde91954ed2e791f08639d"}, "originalPosition": 139}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk2Mjg3ODE2", "url": "https://github.com/elastic/elasticsearch/pull/55322#pullrequestreview-396287816", "createdAt": "2020-04-20T09:29:09Z", "commit": {"oid": "257a00a74e76519112dde91954ed2e791f08639d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQwOToyOTowOVrOGILi7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQwOToyOTowOVrOGILi7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTIzMDk1Ng==", "bodyText": "I see that this is taking the same approach as we use for uploading snapshot files (BlobStoreRepository). I would prefer not to hold onto workers for such a long time, as it can block the snapshot thread pool for a long time (cc: @original-brownbear).\nIn both cases (also the one BlobStoreRepository), I would prefer for the worker to process one file, then enqueue another task to the thread pool to pick up the next piece of work. This allows other operations to make progress as well, instead of waiting for a long time in the snapshot queue.", "url": "https://github.com/elastic/elasticsearch/pull/55322#discussion_r411230956", "createdAt": "2020-04-20T09:29:09Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -331,12 +359,133 @@ public String toString() {\n         return this.getClass().getSimpleName() + \"@snapshotId=\" + snapshotId + \" lockFactory=\" + lockFactory;\n     }\n \n+    private void prewarmCache() {\n+        assert Thread.holdsLock(this);\n+        assert loadCacheEagerly;\n+        assert useCache;\n+\n+        final BlockingQueue<CheckedRunnable<Exception>> queue = new SizeBlockingQueue<>(new LinkedBlockingQueue<>(), Integer.MAX_VALUE);\n+        for (BlobStoreIndexShardSnapshot.FileInfo file : snapshot().indexFiles()) {\n+            final String fileName = file.physicalName();\n+            if (isExcludedFromCache(fileName) == false && file.metadata().hashEqualsContents() == false) {\n+                final long numberOfParts = file.numberOfParts();\n+                if (queue.remainingCapacity() > numberOfParts) {\n+                    logger.debug(\n+                        \"{} prewarming cache for file [{}] of length [{}] and [{}] parts\",\n+                        shardId,\n+                        fileName,\n+                        file.length(),\n+                        numberOfParts\n+                    );\n+                    final long startTimeInNanos = statsCurrentTimeNanosSupplier.getAsLong();\n+                    try {\n+                        final IndexInput input = openInput(file, CachedBlobContainerIndexInput.CACHE_WARMING_CONTEXT);\n+                        assert input instanceof CachedBlobContainerIndexInput : \"expected cached index input but got \" + input.getClass();\n+\n+                        final CountDown countDown = new CountDown(Math.toIntExact(numberOfParts));\n+                        for (long p = 0; p < numberOfParts; p++) {\n+                            final int part = Math.toIntExact(p);\n+                            queue.add(() -> {\n+                                try {\n+                                    final long partStartTimeInNanos = statsCurrentTimeNanosSupplier.getAsLong();\n+                                    final CachedBlobContainerIndexInput cachedIndexInput = (CachedBlobContainerIndexInput) input.clone();\n+                                    assert loaded == false : \"snapshot should not be fully loaded until all prewarming tasks are completed\";\n+\n+                                    final int bytesRead = cachedIndexInput.prefetchPart(part); // TODO does not include any rate limitation\n+                                    assert bytesRead == file.partBytes(part);\n+\n+                                    logger.trace(\n+                                        () -> new ParameterizedMessage(\n+                                            \"{} part [{}/{}] of length [{}] prewarmed in cache for file [{}] in [{}] ms\",\n+                                            shardId,\n+                                            part,\n+                                            numberOfParts,\n+                                            file.partBytes(part),\n+                                            fileName,\n+                                            TimeUnit.NANOSECONDS.toMillis(statsCurrentTimeNanosSupplier.getAsLong() - partStartTimeInNanos)\n+                                        )\n+                                    );\n+                                } finally {\n+                                    if (countDown.countDown()) {\n+                                        IOUtils.closeWhileHandlingException(input);\n+                                        logger.debug(\n+                                            \"{} cache prewarmed for file [{}] in [{}] ms\",\n+                                            shardId,\n+                                            fileName,\n+                                            TimeUnit.NANOSECONDS.toMillis(statsCurrentTimeNanosSupplier.getAsLong() - startTimeInNanos)\n+                                        );\n+                                    }\n+                                }\n+                            });\n+                        }\n+                    } catch (Exception e) {\n+                        logger.warn(() -> new ParameterizedMessage(\"{} failed to prewarm cache for file [{}]\", shardId, fileName), e);\n+                    }\n+                }\n+            }\n+        }\n+\n+        final String threadPoolName = ThreadPool.Names.SNAPSHOT;\n+        final Executor executor = threadPool.executor(threadPoolName);\n+        final int workers = Math.min(threadPool.info(threadPoolName).getMax(), queue.size());\n+\n+        final CountDownLatch latch = new CountDownLatch(workers);\n+        for (int i = 0; i < workers; ++i) {\n+            executor.execute(new AbstractRunnable() {\n+                @Override\n+                protected void doRun() throws Exception {\n+                    CheckedRunnable<Exception> loader;\n+                    while (isOpen && (loader = queue.poll(0L, TimeUnit.MILLISECONDS)) != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "257a00a74e76519112dde91954ed2e791f08639d"}, "originalPosition": 218}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4ab253a7e35c1da390b6313886af9c2b7e011d86", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/4ab253a7e35c1da390b6313886af9c2b7e011d86", "committedDate": "2020-04-23T12:48:21Z", "message": "Merge branch 'master' into load-cache-eagerly"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9a67e890f0ee086ac3612e99517130cdb442edfd", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/9a67e890f0ee086ac3612e99517130cdb442edfd", "committedDate": "2020-04-23T15:56:41Z", "message": "apply feedback"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk5NzM1NTk2", "url": "https://github.com/elastic/elasticsearch/pull/55322#pullrequestreview-399735596", "createdAt": "2020-04-24T08:17:58Z", "commit": {"oid": "9a67e890f0ee086ac3612e99517130cdb442edfd"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQwODoxNzo1OFrOGLMIIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQwODoxNzo1OFrOGLMIIA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDM4NjIwOA==", "bodyText": "This will queue up all chunks at once on the thread pool. To make this fairer among multiple recoveries, I would prefer something like https://github.com/elastic/elasticsearch/compare/master...ywelsch:para-restores?expand=1\nCan be a follow-up though if you prefer.", "url": "https://github.com/elastic/elasticsearch/pull/55322#discussion_r414386208", "createdAt": "2020-04-24T08:17:58Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -331,12 +353,85 @@ public String toString() {\n         return this.getClass().getSimpleName() + \"@snapshotId=\" + snapshotId + \" lockFactory=\" + lockFactory;\n     }\n \n+    private void prewarmCache() {\n+        if (loadCacheEagerly) {\n+            final List<BlobStoreIndexShardSnapshot.FileInfo> cacheFiles = snapshot().indexFiles()\n+                .stream()\n+                .filter(file -> file.metadata().hashEqualsContents() == false)\n+                .filter(file -> isExcludedFromCache(file.physicalName()) == false)\n+                .collect(Collectors.toList());\n+\n+            final Executor executor = threadPool.executor(SEARCHABLE_SNAPSHOTS_THREAD_POOL_NAME);\n+            logger.debug(\"{} warming shard cache for [{}] files\", shardId, cacheFiles.size());\n+\n+            for (BlobStoreIndexShardSnapshot.FileInfo cacheFile : cacheFiles) {\n+                final String fileName = cacheFile.physicalName();\n+                try {\n+                    final IndexInput input = openInput(fileName, CachedBlobContainerIndexInput.CACHE_WARMING_CONTEXT);\n+                    assert input instanceof CachedBlobContainerIndexInput : \"expected cached index input but got \" + input.getClass();\n+\n+                    final long numberOfParts = cacheFile.numberOfParts();\n+                    final CountDown countDown = new CountDown(Math.toIntExact(numberOfParts));\n+                    for (long p = 0; p < numberOfParts; p++) {\n+                        final int part = Math.toIntExact(p);\n+                        executor.execute(new AbstractRunnable() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a67e890f0ee086ac3612e99517130cdb442edfd"}, "originalPosition": 156}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk5ODQyMDAy", "url": "https://github.com/elastic/elasticsearch/pull/55322#pullrequestreview-399842002", "createdAt": "2020-04-24T10:52:45Z", "commit": {"oid": "9a67e890f0ee086ac3612e99517130cdb442edfd"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQxMDo1Mjo0NVrOGLSCqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQxMTowNTo0NlrOGLSeOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQ4MzExNA==", "bodyText": "Suggest keeping the terminology consistent around \"warming\", how about index.store.snapshot.cache.prewarm.enabled?", "url": "https://github.com/elastic/elasticsearch/pull/55322#discussion_r414483114", "createdAt": "2020-04-24T10:52:45Z", "author": {"login": "DaveCTurner"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshots.java", "diffHunk": "@@ -99,6 +103,11 @@\n         true,\n         Setting.Property.IndexScope\n     );\n+    public static final Setting<Boolean> SNAPSHOT_CACHE_LOAD_EAGERLY_SETTING = Setting.boolSetting(\n+        \"index.store.snapshot.cache.load.eagerly\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a67e890f0ee086ac3612e99517130cdb442edfd"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQ4NDc0Mw==", "bodyText": "I think we can relax the assertion here to permit the searchable_snapshots threadpool to access the repo, rather than overloading it only in CachedBlobContainerIndexInput.", "url": "https://github.com/elastic/elasticsearch/pull/55322#discussion_r414484743", "createdAt": "2020-04-24T10:55:42Z", "author": {"login": "DaveCTurner"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/BaseSearchableSnapshotIndexInput.java", "diffHunk": "@@ -129,7 +129,7 @@ protected InputStream openSlice(long slice) throws IOException {\n         }\n     }\n \n-    protected final boolean assertCurrentThreadMayAccessBlobStore() {\n+    protected boolean assertCurrentThreadMayAccessBlobStore() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a67e890f0ee086ac3612e99517130cdb442edfd"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQ4NjcwOQ==", "bodyText": "I think this is no longer necessary? The private openInput method is only called in one place.", "url": "https://github.com/elastic/elasticsearch/pull/55322#discussion_r414486709", "createdAt": "2020-04-24T10:59:13Z", "author": {"login": "DaveCTurner"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -290,17 +315,20 @@ public CacheFile getCacheFile(CacheKey cacheKey, long fileLength) throws Excepti\n \n     @Override\n     public IndexInput openInput(final String name, final IOContext context) throws IOException {\n-        ensureOpen();\n+        return openInput(fileInfo(name), context);\n+    }\n \n-        final BlobStoreIndexShardSnapshot.FileInfo fileInfo = fileInfo(name);\n+    private IndexInput openInput(final BlobStoreIndexShardSnapshot.FileInfo fileInfo, final IOContext context) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY3MTIwMA=="}, "originalCommit": {"oid": "257a00a74e76519112dde91954ed2e791f08639d"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQ4NzI4Mw==", "bodyText": "Could you transfer that to a // TODO comment, just so we are sure not to lose it?", "url": "https://github.com/elastic/elasticsearch/pull/55322#discussion_r414487283", "createdAt": "2020-04-24T11:00:19Z", "author": {"login": "DaveCTurner"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -331,12 +353,85 @@ public String toString() {\n         return this.getClass().getSimpleName() + \"@snapshotId=\" + snapshotId + \" lockFactory=\" + lockFactory;\n     }\n \n+    private void prewarmCache() {\n+        if (loadCacheEagerly) {\n+            final List<BlobStoreIndexShardSnapshot.FileInfo> cacheFiles = snapshot().indexFiles()\n+                .stream()\n+                .filter(file -> file.metadata().hashEqualsContents() == false)\n+                .filter(file -> isExcludedFromCache(file.physicalName()) == false)\n+                .collect(Collectors.toList());\n+\n+            final Executor executor = threadPool.executor(SEARCHABLE_SNAPSHOTS_THREAD_POOL_NAME);\n+            logger.debug(\"{} warming shard cache for [{}] files\", shardId, cacheFiles.size());\n+\n+            for (BlobStoreIndexShardSnapshot.FileInfo cacheFile : cacheFiles) {\n+                final String fileName = cacheFile.physicalName();\n+                try {\n+                    final IndexInput input = openInput(fileName, CachedBlobContainerIndexInput.CACHE_WARMING_CONTEXT);\n+                    assert input instanceof CachedBlobContainerIndexInput : \"expected cached index input but got \" + input.getClass();\n+\n+                    final long numberOfParts = cacheFile.numberOfParts();\n+                    final CountDown countDown = new CountDown(Math.toIntExact(numberOfParts));\n+                    for (long p = 0; p < numberOfParts; p++) {\n+                        final int part = Math.toIntExact(p);\n+                        executor.execute(new AbstractRunnable() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDM4NjIwOA=="}, "originalCommit": {"oid": "9a67e890f0ee086ac3612e99517130cdb442edfd"}, "originalPosition": 156}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQ4ODkzNg==", "bodyText": "A Tuple argument is a bit strange, can we pass in the two longs directly instead?", "url": "https://github.com/elastic/elasticsearch/pull/55322#discussion_r414488936", "createdAt": "2020-04-24T11:03:26Z", "author": {"login": "DaveCTurner"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java", "diffHunk": "@@ -249,41 +248,36 @@ private void ensureOpen() {\n     }\n \n     CompletableFuture<Integer> fetchRange(\n-        long position,\n+        Tuple<Long, Long> range,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a67e890f0ee086ac3612e99517130cdb442edfd"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQ4OTIzMQ==", "bodyText": "Also invalid if the start of the range is after the end?", "url": "https://github.com/elastic/elasticsearch/pull/55322#discussion_r414489231", "createdAt": "2020-04-24T11:04:01Z", "author": {"login": "DaveCTurner"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java", "diffHunk": "@@ -249,41 +248,36 @@ private void ensureOpen() {\n     }\n \n     CompletableFuture<Integer> fetchRange(\n-        long position,\n+        Tuple<Long, Long> range,\n         CheckedBiFunction<Long, Long, Integer, IOException> onRangeAvailable,\n         CheckedBiConsumer<Long, Long, IOException> onRangeMissing\n     ) {\n         final CompletableFuture<Integer> future = new CompletableFuture<>();\n         try {\n-            if (position < 0 || position > tracker.getLength()) {\n-                throw new IllegalArgumentException(\"Wrong read position [\" + position + \"]\");\n+            if (range.v1() < 0 || range.v1() > tracker.getLength() || range.v2() < 0 || range.v2() > tracker.getLength()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a67e890f0ee086ac3612e99517130cdb442edfd"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQ5MDE3MQ==", "bodyText": "Don't really need this guard any more.", "url": "https://github.com/elastic/elasticsearch/pull/55322#discussion_r414490171", "createdAt": "2020-04-24T11:05:46Z", "author": {"login": "DaveCTurner"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java", "diffHunk": "@@ -249,41 +248,36 @@ private void ensureOpen() {\n     }\n \n     CompletableFuture<Integer> fetchRange(\n-        long position,\n+        Tuple<Long, Long> range,\n         CheckedBiFunction<Long, Long, Integer, IOException> onRangeAvailable,\n         CheckedBiConsumer<Long, Long, IOException> onRangeMissing\n     ) {\n         final CompletableFuture<Integer> future = new CompletableFuture<>();\n         try {\n-            if (position < 0 || position > tracker.getLength()) {\n-                throw new IllegalArgumentException(\"Wrong read position [\" + position + \"]\");\n+            if (range.v1() < 0 || range.v1() > tracker.getLength() || range.v2() < 0 || range.v2() > tracker.getLength()) {\n+                throw new IllegalArgumentException(\n+                    \"Invalid range [start=\" + range.v1() + \", end=\" + range.v2() + \"] for length [\" + tracker.getLength() + ']'\n+                );\n             }\n-\n             ensureOpen();\n-            final long rangeStart = (position / rangeSize) * rangeSize;\n-            final long rangeEnd = Math.min(rangeStart + rangeSize, tracker.getLength());\n-\n             final List<SparseFileTracker.Gap> gaps = tracker.waitForRange(\n-                rangeStart,\n-                rangeEnd,\n+                range.v1(),\n+                range.v2(),\n                 ActionListener.wrap(\n-                    rangeReady -> future.complete(onRangeAvailable.apply(rangeStart, rangeEnd)),\n+                    rangeReady -> future.complete(onRangeAvailable.apply(range.v1(), range.v2())),\n                     rangeFailure -> future.completeExceptionally(rangeFailure)\n                 )\n             );\n \n             if (gaps.size() > 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a67e890f0ee086ac3612e99517130cdb442edfd"}, "originalPosition": 65}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk5ODYxMzgw", "url": "https://github.com/elastic/elasticsearch/pull/55322#pullrequestreview-399861380", "createdAt": "2020-04-24T11:24:49Z", "commit": {"oid": "9a67e890f0ee086ac3612e99517130cdb442edfd"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQxMToyNDo0OVrOGLTHow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQxMToyNDo0OVrOGLTHow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDUwMDc3MQ==", "bodyText": "Can we assert that the returned range is the whole part? I think that'd be useful documentation if nothing else.", "url": "https://github.com/elastic/elasticsearch/pull/55322#discussion_r414500771", "createdAt": "2020-04-24T11:24:49Z", "author": {"login": "DaveCTurner"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java", "diffHunk": "@@ -131,6 +172,31 @@ protected void readInternal(final byte[] buffer, final int offset, final int len\n         lastSeekPosition = lastReadPosition;\n     }\n \n+    /**\n+     * Prefetches a complete part and writes it in cache. This method is used to prewarm the cache.\n+     */\n+    public int prefetchPart(final int part) throws IOException {\n+        ensureContext(ctx -> ctx == CACHE_WARMING_CONTEXT);\n+        if (part >= fileInfo.numberOfParts()) {\n+            throw new IllegalArgumentException(\"Unexpected part number [\" + part + \"]\");\n+        }\n+        final Tuple<Long, Long> range = computeRange(IntStream.range(0, part).mapToLong(fileInfo::partBytes).sum());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a67e890f0ee086ac3612e99517130cdb442edfd"}, "originalPosition": 138}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c8a1c6bf7e480d4961fe1e4a6d7fb8ab01e85534", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/c8a1c6bf7e480d4961fe1e4a6d7fb8ab01e85534", "committedDate": "2020-04-24T12:13:42Z", "message": "remove unused openinput"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a635c7f064604d74bec4c520580846042aee6310", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/a635c7f064604d74bec4c520580846042aee6310", "committedDate": "2020-04-24T12:16:36Z", "message": "add todo"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4ee96afd25d50d941bfd43e0a4c558cfded45b54", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/4ee96afd25d50d941bfd43e0a4c558cfded45b54", "committedDate": "2020-04-24T12:29:27Z", "message": "rename setting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0469c7b582ffa55b267d082c41c29221b3e6e876", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/0469c7b582ffa55b267d082c41c29221b3e6e876", "committedDate": "2020-04-24T12:31:57Z", "message": "assert thread name"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4dc76b83c10f3881a7783896dd3610bc7baae522", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/4dc76b83c10f3881a7783896dd3610bc7baae522", "committedDate": "2020-04-24T12:38:55Z", "message": "remove tuple"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e9831a3c1c5f2035586b08bf390667a149313359", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/e9831a3c1c5f2035586b08bf390667a149313359", "committedDate": "2020-04-24T12:39:49Z", "message": "remove unnecessary condition"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e01bf710ffa6a00ab730fc3efe45b4204dadd763", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/e01bf710ffa6a00ab730fc3efe45b4204dadd763", "committedDate": "2020-04-24T13:16:12Z", "message": "assert range"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk5OTYwMzA4", "url": "https://github.com/elastic/elasticsearch/pull/55322#pullrequestreview-399960308", "createdAt": "2020-04-24T13:46:03Z", "commit": {"oid": "e01bf710ffa6a00ab730fc3efe45b4204dadd763"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQxMzo0NjowM1rOGLYdEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQxMzo0NjozOVrOGLYfBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDU4ODE3OQ==", "bodyText": "Should we avoid even creating this threadpool if prewarming is disabled?", "url": "https://github.com/elastic/elasticsearch/pull/55322#discussion_r414588179", "createdAt": "2020-04-24T13:46:03Z", "author": {"login": "DaveCTurner"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshots.java", "diffHunk": "@@ -252,4 +266,21 @@ public void onIndexModule(IndexModule indexModule) {\n         }\n     }\n \n+    public List<ExecutorBuilder<?>> getExecutorBuilders(Settings settings) {\n+        if (SEARCHABLE_SNAPSHOTS_FEATURE_ENABLED) {\n+            return List.of(executorBuilder());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e01bf710ffa6a00ab730fc3efe45b4204dadd763"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDU4ODY3OA==", "bodyText": "We could reasonably not have any active threads if there's no pre-warming going on I think.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        1,\n          \n          \n            \n                        0,", "url": "https://github.com/elastic/elasticsearch/pull/55322#discussion_r414588678", "createdAt": "2020-04-24T13:46:39Z", "author": {"login": "DaveCTurner"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshots.java", "diffHunk": "@@ -252,4 +266,21 @@ public void onIndexModule(IndexModule indexModule) {\n         }\n     }\n \n+    public List<ExecutorBuilder<?>> getExecutorBuilders(Settings settings) {\n+        if (SEARCHABLE_SNAPSHOTS_FEATURE_ENABLED) {\n+            return List.of(executorBuilder());\n+        } else {\n+            return List.of();\n+        }\n+    }\n+\n+    public static ExecutorBuilder<?> executorBuilder() {\n+        return new ScalingExecutorBuilder(\n+            SEARCHABLE_SNAPSHOTS_THREAD_POOL_NAME,\n+            1,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e01bf710ffa6a00ab730fc3efe45b4204dadd763"}, "originalPosition": 87}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "baa8258283eb91a45d3fc433320bce0a8aaca191", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/baa8258283eb91a45d3fc433320bce0a8aaca191", "committedDate": "2020-04-24T15:03:18Z", "message": "zero"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3229, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}