{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzc5Njg5MzIx", "number": 52778, "title": "[ML] Parse and report memory usage for DF Analytics", "bodyText": "Adds reporting of memory usage for data frame analytics jobs.\nThis commit introduces a new index pattern .ml-stats-* whose\nfirst concrete index will be .ml-stats-000001. This index serves\nto store instrumentation information for those jobs.", "createdAt": "2020-02-25T16:48:05Z", "url": "https://github.com/elastic/elasticsearch/pull/52778", "merged": true, "mergeCommit": {"oid": "dd331935b31f83024633a6ec84da5be946b4e7d1"}, "closed": true, "closedAt": "2020-02-28T15:35:07Z", "author": {"login": "dimitris-athanasiou"}, "timelineItems": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcIFvk1AFqTM2NDgzODM2OA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcIwhOygBqjMwODIwNzc0ODY=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY0ODM4MzY4", "url": "https://github.com/elastic/elasticsearch/pull/52778#pullrequestreview-364838368", "createdAt": "2020-02-26T11:55:08Z", "commit": {"oid": "6333b38ea14ee908d9be870ca4d0edc158a37dda"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxMTo1NTowOFrOFuovRQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxMjoxMzowOVrOFupNig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDQ0NjI3Nw==", "bodyText": "There's an inconsistency here, because if the index and alias already existed when the method was called the response is false, but if the method is called twice concurrently such that one concurrent call creates it and the other gets a ResourceAlreadyExistsException then both return true.\nIf the boolean is intended to be \"did this call create the index and alias\" then one should return false in this case.\nBut it's not actually documented what the returned boolean is supposed to mean.  Doing that would be good too.", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r384446277", "createdAt": "2020-02-26T11:55:08Z", "author": {"login": "droberts195"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/MlStatsIndex.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml;\n+\n+import org.elasticsearch.ResourceAlreadyExistsException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.admin.indices.alias.Alias;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexAction;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexRequest;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.template.TemplateUtils;\n+\n+/**\n+ * Describes the indices where ML is storing various stats about the users jobs.\n+ */\n+public class MlStatsIndex {\n+\n+    public static final String TEMPLATE_NAME = \".ml-stats\";\n+\n+    private static final String MAPPINGS_VERSION_VARIABLE = \"xpack.ml.version\";\n+\n+    private MlStatsIndex() {}\n+\n+    public static String mapping() {\n+        return TemplateUtils.loadTemplate(\"/org/elasticsearch/xpack/core/ml/stats_index_mappings.json\",\n+            Version.CURRENT.toString(), MAPPINGS_VERSION_VARIABLE);\n+    }\n+\n+    public static String indexPattern() {\n+        return TEMPLATE_NAME + \"-*\";\n+    }\n+\n+    public static String writeAlias() {\n+        return \".ml-stats-write\";\n+    }\n+\n+    /**\n+     * Creates the first concrete .ml-stats-000001 index (if necessary)\n+     * Creates the .ml-stats-write alias for that index.\n+     */\n+    public static void createStatsIndexAndAliasIfNecessary(Client client, ClusterState state, ActionListener<Boolean> listener) {\n+\n+        if (state.getMetaData().getAliasAndIndexLookup().containsKey(writeAlias())) {\n+            listener.onResponse(false);\n+            return;\n+        }\n+\n+        ActionListener<CreateIndexResponse> createIndexListener = ActionListener.wrap(\n+            createIndexResponse -> listener.onResponse(true),\n+            error -> {\n+                if (ExceptionsHelper.unwrapCause(error) instanceof ResourceAlreadyExistsException) {\n+                    listener.onResponse(true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6333b38ea14ee908d9be870ca4d0edc158a37dda"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDQ0ODcwMw==", "bodyText": "This doesn't cover the edge case where the index exists but the write alias doesn't (presumably because a user accidentally deleted it, but maybe also due to a bug in ILM).\nI think this method should cover that case like AnomalyDetectorsIndex.createStateIndexAndAliasIfNecessary() does.  It will avoid support cases if the system can be self healing in this situation.  At present it will return true giving the impression that everything is good when the post conditions are that the index exists but not the alias.", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r384448703", "createdAt": "2020-02-26T12:00:35Z", "author": {"login": "droberts195"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/MlStatsIndex.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml;\n+\n+import org.elasticsearch.ResourceAlreadyExistsException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.admin.indices.alias.Alias;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexAction;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexRequest;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.template.TemplateUtils;\n+\n+/**\n+ * Describes the indices where ML is storing various stats about the users jobs.\n+ */\n+public class MlStatsIndex {\n+\n+    public static final String TEMPLATE_NAME = \".ml-stats\";\n+\n+    private static final String MAPPINGS_VERSION_VARIABLE = \"xpack.ml.version\";\n+\n+    private MlStatsIndex() {}\n+\n+    public static String mapping() {\n+        return TemplateUtils.loadTemplate(\"/org/elasticsearch/xpack/core/ml/stats_index_mappings.json\",\n+            Version.CURRENT.toString(), MAPPINGS_VERSION_VARIABLE);\n+    }\n+\n+    public static String indexPattern() {\n+        return TEMPLATE_NAME + \"-*\";\n+    }\n+\n+    public static String writeAlias() {\n+        return \".ml-stats-write\";\n+    }\n+\n+    /**\n+     * Creates the first concrete .ml-stats-000001 index (if necessary)\n+     * Creates the .ml-stats-write alias for that index.\n+     */\n+    public static void createStatsIndexAndAliasIfNecessary(Client client, ClusterState state, ActionListener<Boolean> listener) {\n+\n+        if (state.getMetaData().getAliasAndIndexLookup().containsKey(writeAlias())) {\n+            listener.onResponse(false);\n+            return;\n+        }\n+\n+        ActionListener<CreateIndexResponse> createIndexListener = ActionListener.wrap(\n+            createIndexResponse -> listener.onResponse(true),\n+            error -> {\n+                if (ExceptionsHelper.unwrapCause(error) instanceof ResourceAlreadyExistsException) {\n+                    listener.onResponse(true);\n+                } else {\n+                    listener.onFailure(error);\n+                }\n+            }\n+        );\n+\n+        CreateIndexRequest createIndexRequest = client.admin()\n+            .indices()\n+            .prepareCreate(TEMPLATE_NAME + \"-000001\")\n+            .addAlias(new Alias(writeAlias()).writeIndex(true))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6333b38ea14ee908d9be870ca4d0edc158a37dda"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDQ1MzE2Ng==", "bodyText": "I don't think it's good that we're propagating the behaviour of the old Prelert time parsing that is completely non-standard in the Elastic stack into new code:\n            if (date.trim().length() <= 10) { // seconds\n                return epoch * 1000;\n            } else {\n                return epoch;\n            }\n\nIt would have been best if we'd removed this years ago.\nMaybe now is a good opportunity to rename TimeUtils.parseTimeField() to TimeUtils.parseTimeFieldDeprecated() and TimeUtils.parseTimeFieldToInstant() to TimeUtils.parseTimeFieldToInstantDeprecated(), annotate both with @Deprecated and introduce a new method TimeUtils.parseTimeFieldToInstant() that can be used here that replaces return Instant.ofEpochMilli(dateStringToEpoch(parser.text())); with return Instant.from(DateFieldMapper.DEFAULT_DATE_TIME_FORMATTER.parse(parser.text()));.", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r384453166", "createdAt": "2020-02-26T12:11:01Z", "author": {"login": "droberts195"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/stats/MemoryUsage.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.dataframe.stats;\n+\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+\n+public class MemoryUsage implements Writeable, ToXContentObject {\n+\n+    public static final String TYPE_VALUE = \"analytics_memory_usage\";\n+\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField JOB_ID = new ParseField(\"job_id\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"timestamp\");\n+    public static final ParseField PEAK_USAGE_BYTES = new ParseField(\"peak_usage_bytes\");\n+\n+    public static final ConstructingObjectParser<MemoryUsage, Void> STRICT_PARSER = createParser(false);\n+    public static final ConstructingObjectParser<MemoryUsage, Void> LENIENT_PARSER = createParser(true);\n+\n+    private static ConstructingObjectParser<MemoryUsage, Void> createParser(boolean ignoreUnknownFields) {\n+        ConstructingObjectParser<MemoryUsage, Void> parser = new ConstructingObjectParser<>(TYPE_VALUE,\n+            ignoreUnknownFields, a -> new MemoryUsage((String) a[0], (Instant) a[1], (long) a[2]));\n+\n+        parser.declareString((bucket, s) -> {}, TYPE);\n+        parser.declareString(ConstructingObjectParser.constructorArg(), JOB_ID);\n+        parser.declareField(ConstructingObjectParser.constructorArg(),\n+            p -> TimeUtils.parseTimeFieldToInstant(p, TIMESTAMP.getPreferredName()),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6333b38ea14ee908d9be870ca4d0edc158a37dda"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDQ1NDAyNg==", "bodyText": "It would be good to add a comment that the reason for rounding to millisecond accuracy is that the XContent representation rounds to millisecond accuracy and it makes debugging hard if the internal accuracy is greater.", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r384454026", "createdAt": "2020-02-26T12:13:09Z", "author": {"login": "droberts195"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/stats/MemoryUsage.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.dataframe.stats;\n+\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+\n+public class MemoryUsage implements Writeable, ToXContentObject {\n+\n+    public static final String TYPE_VALUE = \"analytics_memory_usage\";\n+\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField JOB_ID = new ParseField(\"job_id\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"timestamp\");\n+    public static final ParseField PEAK_USAGE_BYTES = new ParseField(\"peak_usage_bytes\");\n+\n+    public static final ConstructingObjectParser<MemoryUsage, Void> STRICT_PARSER = createParser(false);\n+    public static final ConstructingObjectParser<MemoryUsage, Void> LENIENT_PARSER = createParser(true);\n+\n+    private static ConstructingObjectParser<MemoryUsage, Void> createParser(boolean ignoreUnknownFields) {\n+        ConstructingObjectParser<MemoryUsage, Void> parser = new ConstructingObjectParser<>(TYPE_VALUE,\n+            ignoreUnknownFields, a -> new MemoryUsage((String) a[0], (Instant) a[1], (long) a[2]));\n+\n+        parser.declareString((bucket, s) -> {}, TYPE);\n+        parser.declareString(ConstructingObjectParser.constructorArg(), JOB_ID);\n+        parser.declareField(ConstructingObjectParser.constructorArg(),\n+            p -> TimeUtils.parseTimeFieldToInstant(p, TIMESTAMP.getPreferredName()),\n+            TIMESTAMP,\n+            ObjectParser.ValueType.VALUE);\n+        parser.declareLong(ConstructingObjectParser.constructorArg(), PEAK_USAGE_BYTES);\n+        return parser;\n+    }\n+\n+    private final String jobId;\n+    private final Instant timestamp;\n+    private final long peakUsageBytes;\n+\n+    public MemoryUsage(String jobId, Instant timestamp, long peakUsageBytes) {\n+        this.jobId = Objects.requireNonNull(jobId);\n+        this.timestamp = Instant.ofEpochMilli(ExceptionsHelper.requireNonNull(timestamp, TIMESTAMP).toEpochMilli());\n+        this.peakUsageBytes = peakUsageBytes;\n+    }\n+\n+    public MemoryUsage(StreamInput in) throws IOException {\n+        jobId = in.readString();\n+        timestamp = in.readInstant();\n+        peakUsageBytes = in.readVLong();\n+    }\n+\n+    @Override\n+    public void writeTo(StreamOutput out) throws IOException {\n+        out.writeString(jobId);\n+        out.writeInstant(timestamp);\n+        out.writeVLong(peakUsageBytes);\n+    }\n+\n+    @Override\n+    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n+        builder.startObject();\n+        if (params.paramAsBoolean(ToXContentParams.FOR_INTERNAL_STORAGE, false)) {\n+            builder.field(TYPE.getPreferredName(), TYPE_VALUE);\n+            builder.field(JOB_ID.getPreferredName(), jobId);\n+        }\n+        builder.timeField(TIMESTAMP.getPreferredName(), TIMESTAMP.getPreferredName() + \"_string\", timestamp.toEpochMilli());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6333b38ea14ee908d9be870ca4d0edc158a37dda"}, "originalPosition": 81}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1MTk4Nzk3", "url": "https://github.com/elastic/elasticsearch/pull/52778#pullrequestreview-365198797", "createdAt": "2020-02-26T19:57:18Z", "commit": {"oid": "6333b38ea14ee908d9be870ca4d0edc158a37dda"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxOTo1NzoxOFrOFu6GLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMDoxNDo0OVrOFu6pHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDczMDY2OQ==", "bodyText": "Why is this necessary? Presumably, the only time it is parsing TYPE is when it is reading from the index. In that case, it should ignore unknown fields.", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r384730669", "createdAt": "2020-02-26T19:57:18Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/stats/MemoryUsage.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.dataframe.stats;\n+\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+\n+public class MemoryUsage implements Writeable, ToXContentObject {\n+\n+    public static final String TYPE_VALUE = \"analytics_memory_usage\";\n+\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField JOB_ID = new ParseField(\"job_id\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"timestamp\");\n+    public static final ParseField PEAK_USAGE_BYTES = new ParseField(\"peak_usage_bytes\");\n+\n+    public static final ConstructingObjectParser<MemoryUsage, Void> STRICT_PARSER = createParser(false);\n+    public static final ConstructingObjectParser<MemoryUsage, Void> LENIENT_PARSER = createParser(true);\n+\n+    private static ConstructingObjectParser<MemoryUsage, Void> createParser(boolean ignoreUnknownFields) {\n+        ConstructingObjectParser<MemoryUsage, Void> parser = new ConstructingObjectParser<>(TYPE_VALUE,\n+            ignoreUnknownFields, a -> new MemoryUsage((String) a[0], (Instant) a[1], (long) a[2]));\n+\n+        parser.declareString((bucket, s) -> {}, TYPE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6333b38ea14ee908d9be870ca4d0edc158a37dda"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDczMjA3Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    return new ToXContent.MapParams(Collections.singletonMap(ToXContentParams.FOR_INTERNAL_STORAGE, \"true\"));\n          \n          \n            \n                    return new ToXContent.MapParams(Collections.singletonMap(ToXContentParams.FOR_INTERNAL_STORAGE, Boolean.toString(lenient));\n          \n      \n    \n    \n  \n\nI think will work so that the empty parsing declaration for TYPE can go away.", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r384732072", "createdAt": "2020-02-26T20:00:02Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/core/ml/dataframe/stats/MemoryUsageTests.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.dataframe.stats;\n+\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.test.AbstractSerializingTestCase;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.junit.Before;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Collections;\n+\n+public class MemoryUsageTests extends AbstractSerializingTestCase<MemoryUsage> {\n+\n+    private boolean lenient;\n+\n+    @Before\n+    public void chooseStrictOrLenient() {\n+        lenient = randomBoolean();\n+    }\n+\n+    @Override\n+    protected boolean supportsUnknownFields() {\n+        return lenient;\n+    }\n+\n+    @Override\n+    protected MemoryUsage doParseInstance(XContentParser parser) throws IOException {\n+        return lenient ? MemoryUsage.LENIENT_PARSER.parse(parser, null) : MemoryUsage.STRICT_PARSER.parse(parser, null);\n+    }\n+\n+    @Override\n+    protected ToXContent.Params getToXContentParams() {\n+        return new ToXContent.MapParams(Collections.singletonMap(ToXContentParams.FOR_INTERNAL_STORAGE, \"true\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6333b38ea14ee908d9be870ca4d0edc158a37dda"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDczNzM2NA==", "bodyText": "I wonder if we will hit scaling issues if there are 100s of stopped tasks.\nSeems like we could be making 100s of unbatched, search requests.", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r384737364", "createdAt": "2020-02-26T20:09:57Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportGetDataFrameAnalyticsStatsAction.java", "diffHunk": "@@ -157,75 +160,99 @@ void gatherStatsForStoppedTasks(List<String> expandedIds, GetDataFrameAnalyticsS\n             return;\n         }\n \n-        searchStoredProgresses(stoppedTasksIds, ActionListener.wrap(\n-            storedProgresses -> {\n-                List<Stats> stoppedStats = new ArrayList<>(stoppedTasksIds.size());\n-                for (int i = 0; i < stoppedTasksIds.size(); i++) {\n-                    String configId = stoppedTasksIds.get(i);\n-                    StoredProgress storedProgress = storedProgresses.get(i);\n-                    stoppedStats.add(buildStats(configId, storedProgress.get()));\n-                }\n-                List<Stats> allTasksStats = new ArrayList<>(runningTasksResponse.getResponse().results());\n-                allTasksStats.addAll(stoppedStats);\n-                Collections.sort(allTasksStats, Comparator.comparing(Stats::getId));\n-                listener.onResponse(new GetDataFrameAnalyticsStatsAction.Response(new QueryPage<>(\n-                    allTasksStats, allTasksStats.size(), GetDataFrameAnalyticsAction.Response.RESULTS_FIELD)));\n-            },\n-            listener::onFailure\n-        ));\n+        AtomicInteger counter = new AtomicInteger(stoppedTasksIds.size());\n+        AtomicArray<Stats> jobStats = new AtomicArray<>(stoppedTasksIds.size());\n+        for (int i = 0; i < stoppedTasksIds.size(); i++) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6333b38ea14ee908d9be870ca4d0edc158a37dda"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDczOTYxMw==", "bodyText": "\u2764\ufe0f", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r384739613", "createdAt": "2020-02-26T20:14:49Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/utils/persistence/MlParserUtils.java", "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.utils.persistence;\n+\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchParseException;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.XContentType;\n+import org.elasticsearch.search.SearchHit;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.function.BiFunction;\n+\n+public final class MlParserUtils {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6333b38ea14ee908d9be870ca4d0edc158a37dda"}, "originalPosition": 22}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2MzUyNTE1", "url": "https://github.com/elastic/elasticsearch/pull/52778#pullrequestreview-366352515", "createdAt": "2020-02-28T12:08:49Z", "commit": {"oid": "788b4f7b0500c5361a35184a2503214e071ac614"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2Mzk5OTY2", "url": "https://github.com/elastic/elasticsearch/pull/52778#pullrequestreview-366399966", "createdAt": "2020-02-28T13:35:56Z", "commit": {"oid": "788b4f7b0500c5361a35184a2503214e071ac614"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f9ad144a7ca71022b7936250e982cf455c495aac", "author": {"user": {"login": "dimitris-athanasiou", "name": "Dimitris Athanasiou"}}, "url": "https://github.com/elastic/elasticsearch/commit/f9ad144a7ca71022b7936250e982cf455c495aac", "committedDate": "2020-02-28T13:55:22Z", "message": "[ML] Parse and report memory usage for DF Analytics\n\nAdds reporting of memory usage for data frame analytics jobs.\nThis commit introduces a new index pattern `.ml-stats-*` whose\nfirst concrete index will be `.ml-stats-000001`. This index serves\nto store instrumentation information for those jobs."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b31415793bda55d58f336b8500a02b5fde70abf1", "author": {"user": {"login": "dimitris-athanasiou", "name": "Dimitris Athanasiou"}}, "url": "https://github.com/elastic/elasticsearch/commit/b31415793bda55d58f336b8500a02b5fde70abf1", "committedDate": "2020-02-28T13:55:23Z", "message": "Address review comments about index creation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1a911ebe02cf21ba6a0ea5c1a4c8659097fca1db", "author": {"user": {"login": "dimitris-athanasiou", "name": "Dimitris Athanasiou"}}, "url": "https://github.com/elastic/elasticsearch/commit/1a911ebe02cf21ba6a0ea5c1a4c8659097fca1db", "committedDate": "2020-02-28T13:55:23Z", "message": "Deprecate TimeUtils methods that handle epoch seconds"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3aba9671805ee4527f81d59684e17cb81c972bd3", "author": {"user": {"login": "dimitris-athanasiou", "name": "Dimitris Athanasiou"}}, "url": "https://github.com/elastic/elasticsearch/commit/3aba9671805ee4527f81d59684e17cb81c972bd3", "committedDate": "2020-02-28T13:55:23Z", "message": "Add comment for MemoryUsage.timestamp epoch millis rounding"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "788b4f7b0500c5361a35184a2503214e071ac614", "author": {"user": {"login": "dimitris-athanasiou", "name": "Dimitris Athanasiou"}}, "url": "https://github.com/elastic/elasticsearch/commit/788b4f7b0500c5361a35184a2503214e071ac614", "committedDate": "2020-02-28T11:18:53Z", "message": "Add comment for MemoryUsage.timestamp epoch millis rounding"}, "afterCommit": {"oid": "3aba9671805ee4527f81d59684e17cb81c972bd3", "author": {"user": {"login": "dimitris-athanasiou", "name": "Dimitris Athanasiou"}}, "url": "https://github.com/elastic/elasticsearch/commit/3aba9671805ee4527f81d59684e17cb81c972bd3", "committedDate": "2020-02-28T13:55:23Z", "message": "Add comment for MemoryUsage.timestamp epoch millis rounding"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2157, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}