{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA0MjM1NTcz", "number": 55293, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwOTo0NjoyOVrODybKCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQwNzozODowNlrODzlr7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MjAwMzI4OnYy", "diffSide": "LEFT", "path": "server/src/main/java/org/elasticsearch/repositories/RepositoryData.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwOTo0NjoyOVrOGGdWSA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwOTo0NjoyOVrOGGdWSA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQyNTQ4MA==", "bodyText": "This was broken, we were mutating the existing LinkedHashSet", "url": "https://github.com/elastic/elasticsearch/pull/55293#discussion_r409425480", "createdAt": "2020-04-16T09:46:29Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/repositories/RepositoryData.java", "diffHunk": "@@ -213,9 +214,16 @@ public RepositoryData addSnapshot(final SnapshotId snapshotId,\n         newSnapshotStates.put(snapshotId.getUUID(), snapshotState);\n         Map<String, Version> newSnapshotVersions = new HashMap<>(snapshotVersions);\n         newSnapshotVersions.put(snapshotId.getUUID(), version);\n-        Map<IndexId, Set<SnapshotId>> allIndexSnapshots = new HashMap<>(indexSnapshots);\n+        Map<IndexId, List<SnapshotId>> allIndexSnapshots = new HashMap<>(indexSnapshots);\n         for (final IndexId indexId : shardGenerations.indices()) {\n-            allIndexSnapshots.computeIfAbsent(indexId, k -> new LinkedHashSet<>()).add(snapshotId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13cb49a81148ca6d9c73c5fcecb592253ce8d5c6"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MjAyMDk3OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/repositories/RepositoryData.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwOTo1MTowOVrOGGdhUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwOTo1MTowOVrOGGdhUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQyODMwNw==", "bodyText": "Not great that we're quadratic here now (for the nested loop), but I don't think it really matters much relative to the significant space+GC savings.", "url": "https://github.com/elastic/elasticsearch/pull/55293#discussion_r409428307", "createdAt": "2020-04-16T09:51:09Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/repositories/RepositoryData.java", "diffHunk": "@@ -253,23 +261,24 @@ public RepositoryData removeSnapshot(final SnapshotId snapshotId, final ShardGen\n         newSnapshotStates.remove(snapshotId.getUUID());\n         final Map<String, Version> newSnapshotVersions = new HashMap<>(snapshotVersions);\n         newSnapshotVersions.remove(snapshotId.getUUID());\n-        Map<IndexId, Set<SnapshotId>> indexSnapshots = new HashMap<>();\n+        Map<IndexId, List<SnapshotId>> indexSnapshots = new HashMap<>();\n         for (final IndexId indexId : indices.values()) {\n-            Set<SnapshotId> set;\n-            Set<SnapshotId> snapshotIds = this.indexSnapshots.get(indexId);\n+            List<SnapshotId> remaining;\n+            List<SnapshotId> snapshotIds = this.indexSnapshots.get(indexId);\n             assert snapshotIds != null;\n             if (snapshotIds.contains(snapshotId)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13cb49a81148ca6d9c73c5fcecb592253ce8d5c6"}, "originalPosition": 66}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1NDIwNDk1OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/repositories/RepositoryData.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQwNzozNTozM1rOGIHHsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxNDoxMToyNVrOGIWgAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1ODQ0OA==", "bodyText": "why create a copy of the copy?", "url": "https://github.com/elastic/elasticsearch/pull/55293#discussion_r411158448", "createdAt": "2020-04-20T07:35:33Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/repositories/RepositoryData.java", "diffHunk": "@@ -213,9 +214,16 @@ public RepositoryData addSnapshot(final SnapshotId snapshotId,\n         newSnapshotStates.put(snapshotId.getUUID(), snapshotState);\n         Map<String, Version> newSnapshotVersions = new HashMap<>(snapshotVersions);\n         newSnapshotVersions.put(snapshotId.getUUID(), version);\n-        Map<IndexId, Set<SnapshotId>> allIndexSnapshots = new HashMap<>(indexSnapshots);\n+        Map<IndexId, List<SnapshotId>> allIndexSnapshots = new HashMap<>(indexSnapshots);\n         for (final IndexId indexId : shardGenerations.indices()) {\n-            allIndexSnapshots.computeIfAbsent(indexId, k -> new LinkedHashSet<>()).add(snapshotId);\n+            final List<SnapshotId> snapshotIds = allIndexSnapshots.get(indexId);\n+            if (snapshotIds == null) {\n+                allIndexSnapshots.put(indexId, List.of(snapshotId));\n+            } else {\n+                final List<SnapshotId> copy = new ArrayList<>(snapshotIds);\n+                copy.add(snapshotId);\n+                allIndexSnapshots.put(indexId, List.copyOf(copy));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b267d9c4ad95e220544c773d01750e886283d471"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTIwODIyOQ==", "bodyText": "These RepositoryData instances live for quite a while, so I figured the cost of doing another copy is worth the lower storage overhead + shorter path to the GC root compared to wrapping with Collections.unmodifiableList? I could technically make this more efficient by copying to a SnapshotId[] and then just wrapping that array but I figured this wasn't that much slower and nicer to read.", "url": "https://github.com/elastic/elasticsearch/pull/55293#discussion_r411208229", "createdAt": "2020-04-20T08:55:06Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/repositories/RepositoryData.java", "diffHunk": "@@ -213,9 +214,16 @@ public RepositoryData addSnapshot(final SnapshotId snapshotId,\n         newSnapshotStates.put(snapshotId.getUUID(), snapshotState);\n         Map<String, Version> newSnapshotVersions = new HashMap<>(snapshotVersions);\n         newSnapshotVersions.put(snapshotId.getUUID(), version);\n-        Map<IndexId, Set<SnapshotId>> allIndexSnapshots = new HashMap<>(indexSnapshots);\n+        Map<IndexId, List<SnapshotId>> allIndexSnapshots = new HashMap<>(indexSnapshots);\n         for (final IndexId indexId : shardGenerations.indices()) {\n-            allIndexSnapshots.computeIfAbsent(indexId, k -> new LinkedHashSet<>()).add(snapshotId);\n+            final List<SnapshotId> snapshotIds = allIndexSnapshots.get(indexId);\n+            if (snapshotIds == null) {\n+                allIndexSnapshots.put(indexId, List.of(snapshotId));\n+            } else {\n+                final List<SnapshotId> copy = new ArrayList<>(snapshotIds);\n+                copy.add(snapshotId);\n+                allIndexSnapshots.put(indexId, List.copyOf(copy));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1ODQ0OA=="}, "originalCommit": {"oid": "b267d9c4ad95e220544c773d01750e886283d471"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTM4NzE3Mw==", "bodyText": "I looked into how List.copyOf is implemented, and lo and behold, it copies the elements twice (first calls Collection.toArray(), and then creates another copy of that temporary array in List.of (using manual for loop, FFS).\nThis means that the list is copied three times here, plus the resize of the ArrayList when calling copy.add(snapshotId);, leading to another full copy ....\nHigh-level languages ftw.", "url": "https://github.com/elastic/elasticsearch/pull/55293#discussion_r411387173", "createdAt": "2020-04-20T13:42:39Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/repositories/RepositoryData.java", "diffHunk": "@@ -213,9 +214,16 @@ public RepositoryData addSnapshot(final SnapshotId snapshotId,\n         newSnapshotStates.put(snapshotId.getUUID(), snapshotState);\n         Map<String, Version> newSnapshotVersions = new HashMap<>(snapshotVersions);\n         newSnapshotVersions.put(snapshotId.getUUID(), version);\n-        Map<IndexId, Set<SnapshotId>> allIndexSnapshots = new HashMap<>(indexSnapshots);\n+        Map<IndexId, List<SnapshotId>> allIndexSnapshots = new HashMap<>(indexSnapshots);\n         for (final IndexId indexId : shardGenerations.indices()) {\n-            allIndexSnapshots.computeIfAbsent(indexId, k -> new LinkedHashSet<>()).add(snapshotId);\n+            final List<SnapshotId> snapshotIds = allIndexSnapshots.get(indexId);\n+            if (snapshotIds == null) {\n+                allIndexSnapshots.put(indexId, List.of(snapshotId));\n+            } else {\n+                final List<SnapshotId> copy = new ArrayList<>(snapshotIds);\n+                copy.add(snapshotId);\n+                allIndexSnapshots.put(indexId, List.copyOf(copy));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1ODQ0OA=="}, "originalCommit": {"oid": "b267d9c4ad95e220544c773d01750e886283d471"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTQxMDQzMg==", "bodyText": ":) you win => I pushed 8319e21 , probably not worth the hassle to go further than this then.", "url": "https://github.com/elastic/elasticsearch/pull/55293#discussion_r411410432", "createdAt": "2020-04-20T14:11:25Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/repositories/RepositoryData.java", "diffHunk": "@@ -213,9 +214,16 @@ public RepositoryData addSnapshot(final SnapshotId snapshotId,\n         newSnapshotStates.put(snapshotId.getUUID(), snapshotState);\n         Map<String, Version> newSnapshotVersions = new HashMap<>(snapshotVersions);\n         newSnapshotVersions.put(snapshotId.getUUID(), version);\n-        Map<IndexId, Set<SnapshotId>> allIndexSnapshots = new HashMap<>(indexSnapshots);\n+        Map<IndexId, List<SnapshotId>> allIndexSnapshots = new HashMap<>(indexSnapshots);\n         for (final IndexId indexId : shardGenerations.indices()) {\n-            allIndexSnapshots.computeIfAbsent(indexId, k -> new LinkedHashSet<>()).add(snapshotId);\n+            final List<SnapshotId> snapshotIds = allIndexSnapshots.get(indexId);\n+            if (snapshotIds == null) {\n+                allIndexSnapshots.put(indexId, List.of(snapshotId));\n+            } else {\n+                final List<SnapshotId> copy = new ArrayList<>(snapshotIds);\n+                copy.add(snapshotId);\n+                allIndexSnapshots.put(indexId, List.copyOf(copy));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1ODQ0OA=="}, "originalCommit": {"oid": "b267d9c4ad95e220544c773d01750e886283d471"}, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1NDIxMTM4OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/repositories/RepositoryData.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQwNzozNzoyM1rOGIHLmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQwNzozNzoyM1rOGIHLmw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1OTQ1MQ==", "bodyText": "same thing here, copy of copy", "url": "https://github.com/elastic/elasticsearch/pull/55293#discussion_r411159451", "createdAt": "2020-04-20T07:37:23Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/repositories/RepositoryData.java", "diffHunk": "@@ -253,23 +261,25 @@ public RepositoryData removeSnapshot(final SnapshotId snapshotId, final ShardGen\n         newSnapshotStates.remove(snapshotId.getUUID());\n         final Map<String, Version> newSnapshotVersions = new HashMap<>(snapshotVersions);\n         newSnapshotVersions.remove(snapshotId.getUUID());\n-        Map<IndexId, Set<SnapshotId>> indexSnapshots = new HashMap<>();\n+        Map<IndexId, List<SnapshotId>> indexSnapshots = new HashMap<>();\n         for (final IndexId indexId : indices.values()) {\n-            Set<SnapshotId> set;\n-            Set<SnapshotId> snapshotIds = this.indexSnapshots.get(indexId);\n+            List<SnapshotId> remaining;\n+            List<SnapshotId> snapshotIds = this.indexSnapshots.get(indexId);\n             assert snapshotIds != null;\n-            if (snapshotIds.contains(snapshotId)) {\n+            final int listIndex = snapshotIds.indexOf(snapshotId);\n+            if (listIndex > -1) {\n                 if (snapshotIds.size() == 1) {\n                     // removing the snapshot will mean no more snapshots\n                     // have this index, so just skip over it\n                     continue;\n                 }\n-                set = new LinkedHashSet<>(snapshotIds);\n-                set.remove(snapshotId);\n+                remaining = new ArrayList<>(snapshotIds);\n+                remaining.remove(listIndex);\n+                remaining = List.copyOf(remaining);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b267d9c4ad95e220544c773d01750e886283d471"}, "originalPosition": 78}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1NDIxNDIyOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/repositories/RepositoryData.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQwNzozODowNlrOGIHNSw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQwNzozODowNlrOGIHNSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1OTg4Mw==", "bodyText": "copy of copy", "url": "https://github.com/elastic/elasticsearch/pull/55293#discussion_r411159883", "createdAt": "2020-04-20T07:38:06Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/repositories/RepositoryData.java", "diffHunk": "@@ -513,7 +523,7 @@ public static RepositoryData snapshotsFromXContent(final XContentParser parser,\n                             }\n                         }\n                         assert indexId != null;\n-                        indexSnapshots.put(indexId, snapshotIds);\n+                        indexSnapshots.put(indexId, List.copyOf(snapshotIds));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b267d9c4ad95e220544c773d01750e886283d471"}, "originalPosition": 131}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1081, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}