{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY2NDg0MzM1", "number": 51364, "title": "[ML] Add _cat/ml/anomaly_detectors API", "bodyText": "Adds new  _cat/ml/anomaly_detectors and  _cat/ml/anomaly_detectors/{job_id} endpoints\nExample output:\nGET /_cat/ml/anomaly_detectors?v\n>\nid                    state data.processed_records model.bytes model.memory_status forecast.total bucket.count\nhigh_sum_total_sales closed 4674                   1.5mb                        ok 0              743\nlow_request_rate     closed 1216                   40.5kb                       ok 0              1457\nresponse_code_rates  closed 14073                  132.7kb                      ok 0              1460\nurl_scanning         closed 14073                  501.7kb                      ok 0              1460\n\nSame call but sorted\nGET /_cat/ml/anomaly_detectors?v&s=dpr:desc\n>\nid                    state data.processed_records model.bytes model.memory_status forecast.total bucket.count\nresponse_code_rates  closed 14073                  132.7kb                      ok 0              1460\nurl_scanning         closed 14073                  501.7kb                      ok 0              1460\nhigh_sum_total_sales closed 4674                   1.5mb                        ok 0              743\nlow_request_rate     closed 1216                   40.5kb                       ok 0              1457\n\nFor specific jobs and only specific fields\nGET /_cat/ml/anomaly_detectors/*rate*?v&h=id,dpr,mb\n>\nid                  dpr   mb\nlow_request_rate    1216  40.5kb\nresponse_code_rates 28146 132.7kb\n\nAll other typical settings are supported as well.\nHelp output\nid                               |                                    | the job_id                                                       \nstate                            | s                                  | the job state                                                    \nopened_time                      | ot                                 | the amount of time the job has been opened                       \nassignment_explanation           | ae                                 | why the job is or is not assigned to a node                      \ndata.processed_records           | dpr,dataProcessedRecords           | number of processed records                                      \ndata.processed_fields            | dpr,dataProcessedFields            | number of processed fields                                       \ndata.input_bytes                 | dib,dataInputBytes                 | total input bytes                                                \ndata.input_records               | dir,dataInputRecords               | total record count                                               \ndata.input_fields                | dif,dataInputFields                | total field count                                                \ndata.invalid_dates               | did,dataInvalidDates               | number of records with invalid dates                             \ndata.missing_fields              | dmf,dataMissingFields              | number of records with missing fields                            \ndata.out_of_order_timestamps     | doot,dataOutOfOrderTimestamps      | number of records handled out of order                           \ndata.empty_buckets               | deb,dataEmptyBuckes                | number of empty buckets                                          \ndata.sparse_buckets              | dsb,dataSparseBuckets              | number of sparse buckets                                         \ndata.buckets                     | db,dataBuckes                      | total bucket count                                               \ndata.earliest_record             | der,dataEarliestRecord             | earliest record time                                             \ndata.latest_record               | dlr,dataLatestRecord               | latest record time                                               \ndata.last                        | dl,dataLast                        | last time data was seen                                          \ndata.last_empty_bucket           | dleb,dataLastEmptyBucket           | last time an empty bucket occurred                               \ndata.last_sparse_bucket          | dlsb,dataLastSparseBucket          | last time a sparse bucket occurred                               \nmodel.bytes                      | mb,modelBytes                      | model size                                                       \nmodel.memory_status              | mms,modelMemoryStatus              | current memory status                                            \nmodel.bytes_exceeded             | mbe,modelBytesExceeded             | how much the model has exceeded the limit                        \nmodel.memory_limit               | mml,modelMemoryLimit               | model memory limit                                               \nmodel.by_fields                  | mbf,modelByFields                  | count of 'by' fields                                             \nmodel.over_fields                | mof,modelOverFields                | count of 'over' fields                                           \nmodel.partition_fields           | mpf,modelPartitionFields           | count of 'partition' fields                                      \nmodel.bucket_allocation_failures | mbaf,modelBucketAllocationFailures | number of bucket allocation failures                             \nmodel.log_time                   | mlt,modelLogTime                   | when the model stats were gathered                               \nmodel.timestamp                  | mt,modelTimestamp                  | the time of the last record when the model stats were gathered   \nforecast.total                   | ft,forecastTotal                   | total number of forecasts                                        \nforecast.memory.min              | fmmin,forecastMemoryMin            | minimum memory used by forecasts                                 \nforecast.memory.max              | fmmax,forecastsMemoryMax           | maximum memory used by forecasts                                 \nforecast.memory.avg              | fmavg,forecastMemoryAvg            | average memory used by forecasts                                 \nforecast.memory.total            | fmt,forecastMemoryTotal            | total memory used by all forecasts                               \nforecast.records.min             | frmin,forecastRecordsMin           | minimum record count for forecasts                               \nforecast.records.max             | frmax,forecastRecordsMax           | maximum record count for forecasts                               \nforecast.records.avg             | fravg,forecastRecordsAvg           | average record count for forecasts                               \nforecast.records.total           | frt,forecastRecordsTotal           | total record count for all forecasts                             \nforecast.time.min                | ftmin,forecastTimeMin              | minimum runtime for forecasts                                    \nforecast.time.max                | ftmax,forecastTimeMax              | maximum run time for forecasts                                   \nforecast.time.avg                | ftavg,forecastTimeAvg              | average runtime for all forecasts (milliseconds)                 \nforecast.time.total              | ftt,forecastTimeTotal              | total runtime for all forecasts                                  \nnode.id                          | ni,nodeId                          | id of the assigned node                                          \nnode.name                        | nn,nodeName                        | name of the assigned node                                        \nnode.ephemeral_id                | ne,nodeEphemeralId                 | ephemeral id of the assigned node                                \nnode.address                     | na,nodeAddress                     | network address of the assigned node                             \nbucket.count                     | bc,bucketCount                     | bucket count                                                     \nbucket.time.total                | btt,bucketTimeTotal                | total bucket processing time                                     \nbucket.time.min                  | btmin,bucketTimeMin                | minimum bucket processing time                                   \nbucket.time.max                  | btmax,bucketTimeMax                | maximum bucket processing time                                   \nbucket.time.exp_avg              | btea,bucketTimeExpAvg              | exponential average bucket processing time (milliseconds)        \nbucket.time.exp_avg_hour         | bteah,bucketTimeExpAvgHour         | exponential average bucket processing time by hour (milliseconds)", "createdAt": "2020-01-23T17:41:42Z", "url": "https://github.com/elastic/elasticsearch/pull/51364", "merged": true, "mergeCommit": {"oid": "a25f9222c4ce3ff6eb766192d8e922a78c690f56"}, "closed": true, "closedAt": "2020-01-24T13:20:33Z", "author": {"login": "benwtrent"}, "timelineItems": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb9NwGmgH2gAyMzY2NDg0MzM1OmNlMzRjMzIxMTU0Zjc3OWQyMmQyNzQxYjAyZWJkOGU3Y2MxYTliZGQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABb9eBBvgH2gAyMzY2NDg0MzM1OjllYWE4ZTgzN2QwZmMzMjUwNDFiMjJlZjgyZjhlNWE0MmRkZmUzYjk=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "ce34c321154f779d22d2741b02ebd8e7cc1a9bdd", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/ce34c321154f779d22d2741b02ebd8e7cc1a9bdd", "committedDate": "2020-01-23T17:25:37Z", "message": "[ML] Add _cat/ml/anomaly_detectors/_stats"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ3NTMzMDEz", "url": "https://github.com/elastic/elasticsearch/pull/51364#pullrequestreview-347533013", "createdAt": "2020-01-23T18:58:29Z", "commit": {"oid": "ce34c321154f779d22d2741b02ebd8e7cc1a9bdd"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QxODo1ODoyOVrOFhJJfg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QxOTowNzowMlrOFhJY7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDI5NzIxNA==", "bodyText": "dataBuckes: missing \"t\"", "url": "https://github.com/elastic/elasticsearch/pull/51364#discussion_r370297214", "createdAt": "2020-01-23T18:58:29Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/rest/cat/RestCatJobStatsAction.java", "diffHunk": "@@ -0,0 +1,389 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.rest.cat;\n+\n+import org.elasticsearch.client.node.NodeClient;\n+import org.elasticsearch.cluster.metadata.MetaData;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.Table;\n+import org.elasticsearch.common.unit.ByteSizeValue;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.rest.RestController;\n+import org.elasticsearch.rest.RestRequest;\n+import org.elasticsearch.rest.RestResponse;\n+import org.elasticsearch.rest.action.RestResponseListener;\n+import org.elasticsearch.rest.action.cat.AbstractCatAction;\n+import org.elasticsearch.rest.action.cat.RestTable;\n+import org.elasticsearch.xpack.core.ml.action.GetJobsStatsAction;\n+import org.elasticsearch.xpack.core.ml.job.config.Job;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.DataCounts;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.ModelSizeStats;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.TimingStats;\n+import org.elasticsearch.xpack.core.ml.stats.ForecastStats;\n+\n+import static org.elasticsearch.rest.RestRequest.Method.GET;\n+\n+public class RestCatJobStatsAction extends AbstractCatAction {\n+\n+    public RestCatJobStatsAction(RestController controller) {\n+        controller.registerHandler(GET, \"_cat/ml/anomaly_detectors/{\" + Job.ID.getPreferredName() + \"}/_stats\", this);\n+        controller.registerHandler(GET, \"_cat/ml/anomaly_detectors/_stats\", this);\n+    }\n+\n+    @Override\n+    public String getName() {\n+        return \"cat_ml_get_job_stats_action\";\n+    }\n+\n+    @Override\n+    protected RestChannelConsumer doCatRequest(RestRequest restRequest, NodeClient client) {\n+        String jobId = restRequest.param(Job.ID.getPreferredName());\n+        if (Strings.isNullOrEmpty(jobId)) {\n+            jobId = MetaData.ALL;\n+        }\n+        GetJobsStatsAction.Request request = new GetJobsStatsAction.Request(jobId);\n+        request.setAllowNoJobs(restRequest.paramAsBoolean(GetJobsStatsAction.Request.ALLOW_NO_JOBS.getPreferredName(),\n+            request.allowNoJobs()));\n+        return channel -> client.execute(GetJobsStatsAction.INSTANCE, request, new RestResponseListener<>(channel) {\n+            @Override\n+            public RestResponse buildResponse(GetJobsStatsAction.Response getJobStatsResponse) throws Exception {\n+                return RestTable.buildResponse(buildTable(restRequest, getJobStatsResponse), channel);\n+            }\n+        });\n+    }\n+\n+    @Override\n+    protected void documentation(StringBuilder sb) {\n+        sb.append(\"/_cat/ml/anomaly_detectors/_stats\\n\");\n+        sb.append(\"/_cat/ml/anomaly_detectors/{job_id}/_stats\\n\");\n+    }\n+\n+    @Override\n+    protected Table getTableWithHeader(RestRequest request) {\n+        Table table = new Table();\n+        table.startHeaders();\n+\n+        // Job Info\n+        table.addCell(\"id\", TableColumnAttributeBuilder.builder().setDescription(\"the job_id\").build());\n+        table.addCell(\"state\", TableColumnAttributeBuilder.builder()\n+            .setDescription(\"the job state\")\n+            .setAliases(\"s\")\n+            .setTextAlignment(TableColumnAttributeBuilder.TextAlign.RIGHT)\n+            .build());\n+        table.addCell(\"opened_time\",\n+            TableColumnAttributeBuilder.builder()\n+                .setDescription(\"the amount of time the job has been opened\")\n+                .setAliases(\"ot\")\n+                .setDisplayByDefault(false)\n+                .build());\n+        table.addCell(\"assignment_explanation\",\n+            TableColumnAttributeBuilder.builder(\"why the job is or is not assigned to a node\", false)\n+                .setAliases(\"ae\")\n+                .build());\n+\n+        // Data Counts\n+        table.addCell(\"data.processed_records\",\n+            TableColumnAttributeBuilder.builder(\"number of processed records\")\n+            .setAliases(\"dpr\", \"dataProcessedRecords\")\n+            .build());\n+        table.addCell(\"data.processed_fields\",\n+            TableColumnAttributeBuilder.builder(\"number of processed fields\", false)\n+                .setAliases(\"dpr\", \"dataProcessedFields\")\n+                .build());\n+        table.addCell(\"data.input_bytes\",\n+            TableColumnAttributeBuilder.builder(\"total input bytes\", false)\n+                .setAliases(\"dib\", \"dataInputBytes\")\n+                .build());\n+        table.addCell(\"data.input_records\",\n+            TableColumnAttributeBuilder.builder(\"total record count\", false)\n+                .setAliases(\"dir\", \"dataInputRecords\")\n+                .build());\n+        table.addCell(\"data.input_fields\",\n+            TableColumnAttributeBuilder.builder(\"total field count\", false)\n+                .setAliases(\"dif\", \"dataInputFields\")\n+                .build());\n+        table.addCell(\"data.invalid_dates\",\n+            TableColumnAttributeBuilder.builder(\"number of records with invalid dates\", false)\n+                .setAliases(\"did\", \"dataInvalidDates\")\n+                .build());\n+        table.addCell(\"data.missing_fields\",\n+            TableColumnAttributeBuilder.builder(\"number of records with missing fields\", false)\n+                .setAliases(\"dmf\", \"dataMissingFields\")\n+                .build());\n+        table.addCell(\"data.out_of_order_timestamps\",\n+            TableColumnAttributeBuilder.builder(\"number of records handled out of order\", false)\n+                .setAliases(\"doot\", \"dataOutOfOrderTimestamps\")\n+                .build());\n+        table.addCell(\"data.empty_buckets\",\n+            TableColumnAttributeBuilder.builder(\"number of empty buckets\", false)\n+                .setAliases(\"deb\", \"dataEmptyBuckes\")\n+                .build());\n+        table.addCell(\"data.sparse_buckets\",\n+            TableColumnAttributeBuilder.builder(\"number of sparse buckets\", false)\n+                .setAliases(\"dsb\", \"dataSparseBuckets\")\n+                .build());\n+        table.addCell(\"data.buckets\",\n+            TableColumnAttributeBuilder.builder(\"total bucket count\", false)\n+                .setAliases(\"db\", \"dataBuckes\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce34c321154f779d22d2741b02ebd8e7cc1a9bdd"}, "originalPosition": 131}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDI5NzkyMg==", "bodyText": "dataBuckes: missing \"t\"", "url": "https://github.com/elastic/elasticsearch/pull/51364#discussion_r370297922", "createdAt": "2020-01-23T19:00:00Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/rest/cat/RestCatJobStatsAction.java", "diffHunk": "@@ -0,0 +1,389 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.rest.cat;\n+\n+import org.elasticsearch.client.node.NodeClient;\n+import org.elasticsearch.cluster.metadata.MetaData;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.Table;\n+import org.elasticsearch.common.unit.ByteSizeValue;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.rest.RestController;\n+import org.elasticsearch.rest.RestRequest;\n+import org.elasticsearch.rest.RestResponse;\n+import org.elasticsearch.rest.action.RestResponseListener;\n+import org.elasticsearch.rest.action.cat.AbstractCatAction;\n+import org.elasticsearch.rest.action.cat.RestTable;\n+import org.elasticsearch.xpack.core.ml.action.GetJobsStatsAction;\n+import org.elasticsearch.xpack.core.ml.job.config.Job;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.DataCounts;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.ModelSizeStats;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.TimingStats;\n+import org.elasticsearch.xpack.core.ml.stats.ForecastStats;\n+\n+import static org.elasticsearch.rest.RestRequest.Method.GET;\n+\n+public class RestCatJobStatsAction extends AbstractCatAction {\n+\n+    public RestCatJobStatsAction(RestController controller) {\n+        controller.registerHandler(GET, \"_cat/ml/anomaly_detectors/{\" + Job.ID.getPreferredName() + \"}/_stats\", this);\n+        controller.registerHandler(GET, \"_cat/ml/anomaly_detectors/_stats\", this);\n+    }\n+\n+    @Override\n+    public String getName() {\n+        return \"cat_ml_get_job_stats_action\";\n+    }\n+\n+    @Override\n+    protected RestChannelConsumer doCatRequest(RestRequest restRequest, NodeClient client) {\n+        String jobId = restRequest.param(Job.ID.getPreferredName());\n+        if (Strings.isNullOrEmpty(jobId)) {\n+            jobId = MetaData.ALL;\n+        }\n+        GetJobsStatsAction.Request request = new GetJobsStatsAction.Request(jobId);\n+        request.setAllowNoJobs(restRequest.paramAsBoolean(GetJobsStatsAction.Request.ALLOW_NO_JOBS.getPreferredName(),\n+            request.allowNoJobs()));\n+        return channel -> client.execute(GetJobsStatsAction.INSTANCE, request, new RestResponseListener<>(channel) {\n+            @Override\n+            public RestResponse buildResponse(GetJobsStatsAction.Response getJobStatsResponse) throws Exception {\n+                return RestTable.buildResponse(buildTable(restRequest, getJobStatsResponse), channel);\n+            }\n+        });\n+    }\n+\n+    @Override\n+    protected void documentation(StringBuilder sb) {\n+        sb.append(\"/_cat/ml/anomaly_detectors/_stats\\n\");\n+        sb.append(\"/_cat/ml/anomaly_detectors/{job_id}/_stats\\n\");\n+    }\n+\n+    @Override\n+    protected Table getTableWithHeader(RestRequest request) {\n+        Table table = new Table();\n+        table.startHeaders();\n+\n+        // Job Info\n+        table.addCell(\"id\", TableColumnAttributeBuilder.builder().setDescription(\"the job_id\").build());\n+        table.addCell(\"state\", TableColumnAttributeBuilder.builder()\n+            .setDescription(\"the job state\")\n+            .setAliases(\"s\")\n+            .setTextAlignment(TableColumnAttributeBuilder.TextAlign.RIGHT)\n+            .build());\n+        table.addCell(\"opened_time\",\n+            TableColumnAttributeBuilder.builder()\n+                .setDescription(\"the amount of time the job has been opened\")\n+                .setAliases(\"ot\")\n+                .setDisplayByDefault(false)\n+                .build());\n+        table.addCell(\"assignment_explanation\",\n+            TableColumnAttributeBuilder.builder(\"why the job is or is not assigned to a node\", false)\n+                .setAliases(\"ae\")\n+                .build());\n+\n+        // Data Counts\n+        table.addCell(\"data.processed_records\",\n+            TableColumnAttributeBuilder.builder(\"number of processed records\")\n+            .setAliases(\"dpr\", \"dataProcessedRecords\")\n+            .build());\n+        table.addCell(\"data.processed_fields\",\n+            TableColumnAttributeBuilder.builder(\"number of processed fields\", false)\n+                .setAliases(\"dpr\", \"dataProcessedFields\")\n+                .build());\n+        table.addCell(\"data.input_bytes\",\n+            TableColumnAttributeBuilder.builder(\"total input bytes\", false)\n+                .setAliases(\"dib\", \"dataInputBytes\")\n+                .build());\n+        table.addCell(\"data.input_records\",\n+            TableColumnAttributeBuilder.builder(\"total record count\", false)\n+                .setAliases(\"dir\", \"dataInputRecords\")\n+                .build());\n+        table.addCell(\"data.input_fields\",\n+            TableColumnAttributeBuilder.builder(\"total field count\", false)\n+                .setAliases(\"dif\", \"dataInputFields\")\n+                .build());\n+        table.addCell(\"data.invalid_dates\",\n+            TableColumnAttributeBuilder.builder(\"number of records with invalid dates\", false)\n+                .setAliases(\"did\", \"dataInvalidDates\")\n+                .build());\n+        table.addCell(\"data.missing_fields\",\n+            TableColumnAttributeBuilder.builder(\"number of records with missing fields\", false)\n+                .setAliases(\"dmf\", \"dataMissingFields\")\n+                .build());\n+        table.addCell(\"data.out_of_order_timestamps\",\n+            TableColumnAttributeBuilder.builder(\"number of records handled out of order\", false)\n+                .setAliases(\"doot\", \"dataOutOfOrderTimestamps\")\n+                .build());\n+        table.addCell(\"data.empty_buckets\",\n+            TableColumnAttributeBuilder.builder(\"number of empty buckets\", false)\n+                .setAliases(\"deb\", \"dataEmptyBuckes\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce34c321154f779d22d2741b02ebd8e7cc1a9bdd"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMwMTE2NA==", "bodyText": "nit: a bool to avoid repeating forecastStats == null || forecastStats.getTotal() <= 0L for every cell?", "url": "https://github.com/elastic/elasticsearch/pull/51364#discussion_r370301164", "createdAt": "2020-01-23T19:07:02Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/rest/cat/RestCatJobStatsAction.java", "diffHunk": "@@ -0,0 +1,389 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.rest.cat;\n+\n+import org.elasticsearch.client.node.NodeClient;\n+import org.elasticsearch.cluster.metadata.MetaData;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.Table;\n+import org.elasticsearch.common.unit.ByteSizeValue;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.rest.RestController;\n+import org.elasticsearch.rest.RestRequest;\n+import org.elasticsearch.rest.RestResponse;\n+import org.elasticsearch.rest.action.RestResponseListener;\n+import org.elasticsearch.rest.action.cat.AbstractCatAction;\n+import org.elasticsearch.rest.action.cat.RestTable;\n+import org.elasticsearch.xpack.core.ml.action.GetJobsStatsAction;\n+import org.elasticsearch.xpack.core.ml.job.config.Job;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.DataCounts;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.ModelSizeStats;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.TimingStats;\n+import org.elasticsearch.xpack.core.ml.stats.ForecastStats;\n+\n+import static org.elasticsearch.rest.RestRequest.Method.GET;\n+\n+public class RestCatJobStatsAction extends AbstractCatAction {\n+\n+    public RestCatJobStatsAction(RestController controller) {\n+        controller.registerHandler(GET, \"_cat/ml/anomaly_detectors/{\" + Job.ID.getPreferredName() + \"}/_stats\", this);\n+        controller.registerHandler(GET, \"_cat/ml/anomaly_detectors/_stats\", this);\n+    }\n+\n+    @Override\n+    public String getName() {\n+        return \"cat_ml_get_job_stats_action\";\n+    }\n+\n+    @Override\n+    protected RestChannelConsumer doCatRequest(RestRequest restRequest, NodeClient client) {\n+        String jobId = restRequest.param(Job.ID.getPreferredName());\n+        if (Strings.isNullOrEmpty(jobId)) {\n+            jobId = MetaData.ALL;\n+        }\n+        GetJobsStatsAction.Request request = new GetJobsStatsAction.Request(jobId);\n+        request.setAllowNoJobs(restRequest.paramAsBoolean(GetJobsStatsAction.Request.ALLOW_NO_JOBS.getPreferredName(),\n+            request.allowNoJobs()));\n+        return channel -> client.execute(GetJobsStatsAction.INSTANCE, request, new RestResponseListener<>(channel) {\n+            @Override\n+            public RestResponse buildResponse(GetJobsStatsAction.Response getJobStatsResponse) throws Exception {\n+                return RestTable.buildResponse(buildTable(restRequest, getJobStatsResponse), channel);\n+            }\n+        });\n+    }\n+\n+    @Override\n+    protected void documentation(StringBuilder sb) {\n+        sb.append(\"/_cat/ml/anomaly_detectors/_stats\\n\");\n+        sb.append(\"/_cat/ml/anomaly_detectors/{job_id}/_stats\\n\");\n+    }\n+\n+    @Override\n+    protected Table getTableWithHeader(RestRequest request) {\n+        Table table = new Table();\n+        table.startHeaders();\n+\n+        // Job Info\n+        table.addCell(\"id\", TableColumnAttributeBuilder.builder().setDescription(\"the job_id\").build());\n+        table.addCell(\"state\", TableColumnAttributeBuilder.builder()\n+            .setDescription(\"the job state\")\n+            .setAliases(\"s\")\n+            .setTextAlignment(TableColumnAttributeBuilder.TextAlign.RIGHT)\n+            .build());\n+        table.addCell(\"opened_time\",\n+            TableColumnAttributeBuilder.builder()\n+                .setDescription(\"the amount of time the job has been opened\")\n+                .setAliases(\"ot\")\n+                .setDisplayByDefault(false)\n+                .build());\n+        table.addCell(\"assignment_explanation\",\n+            TableColumnAttributeBuilder.builder(\"why the job is or is not assigned to a node\", false)\n+                .setAliases(\"ae\")\n+                .build());\n+\n+        // Data Counts\n+        table.addCell(\"data.processed_records\",\n+            TableColumnAttributeBuilder.builder(\"number of processed records\")\n+            .setAliases(\"dpr\", \"dataProcessedRecords\")\n+            .build());\n+        table.addCell(\"data.processed_fields\",\n+            TableColumnAttributeBuilder.builder(\"number of processed fields\", false)\n+                .setAliases(\"dpr\", \"dataProcessedFields\")\n+                .build());\n+        table.addCell(\"data.input_bytes\",\n+            TableColumnAttributeBuilder.builder(\"total input bytes\", false)\n+                .setAliases(\"dib\", \"dataInputBytes\")\n+                .build());\n+        table.addCell(\"data.input_records\",\n+            TableColumnAttributeBuilder.builder(\"total record count\", false)\n+                .setAliases(\"dir\", \"dataInputRecords\")\n+                .build());\n+        table.addCell(\"data.input_fields\",\n+            TableColumnAttributeBuilder.builder(\"total field count\", false)\n+                .setAliases(\"dif\", \"dataInputFields\")\n+                .build());\n+        table.addCell(\"data.invalid_dates\",\n+            TableColumnAttributeBuilder.builder(\"number of records with invalid dates\", false)\n+                .setAliases(\"did\", \"dataInvalidDates\")\n+                .build());\n+        table.addCell(\"data.missing_fields\",\n+            TableColumnAttributeBuilder.builder(\"number of records with missing fields\", false)\n+                .setAliases(\"dmf\", \"dataMissingFields\")\n+                .build());\n+        table.addCell(\"data.out_of_order_timestamps\",\n+            TableColumnAttributeBuilder.builder(\"number of records handled out of order\", false)\n+                .setAliases(\"doot\", \"dataOutOfOrderTimestamps\")\n+                .build());\n+        table.addCell(\"data.empty_buckets\",\n+            TableColumnAttributeBuilder.builder(\"number of empty buckets\", false)\n+                .setAliases(\"deb\", \"dataEmptyBuckes\")\n+                .build());\n+        table.addCell(\"data.sparse_buckets\",\n+            TableColumnAttributeBuilder.builder(\"number of sparse buckets\", false)\n+                .setAliases(\"dsb\", \"dataSparseBuckets\")\n+                .build());\n+        table.addCell(\"data.buckets\",\n+            TableColumnAttributeBuilder.builder(\"total bucket count\", false)\n+                .setAliases(\"db\", \"dataBuckes\")\n+                .build());\n+        table.addCell(\"data.earliest_record\",\n+            TableColumnAttributeBuilder.builder(\"earliest record time\", false)\n+                .setAliases(\"der\", \"dataEarliestRecord\")\n+                .build());\n+        table.addCell(\"data.latest_record\",\n+            TableColumnAttributeBuilder.builder(\"latest record time\", false)\n+                .setAliases(\"dlr\", \"dataLatestRecord\")\n+                .build());\n+        table.addCell(\"data.last\",\n+            TableColumnAttributeBuilder.builder(\"last time data was seen\", false)\n+                .setAliases(\"dl\", \"dataLast\")\n+                .build());\n+        table.addCell(\"data.last_empty_bucket\",\n+            TableColumnAttributeBuilder.builder(\"last time an empty bucket occurred\", false)\n+                .setAliases(\"dleb\", \"dataLastEmptyBucket\")\n+                .build());\n+        table.addCell(\"data.last_sparse_bucket\",\n+            TableColumnAttributeBuilder.builder(\"last time a sparse bucket occurred\", false)\n+                .setAliases(\"dlsb\", \"dataLastSparseBucket\")\n+                .build());\n+\n+        // Model Size stats\n+        table.addCell(\"model.bytes\",\n+            TableColumnAttributeBuilder.builder(\"model size\").setAliases(\"mb\", \"modelBytes\").build());\n+        table.addCell(\"model.memory_status\",\n+            TableColumnAttributeBuilder.builder(\"current memory status\")\n+                .setAliases(\"mms\", \"modelMemoryStatus\")\n+                .setTextAlignment(TableColumnAttributeBuilder.TextAlign.RIGHT)\n+                .build());\n+        table.addCell(\"model.bytes_exceeded\",\n+            TableColumnAttributeBuilder.builder(\"how much the model has exceeded the limit\", false)\n+                .setAliases(\"mbe\", \"modelBytesExceeded\")\n+                .build());\n+        table.addCell(\"model.memory_limit\",\n+            TableColumnAttributeBuilder.builder(\"model memory limit\", false)\n+                .setAliases(\"mml\", \"modelMemoryLimit\")\n+                .build());\n+        table.addCell(\"model.by_fields\",\n+            TableColumnAttributeBuilder.builder(\"count of 'by' fields\", false)\n+                .setAliases(\"mbf\", \"modelByFields\")\n+                .build());\n+        table.addCell(\"model.over_fields\",\n+            TableColumnAttributeBuilder.builder(\"count of 'over' fields\", false)\n+                .setAliases(\"mof\", \"modelOverFields\")\n+                .build());\n+        table.addCell(\"model.partition_fields\",\n+            TableColumnAttributeBuilder.builder(\"count of 'partition' fields\", false)\n+                .setAliases(\"mpf\", \"modelPartitionFields\")\n+                .build());\n+        table.addCell(\"model.bucket_allocation_failures\",\n+            TableColumnAttributeBuilder.builder(\"number of bucket allocation failures\", false)\n+                .setAliases(\"mbaf\", \"modelBucketAllocationFailures\")\n+                .build());\n+        table.addCell(\"model.log_time\",\n+            TableColumnAttributeBuilder.builder(\"when the model stats were gathered\", false)\n+                .setAliases(\"mlt\", \"modelLogTime\")\n+                .build());\n+        table.addCell(\"model.timestamp\",\n+            TableColumnAttributeBuilder.builder(\"the time of the last record when the model stats were gathered\", false)\n+                .setAliases(\"mt\", \"modelTimestamp\")\n+                .build());\n+\n+        // Forecast Stats\n+        table.addCell(\"forecast.\" + ForecastStats.Fields.TOTAL,\n+            TableColumnAttributeBuilder.builder(\"total number of forecasts\").setAliases(\"ft\", \"forecastTotal\").build());\n+        table.addCell(\"forecast.memory.min\",\n+            TableColumnAttributeBuilder.builder(\"minimum memory used by forecasts\", false)\n+                .setAliases(\"fmmin\", \"forecastMemoryMin\")\n+                .build());\n+        table.addCell(\"forecast.memory.max\",\n+            TableColumnAttributeBuilder.builder(\"maximum memory used by forecasts\", false)\n+                .setAliases(\"fmmax\", \"forecastsMemoryMax\")\n+                .build());\n+        table.addCell(\"forecast.memory.avg\",\n+            TableColumnAttributeBuilder.builder(\"average memory used by forecasts\", false)\n+                .setAliases(\"fmavg\", \"forecastMemoryAvg\")\n+                .build());\n+        table.addCell(\"forecast.memory.total\",\n+            TableColumnAttributeBuilder.builder(\"total memory used by all forecasts\", false)\n+                .setAliases(\"fmt\", \"forecastMemoryTotal\")\n+                .build());\n+        table.addCell(\"forecast.\" + ForecastStats.Fields.RECORDS + \".min\",\n+            TableColumnAttributeBuilder.builder(\"minimum record count for forecasts\", false)\n+                .setAliases(\"frmin\", \"forecastRecordsMin\")\n+                .build());\n+        table.addCell(\"forecast.\" + ForecastStats.Fields.RECORDS + \".max\",\n+            TableColumnAttributeBuilder.builder(\"maximum record count for forecasts\", false)\n+                .setAliases(\"frmax\", \"forecastRecordsMax\")\n+                .build());\n+        table.addCell(\"forecast.\" + ForecastStats.Fields.RECORDS + \".avg\",\n+            TableColumnAttributeBuilder.builder(\"average record count for forecasts\", false)\n+                .setAliases(\"fravg\", \"forecastRecordsAvg\")\n+                .build());\n+        table.addCell(\"forecast.\" + ForecastStats.Fields.RECORDS + \".total\",\n+            TableColumnAttributeBuilder.builder(\"total record count for all forecasts\", false)\n+                .setAliases(\"frt\", \"forecastRecordsTotal\")\n+                .build());\n+        table.addCell(\"forecast.time.min\",\n+            TableColumnAttributeBuilder.builder(\"minimum runtime for forecasts\", false)\n+                .setAliases(\"ftmin\", \"forecastTimeMin\")\n+                .build());\n+        table.addCell(\"forecast.time.max\",\n+            TableColumnAttributeBuilder.builder(\"maximum run time for forecasts\", false)\n+                .setAliases(\"ftmax\", \"forecastTimeMax\")\n+                .build());\n+        table.addCell(\"forecast.time.avg\",\n+            TableColumnAttributeBuilder.builder(\"average runtime for all forecasts (milliseconds)\", false)\n+                .setAliases(\"ftavg\", \"forecastTimeAvg\")\n+                .build());\n+        table.addCell(\"forecast.time.total\",\n+            TableColumnAttributeBuilder.builder(\"total runtime for all forecasts\", false)\n+                .setAliases(\"ftt\", \"forecastTimeTotal\").build());\n+\n+        //Node info\n+        table.addCell(\"node.id\",\n+            TableColumnAttributeBuilder.builder(\"id of the assigned node\", false)\n+                .setAliases(\"ni\", \"nodeId\")\n+                .build());\n+        table.addCell(\"node.name\",\n+            TableColumnAttributeBuilder.builder(\"name of the assigned node\", false)\n+                .setAliases(\"nn\", \"nodeName\")\n+                .build());\n+        table.addCell(\"node.ephemeral_id\",\n+            TableColumnAttributeBuilder.builder(\"ephemeral id of the assigned node\", false)\n+                .setAliases(\"ne\", \"nodeEphemeralId\")\n+                .build());\n+        table.addCell(\"node.address\",\n+            TableColumnAttributeBuilder.builder(\"network address of the assigned node\", false)\n+                .setAliases(\"na\", \"nodeAddress\")\n+                .build());\n+\n+        //Timing Stats\n+        table.addCell(\"bucket.count\",\n+            TableColumnAttributeBuilder.builder(\"bucket count\")\n+                .setAliases(\"bc\", \"bucketCount\")\n+                .build());\n+        table.addCell(\"bucket.time.total\",\n+            TableColumnAttributeBuilder.builder(\"total bucket processing time\", false)\n+                .setAliases(\"btt\", \"bucketTimeTotal\")\n+                .build());\n+        table.addCell(\"bucket.time.min\",\n+            TableColumnAttributeBuilder.builder(\"minimum bucket processing time\", false)\n+                .setAliases(\"btmin\", \"bucketTimeMin\")\n+                .build());\n+        table.addCell(\"bucket.time.max\",\n+            TableColumnAttributeBuilder.builder(\"maximum bucket processing time\", false)\n+                .setAliases(\"btmax\", \"bucketTimeMax\")\n+                .build());\n+        table.addCell(\"bucket.time.exp_avg\",\n+            TableColumnAttributeBuilder.builder(\"exponential average bucket processing time (milliseconds)\", false)\n+                .setAliases(\"btea\", \"bucketTimeExpAvg\")\n+                .build());\n+        table.addCell(\"bucket.time.exp_avg_hour\",\n+            TableColumnAttributeBuilder.builder(\"exponential average bucket processing time by hour (milliseconds)\", false)\n+                .setAliases(\"bteah\", \"bucketTimeExpAvgHour\")\n+                .build());\n+\n+        table.endHeaders();\n+        return table;\n+    }\n+\n+    private Table buildTable(RestRequest request, GetJobsStatsAction.Response jobStats) {\n+        Table table = getTableWithHeader(request);\n+        jobStats.getResponse().results().forEach(job -> {\n+            table.startRow();\n+            table.addCell(job.getJobId());\n+            table.addCell(job.getState().value());\n+            table.addCell(job.getOpenTime());\n+            table.addCell(job.getAssignmentExplanation());\n+\n+            DataCounts dataCounts = job.getDataCounts();\n+            table.addCell(dataCounts.getProcessedRecordCount());\n+            table.addCell(dataCounts.getProcessedFieldCount());\n+            table.addCell(new ByteSizeValue(dataCounts.getInputBytes()));\n+            table.addCell(dataCounts.getInputRecordCount());\n+            table.addCell(dataCounts.getInputFieldCount());\n+            table.addCell(dataCounts.getInvalidDateCount());\n+            table.addCell(dataCounts.getMissingFieldCount());\n+            table.addCell(dataCounts.getOutOfOrderTimeStampCount());\n+            table.addCell(dataCounts.getEmptyBucketCount());\n+            table.addCell(dataCounts.getSparseBucketCount());\n+            table.addCell(dataCounts.getBucketCount());\n+            table.addCell(dataCounts.getEarliestRecordTimeStamp());\n+            table.addCell(dataCounts.getLatestRecordTimeStamp());\n+            table.addCell(dataCounts.getLastDataTimeStamp());\n+            table.addCell(dataCounts.getLatestEmptyBucketTimeStamp());\n+            table.addCell(dataCounts.getLatestSparseBucketTimeStamp());\n+\n+\n+            ModelSizeStats modelSizeStats = job.getModelSizeStats();\n+            table.addCell(modelSizeStats == null ? null : new ByteSizeValue(modelSizeStats.getModelBytes()));\n+            table.addCell(modelSizeStats == null ? null : modelSizeStats.getMemoryStatus().toString());\n+            table.addCell(modelSizeStats == null || modelSizeStats.getModelBytesExceeded() == null ?\n+                null :\n+                new ByteSizeValue(modelSizeStats.getModelBytesExceeded()));\n+            table.addCell(modelSizeStats == null || modelSizeStats.getModelBytesMemoryLimit() == null ?\n+                null :\n+                new ByteSizeValue(modelSizeStats.getModelBytesMemoryLimit()));\n+            table.addCell(modelSizeStats == null ? null : modelSizeStats.getTotalByFieldCount());\n+            table.addCell(modelSizeStats == null ? null : modelSizeStats.getTotalOverFieldCount());\n+            table.addCell(modelSizeStats == null ? null : modelSizeStats.getTotalPartitionFieldCount());\n+            table.addCell(modelSizeStats == null ? null : modelSizeStats.getBucketAllocationFailuresCount());\n+            table.addCell(modelSizeStats == null ? null : modelSizeStats.getLogTime());\n+            table.addCell(modelSizeStats == null ? null : modelSizeStats.getTimestamp());\n+\n+            ForecastStats forecastStats = job.getForecastStats();\n+            table.addCell(forecastStats == null ? null : forecastStats.getTotal());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce34c321154f779d22d2741b02ebd8e7cc1a9bdd"}, "originalPosition": 339}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9eaa8e837d0fc325041b22ef82f8e5a42ddfe3b9", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/9eaa8e837d0fc325041b22ef82f8e5a42ddfe3b9", "committedDate": "2020-01-24T12:22:35Z", "message": "addressing PR feedback"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2885, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}