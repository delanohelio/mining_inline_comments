{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTMxMzc4NjA5", "number": 65796, "title": "SQL: Fix SUM(all zeroes) to return 0 instead of NULL", "bodyText": "Previously the SUM(all zeroes) was NULL, but after this change the SUM\nSQL function call is automatically upgraded into a stats aggregation\ninstead of a sum aggregation. The stats aggregation only results in\nNULL if the there were no rows, no values to aggregate, which is the\nexpected behaviour across different SQL implementations.\nThis is a workaround for #45251 .", "createdAt": "2020-12-03T00:40:36Z", "url": "https://github.com/elastic/elasticsearch/pull/65796", "merged": true, "mergeCommit": {"oid": "b74792a8f20ce00142d6fac5e1034e611ef86f8d"}, "closed": true, "closedAt": "2020-12-09T17:13:28Z", "author": {"login": "palesz"}, "timelineItems": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdiXx11gH2gAyNTMxMzc4NjA5OmQyYmE5NThkYWIwMmM1OTk1MjczMDhiZTc1NWZjMGM4OWM5MjgzZTM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdkcy6wAFqTU0ODA3NjcyNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "d2ba958dab02c599527308be755fc0c89c9283e3", "author": {"user": {"login": "palesz", "name": "Andras Palinkas"}}, "url": "https://github.com/elastic/elasticsearch/commit/d2ba958dab02c599527308be755fc0c89c9283e3", "committedDate": "2020-12-03T00:12:55Z", "message": "SQL: Fix SUM(all zeroes)\n\nPreviously the SUM(all zeroes) was `NULL`, but after this change the SUM\nSQL function call is automatically upgraded into a `stats` aggregation\ninstead of a `sum` aggregation. The `stats` aggregation only results in\n`NULL` if the there were no rows, no values to aggregate, which is the\nexpected behaviour across different SQL implementations.\n\nThis is a workaround for #45251 ."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQzNjEzNjkz", "url": "https://github.com/elastic/elasticsearch/pull/65796#pullrequestreview-543613693", "createdAt": "2020-12-03T06:29:48Z", "commit": {"oid": "d2ba958dab02c599527308be755fc0c89c9283e3"}, "state": "COMMENTED", "comments": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QwNjoyOTo0OFrOH99WIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QwODozNzo1NlrOH-JTsA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDczMDI3Mg==", "bodyText": "I'm not against tests for FIRST and LAST, but why are these relevant for SUM() returning 0 instead of NULL?", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534730272", "createdAt": "2020-12-03T06:29:48Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/sql/qa/server/src/main/resources/agg-nulls-zeros.csv-spec", "diffHunk": "@@ -0,0 +1,359 @@\n+\n+aggregatingAllZerosWithFirst\n+schema::FIRST_AllZeros:i\n+SELECT FIRST(bytes_in) as \"FIRST_AllZeros\" FROM logs WHERE bytes_in = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2ba958dab02c599527308be755fc0c89c9283e3"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDczMTc3OQ==", "bodyText": "Also, to make a bit more complex, I'd also add SELECT COUNT(*), FIRST(bytes_in) as FIRST_AllZeros, FIRST(bytes_out) as FIRST_AllNulls FROM logs WHERE bytes_in = 0 AND bytes_out IS NULL.", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534731779", "createdAt": "2020-12-03T06:31:24Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/sql/qa/server/src/main/resources/agg-nulls-zeros.csv-spec", "diffHunk": "@@ -0,0 +1,359 @@\n+\n+aggregatingAllZerosWithFirst\n+schema::FIRST_AllZeros:i\n+SELECT FIRST(bytes_in) as \"FIRST_AllZeros\" FROM logs WHERE bytes_in = 0;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDczMDI3Mg=="}, "originalCommit": {"oid": "d2ba958dab02c599527308be755fc0c89c9283e3"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDczNTY1NA==", "bodyText": "I don't think a new csv-spec file is needed. There are two (agg.sql-spec and agg.csv-spec) that deal with aggregations already. I'd add the tests below to the existing file(s).", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534735654", "createdAt": "2020-12-03T06:35:20Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/sql/qa/server/src/main/resources/agg-nulls-zeros.csv-spec", "diffHunk": "@@ -0,0 +1,359 @@\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2ba958dab02c599527308be755fc0c89c9283e3"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDczNjQzMw==", "bodyText": "We already have a test that deals with this scenario: SELECT COUNT(*) count FROM test_emp WHERE first_name IS NULL", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534736433", "createdAt": "2020-12-03T06:36:08Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/sql/qa/server/src/main/resources/agg-nulls-zeros.csv-spec", "diffHunk": "@@ -0,0 +1,359 @@\n+\n+aggregatingAllZerosWithFirst\n+schema::FIRST_AllZeros:i\n+SELECT FIRST(bytes_in) as \"FIRST_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+FIRST_AllZeros \n+---------------\n+0              \n+;\n+\n+\n+aggregatingAllNullsWithFirst\n+schema::FIRST_AllNulls:i\n+SELECT FIRST(bytes_out) as \"FIRST_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+FIRST_AllNulls \n+---------------\n+null           \n+;\n+\n+\n+aggregatingAllZerosWithLast\n+schema::LAST_AllZeros:i\n+SELECT LAST(bytes_in) as \"LAST_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ LAST_AllZeros \n+---------------\n+0              \n+;\n+\n+\n+aggregatingAllNullsWithLast\n+schema::LAST_AllNulls:i\n+SELECT LAST(bytes_out) as \"LAST_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ LAST_AllNulls \n+---------------\n+null           \n+;\n+\n+\n+aggregatingAllZerosWithCount\n+schema::COUNT_AllZeros:l\n+SELECT COUNT(bytes_in) as \"COUNT_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+COUNT_AllZeros \n+---------------\n+2              \n+;\n+\n+\n+aggregatingAllNullsWithCount\n+schema::COUNT_AllNulls:l\n+SELECT COUNT(bytes_out) as \"COUNT_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+COUNT_AllNulls \n+---------------\n+0              \n+;\n+\n+\n+aggregatingAllZerosWithCountStar\n+schema::COUNT_AllZeros:l\n+SELECT COUNT(*) as \"COUNT_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+COUNT_AllZeros \n+---------------\n+2              \n+;\n+\n+\n+aggregatingAllNullsWithCountStar\n+schema::COUNT_AllNulls:l\n+SELECT COUNT(*) as \"COUNT_AllNulls\" FROM logs WHERE bytes_out IS NULL;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2ba958dab02c599527308be755fc0c89c9283e3"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDc3MDM0NA==", "bodyText": "I would look in checking if adding or changing one of the entries in logs to have bytes_in as null would have a big impact on the existing tests.  If not, then I would make the change (either adding an entry or changing an existent one) and then a more complex query like SELECT bytes_in, SUM(bytes_in) as SUM_AllNulls, MIN(bytes_in), MAX(bytes_in), AVG(bytes_in) FROM logs WHERE bytes_in = 0 OR bytes_in IS NULL GROUP BY bytes_in would be possible.", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534770344", "createdAt": "2020-12-03T07:03:56Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/sql/qa/server/src/main/resources/agg-nulls-zeros.csv-spec", "diffHunk": "@@ -0,0 +1,359 @@\n+\n+aggregatingAllZerosWithFirst\n+schema::FIRST_AllZeros:i\n+SELECT FIRST(bytes_in) as \"FIRST_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+FIRST_AllZeros \n+---------------\n+0              \n+;\n+\n+\n+aggregatingAllNullsWithFirst\n+schema::FIRST_AllNulls:i\n+SELECT FIRST(bytes_out) as \"FIRST_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+FIRST_AllNulls \n+---------------\n+null           \n+;\n+\n+\n+aggregatingAllZerosWithLast\n+schema::LAST_AllZeros:i\n+SELECT LAST(bytes_in) as \"LAST_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ LAST_AllZeros \n+---------------\n+0              \n+;\n+\n+\n+aggregatingAllNullsWithLast\n+schema::LAST_AllNulls:i\n+SELECT LAST(bytes_out) as \"LAST_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ LAST_AllNulls \n+---------------\n+null           \n+;\n+\n+\n+aggregatingAllZerosWithCount\n+schema::COUNT_AllZeros:l\n+SELECT COUNT(bytes_in) as \"COUNT_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+COUNT_AllZeros \n+---------------\n+2              \n+;\n+\n+\n+aggregatingAllNullsWithCount\n+schema::COUNT_AllNulls:l\n+SELECT COUNT(bytes_out) as \"COUNT_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+COUNT_AllNulls \n+---------------\n+0              \n+;\n+\n+\n+aggregatingAllZerosWithCountStar\n+schema::COUNT_AllZeros:l\n+SELECT COUNT(*) as \"COUNT_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+COUNT_AllZeros \n+---------------\n+2              \n+;\n+\n+\n+aggregatingAllNullsWithCountStar\n+schema::COUNT_AllNulls:l\n+SELECT COUNT(*) as \"COUNT_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+COUNT_AllNulls \n+---------------\n+51             \n+;\n+\n+\n+aggregatingAllZerosWithAvg\n+schema::AVG_AllZeros:d\n+SELECT AVG(bytes_in) as \"AVG_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ AVG_AllZeros  \n+---------------\n+0.0            \n+;\n+\n+\n+aggregatingAllNullsWithAvg\n+schema::AVG_AllNulls:d\n+SELECT AVG(bytes_out) as \"AVG_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ AVG_AllNulls  \n+---------------\n+null           \n+;\n+\n+\n+aggregatingAllZerosWithMin\n+schema::MIN_AllZeros:i\n+SELECT MIN(bytes_in) as \"MIN_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ MIN_AllZeros  \n+---------------\n+0              \n+;\n+\n+\n+aggregatingAllNullsWithMin\n+schema::MIN_AllNulls:i\n+SELECT MIN(bytes_out) as \"MIN_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ MIN_AllNulls  \n+---------------\n+null           \n+;\n+\n+\n+aggregatingAllZerosWithMax\n+schema::MAX_AllZeros:i\n+SELECT MAX(bytes_in) as \"MAX_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ MAX_AllZeros  \n+---------------\n+0              \n+;\n+\n+\n+aggregatingAllNullsWithMax\n+schema::MAX_AllNulls:i\n+SELECT MAX(bytes_out) as \"MAX_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ MAX_AllNulls  \n+---------------\n+null           \n+;\n+\n+\n+aggregatingAllZerosWithSum\n+schema::SUM_AllZeros:i\n+SELECT SUM(bytes_in) as \"SUM_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ SUM_AllZeros  \n+---------------\n+0              \n+;\n+\n+\n+aggregatingAllNullsWithSum\n+schema::SUM_AllNulls:i\n+SELECT SUM(bytes_out) as \"SUM_AllNulls\" FROM logs WHERE bytes_out IS NULL;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2ba958dab02c599527308be755fc0c89c9283e3"}, "originalPosition": 154}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDc3MjM3Mg==", "bodyText": "Why -Ignore. Also, why adding the test as sql-spec if the test already exists in .csv-spec?", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534772372", "createdAt": "2020-12-03T07:06:00Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/sql/qa/server/src/main/resources/agg-nulls-zeros.sql-spec", "diffHunk": "@@ -0,0 +1,73 @@\n+\n+aggregatingAllZerosWithFirst-Ignore", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2ba958dab02c599527308be755fc0c89c9283e3"}, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDc3MzQ2NQ==", "bodyText": "Same comment for this file, regarding the already existent aggs-related spec file.", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534773465", "createdAt": "2020-12-03T07:06:44Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/sql/qa/server/src/main/resources/agg-nulls-zeros.sql-spec", "diffHunk": "@@ -0,0 +1,73 @@\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2ba958dab02c599527308be755fc0c89c9283e3"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDgxNTUwNA==", "bodyText": "Either change the name of the file or add a new sql file (preferable) to be used with H2. setup_test_emp doesn't reflect the file content anymore.", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534815504", "createdAt": "2020-12-03T07:33:35Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/sql/qa/server/src/main/resources/setup_test_emp.sql", "diffHunk": "@@ -9,4 +9,17 @@ CREATE TABLE \"test_emp\" (\n                     \"last_name\" VARCHAR(50),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2ba958dab02c599527308be755fc0c89c9283e3"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkxNDYxMg==", "bodyText": "@Override goes on a separate line.", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534914612", "createdAt": "2020-12-03T08:30:51Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/sql/src/main/java/org/elasticsearch/xpack/sql/optimizer/Optimizer.java", "diffHunk": "@@ -983,6 +984,37 @@ public LogicalPlan apply(LogicalPlan p) {\n         }\n     }\n \n+    static class ReplaceSumWithStats extends OptimizerBasicRule {\n+        // this is a workaround for the https://github.com/elastic/elasticsearch/issues/45251 issue\n+        // should be removed as soon as the issue is fixed\n+        // NOTE: this rule should always be applied AFTER the ReplaceAggsWithStats rule\n+\n+        @Override public LogicalPlan apply(LogicalPlan plan) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2ba958dab02c599527308be755fc0c89c9283e3"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkyMjI3OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    assertEquals(Alias.class, p.aggregates().get(0).getClass());\n          \n          \n            \n                    assertTrue(p.aggregates().get(0) instanceof Alias);", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534922279", "createdAt": "2020-12-03T08:35:20Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/sql/src/test/java/org/elasticsearch/xpack/sql/optimizer/OptimizerTests.java", "diffHunk": "@@ -1023,4 +1022,43 @@ public void testReplaceAttributesWithTarget() {\n         gt = (GreaterThan) and.left();\n         assertEquals(a, gt.left());\n     }\n+\n+    //\n+    // ReplaceSumWithStats rule\n+    //\n+    public void testSumIsReplacedWithStats() {\n+        FieldAttribute fa = getFieldAttribute();\n+        Sum sum = new Sum(EMPTY, fa);\n+        \n+        Alias sumAlias = new Alias(EMPTY, \"sum\", sum);\n+        \n+        Aggregate aggregate = new Aggregate(EMPTY, FROM(), emptyList(), asList(sumAlias));\n+        LogicalPlan optimizedPlan = new Optimizer().optimize(aggregate);\n+        assertEquals(Aggregate.class, optimizedPlan.getClass());\n+        Aggregate p = (Aggregate) optimizedPlan; \n+        assertEquals(1, p.aggregates().size());\n+        assertEquals(Alias.class, p.aggregates().get(0).getClass());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2ba958dab02c599527308be755fc0c89c9283e3"}, "originalPosition": 218}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkyMjgzMw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    assertEquals(InnerAggregate.class, alias.child().getClass());\n          \n          \n            \n                    assertTrue(alias.child() instanceof InnerAggregate);", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534922833", "createdAt": "2020-12-03T08:35:39Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/sql/src/test/java/org/elasticsearch/xpack/sql/optimizer/OptimizerTests.java", "diffHunk": "@@ -1023,4 +1022,43 @@ public void testReplaceAttributesWithTarget() {\n         gt = (GreaterThan) and.left();\n         assertEquals(a, gt.left());\n     }\n+\n+    //\n+    // ReplaceSumWithStats rule\n+    //\n+    public void testSumIsReplacedWithStats() {\n+        FieldAttribute fa = getFieldAttribute();\n+        Sum sum = new Sum(EMPTY, fa);\n+        \n+        Alias sumAlias = new Alias(EMPTY, \"sum\", sum);\n+        \n+        Aggregate aggregate = new Aggregate(EMPTY, FROM(), emptyList(), asList(sumAlias));\n+        LogicalPlan optimizedPlan = new Optimizer().optimize(aggregate);\n+        assertEquals(Aggregate.class, optimizedPlan.getClass());\n+        Aggregate p = (Aggregate) optimizedPlan; \n+        assertEquals(1, p.aggregates().size());\n+        assertEquals(Alias.class, p.aggregates().get(0).getClass());\n+        Alias alias = (Alias) p.aggregates().get(0);\n+        assertEquals(InnerAggregate.class, alias.child().getClass());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2ba958dab02c599527308be755fc0c89c9283e3"}, "originalPosition": 220}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkyNDc5OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    assertEquals(Aggregate.class, optimizedPlan.getClass());\n          \n          \n            \n                    assertTrue(optimizedPlan instanceof Aggregate);", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534924799", "createdAt": "2020-12-03T08:36:47Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/sql/src/test/java/org/elasticsearch/xpack/sql/optimizer/OptimizerTests.java", "diffHunk": "@@ -1023,4 +1022,43 @@ public void testReplaceAttributesWithTarget() {\n         gt = (GreaterThan) and.left();\n         assertEquals(a, gt.left());\n     }\n+\n+    //\n+    // ReplaceSumWithStats rule\n+    //\n+    public void testSumIsReplacedWithStats() {\n+        FieldAttribute fa = getFieldAttribute();\n+        Sum sum = new Sum(EMPTY, fa);\n+        \n+        Alias sumAlias = new Alias(EMPTY, \"sum\", sum);\n+        \n+        Aggregate aggregate = new Aggregate(EMPTY, FROM(), emptyList(), asList(sumAlias));\n+        LogicalPlan optimizedPlan = new Optimizer().optimize(aggregate);\n+        assertEquals(Aggregate.class, optimizedPlan.getClass());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2ba958dab02c599527308be755fc0c89c9283e3"}, "originalPosition": 215}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkyNTUxNw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    assertEquals(sum, ((InnerAggregate)alias.child()).inner());\n          \n          \n            \n                    assertEquals(sum, ((InnerAggregate) alias.child()).inner());", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534925517", "createdAt": "2020-12-03T08:37:21Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/sql/src/test/java/org/elasticsearch/xpack/sql/optimizer/OptimizerTests.java", "diffHunk": "@@ -1023,4 +1022,43 @@ public void testReplaceAttributesWithTarget() {\n         gt = (GreaterThan) and.left();\n         assertEquals(a, gt.left());\n     }\n+\n+    //\n+    // ReplaceSumWithStats rule\n+    //\n+    public void testSumIsReplacedWithStats() {\n+        FieldAttribute fa = getFieldAttribute();\n+        Sum sum = new Sum(EMPTY, fa);\n+        \n+        Alias sumAlias = new Alias(EMPTY, \"sum\", sum);\n+        \n+        Aggregate aggregate = new Aggregate(EMPTY, FROM(), emptyList(), asList(sumAlias));\n+        LogicalPlan optimizedPlan = new Optimizer().optimize(aggregate);\n+        assertEquals(Aggregate.class, optimizedPlan.getClass());\n+        Aggregate p = (Aggregate) optimizedPlan; \n+        assertEquals(1, p.aggregates().size());\n+        assertEquals(Alias.class, p.aggregates().get(0).getClass());\n+        Alias alias = (Alias) p.aggregates().get(0);\n+        assertEquals(InnerAggregate.class, alias.child().getClass());\n+        assertEquals(sum, ((InnerAggregate)alias.child()).inner());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2ba958dab02c599527308be755fc0c89c9283e3"}, "originalPosition": 221}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkyNjI1Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    assertEquals(Aggregate.class, optimizedPlan.getClass());\n          \n          \n            \n                    assertTrue(optimizedPlan instanceof Aggregate);", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534926256", "createdAt": "2020-12-03T08:37:56Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/sql/src/test/java/org/elasticsearch/xpack/sql/optimizer/OptimizerTests.java", "diffHunk": "@@ -1023,4 +1022,43 @@ public void testReplaceAttributesWithTarget() {\n         gt = (GreaterThan) and.left();\n         assertEquals(a, gt.left());\n     }\n+\n+    //\n+    // ReplaceSumWithStats rule\n+    //\n+    public void testSumIsReplacedWithStats() {\n+        FieldAttribute fa = getFieldAttribute();\n+        Sum sum = new Sum(EMPTY, fa);\n+        \n+        Alias sumAlias = new Alias(EMPTY, \"sum\", sum);\n+        \n+        Aggregate aggregate = new Aggregate(EMPTY, FROM(), emptyList(), asList(sumAlias));\n+        LogicalPlan optimizedPlan = new Optimizer().optimize(aggregate);\n+        assertEquals(Aggregate.class, optimizedPlan.getClass());\n+        Aggregate p = (Aggregate) optimizedPlan; \n+        assertEquals(1, p.aggregates().size());\n+        assertEquals(Alias.class, p.aggregates().get(0).getClass());\n+        Alias alias = (Alias) p.aggregates().get(0);\n+        assertEquals(InnerAggregate.class, alias.child().getClass());\n+        assertEquals(sum, ((InnerAggregate)alias.child()).inner());\n+    }\n+\n+    /**\n+     * Once the bug is fixed, the above {@link OptimizerTests#testSumIsReplacedWithStats()} should be\n+     * invalid and should be deleted, and the test below should apply.\n+     */\n+    @AwaitsFix(bugUrl = \"https://github.com/elastic/elasticsearch/issues/45251\")\n+    public void testSumIsNotReplacedWithStats() {\n+        FieldAttribute fa = getFieldAttribute();\n+        Sum sum = new Sum(EMPTY, fa);\n+\n+        Alias sumAlias = new Alias(EMPTY, \"sum\", sum);\n+\n+        Aggregate aggregate = new Aggregate(EMPTY, FROM(), emptyList(), asList(sumAlias));\n+        LogicalPlan optimizedPlan = new Optimizer().optimize(aggregate);\n+        assertEquals(Aggregate.class, optimizedPlan.getClass());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2ba958dab02c599527308be755fc0c89c9283e3"}, "originalPosition": 237}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQzOTgyMDE3", "url": "https://github.com/elastic/elasticsearch/pull/65796#pullrequestreview-543982017", "createdAt": "2020-12-03T14:03:01Z", "commit": {"oid": "d2ba958dab02c599527308be755fc0c89c9283e3"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxNDowMzowMVrOH-dJvA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxNDowNTo1N1rOH-dR5A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTI1MTM4OA==", "bodyText": "+1", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r535251388", "createdAt": "2020-12-03T14:03:01Z", "author": {"login": "matriv"}, "path": "x-pack/plugin/sql/qa/server/src/main/resources/agg-nulls-zeros.csv-spec", "diffHunk": "@@ -0,0 +1,359 @@\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDczNTY1NA=="}, "originalCommit": {"oid": "d2ba958dab02c599527308be755fc0c89c9283e3"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTI1MzQ3Ng==", "bodyText": "We have a mix of those assertions, I wouldn't mind keeping it as is.", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r535253476", "createdAt": "2020-12-03T14:05:57Z", "author": {"login": "matriv"}, "path": "x-pack/plugin/sql/src/test/java/org/elasticsearch/xpack/sql/optimizer/OptimizerTests.java", "diffHunk": "@@ -1023,4 +1022,43 @@ public void testReplaceAttributesWithTarget() {\n         gt = (GreaterThan) and.left();\n         assertEquals(a, gt.left());\n     }\n+\n+    //\n+    // ReplaceSumWithStats rule\n+    //\n+    public void testSumIsReplacedWithStats() {\n+        FieldAttribute fa = getFieldAttribute();\n+        Sum sum = new Sum(EMPTY, fa);\n+        \n+        Alias sumAlias = new Alias(EMPTY, \"sum\", sum);\n+        \n+        Aggregate aggregate = new Aggregate(EMPTY, FROM(), emptyList(), asList(sumAlias));\n+        LogicalPlan optimizedPlan = new Optimizer().optimize(aggregate);\n+        assertEquals(Aggregate.class, optimizedPlan.getClass());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkyNDc5OQ=="}, "originalCommit": {"oid": "d2ba958dab02c599527308be755fc0c89c9283e3"}, "originalPosition": 215}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ0MTgyMDI3", "url": "https://github.com/elastic/elasticsearch/pull/65796#pullrequestreview-544182027", "createdAt": "2020-12-03T17:03:44Z", "commit": {"oid": "d2ba958dab02c599527308be755fc0c89c9283e3"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxNzowMzo0NVrOH-nSgQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxNzoxMzowOVrOH-nzmg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQxNzQ3Mw==", "bodyText": "Class comment sound sit before the class declaration", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r535417473", "createdAt": "2020-12-03T17:03:45Z", "author": {"login": "costin"}, "path": "x-pack/plugin/sql/src/main/java/org/elasticsearch/xpack/sql/optimizer/Optimizer.java", "diffHunk": "@@ -983,6 +984,37 @@ public LogicalPlan apply(LogicalPlan p) {\n         }\n     }\n \n+    static class ReplaceSumWithStats extends OptimizerBasicRule {\n+        // this is a workaround for the https://github.com/elastic/elasticsearch/issues/45251 issue", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2ba958dab02c599527308be755fc0c89c9283e3"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQyMDM4Mg==", "bodyText": "Minor adjustment - to avoid having two return staments do the transformation if the list is non-empty and assign that to the plan\nif (statsPerField.isEmpty() == false) {\n   plan = plan.transformExpression()\n}\n\nreturn plan;", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r535420382", "createdAt": "2020-12-03T17:06:38Z", "author": {"login": "costin"}, "path": "x-pack/plugin/sql/src/main/java/org/elasticsearch/xpack/sql/optimizer/Optimizer.java", "diffHunk": "@@ -983,6 +984,37 @@ public LogicalPlan apply(LogicalPlan p) {\n         }\n     }\n \n+    static class ReplaceSumWithStats extends OptimizerBasicRule {\n+        // this is a workaround for the https://github.com/elastic/elasticsearch/issues/45251 issue\n+        // should be removed as soon as the issue is fixed\n+        // NOTE: this rule should always be applied AFTER the ReplaceAggsWithStats rule\n+\n+        @Override public LogicalPlan apply(LogicalPlan plan) {\n+            final Map<Expression, Stats> statsPerField = new LinkedHashMap<>();\n+            \n+            plan.forEachExpressionsUp(e -> {\n+                if (e instanceof Sum) {\n+                    statsPerField.computeIfAbsent(((Sum) e).field(), field -> {\n+                        Source source = new Source(field.sourceLocation(), \"STATS(\" + field.sourceText() + \")\");\n+                        return new Stats(source, field);\n+                    });\n+                }\n+            });\n+            \n+            if (statsPerField.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2ba958dab02c599527308be755fc0c89c9283e3"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQyNDkwMg==", "bodyText": "To Andrei's point, isn't logs.csv used already and if not can you track down why we add it in the first place? Additionally instead of adding a new data file (assuming it is not used) you can emulate the null using a CASE function for bonus points.", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r535424902", "createdAt": "2020-12-03T17:11:41Z", "author": {"login": "costin"}, "path": "x-pack/plugin/sql/qa/server/src/main/resources/setup_test_emp.sql", "diffHunk": "@@ -9,4 +9,17 @@ CREATE TABLE \"test_emp\" (\n                     \"last_name\" VARCHAR(50),\n                     \"salary\" INT\n                    )\n-   AS SELECT * FROM CSVREAD('classpath:/employees.csv');\n\\ No newline at end of file\n+   AS SELECT * FROM CSVREAD('classpath:/employees.csv');\n+   \n+DROP TABLE IF EXISTS \"logs\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2ba958dab02c599527308be755fc0c89c9283e3"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQyNTk0Ng==", "bodyText": "No need to prefix all tests with aggregating - that already happens through the file name.", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r535425946", "createdAt": "2020-12-03T17:13:09Z", "author": {"login": "costin"}, "path": "x-pack/plugin/sql/qa/server/src/main/resources/agg-nulls-zeros.csv-spec", "diffHunk": "@@ -0,0 +1,359 @@\n+\n+aggregatingAllZerosWithFirst", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2ba958dab02c599527308be755fc0c89c9283e3"}, "originalPosition": 2}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2381ca0b75817895c97c55572bbc053fbd573cd1", "author": {"user": {"login": "palesz", "name": "Andras Palinkas"}}, "url": "https://github.com/elastic/elasticsearch/commit/2381ca0b75817895c97c55572bbc053fbd573cd1", "committedDate": "2020-12-07T22:03:29Z", "message": "PR suggestions"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "25fd2f036be25c03b0e1f32778682a653e32ef97", "author": {"user": {"login": "palesz", "name": "Andras Palinkas"}}, "url": "https://github.com/elastic/elasticsearch/commit/25fd2f036be25c03b0e1f32778682a653e32ef97", "committedDate": "2020-12-07T22:04:39Z", "message": "Merge remote-tracking branch 'origin/master' into fix/sum-null"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ebe06e8ba86d7ab7ec567108da31207578972591", "author": {"user": {"login": "palesz", "name": "Andras Palinkas"}}, "url": "https://github.com/elastic/elasticsearch/commit/ebe06e8ba86d7ab7ec567108da31207578972591", "committedDate": "2020-12-07T22:30:15Z", "message": "Minor test fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "89987b13ed981098bddff7d7968a05448172280a", "author": {"user": {"login": "palesz", "name": "Andras Palinkas"}}, "url": "https://github.com/elastic/elasticsearch/commit/89987b13ed981098bddff7d7968a05448172280a", "committedDate": "2020-12-07T22:32:58Z", "message": "Merge remote-tracking branch 'origin/master' into fix/sum-null"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ2OTMxNDg0", "url": "https://github.com/elastic/elasticsearch/pull/65796#pullrequestreview-546931484", "createdAt": "2020-12-08T09:22:38Z", "commit": {"oid": "89987b13ed981098bddff7d7968a05448172280a"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQwOToyMjozOFrOIBPVZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQwOTo0MjowMFrOIBQNAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODE3MDcyNw==", "bodyText": "Could you put comma at the end of the line instead of at the start?", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r538170727", "createdAt": "2020-12-08T09:22:38Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/sql/qa/server/src/main/resources/agg.csv-spec", "diffHunk": "@@ -1325,3 +1325,386 @@ F              |1964-10-18T00:00:00.000Z|1952-04-19T00:00:00.000Z\n M              |1965-01-03T00:00:00.000Z|1952-02-27T00:00:00.000Z\n ;\n \n+\n+//\n+// Aggregations on NULLs and Zeros\n+//\n+\n+allZerosWithFirst\n+schema::FIRST_AllZeros:i\n+SELECT FIRST(bytes_in) as \"FIRST_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+FIRST_AllZeros \n+---------------\n+0              \n+;\n+\n+\n+allNullsWithFirst\n+schema::FIRST_AllNulls:i\n+SELECT FIRST(bytes_out) as \"FIRST_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+FIRST_AllNulls \n+---------------\n+null           \n+;\n+\n+\n+allZerosWithLast\n+schema::LAST_AllZeros:i\n+SELECT LAST(bytes_in) as \"LAST_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ LAST_AllZeros \n+---------------\n+0              \n+;\n+\n+\n+allNullsWithLast\n+schema::LAST_AllNulls:i\n+SELECT LAST(bytes_out) as \"LAST_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ LAST_AllNulls \n+---------------\n+null           \n+;\n+\n+\n+allZerosWithCount\n+schema::COUNT_AllZeros:l\n+SELECT COUNT(bytes_in) as \"COUNT_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+COUNT_AllZeros \n+---------------\n+2              \n+;\n+\n+\n+allNullsWithCount\n+schema::COUNT_AllNulls:l\n+SELECT COUNT(bytes_out) as \"COUNT_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+COUNT_AllNulls \n+---------------\n+0              \n+;\n+\n+\n+\n+allZerosWithAvg\n+schema::AVG_AllZeros:d\n+SELECT AVG(bytes_in) as \"AVG_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ AVG_AllZeros  \n+---------------\n+0.0            \n+;\n+\n+\n+allNullsWithAvg\n+schema::AVG_AllNulls:d\n+SELECT AVG(bytes_out) as \"AVG_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ AVG_AllNulls  \n+---------------\n+null           \n+;\n+\n+\n+allZerosWithMin\n+schema::MIN_AllZeros:i\n+SELECT MIN(bytes_in) as \"MIN_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ MIN_AllZeros  \n+---------------\n+0              \n+;\n+\n+\n+allNullsWithMin\n+schema::MIN_AllNulls:i\n+SELECT MIN(bytes_out) as \"MIN_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ MIN_AllNulls  \n+---------------\n+null           \n+;\n+\n+\n+allZerosWithMax\n+schema::MAX_AllZeros:i\n+SELECT MAX(bytes_in) as \"MAX_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ MAX_AllZeros  \n+---------------\n+0              \n+;\n+\n+\n+allNullsWithMax\n+schema::MAX_AllNulls:i\n+SELECT MAX(bytes_out) as \"MAX_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ MAX_AllNulls  \n+---------------\n+null           \n+;\n+\n+\n+allZerosWithSum\n+schema::SUM_AllZeros:i\n+SELECT SUM(bytes_in) as \"SUM_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ SUM_AllZeros  \n+---------------\n+0              \n+;\n+\n+\n+allNullsWithSum\n+schema::SUM_AllNulls:i\n+SELECT SUM(bytes_out) as \"SUM_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ SUM_AllNulls  \n+---------------\n+null           \n+;\n+\n+\n+allZerosWithPercentile\n+schema::PERCENTILE_AllZeros:d\n+SELECT PERCENTILE(bytes_in, 0) as \"PERCENTILE_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+PERCENTILE_AllZeros\n+-------------------\n+0.0                \n+;\n+\n+\n+allNullsWithPercentile\n+schema::PERCENTILE_AllNulls:d\n+SELECT PERCENTILE(bytes_out, 0) as \"PERCENTILE_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+PERCENTILE_AllNulls\n+-------------------\n+null               \n+;\n+\n+\n+allZerosWithPercentileRank\n+schema::PERCENTILE_RANK_AllZeros:d\n+SELECT PERCENTILE_RANK(bytes_in, 0) as \"PERCENTILE_RANK_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+PERCENTILE_RANK_AllZeros\n+------------------------\n+100.0                   \n+;\n+\n+\n+allNullsWithPercentileRank\n+schema::PERCENTILE_RANK_AllNulls:d\n+SELECT PERCENTILE_RANK(bytes_out, 0) as \"PERCENTILE_RANK_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+PERCENTILE_RANK_AllNulls\n+------------------------\n+null                    \n+;\n+\n+\n+allZerosWithSumOfSquares\n+schema::SUM_OF_SQUARES_AllZeros:d\n+SELECT SUM_OF_SQUARES(bytes_in) as \"SUM_OF_SQUARES_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+SUM_OF_SQUARES_AllZeros\n+-----------------------\n+0.0                    \n+;\n+\n+\n+allNullsWithSumOfSquares\n+schema::SUM_OF_SQUARES_AllNulls:d\n+SELECT SUM_OF_SQUARES(bytes_out) as \"SUM_OF_SQUARES_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+SUM_OF_SQUARES_AllNulls\n+-----------------------\n+null                   \n+;\n+\n+\n+allZerosWithStddevPop\n+schema::STDDEV_POP_AllZeros:d\n+SELECT STDDEV_POP(bytes_in) as \"STDDEV_POP_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+STDDEV_POP_AllZeros\n+-------------------\n+0.0                \n+;\n+\n+\n+allNullsWithStddevPop\n+schema::STDDEV_POP_AllNulls:d\n+SELECT STDDEV_POP(bytes_out) as \"STDDEV_POP_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+STDDEV_POP_AllNulls\n+-------------------\n+null               \n+;\n+\n+\n+allZerosWithStddevSamp\n+schema::STDDEV_SAMP_AllZeros:d\n+SELECT STDDEV_SAMP(bytes_in) as \"STDDEV_SAMP_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+STDDEV_SAMP_AllZeros\n+--------------------\n+0.0                 \n+;\n+\n+\n+allNullsWithStddevSamp\n+schema::STDDEV_SAMP_AllNulls:d\n+SELECT STDDEV_SAMP(bytes_out) as \"STDDEV_SAMP_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+STDDEV_SAMP_AllNulls\n+--------------------\n+null                \n+;\n+\n+\n+allZerosWithVarSamp\n+schema::VAR_SAMP_AllZeros:d\n+SELECT VAR_SAMP(bytes_in) as \"VAR_SAMP_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+VAR_SAMP_AllZeros\n+-----------------\n+0.0              \n+;\n+\n+\n+allNullsWithVarSamp\n+schema::VAR_SAMP_AllNulls:d\n+SELECT VAR_SAMP(bytes_out) as \"VAR_SAMP_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+VAR_SAMP_AllNulls\n+-----------------\n+null             \n+;\n+\n+\n+allZerosWithVarPop\n+schema::VAR_POP_AllZeros:d\n+SELECT VAR_POP(bytes_in) as \"VAR_POP_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+VAR_POP_AllZeros\n+----------------\n+0.0             \n+;\n+\n+\n+allNullsWithVarPop\n+schema::VAR_POP_AllNulls:d\n+SELECT VAR_POP(bytes_out) as \"VAR_POP_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+VAR_POP_AllNulls\n+----------------\n+null            \n+;\n+\n+\n+allZerosWithSkewness\n+schema::SKEWNESS_AllZeros:d\n+SELECT SKEWNESS(bytes_in) as \"SKEWNESS_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+SKEWNESS_AllZeros\n+-----------------\n+NaN              \n+;\n+\n+\n+allNullsWithSkewness\n+schema::SKEWNESS_AllNulls:d\n+SELECT SKEWNESS(bytes_out) as \"SKEWNESS_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+SKEWNESS_AllNulls\n+-----------------\n+null             \n+;\n+\n+\n+allZerosWithMad\n+schema::MAD_AllZeros:d\n+SELECT MAD(bytes_in) as \"MAD_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ MAD_AllZeros  \n+---------------\n+0.0            \n+;\n+\n+\n+allNullsWithMad\n+schema::MAD_AllNulls:d\n+SELECT MAD(bytes_out) as \"MAD_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ MAD_AllNulls  \n+---------------\n+NaN            \n+;\n+\n+\n+allZerosWithKurtosis\n+schema::KURTOSIS_AllZeros:d\n+SELECT KURTOSIS(bytes_in) as \"KURTOSIS_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+KURTOSIS_AllZeros\n+-----------------\n+NaN              \n+;\n+\n+\n+allNullsWithKurtosis\n+schema::KURTOSIS_AllNulls:d\n+SELECT KURTOSIS(bytes_out) as \"KURTOSIS_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+KURTOSIS_AllNulls\n+-----------------\n+null             \n+;\n+\n+nullsAndZerosCombined\n+schema::COUNT(*):l|COUNT_AllZeros:l|COUNT_AllNulls:l|FIRST_AllZeros:i|FIRST_AllNulls:i|SUM_AllZeros:i|SUM_AllNulls:i\n+SELECT\n+    COUNT(*)\n+    , COUNT(bytes_in) AS \"COUNT_AllZeros\"\n+    , COUNT(bytes_out) AS \"COUNT_AllNulls\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "89987b13ed981098bddff7d7968a05448172280a"}, "originalPosition": 354}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODE3Mzk0OA==", "bodyText": "Just a minor suggestion: ORDER BY ... DESC.", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r538173948", "createdAt": "2020-12-08T09:26:55Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/sql/qa/server/src/main/resources/agg.csv-spec", "diffHunk": "@@ -1325,3 +1325,386 @@ F              |1964-10-18T00:00:00.000Z|1952-04-19T00:00:00.000Z\n M              |1965-01-03T00:00:00.000Z|1952-02-27T00:00:00.000Z\n ;\n \n+\n+//\n+// Aggregations on NULLs and Zeros\n+//\n+\n+allZerosWithFirst\n+schema::FIRST_AllZeros:i\n+SELECT FIRST(bytes_in) as \"FIRST_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+FIRST_AllZeros \n+---------------\n+0              \n+;\n+\n+\n+allNullsWithFirst\n+schema::FIRST_AllNulls:i\n+SELECT FIRST(bytes_out) as \"FIRST_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+FIRST_AllNulls \n+---------------\n+null           \n+;\n+\n+\n+allZerosWithLast\n+schema::LAST_AllZeros:i\n+SELECT LAST(bytes_in) as \"LAST_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ LAST_AllZeros \n+---------------\n+0              \n+;\n+\n+\n+allNullsWithLast\n+schema::LAST_AllNulls:i\n+SELECT LAST(bytes_out) as \"LAST_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ LAST_AllNulls \n+---------------\n+null           \n+;\n+\n+\n+allZerosWithCount\n+schema::COUNT_AllZeros:l\n+SELECT COUNT(bytes_in) as \"COUNT_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+COUNT_AllZeros \n+---------------\n+2              \n+;\n+\n+\n+allNullsWithCount\n+schema::COUNT_AllNulls:l\n+SELECT COUNT(bytes_out) as \"COUNT_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+COUNT_AllNulls \n+---------------\n+0              \n+;\n+\n+\n+\n+allZerosWithAvg\n+schema::AVG_AllZeros:d\n+SELECT AVG(bytes_in) as \"AVG_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ AVG_AllZeros  \n+---------------\n+0.0            \n+;\n+\n+\n+allNullsWithAvg\n+schema::AVG_AllNulls:d\n+SELECT AVG(bytes_out) as \"AVG_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ AVG_AllNulls  \n+---------------\n+null           \n+;\n+\n+\n+allZerosWithMin\n+schema::MIN_AllZeros:i\n+SELECT MIN(bytes_in) as \"MIN_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ MIN_AllZeros  \n+---------------\n+0              \n+;\n+\n+\n+allNullsWithMin\n+schema::MIN_AllNulls:i\n+SELECT MIN(bytes_out) as \"MIN_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ MIN_AllNulls  \n+---------------\n+null           \n+;\n+\n+\n+allZerosWithMax\n+schema::MAX_AllZeros:i\n+SELECT MAX(bytes_in) as \"MAX_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ MAX_AllZeros  \n+---------------\n+0              \n+;\n+\n+\n+allNullsWithMax\n+schema::MAX_AllNulls:i\n+SELECT MAX(bytes_out) as \"MAX_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ MAX_AllNulls  \n+---------------\n+null           \n+;\n+\n+\n+allZerosWithSum\n+schema::SUM_AllZeros:i\n+SELECT SUM(bytes_in) as \"SUM_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ SUM_AllZeros  \n+---------------\n+0              \n+;\n+\n+\n+allNullsWithSum\n+schema::SUM_AllNulls:i\n+SELECT SUM(bytes_out) as \"SUM_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ SUM_AllNulls  \n+---------------\n+null           \n+;\n+\n+\n+allZerosWithPercentile\n+schema::PERCENTILE_AllZeros:d\n+SELECT PERCENTILE(bytes_in, 0) as \"PERCENTILE_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+PERCENTILE_AllZeros\n+-------------------\n+0.0                \n+;\n+\n+\n+allNullsWithPercentile\n+schema::PERCENTILE_AllNulls:d\n+SELECT PERCENTILE(bytes_out, 0) as \"PERCENTILE_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+PERCENTILE_AllNulls\n+-------------------\n+null               \n+;\n+\n+\n+allZerosWithPercentileRank\n+schema::PERCENTILE_RANK_AllZeros:d\n+SELECT PERCENTILE_RANK(bytes_in, 0) as \"PERCENTILE_RANK_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+PERCENTILE_RANK_AllZeros\n+------------------------\n+100.0                   \n+;\n+\n+\n+allNullsWithPercentileRank\n+schema::PERCENTILE_RANK_AllNulls:d\n+SELECT PERCENTILE_RANK(bytes_out, 0) as \"PERCENTILE_RANK_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+PERCENTILE_RANK_AllNulls\n+------------------------\n+null                    \n+;\n+\n+\n+allZerosWithSumOfSquares\n+schema::SUM_OF_SQUARES_AllZeros:d\n+SELECT SUM_OF_SQUARES(bytes_in) as \"SUM_OF_SQUARES_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+SUM_OF_SQUARES_AllZeros\n+-----------------------\n+0.0                    \n+;\n+\n+\n+allNullsWithSumOfSquares\n+schema::SUM_OF_SQUARES_AllNulls:d\n+SELECT SUM_OF_SQUARES(bytes_out) as \"SUM_OF_SQUARES_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+SUM_OF_SQUARES_AllNulls\n+-----------------------\n+null                   \n+;\n+\n+\n+allZerosWithStddevPop\n+schema::STDDEV_POP_AllZeros:d\n+SELECT STDDEV_POP(bytes_in) as \"STDDEV_POP_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+STDDEV_POP_AllZeros\n+-------------------\n+0.0                \n+;\n+\n+\n+allNullsWithStddevPop\n+schema::STDDEV_POP_AllNulls:d\n+SELECT STDDEV_POP(bytes_out) as \"STDDEV_POP_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+STDDEV_POP_AllNulls\n+-------------------\n+null               \n+;\n+\n+\n+allZerosWithStddevSamp\n+schema::STDDEV_SAMP_AllZeros:d\n+SELECT STDDEV_SAMP(bytes_in) as \"STDDEV_SAMP_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+STDDEV_SAMP_AllZeros\n+--------------------\n+0.0                 \n+;\n+\n+\n+allNullsWithStddevSamp\n+schema::STDDEV_SAMP_AllNulls:d\n+SELECT STDDEV_SAMP(bytes_out) as \"STDDEV_SAMP_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+STDDEV_SAMP_AllNulls\n+--------------------\n+null                \n+;\n+\n+\n+allZerosWithVarSamp\n+schema::VAR_SAMP_AllZeros:d\n+SELECT VAR_SAMP(bytes_in) as \"VAR_SAMP_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+VAR_SAMP_AllZeros\n+-----------------\n+0.0              \n+;\n+\n+\n+allNullsWithVarSamp\n+schema::VAR_SAMP_AllNulls:d\n+SELECT VAR_SAMP(bytes_out) as \"VAR_SAMP_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+VAR_SAMP_AllNulls\n+-----------------\n+null             \n+;\n+\n+\n+allZerosWithVarPop\n+schema::VAR_POP_AllZeros:d\n+SELECT VAR_POP(bytes_in) as \"VAR_POP_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+VAR_POP_AllZeros\n+----------------\n+0.0             \n+;\n+\n+\n+allNullsWithVarPop\n+schema::VAR_POP_AllNulls:d\n+SELECT VAR_POP(bytes_out) as \"VAR_POP_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+VAR_POP_AllNulls\n+----------------\n+null            \n+;\n+\n+\n+allZerosWithSkewness\n+schema::SKEWNESS_AllZeros:d\n+SELECT SKEWNESS(bytes_in) as \"SKEWNESS_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+SKEWNESS_AllZeros\n+-----------------\n+NaN              \n+;\n+\n+\n+allNullsWithSkewness\n+schema::SKEWNESS_AllNulls:d\n+SELECT SKEWNESS(bytes_out) as \"SKEWNESS_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+SKEWNESS_AllNulls\n+-----------------\n+null             \n+;\n+\n+\n+allZerosWithMad\n+schema::MAD_AllZeros:d\n+SELECT MAD(bytes_in) as \"MAD_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ MAD_AllZeros  \n+---------------\n+0.0            \n+;\n+\n+\n+allNullsWithMad\n+schema::MAD_AllNulls:d\n+SELECT MAD(bytes_out) as \"MAD_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ MAD_AllNulls  \n+---------------\n+NaN            \n+;\n+\n+\n+allZerosWithKurtosis\n+schema::KURTOSIS_AllZeros:d\n+SELECT KURTOSIS(bytes_in) as \"KURTOSIS_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+KURTOSIS_AllZeros\n+-----------------\n+NaN              \n+;\n+\n+\n+allNullsWithKurtosis\n+schema::KURTOSIS_AllNulls:d\n+SELECT KURTOSIS(bytes_out) as \"KURTOSIS_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+KURTOSIS_AllNulls\n+-----------------\n+null             \n+;\n+\n+nullsAndZerosCombined\n+schema::COUNT(*):l|COUNT_AllZeros:l|COUNT_AllNulls:l|FIRST_AllZeros:i|FIRST_AllNulls:i|SUM_AllZeros:i|SUM_AllNulls:i\n+SELECT\n+    COUNT(*)\n+    , COUNT(bytes_in) AS \"COUNT_AllZeros\"\n+    , COUNT(bytes_out) AS \"COUNT_AllNulls\"\n+    , FIRST(bytes_in) AS \"FIRST_AllZeros\"\n+    , FIRST(bytes_out) AS \"FIRST_AllNulls\"\n+    , SUM(bytes_in) AS \"SUM_AllZeros\"\n+    , SUM(bytes_out) AS \"SUM_AllNulls\"\n+FROM logs\n+WHERE bytes_in = 0 AND bytes_out IS NULL;\n+\n+   COUNT(*)    |COUNT(bytes_in)|COUNT(bytes_out)|FIRST_AllZeros |FIRST_AllNulls | SUM_AllZeros  | SUM_AllNulls  \n+---------------+---------------+----------------+---------------+---------------+---------------+---------------\n+1              |1              |0               |0              |null           |0              |null           \n+;\n+\n+\n+groupedByNullsAndZeros\n+schema::bytes_in:i|COUNT(*):l|SUM(bytes_in):i|MIN(bytes_in):i|MAX(bytes_in):i|AVG(bytes_in):d\n+SELECT\n+    bytes_in\n+    , COUNT(*)\n+    , SUM(bytes_in)\n+    , MIN(bytes_in)\n+    , MAX(bytes_in)\n+    , AVG(bytes_in)\n+FROM logs\n+WHERE NVL(bytes_in, 0) = 0\n+GROUP BY bytes_in\n+ORDER BY bytes_in;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "89987b13ed981098bddff7d7968a05448172280a"}, "originalPosition": 380}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODE4NDk2MA==", "bodyText": "Please, add one more test, that uses two SUMs and some other elements: SELECT SUM(bytes_in), SUM(bytes_out), client_ip, COUNT(*) AS c FROM logs WHERE client_ip = '10.0.0.0/16' AND NVL(bytes_out, 0) = 0 GROUP BY client_ip ORDER BY c DESC, SUM(bytes_in) ASC NULLS FIRST", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r538184960", "createdAt": "2020-12-08T09:42:00Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/sql/qa/server/src/main/resources/agg.csv-spec", "diffHunk": "@@ -1325,3 +1325,386 @@ F              |1964-10-18T00:00:00.000Z|1952-04-19T00:00:00.000Z\n M              |1965-01-03T00:00:00.000Z|1952-02-27T00:00:00.000Z\n ;\n \n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "89987b13ed981098bddff7d7968a05448172280a"}, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ3MDYxMTQy", "url": "https://github.com/elastic/elasticsearch/pull/65796#pullrequestreview-547061142", "createdAt": "2020-12-08T10:39:15Z", "commit": {"oid": "89987b13ed981098bddff7d7968a05448172280a"}, "state": "APPROVED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQxMDozOToxNVrOIBS2pg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQxMDo0NTo1NFrOIBTLnw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODIyODM5MA==", "bodyText": "Why was this added and what would have happened without it?", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r538228390", "createdAt": "2020-12-08T10:39:15Z", "author": {"login": "costin"}, "path": "x-pack/plugin/sql/qa/server/src/main/resources/logs.csv", "diffHunk": "@@ -99,3 +99,4 @@ id,@timestamp,bytes_in,bytes_out,client_ip,client_port,dest_ip,status\n 98,2017-11-10T21:12:24Z,74,90,10.0.0.134,57203,172.20.10.1,OK\n 99,2017-11-10T21:17:37Z,39,512,10.0.0.128,29333,,OK\n 100,2017-11-10T03:21:36Z,64,183,10.0.0.129,4541,172.16.1.1,OK\n+101,2017-11-10T23:22:36Z,,,10.0.2.129,4541,172.20.11.1,OK", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "89987b13ed981098bddff7d7968a05448172280a"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODIyOTc4Mg==", "bodyText": "I find this comment confusing.\nThis PR is a fix for #45251 itself due to an issue in Elasticsearch not SQL.\nOnce the issue in Elasticsearch is fixed the workaround in QL won't be needed. Pointing to the SQL issue itself asking for the workaround is incorrect.", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r538229782", "createdAt": "2020-12-08T10:40:43Z", "author": {"login": "costin"}, "path": "x-pack/plugin/sql/src/main/java/org/elasticsearch/xpack/sql/optimizer/Optimizer.java", "diffHunk": "@@ -983,6 +984,38 @@ public LogicalPlan apply(LogicalPlan p) {\n         }\n     }\n \n+    // This is a workaround for the https://github.com/elastic/elasticsearch/issues/45251 issue\n+    // Should be removed as soon as the above issue is fixed\n+    // NOTE: this rule should always be applied AFTER the ReplaceAggsWithStats rule", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "89987b13ed981098bddff7d7968a05448172280a"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODIzMzQwMA==", "bodyText": "Incorrect issue referenced - this PR provides the workaround in SQL for ES. Once the issue in ES gets solved, this test can be enabled.", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r538233400", "createdAt": "2020-12-08T10:45:26Z", "author": {"login": "costin"}, "path": "x-pack/plugin/sql/src/test/java/org/elasticsearch/xpack/sql/optimizer/OptimizerTests.java", "diffHunk": "@@ -1023,4 +1022,43 @@ public void testReplaceAttributesWithTarget() {\n         gt = (GreaterThan) and.left();\n         assertEquals(a, gt.left());\n     }\n+\n+    //\n+    // ReplaceSumWithStats rule\n+    //\n+    public void testSumIsReplacedWithStats() {\n+        FieldAttribute fa = getFieldAttribute();\n+        Sum sum = new Sum(EMPTY, fa);\n+        \n+        Alias sumAlias = new Alias(EMPTY, \"sum\", sum);\n+        \n+        Aggregate aggregate = new Aggregate(EMPTY, FROM(), emptyList(), asList(sumAlias));\n+        LogicalPlan optimizedPlan = new Optimizer().optimize(aggregate);\n+        assertTrue(optimizedPlan instanceof Aggregate);\n+        Aggregate p = (Aggregate) optimizedPlan; \n+        assertEquals(1, p.aggregates().size());\n+        assertTrue(p.aggregates().get(0) instanceof Alias);\n+        Alias alias = (Alias) p.aggregates().get(0);\n+        assertTrue(alias.child() instanceof InnerAggregate);\n+        assertEquals(sum, ((InnerAggregate) alias.child()).inner());\n+    }\n+\n+    /**\n+     * Once the bug is fixed, the above {@link OptimizerTests#testSumIsReplacedWithStats()} should be\n+     * invalid and should be deleted, and the test below should apply.\n+     */\n+    @AwaitsFix(bugUrl = \"https://github.com/elastic/elasticsearch/issues/45251\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "89987b13ed981098bddff7d7968a05448172280a"}, "originalPosition": 228}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODIzMzc1OQ==", "bodyText": "Same comment here regarding the Github issue.", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r538233759", "createdAt": "2020-12-08T10:45:54Z", "author": {"login": "costin"}, "path": "x-pack/plugin/sql/src/test/java/org/elasticsearch/xpack/sql/planner/QueryTranslatorTests.java", "diffHunk": "@@ -2443,4 +2443,19 @@ public void testPercentileOptimization() {\n         test.accept(\"PERCENTILE\", p -> ((PercentilesAggregationBuilder)p).percentiles());\n         test.accept(\"PERCENTILE_RANK\", p -> ((PercentileRanksAggregationBuilder)p).values());\n     }\n+\n+    // workaround for the https://github.com/elastic/elasticsearch/issues/45251 issue", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "89987b13ed981098bddff7d7968a05448172280a"}, "originalPosition": 39}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "051d11cac05342dce4170c4a7180a3fe050c2d95", "author": {"user": {"login": "palesz", "name": "Andras Palinkas"}}, "url": "https://github.com/elastic/elasticsearch/commit/051d11cac05342dce4170c4a7180a3fe050c2d95", "committedDate": "2020-12-08T16:17:05Z", "message": "PR suggestions"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "92c348287bbb1b3b268840ae0b2a9d5996acc13d", "author": {"user": {"login": "palesz", "name": "Andras Palinkas"}}, "url": "https://github.com/elastic/elasticsearch/commit/92c348287bbb1b3b268840ae0b2a9d5996acc13d", "committedDate": "2020-12-08T16:17:18Z", "message": "Merge remote-tracking branch 'origin/master' into fix/sum-null"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ3NjY1MjI0", "url": "https://github.com/elastic/elasticsearch/pull/65796#pullrequestreview-547665224", "createdAt": "2020-12-08T21:55:52Z", "commit": {"oid": "92c348287bbb1b3b268840ae0b2a9d5996acc13d"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ3OTQ4MTE3", "url": "https://github.com/elastic/elasticsearch/pull/65796#pullrequestreview-547948117", "createdAt": "2020-12-09T08:36:59Z", "commit": {"oid": "92c348287bbb1b3b268840ae0b2a9d5996acc13d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQwODozNjo1OVrOICIl3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQwODozNjo1OVrOICIl3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTEwODgyOA==", "bodyText": "Not related to this PR, but I was wondering: most forEachExpressionsUp/Down methods invocations do pattern matching as first thing. Wouldn't an alternative method similar to Node#forEachUp/Down taking a type token make sense?", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r539108828", "createdAt": "2020-12-09T08:36:59Z", "author": {"login": "bpintea"}, "path": "x-pack/plugin/sql/src/main/java/org/elasticsearch/xpack/sql/optimizer/Optimizer.java", "diffHunk": "@@ -983,6 +984,39 @@ public LogicalPlan apply(LogicalPlan p) {\n         }\n     }\n \n+    // This class is a workaround for the SUM(all zeros) = NULL issue raised in https://github.com/elastic/elasticsearch/issues/45251 and\n+    // should be removed as soon as root cause is fixed and the sum aggregation results can differentiate between SUM(all zeroes) \n+    // and SUM(all nulls)\n+    // NOTE: this rule should always be applied AFTER the ReplaceAggsWithStats rule\n+    static class ReplaceSumWithStats extends OptimizerBasicRule {\n+        \n+        @Override \n+        public LogicalPlan apply(LogicalPlan plan) {\n+            final Map<Expression, Stats> statsPerField = new LinkedHashMap<>();\n+            \n+            plan.forEachExpressionsUp(e -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92c348287bbb1b3b268840ae0b2a9d5996acc13d"}, "originalPosition": 22}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ4MDc2NzI2", "url": "https://github.com/elastic/elasticsearch/pull/65796#pullrequestreview-548076726", "createdAt": "2020-12-09T11:11:28Z", "commit": {"oid": "92c348287bbb1b3b268840ae0b2a9d5996acc13d"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4146, "cost": 1, "resetAt": "2021-10-28T19:08:13Z"}}}