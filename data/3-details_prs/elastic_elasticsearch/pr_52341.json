{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzc1MDkxMzQy", "number": 52341, "title": "Add Caching for RepositoryData in BlobStoreRepository", "bodyText": "Cache latest RepositoryData on heap when it's absolutely safe to do so (i.e. when the repository is in strictly consistent mode).\nRepositoryData can safely be assumed to not grow to a size that would cause trouble because we often have at least two copies of it loaded at the same time when doing repository operations. Also, concurrent snapshot API status requests currently load it independently of each other and so on, making it safe to cache on heap and assume as \"small\" IMO.\nThe benefits of this move are:\n\nMuch faster repository status API calls\n\nlisting all snapshot names becomes instant\nOther operations are sped up massively too because they mostly operate in two steps: load repository data then load multiple other blobs to get the additional data\n\n\nAdditional cloud cost savings\nBetter resiliency, saving another spot where an IO issue could break the snapshot\nWe can simplify a number of spots in the current code that currently pass around the repository data in tricky ways to avoid loading it multiple times in follow ups.\n\nI know we are thinking about caching other repository metadata in an internal index, but I think this blob is better served from heap since it's so performance critical (this is irrelevant now to some degree but more interesting for concurrent repository operations).", "createdAt": "2020-02-13T21:15:46Z", "url": "https://github.com/elastic/elasticsearch/pull/52341", "merged": true, "mergeCommit": {"oid": "f5ca487fc4deb8e829b6f8e39fdb321d2af3d0f8"}, "closed": true, "closedAt": "2020-02-20T11:58:30Z", "author": {"login": "original-brownbear"}, "timelineItems": {"totalCount": 22, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcEBnWgAH2gAyMzc1MDkxMzQyOmY2ODMzYThjMjM3MjA2Y2E2YTAwMTkyNzkyZTRmODZhZTg0YjM5NGE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcGJR7EgFqTM2MTgyMTcyNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "f6833a8c237206ca6a00192792e4f86ae84b394a", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/f6833a8c237206ca6a00192792e4f86ae84b394a", "committedDate": "2020-02-13T21:14:40Z", "message": "Add Caching for RepositoryData in BlobStoreRepository\n\nWIP"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3f198b1b73aa3242f7278ae2ba9079e3a03cf1a9", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/3f198b1b73aa3242f7278ae2ba9079e3a03cf1a9", "committedDate": "2020-02-14T07:42:13Z", "message": "Merge remote-tracking branch 'elastic/master' into cache-latest-repository-data"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "246d5ee447f0ed59c548bf3757527ffd39ceb2d9", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/246d5ee447f0ed59c548bf3757527ffd39ceb2d9", "committedDate": "2020-02-14T08:10:51Z", "message": "docs + safer"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU4Nzc3MDk3", "url": "https://github.com/elastic/elasticsearch/pull/52341#pullrequestreview-358777097", "createdAt": "2020-02-14T08:29:22Z", "commit": {"oid": "246d5ee447f0ed59c548bf3757527ffd39ceb2d9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwODoyOToyMlrOFpuyzw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwODoyOToyMlrOFpuyzw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMwMjYwNw==", "bodyText": "Just fixing a bug here that prevented node restarts in tests for nodes that used secure settings. If we always return the same SecureString for getString then if a node ever closes that SecureString it couldn't get the setting again.", "url": "https://github.com/elastic/elasticsearch/pull/52341#discussion_r379302607", "createdAt": "2020-02-14T08:29:22Z", "author": {"login": "original-brownbear"}, "path": "test/framework/src/main/java/org/elasticsearch/common/settings/MockSecureSettings.java", "diffHunk": "@@ -36,7 +36,7 @@\n  */\n public class MockSecureSettings implements SecureSettings {\n \n-    private Map<String, SecureString> secureStrings = new HashMap<>();\n+    private Map<String, String> secureStrings = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "246d5ee447f0ed59c548bf3757527ffd39ceb2d9"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU4Nzc4OTMw", "url": "https://github.com/elastic/elasticsearch/pull/52341#pullrequestreview-358778930", "createdAt": "2020-02-14T08:33:10Z", "commit": {"oid": "246d5ee447f0ed59c548bf3757527ffd39ceb2d9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwODozMzoxMFrOFpu4Vw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwODozMzoxMFrOFpu4Vw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMwNDAyMw==", "bodyText": "This is admittedly pretty dirty now test-wise. Obviously, it also illustrates that this change slightly weakens our ability to detect concurrent repository writes from multiple clusters.\nIMO, this is a fair trade-off though and one we've already been making over and over in other spots (anytime we optimised away a loading of RepositoryData we weakened the ability to detect concurrent load obviously).", "url": "https://github.com/elastic/elasticsearch/pull/52341#discussion_r379304023", "createdAt": "2020-02-14T08:33:10Z", "author": {"login": "original-brownbear"}, "path": "server/src/test/java/org/elasticsearch/snapshots/CorruptedBlobStoreRepositoryIT.java", "diffHunk": "@@ -356,4 +367,9 @@ private void assertRepositoryBlocked(Client client, String repo, String existing\n         assertThat(repositoryException4.getMessage(),\n             containsString(\"Could not read repository data because the contents of the repository do not match its expected state.\"));\n     }\n+\n+    private void fullRestart() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "246d5ee447f0ed59c548bf3757527ffd39ceb2d9"}, "originalPosition": 86}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b5d135470c1f6b1b31b0f1e94a1ded21bf9baff1", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/b5d135470c1f6b1b31b0f1e94a1ded21bf9baff1", "committedDate": "2020-02-14T08:39:21Z", "message": "shorter"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU4ODE0Njgx", "url": "https://github.com/elastic/elasticsearch/pull/52341#pullrequestreview-358814681", "createdAt": "2020-02-14T09:37:34Z", "commit": {"oid": "b5d135470c1f6b1b31b0f1e94a1ded21bf9baff1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwOTozNzozNFrOFpwlWg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwOTozNzozNFrOFpwlWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMzMTkzMA==", "bodyText": "This is a little dirty and we talked about it in other PRs .. the generation here is -1 due to the weird way the repository data is loaded initially and we have to eventually set it. I'll clean that up in a follow up, for now just setting it here where it matters (it doesn't matter in the above code when serializing filteredRepositoryData to the repo) seemed the driest.", "url": "https://github.com/elastic/elasticsearch/pull/52341#discussion_r379331930", "createdAt": "2020-02-14T09:37:34Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java", "diffHunk": "@@ -1359,6 +1398,7 @@ public void onFailure(String source, Exception e) {\n \n                     @Override\n                     public void clusterStateProcessed(String source, ClusterState oldState, ClusterState newState) {\n+                        cacheRepositoryData(filteredRepositoryData.withGenId(newGen));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5d135470c1f6b1b31b0f1e94a1ded21bf9baff1"}, "originalPosition": 91}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7abac783bfb90a85efd792a634da62b70abc2f72", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/7abac783bfb90a85efd792a634da62b70abc2f72", "committedDate": "2020-02-17T14:52:22Z", "message": "Merge remote-tracking branch 'elastic/master' into cache-latest-repository-data"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dff276e33aac592ee1bf014a7f31be827cbbec25", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/dff276e33aac592ee1bf014a7f31be827cbbec25", "committedDate": "2020-02-19T09:38:01Z", "message": "Merge remote-tracking branch 'elastic/master' into cache-latest-repository-data"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7a2ecf6866fa048467c3c9a1e8e8d459fbb8fdf0", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/7a2ecf6866fa048467c3c9a1e8e8d459fbb8fdf0", "committedDate": "2020-02-19T11:07:07Z", "message": "Size Limit Cache and Intern Strings"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYxMDI2NzA3", "url": "https://github.com/elastic/elasticsearch/pull/52341#pullrequestreview-361026707", "createdAt": "2020-02-19T11:11:53Z", "commit": {"oid": "7a2ecf6866fa048467c3c9a1e8e8d459fbb8fdf0"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQxMToxMTo1M1rOFrkO8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQxMToxMTo1M1rOFrkO8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTIyNjczOQ==", "bodyText": "Moving to interning here and for the snapshot id actually makes the on heap RepositoryData about the same size as the serialized one (unfortunately for the time being we serialize it as json uncompressed) => I think the safety check for 500kb I added is valid.", "url": "https://github.com/elastic/elasticsearch/pull/52341#discussion_r381226739", "createdAt": "2020-02-19T11:11:53Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/repositories/IndexId.java", "diffHunk": "@@ -42,16 +42,14 @@\n     private final int hashCode;\n \n     public IndexId(final String name, final String id) {\n-        this.name = name;\n-        this.id = id;\n+        this.name = name.intern();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7a2ecf6866fa048467c3c9a1e8e8d459fbb8fdf0"}, "originalPosition": 6}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYxMDMxNjc4", "url": "https://github.com/elastic/elasticsearch/pull/52341#pullrequestreview-361031678", "createdAt": "2020-02-19T11:20:16Z", "commit": {"oid": "7a2ecf6866fa048467c3c9a1e8e8d459fbb8fdf0"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQxMToyMDoxNlrOFrkeDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQxMToyMDoxNlrOFrkeDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTIzMDYwNg==", "bodyText": "For context:\non heap 1k shards in a snapshot means about 25kb of shard generations which themselves make up ~50% of the size of RepositoryData on heap with the interning changes I added.\nThe number of snapshots doesn't matter much by comparison. So in the Cloud case of 100 snapshots, this would allow for caching snapshots of up to ~ 15k shards which should work fine for most users I'm assuming.", "url": "https://github.com/elastic/elasticsearch/pull/52341#discussion_r381230606", "createdAt": "2020-02-19T11:20:16Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java", "diffHunk": "@@ -1116,6 +1135,44 @@ public void getRepositoryData(ActionListener<RepositoryData> listener) {\n         }\n     }\n \n+    /**\n+     * Puts the given {@link RepositoryData} into the cache if it is of a newer generation and only if the repository is not using\n+     * {@link #bestEffortConsistency}. When using {@link #bestEffortConsistency} the repository is using listing to find the latest\n+     * {@code index-N} blob and there are no hard guarantees that a given repository generation won't be reused since an external\n+     * modification can lead to moving from a higher {@code N} to a lower {@code N} value which mean we can't safely assume that a given\n+     * generation will always contain the same {@link RepositoryData}.\n+     *\n+     * @param updated RepositoryData to cache if newer than the cache contents\n+     */\n+    private void cacheRepositoryData(RepositoryData updated) {\n+        if (bestEffortConsistency == false) {\n+            try {\n+                final int len =\n+                    BytesReference.bytes(updated.snapshotsToXContent(XContentFactory.jsonBuilder(), true)).length();\n+                if (len > ByteSizeUnit.KB.toBytes(500)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7a2ecf6866fa048467c3c9a1e8e8d459fbb8fdf0"}, "originalPosition": 78}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "039c0d05323ae4e769c7e89c61feb049051c1d08", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/039c0d05323ae4e769c7e89c61feb049051c1d08", "committedDate": "2020-02-19T11:22:54Z", "message": "intern all the way"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYxMDkzMDAx", "url": "https://github.com/elastic/elasticsearch/pull/52341#pullrequestreview-361093001", "createdAt": "2020-02-19T13:06:43Z", "commit": {"oid": "039c0d05323ae4e769c7e89c61feb049051c1d08"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQxMzowNjo0M1rOFrnVSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQxMzoxNDozNVrOFrnkhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTI3NzUxNA==", "bodyText": "I would prefer to avoid JVM String interning. If we can deduplicate the Strings ourselves, that's fine, but adding more and more stuff to be internalized feels dangerous (another source of OOM).", "url": "https://github.com/elastic/elasticsearch/pull/52341#discussion_r381277514", "createdAt": "2020-02-19T13:06:43Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/repositories/IndexId.java", "diffHunk": "@@ -42,16 +42,14 @@\n     private final int hashCode;\n \n     public IndexId(final String name, final String id) {\n-        this.name = name;\n-        this.id = id;\n+        this.name = name.intern();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTIyNjczOQ=="}, "originalCommit": {"oid": "7a2ecf6866fa048467c3c9a1e8e8d459fbb8fdf0"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTI3OTExNw==", "bodyText": "maybe we can just cache the serialized (and compressed) bytes instead of the object. Decompressing should still be fast.", "url": "https://github.com/elastic/elasticsearch/pull/52341#discussion_r381279117", "createdAt": "2020-02-19T13:10:04Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java", "diffHunk": "@@ -513,10 +514,13 @@ public void deleteSnapshot(SnapshotId snapshotId, long repositoryStateId, Versio\n     private RepositoryData safeRepositoryData(long repositoryStateId, Map<String, BlobMetaData> rootBlobs) {\n         final long generation = latestGeneration(rootBlobs.keySet());\n         final long genToLoad;\n+        final RepositoryData cached;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "039c0d05323ae4e769c7e89c61feb049051c1d08"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTI4MTQxMw==", "bodyText": "If the node can't serialize the RepositoryData, it would die here. Perhaps just catch and log (while having an assert as well for our tests)", "url": "https://github.com/elastic/elasticsearch/pull/52341#discussion_r381281413", "createdAt": "2020-02-19T13:14:35Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java", "diffHunk": "@@ -1116,6 +1135,44 @@ public void getRepositoryData(ActionListener<RepositoryData> listener) {\n         }\n     }\n \n+    /**\n+     * Puts the given {@link RepositoryData} into the cache if it is of a newer generation and only if the repository is not using\n+     * {@link #bestEffortConsistency}. When using {@link #bestEffortConsistency} the repository is using listing to find the latest\n+     * {@code index-N} blob and there are no hard guarantees that a given repository generation won't be reused since an external\n+     * modification can lead to moving from a higher {@code N} to a lower {@code N} value which mean we can't safely assume that a given\n+     * generation will always contain the same {@link RepositoryData}.\n+     *\n+     * @param updated RepositoryData to cache if newer than the cache contents\n+     */\n+    private void cacheRepositoryData(RepositoryData updated) {\n+        if (bestEffortConsistency == false) {\n+            try {\n+                final int len =\n+                    BytesReference.bytes(updated.snapshotsToXContent(XContentFactory.jsonBuilder(), true)).length();\n+                if (len > ByteSizeUnit.KB.toBytes(500)) {\n+                    logger.debug(\"Not caching repository data of size [{}] for repository [{}] because it is larger than 500KB in\" +\n+                        \" serialized size\", len, metadata.name());\n+                    if (len > ByteSizeUnit.MB.toBytes(5)) {\n+                        logger.warn(\"Your repository metadata blob for repository [{}] is larger than 5MB. Consider moving to a fresh\" +\n+                            \" repository for new snapshots or deleting unneeded snapshots from your repository to ensure stable\" +\n+                            \" repository behavior going forward.\", metadata.name());\n+                    }\n+                    // Set empty repository data to not waste heap for an outdated cached value\n+                    latestKnownRepositoryData.set(RepositoryData.EMPTY);\n+                    return;\n+                }\n+            } catch (IOException e) {\n+                throw new AssertionError(\"Impossible, no IO happens here\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "039c0d05323ae4e769c7e89c61feb049051c1d08"}, "originalPosition": 91}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9c060f9895214b003cb2313a2afc0b0fd8d13ce3", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/9c060f9895214b003cb2313a2afc0b0fd8d13ce3", "committedDate": "2020-02-19T15:19:57Z", "message": "Merge remote-tracking branch 'elastic/master' into cache-latest-repository-data"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYxMjAxNTIy", "url": "https://github.com/elastic/elasticsearch/pull/52341#pullrequestreview-361201522", "createdAt": "2020-02-19T15:50:42Z", "commit": {"oid": "039c0d05323ae4e769c7e89c61feb049051c1d08"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQxNTo1MDo0MlrOFrsfBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQxNTo1MTo0NFrOFrsh4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTM2MTkyNQ==", "bodyText": "Maybe make RepositoryData implements Accountable? Should we craft an estimating function instead of serializing the whole RepositoryData back again? If we were serializing back to XContent we could pass a FilterOutputStream to the XContentBuilder so that it just count bytes and not build everything in heap.\nOr if we follow Yannick's suggestion on caching the serialized and compressed bytes then maybe we should keep track of the length of the original blob.", "url": "https://github.com/elastic/elasticsearch/pull/52341#discussion_r381361925", "createdAt": "2020-02-19T15:50:42Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java", "diffHunk": "@@ -1116,6 +1135,44 @@ public void getRepositoryData(ActionListener<RepositoryData> listener) {\n         }\n     }\n \n+    /**\n+     * Puts the given {@link RepositoryData} into the cache if it is of a newer generation and only if the repository is not using\n+     * {@link #bestEffortConsistency}. When using {@link #bestEffortConsistency} the repository is using listing to find the latest\n+     * {@code index-N} blob and there are no hard guarantees that a given repository generation won't be reused since an external\n+     * modification can lead to moving from a higher {@code N} to a lower {@code N} value which mean we can't safely assume that a given\n+     * generation will always contain the same {@link RepositoryData}.\n+     *\n+     * @param updated RepositoryData to cache if newer than the cache contents\n+     */\n+    private void cacheRepositoryData(RepositoryData updated) {\n+        if (bestEffortConsistency == false) {\n+            try {\n+                final int len =\n+                    BytesReference.bytes(updated.snapshotsToXContent(XContentFactory.jsonBuilder(), true)).length();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "039c0d05323ae4e769c7e89c61feb049051c1d08"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTM2MjY1Ng==", "bodyText": "Maybe add a TODO then?", "url": "https://github.com/elastic/elasticsearch/pull/52341#discussion_r381362656", "createdAt": "2020-02-19T15:51:44Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java", "diffHunk": "@@ -1359,6 +1398,7 @@ public void onFailure(String source, Exception e) {\n \n                     @Override\n                     public void clusterStateProcessed(String source, ClusterState oldState, ClusterState newState) {\n+                        cacheRepositoryData(filteredRepositoryData.withGenId(newGen));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMzMTkzMA=="}, "originalCommit": {"oid": "b5d135470c1f6b1b31b0f1e94a1ded21bf9baff1"}, "originalPosition": 91}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "44ba2707de568f2354a6c5461b10019e5405ee45", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/44ba2707de568f2354a6c5461b10019e5405ee45", "committedDate": "2020-02-19T16:55:23Z", "message": "Merge remote-tracking branch 'elastic/master' into cache-latest-repository-data"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "520716e419104af476d2b37fe3e849afc9378942", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/520716e419104af476d2b37fe3e849afc9378942", "committedDate": "2020-02-19T18:36:44Z", "message": "Cache compressed serialized"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYxNzU5MzM4", "url": "https://github.com/elastic/elasticsearch/pull/52341#pullrequestreview-361759338", "createdAt": "2020-02-20T09:45:28Z", "commit": {"oid": "520716e419104af476d2b37fe3e849afc9378942"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yMFQwOTo0NToyOFrOFsMlcQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yMFQwOTo1NDoyNVrOFsM5RQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTg4Nzg1Nw==", "bodyText": "I think I would prefer an explicit undocumented setting to disable the cache. This might also turn out to be useful if we see any issues with this new functionality", "url": "https://github.com/elastic/elasticsearch/pull/52341#discussion_r381887857", "createdAt": "2020-02-20T09:45:28Z", "author": {"login": "ywelsch"}, "path": "plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java", "diffHunk": "@@ -132,6 +132,8 @@ public void testEnforcedCooldownPeriod() throws IOException {\n             }\n         })));\n \n+        // Master failover to clear RepositoryData cache", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "520716e419104af476d2b37fe3e849afc9378942"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTg4ODgxNQ==", "bodyText": "Should cached.v2() always be non-null if cached != null?", "url": "https://github.com/elastic/elasticsearch/pull/52341#discussion_r381888815", "createdAt": "2020-02-20T09:47:04Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java", "diffHunk": "@@ -529,6 +536,9 @@ private RepositoryData safeRepositoryData(long repositoryStateId, Map<String, Bl\n             throw new RepositoryException(metadata.name(), \"concurrent modification of the index-N file, expected current generation [\" +\n                 repositoryStateId + \"], actual current generation [\" + genToLoad + \"]\");\n         }\n+        if (cached != null && cached.v1() == genToLoad && cached.v2() != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "520716e419104af476d2b37fe3e849afc9378942"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTg4OTAxOQ==", "bodyText": "perhaps just initialize to null?", "url": "https://github.com/elastic/elasticsearch/pull/52341#discussion_r381889019", "createdAt": "2020-02-20T09:47:29Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java", "diffHunk": "@@ -1057,6 +1067,10 @@ public void endVerification(String seed) {\n     // and concurrent modifications.\n     private final AtomicLong latestKnownRepoGen = new AtomicLong(RepositoryData.UNKNOWN_REPO_GEN);\n \n+    // Best effort cache of the latest known repository data and its generation, cached serialized as compressed json\n+    private final AtomicReference<Tuple<Long, BytesReference>> latestKnownRepositoryData =\n+        new AtomicReference<>(new Tuple<>(RepositoryData.EMPTY_REPO_GEN, null));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "520716e419104af476d2b37fe3e849afc9378942"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTg5MTE3Nw==", "bodyText": "just set to null?", "url": "https://github.com/elastic/elasticsearch/pull/52341#discussion_r381891177", "createdAt": "2020-02-20T09:51:17Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java", "diffHunk": "@@ -1116,6 +1139,62 @@ public void getRepositoryData(ActionListener<RepositoryData> listener) {\n         }\n     }\n \n+    /**\n+     * Puts the given {@link RepositoryData} into the cache if it is of a newer generation and only if the repository is not using\n+     * {@link #bestEffortConsistency}. When using {@link #bestEffortConsistency} the repository is using listing to find the latest\n+     * {@code index-N} blob and there are no hard guarantees that a given repository generation won't be reused since an external\n+     * modification can lead to moving from a higher {@code N} to a lower {@code N} value which mean we can't safely assume that a given\n+     * generation will always contain the same {@link RepositoryData}.\n+     *\n+     * @param updated RepositoryData to cache if newer than the cache contents\n+     */\n+    private void cacheRepositoryData(RepositoryData updated) {\n+        if (bestEffortConsistency == false) {\n+            final BytesReference serialized;\n+            BytesStreamOutput out = new BytesStreamOutput();\n+            try {\n+                try (StreamOutput tmp = CompressorFactory.COMPRESSOR.streamOutput(out);\n+                     XContentBuilder builder = XContentFactory.jsonBuilder(tmp)) {\n+                    updated.snapshotsToXContent(builder, true);\n+                }\n+                serialized = out.bytes();\n+                final int len = serialized.length();\n+                if (len > ByteSizeUnit.KB.toBytes(500)) {\n+                    logger.debug(\"Not caching repository data of size [{}] for repository [{}] because it is larger than 500KB in\" +\n+                        \" serialized size\", len, metadata.name());\n+                    if (len > ByteSizeUnit.MB.toBytes(5)) {\n+                        logger.warn(\"Your repository metadata blob for repository [{}] is larger than 5MB. Consider moving to a fresh\" +\n+                            \" repository for new snapshots or deleting unneeded snapshots from your repository to ensure stable\" +\n+                            \" repository behavior going forward.\", metadata.name());\n+                    }\n+                    // Set empty repository data to not waste heap for an outdated cached value\n+                    latestKnownRepositoryData.set(new Tuple<>(RepositoryData.EMPTY_REPO_GEN, null));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "520716e419104af476d2b37fe3e849afc9378942"}, "originalPosition": 118}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTg5MjkzMw==", "bodyText": "I think this optimization is unnecessary, and complicating the checks on null (see my suggestions above)", "url": "https://github.com/elastic/elasticsearch/pull/52341#discussion_r381892933", "createdAt": "2020-02-20T09:54:25Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java", "diffHunk": "@@ -1116,6 +1139,62 @@ public void getRepositoryData(ActionListener<RepositoryData> listener) {\n         }\n     }\n \n+    /**\n+     * Puts the given {@link RepositoryData} into the cache if it is of a newer generation and only if the repository is not using\n+     * {@link #bestEffortConsistency}. When using {@link #bestEffortConsistency} the repository is using listing to find the latest\n+     * {@code index-N} blob and there are no hard guarantees that a given repository generation won't be reused since an external\n+     * modification can lead to moving from a higher {@code N} to a lower {@code N} value which mean we can't safely assume that a given\n+     * generation will always contain the same {@link RepositoryData}.\n+     *\n+     * @param updated RepositoryData to cache if newer than the cache contents\n+     */\n+    private void cacheRepositoryData(RepositoryData updated) {\n+        if (bestEffortConsistency == false) {\n+            final BytesReference serialized;\n+            BytesStreamOutput out = new BytesStreamOutput();\n+            try {\n+                try (StreamOutput tmp = CompressorFactory.COMPRESSOR.streamOutput(out);\n+                     XContentBuilder builder = XContentFactory.jsonBuilder(tmp)) {\n+                    updated.snapshotsToXContent(builder, true);\n+                }\n+                serialized = out.bytes();\n+                final int len = serialized.length();\n+                if (len > ByteSizeUnit.KB.toBytes(500)) {\n+                    logger.debug(\"Not caching repository data of size [{}] for repository [{}] because it is larger than 500KB in\" +\n+                        \" serialized size\", len, metadata.name());\n+                    if (len > ByteSizeUnit.MB.toBytes(5)) {\n+                        logger.warn(\"Your repository metadata blob for repository [{}] is larger than 5MB. Consider moving to a fresh\" +\n+                            \" repository for new snapshots or deleting unneeded snapshots from your repository to ensure stable\" +\n+                            \" repository behavior going forward.\", metadata.name());\n+                    }\n+                    // Set empty repository data to not waste heap for an outdated cached value\n+                    latestKnownRepositoryData.set(new Tuple<>(RepositoryData.EMPTY_REPO_GEN, null));\n+                    return;\n+                }\n+            } catch (IOException e) {\n+                assert false : new AssertionError(\"Impossible, no IO happens here\", e);\n+                logger.warn(\"Failed to serialize repository data\", e);\n+                return;\n+            }\n+            latestKnownRepositoryData.updateAndGet(known -> {\n+                if (known.v1() > updated.getGenId()) {\n+                    return known;\n+                }\n+                return new Tuple<>(updated.getGenId(), serialized);\n+            });\n+        }\n+    }\n+\n+    private RepositoryData repositoryDataFromCachedEntry(Tuple<Long, BytesReference> cacheEntry) throws IOException {\n+        if (cacheEntry.v1() == RepositoryData.EMPTY_REPO_GEN) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "520716e419104af476d2b37fe3e849afc9378942"}, "originalPosition": 136}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a02f12943ac5ffb0414fe7f73daf73bf6dacf2e3", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/a02f12943ac5ffb0414fe7f73daf73bf6dacf2e3", "committedDate": "2020-02-20T10:31:23Z", "message": "Merge remote-tracking branch 'elastic/master' into cache-latest-repository-data"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "533b4f89a8201fa851620824c1d0a3e5f447724a", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/533b4f89a8201fa851620824c1d0a3e5f447724a", "committedDate": "2020-02-20T10:53:30Z", "message": "CR: setting to disable cache and null out cache"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYxODIxNzI3", "url": "https://github.com/elastic/elasticsearch/pull/52341#pullrequestreview-361821727", "createdAt": "2020-02-20T11:18:21Z", "commit": {"oid": "533b4f89a8201fa851620824c1d0a3e5f447724a"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2471, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}