{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzc5Njg5MzIx", "number": 52778, "reviewThreads": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxMTo1NTowOFrODjDFSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMDoxNDo0OVrODjOavg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4MDc3MjU4OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/MlStatsIndex.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxMTo1NTowOFrOFuovRQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxMTo1NTowOFrOFuovRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDQ0NjI3Nw==", "bodyText": "There's an inconsistency here, because if the index and alias already existed when the method was called the response is false, but if the method is called twice concurrently such that one concurrent call creates it and the other gets a ResourceAlreadyExistsException then both return true.\nIf the boolean is intended to be \"did this call create the index and alias\" then one should return false in this case.\nBut it's not actually documented what the returned boolean is supposed to mean.  Doing that would be good too.", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r384446277", "createdAt": "2020-02-26T11:55:08Z", "author": {"login": "droberts195"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/MlStatsIndex.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml;\n+\n+import org.elasticsearch.ResourceAlreadyExistsException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.admin.indices.alias.Alias;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexAction;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexRequest;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.template.TemplateUtils;\n+\n+/**\n+ * Describes the indices where ML is storing various stats about the users jobs.\n+ */\n+public class MlStatsIndex {\n+\n+    public static final String TEMPLATE_NAME = \".ml-stats\";\n+\n+    private static final String MAPPINGS_VERSION_VARIABLE = \"xpack.ml.version\";\n+\n+    private MlStatsIndex() {}\n+\n+    public static String mapping() {\n+        return TemplateUtils.loadTemplate(\"/org/elasticsearch/xpack/core/ml/stats_index_mappings.json\",\n+            Version.CURRENT.toString(), MAPPINGS_VERSION_VARIABLE);\n+    }\n+\n+    public static String indexPattern() {\n+        return TEMPLATE_NAME + \"-*\";\n+    }\n+\n+    public static String writeAlias() {\n+        return \".ml-stats-write\";\n+    }\n+\n+    /**\n+     * Creates the first concrete .ml-stats-000001 index (if necessary)\n+     * Creates the .ml-stats-write alias for that index.\n+     */\n+    public static void createStatsIndexAndAliasIfNecessary(Client client, ClusterState state, ActionListener<Boolean> listener) {\n+\n+        if (state.getMetaData().getAliasAndIndexLookup().containsKey(writeAlias())) {\n+            listener.onResponse(false);\n+            return;\n+        }\n+\n+        ActionListener<CreateIndexResponse> createIndexListener = ActionListener.wrap(\n+            createIndexResponse -> listener.onResponse(true),\n+            error -> {\n+                if (ExceptionsHelper.unwrapCause(error) instanceof ResourceAlreadyExistsException) {\n+                    listener.onResponse(true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6333b38ea14ee908d9be870ca4d0edc158a37dda"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4MDc4NzMzOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/MlStatsIndex.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxMjowMDozNVrOFuo4vw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxNTowOTowOFrOFvVRIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDQ0ODcwMw==", "bodyText": "This doesn't cover the edge case where the index exists but the write alias doesn't (presumably because a user accidentally deleted it, but maybe also due to a bug in ILM).\nI think this method should cover that case like AnomalyDetectorsIndex.createStateIndexAndAliasIfNecessary() does.  It will avoid support cases if the system can be self healing in this situation.  At present it will return true giving the impression that everything is good when the post conditions are that the index exists but not the alias.", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r384448703", "createdAt": "2020-02-26T12:00:35Z", "author": {"login": "droberts195"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/MlStatsIndex.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml;\n+\n+import org.elasticsearch.ResourceAlreadyExistsException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.admin.indices.alias.Alias;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexAction;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexRequest;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.template.TemplateUtils;\n+\n+/**\n+ * Describes the indices where ML is storing various stats about the users jobs.\n+ */\n+public class MlStatsIndex {\n+\n+    public static final String TEMPLATE_NAME = \".ml-stats\";\n+\n+    private static final String MAPPINGS_VERSION_VARIABLE = \"xpack.ml.version\";\n+\n+    private MlStatsIndex() {}\n+\n+    public static String mapping() {\n+        return TemplateUtils.loadTemplate(\"/org/elasticsearch/xpack/core/ml/stats_index_mappings.json\",\n+            Version.CURRENT.toString(), MAPPINGS_VERSION_VARIABLE);\n+    }\n+\n+    public static String indexPattern() {\n+        return TEMPLATE_NAME + \"-*\";\n+    }\n+\n+    public static String writeAlias() {\n+        return \".ml-stats-write\";\n+    }\n+\n+    /**\n+     * Creates the first concrete .ml-stats-000001 index (if necessary)\n+     * Creates the .ml-stats-write alias for that index.\n+     */\n+    public static void createStatsIndexAndAliasIfNecessary(Client client, ClusterState state, ActionListener<Boolean> listener) {\n+\n+        if (state.getMetaData().getAliasAndIndexLookup().containsKey(writeAlias())) {\n+            listener.onResponse(false);\n+            return;\n+        }\n+\n+        ActionListener<CreateIndexResponse> createIndexListener = ActionListener.wrap(\n+            createIndexResponse -> listener.onResponse(true),\n+            error -> {\n+                if (ExceptionsHelper.unwrapCause(error) instanceof ResourceAlreadyExistsException) {\n+                    listener.onResponse(true);\n+                } else {\n+                    listener.onFailure(error);\n+                }\n+            }\n+        );\n+\n+        CreateIndexRequest createIndexRequest = client.admin()\n+            .indices()\n+            .prepareCreate(TEMPLATE_NAME + \"-000001\")\n+            .addAlias(new Alias(writeAlias()).writeIndex(true))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6333b38ea14ee908d9be870ca4d0edc158a37dda"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTE3NTg0Mg==", "bodyText": "Good point. I thought the main reason we had that code for anomaly detection was because originally we were not using aliases. But I can see how being able to self-heal would help.", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r385175842", "createdAt": "2020-02-27T15:09:08Z", "author": {"login": "dimitris-athanasiou"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/MlStatsIndex.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml;\n+\n+import org.elasticsearch.ResourceAlreadyExistsException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.admin.indices.alias.Alias;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexAction;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexRequest;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.template.TemplateUtils;\n+\n+/**\n+ * Describes the indices where ML is storing various stats about the users jobs.\n+ */\n+public class MlStatsIndex {\n+\n+    public static final String TEMPLATE_NAME = \".ml-stats\";\n+\n+    private static final String MAPPINGS_VERSION_VARIABLE = \"xpack.ml.version\";\n+\n+    private MlStatsIndex() {}\n+\n+    public static String mapping() {\n+        return TemplateUtils.loadTemplate(\"/org/elasticsearch/xpack/core/ml/stats_index_mappings.json\",\n+            Version.CURRENT.toString(), MAPPINGS_VERSION_VARIABLE);\n+    }\n+\n+    public static String indexPattern() {\n+        return TEMPLATE_NAME + \"-*\";\n+    }\n+\n+    public static String writeAlias() {\n+        return \".ml-stats-write\";\n+    }\n+\n+    /**\n+     * Creates the first concrete .ml-stats-000001 index (if necessary)\n+     * Creates the .ml-stats-write alias for that index.\n+     */\n+    public static void createStatsIndexAndAliasIfNecessary(Client client, ClusterState state, ActionListener<Boolean> listener) {\n+\n+        if (state.getMetaData().getAliasAndIndexLookup().containsKey(writeAlias())) {\n+            listener.onResponse(false);\n+            return;\n+        }\n+\n+        ActionListener<CreateIndexResponse> createIndexListener = ActionListener.wrap(\n+            createIndexResponse -> listener.onResponse(true),\n+            error -> {\n+                if (ExceptionsHelper.unwrapCause(error) instanceof ResourceAlreadyExistsException) {\n+                    listener.onResponse(true);\n+                } else {\n+                    listener.onFailure(error);\n+                }\n+            }\n+        );\n+\n+        CreateIndexRequest createIndexRequest = client.admin()\n+            .indices()\n+            .prepareCreate(TEMPLATE_NAME + \"-000001\")\n+            .addAlias(new Alias(writeAlias()).writeIndex(true))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDQ0ODcwMw=="}, "originalCommit": {"oid": "6333b38ea14ee908d9be870ca4d0edc158a37dda"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4MDgxNTAwOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/stats/MemoryUsage.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxMjoxMTowMVrOFupKLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxMjoxMTowMVrOFupKLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDQ1MzE2Ng==", "bodyText": "I don't think it's good that we're propagating the behaviour of the old Prelert time parsing that is completely non-standard in the Elastic stack into new code:\n            if (date.trim().length() <= 10) { // seconds\n                return epoch * 1000;\n            } else {\n                return epoch;\n            }\n\nIt would have been best if we'd removed this years ago.\nMaybe now is a good opportunity to rename TimeUtils.parseTimeField() to TimeUtils.parseTimeFieldDeprecated() and TimeUtils.parseTimeFieldToInstant() to TimeUtils.parseTimeFieldToInstantDeprecated(), annotate both with @Deprecated and introduce a new method TimeUtils.parseTimeFieldToInstant() that can be used here that replaces return Instant.ofEpochMilli(dateStringToEpoch(parser.text())); with return Instant.from(DateFieldMapper.DEFAULT_DATE_TIME_FORMATTER.parse(parser.text()));.", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r384453166", "createdAt": "2020-02-26T12:11:01Z", "author": {"login": "droberts195"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/stats/MemoryUsage.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.dataframe.stats;\n+\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+\n+public class MemoryUsage implements Writeable, ToXContentObject {\n+\n+    public static final String TYPE_VALUE = \"analytics_memory_usage\";\n+\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField JOB_ID = new ParseField(\"job_id\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"timestamp\");\n+    public static final ParseField PEAK_USAGE_BYTES = new ParseField(\"peak_usage_bytes\");\n+\n+    public static final ConstructingObjectParser<MemoryUsage, Void> STRICT_PARSER = createParser(false);\n+    public static final ConstructingObjectParser<MemoryUsage, Void> LENIENT_PARSER = createParser(true);\n+\n+    private static ConstructingObjectParser<MemoryUsage, Void> createParser(boolean ignoreUnknownFields) {\n+        ConstructingObjectParser<MemoryUsage, Void> parser = new ConstructingObjectParser<>(TYPE_VALUE,\n+            ignoreUnknownFields, a -> new MemoryUsage((String) a[0], (Instant) a[1], (long) a[2]));\n+\n+        parser.declareString((bucket, s) -> {}, TYPE);\n+        parser.declareString(ConstructingObjectParser.constructorArg(), JOB_ID);\n+        parser.declareField(ConstructingObjectParser.constructorArg(),\n+            p -> TimeUtils.parseTimeFieldToInstant(p, TIMESTAMP.getPreferredName()),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6333b38ea14ee908d9be870ca4d0edc158a37dda"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4MDgyMDIzOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/stats/MemoryUsage.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxMjoxMzowOVrOFupNig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxMjoxMzowOVrOFupNig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDQ1NDAyNg==", "bodyText": "It would be good to add a comment that the reason for rounding to millisecond accuracy is that the XContent representation rounds to millisecond accuracy and it makes debugging hard if the internal accuracy is greater.", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r384454026", "createdAt": "2020-02-26T12:13:09Z", "author": {"login": "droberts195"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/stats/MemoryUsage.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.dataframe.stats;\n+\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+\n+public class MemoryUsage implements Writeable, ToXContentObject {\n+\n+    public static final String TYPE_VALUE = \"analytics_memory_usage\";\n+\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField JOB_ID = new ParseField(\"job_id\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"timestamp\");\n+    public static final ParseField PEAK_USAGE_BYTES = new ParseField(\"peak_usage_bytes\");\n+\n+    public static final ConstructingObjectParser<MemoryUsage, Void> STRICT_PARSER = createParser(false);\n+    public static final ConstructingObjectParser<MemoryUsage, Void> LENIENT_PARSER = createParser(true);\n+\n+    private static ConstructingObjectParser<MemoryUsage, Void> createParser(boolean ignoreUnknownFields) {\n+        ConstructingObjectParser<MemoryUsage, Void> parser = new ConstructingObjectParser<>(TYPE_VALUE,\n+            ignoreUnknownFields, a -> new MemoryUsage((String) a[0], (Instant) a[1], (long) a[2]));\n+\n+        parser.declareString((bucket, s) -> {}, TYPE);\n+        parser.declareString(ConstructingObjectParser.constructorArg(), JOB_ID);\n+        parser.declareField(ConstructingObjectParser.constructorArg(),\n+            p -> TimeUtils.parseTimeFieldToInstant(p, TIMESTAMP.getPreferredName()),\n+            TIMESTAMP,\n+            ObjectParser.ValueType.VALUE);\n+        parser.declareLong(ConstructingObjectParser.constructorArg(), PEAK_USAGE_BYTES);\n+        return parser;\n+    }\n+\n+    private final String jobId;\n+    private final Instant timestamp;\n+    private final long peakUsageBytes;\n+\n+    public MemoryUsage(String jobId, Instant timestamp, long peakUsageBytes) {\n+        this.jobId = Objects.requireNonNull(jobId);\n+        this.timestamp = Instant.ofEpochMilli(ExceptionsHelper.requireNonNull(timestamp, TIMESTAMP).toEpochMilli());\n+        this.peakUsageBytes = peakUsageBytes;\n+    }\n+\n+    public MemoryUsage(StreamInput in) throws IOException {\n+        jobId = in.readString();\n+        timestamp = in.readInstant();\n+        peakUsageBytes = in.readVLong();\n+    }\n+\n+    @Override\n+    public void writeTo(StreamOutput out) throws IOException {\n+        out.writeString(jobId);\n+        out.writeInstant(timestamp);\n+        out.writeVLong(peakUsageBytes);\n+    }\n+\n+    @Override\n+    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n+        builder.startObject();\n+        if (params.paramAsBoolean(ToXContentParams.FOR_INTERNAL_STORAGE, false)) {\n+            builder.field(TYPE.getPreferredName(), TYPE_VALUE);\n+            builder.field(JOB_ID.getPreferredName(), jobId);\n+        }\n+        builder.timeField(TIMESTAMP.getPreferredName(), TIMESTAMP.getPreferredName() + \"_string\", timestamp.toEpochMilli());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6333b38ea14ee908d9be870ca4d0edc158a37dda"}, "originalPosition": 81}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4MjU3MjY1OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/stats/MemoryUsage.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxOTo1NzoxOFrOFu6GLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQxMTowMzozNVrOFvxTBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDczMDY2OQ==", "bodyText": "Why is this necessary? Presumably, the only time it is parsing TYPE is when it is reading from the index. In that case, it should ignore unknown fields.", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r384730669", "createdAt": "2020-02-26T19:57:18Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/stats/MemoryUsage.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.dataframe.stats;\n+\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+\n+public class MemoryUsage implements Writeable, ToXContentObject {\n+\n+    public static final String TYPE_VALUE = \"analytics_memory_usage\";\n+\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField JOB_ID = new ParseField(\"job_id\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"timestamp\");\n+    public static final ParseField PEAK_USAGE_BYTES = new ParseField(\"peak_usage_bytes\");\n+\n+    public static final ConstructingObjectParser<MemoryUsage, Void> STRICT_PARSER = createParser(false);\n+    public static final ConstructingObjectParser<MemoryUsage, Void> LENIENT_PARSER = createParser(true);\n+\n+    private static ConstructingObjectParser<MemoryUsage, Void> createParser(boolean ignoreUnknownFields) {\n+        ConstructingObjectParser<MemoryUsage, Void> parser = new ConstructingObjectParser<>(TYPE_VALUE,\n+            ignoreUnknownFields, a -> new MemoryUsage((String) a[0], (Instant) a[1], (long) a[2]));\n+\n+        parser.declareString((bucket, s) -> {}, TYPE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6333b38ea14ee908d9be870ca4d0edc158a37dda"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTAxNzI4OA==", "bodyText": "I don't think it's that bad to include it even though it's technically redundant.  It serves partly as documentation that we expect the field to exist if somebody is looking at the parser definition to find out which fields are expected in the document in the current product version.", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r385017288", "createdAt": "2020-02-27T09:50:22Z", "author": {"login": "droberts195"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/stats/MemoryUsage.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.dataframe.stats;\n+\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+\n+public class MemoryUsage implements Writeable, ToXContentObject {\n+\n+    public static final String TYPE_VALUE = \"analytics_memory_usage\";\n+\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField JOB_ID = new ParseField(\"job_id\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"timestamp\");\n+    public static final ParseField PEAK_USAGE_BYTES = new ParseField(\"peak_usage_bytes\");\n+\n+    public static final ConstructingObjectParser<MemoryUsage, Void> STRICT_PARSER = createParser(false);\n+    public static final ConstructingObjectParser<MemoryUsage, Void> LENIENT_PARSER = createParser(true);\n+\n+    private static ConstructingObjectParser<MemoryUsage, Void> createParser(boolean ignoreUnknownFields) {\n+        ConstructingObjectParser<MemoryUsage, Void> parser = new ConstructingObjectParser<>(TYPE_VALUE,\n+            ignoreUnknownFields, a -> new MemoryUsage((String) a[0], (Instant) a[1], (long) a[2]));\n+\n+        parser.declareString((bucket, s) -> {}, TYPE);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDczMDY2OQ=="}, "originalCommit": {"oid": "6333b38ea14ee908d9be870ca4d0edc158a37dda"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTYzNTA3OA==", "bodyText": "Good point!", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r385635078", "createdAt": "2020-02-28T11:03:35Z", "author": {"login": "dimitris-athanasiou"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/stats/MemoryUsage.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.dataframe.stats;\n+\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+\n+public class MemoryUsage implements Writeable, ToXContentObject {\n+\n+    public static final String TYPE_VALUE = \"analytics_memory_usage\";\n+\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField JOB_ID = new ParseField(\"job_id\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"timestamp\");\n+    public static final ParseField PEAK_USAGE_BYTES = new ParseField(\"peak_usage_bytes\");\n+\n+    public static final ConstructingObjectParser<MemoryUsage, Void> STRICT_PARSER = createParser(false);\n+    public static final ConstructingObjectParser<MemoryUsage, Void> LENIENT_PARSER = createParser(true);\n+\n+    private static ConstructingObjectParser<MemoryUsage, Void> createParser(boolean ignoreUnknownFields) {\n+        ConstructingObjectParser<MemoryUsage, Void> parser = new ConstructingObjectParser<>(TYPE_VALUE,\n+            ignoreUnknownFields, a -> new MemoryUsage((String) a[0], (Instant) a[1], (long) a[2]));\n+\n+        parser.declareString((bucket, s) -> {}, TYPE);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDczMDY2OQ=="}, "originalCommit": {"oid": "6333b38ea14ee908d9be870ca4d0edc158a37dda"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4MjU4MTIxOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/core/ml/dataframe/stats/MemoryUsageTests.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMDowMDowMlrOFu6LqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQxMTo0MzowOVrOFvyTgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDczMjA3Mg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    return new ToXContent.MapParams(Collections.singletonMap(ToXContentParams.FOR_INTERNAL_STORAGE, \"true\"));\n          \n          \n            \n                    return new ToXContent.MapParams(Collections.singletonMap(ToXContentParams.FOR_INTERNAL_STORAGE, Boolean.toString(lenient));\n          \n      \n    \n    \n  \n\nI think will work so that the empty parsing declaration for TYPE can go away.", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r384732072", "createdAt": "2020-02-26T20:00:02Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/core/ml/dataframe/stats/MemoryUsageTests.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.dataframe.stats;\n+\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.test.AbstractSerializingTestCase;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.junit.Before;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Collections;\n+\n+public class MemoryUsageTests extends AbstractSerializingTestCase<MemoryUsage> {\n+\n+    private boolean lenient;\n+\n+    @Before\n+    public void chooseStrictOrLenient() {\n+        lenient = randomBoolean();\n+    }\n+\n+    @Override\n+    protected boolean supportsUnknownFields() {\n+        return lenient;\n+    }\n+\n+    @Override\n+    protected MemoryUsage doParseInstance(XContentParser parser) throws IOException {\n+        return lenient ? MemoryUsage.LENIENT_PARSER.parse(parser, null) : MemoryUsage.STRICT_PARSER.parse(parser, null);\n+    }\n+\n+    @Override\n+    protected ToXContent.Params getToXContentParams() {\n+        return new ToXContent.MapParams(Collections.singletonMap(ToXContentParams.FOR_INTERNAL_STORAGE, \"true\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6333b38ea14ee908d9be870ca4d0edc158a37dda"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTY1MTU4Ng==", "bodyText": "The problem is we also only write out job_id for internal storage. Then we can't test for equality. Given that, I think I'd rather keep parsing TYPE.", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r385651586", "createdAt": "2020-02-28T11:43:09Z", "author": {"login": "dimitris-athanasiou"}, "path": "x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/core/ml/dataframe/stats/MemoryUsageTests.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.dataframe.stats;\n+\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.test.AbstractSerializingTestCase;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.junit.Before;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Collections;\n+\n+public class MemoryUsageTests extends AbstractSerializingTestCase<MemoryUsage> {\n+\n+    private boolean lenient;\n+\n+    @Before\n+    public void chooseStrictOrLenient() {\n+        lenient = randomBoolean();\n+    }\n+\n+    @Override\n+    protected boolean supportsUnknownFields() {\n+        return lenient;\n+    }\n+\n+    @Override\n+    protected MemoryUsage doParseInstance(XContentParser parser) throws IOException {\n+        return lenient ? MemoryUsage.LENIENT_PARSER.parse(parser, null) : MemoryUsage.STRICT_PARSER.parse(parser, null);\n+    }\n+\n+    @Override\n+    protected ToXContent.Params getToXContentParams() {\n+        return new ToXContent.MapParams(Collections.singletonMap(ToXContentParams.FOR_INTERNAL_STORAGE, \"true\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDczMjA3Mg=="}, "originalCommit": {"oid": "6333b38ea14ee908d9be870ca4d0edc158a37dda"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4MjYxNTcxOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportGetDataFrameAnalyticsStatsAction.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMDowOTo1N1rOFu6gVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQxMTo1NjoyN1rOFvynbw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDczNzM2NA==", "bodyText": "I wonder if we will hit scaling issues if there are 100s of stopped tasks.\nSeems like we could be making 100s of unbatched, search requests.", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r384737364", "createdAt": "2020-02-26T20:09:57Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportGetDataFrameAnalyticsStatsAction.java", "diffHunk": "@@ -157,75 +160,99 @@ void gatherStatsForStoppedTasks(List<String> expandedIds, GetDataFrameAnalyticsS\n             return;\n         }\n \n-        searchStoredProgresses(stoppedTasksIds, ActionListener.wrap(\n-            storedProgresses -> {\n-                List<Stats> stoppedStats = new ArrayList<>(stoppedTasksIds.size());\n-                for (int i = 0; i < stoppedTasksIds.size(); i++) {\n-                    String configId = stoppedTasksIds.get(i);\n-                    StoredProgress storedProgress = storedProgresses.get(i);\n-                    stoppedStats.add(buildStats(configId, storedProgress.get()));\n-                }\n-                List<Stats> allTasksStats = new ArrayList<>(runningTasksResponse.getResponse().results());\n-                allTasksStats.addAll(stoppedStats);\n-                Collections.sort(allTasksStats, Comparator.comparing(Stats::getId));\n-                listener.onResponse(new GetDataFrameAnalyticsStatsAction.Response(new QueryPage<>(\n-                    allTasksStats, allTasksStats.size(), GetDataFrameAnalyticsAction.Response.RESULTS_FIELD)));\n-            },\n-            listener::onFailure\n-        ));\n+        AtomicInteger counter = new AtomicInteger(stoppedTasksIds.size());\n+        AtomicArray<Stats> jobStats = new AtomicArray<>(stoppedTasksIds.size());\n+        for (int i = 0; i < stoppedTasksIds.size(); i++) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6333b38ea14ee908d9be870ca4d0edc158a37dda"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTY1NjY4Nw==", "bodyText": "This is why I changed the code to make a multi-search per job. If we batch everything up, then we have jobs * stats_fields searches in a single multi-search and that to have its own problems. We do it this way for anomaly detection jobs too. Not sure there's a better way.", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r385656687", "createdAt": "2020-02-28T11:56:27Z", "author": {"login": "dimitris-athanasiou"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportGetDataFrameAnalyticsStatsAction.java", "diffHunk": "@@ -157,75 +160,99 @@ void gatherStatsForStoppedTasks(List<String> expandedIds, GetDataFrameAnalyticsS\n             return;\n         }\n \n-        searchStoredProgresses(stoppedTasksIds, ActionListener.wrap(\n-            storedProgresses -> {\n-                List<Stats> stoppedStats = new ArrayList<>(stoppedTasksIds.size());\n-                for (int i = 0; i < stoppedTasksIds.size(); i++) {\n-                    String configId = stoppedTasksIds.get(i);\n-                    StoredProgress storedProgress = storedProgresses.get(i);\n-                    stoppedStats.add(buildStats(configId, storedProgress.get()));\n-                }\n-                List<Stats> allTasksStats = new ArrayList<>(runningTasksResponse.getResponse().results());\n-                allTasksStats.addAll(stoppedStats);\n-                Collections.sort(allTasksStats, Comparator.comparing(Stats::getId));\n-                listener.onResponse(new GetDataFrameAnalyticsStatsAction.Response(new QueryPage<>(\n-                    allTasksStats, allTasksStats.size(), GetDataFrameAnalyticsAction.Response.RESULTS_FIELD)));\n-            },\n-            listener::onFailure\n-        ));\n+        AtomicInteger counter = new AtomicInteger(stoppedTasksIds.size());\n+        AtomicArray<Stats> jobStats = new AtomicArray<>(stoppedTasksIds.size());\n+        for (int i = 0; i < stoppedTasksIds.size(); i++) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDczNzM2NA=="}, "originalCommit": {"oid": "6333b38ea14ee908d9be870ca4d0edc158a37dda"}, "originalPosition": 105}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4MjYyOTc0OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/utils/persistence/MlParserUtils.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMDoxNDo0OVrOFu6pHQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMDoxNDo0OVrOFu6pHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDczOTYxMw==", "bodyText": "\u2764\ufe0f", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r384739613", "createdAt": "2020-02-26T20:14:49Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/utils/persistence/MlParserUtils.java", "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.utils.persistence;\n+\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchParseException;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.XContentType;\n+import org.elasticsearch.search.SearchHit;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.function.BiFunction;\n+\n+public final class MlParserUtils {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6333b38ea14ee908d9be870ca4d0edc158a37dda"}, "originalPosition": 22}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3791, "cost": 1, "resetAt": "2021-11-12T19:05:54Z"}}}