{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk2MTgzNTcy", "number": 63120, "title": "Wildcard field - add normalisation of ngram tokens to reduce disk space.", "bodyText": "All punctuation becomes / char and for A-Z0-9 chars turn even codepoints to prior odd e.g. aab becomes aaa.\nCloses #62817", "createdAt": "2020-10-01T11:26:57Z", "url": "https://github.com/elastic/elasticsearch/pull/63120", "merged": true, "mergeCommit": {"oid": "c23061345a2da58161b145060a3678694b607f91"}, "closed": true, "closedAt": "2020-10-02T14:26:10Z", "author": {"login": "markharwood"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdOQEJRgBqjM4MjkwNTc5ODk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdOmQ69gBqjM4MzQwNTUwNzY=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9f85d11dc63a9e57ec561c5b46209e3fa51e95c9", "author": {"user": {"login": "markharwood", "name": null}}, "url": "https://github.com/elastic/elasticsearch/commit/9f85d11dc63a9e57ec561c5b46209e3fa51e95c9", "committedDate": "2020-10-01T11:24:23Z", "message": "Add normalisation of ngram tokens to reduce disk space.\nAll punctuation becomes / char and for A-Z0-9 chars turn even codepoints to prior odd e.g. aab becomes aaa\n\nCloses #62817"}, "afterCommit": {"oid": "ceb82a10c64b94414dee8fa8a196886f61796a28", "author": {"user": {"login": "markharwood", "name": null}}, "url": "https://github.com/elastic/elasticsearch/commit/ceb82a10c64b94414dee8fa8a196886f61796a28", "committedDate": "2020-10-01T11:55:01Z", "message": "Add normalisation of ngram tokens to reduce disk space.\nAll punctuation becomes / char and for A-Z0-9 chars turn even codepoints to prior odd e.g. aab becomes aaa\n\nCloses #62817"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAwMzAzMzQ3", "url": "https://github.com/elastic/elasticsearch/pull/63120#pullrequestreview-500303347", "createdAt": "2020-10-01T12:40:39Z", "commit": {"oid": "ceb82a10c64b94414dee8fa8a196886f61796a28"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMVQxMjo0MDozOVrOHbIdrg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMVQxMjo0OTo0N1rOHbIz6A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODIxMjI3MA==", "bodyText": "Can we generalize the block checks above with Character.isLetterOrDigit() == false ?", "url": "https://github.com/elastic/elasticsearch/pull/63120#discussion_r498212270", "createdAt": "2020-10-01T12:40:39Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java", "diffHunk": "@@ -91,13 +93,98 @@\n     public static final String CONTENT_TYPE = \"wildcard\";\n     public static short MAX_CLAUSES_IN_APPROXIMATION_QUERY = 10;\n     public static final int NGRAM_SIZE = 3;\n-    static final NamedAnalyzer WILDCARD_ANALYZER = new NamedAnalyzer(\"_wildcard\", AnalyzerScope.GLOBAL, new Analyzer() {\n+    static final NamedAnalyzer WILDCARD_ANALYZER_7_10 = new NamedAnalyzer(\"_wildcard_7_10\", AnalyzerScope.GLOBAL, new Analyzer() {\n         @Override\n         public TokenStreamComponents createComponents(String fieldName) {\n             Tokenizer tokenizer = new NGramTokenizer(NGRAM_SIZE, NGRAM_SIZE);\n-            return new TokenStreamComponents(tokenizer);\n+            TokenStream tok = new NormaliseThinningFilter(tokenizer);\n+            \n+            return new TokenStreamComponents(r -> {\n+                tokenizer.setReader(r);\n+            }, tok);            \n+            \n+            \n         }\n     });\n+    \n+    // @deprecated - used for BWC with elasticsearch 7.9\n+    static final NamedAnalyzer WILDCARD_ANALYZER_7_9 = new NamedAnalyzer(\"_wildcard\", AnalyzerScope.GLOBAL, new Analyzer() {\n+        @Override\n+        public TokenStreamComponents createComponents(String fieldName) {\n+            Tokenizer tokenizer = new NGramTokenizer(NGRAM_SIZE, NGRAM_SIZE);\n+                return new TokenStreamComponents(tokenizer);\n+        }\n+    });\n+    \n+    public static class NormaliseThinningFilter extends TokenFilter {\n+        private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n+        \n+        /**\n+         * Create a new NormaliseThinningFilter, that normalizes token text such that even-numbered ascii values\n+         * are made odd and punctuation is replaced with /\n+         * \n+         * @param in TokenStream to filter\n+         */\n+        public NormaliseThinningFilter(TokenStream in) {\n+          super(in);\n+        }\n+        \n+        @Override\n+        public final boolean incrementToken() throws IOException {\n+          if (input.incrementToken()) {\n+              normalize(termAtt.buffer(), 0, termAtt.length());\n+            return true;\n+          } else\n+            return false;\n+        }\n+        \n+        public static String normalize(String s) {\n+            char[] chars = s.toCharArray();\n+            normalize(chars, 0, chars.length);\n+            return new String(chars);            \n+        }\n+        \n+        /**\n+         * Normalizes a token\n+         */\n+        public static void normalize(final char[] buffer, final int offset, final int limit) {\n+          assert buffer.length >= limit;\n+          assert 0 <= offset && offset <= buffer.length;\n+          for (int i = offset; i < limit;) {\n+            int codepoint = Character.codePointAt(buffer, i, limit);\n+            i += Character.toChars(\n+                    normalize(codepoint), buffer, i);\n+           }\n+        }\n+\n+        private static int normalize(int codepoint) {\n+            // Normalize  space ! \" # $ % &  ' ( } * + , - . chars to / \n+            if (codepoint >=32 && codepoint <= 47) {\n+                return 47; \n+            }\n+            // Normalize : ; < = > ? @ chars to / \n+            if (codepoint >=58 && codepoint <= 64) {\n+                return 47; \n+            }\n+            // Normalize  [ \\ ] ^ _ ` chars to / \n+            if (codepoint >=91 && codepoint <= 96) {\n+                return 47; \n+            }\n+            // Normalize  { | } ~ chars to / \n+            if (codepoint >=123 && codepoint <= 126) {\n+                return 47; \n+            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ceb82a10c64b94414dee8fa8a196886f61796a28"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODIxNDY1Mw==", "bodyText": "We could add the lowercase filter here instead of lowercasing outside of the analyzer ? I also wonder if putting a ASCIIFoldingFilter makes sense but that's maybe a different scope.", "url": "https://github.com/elastic/elasticsearch/pull/63120#discussion_r498214653", "createdAt": "2020-10-01T12:44:34Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java", "diffHunk": "@@ -91,13 +93,98 @@\n     public static final String CONTENT_TYPE = \"wildcard\";\n     public static short MAX_CLAUSES_IN_APPROXIMATION_QUERY = 10;\n     public static final int NGRAM_SIZE = 3;\n-    static final NamedAnalyzer WILDCARD_ANALYZER = new NamedAnalyzer(\"_wildcard\", AnalyzerScope.GLOBAL, new Analyzer() {\n+    static final NamedAnalyzer WILDCARD_ANALYZER_7_10 = new NamedAnalyzer(\"_wildcard_7_10\", AnalyzerScope.GLOBAL, new Analyzer() {\n         @Override\n         public TokenStreamComponents createComponents(String fieldName) {\n             Tokenizer tokenizer = new NGramTokenizer(NGRAM_SIZE, NGRAM_SIZE);\n-            return new TokenStreamComponents(tokenizer);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ceb82a10c64b94414dee8fa8a196886f61796a28"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODIxNjk2MQ==", "bodyText": "This should depend on the index created version ?", "url": "https://github.com/elastic/elasticsearch/pull/63120#discussion_r498216961", "createdAt": "2020-10-01T12:48:10Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java", "diffHunk": "@@ -215,13 +302,15 @@ public WildcardFieldMapper build(BuilderContext context) {\n         private WildcardFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n             super(name, true, fieldType.stored(), true,\n                 new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n-            setIndexAnalyzer(WILDCARD_ANALYZER);\n+            setIndexAnalyzer(WILDCARD_ANALYZER_7_10);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ceb82a10c64b94414dee8fa8a196886f61796a28"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODIxNzcxMQ==", "bodyText": "You don't need to resolve this at query-time. The correct analyzer can be picked once from the index created version when the field type is created.", "url": "https://github.com/elastic/elasticsearch/pull/63120#discussion_r498217711", "createdAt": "2020-10-01T12:49:26Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java", "diffHunk": "@@ -215,13 +302,15 @@ public WildcardFieldMapper build(BuilderContext context) {\n         private WildcardFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n             super(name, true, fieldType.stored(), true,\n                 new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n-            setIndexAnalyzer(WILDCARD_ANALYZER);\n+            setIndexAnalyzer(WILDCARD_ANALYZER_7_10);\n         }\n \n         @Override\n         public Query wildcardQuery(String wildcardPattern, RewriteMethod method, boolean caseInsensitive, QueryShardContext context) {\n \n             String ngramIndexPattern = addLineEndChars(toLowerCase(wildcardPattern));\n+            \n+            Analyzer analyzer = getCorrectAnalyzerForIndexVersion(context);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ceb82a10c64b94414dee8fa8a196886f61796a28"}, "originalPosition": 130}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODIxNzg4Mw==", "bodyText": "same here", "url": "https://github.com/elastic/elasticsearch/pull/63120#discussion_r498217883", "createdAt": "2020-10-01T12:49:41Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java", "diffHunk": "@@ -673,6 +765,7 @@ public Query rangeQuery(\n         ) {\n             BytesRef lower = lowerTerm == null ? null : BytesRefs.toBytesRef(lowerTerm);\n             BytesRef upper = upperTerm == null ? null : BytesRefs.toBytesRef(upperTerm);\n+            Analyzer analyzer = getCorrectAnalyzerForIndexVersion(context);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ceb82a10c64b94414dee8fa8a196886f61796a28"}, "originalPosition": 296}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODIxNzk2MA==", "bodyText": "and here", "url": "https://github.com/elastic/elasticsearch/pull/63120#discussion_r498217960", "createdAt": "2020-10-01T12:49:47Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java", "diffHunk": "@@ -751,6 +836,8 @@ public Query fuzzyQuery(\n         ) {\n             String searchTerm = BytesRefs.toString(value);\n             String lowerSearchTerm = toLowerCase(searchTerm);\n+            Analyzer analyzer = getCorrectAnalyzerForIndexVersion(context);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ceb82a10c64b94414dee8fa8a196886f61796a28"}, "originalPosition": 341}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAxMDM0OTk3", "url": "https://github.com/elastic/elasticsearch/pull/63120#pullrequestreview-501034997", "createdAt": "2020-10-02T10:48:05Z", "commit": {"oid": "c2e4e84800ac207379be6e1254a95e4c03833b17"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQxMDo0ODowNVrOHbpRtQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQxMDo0ODowNVrOHbpRtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODc0OTg3Nw==", "bodyText": "nit: can we rename into PunctuationFoldingFilter or something similar ?", "url": "https://github.com/elastic/elasticsearch/pull/63120#discussion_r498749877", "createdAt": "2020-10-02T10:48:05Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java", "diffHunk": "@@ -91,13 +94,95 @@\n     public static final String CONTENT_TYPE = \"wildcard\";\n     public static short MAX_CLAUSES_IN_APPROXIMATION_QUERY = 10;\n     public static final int NGRAM_SIZE = 3;\n-    static final NamedAnalyzer WILDCARD_ANALYZER = new NamedAnalyzer(\"_wildcard\", AnalyzerScope.GLOBAL, new Analyzer() {\n+    static final NamedAnalyzer WILDCARD_ANALYZER_7_10 = new NamedAnalyzer(\"_wildcard_7_10\", AnalyzerScope.GLOBAL, new Analyzer() {\n         @Override\n         public TokenStreamComponents createComponents(String fieldName) {\n             Tokenizer tokenizer = new NGramTokenizer(NGRAM_SIZE, NGRAM_SIZE);\n-            return new TokenStreamComponents(tokenizer);\n+            \n+            TokenStream tok = new LowerCaseFilter(tokenizer);\n+            tok = new NormaliseThinningFilter(tok);\n+            \n+            return new TokenStreamComponents(r -> {\n+                tokenizer.setReader(r);\n+            }, tok);            \n+            \n+            \n         }\n     });\n+    \n+    // @deprecated - used for BWC with elasticsearch 7.9\n+    static final NamedAnalyzer WILDCARD_ANALYZER_7_9 = new NamedAnalyzer(\"_wildcard\", AnalyzerScope.GLOBAL, new Analyzer() {\n+        @Override\n+        public TokenStreamComponents createComponents(String fieldName) {\n+            Tokenizer tokenizer = new NGramTokenizer(NGRAM_SIZE, NGRAM_SIZE);\n+            TokenStream tok = new LowerCaseFilter(tokenizer);\n+//                return new TokenStreamComponents(tokenizer);\n+            return new TokenStreamComponents(r -> {\n+                tokenizer.setReader(r);\n+            }, tok);            \n+        }\n+    });\n+    \n+    public static class NormaliseThinningFilter extends TokenFilter {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c2e4e84800ac207379be6e1254a95e4c03833b17"}, "originalPosition": 52}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c2e4e84800ac207379be6e1254a95e4c03833b17", "author": {"user": {"login": "markharwood", "name": null}}, "url": "https://github.com/elastic/elasticsearch/commit/c2e4e84800ac207379be6e1254a95e4c03833b17", "committedDate": "2020-10-01T14:35:33Z", "message": "Remove debug"}, "afterCommit": {"oid": "2253c70a38946b6a0efd8c88476c6b4e01f1f53b", "author": {"user": {"login": "markharwood", "name": null}}, "url": "https://github.com/elastic/elasticsearch/commit/2253c70a38946b6a0efd8c88476c6b4e01f1f53b", "committedDate": "2020-10-02T11:04:35Z", "message": "Class rename"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bb905c67fa41ba6718d9c593848c166762b8cb6a", "author": {"user": {"login": "markharwood", "name": null}}, "url": "https://github.com/elastic/elasticsearch/commit/bb905c67fa41ba6718d9c593848c166762b8cb6a", "committedDate": "2020-10-02T13:46:53Z", "message": "Add normalisation of ngram tokens to reduce disk space.\nAll punctuation becomes / char and for A-Z0-9 chars turn even codepoints to prior odd e.g. aab becomes aaa\n\nCloses #62817"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "de6c3f6613df9806aaa7d2598bb439b27d138853", "author": {"user": {"login": "markharwood", "name": null}}, "url": "https://github.com/elastic/elasticsearch/commit/de6c3f6613df9806aaa7d2598bb439b27d138853", "committedDate": "2020-10-02T13:46:53Z", "message": "Addressing review comments. Made lowercaseFilter part of Analyzer and set IndexAnalyzer appropriately on FieldType construction"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4261a2aad4baffc8907bf78fc499d515233927a1", "author": {"user": {"login": "markharwood", "name": null}}, "url": "https://github.com/elastic/elasticsearch/commit/4261a2aad4baffc8907bf78fc499d515233927a1", "committedDate": "2020-10-02T13:46:53Z", "message": "Line length"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d6cf5dc9451d7084a6abc7ae768a502c5e6746fe", "author": {"user": {"login": "markharwood", "name": null}}, "url": "https://github.com/elastic/elasticsearch/commit/d6cf5dc9451d7084a6abc7ae768a502c5e6746fe", "committedDate": "2020-10-02T13:46:53Z", "message": "Remove debug"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dcbe91ffd5917d12e87216d57f9008ff60536d0d", "author": {"user": {"login": "markharwood", "name": null}}, "url": "https://github.com/elastic/elasticsearch/commit/dcbe91ffd5917d12e87216d57f9008ff60536d0d", "committedDate": "2020-10-02T13:46:53Z", "message": "Class rename"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3944cf6f84456624a7f87c77bbb32e110d6073db", "author": {"user": {"login": "markharwood", "name": null}}, "url": "https://github.com/elastic/elasticsearch/commit/3944cf6f84456624a7f87c77bbb32e110d6073db", "committedDate": "2020-10-02T13:46:53Z", "message": "Removed commented out code"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2253c70a38946b6a0efd8c88476c6b4e01f1f53b", "author": {"user": {"login": "markharwood", "name": null}}, "url": "https://github.com/elastic/elasticsearch/commit/2253c70a38946b6a0efd8c88476c6b4e01f1f53b", "committedDate": "2020-10-02T11:04:35Z", "message": "Class rename"}, "afterCommit": {"oid": "3944cf6f84456624a7f87c77bbb32e110d6073db", "author": {"user": {"login": "markharwood", "name": null}}, "url": "https://github.com/elastic/elasticsearch/commit/3944cf6f84456624a7f87c77bbb32e110d6073db", "committedDate": "2020-10-02T13:46:53Z", "message": "Removed commented out code"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4451, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}