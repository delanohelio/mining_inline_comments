{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDUwNjAwNTc1", "number": 59740, "title": "Allocate slightly less per bucket", "bodyText": "This replaces that data structure that we use to resolve bucket ids in\nbucketing aggs that are inside other bucketing aggs. This replaces the\n\"legoed together\" data structure with a purpose built LongLongHash\nwith semantics similar to LongHash, except that it has two longs\nas keys instead of one.\nThe microbenchmarks show a fairly substantial performance gain on the\nhot path, around 30%. Rally's higher level benchmarks show anywhere\nfrom 0 to 7% speed improvements. Not as much as I'd hoped, but nothing\nto sneeze at. And, after all, we all allocating slightly less data per\nowningBucketOrd, which is always nice.", "createdAt": "2020-07-16T23:35:37Z", "url": "https://github.com/elastic/elasticsearch/pull/59740", "merged": true, "mergeCommit": {"oid": "cce9f6cf0a9667582731a267e1d85b6dad793cb1"}, "closed": true, "closedAt": "2020-07-20T13:00:59Z", "author": {"login": "nik9000"}, "timelineItems": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc1l5L0gH2gAyNDUwNjAwNTc1OmQ5MjE1N2M0ZmJlNjEzMDk1OTkzNzRlOWVkNTdiYWZiNTM3Mzg1OWQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc116bDgFqTQ1MDc2MjA2NA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "d92157c4fbe61309599374e9ed57bafb5373859d", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/d92157c4fbe61309599374e9ed57bafb5373859d", "committedDate": "2020-07-16T21:13:01Z", "message": "Replace legoed data structure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3a40a47ab37f22d2ca17cb67eac09ca03a367843", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/3a40a47ab37f22d2ca17cb67eac09ca03a367843", "committedDate": "2020-07-16T21:23:39Z", "message": "Try compacting keys"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8ccc652ae6d1c70b525c5cac2d950f664decefad", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/8ccc652ae6d1c70b525c5cac2d950f664decefad", "committedDate": "2020-07-16T22:43:01Z", "message": "Reverse"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0cbe92fc4134008c4922bc808b139804345bdde8", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/0cbe92fc4134008c4922bc808b139804345bdde8", "committedDate": "2020-07-16T23:25:10Z", "message": "Nope"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUwNzYyMDY0", "url": "https://github.com/elastic/elasticsearch/pull/59740#pullrequestreview-450762064", "createdAt": "2020-07-17T15:39:43Z", "commit": {"oid": "0cbe92fc4134008c4922bc808b139804345bdde8"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNTozOTo0M1rOGzX15w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNTozOTo0M1rOGzX15w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUyMTE5MQ==", "bodyText": "is this meant to be used?", "url": "https://github.com/elastic/elasticsearch/pull/59740#discussion_r456521191", "createdAt": "2020-07-17T15:39:43Z", "author": {"login": "talevy"}, "path": "server/src/main/java/org/elasticsearch/common/util/LongLongHash.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.common.util;\n+\n+import com.carrotsearch.hppc.BitMixer;\n+\n+import org.elasticsearch.common.lease.Releasables;\n+\n+/**\n+ * Specialized hash table implementation similar to BytesRefHash that maps\n+ * two long values to ids. Collisions are resolved with open addressing and\n+ * linear probing, growth is smooth thanks to {@link BigArrays} and capacity\n+ * is always a multiple of 2 for faster identification of buckets.\n+ * This class is not thread-safe.\n+ */\n+// IDs are internally stored as id + 1 so that 0 encodes for an empty slot\n+public final class LongLongHash extends AbstractHash {\n+    /**\n+     * The keys of the hash, stored one after another. So the keys for an id\n+     * are stored in {@code 2 * id} and {@code 2 * id + 1}. This arrangement\n+     * makes {@link #add(long, long)} about 17% faster which seems worth it\n+     * because it is in the critical path for aggregations.\n+     */\n+    private LongArray keys;\n+\n+    // Constructor with configurable capacity and default maximum load factor.\n+    public LongLongHash(long capacity, BigArrays bigArrays) {\n+        this(capacity, DEFAULT_MAX_LOAD_FACTOR, bigArrays);\n+    }\n+\n+    //Constructor with configurable capacity and load factor.\n+    public LongLongHash(long capacity, float maxLoadFactor, BigArrays bigArrays) {\n+        super(capacity, maxLoadFactor, bigArrays);\n+        keys = bigArrays.newLongArray(2 * capacity, false);\n+    }\n+\n+    /**\n+     * Return the first key at {@code 0 &lt;= index &lt;= capacity()}. The\n+     * result is undefined if the slot is unused.\n+     */\n+    public long getKey1(long id) {\n+        return keys.get(2 * id);\n+    }\n+\n+    /**\n+     * Return the second key at {@code 0 &lt;= index &lt;= capacity()}. The\n+     * result is undefined if the slot is unused.\n+     */\n+    public long getKey2(long id) {\n+        return keys.get(2 * id + 1);\n+    }\n+\n+    /**\n+     * Get the id associated with <code>key</code> or -1 if the key is not contained in the hash.\n+     */\n+    public long find(long key1, long key2) {\n+        final long slot = slot(hash(key1, key2), mask);\n+        for (long index = slot; ; index = nextSlot(index, mask)) {\n+            final long id = id(index);\n+            long keyOffset = 2 * id;\n+            if (id == -1 || (keys.get(keyOffset) == key1 && keys.get(keyOffset + 1) == key2)) {\n+                return id;\n+            }\n+        }\n+    }\n+\n+    private long set(long key1, long key2, long id) {\n+        assert size < maxSize;\n+        final long slot = slot(hash(key1, key2), mask);\n+        for (long index = slot; ; index = nextSlot(index, mask)) {\n+            final long curId = id(index);\n+            if (curId == -1) { // means unset\n+                id(index, id);\n+                append(id, key1, key2);\n+                ++size;\n+                return id;\n+            } else {\n+                long keyOffset = 2 * curId;\n+                if (keys.get(keyOffset) == key1 && keys.get(keyOffset + 1) == key2) {\n+                    return -1 - curId;\n+                }\n+            }\n+        }\n+    }\n+\n+    private void append(long id, long key1, long key2) {\n+        long keyOffset = 2 * id;\n+        keys = bigArrays.grow(keys, keyOffset + 2);\n+        keys.set(keyOffset, key1);\n+        keys.set(keyOffset + 1, key2);\n+    }\n+\n+    private void reset(long key1, long key2, long id) {\n+        final long slot = slot(hash(key1, key2), mask);\n+        for (long index = slot; ; index = nextSlot(index, mask)) {\n+            final long curId = id(index);\n+            if (curId == -1) { // means unset\n+                id(index, id);\n+                append(id, key1, key2);\n+                break;\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Try to add {@code key}. Return its newly allocated id if it wasn't in\n+     * the hash table yet, or {@code -1-id} if it was already present in\n+     * the hash table.\n+     */\n+    public long add(long key1, long key2) {\n+        if (size >= maxSize) {\n+            assert size == maxSize;\n+            grow();\n+        }\n+        assert size < maxSize;\n+        return set(key1, key2, size);\n+    }\n+\n+    @Override\n+    protected void removeAndAdd(long index) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0cbe92fc4134008c4922bc808b139804345bdde8"}, "originalPosition": 137}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4325, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}