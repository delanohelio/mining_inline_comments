{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI3MjcwNjQ0", "number": 57608, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QxNToxNToxNFrOECMxkw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QxNToxNToxNFrOECMxkw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwNzQxOTA3OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/indices/recovery/RemoteRecoveryTargetHandler.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QxNToxNToxNFrOGegqBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQxNTowNjoyN1rOGfKhog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDY0NTUxMA==", "bodyText": "The root of the issue here is that we keep retrying the request here when the node is gone from the cluster for good. Since we never stop this retry, we never release the underlying commit and the respective assertion for releasing all the commits in the ITs fails.\nThis fix feels really dirty to me though. I mainly opened this to illustrate where the problem lies, not sure this is an appropriate fix. Ideally, I'd hope we would have some mechanism for cancelling the retry if a node is dropped form the cluster but I couldn't find an easy way of building that (maybe someone else can?).", "url": "https://github.com/elastic/elasticsearch/pull/57608#discussion_r434645510", "createdAt": "2020-06-03T15:15:14Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/indices/recovery/RemoteRecoveryTargetHandler.java", "diffHunk": "@@ -261,7 +266,7 @@ public void tryAction(ActionListener<T> listener) {\n \n             @Override\n             public boolean shouldRetry(Exception e) {\n-                return retriesSupported && retryableException(e);\n+                return retriesSupported && clusterService.state().nodes().nodeExists(targetNode) && retryableException(e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "26ef3d17ad253120ef3038b32d6d7af7a0d2698d"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDY0ODEwMQ==", "bodyText": "ClusterStateObserver is the magical thing here. It should be registered whenever we schedule a retry, and early cancel a scheduled retry when the target node drops from the cluster.", "url": "https://github.com/elastic/elasticsearch/pull/57608#discussion_r434648101", "createdAt": "2020-06-03T15:18:40Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/indices/recovery/RemoteRecoveryTargetHandler.java", "diffHunk": "@@ -261,7 +266,7 @@ public void tryAction(ActionListener<T> listener) {\n \n             @Override\n             public boolean shouldRetry(Exception e) {\n-                return retriesSupported && retryableException(e);\n+                return retriesSupported && clusterService.state().nodes().nodeExists(targetNode) && retryableException(e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDY0NTUxMA=="}, "originalCommit": {"oid": "26ef3d17ad253120ef3038b32d6d7af7a0d2698d"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDY1MzQzMQ==", "bodyText": "Why don't we just have a single cluster state observer for RemoteRecoveryTargetHandler? We already have the whole cancellation infrastructure already built. Adding individual ones seems unnecessary.", "url": "https://github.com/elastic/elasticsearch/pull/57608#discussion_r434653431", "createdAt": "2020-06-03T15:25:55Z", "author": {"login": "tbrooks8"}, "path": "server/src/main/java/org/elasticsearch/indices/recovery/RemoteRecoveryTargetHandler.java", "diffHunk": "@@ -261,7 +266,7 @@ public void tryAction(ActionListener<T> listener) {\n \n             @Override\n             public boolean shouldRetry(Exception e) {\n-                return retriesSupported && retryableException(e);\n+                return retriesSupported && clusterService.state().nodes().nodeExists(targetNode) && retryableException(e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDY0NTUxMA=="}, "originalCommit": {"oid": "26ef3d17ad253120ef3038b32d6d7af7a0d2698d"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDY1NDgwMg==", "bodyText": "I didn't look at it in detail. Either is fine by me. Looks like @tbrooks8 volunteered to be a reviewer :)", "url": "https://github.com/elastic/elasticsearch/pull/57608#discussion_r434654802", "createdAt": "2020-06-03T15:27:39Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/indices/recovery/RemoteRecoveryTargetHandler.java", "diffHunk": "@@ -261,7 +266,7 @@ public void tryAction(ActionListener<T> listener) {\n \n             @Override\n             public boolean shouldRetry(Exception e) {\n-                return retriesSupported && retryableException(e);\n+                return retriesSupported && clusterService.state().nodes().nodeExists(targetNode) && retryableException(e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDY0NTUxMA=="}, "originalCommit": {"oid": "26ef3d17ad253120ef3038b32d6d7af7a0d2698d"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTMzMTQ5MA==", "bodyText": "Alright, handled this via a cluster state listener instead of observer now, that looked a little simpler and more efficient to implement than an observer here. Let me know what you think :)", "url": "https://github.com/elastic/elasticsearch/pull/57608#discussion_r435331490", "createdAt": "2020-06-04T15:06:27Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/indices/recovery/RemoteRecoveryTargetHandler.java", "diffHunk": "@@ -261,7 +266,7 @@ public void tryAction(ActionListener<T> listener) {\n \n             @Override\n             public boolean shouldRetry(Exception e) {\n-                return retriesSupported && retryableException(e);\n+                return retriesSupported && clusterService.state().nodes().nodeExists(targetNode) && retryableException(e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDY0NTUxMA=="}, "originalCommit": {"oid": "26ef3d17ad253120ef3038b32d6d7af7a0d2698d"}, "originalPosition": 51}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3652, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}