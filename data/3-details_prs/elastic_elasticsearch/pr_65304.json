{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI0NTY3MjMz", "number": 65304, "title": "[Transform] Implement latest function for Transform", "bodyText": "Latest doc function is supposed to answer the question: What is the latest document among all the documents having certain unique key.\nThis PR implements latest doc function that works in both batch and continuous mode.\nRelates #65869", "createdAt": "2020-11-20T09:20:46Z", "url": "https://github.com/elastic/elasticsearch/pull/65304", "merged": true, "mergeCommit": {"oid": "d3aef910c14fbf4a8b54ebc01641ebf3feb6476d"}, "closed": true, "closedAt": "2020-12-08T12:16:53Z", "author": {"login": "przemekwitek"}, "timelineItems": {"totalCount": 43, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdeUPRqgBqjQwMjAwNTkzMzE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdkIZkwgH2gAyNTI0NTY3MjMzOmFiYWYyYmY3M2M0OGVjNmZkZTAyYThmMTZkMmUwZjc3YjU2ZmNiYzM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "31e9896b26cb90a7c72fd8db3a2b3acab75e01bc", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/31e9896b26cb90a7c72fd8db3a2b3acab75e01bc", "committedDate": "2020-11-19T13:12:37Z", "message": "Implement latest_doc function"}, "afterCommit": {"oid": "8f9c85b88863433ed3be46f07d88467217f73ac4", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/8f9c85b88863433ed3be46f07d88467217f73ac4", "committedDate": "2020-11-20T09:49:36Z", "message": "Implement latest_doc function"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8f9c85b88863433ed3be46f07d88467217f73ac4", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/8f9c85b88863433ed3be46f07d88467217f73ac4", "committedDate": "2020-11-20T09:49:36Z", "message": "Implement latest_doc function"}, "afterCommit": {"oid": "cf53f8dd50db46098735b7fcac5f3641a3833325", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/cf53f8dd50db46098735b7fcac5f3641a3833325", "committedDate": "2020-11-23T09:32:31Z", "message": "Implement latest_doc function"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "cf53f8dd50db46098735b7fcac5f3641a3833325", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/cf53f8dd50db46098735b7fcac5f3641a3833325", "committedDate": "2020-11-23T09:32:31Z", "message": "Implement latest_doc function"}, "afterCommit": {"oid": "62b199c877200b6314546062a3465504259b924b", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/62b199c877200b6314546062a3465504259b924b", "committedDate": "2020-11-23T10:42:41Z", "message": "Implement latest_doc function"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "62b199c877200b6314546062a3465504259b924b", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/62b199c877200b6314546062a3465504259b924b", "committedDate": "2020-11-23T10:42:41Z", "message": "Implement latest_doc function"}, "afterCommit": {"oid": "d9af463d07140982911f4928cf7386ba3b628fb3", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/d9af463d07140982911f4928cf7386ba3b628fb3", "committedDate": "2020-11-23T11:53:02Z", "message": "Implement latest_doc function"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d9af463d07140982911f4928cf7386ba3b628fb3", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/d9af463d07140982911f4928cf7386ba3b628fb3", "committedDate": "2020-11-23T11:53:02Z", "message": "Implement latest_doc function"}, "afterCommit": {"oid": "c382ab404d769fc7c07a545e9b24b44b500a28f2", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/c382ab404d769fc7c07a545e9b24b44b500a28f2", "committedDate": "2020-11-23T13:01:12Z", "message": "Implement latest_doc function"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c382ab404d769fc7c07a545e9b24b44b500a28f2", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/c382ab404d769fc7c07a545e9b24b44b500a28f2", "committedDate": "2020-11-23T13:01:12Z", "message": "Implement latest_doc function"}, "afterCommit": {"oid": "f67ca63c4f2688fcdbf7659ab89dd0ce7151e9da", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/f67ca63c4f2688fcdbf7659ab89dd0ce7151e9da", "committedDate": "2020-11-23T14:49:06Z", "message": "Implement latest_doc function"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f67ca63c4f2688fcdbf7659ab89dd0ce7151e9da", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/f67ca63c4f2688fcdbf7659ab89dd0ce7151e9da", "committedDate": "2020-11-23T14:49:06Z", "message": "Implement latest_doc function"}, "afterCommit": {"oid": "e3086b31d6cbf353d3e74029fd29bd739f4e028e", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/e3086b31d6cbf353d3e74029fd29bd739f4e028e", "committedDate": "2020-11-25T06:28:20Z", "message": "Implement latest_doc function"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e3086b31d6cbf353d3e74029fd29bd739f4e028e", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/e3086b31d6cbf353d3e74029fd29bd739f4e028e", "committedDate": "2020-11-25T06:28:20Z", "message": "Implement latest_doc function"}, "afterCommit": {"oid": "aa8c507441a4ddaa7f642b1e04d3b58d7de6d2b0", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/aa8c507441a4ddaa7f642b1e04d3b58d7de6d2b0", "committedDate": "2020-11-25T07:15:12Z", "message": "Implement latest_doc function"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "aa8c507441a4ddaa7f642b1e04d3b58d7de6d2b0", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/aa8c507441a4ddaa7f642b1e04d3b58d7de6d2b0", "committedDate": "2020-11-25T07:15:12Z", "message": "Implement latest_doc function"}, "afterCommit": {"oid": "31610548bd30cb1b0edd44218a265499f5ad516a", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/31610548bd30cb1b0edd44218a265499f5ad516a", "committedDate": "2020-11-25T07:38:05Z", "message": "Implement latest function"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "31610548bd30cb1b0edd44218a265499f5ad516a", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/31610548bd30cb1b0edd44218a265499f5ad516a", "committedDate": "2020-11-25T07:38:05Z", "message": "Implement latest function"}, "afterCommit": {"oid": "c2ce81641a8e85f4cd6c18141b468e97ade642c3", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/c2ce81641a8e85f4cd6c18141b468e97ade642c3", "committedDate": "2020-11-25T08:48:37Z", "message": "Implement latest function"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c2ce81641a8e85f4cd6c18141b468e97ade642c3", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/c2ce81641a8e85f4cd6c18141b468e97ade642c3", "committedDate": "2020-11-25T08:48:37Z", "message": "Implement latest function"}, "afterCommit": {"oid": "57d8fe809c3d269a0addeae272bb1fe972c464f5", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/57d8fe809c3d269a0addeae272bb1fe972c464f5", "committedDate": "2020-11-25T08:58:56Z", "message": "Implement latest function"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "57d8fe809c3d269a0addeae272bb1fe972c464f5", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/57d8fe809c3d269a0addeae272bb1fe972c464f5", "committedDate": "2020-11-25T08:58:56Z", "message": "Implement latest function"}, "afterCommit": {"oid": "8285d15abaa4bd5e014013557bb02a1ca6de2af3", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/8285d15abaa4bd5e014013557bb02a1ca6de2af3", "committedDate": "2020-11-25T13:35:21Z", "message": "Implement latest function"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8285d15abaa4bd5e014013557bb02a1ca6de2af3", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/8285d15abaa4bd5e014013557bb02a1ca6de2af3", "committedDate": "2020-11-25T13:35:21Z", "message": "Implement latest function"}, "afterCommit": {"oid": "2a7ce85fafe7a471c486d9328b05c32390e1e744", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/2a7ce85fafe7a471c486d9328b05c32390e1e744", "committedDate": "2020-11-25T13:54:53Z", "message": "Implement latest function"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2a7ce85fafe7a471c486d9328b05c32390e1e744", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/2a7ce85fafe7a471c486d9328b05c32390e1e744", "committedDate": "2020-11-25T13:54:53Z", "message": "Implement latest function"}, "afterCommit": {"oid": "bc4727dda72be041ef0830b0e69aa06a47c16aea", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/bc4727dda72be041ef0830b0e69aa06a47c16aea", "committedDate": "2020-11-25T14:26:53Z", "message": "Implement latest function"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "bc4727dda72be041ef0830b0e69aa06a47c16aea", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/bc4727dda72be041ef0830b0e69aa06a47c16aea", "committedDate": "2020-11-25T14:26:53Z", "message": "Implement latest function"}, "afterCommit": {"oid": "588b2f0ebc45876725b472d121c39395e96c6895", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/588b2f0ebc45876725b472d121c39395e96c6895", "committedDate": "2020-11-26T07:12:22Z", "message": "Implement latest function"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "588b2f0ebc45876725b472d121c39395e96c6895", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/588b2f0ebc45876725b472d121c39395e96c6895", "committedDate": "2020-11-26T07:12:22Z", "message": "Implement latest function"}, "afterCommit": {"oid": "1022c4ee85ddc4afb1f0720d14c69a671c050cce", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/1022c4ee85ddc4afb1f0720d14c69a671c050cce", "committedDate": "2020-11-26T07:14:06Z", "message": "Implement latest function"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "1022c4ee85ddc4afb1f0720d14c69a671c050cce", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/1022c4ee85ddc4afb1f0720d14c69a671c050cce", "committedDate": "2020-11-26T07:14:06Z", "message": "Implement latest function"}, "afterCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/bc74f3eee61e1a8291143034da04a8256eb6a297", "committedDate": "2020-11-26T07:23:24Z", "message": "Implement latest function"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM5MTM3NjUz", "url": "https://github.com/elastic/elasticsearch/pull/65304#pullrequestreview-539137653", "createdAt": "2020-11-26T09:30:45Z", "commit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwOTozMDo0NVrOH6S4hw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQxMDoyMzo0OFrOH6VBrA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDg4ODgzOQ==", "bodyText": "pivot and latest should be mutually exclusive.\nI think in the client we can check and throw in the constructor.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r530888839", "createdAt": "2020-11-26T09:30:45Z", "author": {"login": "hendrikmuhs"}, "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/transform/transforms/TransformConfig.java", "diffHunk": "@@ -162,6 +184,7 @@ public static TransformConfig forPreview(final SourceConfig source, final PivotC\n         this.frequency = frequency;\n         this.syncConfig = syncConfig;\n         this.pivotConfig = pivotConfig;\n+        this.latestDocConfig = latestDocConfig;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDg5NDgxNQ==", "bodyText": "we haven't decided yet, what we do with missing_bucket. We should bring that up in the design discussion again.\nDefault terms that have no value are omitted, with missing_bucket: true they are returned as null value.\nI wonder if this should be:\n\na per field setting\na setting for all fields together\nnot have a setting but internally default to true\n\nI rule out the option to not have a setting but internally default to false as this seems strange to me.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r530894815", "createdAt": "2020-11-26T09:39:42Z", "author": {"login": "hendrikmuhs"}, "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.client.transform.transforms.latest;\n+\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+/**\n+ * Class describing how to compute latest doc for every unique key\n+ */\n+public class LatestDocConfig implements ToXContentObject {\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");\n+\n+    private final List<String> uniqueKey;\n+    private final List<SortBuilder<?>> sort;\n+\n+    @SuppressWarnings(\"unchecked\")\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> PARSER =\n+        new ConstructingObjectParser<>(\n+            \"latest_doc_config\", true, args -> new LatestDocConfig((List<String>) args[0], (List<SortBuilder<?>>) args[1]));\n+\n+    static {\n+        PARSER.declareStringArray(constructorArg(), UNIQUE_KEY);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDkwMzkwMg==", "bodyText": "do we support all options? This seems problematic for continuous. Maybe we should start simple and only allow strings? I think however it is a good idea to internally use List<SortBuilder<?>>. If you look at TopHitsAggregationBuilder it contains convenience methods that take a string build the SortBuilder internally. I think that would be good.\nLet's maybe revisit after you have a 1st implementation for continuous and after we know what is possible or not. Maybe its better to reduce the number options.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r530903902", "createdAt": "2020-11-26T09:53:18Z", "author": {"login": "hendrikmuhs"}, "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.client.transform.transforms.latest;\n+\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+/**\n+ * Class describing how to compute latest doc for every unique key\n+ */\n+public class LatestDocConfig implements ToXContentObject {\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");\n+\n+    private final List<String> uniqueKey;\n+    private final List<SortBuilder<?>> sort;\n+\n+    @SuppressWarnings(\"unchecked\")\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> PARSER =\n+        new ConstructingObjectParser<>(\n+            \"latest_doc_config\", true, args -> new LatestDocConfig((List<String>) args[0], (List<SortBuilder<?>>) args[1]));\n+\n+    static {\n+        PARSER.declareStringArray(constructorArg(), UNIQUE_KEY);\n+        PARSER.declareField(constructorArg(), (p, c) -> SortBuilder.fromXContent(p), SORT, ObjectParser.ValueType.OBJECT_ARRAY_OR_STRING);\n+    }\n+\n+    public static LatestDocConfig fromXContent(final XContentParser parser) {\n+        return PARSER.apply(parser, null);\n+    }\n+\n+    LatestDocConfig(List<String> uniqueKey, List<SortBuilder<?>> sort) {\n+        this.uniqueKey = uniqueKey;\n+        this.sort = sort;\n+    }\n+\n+    @Override\n+    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n+        builder.startObject();\n+        builder.field(UNIQUE_KEY.getPreferredName(), uniqueKey);\n+        builder.field(SORT.getPreferredName(), sort);\n+        builder.endObject();\n+        return builder;\n+    }\n+\n+    public List<String> getUniqueKey() {\n+        return uniqueKey;\n+    }\n+\n+    public List<SortBuilder<?>> getSort() {\n+        return sort;\n+    }\n+\n+    @Override\n+    public boolean equals(Object other) {\n+        if (this == other) {\n+            return true;\n+        }\n+        if (other == null || getClass() != other.getClass()) {\n+            return false;\n+        }\n+        LatestDocConfig that = (LatestDocConfig) other;\n+        return Objects.equals(this.uniqueKey, that.uniqueKey) && Objects.equals(this.sort, that.sort);\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return Objects.hash(uniqueKey, sort);\n+    }\n+\n+    public static Builder builder() {\n+        return new Builder();\n+    }\n+\n+    public static class Builder {\n+        private List<String> uniqueKey;\n+        private List<SortBuilder<?>> sort;\n+\n+        /**\n+         * Set how to group the source data\n+         * @param uniqueKey The configuration describing how to group the source data\n+         * @return the {@link Builder} with the interval set.\n+         */\n+        public Builder setUniqueKey(String... uniqueKey) {\n+            return setUniqueKey(Arrays.asList(uniqueKey));\n+        }\n+\n+        public Builder setUniqueKey(List<String> uniqueKey) {\n+            this.uniqueKey = uniqueKey;\n+            return this;\n+        }\n+\n+        public Builder setSort(FieldSortBuilder sort) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 125}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDkwNTQxMA==", "bodyText": "a test for expectThrows if both are given, to test mutual exclusiveness", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r530905410", "createdAt": "2020-11-26T09:55:25Z", "author": {"login": "hendrikmuhs"}, "path": "client/rest-high-level/src/test/java/org/elasticsearch/client/transform/transforms/TransformConfigTests.java", "diffHunk": "@@ -41,13 +44,23 @@\n public class TransformConfigTests extends AbstractXContentTestCase<TransformConfig> {\n \n     public static TransformConfig randomTransformConfig() {\n+        PivotConfig pivotConfig;\n+        LatestDocConfig latestDocConfig;\n+        if (randomBoolean()) {\n+            pivotConfig = PivotConfigTests.randomPivotConfig();\n+            latestDocConfig = null;\n+        } else {\n+            pivotConfig = null;\n+            latestDocConfig = LatestDocConfigTests.randomLatestDocConfig();\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDkwOTExOQ==", "bodyText": "same remark: we need to sort out what we do with missing_bucket", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r530909119", "createdAt": "2020-11-26T10:00:44Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core.transform.transforms.latest;\n+\n+import org.elasticsearch.action.ActionRequestValidationException;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+import org.elasticsearch.xpack.core.transform.utils.ExceptionsHelper;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+public class LatestDocConfig implements Writeable, ToXContentObject {\n+\n+    private static final String NAME = \"transform_latest_doc\";\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDkxMTAzMQ==", "bodyText": "there are also test classes for hlrc <-> server and back in the hlrc sub package. Every new class should implement this, although we haven't reached full coverage yet. Adding support for latest should be easy.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r530911031", "createdAt": "2020-11-26T10:03:41Z", "author": {"login": "hendrikmuhs"}, "path": "client/rest-high-level/src/test/java/org/elasticsearch/client/transform/transforms/latest/LatestDocConfigTests.java", "diffHunk": "@@ -0,0 +1,58 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.client.transform.transforms.latest;\n+\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.sort.SortBuilders;\n+import org.elasticsearch.test.AbstractXContentTestCase;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.function.Predicate;\n+\n+public class LatestDocConfigTests extends AbstractXContentTestCase<LatestDocConfig> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDkxNDUwNg==", "bodyText": "do we have an idea about this default? I agree that we should have a higher default than pivot.\nshould make this a constant which can be overridden with config.getMaxPageSearchSize()", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r530914506", "createdAt": "2020-11-26T10:09:07Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "diffHunk": "@@ -0,0 +1,276 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.latest;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesAction;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesRequest;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.search.SearchAction;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.query.BoolQueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.search.aggregations.Aggregation;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.Aggregations;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.metrics.TopHits;\n+import org.elasticsearch.search.aggregations.metrics.TopHitsAggregationBuilder;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.transform.TransformMessages;\n+import org.elasticsearch.xpack.core.transform.transforms.SourceConfig;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformIndexerStats;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformProgress;\n+import org.elasticsearch.xpack.core.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.xpack.transform.transforms.Function;\n+import org.elasticsearch.xpack.transform.transforms.pivot.SchemaUtil;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.function.Predicate.not;\n+import static java.util.stream.Collectors.toMap;\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class LatestDoc implements Function {\n+\n+    public static final int TEST_QUERY_PAGE_SIZE = 50;\n+\n+    private static final String COMPOSITE_AGGREGATION_NAME = \"_transform\";\n+    private static final String LATEST_AGGREGATION_NAME = \"_latest\";\n+    private static final Logger logger = LogManager.getLogger(LatestDoc.class);\n+\n+    private final LatestDocConfig config;\n+\n+    // objects for re-using\n+    private final CompositeAggregationBuilder cachedCompositeAggregation;\n+\n+    public LatestDoc(LatestDocConfig config) {\n+        if (config.getSort().size() != 1) {\n+            throw new ElasticsearchException(\"sort must specify exactly one sorting field\");\n+        }\n+        this.config = config;\n+        this.cachedCompositeAggregation = createCompositeAggregation(config);\n+    }\n+\n+    private static CompositeAggregationBuilder createCompositeAggregation(LatestDocConfig config) {\n+        assert config.getSort().size() >= 1 && config.getSort().get(0) instanceof FieldSortBuilder;\n+\n+        CompositeAggregationBuilder compositeAggregation;\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            config.toCompositeAggXContent(builder);\n+            XContentParser parser = builder.generator()\n+                .contentType()\n+                .xContent()\n+                .createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, BytesReference.bytes(builder).streamInput());\n+            compositeAggregation = CompositeAggregationBuilder.PARSER.parse(parser, COMPOSITE_AGGREGATION_NAME);\n+        } catch (IOException e) {\n+            throw new RuntimeException(\n+                TransformMessages.getMessage(TransformMessages.TRANSFORM_FAILED_TO_CREATE_COMPOSITE_AGGREGATION, \"latest_doc\"), e);\n+        }\n+        TopHitsAggregationBuilder topHitsAgg = AggregationBuilders.topHits(LATEST_AGGREGATION_NAME).size(1).sort(config.getSort().get(0));\n+        compositeAggregation.subAggregation(topHitsAgg);\n+        return compositeAggregation;\n+    }\n+\n+    @Override\n+    public int getInitialPageSize() {\n+        return 5000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDkyMzk0OA==", "bodyText": "this is used for latest? In this case we should think about moving SchemaUtil out of the pivot package.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r530923948", "createdAt": "2020-11-26T10:23:48Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/pivot/SchemaUtil.java", "diffHunk": "@@ -265,7 +265,7 @@ private static void getSourceFieldMappings(\n         );\n     }\n \n-    private static Map<String, String> extractFieldMappings(FieldCapabilitiesResponse response) {\n+    public static Map<String, String> extractFieldMappings(FieldCapabilitiesResponse response) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 5}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/bc74f3eee61e1a8291143034da04a8256eb6a297", "committedDate": "2020-11-26T07:23:24Z", "message": "Implement latest function"}, "afterCommit": {"oid": "e288a71e2175f930287b62e1cdaf7ff6ddc12bb2", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/e288a71e2175f930287b62e1cdaf7ff6ddc12bb2", "committedDate": "2020-12-01T09:51:38Z", "message": "Implement change collector for latest function"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9878e96958df434bee68df5b6a5b96ac92394f41", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/9878e96958df434bee68df5b6a5b96ac92394f41", "committedDate": "2020-12-01T14:50:52Z", "message": "Apply review comments"}, "afterCommit": {"oid": "a45fbd2358b8b493f323b446a2ff9e56ce2c0c55", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/a45fbd2358b8b493f323b446a2ff9e56ce2c0c55", "committedDate": "2020-12-02T07:47:14Z", "message": "Verify optimization in LatestDocContinuousIT"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3d3fb2099e3b9f73832d06f3f8d1a45a9e46d7b4", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/3d3fb2099e3b9f73832d06f3f8d1a45a9e46d7b4", "committedDate": "2020-12-02T09:19:32Z", "message": "Add validations with unit tests"}, "afterCommit": {"oid": "87f900d8d94a4be35af6fb91a24b8086f14b44fa", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/87f900d8d94a4be35af6fb91a24b8086f14b44fa", "committedDate": "2020-12-02T11:10:07Z", "message": "Add validations with unit tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyNzgyNTE2", "url": "https://github.com/elastic/elasticsearch/pull/65304#pullrequestreview-542782516", "createdAt": "2020-12-02T12:23:45Z", "commit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxMjoyMzo0NlrOH9Ye6A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxMjo0MDowMlrOH9ZD5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEyNjMxMg==", "bodyText": "I agree, the validation should be backend only. Especially since the validation would run against a GET and the HLRC needs to be forwards compatible.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534126312", "createdAt": "2020-12-02T12:23:46Z", "author": {"login": "benwtrent"}, "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/transform/transforms/TransformConfig.java", "diffHunk": "@@ -162,6 +184,7 @@ public static TransformConfig forPreview(final SourceConfig source, final PivotC\n         this.frequency = frequency;\n         this.syncConfig = syncConfig;\n         this.pivotConfig = pivotConfig;\n+        this.latestDocConfig = latestDocConfig;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDg4ODgzOQ=="}, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEyNzg3MA==", "bodyText": "TRANSFORM_CONFIGURATION_NO_TRANSFORM could you rename this message constant? I know the message is probably OK (since it says \"exactly 1\") but the constant name implies something else.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534127870", "createdAt": "2020-12-02T12:26:25Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/TransformConfig.java", "diffHunk": "@@ -176,11 +183,12 @@ public static String documentId(String transformId) {\n         this.syncConfig = syncConfig;\n         this.setHeaders(headers == null ? Collections.emptyMap() : headers);\n         this.pivotConfig = pivotConfig;\n+        this.latestDocConfig = latestDocConfig;\n         this.description = description;\n         this.settings = settings == null ? new SettingsConfig() : settings;\n \n-        // at least one function must be defined\n-        if (this.pivotConfig == null) {\n+        // exactly one function must be defined\n+        if ((this.pivotConfig == null) == (this.latestDocConfig == null)) {\n             throw new IllegalArgumentException(TransformMessages.TRANSFORM_CONFIGURATION_NO_TRANSFORM);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEyOTM0OA==", "bodyText": "Is there a chance that an API caller would see this?\nIf so, we definitely need to adjust this from FieldSortBuilder to something API friendly.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534129348", "createdAt": "2020-12-02T12:28:54Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core.transform.transforms.latest;\n+\n+import org.elasticsearch.action.ActionRequestValidationException;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.bucket.terms.TermsAggregationBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+import org.elasticsearch.xpack.core.transform.utils.ExceptionsHelper;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.action.ValidateActions.addValidationError;\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+public class LatestDocConfig implements Writeable, ToXContentObject {\n+\n+    private static final String NAME = \"transform_latest_doc\";\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");\n+\n+    private final List<String> uniqueKey;\n+    private final List<SortBuilder<?>> sort;\n+\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> STRICT_PARSER = createParser(false);\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> LENIENT_PARSER = createParser(true);\n+\n+    private static ConstructingObjectParser<LatestDocConfig, Void> createParser(boolean lenient) {\n+        ConstructingObjectParser<LatestDocConfig, Void> parser =\n+            new ConstructingObjectParser<>(\n+                NAME, lenient, args -> new LatestDocConfig((List<String>) args[0], (List<SortBuilder<?>>) args[1]));\n+\n+        parser.declareStringArray(constructorArg(), UNIQUE_KEY);\n+        parser.declareField(constructorArg(), (p, c) -> SortBuilder.fromXContent(p), SORT, ObjectParser.ValueType.OBJECT_ARRAY_OR_STRING);\n+\n+        return parser;\n+    }\n+\n+    public static LatestDocConfig fromXContent(final XContentParser parser, boolean lenient) throws IOException {\n+        return lenient ? LENIENT_PARSER.apply(parser, null) : STRICT_PARSER.apply(parser, null);\n+    }\n+\n+    public LatestDocConfig(List<String> uniqueKey, List<SortBuilder<?>> sort) {\n+        this.uniqueKey = ExceptionsHelper.requireNonNull(uniqueKey, UNIQUE_KEY.getPreferredName());\n+        this.sort = ExceptionsHelper.requireNonNull(sort, SORT.getPreferredName());\n+    }\n+\n+    public LatestDocConfig(StreamInput in) throws IOException {\n+        this.uniqueKey = in.readStringList();\n+        this.sort = in.readList(FieldSortBuilder::new);\n+    }\n+\n+    public List<String> getUniqueKey() {\n+        return uniqueKey;\n+    }\n+\n+    public List<SortBuilder<?>> getSort() {\n+        return sort;\n+    }\n+\n+    public ActionRequestValidationException validate(ActionRequestValidationException validationException) {\n+        if (uniqueKey.isEmpty()) {\n+            validationException = addValidationError(\"latest_doc.unique_key must be non-empty\", validationException);\n+        } else {\n+            for (int i = 0; i < uniqueKey.size(); ++i) {\n+                if (Strings.isNullOrEmpty(uniqueKey.get(i))) {\n+                    validationException =\n+                        addValidationError(\"latest_doc.unique_key[\" + i + \"] element must be non-empty\", validationException);\n+                }\n+            }\n+        }\n+\n+        if (sort.size() != 1) {\n+            validationException = addValidationError(\"latest_doc.sort must have exactly one element\", validationException);\n+        } else {\n+            SortBuilder<?> theOnlySort = sort.get(0);\n+            if (theOnlySort instanceof FieldSortBuilder == false) {\n+                validationException =\n+                    addValidationError(\n+                        \"latest_doc.sort[0] must be of type FieldSortBuilder, was: \" + theOnlySort.getClass().getSimpleName(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzMTM0Ng==", "bodyText": "I am not 100% sure about this. Is it valid for a user to have their OWN field that starts with _?", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534131346", "createdAt": "2020-12-02T12:32:16Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/common/DocumentConversionUtils.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.common;\n+\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Map;\n+\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class DocumentConversionUtils {\n+\n+    public static IndexRequest convertDocumentToIndexRequest(Map<String, Object> document,\n+                                                             String destinationIndex,\n+                                                             String destinationPipeline) {\n+        String id = (String) document.get(TransformField.DOCUMENT_ID_FIELD);\n+        if (id == null) {\n+            throw new RuntimeException(\"Expected a document id but got null.\");\n+        }\n+\n+        XContentBuilder builder = skipInternalFields(document);\n+        IndexRequest request = new IndexRequest(destinationIndex).source(builder).id(id);\n+        if (destinationPipeline != null) {\n+            request.setPipeline(destinationPipeline);\n+        }\n+        return request;\n+    }\n+\n+    private static XContentBuilder skipInternalFields(Map<String, Object> document) {\n+        XContentBuilder builder;\n+        try {\n+            builder = jsonBuilder();\n+            builder.startObject();\n+            for (Map.Entry<String, ?> value : document.entrySet()) {\n+                // skip all internal fields\n+                if (value.getKey().startsWith(\"_\") == false) {\n+                    builder.field(value.getKey(), value.getValue());\n+                }\n+            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzMjI5NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    logger.trace(\"Search request: {}\", searchRequest);\n          \n          \n            \n                    logger.trace(() -> new ParameterizedMessage(\"Search request: {}\", searchRequest));", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534132295", "createdAt": "2020-12-02T12:34:00Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.latest;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesAction;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesRequest;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.search.SearchAction;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.query.BoolQueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.Aggregations;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.metrics.TopHits;\n+import org.elasticsearch.search.aggregations.metrics.TopHitsAggregationBuilder;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+import org.elasticsearch.xpack.core.transform.TransformMessages;\n+import org.elasticsearch.xpack.core.transform.transforms.SourceConfig;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformIndexerStats;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformProgress;\n+import org.elasticsearch.xpack.core.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.xpack.transform.transforms.Function;\n+import org.elasticsearch.xpack.transform.transforms.IDGenerator;\n+import org.elasticsearch.xpack.transform.transforms.pivot.SchemaUtil;\n+import org.elasticsearch.xpack.transform.transforms.common.DocumentConversionUtils;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.function.Predicate.not;\n+import static java.util.stream.Collectors.toMap;\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class LatestDoc implements Function {\n+\n+    public static final int DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE = 5000;\n+    public static final int TEST_QUERY_PAGE_SIZE = 50;\n+\n+    private static final String COMPOSITE_AGGREGATION_NAME = \"_transform\";\n+    private static final String TOP_HITS_AGGREGATION_NAME = \"_top_hits\";\n+    private static final Logger logger = LogManager.getLogger(LatestDoc.class);\n+\n+    private final LatestDocConfig config;\n+\n+    // objects for re-using\n+    private final CompositeAggregationBuilder cachedCompositeAggregation;\n+\n+    public LatestDoc(LatestDocConfig config) {\n+        this.config = config;\n+        this.cachedCompositeAggregation = createCompositeAggregation(config);\n+    }\n+\n+    private static CompositeAggregationBuilder createCompositeAggregation(LatestDocConfig config) {\n+        assert config.getSort().size() == 1 && config.getSort().get(0) instanceof FieldSortBuilder;\n+\n+        CompositeAggregationBuilder compositeAggregation;\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            config.toCompositeAggXContent(builder);\n+            XContentParser parser = builder.generator()\n+                .contentType()\n+                .xContent()\n+                .createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, BytesReference.bytes(builder).streamInput());\n+            compositeAggregation = CompositeAggregationBuilder.PARSER.parse(parser, COMPOSITE_AGGREGATION_NAME);\n+        } catch (IOException e) {\n+            throw new RuntimeException(\n+                TransformMessages.getMessage(TransformMessages.TRANSFORM_FAILED_TO_CREATE_COMPOSITE_AGGREGATION, \"latest_doc\"), e);\n+        }\n+        TopHitsAggregationBuilder topHitsAgg =\n+            AggregationBuilders.topHits(TOP_HITS_AGGREGATION_NAME)\n+                .size(1)  // we are only interested in the top-1\n+                .sorts(config.getSort());  // we copy the sort config directly from the function config\n+        compositeAggregation.subAggregation(topHitsAgg);\n+        return compositeAggregation;\n+    }\n+\n+    @Override\n+    public int getInitialPageSize() {\n+        return DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE;\n+    }\n+\n+    private SearchRequest buildSearchRequest(SourceConfig sourceConfig, Map<String, Object> position, int pageSize) {\n+        SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();\n+        buildSearchQuery(sourceBuilder, null, pageSize);\n+        sourceBuilder.query(sourceConfig.getQueryConfig().getQuery());\n+        SearchRequest searchRequest =\n+            new SearchRequest(sourceConfig.getIndex())\n+                .source(sourceBuilder)\n+                .indicesOptions(IndicesOptions.LENIENT_EXPAND_OPEN);\n+        logger.trace(\"Search request: {}\", searchRequest);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzMzYyMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                    \"Unexpected status from response of test query: \" + response.status(),\n          \n          \n            \n                                    response.status()\n          \n          \n            \n                                    \"Unexpected status from response of test query: {}\",\n          \n          \n            \n                                    response.status(),\n          \n          \n            \n                                    response.status()\n          \n      \n    \n    \n  \n\nDoesn't this work?", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534133622", "createdAt": "2020-12-02T12:36:14Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.latest;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesAction;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesRequest;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.search.SearchAction;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.query.BoolQueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.Aggregations;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.metrics.TopHits;\n+import org.elasticsearch.search.aggregations.metrics.TopHitsAggregationBuilder;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+import org.elasticsearch.xpack.core.transform.TransformMessages;\n+import org.elasticsearch.xpack.core.transform.transforms.SourceConfig;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformIndexerStats;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformProgress;\n+import org.elasticsearch.xpack.core.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.xpack.transform.transforms.Function;\n+import org.elasticsearch.xpack.transform.transforms.IDGenerator;\n+import org.elasticsearch.xpack.transform.transforms.pivot.SchemaUtil;\n+import org.elasticsearch.xpack.transform.transforms.common.DocumentConversionUtils;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.function.Predicate.not;\n+import static java.util.stream.Collectors.toMap;\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class LatestDoc implements Function {\n+\n+    public static final int DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE = 5000;\n+    public static final int TEST_QUERY_PAGE_SIZE = 50;\n+\n+    private static final String COMPOSITE_AGGREGATION_NAME = \"_transform\";\n+    private static final String TOP_HITS_AGGREGATION_NAME = \"_top_hits\";\n+    private static final Logger logger = LogManager.getLogger(LatestDoc.class);\n+\n+    private final LatestDocConfig config;\n+\n+    // objects for re-using\n+    private final CompositeAggregationBuilder cachedCompositeAggregation;\n+\n+    public LatestDoc(LatestDocConfig config) {\n+        this.config = config;\n+        this.cachedCompositeAggregation = createCompositeAggregation(config);\n+    }\n+\n+    private static CompositeAggregationBuilder createCompositeAggregation(LatestDocConfig config) {\n+        assert config.getSort().size() == 1 && config.getSort().get(0) instanceof FieldSortBuilder;\n+\n+        CompositeAggregationBuilder compositeAggregation;\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            config.toCompositeAggXContent(builder);\n+            XContentParser parser = builder.generator()\n+                .contentType()\n+                .xContent()\n+                .createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, BytesReference.bytes(builder).streamInput());\n+            compositeAggregation = CompositeAggregationBuilder.PARSER.parse(parser, COMPOSITE_AGGREGATION_NAME);\n+        } catch (IOException e) {\n+            throw new RuntimeException(\n+                TransformMessages.getMessage(TransformMessages.TRANSFORM_FAILED_TO_CREATE_COMPOSITE_AGGREGATION, \"latest_doc\"), e);\n+        }\n+        TopHitsAggregationBuilder topHitsAgg =\n+            AggregationBuilders.topHits(TOP_HITS_AGGREGATION_NAME)\n+                .size(1)  // we are only interested in the top-1\n+                .sorts(config.getSort());  // we copy the sort config directly from the function config\n+        compositeAggregation.subAggregation(topHitsAgg);\n+        return compositeAggregation;\n+    }\n+\n+    @Override\n+    public int getInitialPageSize() {\n+        return DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE;\n+    }\n+\n+    private SearchRequest buildSearchRequest(SourceConfig sourceConfig, Map<String, Object> position, int pageSize) {\n+        SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();\n+        buildSearchQuery(sourceBuilder, null, pageSize);\n+        sourceBuilder.query(sourceConfig.getQueryConfig().getQuery());\n+        SearchRequest searchRequest =\n+            new SearchRequest(sourceConfig.getIndex())\n+                .source(sourceBuilder)\n+                .indicesOptions(IndicesOptions.LENIENT_EXPAND_OPEN);\n+        logger.trace(\"Search request: {}\", searchRequest);\n+        return searchRequest;\n+    }\n+\n+    @Override\n+    public SearchSourceBuilder buildSearchQuery(SearchSourceBuilder builder, Map<String, Object> position, int pageSize) {\n+        cachedCompositeAggregation.aggregateAfter(position);\n+        cachedCompositeAggregation.size(pageSize);\n+        return builder.size(0).aggregation(cachedCompositeAggregation);\n+    }\n+\n+    @Override\n+    public ChangeCollector buildChangeCollector(String synchronizationField) {\n+        return new LatestDocChangeCollector(synchronizationField);\n+    }\n+\n+    private Stream<Map<String, Object>> extractResults(CompositeAggregation compositeAgg, TransformIndexerStats transformIndexerStats) {\n+        return compositeAgg.getBuckets().stream()\n+            .map(bucket -> {\n+                transformIndexerStats.incrementNumDocuments(bucket.getDocCount());\n+                TopHits topHits = bucket.getAggregations().get(TOP_HITS_AGGREGATION_NAME);\n+                assert topHits.getHits().getHits().length == 1;\n+                Map<String, Object> document = topHits.getHits().getHits()[0].getSourceAsMap();\n+\n+                // generator to create unique but deterministic document ids, so we\n+                // - do not create duplicates if we re-run after failure\n+                // - update documents\n+                IDGenerator idGen = new IDGenerator();\n+                config.getUniqueKey().forEach(field -> idGen.add(field, bucket.getKey().get(field)));\n+\n+                document.put(TransformField.DOCUMENT_ID_FIELD, idGen.getID());\n+                return document;\n+            });\n+    }\n+\n+    @Override\n+    public Tuple<Stream<IndexRequest>, Map<String, Object>> processSearchResponse(\n+        SearchResponse searchResponse,\n+        String destinationIndex,\n+        String destinationPipeline,\n+        Map<String, String> fieldTypeMap,\n+        TransformIndexerStats stats\n+    ) {\n+        Aggregations aggregations = searchResponse.getAggregations();\n+\n+        // Treat this as a \"we reached the end\".\n+        // This should only happen when all underlying indices have gone away. Consequently, there is no more data to read.\n+        if (aggregations == null) {\n+            return null;\n+        }\n+\n+        CompositeAggregation compositeAgg = aggregations.get(COMPOSITE_AGGREGATION_NAME);\n+        if (compositeAgg == null || compositeAgg.getBuckets().isEmpty()) {\n+            return null;\n+        }\n+\n+        Stream<IndexRequest> indexRequestStream =\n+            extractResults(compositeAgg, stats)\n+                .map(document -> DocumentConversionUtils.convertDocumentToIndexRequest(document, destinationIndex, destinationPipeline));\n+        return Tuple.tuple(indexRequestStream, compositeAgg.afterKey());\n+    }\n+\n+    @Override\n+    public void validateQuery(Client client, SourceConfig sourceConfig, ActionListener<Boolean> listener) {\n+        SearchRequest searchRequest = buildSearchRequest(sourceConfig, null, TEST_QUERY_PAGE_SIZE);\n+\n+        client.execute(SearchAction.INSTANCE, searchRequest, ActionListener.wrap(response -> {\n+            if (response == null) {\n+                listener.onFailure(\n+                    new ElasticsearchStatusException(\"Unexpected null response from test query\", RestStatus.SERVICE_UNAVAILABLE)\n+                );\n+                return;\n+            }\n+            if (response.status() != RestStatus.OK) {\n+                listener.onFailure(\n+                    new ElasticsearchStatusException(\n+                        \"Unexpected status from response of test query: \" + response.status(),\n+                        response.status()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 194}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzNDA4Mg==", "bodyText": "same concern as before around user defined fields that start with _", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534134082", "createdAt": "2020-12-02T12:37:06Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.latest;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesAction;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesRequest;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.search.SearchAction;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.query.BoolQueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.Aggregations;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.metrics.TopHits;\n+import org.elasticsearch.search.aggregations.metrics.TopHitsAggregationBuilder;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+import org.elasticsearch.xpack.core.transform.TransformMessages;\n+import org.elasticsearch.xpack.core.transform.transforms.SourceConfig;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformIndexerStats;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformProgress;\n+import org.elasticsearch.xpack.core.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.xpack.transform.transforms.Function;\n+import org.elasticsearch.xpack.transform.transforms.IDGenerator;\n+import org.elasticsearch.xpack.transform.transforms.pivot.SchemaUtil;\n+import org.elasticsearch.xpack.transform.transforms.common.DocumentConversionUtils;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.function.Predicate.not;\n+import static java.util.stream.Collectors.toMap;\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class LatestDoc implements Function {\n+\n+    public static final int DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE = 5000;\n+    public static final int TEST_QUERY_PAGE_SIZE = 50;\n+\n+    private static final String COMPOSITE_AGGREGATION_NAME = \"_transform\";\n+    private static final String TOP_HITS_AGGREGATION_NAME = \"_top_hits\";\n+    private static final Logger logger = LogManager.getLogger(LatestDoc.class);\n+\n+    private final LatestDocConfig config;\n+\n+    // objects for re-using\n+    private final CompositeAggregationBuilder cachedCompositeAggregation;\n+\n+    public LatestDoc(LatestDocConfig config) {\n+        this.config = config;\n+        this.cachedCompositeAggregation = createCompositeAggregation(config);\n+    }\n+\n+    private static CompositeAggregationBuilder createCompositeAggregation(LatestDocConfig config) {\n+        assert config.getSort().size() == 1 && config.getSort().get(0) instanceof FieldSortBuilder;\n+\n+        CompositeAggregationBuilder compositeAggregation;\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            config.toCompositeAggXContent(builder);\n+            XContentParser parser = builder.generator()\n+                .contentType()\n+                .xContent()\n+                .createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, BytesReference.bytes(builder).streamInput());\n+            compositeAggregation = CompositeAggregationBuilder.PARSER.parse(parser, COMPOSITE_AGGREGATION_NAME);\n+        } catch (IOException e) {\n+            throw new RuntimeException(\n+                TransformMessages.getMessage(TransformMessages.TRANSFORM_FAILED_TO_CREATE_COMPOSITE_AGGREGATION, \"latest_doc\"), e);\n+        }\n+        TopHitsAggregationBuilder topHitsAgg =\n+            AggregationBuilders.topHits(TOP_HITS_AGGREGATION_NAME)\n+                .size(1)  // we are only interested in the top-1\n+                .sorts(config.getSort());  // we copy the sort config directly from the function config\n+        compositeAggregation.subAggregation(topHitsAgg);\n+        return compositeAggregation;\n+    }\n+\n+    @Override\n+    public int getInitialPageSize() {\n+        return DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE;\n+    }\n+\n+    private SearchRequest buildSearchRequest(SourceConfig sourceConfig, Map<String, Object> position, int pageSize) {\n+        SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();\n+        buildSearchQuery(sourceBuilder, null, pageSize);\n+        sourceBuilder.query(sourceConfig.getQueryConfig().getQuery());\n+        SearchRequest searchRequest =\n+            new SearchRequest(sourceConfig.getIndex())\n+                .source(sourceBuilder)\n+                .indicesOptions(IndicesOptions.LENIENT_EXPAND_OPEN);\n+        logger.trace(\"Search request: {}\", searchRequest);\n+        return searchRequest;\n+    }\n+\n+    @Override\n+    public SearchSourceBuilder buildSearchQuery(SearchSourceBuilder builder, Map<String, Object> position, int pageSize) {\n+        cachedCompositeAggregation.aggregateAfter(position);\n+        cachedCompositeAggregation.size(pageSize);\n+        return builder.size(0).aggregation(cachedCompositeAggregation);\n+    }\n+\n+    @Override\n+    public ChangeCollector buildChangeCollector(String synchronizationField) {\n+        return new LatestDocChangeCollector(synchronizationField);\n+    }\n+\n+    private Stream<Map<String, Object>> extractResults(CompositeAggregation compositeAgg, TransformIndexerStats transformIndexerStats) {\n+        return compositeAgg.getBuckets().stream()\n+            .map(bucket -> {\n+                transformIndexerStats.incrementNumDocuments(bucket.getDocCount());\n+                TopHits topHits = bucket.getAggregations().get(TOP_HITS_AGGREGATION_NAME);\n+                assert topHits.getHits().getHits().length == 1;\n+                Map<String, Object> document = topHits.getHits().getHits()[0].getSourceAsMap();\n+\n+                // generator to create unique but deterministic document ids, so we\n+                // - do not create duplicates if we re-run after failure\n+                // - update documents\n+                IDGenerator idGen = new IDGenerator();\n+                config.getUniqueKey().forEach(field -> idGen.add(field, bucket.getKey().get(field)));\n+\n+                document.put(TransformField.DOCUMENT_ID_FIELD, idGen.getID());\n+                return document;\n+            });\n+    }\n+\n+    @Override\n+    public Tuple<Stream<IndexRequest>, Map<String, Object>> processSearchResponse(\n+        SearchResponse searchResponse,\n+        String destinationIndex,\n+        String destinationPipeline,\n+        Map<String, String> fieldTypeMap,\n+        TransformIndexerStats stats\n+    ) {\n+        Aggregations aggregations = searchResponse.getAggregations();\n+\n+        // Treat this as a \"we reached the end\".\n+        // This should only happen when all underlying indices have gone away. Consequently, there is no more data to read.\n+        if (aggregations == null) {\n+            return null;\n+        }\n+\n+        CompositeAggregation compositeAgg = aggregations.get(COMPOSITE_AGGREGATION_NAME);\n+        if (compositeAgg == null || compositeAgg.getBuckets().isEmpty()) {\n+            return null;\n+        }\n+\n+        Stream<IndexRequest> indexRequestStream =\n+            extractResults(compositeAgg, stats)\n+                .map(document -> DocumentConversionUtils.convertDocumentToIndexRequest(document, destinationIndex, destinationPipeline));\n+        return Tuple.tuple(indexRequestStream, compositeAgg.afterKey());\n+    }\n+\n+    @Override\n+    public void validateQuery(Client client, SourceConfig sourceConfig, ActionListener<Boolean> listener) {\n+        SearchRequest searchRequest = buildSearchRequest(sourceConfig, null, TEST_QUERY_PAGE_SIZE);\n+\n+        client.execute(SearchAction.INSTANCE, searchRequest, ActionListener.wrap(response -> {\n+            if (response == null) {\n+                listener.onFailure(\n+                    new ElasticsearchStatusException(\"Unexpected null response from test query\", RestStatus.SERVICE_UNAVAILABLE)\n+                );\n+                return;\n+            }\n+            if (response.status() != RestStatus.OK) {\n+                listener.onFailure(\n+                    new ElasticsearchStatusException(\n+                        \"Unexpected status from response of test query: \" + response.status(),\n+                        response.status()\n+                    )\n+                );\n+                return;\n+            }\n+            listener.onResponse(true);\n+        }, e -> {\n+            Throwable unwrapped = ExceptionsHelper.unwrapCause(e);\n+            RestStatus status = unwrapped instanceof ElasticsearchException\n+                ? ((ElasticsearchException) unwrapped).status()\n+                : RestStatus.SERVICE_UNAVAILABLE;\n+            listener.onFailure(new ElasticsearchStatusException(\"Failed to test query\", status, unwrapped));\n+        }));\n+    }\n+\n+    @Override\n+    public void validateConfig(ActionListener<Boolean> listener) {\n+        listener.onResponse(true);\n+    }\n+\n+    @Override\n+    public void deduceMappings(Client client, SourceConfig sourceConfig, ActionListener<Map<String, String>> listener) {\n+        FieldCapabilitiesRequest fieldCapabilitiesRequest =\n+            new FieldCapabilitiesRequest().indices(sourceConfig.getIndex())\n+                .fields(\"*\")\n+                .indicesOptions(IndicesOptions.LENIENT_EXPAND_OPEN);\n+        client.execute(\n+            FieldCapabilitiesAction.INSTANCE,\n+            fieldCapabilitiesRequest,\n+            ActionListener.wrap(\n+                response -> listener.onResponse(\n+                    SchemaUtil.extractFieldMappings(response).entrySet().stream()\n+                        .filter(not(e -> e.getKey().startsWith(\"_\")))\n+                        .collect(toMap(Map.Entry::getKey, Map.Entry::getValue))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 227}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzNTc4MQ==", "bodyText": "Ah, I see the pivot was already doing this. But it is still a concern. Especially since now as we are copying the doc directly.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534135781", "createdAt": "2020-12-02T12:40:02Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/pivot/Pivot.java", "diffHunk": "@@ -142,17 +136,17 @@ public void preview(\n                     final Aggregations aggregations = r.getAggregations();\n                     if (aggregations == null) {\n                         listener.onFailure(\n-                            new ElasticsearchStatusException(\"Source indices have been deleted or closed.\", RestStatus.BAD_REQUEST)\n-                        );\n+                            new ElasticsearchStatusException(\"Source indices have been deleted or closed.\", RestStatus.BAD_REQUEST));\n                         return;\n                     }\n                     final CompositeAggregation agg = aggregations.get(COMPOSITE_AGGREGATION_NAME);\n                     TransformIndexerStats stats = new TransformIndexerStats();\n-                    // remove all internal fields\n \n-                    List<Map<String, Object>> docs = extractResults(agg, fieldTypeMap, stats).peek(\n-                        doc -> doc.keySet().removeIf(k -> k.startsWith(\"_\"))\n-                    ).collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 58}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a8c6d73294f7dd581a5455214d6689e5e7758f3d", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/a8c6d73294f7dd581a5455214d6689e5e7758f3d", "committedDate": "2020-12-02T13:26:58Z", "message": "Apply review comments"}, "afterCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/ffbe53da6cde7fd7d4749165df4f527cf8eb27ec", "committedDate": "2020-12-03T07:22:08Z", "message": "Use \"latest\" rather than \"latest_doc\" as the function name.\nMake \"sort\" a simple string."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQzNzAyMTIy", "url": "https://github.com/elastic/elasticsearch/pull/65304#pullrequestreview-543702122", "createdAt": "2020-12-03T08:21:01Z", "commit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "state": "COMMENTED", "comments": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QwODoyMTowMVrOH-HiEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxMDoxMDozNVrOH-Qw5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDg5NzE2OQ==", "bodyText": "rename if we settle on latest", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534897169", "createdAt": "2020-12-03T08:21:01Z", "author": {"login": "hendrikmuhs"}, "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/transform/transforms/TransformConfig.java", "diffHunk": "@@ -61,6 +63,7 @@\n     private final SyncConfig syncConfig;\n     private final SettingsConfig settings;\n     private final PivotConfig pivotConfig;\n+    private final LatestDocConfig latestDocConfig;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkwNDM1MA==", "bodyText": "I don't think we will ever support both, but it's ok.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534904350", "createdAt": "2020-12-03T08:25:09Z", "author": {"login": "hendrikmuhs"}, "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/transform/transforms/TransformConfig.java", "diffHunk": "@@ -162,6 +184,7 @@ public static TransformConfig forPreview(final SourceConfig source, final PivotC\n         this.frequency = frequency;\n         this.syncConfig = syncConfig;\n         this.pivotConfig = pivotConfig;\n+        this.latestDocConfig = latestDocConfig;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDg4ODgzOQ=="}, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkzMTk3Ng==", "bodyText": "nit: although I think it will never be possible, it would be more correct to move this into the if below line 103.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534931976", "createdAt": "2020-12-03T08:42:17Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/TransformConfig.java", "diffHunk": "@@ -176,12 +183,13 @@ public static String documentId(String transformId) {\n         this.syncConfig = syncConfig;\n         this.setHeaders(headers == null ? Collections.emptyMap() : headers);\n         this.pivotConfig = pivotConfig;\n+        this.latestDocConfig = latestDocConfig;\n         this.description = description;\n         this.settings = settings == null ? new SettingsConfig() : settings;\n \n-        // at least one function must be defined\n-        if (this.pivotConfig == null) {\n-            throw new IllegalArgumentException(TransformMessages.TRANSFORM_CONFIGURATION_NO_TRANSFORM);\n+        // exactly one function must be defined\n+        if ((this.pivotConfig == null) == (this.latestDocConfig == null)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkzNDY5NA==", "bodyText": "could be a set?", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534934694", "createdAt": "2020-12-03T08:43:54Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core.transform.transforms.latest;\n+\n+import org.elasticsearch.action.ActionRequestValidationException;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.bucket.terms.TermsAggregationBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+import org.elasticsearch.search.sort.SortBuilders;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.xpack.core.transform.utils.ExceptionsHelper;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.action.ValidateActions.addValidationError;\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+public class LatestDocConfig implements Writeable, ToXContentObject {\n+\n+    private static final String NAME = \"latest_config\";\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");\n+\n+    private final List<String> uniqueKey;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkzNjA4Mw==", "bodyText": "\ud83d\udc4d lets omit missing_bucket but hard code it to true in the implementation of latest", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534936083", "createdAt": "2020-12-03T08:44:44Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core.transform.transforms.latest;\n+\n+import org.elasticsearch.action.ActionRequestValidationException;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+import org.elasticsearch.xpack.core.transform.utils.ExceptionsHelper;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+public class LatestDocConfig implements Writeable, ToXContentObject {\n+\n+    private static final String NAME = \"transform_latest_doc\";\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDkwOTExOQ=="}, "originalCommit": {"oid": "bc74f3eee61e1a8291143034da04a8256eb6a297"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDk1MzUzMQ==", "bodyText": "it should not be possible (for strict) to allow unique_key double entries (see my comment regarding using set). To be able to use a set, it seems ok to de-dedup on lenient and throw on strict.\n(same for sort)", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534953531", "createdAt": "2020-12-03T08:53:24Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core.transform.transforms.latest;\n+\n+import org.elasticsearch.action.ActionRequestValidationException;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.bucket.terms.TermsAggregationBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+import org.elasticsearch.search.sort.SortBuilders;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.xpack.core.transform.utils.ExceptionsHelper;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.action.ValidateActions.addValidationError;\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+public class LatestDocConfig implements Writeable, ToXContentObject {\n+\n+    private static final String NAME = \"latest_config\";\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");\n+\n+    private final List<String> uniqueKey;\n+    private final String sort;\n+\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> STRICT_PARSER = createParser(false);\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> LENIENT_PARSER = createParser(true);\n+\n+    private static ConstructingObjectParser<LatestDocConfig, Void> createParser(boolean lenient) {\n+        ConstructingObjectParser<LatestDocConfig, Void> parser =\n+            new ConstructingObjectParser<>(NAME, lenient, args -> new LatestDocConfig((List<String>) args[0], (String) args[1]));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDk3MjI2MQ==", "bodyText": "add missing_bucket here", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534972261", "createdAt": "2020-12-03T09:04:05Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/latest/LatestDocConfig.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core.transform.transforms.latest;\n+\n+import org.elasticsearch.action.ActionRequestValidationException;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.bucket.terms.TermsAggregationBuilder;\n+import org.elasticsearch.search.sort.SortBuilder;\n+import org.elasticsearch.search.sort.SortBuilders;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.xpack.core.transform.utils.ExceptionsHelper;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.action.ValidateActions.addValidationError;\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+public class LatestDocConfig implements Writeable, ToXContentObject {\n+\n+    private static final String NAME = \"latest_config\";\n+\n+    private static final ParseField UNIQUE_KEY = new ParseField(\"unique_key\");\n+    private static final ParseField SORT = new ParseField(\"sort\");\n+\n+    private final List<String> uniqueKey;\n+    private final String sort;\n+\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> STRICT_PARSER = createParser(false);\n+    private static final ConstructingObjectParser<LatestDocConfig, Void> LENIENT_PARSER = createParser(true);\n+\n+    private static ConstructingObjectParser<LatestDocConfig, Void> createParser(boolean lenient) {\n+        ConstructingObjectParser<LatestDocConfig, Void> parser =\n+            new ConstructingObjectParser<>(NAME, lenient, args -> new LatestDocConfig((List<String>) args[0], (String) args[1]));\n+\n+        parser.declareStringArray(constructorArg(), UNIQUE_KEY);\n+        parser.declareString(constructorArg(), SORT);\n+\n+        return parser;\n+    }\n+\n+    public static LatestDocConfig fromXContent(final XContentParser parser, boolean lenient) throws IOException {\n+        return lenient ? LENIENT_PARSER.apply(parser, null) : STRICT_PARSER.apply(parser, null);\n+    }\n+\n+    public LatestDocConfig(List<String> uniqueKey, String sort) {\n+        this.uniqueKey = ExceptionsHelper.requireNonNull(uniqueKey, UNIQUE_KEY.getPreferredName());\n+        this.sort = ExceptionsHelper.requireNonNull(sort, SORT.getPreferredName());\n+    }\n+\n+    public LatestDocConfig(StreamInput in) throws IOException {\n+        this.uniqueKey = in.readStringList();\n+        this.sort = in.readString();\n+    }\n+\n+    public List<String> getUniqueKey() {\n+        return uniqueKey;\n+    }\n+\n+    public String getSort() {\n+        return sort;\n+    }\n+\n+    public List<SortBuilder<?>> getSorts() {\n+        return Collections.singletonList(SortBuilders.fieldSort(sort).order(SortOrder.DESC));\n+    }\n+\n+    public ActionRequestValidationException validate(ActionRequestValidationException validationException) {\n+        if (uniqueKey.isEmpty()) {\n+            validationException = addValidationError(\"latest.unique_key must be non-empty\", validationException);\n+        } else {\n+            for (int i = 0; i < uniqueKey.size(); ++i) {\n+                if (uniqueKey.get(i).isEmpty()) {\n+                    validationException =\n+                        addValidationError(\"latest.unique_key[\" + i + \"] element must be non-empty\", validationException);\n+                }\n+            }\n+        }\n+\n+        if (sort.isEmpty()) {\n+            validationException = addValidationError(\"latest.sort must be non-empty\", validationException);\n+        }\n+\n+        return validationException;\n+    }\n+\n+    @Override\n+    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n+        builder.startObject();\n+        builder.field(UNIQUE_KEY.getPreferredName(), uniqueKey);\n+        builder.field(SORT.getPreferredName(), sort);\n+        builder.endObject();\n+        return builder;\n+    }\n+\n+    public void toCompositeAggXContent(XContentBuilder builder) throws IOException {\n+        builder.startObject();\n+        builder.field(CompositeAggregationBuilder.SOURCES_FIELD_NAME.getPreferredName());\n+\n+        builder.startArray();\n+        for (String field : uniqueKey) {\n+            builder.startObject();\n+            builder.startObject(field);\n+            builder.startObject(TermsAggregationBuilder.NAME);\n+            builder.field(\"field\", field);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDk4OTY4NQ==", "bodyText": "see below, you also need to implement isValid(). This is some legacy code, #59588 is a todo to clean this up. The difference between the 2:\n\nvalidate is used for actions\nisValid is called when a transform starts as a check before the task runs, so this is not part of an action\n\nWe should consolidate this, for now try to reuse validate. Maybe you can just call validate and check for !null (no need to copy bad code). Long term we should change validate to return ValidationException and translate it to ActionRequestValidationException on the outer layer. ActionRequestValidationException is just a facade.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534989685", "createdAt": "2020-12-03T09:20:58Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/transform/transforms/TransformConfig.java", "diffHunk": "@@ -297,8 +300,10 @@ public ActionRequestValidationException validate(ActionRequestValidationExceptio\n         if (pivotConfig != null) {\n             validationException = pivotConfig.validate(validationException);\n         }\n+        if (latestDocConfig != null) {\n+            validationException = latestDocConfig.validate(validationException);\n+        }\n         validationException = settings.validate(validationException);\n-\n         return validationException;\n     }\n ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 157}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDk5ODI4MA==", "bodyText": "can you add sparse data, so we cover missing_bucket?", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r534998280", "createdAt": "2020-12-03T09:27:16Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/transform/qa/multi-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/transform/integration/LatestDocIT.java", "diffHunk": "@@ -0,0 +1,167 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.integration;\n+\n+import org.elasticsearch.action.admin.indices.refresh.RefreshRequest;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.client.RequestOptions;\n+import org.elasticsearch.client.RestHighLevelClient;\n+import org.elasticsearch.client.indices.GetMappingsRequest;\n+import org.elasticsearch.client.indices.GetMappingsResponse;\n+import org.elasticsearch.client.transform.PreviewTransformRequest;\n+import org.elasticsearch.client.transform.PreviewTransformResponse;\n+import org.elasticsearch.client.transform.transforms.TransformConfig;\n+import org.elasticsearch.client.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.search.SearchHit;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.junit.After;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.stream.Stream;\n+\n+import static java.util.stream.Collectors.toList;\n+import static org.hamcrest.Matchers.containsInAnyOrder;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.is;\n+\n+public class LatestDocIT extends TransformIntegTestCase {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTAwOTgwNQ==", "bodyText": "this conflicts with my PR, where I use addCommonSetings. Maybe it is better to remove addCommonBuilderParameters instead.\nHowever as we are working in parallel on this, I think it is best to avoid changing this for now, but in a follow up PR.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535009805", "createdAt": "2020-12-03T09:35:29Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/transform/qa/single-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/transform/integration/continuous/ContinuousTestCase.java", "diffHunk": "@@ -75,28 +76,29 @@\n      * Test results after 1 iteration in the test runner.\n      *\n      * @param iteration the current iteration\n+     * @param modifiedEvents set of events modified in the current iteration\n      */\n-    public abstract void testIteration(int iteration) throws IOException;\n+    public abstract void testIteration(int iteration, Set<String> modifiedEvents) throws IOException;\n \n     protected TransformConfig.Builder addCommonBuilderParameters(TransformConfig.Builder builder) {\n-        return builder.setSyncConfig(getSyncConfig())\n-            .setSettings(addCommonSetings(new SettingsConfig.Builder()).build())\n+        return builder\n+            .setSyncConfig(getSyncConfig())\n+            .setSettings(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTAxMTc3MA==", "bodyText": "good idea!", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535011770", "createdAt": "2020-12-03T09:37:09Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/transform/qa/single-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/transform/integration/continuous/TransformContinuousIT.java", "diffHunk": "@@ -208,10 +211,12 @@ public void testContinousEvents() throws Exception {\n             BulkRequest bulkRequest = new BulkRequest(sourceIndexName);\n \n             int numDocs = randomIntBetween(1000, 20000);\n+            Set<String> modifiedEvents = new HashSet<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTAyMjMyOQ==", "bodyText": "_ is supposed to be reserved for internal usage, but I am not sure if we are strict on it everywhere. Might be worth a follow up issue.\nWe could disallow _ prefixes in the transform config, it seems indexing allows _ as long as you do not try to set reserved fields like _index, _source, etc.\nFor aggs it is valid to start with _.\nIt seems e.g. > is invalid for aggs, so it might be better to use >. As its completely internal and not stored anywhere, we can change it without any BWC issues.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535022329", "createdAt": "2020-12-03T09:47:26Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/common/DocumentConversionUtils.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.common;\n+\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Map;\n+\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class DocumentConversionUtils {\n+\n+    public static IndexRequest convertDocumentToIndexRequest(Map<String, Object> document,\n+                                                             String destinationIndex,\n+                                                             String destinationPipeline) {\n+        String id = (String) document.get(TransformField.DOCUMENT_ID_FIELD);\n+        if (id == null) {\n+            throw new RuntimeException(\"Expected a document id but got null.\");\n+        }\n+\n+        XContentBuilder builder = skipInternalFields(document);\n+        IndexRequest request = new IndexRequest(destinationIndex).source(builder).id(id);\n+        if (destinationPipeline != null) {\n+            request.setPipeline(destinationPipeline);\n+        }\n+        return request;\n+    }\n+\n+    private static XContentBuilder skipInternalFields(Map<String, Object> document) {\n+        XContentBuilder builder;\n+        try {\n+            builder = jsonBuilder();\n+            builder.startObject();\n+            for (Map.Entry<String, ?> value : document.entrySet()) {\n+                // skip all internal fields\n+                if (value.getKey().startsWith(\"_\") == false) {\n+                    builder.field(value.getKey(), value.getValue());\n+                }\n+            }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzMTM0Ng=="}, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTAzNjMyMA==", "bodyText": "we could move this method into this class and make the config class more lightweight. It looks like a legacy code smell in pivot, we should not copy.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535036320", "createdAt": "2020-12-03T09:59:19Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.latest;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesAction;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesRequest;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.search.SearchAction;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.query.BoolQueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.Aggregations;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.metrics.TopHits;\n+import org.elasticsearch.search.aggregations.metrics.TopHitsAggregationBuilder;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+import org.elasticsearch.xpack.core.transform.TransformMessages;\n+import org.elasticsearch.xpack.core.transform.transforms.SourceConfig;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformIndexerStats;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformProgress;\n+import org.elasticsearch.xpack.core.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.xpack.transform.transforms.Function;\n+import org.elasticsearch.xpack.transform.transforms.IDGenerator;\n+import org.elasticsearch.xpack.transform.transforms.common.DocumentConversionUtils;\n+import org.elasticsearch.xpack.transform.transforms.pivot.SchemaUtil;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.function.Predicate.not;\n+import static java.util.stream.Collectors.toMap;\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class LatestDoc implements Function {\n+\n+    public static final int DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE = 5000;\n+    public static final int TEST_QUERY_PAGE_SIZE = 50;\n+\n+    private static final String COMPOSITE_AGGREGATION_NAME = \"_transform\";\n+    private static final String TOP_HITS_AGGREGATION_NAME = \"_top_hits\";\n+    private static final Logger logger = LogManager.getLogger(LatestDoc.class);\n+\n+    private final LatestDocConfig config;\n+\n+    // objects for re-using\n+    private final CompositeAggregationBuilder cachedCompositeAggregation;\n+\n+    public LatestDoc(LatestDocConfig config) {\n+        this.config = config;\n+        this.cachedCompositeAggregation = createCompositeAggregation(config);\n+    }\n+\n+    private static CompositeAggregationBuilder createCompositeAggregation(LatestDocConfig config) {\n+        CompositeAggregationBuilder compositeAggregation;\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            config.toCompositeAggXContent(builder);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTAzNzc3OQ==", "bodyText": "\ud83d\udc4d another indicator that config.toCompositeAggXContent should not exist", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535037779", "createdAt": "2020-12-03T10:00:37Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.latest;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesAction;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesRequest;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.search.SearchAction;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.query.BoolQueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.Aggregations;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.metrics.TopHits;\n+import org.elasticsearch.search.aggregations.metrics.TopHitsAggregationBuilder;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+import org.elasticsearch.xpack.core.transform.TransformMessages;\n+import org.elasticsearch.xpack.core.transform.transforms.SourceConfig;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformIndexerStats;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformProgress;\n+import org.elasticsearch.xpack.core.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.xpack.transform.transforms.Function;\n+import org.elasticsearch.xpack.transform.transforms.IDGenerator;\n+import org.elasticsearch.xpack.transform.transforms.common.DocumentConversionUtils;\n+import org.elasticsearch.xpack.transform.transforms.pivot.SchemaUtil;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.function.Predicate.not;\n+import static java.util.stream.Collectors.toMap;\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class LatestDoc implements Function {\n+\n+    public static final int DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE = 5000;\n+    public static final int TEST_QUERY_PAGE_SIZE = 50;\n+\n+    private static final String COMPOSITE_AGGREGATION_NAME = \"_transform\";\n+    private static final String TOP_HITS_AGGREGATION_NAME = \"_top_hits\";\n+    private static final Logger logger = LogManager.getLogger(LatestDoc.class);\n+\n+    private final LatestDocConfig config;\n+\n+    // objects for re-using\n+    private final CompositeAggregationBuilder cachedCompositeAggregation;\n+\n+    public LatestDoc(LatestDocConfig config) {\n+        this.config = config;\n+        this.cachedCompositeAggregation = createCompositeAggregation(config);\n+    }\n+\n+    private static CompositeAggregationBuilder createCompositeAggregation(LatestDocConfig config) {\n+        CompositeAggregationBuilder compositeAggregation;\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            config.toCompositeAggXContent(builder);\n+            XContentParser parser = builder.generator()\n+                .contentType()\n+                .xContent()\n+                .createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, BytesReference.bytes(builder).streamInput());\n+            compositeAggregation = CompositeAggregationBuilder.PARSER.parse(parser, COMPOSITE_AGGREGATION_NAME);\n+        } catch (IOException e) {\n+            throw new RuntimeException(\n+                TransformMessages.getMessage(TransformMessages.TRANSFORM_FAILED_TO_CREATE_COMPOSITE_AGGREGATION, \"latest\"), e);\n+        }\n+        TopHitsAggregationBuilder topHitsAgg =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTA0NTI1Mw==", "bodyText": "you might get rid of this method or at least rename it. Another example of legacy in pivot, better not to copy (in pivot we ended up with this after several re-factorings, it should be fixed there, too!).\nThe name is misleading, this is called for validation and preview, maybe you can name it accordingly. Or if you think re-usage makes no sense inline it.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535045253", "createdAt": "2020-12-03T10:07:41Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.latest;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesAction;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesRequest;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.search.SearchAction;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.query.BoolQueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.Aggregations;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.metrics.TopHits;\n+import org.elasticsearch.search.aggregations.metrics.TopHitsAggregationBuilder;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+import org.elasticsearch.xpack.core.transform.TransformMessages;\n+import org.elasticsearch.xpack.core.transform.transforms.SourceConfig;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformIndexerStats;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformProgress;\n+import org.elasticsearch.xpack.core.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.xpack.transform.transforms.Function;\n+import org.elasticsearch.xpack.transform.transforms.IDGenerator;\n+import org.elasticsearch.xpack.transform.transforms.common.DocumentConversionUtils;\n+import org.elasticsearch.xpack.transform.transforms.pivot.SchemaUtil;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.function.Predicate.not;\n+import static java.util.stream.Collectors.toMap;\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class LatestDoc implements Function {\n+\n+    public static final int DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE = 5000;\n+    public static final int TEST_QUERY_PAGE_SIZE = 50;\n+\n+    private static final String COMPOSITE_AGGREGATION_NAME = \"_transform\";\n+    private static final String TOP_HITS_AGGREGATION_NAME = \"_top_hits\";\n+    private static final Logger logger = LogManager.getLogger(LatestDoc.class);\n+\n+    private final LatestDocConfig config;\n+\n+    // objects for re-using\n+    private final CompositeAggregationBuilder cachedCompositeAggregation;\n+\n+    public LatestDoc(LatestDocConfig config) {\n+        this.config = config;\n+        this.cachedCompositeAggregation = createCompositeAggregation(config);\n+    }\n+\n+    private static CompositeAggregationBuilder createCompositeAggregation(LatestDocConfig config) {\n+        CompositeAggregationBuilder compositeAggregation;\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            config.toCompositeAggXContent(builder);\n+            XContentParser parser = builder.generator()\n+                .contentType()\n+                .xContent()\n+                .createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, BytesReference.bytes(builder).streamInput());\n+            compositeAggregation = CompositeAggregationBuilder.PARSER.parse(parser, COMPOSITE_AGGREGATION_NAME);\n+        } catch (IOException e) {\n+            throw new RuntimeException(\n+                TransformMessages.getMessage(TransformMessages.TRANSFORM_FAILED_TO_CREATE_COMPOSITE_AGGREGATION, \"latest\"), e);\n+        }\n+        TopHitsAggregationBuilder topHitsAgg =\n+            AggregationBuilders.topHits(TOP_HITS_AGGREGATION_NAME)\n+                .size(1)  // we are only interested in the top-1\n+                .sorts(config.getSorts());  // we copy the sort config directly from the function config\n+        compositeAggregation.subAggregation(topHitsAgg);\n+        return compositeAggregation;\n+    }\n+\n+    @Override\n+    public int getInitialPageSize() {\n+        return DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE;\n+    }\n+\n+    private SearchRequest buildSearchRequest(SourceConfig sourceConfig, Map<String, Object> position, int pageSize) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTA0ODQyMQ==", "bodyText": "as a result of my other comment, I wonder if this trace is useless. We have much better logging in the indexer and that's what people should use for debugging a transform problem. This is only called in validation and preview.", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r535048421", "createdAt": "2020-12-03T10:10:35Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/latest/LatestDoc.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.latest;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesAction;\n+import org.elasticsearch.action.fieldcaps.FieldCapabilitiesRequest;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.search.SearchAction;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.query.BoolQueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.Aggregations;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.metrics.TopHits;\n+import org.elasticsearch.search.aggregations.metrics.TopHitsAggregationBuilder;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.transform.TransformField;\n+import org.elasticsearch.xpack.core.transform.TransformMessages;\n+import org.elasticsearch.xpack.core.transform.transforms.SourceConfig;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformIndexerStats;\n+import org.elasticsearch.xpack.core.transform.transforms.TransformProgress;\n+import org.elasticsearch.xpack.core.transform.transforms.latest.LatestDocConfig;\n+import org.elasticsearch.xpack.transform.transforms.Function;\n+import org.elasticsearch.xpack.transform.transforms.IDGenerator;\n+import org.elasticsearch.xpack.transform.transforms.pivot.SchemaUtil;\n+import org.elasticsearch.xpack.transform.transforms.common.DocumentConversionUtils;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static java.util.function.Predicate.not;\n+import static java.util.stream.Collectors.toMap;\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class LatestDoc implements Function {\n+\n+    public static final int DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE = 5000;\n+    public static final int TEST_QUERY_PAGE_SIZE = 50;\n+\n+    private static final String COMPOSITE_AGGREGATION_NAME = \"_transform\";\n+    private static final String TOP_HITS_AGGREGATION_NAME = \"_top_hits\";\n+    private static final Logger logger = LogManager.getLogger(LatestDoc.class);\n+\n+    private final LatestDocConfig config;\n+\n+    // objects for re-using\n+    private final CompositeAggregationBuilder cachedCompositeAggregation;\n+\n+    public LatestDoc(LatestDocConfig config) {\n+        this.config = config;\n+        this.cachedCompositeAggregation = createCompositeAggregation(config);\n+    }\n+\n+    private static CompositeAggregationBuilder createCompositeAggregation(LatestDocConfig config) {\n+        assert config.getSort().size() == 1 && config.getSort().get(0) instanceof FieldSortBuilder;\n+\n+        CompositeAggregationBuilder compositeAggregation;\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            config.toCompositeAggXContent(builder);\n+            XContentParser parser = builder.generator()\n+                .contentType()\n+                .xContent()\n+                .createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, BytesReference.bytes(builder).streamInput());\n+            compositeAggregation = CompositeAggregationBuilder.PARSER.parse(parser, COMPOSITE_AGGREGATION_NAME);\n+        } catch (IOException e) {\n+            throw new RuntimeException(\n+                TransformMessages.getMessage(TransformMessages.TRANSFORM_FAILED_TO_CREATE_COMPOSITE_AGGREGATION, \"latest_doc\"), e);\n+        }\n+        TopHitsAggregationBuilder topHitsAgg =\n+            AggregationBuilders.topHits(TOP_HITS_AGGREGATION_NAME)\n+                .size(1)  // we are only interested in the top-1\n+                .sorts(config.getSort());  // we copy the sort config directly from the function config\n+        compositeAggregation.subAggregation(topHitsAgg);\n+        return compositeAggregation;\n+    }\n+\n+    @Override\n+    public int getInitialPageSize() {\n+        return DEFAULT_INITIAL_MAX_PAGE_SEARCH_SIZE;\n+    }\n+\n+    private SearchRequest buildSearchRequest(SourceConfig sourceConfig, Map<String, Object> position, int pageSize) {\n+        SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();\n+        buildSearchQuery(sourceBuilder, null, pageSize);\n+        sourceBuilder.query(sourceConfig.getQueryConfig().getQuery());\n+        SearchRequest searchRequest =\n+            new SearchRequest(sourceConfig.getIndex())\n+                .source(sourceBuilder)\n+                .indicesOptions(IndicesOptions.LENIENT_EXPAND_OPEN);\n+        logger.trace(\"Search request: {}\", searchRequest);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzMjI5NQ=="}, "originalCommit": {"oid": "a02238850f4cee7ac1f9e332656abc4304cb066e"}, "originalPosition": 117}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQzODkyNTAz", "url": "https://github.com/elastic/elasticsearch/pull/65304#pullrequestreview-543892503", "createdAt": "2020-12-03T12:13:54Z", "commit": {"oid": "ffbe53da6cde7fd7d4749165df4f527cf8eb27ec"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a13f2f1c3b1da1ea55d0cb2fe01e94049c9adec4", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/a13f2f1c3b1da1ea55d0cb2fe01e94049c9adec4", "committedDate": "2020-12-03T14:09:35Z", "message": "Apply review comments"}, "afterCommit": {"oid": "d80a607104ace330bab5bef2ebd4982057f0b581", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/d80a607104ace330bab5bef2ebd4982057f0b581", "committedDate": "2020-12-04T10:53:44Z", "message": "Move extractFieldMappings method to DocumentConversionUtils and add a unit test\nRe-use removeInternalFields method where applicable"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "290c62e2e6deba27b226c3558b437ade0482e5d8", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/290c62e2e6deba27b226c3558b437ade0482e5d8", "committedDate": "2020-12-08T08:19:07Z", "message": "Implement latest function"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d18c67544c207d826fe9fff6495d534e5b8a8949", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/d18c67544c207d826fe9fff6495d534e5b8a8949", "committedDate": "2020-12-08T08:19:09Z", "message": "Implement change collector for latest function"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6d448da1c15a0210e6e589e39919e3323e8a6d13", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/6d448da1c15a0210e6e589e39919e3323e8a6d13", "committedDate": "2020-12-08T08:19:09Z", "message": "Apply review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4816d83582dc213d176b2294a91788e6004d1ef3", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/4816d83582dc213d176b2294a91788e6004d1ef3", "committedDate": "2020-12-08T08:19:09Z", "message": "Verify optimization in LatestDocContinuousIT"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2de8669e228d1d2a2bf620deb458300b689d739f", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/2de8669e228d1d2a2bf620deb458300b689d739f", "committedDate": "2020-12-08T08:19:10Z", "message": "Introduce constant instead of magic number in the code."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "36973784863c3fb2b17e45ff94931cfdf8584acb", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/36973784863c3fb2b17e45ff94931cfdf8584acb", "committedDate": "2020-12-08T08:19:10Z", "message": "Add validations with unit tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "838116ad667fad0309894acd913f2d7a6e34ee21", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/838116ad667fad0309894acd913f2d7a6e34ee21", "committedDate": "2020-12-08T08:19:10Z", "message": "Validate sort type"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0bca2e9e402958152142ecfdecbbc456a2973a15", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/0bca2e9e402958152142ecfdecbbc456a2973a15", "committedDate": "2020-12-08T08:19:10Z", "message": "Add comments in LatestDocChangeCollector's methods"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fa9f5ea50bfaff85097b6bd9dbcaf26ee2cda3bb", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/fa9f5ea50bfaff85097b6bd9dbcaf26ee2cda3bb", "committedDate": "2020-12-08T08:19:10Z", "message": "Apply review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "90523fb9cadfce968dc4266fb356fa3ba77f5d73", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/90523fb9cadfce968dc4266fb356fa3ba77f5d73", "committedDate": "2020-12-08T08:19:10Z", "message": "Use \"latest\" rather than \"latest_doc\" as the function name.\nMake \"sort\" a simple string."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "31fe6eb96a7ca888e04521f9e9fd20fc70ac37d5", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/31fe6eb96a7ca888e04521f9e9fd20fc70ac37d5", "committedDate": "2020-12-08T08:20:56Z", "message": "Apply review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2439e957173adc701b0bfe6990aec87856540fc1", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/2439e957173adc701b0bfe6990aec87856540fc1", "committedDate": "2020-12-08T08:20:58Z", "message": "Move extractFieldMappings method to DocumentConversionUtils and add a unit test\nRe-use removeInternalFields method where applicable"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d80a607104ace330bab5bef2ebd4982057f0b581", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/d80a607104ace330bab5bef2ebd4982057f0b581", "committedDate": "2020-12-04T10:53:44Z", "message": "Move extractFieldMappings method to DocumentConversionUtils and add a unit test\nRe-use removeInternalFields method where applicable"}, "afterCommit": {"oid": "2439e957173adc701b0bfe6990aec87856540fc1", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/2439e957173adc701b0bfe6990aec87856540fc1", "committedDate": "2020-12-08T08:20:58Z", "message": "Move extractFieldMappings method to DocumentConversionUtils and add a unit test\nRe-use removeInternalFields method where applicable"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ3MDE2NjM3", "url": "https://github.com/elastic/elasticsearch/pull/65304#pullrequestreview-547016637", "createdAt": "2020-12-08T10:14:43Z", "commit": {"oid": "2439e957173adc701b0bfe6990aec87856540fc1"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQxMDoxNDo0M1rOIBRrzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQxMDoxNDo0M1rOIBRrzQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODIwOTIyOQ==", "bodyText": "lets remove that, too", "url": "https://github.com/elastic/elasticsearch/pull/65304#discussion_r538209229", "createdAt": "2020-12-08T10:14:43Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/pivot/Pivot.java", "diffHunk": "@@ -197,7 +191,7 @@ public SearchRequest buildSearchRequest(SourceConfig sourceConfig, Map<String, O\n         searchRequest.source(sourceBuilder);\n         searchRequest.indicesOptions(IndicesOptions.LENIENT_EXPAND_OPEN);\n \n-        logger.trace(\"Search request: {}\", searchRequest);\n+        logger.trace(() -> new ParameterizedMessage(\"Search request: {}\", searchRequest));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2439e957173adc701b0bfe6990aec87856540fc1"}, "originalPosition": 93}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a0ab9d51743428ebe3566d552888ff556d3fb80c", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/a0ab9d51743428ebe3566d552888ff556d3fb80c", "committedDate": "2020-12-08T10:36:21Z", "message": "Rename classes from `LatestDoc*` to `Latest*`"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a887d1cd8808a45e5daff01e81fc9b73f16a9bfe", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/a887d1cd8808a45e5daff01e81fc9b73f16a9bfe", "committedDate": "2020-12-08T11:23:53Z", "message": "Rename classes from `LatestDoc*` to `Latest*`"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "abaf2bf73c48ec6fde02a8f16d2e0f77b56fcbc3", "author": {"user": {"login": "przemekwitek", "name": "Przemys\u0142aw Witek"}}, "url": "https://github.com/elastic/elasticsearch/commit/abaf2bf73c48ec6fde02a8f16d2e0f77b56fcbc3", "committedDate": "2020-12-08T11:25:41Z", "message": "Fix handling null keys by Collectors.toMap"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 902, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}