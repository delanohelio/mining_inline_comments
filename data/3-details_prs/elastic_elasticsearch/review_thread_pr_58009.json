{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMzMjgzODY5", "number": 58009, "reviewThreads": {"totalCount": 20, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMTowOToyMFrOEKDEug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMTo0Mjo0NlrOEKegIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4OTcxNTc4OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/internalClusterTest/java/org/elasticsearch/xpack/ml/integration/ChunkedTrainedMoodelPersisterIT.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMTowOToyMFrOGq3bwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMjoxMDozM1rOGq5XeQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYwMTYwMA==", "bodyText": "nice name, but I guess moodel -> model ;-)", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447601600", "createdAt": "2020-06-30T11:09:20Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/ml/src/internalClusterTest/java/org/elasticsearch/xpack/ml/integration/ChunkedTrainedMoodelPersisterIT.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.integration;\n+\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.action.util.PageParams;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsDest;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsSource;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.MlInferenceNamedXContentProvider;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinition;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinitionTests;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInputTests;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.TargetType;\n+import org.elasticsearch.xpack.ml.MlSingleNodeTestCase;\n+import org.elasticsearch.xpack.ml.dataframe.process.ChunkedTrainedModelPersister;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.DocValueField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.inference.modelsize.MlModelSizeNamedXContentProvider;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfoTests;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+import org.junit.Before;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Set;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+\n+public class ChunkedTrainedMoodelPersisterIT extends MlSingleNodeTestCase {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYyMzMyOA==", "bodyText": ":D", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447623328", "createdAt": "2020-06-30T11:52:34Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/internalClusterTest/java/org/elasticsearch/xpack/ml/integration/ChunkedTrainedMoodelPersisterIT.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.integration;\n+\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.action.util.PageParams;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsDest;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsSource;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.MlInferenceNamedXContentProvider;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinition;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinitionTests;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInputTests;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.TargetType;\n+import org.elasticsearch.xpack.ml.MlSingleNodeTestCase;\n+import org.elasticsearch.xpack.ml.dataframe.process.ChunkedTrainedModelPersister;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.DocValueField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.inference.modelsize.MlModelSizeNamedXContentProvider;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfoTests;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+import org.junit.Before;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Set;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+\n+public class ChunkedTrainedMoodelPersisterIT extends MlSingleNodeTestCase {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYwMTYwMA=="}, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYzMzI3Mw==", "bodyText": "\ud83d\udc2e", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447633273", "createdAt": "2020-06-30T12:10:33Z", "author": {"login": "droberts195"}, "path": "x-pack/plugin/ml/src/internalClusterTest/java/org/elasticsearch/xpack/ml/integration/ChunkedTrainedMoodelPersisterIT.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.integration;\n+\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.action.util.PageParams;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsDest;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsSource;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.MlInferenceNamedXContentProvider;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinition;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinitionTests;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInputTests;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.TargetType;\n+import org.elasticsearch.xpack.ml.MlSingleNodeTestCase;\n+import org.elasticsearch.xpack.ml.dataframe.process.ChunkedTrainedModelPersister;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.DocValueField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.inference.modelsize.MlModelSizeNamedXContentProvider;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfoTests;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+import org.junit.Before;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Set;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+\n+public class ChunkedTrainedMoodelPersisterIT extends MlSingleNodeTestCase {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYwMTYwMA=="}, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4OTc0NjEyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/persistence/TrainedModelDefinitionDoc.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMToxODo0NFrOGq3t4A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMToxODo0NFrOGq3t4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYwNjI0MA==", "bodyText": "nit: abbreviation looks strange if everything else is written out", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447606240", "createdAt": "2020-06-30T11:18:44Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/persistence/TrainedModelDefinitionDoc.java", "diffHunk": "@@ -48,6 +49,7 @@\n         parser.declareInt(TrainedModelDefinitionDoc.Builder::setCompressionVersion, COMPRESSION_VERSION);\n         parser.declareLong(TrainedModelDefinitionDoc.Builder::setDefinitionLength, DEFINITION_LENGTH);\n         parser.declareLong(TrainedModelDefinitionDoc.Builder::setTotalDefinitionLength, TOTAL_DEFINITION_LENGTH);\n+        parser.declareBoolean(TrainedModelDefinitionDoc.Builder::setEos, EOS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4OTc0ODc1OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/internalClusterTest/java/org/elasticsearch/xpack/ml/integration/ChunkedTrainedMoodelPersisterIT.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMToxOTozMFrOGq3vbA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMToxOTozMFrOGq3vbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYwNjYzNg==", "bodyText": "Note there's a simple way to do ceil with integer arithmetic: (str.length() + chunkSize - 1) / chunkSize.", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447606636", "createdAt": "2020-06-30T11:19:30Z", "author": {"login": "tveasey"}, "path": "x-pack/plugin/ml/src/internalClusterTest/java/org/elasticsearch/xpack/ml/integration/ChunkedTrainedMoodelPersisterIT.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.integration;\n+\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.action.util.PageParams;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsDest;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsSource;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.MlInferenceNamedXContentProvider;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinition;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinitionTests;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInputTests;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.TargetType;\n+import org.elasticsearch.xpack.ml.MlSingleNodeTestCase;\n+import org.elasticsearch.xpack.ml.dataframe.process.ChunkedTrainedModelPersister;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.DocValueField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.inference.modelsize.MlModelSizeNamedXContentProvider;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfoTests;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+import org.junit.Before;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Set;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+\n+public class ChunkedTrainedMoodelPersisterIT extends MlSingleNodeTestCase {\n+\n+    private TrainedModelProvider trainedModelProvider;\n+\n+    @Before\n+    public void createComponents() throws Exception {\n+        trainedModelProvider = new TrainedModelProvider(client(), xContentRegistry());\n+        waitForMlTemplates();\n+    }\n+\n+    public void testStoreModelViaChunkedPersister() throws IOException {\n+        String modelId = \"stored-chunked-model\";\n+        DataFrameAnalyticsConfig analyticsConfig = new DataFrameAnalyticsConfig.Builder()\n+            .setId(modelId)\n+            .setSource(new DataFrameAnalyticsSource(new String[] {\"my_source\"}, null, null))\n+            .setDest(new DataFrameAnalyticsDest(\"my_dest\", null))\n+            .setAnalysis(new Regression(\"foo\"))\n+            .build();\n+        List<ExtractedField> extractedFieldList = Collections.singletonList(new DocValueField(\"foo\", Collections.emptySet()));\n+        TrainedModelConfig.Builder configBuilder = buildTrainedModelConfigBuilder(modelId);\n+        String compressedDefinition = configBuilder.build().getCompressedDefinition();\n+        int totalSize = compressedDefinition.length();\n+        List<String> chunks = chunkStringWithSize(compressedDefinition, totalSize/3);\n+\n+        ChunkedTrainedModelPersister persister = new ChunkedTrainedModelPersister(trainedModelProvider,\n+            analyticsConfig,\n+            new DataFrameAnalyticsAuditor(client(), \"test-node\"),\n+            (ex) -> { throw new ElasticsearchException(ex); },\n+            new ExtractedFields(extractedFieldList, Collections.emptyMap())\n+        );\n+\n+        //Accuracy for size is not tested here\n+        ModelSizeInfo modelSizeInfo = ModelSizeInfoTests.createRandom();\n+        persister.createAndIndexInferenceModelMetadata(modelSizeInfo);\n+        for (int i = 0; i < chunks.size(); i++) {\n+            persister.createAndIndexInferenceModelDoc(new TrainedModelDefinitionChunk(chunks.get(i), i, i == (chunks.size() - 1)));\n+        }\n+\n+        PlainActionFuture<Tuple<Long, Set<String>>> getIdsFuture = new PlainActionFuture<>();\n+        trainedModelProvider.expandIds(modelId + \"*\", false, PageParams.defaultParams(), Collections.emptySet(), getIdsFuture);\n+        Tuple<Long, Set<String>> ids = getIdsFuture.actionGet();\n+        assertThat(ids.v1(), equalTo(1L));\n+\n+        PlainActionFuture<TrainedModelConfig> getTrainedModelFuture = new PlainActionFuture<>();\n+        trainedModelProvider.getTrainedModel(ids.v2().iterator().next(), true, getTrainedModelFuture);\n+\n+        TrainedModelConfig storedConfig = getTrainedModelFuture.actionGet();\n+        assertThat(storedConfig.getCompressedDefinition(), equalTo(compressedDefinition));\n+        assertThat(storedConfig.getEstimatedOperations(), equalTo((long)modelSizeInfo.numOperations()));\n+        assertThat(storedConfig.getEstimatedHeapMemory(), equalTo(modelSizeInfo.ramBytesUsed()));\n+    }\n+\n+    private static TrainedModelConfig.Builder buildTrainedModelConfigBuilder(String modelId) {\n+        TrainedModelDefinition.Builder definitionBuilder = TrainedModelDefinitionTests.createRandomBuilder();\n+        long bytesUsed = definitionBuilder.build().ramBytesUsed();\n+        long operations = definitionBuilder.build().getTrainedModel().estimatedNumOperations();\n+        return TrainedModelConfig.builder()\n+            .setCreatedBy(\"ml_test\")\n+            .setParsedDefinition(TrainedModelDefinitionTests.createRandomBuilder(TargetType.REGRESSION))\n+            .setDescription(\"trained model config for test\")\n+            .setModelId(modelId)\n+            .setVersion(Version.CURRENT)\n+            .setLicenseLevel(License.OperationMode.PLATINUM.description())\n+            .setEstimatedHeapMemory(bytesUsed)\n+            .setEstimatedOperations(operations)\n+            .setInput(TrainedModelInputTests.createRandomInput());\n+    }\n+\n+    private static List<String> chunkStringWithSize(String str, int chunkSize) {\n+        List<String> subStrings = new ArrayList<>((int)Math.ceil(str.length()/(double)chunkSize));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 115}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4OTc1NDIxOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/internalClusterTest/java/org/elasticsearch/xpack/ml/integration/ChunkedTrainedMoodelPersisterIT.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMToyMDo1MlrOGq3ymw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMToyMDo1MlrOGq3ymw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYwNzQ1MQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    for (int i = 0; i < str.length();i += chunkSize) {\n          \n          \n            \n                    for (int i = 0; i < str.length(); i += chunkSize) {", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447607451", "createdAt": "2020-06-30T11:20:52Z", "author": {"login": "tveasey"}, "path": "x-pack/plugin/ml/src/internalClusterTest/java/org/elasticsearch/xpack/ml/integration/ChunkedTrainedMoodelPersisterIT.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.integration;\n+\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.action.util.PageParams;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsDest;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsSource;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.MlInferenceNamedXContentProvider;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinition;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinitionTests;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInputTests;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.TargetType;\n+import org.elasticsearch.xpack.ml.MlSingleNodeTestCase;\n+import org.elasticsearch.xpack.ml.dataframe.process.ChunkedTrainedModelPersister;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.DocValueField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.inference.modelsize.MlModelSizeNamedXContentProvider;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfoTests;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+import org.junit.Before;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Set;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+\n+public class ChunkedTrainedMoodelPersisterIT extends MlSingleNodeTestCase {\n+\n+    private TrainedModelProvider trainedModelProvider;\n+\n+    @Before\n+    public void createComponents() throws Exception {\n+        trainedModelProvider = new TrainedModelProvider(client(), xContentRegistry());\n+        waitForMlTemplates();\n+    }\n+\n+    public void testStoreModelViaChunkedPersister() throws IOException {\n+        String modelId = \"stored-chunked-model\";\n+        DataFrameAnalyticsConfig analyticsConfig = new DataFrameAnalyticsConfig.Builder()\n+            .setId(modelId)\n+            .setSource(new DataFrameAnalyticsSource(new String[] {\"my_source\"}, null, null))\n+            .setDest(new DataFrameAnalyticsDest(\"my_dest\", null))\n+            .setAnalysis(new Regression(\"foo\"))\n+            .build();\n+        List<ExtractedField> extractedFieldList = Collections.singletonList(new DocValueField(\"foo\", Collections.emptySet()));\n+        TrainedModelConfig.Builder configBuilder = buildTrainedModelConfigBuilder(modelId);\n+        String compressedDefinition = configBuilder.build().getCompressedDefinition();\n+        int totalSize = compressedDefinition.length();\n+        List<String> chunks = chunkStringWithSize(compressedDefinition, totalSize/3);\n+\n+        ChunkedTrainedModelPersister persister = new ChunkedTrainedModelPersister(trainedModelProvider,\n+            analyticsConfig,\n+            new DataFrameAnalyticsAuditor(client(), \"test-node\"),\n+            (ex) -> { throw new ElasticsearchException(ex); },\n+            new ExtractedFields(extractedFieldList, Collections.emptyMap())\n+        );\n+\n+        //Accuracy for size is not tested here\n+        ModelSizeInfo modelSizeInfo = ModelSizeInfoTests.createRandom();\n+        persister.createAndIndexInferenceModelMetadata(modelSizeInfo);\n+        for (int i = 0; i < chunks.size(); i++) {\n+            persister.createAndIndexInferenceModelDoc(new TrainedModelDefinitionChunk(chunks.get(i), i, i == (chunks.size() - 1)));\n+        }\n+\n+        PlainActionFuture<Tuple<Long, Set<String>>> getIdsFuture = new PlainActionFuture<>();\n+        trainedModelProvider.expandIds(modelId + \"*\", false, PageParams.defaultParams(), Collections.emptySet(), getIdsFuture);\n+        Tuple<Long, Set<String>> ids = getIdsFuture.actionGet();\n+        assertThat(ids.v1(), equalTo(1L));\n+\n+        PlainActionFuture<TrainedModelConfig> getTrainedModelFuture = new PlainActionFuture<>();\n+        trainedModelProvider.getTrainedModel(ids.v2().iterator().next(), true, getTrainedModelFuture);\n+\n+        TrainedModelConfig storedConfig = getTrainedModelFuture.actionGet();\n+        assertThat(storedConfig.getCompressedDefinition(), equalTo(compressedDefinition));\n+        assertThat(storedConfig.getEstimatedOperations(), equalTo((long)modelSizeInfo.numOperations()));\n+        assertThat(storedConfig.getEstimatedHeapMemory(), equalTo(modelSizeInfo.ramBytesUsed()));\n+    }\n+\n+    private static TrainedModelConfig.Builder buildTrainedModelConfigBuilder(String modelId) {\n+        TrainedModelDefinition.Builder definitionBuilder = TrainedModelDefinitionTests.createRandomBuilder();\n+        long bytesUsed = definitionBuilder.build().ramBytesUsed();\n+        long operations = definitionBuilder.build().getTrainedModel().estimatedNumOperations();\n+        return TrainedModelConfig.builder()\n+            .setCreatedBy(\"ml_test\")\n+            .setParsedDefinition(TrainedModelDefinitionTests.createRandomBuilder(TargetType.REGRESSION))\n+            .setDescription(\"trained model config for test\")\n+            .setModelId(modelId)\n+            .setVersion(Version.CURRENT)\n+            .setLicenseLevel(License.OperationMode.PLATINUM.description())\n+            .setEstimatedHeapMemory(bytesUsed)\n+            .setEstimatedOperations(operations)\n+            .setInput(TrainedModelInputTests.createRandomInput());\n+    }\n+\n+    private static List<String> chunkStringWithSize(String str, int chunkSize) {\n+        List<String> subStrings = new ArrayList<>((int)Math.ceil(str.length()/(double)chunkSize));\n+        for (int i = 0; i < str.length();i += chunkSize) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 116}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4OTc5Mjk2OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMTozMzowNVrOGq4KRQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMTozMzowNVrOGq4KRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYxMzUwOQ==", "bodyText": "should currentModelId be reset, too (after LOGGER.info)?", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447613509", "createdAt": "2020-06-30T11:33:05Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 90}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4OTc5NTQzOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMTozMzo1NlrOGq4LxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMToyOTo1NFrOGriCZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYxMzg5Mg==", "bodyText": "why not initialize it empty?", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447613892", "createdAt": "2020-06-30T11:33:56Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY2MjIxOQ==", "bodyText": "it is empty?", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447662219", "createdAt": "2020-06-30T13:00:01Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYxMzg5Mg=="}, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODI5OTYyMw==", "bodyText": "well, ... I mean new AtomicReference<>()", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r448299623", "createdAt": "2020-07-01T11:29:54Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYxMzg5Mg=="}, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4OTgwNDUwOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMTozNjo1MFrOGq4RdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMTozNjo1MFrOGq4RdA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYxNTM0OA==", "bodyText": "I wonder if AtomicBoolean would be nicer with things like updateAndGet", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447615348", "createdAt": "2020-06-30T11:36:50Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4OTgwOTcyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMTozODozMFrOGq4UlQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMTozODozMFrOGq4UlQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYxNjE0OQ==", "bodyText": "consider a constant for the timeout", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447616149", "createdAt": "2020-06-30T11:38:30Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;\n+                    LOGGER.info(\n+                        \"[{}] finished stored trained model definition chunks with id [{}]\",\n+                        analytics.getId(),\n+                        this.currentModelId.get());\n+                    auditor.info(analytics.getId(), \"Stored trained model with id [\" + this.currentModelId.get() + \"]\");\n+                    CountDownLatch refreshLatch = new CountDownLatch(1);\n+                    provider.refreshInferenceIndex(\n+                        new LatchedActionListener<>(ActionListener.wrap(\n+                            refreshResponse -> LOGGER.debug(() -> new ParameterizedMessage(\n+                                \"[{}] refreshed inference index after model store\",\n+                                analytics.getId()\n+                            )),\n+                            e -> LOGGER.warn(\"[{}] failed to refresh inference index after model store\", analytics.getId())),\n+                            refreshLatch));\n+                    try {\n+                        if (refreshLatch.await(30, TimeUnit.SECONDS) == false) {\n+                            LOGGER.error(\"[{}] Timed out (30s) waiting for index refresh\", analytics.getId());\n+                        }\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                }\n+            },\n+            e -> failureHandler.accept(ExceptionsHelper.serverError(\"error storing trained model definition chunk [{}] with id [{}]\", e,\n+                trainedModelDefinitionDoc.getModelId(), trainedModelDefinitionDoc.getDocNum()))\n+        );\n+        provider.storeTrainedModelDefinitionDoc(trainedModelDefinitionDoc, new LatchedActionListener<>(storeListener, latch));\n+        try {\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for chunked inference definition to be stored\", analytics.getId());\n+            }\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            failureHandler.accept(ExceptionsHelper.serverError(\"interrupted waiting for chunked inference definition to be stored\"));\n+        }\n+    }\n+\n+    public void createAndIndexInferenceModelMetadata(ModelSizeInfo inferenceModelSize) {\n+        if (readyToStoreNewModel == false) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"new inference model is attempting to be stored before completion previous model storage\"\n+            ));\n+            return;\n+        }\n+        TrainedModelConfig trainedModelConfig = createTrainedModelConfig(inferenceModelSize);\n+        CountDownLatch latch = storeTrainedModelMetadata(trainedModelConfig);\n+        try {\n+            readyToStoreNewModel = false;\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 139}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4OTgzMjkwOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMTo0NTozM1rOGq4imA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMzoyNDoyOFrOGq8I_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYxOTczNg==", "bodyText": "if this happens, it seems the persister can get stuck, because the doc gets never be stored and readyToStoreNewModel is never reset? Correct me if I am wrong.", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447619736", "createdAt": "2020-06-30T11:45:33Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;\n+                    LOGGER.info(\n+                        \"[{}] finished stored trained model definition chunks with id [{}]\",\n+                        analytics.getId(),\n+                        this.currentModelId.get());\n+                    auditor.info(analytics.getId(), \"Stored trained model with id [\" + this.currentModelId.get() + \"]\");\n+                    CountDownLatch refreshLatch = new CountDownLatch(1);\n+                    provider.refreshInferenceIndex(\n+                        new LatchedActionListener<>(ActionListener.wrap(\n+                            refreshResponse -> LOGGER.debug(() -> new ParameterizedMessage(\n+                                \"[{}] refreshed inference index after model store\",\n+                                analytics.getId()\n+                            )),\n+                            e -> LOGGER.warn(\"[{}] failed to refresh inference index after model store\", analytics.getId())),\n+                            refreshLatch));\n+                    try {\n+                        if (refreshLatch.await(30, TimeUnit.SECONDS) == false) {\n+                            LOGGER.error(\"[{}] Timed out (30s) waiting for index refresh\", analytics.getId());\n+                        }\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                }\n+            },\n+            e -> failureHandler.accept(ExceptionsHelper.serverError(\"error storing trained model definition chunk [{}] with id [{}]\", e,\n+                trainedModelDefinitionDoc.getModelId(), trainedModelDefinitionDoc.getDocNum()))\n+        );\n+        provider.storeTrainedModelDefinitionDoc(trainedModelDefinitionDoc, new LatchedActionListener<>(storeListener, latch));\n+        try {\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for chunked inference definition to be stored\", analytics.getId());\n+            }\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            failureHandler.accept(ExceptionsHelper.serverError(\"interrupted waiting for chunked inference definition to be stored\"));\n+        }\n+    }\n+\n+    public void createAndIndexInferenceModelMetadata(ModelSizeInfo inferenceModelSize) {\n+        if (readyToStoreNewModel == false) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"new inference model is attempting to be stored before completion previous model storage\"\n+            ));\n+            return;\n+        }\n+        TrainedModelConfig trainedModelConfig = createTrainedModelConfig(inferenceModelSize);\n+        CountDownLatch latch = storeTrainedModelMetadata(trainedModelConfig);\n+        try {\n+            readyToStoreNewModel = false;\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for inference model metadata to be stored\", analytics.getId());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYyMzcyOQ==", "bodyText": "yeah, it should reset. Good catch", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447623729", "createdAt": "2020-06-30T11:53:23Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;\n+                    LOGGER.info(\n+                        \"[{}] finished stored trained model definition chunks with id [{}]\",\n+                        analytics.getId(),\n+                        this.currentModelId.get());\n+                    auditor.info(analytics.getId(), \"Stored trained model with id [\" + this.currentModelId.get() + \"]\");\n+                    CountDownLatch refreshLatch = new CountDownLatch(1);\n+                    provider.refreshInferenceIndex(\n+                        new LatchedActionListener<>(ActionListener.wrap(\n+                            refreshResponse -> LOGGER.debug(() -> new ParameterizedMessage(\n+                                \"[{}] refreshed inference index after model store\",\n+                                analytics.getId()\n+                            )),\n+                            e -> LOGGER.warn(\"[{}] failed to refresh inference index after model store\", analytics.getId())),\n+                            refreshLatch));\n+                    try {\n+                        if (refreshLatch.await(30, TimeUnit.SECONDS) == false) {\n+                            LOGGER.error(\"[{}] Timed out (30s) waiting for index refresh\", analytics.getId());\n+                        }\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                }\n+            },\n+            e -> failureHandler.accept(ExceptionsHelper.serverError(\"error storing trained model definition chunk [{}] with id [{}]\", e,\n+                trainedModelDefinitionDoc.getModelId(), trainedModelDefinitionDoc.getDocNum()))\n+        );\n+        provider.storeTrainedModelDefinitionDoc(trainedModelDefinitionDoc, new LatchedActionListener<>(storeListener, latch));\n+        try {\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for chunked inference definition to be stored\", analytics.getId());\n+            }\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            failureHandler.accept(ExceptionsHelper.serverError(\"interrupted waiting for chunked inference definition to be stored\"));\n+        }\n+    }\n+\n+    public void createAndIndexInferenceModelMetadata(ModelSizeInfo inferenceModelSize) {\n+        if (readyToStoreNewModel == false) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"new inference model is attempting to be stored before completion previous model storage\"\n+            ));\n+            return;\n+        }\n+        TrainedModelConfig trainedModelConfig = createTrainedModelConfig(inferenceModelSize);\n+        CountDownLatch latch = storeTrainedModelMetadata(trainedModelConfig);\n+        try {\n+            readyToStoreNewModel = false;\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for inference model metadata to be stored\", analytics.getId());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYxOTczNg=="}, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY3ODcxNw==", "bodyText": "I do not think it should switch back in this timeout check. If it times out, it just took a long time to persist.\nIf the persistence itself fails, then I will reset the boolean flag.\nSimilar behavior for the persistence of the definition docs. exception being, if the definition doc is the eos, then I will reset the flag.", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447678717", "createdAt": "2020-06-30T13:24:28Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;\n+                    LOGGER.info(\n+                        \"[{}] finished stored trained model definition chunks with id [{}]\",\n+                        analytics.getId(),\n+                        this.currentModelId.get());\n+                    auditor.info(analytics.getId(), \"Stored trained model with id [\" + this.currentModelId.get() + \"]\");\n+                    CountDownLatch refreshLatch = new CountDownLatch(1);\n+                    provider.refreshInferenceIndex(\n+                        new LatchedActionListener<>(ActionListener.wrap(\n+                            refreshResponse -> LOGGER.debug(() -> new ParameterizedMessage(\n+                                \"[{}] refreshed inference index after model store\",\n+                                analytics.getId()\n+                            )),\n+                            e -> LOGGER.warn(\"[{}] failed to refresh inference index after model store\", analytics.getId())),\n+                            refreshLatch));\n+                    try {\n+                        if (refreshLatch.await(30, TimeUnit.SECONDS) == false) {\n+                            LOGGER.error(\"[{}] Timed out (30s) waiting for index refresh\", analytics.getId());\n+                        }\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                }\n+            },\n+            e -> failureHandler.accept(ExceptionsHelper.serverError(\"error storing trained model definition chunk [{}] with id [{}]\", e,\n+                trainedModelDefinitionDoc.getModelId(), trainedModelDefinitionDoc.getDocNum()))\n+        );\n+        provider.storeTrainedModelDefinitionDoc(trainedModelDefinitionDoc, new LatchedActionListener<>(storeListener, latch));\n+        try {\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for chunked inference definition to be stored\", analytics.getId());\n+            }\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            failureHandler.accept(ExceptionsHelper.serverError(\"interrupted waiting for chunked inference definition to be stored\"));\n+        }\n+    }\n+\n+    public void createAndIndexInferenceModelMetadata(ModelSizeInfo inferenceModelSize) {\n+        if (readyToStoreNewModel == false) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"new inference model is attempting to be stored before completion previous model storage\"\n+            ));\n+            return;\n+        }\n+        TrainedModelConfig trainedModelConfig = createTrainedModelConfig(inferenceModelSize);\n+        CountDownLatch latch = storeTrainedModelMetadata(trainedModelConfig);\n+        try {\n+            readyToStoreNewModel = false;\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for inference model metadata to be stored\", analytics.getId());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYxOTczNg=="}, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 140}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4OTg5NzUwOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMjowNDoyNFrOGq5JvA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxNDoyMzoxOFrOGq-3gg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYyOTc1Ng==", "bodyText": "There's an asymmetry here with createAndIndexInferenceModelMetadata , which nicely separates setup and teardown from logic to write the docs, maybe it would be worth factoring this out into a storeTrainedModel function?", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447629756", "createdAt": "2020-06-30T12:04:24Z", "author": {"login": "tveasey"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;\n+                    LOGGER.info(\n+                        \"[{}] finished stored trained model definition chunks with id [{}]\",\n+                        analytics.getId(),\n+                        this.currentModelId.get());\n+                    auditor.info(analytics.getId(), \"Stored trained model with id [\" + this.currentModelId.get() + \"]\");\n+                    CountDownLatch refreshLatch = new CountDownLatch(1);\n+                    provider.refreshInferenceIndex(\n+                        new LatchedActionListener<>(ActionListener.wrap(\n+                            refreshResponse -> LOGGER.debug(() -> new ParameterizedMessage(\n+                                \"[{}] refreshed inference index after model store\",\n+                                analytics.getId()\n+                            )),\n+                            e -> LOGGER.warn(\"[{}] failed to refresh inference index after model store\", analytics.getId())),\n+                            refreshLatch));\n+                    try {\n+                        if (refreshLatch.await(30, TimeUnit.SECONDS) == false) {\n+                            LOGGER.error(\"[{}] Timed out (30s) waiting for index refresh\", analytics.getId());\n+                        }\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                }\n+            },\n+            e -> failureHandler.accept(ExceptionsHelper.serverError(\"error storing trained model definition chunk [{}] with id [{}]\", e,\n+                trainedModelDefinitionDoc.getModelId(), trainedModelDefinitionDoc.getDocNum()))\n+        );", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzcyMzM5NA==", "bodyText": "will do", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447723394", "createdAt": "2020-06-30T14:23:18Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;\n+                    LOGGER.info(\n+                        \"[{}] finished stored trained model definition chunks with id [{}]\",\n+                        analytics.getId(),\n+                        this.currentModelId.get());\n+                    auditor.info(analytics.getId(), \"Stored trained model with id [\" + this.currentModelId.get() + \"]\");\n+                    CountDownLatch refreshLatch = new CountDownLatch(1);\n+                    provider.refreshInferenceIndex(\n+                        new LatchedActionListener<>(ActionListener.wrap(\n+                            refreshResponse -> LOGGER.debug(() -> new ParameterizedMessage(\n+                                \"[{}] refreshed inference index after model store\",\n+                                analytics.getId()\n+                            )),\n+                            e -> LOGGER.warn(\"[{}] failed to refresh inference index after model store\", analytics.getId())),\n+                            refreshLatch));\n+                    try {\n+                        if (refreshLatch.await(30, TimeUnit.SECONDS) == false) {\n+                            LOGGER.error(\"[{}] Timed out (30s) waiting for index refresh\", analytics.getId());\n+                        }\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                }\n+            },\n+            e -> failureHandler.accept(ExceptionsHelper.serverError(\"error storing trained model definition chunk [{}] with id [{}]\", e,\n+                trainedModelDefinitionDoc.getModelId(), trainedModelDefinitionDoc.getDocNum()))\n+        );", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYyOTc1Ng=="}, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 116}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4OTkwMzAyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/internalClusterTest/java/org/elasticsearch/xpack/ml/integration/ChunkedTrainedMoodelPersisterIT.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMjowNTo1M1rOGq5NBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxNDoyMjo1NFrOGq-2ZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYzMDU5Nw==", "bodyText": "FYI you can achieve the same with integer maths\n(str.length() + chunkSize -1) / chunkSize", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447630597", "createdAt": "2020-06-30T12:05:53Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/internalClusterTest/java/org/elasticsearch/xpack/ml/integration/ChunkedTrainedMoodelPersisterIT.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.integration;\n+\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.action.util.PageParams;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsDest;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsSource;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.MlInferenceNamedXContentProvider;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinition;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinitionTests;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInputTests;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.TargetType;\n+import org.elasticsearch.xpack.ml.MlSingleNodeTestCase;\n+import org.elasticsearch.xpack.ml.dataframe.process.ChunkedTrainedModelPersister;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.DocValueField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.inference.modelsize.MlModelSizeNamedXContentProvider;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfoTests;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+import org.junit.Before;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Set;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+\n+public class ChunkedTrainedMoodelPersisterIT extends MlSingleNodeTestCase {\n+\n+    private TrainedModelProvider trainedModelProvider;\n+\n+    @Before\n+    public void createComponents() throws Exception {\n+        trainedModelProvider = new TrainedModelProvider(client(), xContentRegistry());\n+        waitForMlTemplates();\n+    }\n+\n+    public void testStoreModelViaChunkedPersister() throws IOException {\n+        String modelId = \"stored-chunked-model\";\n+        DataFrameAnalyticsConfig analyticsConfig = new DataFrameAnalyticsConfig.Builder()\n+            .setId(modelId)\n+            .setSource(new DataFrameAnalyticsSource(new String[] {\"my_source\"}, null, null))\n+            .setDest(new DataFrameAnalyticsDest(\"my_dest\", null))\n+            .setAnalysis(new Regression(\"foo\"))\n+            .build();\n+        List<ExtractedField> extractedFieldList = Collections.singletonList(new DocValueField(\"foo\", Collections.emptySet()));\n+        TrainedModelConfig.Builder configBuilder = buildTrainedModelConfigBuilder(modelId);\n+        String compressedDefinition = configBuilder.build().getCompressedDefinition();\n+        int totalSize = compressedDefinition.length();\n+        List<String> chunks = chunkStringWithSize(compressedDefinition, totalSize/3);\n+\n+        ChunkedTrainedModelPersister persister = new ChunkedTrainedModelPersister(trainedModelProvider,\n+            analyticsConfig,\n+            new DataFrameAnalyticsAuditor(client(), \"test-node\"),\n+            (ex) -> { throw new ElasticsearchException(ex); },\n+            new ExtractedFields(extractedFieldList, Collections.emptyMap())\n+        );\n+\n+        //Accuracy for size is not tested here\n+        ModelSizeInfo modelSizeInfo = ModelSizeInfoTests.createRandom();\n+        persister.createAndIndexInferenceModelMetadata(modelSizeInfo);\n+        for (int i = 0; i < chunks.size(); i++) {\n+            persister.createAndIndexInferenceModelDoc(new TrainedModelDefinitionChunk(chunks.get(i), i, i == (chunks.size() - 1)));\n+        }\n+\n+        PlainActionFuture<Tuple<Long, Set<String>>> getIdsFuture = new PlainActionFuture<>();\n+        trainedModelProvider.expandIds(modelId + \"*\", false, PageParams.defaultParams(), Collections.emptySet(), getIdsFuture);\n+        Tuple<Long, Set<String>> ids = getIdsFuture.actionGet();\n+        assertThat(ids.v1(), equalTo(1L));\n+\n+        PlainActionFuture<TrainedModelConfig> getTrainedModelFuture = new PlainActionFuture<>();\n+        trainedModelProvider.getTrainedModel(ids.v2().iterator().next(), true, getTrainedModelFuture);\n+\n+        TrainedModelConfig storedConfig = getTrainedModelFuture.actionGet();\n+        assertThat(storedConfig.getCompressedDefinition(), equalTo(compressedDefinition));\n+        assertThat(storedConfig.getEstimatedOperations(), equalTo((long)modelSizeInfo.numOperations()));\n+        assertThat(storedConfig.getEstimatedHeapMemory(), equalTo(modelSizeInfo.ramBytesUsed()));\n+    }\n+\n+    private static TrainedModelConfig.Builder buildTrainedModelConfigBuilder(String modelId) {\n+        TrainedModelDefinition.Builder definitionBuilder = TrainedModelDefinitionTests.createRandomBuilder();\n+        long bytesUsed = definitionBuilder.build().ramBytesUsed();\n+        long operations = definitionBuilder.build().getTrainedModel().estimatedNumOperations();\n+        return TrainedModelConfig.builder()\n+            .setCreatedBy(\"ml_test\")\n+            .setParsedDefinition(TrainedModelDefinitionTests.createRandomBuilder(TargetType.REGRESSION))\n+            .setDescription(\"trained model config for test\")\n+            .setModelId(modelId)\n+            .setVersion(Version.CURRENT)\n+            .setLicenseLevel(License.OperationMode.PLATINUM.description())\n+            .setEstimatedHeapMemory(bytesUsed)\n+            .setEstimatedOperations(operations)\n+            .setInput(TrainedModelInputTests.createRandomInput());\n+    }\n+\n+    private static List<String> chunkStringWithSize(String str, int chunkSize) {\n+        List<String> subStrings = new ArrayList<>((int)Math.ceil(str.length()/(double)chunkSize));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzcyMzEwOA==", "bodyText": "will change it :)", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447723108", "createdAt": "2020-06-30T14:22:54Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/internalClusterTest/java/org/elasticsearch/xpack/ml/integration/ChunkedTrainedMoodelPersisterIT.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.integration;\n+\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.action.util.PageParams;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsDest;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsSource;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.MlInferenceNamedXContentProvider;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinition;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinitionTests;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInputTests;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.TargetType;\n+import org.elasticsearch.xpack.ml.MlSingleNodeTestCase;\n+import org.elasticsearch.xpack.ml.dataframe.process.ChunkedTrainedModelPersister;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.DocValueField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.inference.modelsize.MlModelSizeNamedXContentProvider;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfoTests;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+import org.junit.Before;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Set;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+\n+public class ChunkedTrainedMoodelPersisterIT extends MlSingleNodeTestCase {\n+\n+    private TrainedModelProvider trainedModelProvider;\n+\n+    @Before\n+    public void createComponents() throws Exception {\n+        trainedModelProvider = new TrainedModelProvider(client(), xContentRegistry());\n+        waitForMlTemplates();\n+    }\n+\n+    public void testStoreModelViaChunkedPersister() throws IOException {\n+        String modelId = \"stored-chunked-model\";\n+        DataFrameAnalyticsConfig analyticsConfig = new DataFrameAnalyticsConfig.Builder()\n+            .setId(modelId)\n+            .setSource(new DataFrameAnalyticsSource(new String[] {\"my_source\"}, null, null))\n+            .setDest(new DataFrameAnalyticsDest(\"my_dest\", null))\n+            .setAnalysis(new Regression(\"foo\"))\n+            .build();\n+        List<ExtractedField> extractedFieldList = Collections.singletonList(new DocValueField(\"foo\", Collections.emptySet()));\n+        TrainedModelConfig.Builder configBuilder = buildTrainedModelConfigBuilder(modelId);\n+        String compressedDefinition = configBuilder.build().getCompressedDefinition();\n+        int totalSize = compressedDefinition.length();\n+        List<String> chunks = chunkStringWithSize(compressedDefinition, totalSize/3);\n+\n+        ChunkedTrainedModelPersister persister = new ChunkedTrainedModelPersister(trainedModelProvider,\n+            analyticsConfig,\n+            new DataFrameAnalyticsAuditor(client(), \"test-node\"),\n+            (ex) -> { throw new ElasticsearchException(ex); },\n+            new ExtractedFields(extractedFieldList, Collections.emptyMap())\n+        );\n+\n+        //Accuracy for size is not tested here\n+        ModelSizeInfo modelSizeInfo = ModelSizeInfoTests.createRandom();\n+        persister.createAndIndexInferenceModelMetadata(modelSizeInfo);\n+        for (int i = 0; i < chunks.size(); i++) {\n+            persister.createAndIndexInferenceModelDoc(new TrainedModelDefinitionChunk(chunks.get(i), i, i == (chunks.size() - 1)));\n+        }\n+\n+        PlainActionFuture<Tuple<Long, Set<String>>> getIdsFuture = new PlainActionFuture<>();\n+        trainedModelProvider.expandIds(modelId + \"*\", false, PageParams.defaultParams(), Collections.emptySet(), getIdsFuture);\n+        Tuple<Long, Set<String>> ids = getIdsFuture.actionGet();\n+        assertThat(ids.v1(), equalTo(1L));\n+\n+        PlainActionFuture<TrainedModelConfig> getTrainedModelFuture = new PlainActionFuture<>();\n+        trainedModelProvider.getTrainedModel(ids.v2().iterator().next(), true, getTrainedModelFuture);\n+\n+        TrainedModelConfig storedConfig = getTrainedModelFuture.actionGet();\n+        assertThat(storedConfig.getCompressedDefinition(), equalTo(compressedDefinition));\n+        assertThat(storedConfig.getEstimatedOperations(), equalTo((long)modelSizeInfo.numOperations()));\n+        assertThat(storedConfig.getEstimatedHeapMemory(), equalTo(modelSizeInfo.ramBytesUsed()));\n+    }\n+\n+    private static TrainedModelConfig.Builder buildTrainedModelConfigBuilder(String modelId) {\n+        TrainedModelDefinition.Builder definitionBuilder = TrainedModelDefinitionTests.createRandomBuilder();\n+        long bytesUsed = definitionBuilder.build().ramBytesUsed();\n+        long operations = definitionBuilder.build().getTrainedModel().estimatedNumOperations();\n+        return TrainedModelConfig.builder()\n+            .setCreatedBy(\"ml_test\")\n+            .setParsedDefinition(TrainedModelDefinitionTests.createRandomBuilder(TargetType.REGRESSION))\n+            .setDescription(\"trained model config for test\")\n+            .setModelId(modelId)\n+            .setVersion(Version.CURRENT)\n+            .setLicenseLevel(License.OperationMode.PLATINUM.description())\n+            .setEstimatedHeapMemory(bytesUsed)\n+            .setEstimatedOperations(operations)\n+            .setInput(TrainedModelInputTests.createRandomInput());\n+    }\n+\n+    private static List<String> chunkStringWithSize(String str, int chunkSize) {\n+        List<String> subStrings = new ArrayList<>((int)Math.ceil(str.length()/(double)chunkSize));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYzMDU5Nw=="}, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 115}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4OTk2NDc3OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersisterTests.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMjoyMjo0OVrOGq5ykQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxNDoyMzoxMlrOGq-3PQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY0MDIwOQ==", "bodyText": "Maybe I missed them, but I don't see any tests for missing or truncated state. Maybe worth testing these error cases?", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447640209", "createdAt": "2020-06-30T12:22:49Z", "author": {"login": "tveasey"}, "path": "x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersisterTests.java", "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsDest;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsSource;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.DocValueField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfoTests;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+import org.junit.Before;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Mockito;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.hamcrest.Matchers.contains;\n+import static org.hamcrest.Matchers.containsString;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasKey;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Matchers.eq;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+\n+public class ChunkedTrainedModelPersisterTests extends ESTestCase {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzcyMzMyNQ==", "bodyText": "The tests will be in the model provider test class. I will add one", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447723325", "createdAt": "2020-06-30T14:23:12Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersisterTests.java", "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsDest;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsSource;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.DocValueField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfoTests;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+import org.junit.Before;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Mockito;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.hamcrest.Matchers.contains;\n+import static org.hamcrest.Matchers.containsString;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasKey;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Matchers.eq;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+\n+public class ChunkedTrainedModelPersisterTests extends ESTestCase {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY0MDIwOQ=="}, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5MDAxNTEwOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMjozNzowM1rOGq6R3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMjozNzowM1rOGq6R3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY0ODIyMA==", "bodyText": "Log the exception also\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                        refreshLatch));\n          \n          \n            \n            e -> LOGGER.warn(\"new ParameterizedMessage([{}] failed to refresh inference index after model store\", analytics.getId()), e),", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447648220", "createdAt": "2020-06-30T12:37:03Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;\n+                    LOGGER.info(\n+                        \"[{}] finished stored trained model definition chunks with id [{}]\",\n+                        analytics.getId(),\n+                        this.currentModelId.get());\n+                    auditor.info(analytics.getId(), \"Stored trained model with id [\" + this.currentModelId.get() + \"]\");\n+                    CountDownLatch refreshLatch = new CountDownLatch(1);\n+                    provider.refreshInferenceIndex(\n+                        new LatchedActionListener<>(ActionListener.wrap(\n+                            refreshResponse -> LOGGER.debug(() -> new ParameterizedMessage(\n+                                \"[{}] refreshed inference index after model store\",\n+                                analytics.getId()\n+                            )),\n+                            e -> LOGGER.warn(\"[{}] failed to refresh inference index after model store\", analytics.getId())),\n+                            refreshLatch));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 104}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5MDA1OTgyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMjo0ODo0OFrOGq6tuA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxNDoyMTo1NlrOGq-zZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY1NTM1Mg==", "bodyText": "The log level shouldn't be any higher than debug.\nSame for the finished stored trained model definition chunks with id  message above", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447655352", "createdAt": "2020-06-30T12:48:48Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;\n+                    LOGGER.info(\n+                        \"[{}] finished stored trained model definition chunks with id [{}]\",\n+                        analytics.getId(),\n+                        this.currentModelId.get());\n+                    auditor.info(analytics.getId(), \"Stored trained model with id [\" + this.currentModelId.get() + \"]\");\n+                    CountDownLatch refreshLatch = new CountDownLatch(1);\n+                    provider.refreshInferenceIndex(\n+                        new LatchedActionListener<>(ActionListener.wrap(\n+                            refreshResponse -> LOGGER.debug(() -> new ParameterizedMessage(\n+                                \"[{}] refreshed inference index after model store\",\n+                                analytics.getId()\n+                            )),\n+                            e -> LOGGER.warn(\"[{}] failed to refresh inference index after model store\", analytics.getId())),\n+                            refreshLatch));\n+                    try {\n+                        if (refreshLatch.await(30, TimeUnit.SECONDS) == false) {\n+                            LOGGER.error(\"[{}] Timed out (30s) waiting for index refresh\", analytics.getId());\n+                        }\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                }\n+            },\n+            e -> failureHandler.accept(ExceptionsHelper.serverError(\"error storing trained model definition chunk [{}] with id [{}]\", e,\n+                trainedModelDefinitionDoc.getModelId(), trainedModelDefinitionDoc.getDocNum()))\n+        );\n+        provider.storeTrainedModelDefinitionDoc(trainedModelDefinitionDoc, new LatchedActionListener<>(storeListener, latch));\n+        try {\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for chunked inference definition to be stored\", analytics.getId());\n+            }\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            failureHandler.accept(ExceptionsHelper.serverError(\"interrupted waiting for chunked inference definition to be stored\"));\n+        }\n+    }\n+\n+    public void createAndIndexInferenceModelMetadata(ModelSizeInfo inferenceModelSize) {\n+        if (readyToStoreNewModel == false) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"new inference model is attempting to be stored before completion previous model storage\"\n+            ));\n+            return;\n+        }\n+        TrainedModelConfig trainedModelConfig = createTrainedModelConfig(inferenceModelSize);\n+        CountDownLatch latch = storeTrainedModelMetadata(trainedModelConfig);\n+        try {\n+            readyToStoreNewModel = false;\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for inference model metadata to be stored\", analytics.getId());\n+            }\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            failureHandler.accept(ExceptionsHelper.serverError(\"interrupted waiting for inference model metadata to be stored\"));\n+        }\n+    }\n+\n+    private CountDownLatch storeTrainedModelMetadata(TrainedModelConfig trainedModelConfig) {\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Boolean> storeListener = ActionListener.wrap(\n+            aBoolean -> {\n+                if (aBoolean == false) {\n+                    LOGGER.error(\"[{}] Storing trained model metadata responded false\", analytics.getId());\n+                    failureHandler.accept(ExceptionsHelper.serverError(\"storing trained model responded false\"));\n+                } else {\n+                    LOGGER.info(\"[{}] Stored trained model metadata with id [{}]\", analytics.getId(), trainedModelConfig.getModelId());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 156}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY4NzYzMw==", "bodyText": "Ok the equivalent message before was logged at info but lets consider if this is necessary", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447687633", "createdAt": "2020-06-30T13:36:18Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;\n+                    LOGGER.info(\n+                        \"[{}] finished stored trained model definition chunks with id [{}]\",\n+                        analytics.getId(),\n+                        this.currentModelId.get());\n+                    auditor.info(analytics.getId(), \"Stored trained model with id [\" + this.currentModelId.get() + \"]\");\n+                    CountDownLatch refreshLatch = new CountDownLatch(1);\n+                    provider.refreshInferenceIndex(\n+                        new LatchedActionListener<>(ActionListener.wrap(\n+                            refreshResponse -> LOGGER.debug(() -> new ParameterizedMessage(\n+                                \"[{}] refreshed inference index after model store\",\n+                                analytics.getId()\n+                            )),\n+                            e -> LOGGER.warn(\"[{}] failed to refresh inference index after model store\", analytics.getId())),\n+                            refreshLatch));\n+                    try {\n+                        if (refreshLatch.await(30, TimeUnit.SECONDS) == false) {\n+                            LOGGER.error(\"[{}] Timed out (30s) waiting for index refresh\", analytics.getId());\n+                        }\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                }\n+            },\n+            e -> failureHandler.accept(ExceptionsHelper.serverError(\"error storing trained model definition chunk [{}] with id [{}]\", e,\n+                trainedModelDefinitionDoc.getModelId(), trainedModelDefinitionDoc.getDocNum()))\n+        );\n+        provider.storeTrainedModelDefinitionDoc(trainedModelDefinitionDoc, new LatchedActionListener<>(storeListener, latch));\n+        try {\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for chunked inference definition to be stored\", analytics.getId());\n+            }\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            failureHandler.accept(ExceptionsHelper.serverError(\"interrupted waiting for chunked inference definition to be stored\"));\n+        }\n+    }\n+\n+    public void createAndIndexInferenceModelMetadata(ModelSizeInfo inferenceModelSize) {\n+        if (readyToStoreNewModel == false) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"new inference model is attempting to be stored before completion previous model storage\"\n+            ));\n+            return;\n+        }\n+        TrainedModelConfig trainedModelConfig = createTrainedModelConfig(inferenceModelSize);\n+        CountDownLatch latch = storeTrainedModelMetadata(trainedModelConfig);\n+        try {\n+            readyToStoreNewModel = false;\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for inference model metadata to be stored\", analytics.getId());\n+            }\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            failureHandler.accept(ExceptionsHelper.serverError(\"interrupted waiting for inference model metadata to be stored\"));\n+        }\n+    }\n+\n+    private CountDownLatch storeTrainedModelMetadata(TrainedModelConfig trainedModelConfig) {\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Boolean> storeListener = ActionListener.wrap(\n+            aBoolean -> {\n+                if (aBoolean == false) {\n+                    LOGGER.error(\"[{}] Storing trained model metadata responded false\", analytics.getId());\n+                    failureHandler.accept(ExceptionsHelper.serverError(\"storing trained model responded false\"));\n+                } else {\n+                    LOGGER.info(\"[{}] Stored trained model metadata with id [{}]\", analytics.getId(), trainedModelConfig.getModelId());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY1NTM1Mg=="}, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 156}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzcyMjM0MA==", "bodyText": "I am making the individual messages all DEBUG. But when EOS is read, I am logging that as INFO and simply stating that persistence has finished.", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447722340", "createdAt": "2020-06-30T14:21:56Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;\n+                    LOGGER.info(\n+                        \"[{}] finished stored trained model definition chunks with id [{}]\",\n+                        analytics.getId(),\n+                        this.currentModelId.get());\n+                    auditor.info(analytics.getId(), \"Stored trained model with id [\" + this.currentModelId.get() + \"]\");\n+                    CountDownLatch refreshLatch = new CountDownLatch(1);\n+                    provider.refreshInferenceIndex(\n+                        new LatchedActionListener<>(ActionListener.wrap(\n+                            refreshResponse -> LOGGER.debug(() -> new ParameterizedMessage(\n+                                \"[{}] refreshed inference index after model store\",\n+                                analytics.getId()\n+                            )),\n+                            e -> LOGGER.warn(\"[{}] failed to refresh inference index after model store\", analytics.getId())),\n+                            refreshLatch));\n+                    try {\n+                        if (refreshLatch.await(30, TimeUnit.SECONDS) == false) {\n+                            LOGGER.error(\"[{}] Timed out (30s) waiting for index refresh\", analytics.getId());\n+                        }\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                }\n+            },\n+            e -> failureHandler.accept(ExceptionsHelper.serverError(\"error storing trained model definition chunk [{}] with id [{}]\", e,\n+                trainedModelDefinitionDoc.getModelId(), trainedModelDefinitionDoc.getDocNum()))\n+        );\n+        provider.storeTrainedModelDefinitionDoc(trainedModelDefinitionDoc, new LatchedActionListener<>(storeListener, latch));\n+        try {\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for chunked inference definition to be stored\", analytics.getId());\n+            }\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            failureHandler.accept(ExceptionsHelper.serverError(\"interrupted waiting for chunked inference definition to be stored\"));\n+        }\n+    }\n+\n+    public void createAndIndexInferenceModelMetadata(ModelSizeInfo inferenceModelSize) {\n+        if (readyToStoreNewModel == false) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"new inference model is attempting to be stored before completion previous model storage\"\n+            ));\n+            return;\n+        }\n+        TrainedModelConfig trainedModelConfig = createTrainedModelConfig(inferenceModelSize);\n+        CountDownLatch latch = storeTrainedModelMetadata(trainedModelConfig);\n+        try {\n+            readyToStoreNewModel = false;\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for inference model metadata to be stored\", analytics.getId());\n+            }\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            failureHandler.accept(ExceptionsHelper.serverError(\"interrupted waiting for inference model metadata to be stored\"));\n+        }\n+    }\n+\n+    private CountDownLatch storeTrainedModelMetadata(TrainedModelConfig trainedModelConfig) {\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Boolean> storeListener = ActionListener.wrap(\n+            aBoolean -> {\n+                if (aBoolean == false) {\n+                    LOGGER.error(\"[{}] Storing trained model metadata responded false\", analytics.getId());\n+                    failureHandler.accept(ExceptionsHelper.serverError(\"storing trained model responded false\"));\n+                } else {\n+                    LOGGER.info(\"[{}] Stored trained model metadata with id [{}]\", analytics.getId(), trainedModelConfig.getModelId());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY1NTM1Mg=="}, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 156}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5MDIyMjk1OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMzoyNzo0MVrOGq8SWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxNDoyMjo0MFrOGq-1lg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY4MTExMw==", "bodyText": "Add a boolean parameter here to refresh the index when the last doc is indexed that way you don't have to call  provider.refreshInferenceIndex() in the listener", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447681113", "createdAt": "2020-06-30T13:27:41Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;\n+                    LOGGER.info(\n+                        \"[{}] finished stored trained model definition chunks with id [{}]\",\n+                        analytics.getId(),\n+                        this.currentModelId.get());\n+                    auditor.info(analytics.getId(), \"Stored trained model with id [\" + this.currentModelId.get() + \"]\");\n+                    CountDownLatch refreshLatch = new CountDownLatch(1);\n+                    provider.refreshInferenceIndex(\n+                        new LatchedActionListener<>(ActionListener.wrap(\n+                            refreshResponse -> LOGGER.debug(() -> new ParameterizedMessage(\n+                                \"[{}] refreshed inference index after model store\",\n+                                analytics.getId()\n+                            )),\n+                            e -> LOGGER.warn(\"[{}] failed to refresh inference index after model store\", analytics.getId())),\n+                            refreshLatch));\n+                    try {\n+                        if (refreshLatch.await(30, TimeUnit.SECONDS) == false) {\n+                            LOGGER.error(\"[{}] Timed out (30s) waiting for index refresh\", analytics.getId());\n+                        }\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                }\n+            },\n+            e -> failureHandler.accept(ExceptionsHelper.serverError(\"error storing trained model definition chunk [{}] with id [{}]\", e,\n+                trainedModelDefinitionDoc.getModelId(), trainedModelDefinitionDoc.getDocNum()))\n+        );\n+        provider.storeTrainedModelDefinitionDoc(trainedModelDefinitionDoc, new LatchedActionListener<>(storeListener, latch));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzcyMjkwMg==", "bodyText": "I am refactoring this so that the latched listener is the refresh listener and the provider listener always calls the refresh listener (with null when we don't refresh).", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447722902", "createdAt": "2020-06-30T14:22:40Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;\n+                    LOGGER.info(\n+                        \"[{}] finished stored trained model definition chunks with id [{}]\",\n+                        analytics.getId(),\n+                        this.currentModelId.get());\n+                    auditor.info(analytics.getId(), \"Stored trained model with id [\" + this.currentModelId.get() + \"]\");\n+                    CountDownLatch refreshLatch = new CountDownLatch(1);\n+                    provider.refreshInferenceIndex(\n+                        new LatchedActionListener<>(ActionListener.wrap(\n+                            refreshResponse -> LOGGER.debug(() -> new ParameterizedMessage(\n+                                \"[{}] refreshed inference index after model store\",\n+                                analytics.getId()\n+                            )),\n+                            e -> LOGGER.warn(\"[{}] failed to refresh inference index after model store\", analytics.getId())),\n+                            refreshLatch));\n+                    try {\n+                        if (refreshLatch.await(30, TimeUnit.SECONDS) == false) {\n+                            LOGGER.error(\"[{}] Timed out (30s) waiting for index refresh\", analytics.getId());\n+                        }\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                }\n+            },\n+            e -> failureHandler.accept(ExceptionsHelper.serverError(\"error storing trained model definition chunk [{}] with id [{}]\", e,\n+                trainedModelDefinitionDoc.getModelId(), trainedModelDefinitionDoc.getDocNum()))\n+        );\n+        provider.storeTrainedModelDefinitionDoc(trainedModelDefinitionDoc, new LatchedActionListener<>(storeListener, latch));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY4MTExMw=="}, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 117}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5MDM1NDY0OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/persistence/TrainedModelProvider.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMzo1NToxNVrOGq9jJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxNDoyMjo0NlrOGq-16A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzcwMTc5OA==", "bodyText": "Can the methods getTrainedModelForInference and getTrainedModel be refactored to avoid this duplication?", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447701798", "createdAt": "2020-06-30T13:55:15Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/persistence/TrainedModelProvider.java", "diffHunk": "@@ -363,10 +452,22 @@ public void getTrainedModel(final String modelId, final boolean includeDefinitio\n                         String compressedString = docs.stream()\n                             .map(TrainedModelDefinitionDoc::getCompressedString)\n                             .collect(Collectors.joining());\n-                        if (compressedString.length() != docs.get(0).getTotalDefinitionLength()) {\n-                            listener.onFailure(ExceptionsHelper.serverError(\n-                                Messages.getMessage(Messages.MODEL_DEFINITION_TRUNCATED, modelId)));\n-                            return;\n+                        // BWC for when we tracked the total definition length\n+                        // TODO: remove in 9\n+                        if (docs.get(0).getTotalDefinitionLength() != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 149}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzcyMjk4NA==", "bodyText": "definitely", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447722984", "createdAt": "2020-06-30T14:22:46Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/persistence/TrainedModelProvider.java", "diffHunk": "@@ -363,10 +452,22 @@ public void getTrainedModel(final String modelId, final boolean includeDefinitio\n                         String compressedString = docs.stream()\n                             .map(TrainedModelDefinitionDoc::getCompressedString)\n                             .collect(Collectors.joining());\n-                        if (compressedString.length() != docs.get(0).getTotalDefinitionLength()) {\n-                            listener.onFailure(ExceptionsHelper.serverError(\n-                                Messages.getMessage(Messages.MODEL_DEFINITION_TRUNCATED, modelId)));\n-                            return;\n+                        // BWC for when we tracked the total definition length\n+                        // TODO: remove in 9\n+                        if (docs.get(0).getTotalDefinitionLength() != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzcwMTc5OA=="}, "originalCommit": {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854"}, "originalPosition": 149}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5MDY0MzQ5OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxNDo1MzozN1rOGrAVqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxNDo1MzozN1rOGrAVqA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc0NzQ5Ng==", "bodyText": "Is this valid here? i.e. should you be allowing this to start storing new models before logging, etc. Seems like there is a race to reset the currentModelId.", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447747496", "createdAt": "2020-06-30T14:53:37Z", "author": {"login": "tveasey"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -135,29 +105,86 @@ public void createAndIndexInferenceModelMetadata(ModelSizeInfo inferenceModelSiz\n         TrainedModelConfig trainedModelConfig = createTrainedModelConfig(inferenceModelSize);\n         CountDownLatch latch = storeTrainedModelMetadata(trainedModelConfig);\n         try {\n-            readyToStoreNewModel = false;\n-            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+            if (latch.await(STORE_TIMEOUT_SEC, TimeUnit.SECONDS) == false) {\n                 LOGGER.error(\"[{}] Timed out (30s) waiting for inference model metadata to be stored\", analytics.getId());\n             }\n         } catch (InterruptedException e) {\n             Thread.currentThread().interrupt();\n+            this.readyToStoreNewModel.set(true);\n             failureHandler.accept(ExceptionsHelper.serverError(\"interrupted waiting for inference model metadata to be stored\"));\n         }\n     }\n \n+    private CountDownLatch storeTrainedModelDoc(TrainedModelDefinitionDoc trainedModelDefinitionDoc) {\n+        CountDownLatch latch = new CountDownLatch(1);\n+\n+        // Latch is attached to this action as it is the last one to execute.\n+        ActionListener<RefreshResponse> refreshListener = new LatchedActionListener<>(ActionListener.wrap(\n+            refreshed -> {\n+                if (refreshed != null) {\n+                    LOGGER.debug(() -> new ParameterizedMessage(\n+                        \"[{}] refreshed inference index after model store\",\n+                        analytics.getId()\n+                    ));\n+                }\n+            },\n+            e -> LOGGER.warn(\n+                new ParameterizedMessage(\"[{}] failed to refresh inference index after model store\", analytics.getId()),\n+                e)\n+        ), latch);\n+\n+        // First, store the model and refresh is necessary\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+                if (trainedModelDefinitionDoc.isEos() == false) {\n+                    refreshListener.onResponse(null);\n+                    return;\n+                }\n+                readyToStoreNewModel.set(true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b20fb0586874ab6bdd92e4ccda019245c25a708a"}, "originalPosition": 142}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5MzYwODMzOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/internalClusterTest/java/org/elasticsearch/xpack/ml/integration/TrainedModelProviderIT.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQwODozOToxNlrOGrcgeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQwODozOToxNlrOGrcgeQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODIwOTAxNw==", "bodyText": "IntStream.range is end exclusive so we will never get to i == chunks.size() - 1\nShould it be set to false as Eos is set on the last doc in the list in line 223", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r448209017", "createdAt": "2020-07-01T08:39:16Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/src/internalClusterTest/java/org/elasticsearch/xpack/ml/integration/TrainedModelProviderIT.java", "diffHunk": "@@ -195,6 +198,51 @@ public void testGetTruncatedModelDefinition() throws Exception {\n         assertThat(exceptionHolder.get().getMessage(), equalTo(Messages.getMessage(Messages.MODEL_DEFINITION_TRUNCATED, modelId)));\n     }\n \n+    public void testGetTruncatedModelDefinition() throws Exception {\n+        String modelId = \"test-get-truncated-model-config\";\n+        TrainedModelConfig config = buildTrainedModelConfig(modelId);\n+        AtomicReference<Boolean> putConfigHolder = new AtomicReference<>();\n+        AtomicReference<Exception> exceptionHolder = new AtomicReference<>();\n+\n+        blockingCall(listener -> trainedModelProvider.storeTrainedModel(config, listener), putConfigHolder, exceptionHolder);\n+        assertThat(putConfigHolder.get(), is(true));\n+        assertThat(exceptionHolder.get(), is(nullValue()));\n+\n+        List<String> chunks = chunkStringWithSize(config.getCompressedDefinition(), config.getCompressedDefinition().length()/3);\n+\n+        List<TrainedModelDefinitionDoc.Builder> docBuilders = IntStream.range(0, chunks.size() - 1)\n+            .mapToObj(i -> new TrainedModelDefinitionDoc.Builder()\n+                .setDocNum(i)\n+                .setCompressedString(chunks.get(i))\n+                .setCompressionVersion(TrainedModelConfig.CURRENT_DEFINITION_COMPRESSION_VERSION)\n+                .setDefinitionLength(chunks.get(i).length())\n+                .setEos(i == chunks.size() - 1)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "398d9f94f7e200f968f9f5411c690c62cd7bd711"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NDE4MjcxOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMTozMzozNVrOGriJLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMTozMzozNVrOGriJLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMwMTM1OQ==", "bodyText": "nit: now that STORE_TIMEOUT_SEC is a constant, the log message can use it as argument (in other places, too)", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r448301359", "createdAt": "2020-07-01T11:33:35Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.action.admin.indices.refresh.RefreshResponse;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private static final int STORE_TIMEOUT_SEC = 30;\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private final AtomicBoolean readyToStoreNewModel = new AtomicBoolean(true);\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = storeTrainedModelDoc(trainedModelDefinitionDoc);\n+        try {\n+            if (latch.await(STORE_TIMEOUT_SEC, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for chunked inference definition to be stored\", analytics.getId());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dc25e38cba9eee95b97c7952ef6a2c2efa9e394c"}, "originalPosition": 86}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NDIwOTYyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/results/TrainedModelDefinitionChunk.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMTo0Mjo0NlrOGriZ3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMTo0Mjo0NlrOGriZ3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMwNTYyOQ==", "bodyText": "do we need a 3rd state (null)?\nin code it looks like null and false are false.\nit seems simpler to me to use boolean and handle null as part of parsing", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r448305629", "createdAt": "2020-07-01T11:42:46Z", "author": {"login": "hendrikmuhs"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/results/TrainedModelDefinitionChunk.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process.results;\n+\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+\n+import java.io.IOException;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.optionalConstructorArg;\n+\n+public class TrainedModelDefinitionChunk implements ToXContentObject {\n+\n+    private static final ParseField DEFINITION = new ParseField(\"definition\");\n+    private static final ParseField DOC_NUM = new ParseField(\"doc_num\");\n+    private static final ParseField EOS = new ParseField(\"eos\");\n+\n+    public static final ConstructingObjectParser<TrainedModelDefinitionChunk, Void> PARSER = new ConstructingObjectParser<>(\n+        \"chunked_trained_model_definition\",\n+        a -> new TrainedModelDefinitionChunk((String) a[0], (Integer) a[1], (Boolean) a[2]));\n+\n+    static {\n+        PARSER.declareString(constructorArg(), DEFINITION);\n+        PARSER.declareInt(constructorArg(), DOC_NUM);\n+        PARSER.declareBoolean(optionalConstructorArg(), EOS);\n+    }\n+\n+    private final String definition;\n+    private final int docNum;\n+    private final Boolean eos;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dc25e38cba9eee95b97c7952ef6a2c2efa9e394c"}, "originalPosition": 40}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1713, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}