{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDEwNjE1OTc4", "number": 55918, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMTo0OTo1NFrOD3l1kA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMjoxMDo0NVrOD3mQEw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5NjE4MTkyOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMTo0OTo1NFrOGN7QLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMTo0OTo1NFrOGN7QLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzI1NTQ3MQ==", "bodyText": "7.6 always adds the versions to the repository data. If we don't find one here then there's no point in doing any IO because we know that the repository data was written by a version older than 7.6. We can simply go ahead and assume an old version and be done with things. I had to make this change here because I needed this method to work on the CS thread, but we can make it safely in all versions in fact. Loading the individual SnapshotInfo here was never necessary.", "url": "https://github.com/elastic/elasticsearch/pull/55918#discussion_r417255471", "createdAt": "2020-04-29T11:49:54Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java", "diffHunk": "@@ -1289,18 +1118,7 @@ public Version minCompatibleVersion(Version minNodeVersion, String repositoryNam\n                 assert repositoryData.shardGenerations().totalShards() == 0 :\n                     \"Saw shard generations [\" + repositoryData.shardGenerations() +\n                         \"] but did not have versions tracked for snapshot [\" + snapshotId + \"]\";\n-                try {\n-                    final Version foundVersion = repository.getSnapshotInfo(snapshotId).version();\n-                    if (useShardGenerations(foundVersion) == false) {\n-                        // We don't really care about the exact version if its before 7.6 as the 7.5 metadata is the oldest we are able\n-                        // to write out so we stop iterating here and just use 7.5.0 as a placeholder.\n-                        return OLD_SNAPSHOT_FORMAT;\n-                    }\n-                    minCompatVersion = minCompatVersion.before(foundVersion) ? minCompatVersion : foundVersion;\n-                } catch (SnapshotMissingException e) {\n-                    logger.warn(\"Failed to load snapshot metadata, assuming repository is in old format\", e);\n-                    return OLD_SNAPSHOT_FORMAT;\n-                }\n+                return OLD_SNAPSHOT_FORMAT;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "273c21865cccfafc11c9344797e3403f0d70e5d7"}, "originalPosition": 516}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5NjIwNDMwOnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/snapshots/SnapshotResiliencyTests.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMTo1Njo0MVrOGN7dpQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMTo1Njo0MVrOGN7dpQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzI1ODkxNw==", "bodyText": "This is basically a revert of 93c6d77\nMaster fail-over would not lead to a failing snapshot response here with any observable frequency when we had the INIT state.\nIf the client (connected to a data node) lost the connection to the master node (because we disconnect the master temporarily in some runs), it would retry and the master meanwhile would have at the most made it to an INIT state in the CS (which the retry would simply ignore once a new master is elected). Now the first CS update will always be a STARTED state snapshot and a retry can again run into an in-progress snapshot.\nWe should fix clean retrying some other way (could do what we did for force merge UUIDs and generate the unique SnapshotId in the transport request already so that retries can know they're a retry). Since we haven't released 7.8 and this is a really minor UX win to revert here, I think this is an acceptable \"regression\".", "url": "https://github.com/elastic/elasticsearch/pull/55918#discussion_r417258917", "createdAt": "2020-04-29T11:56:41Z", "author": {"login": "original-brownbear"}, "path": "server/src/test/java/org/elasticsearch/snapshots/SnapshotResiliencyTests.java", "diffHunk": "@@ -840,7 +838,11 @@ public void run() {\n                                 scheduleNow(() -> testClusterNodes.stopNode(masterNode));\n                             }\n                             testClusterNodes.randomDataNodeSafe().client.admin().cluster().prepareCreateSnapshot(repoName, snapshotName)\n-                                .execute(snapshotStartedListener);\n+                                    .execute(ActionListener.wrap(() -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "273c21865cccfafc11c9344797e3403f0d70e5d7"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5NjIwOTgzOnYy", "diffSide": "LEFT", "path": "server/src/test/java/org/elasticsearch/discovery/SnapshotDisruptionIT.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMTo1ODoyOVrOGN7hIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMTo1ODoyOVrOGN7hIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzI1OTgwOQ==", "bodyText": "Obsolete :)", "url": "https://github.com/elastic/elasticsearch/pull/55918#discussion_r417259809", "createdAt": "2020-04-29T11:58:29Z", "author": {"login": "original-brownbear"}, "path": "server/src/test/java/org/elasticsearch/discovery/SnapshotDisruptionIT.java", "diffHunk": "@@ -74,84 +74,6 @@ protected Settings nodeSettings(int nodeOrdinal) {\n             .build();\n     }\n \n-    public void testDisruptionOnSnapshotInitialization() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "273c21865cccfafc11c9344797e3403f0d70e5d7"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5NjIyMDY0OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMjowMTo0NlrOGN7nvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMjowMTo0NlrOGN7nvw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzI2MTUwMw==", "bodyText": "Simplified this code a bit since we don't have to find the INIT entry in the existing state any longer and I felt like there was no point in pretending we would have more than one snapshot here yet when we don't have any such thing. Concurrent snapshot operations will need some bigger changes to this step anyway so the pretend loop is of no use yet.", "url": "https://github.com/elastic/elasticsearch/pull/55918#discussion_r417261503", "createdAt": "2020-04-29T12:01:46Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java", "diffHunk": "@@ -193,66 +196,71 @@ public ClusterState execute(ClusterState currentState) {\n                 // Fail if there are any concurrently running snapshots. The only exception to this being a snapshot in INIT state from a\n                 // previous master that we can simply ignore and remove from the cluster state because we would clean it up from the\n                 // cluster state anyway in #applyClusterState.\n-                if (snapshots != null && snapshots.entries().stream().anyMatch(entry ->\n-                    (entry.state() == State.INIT && initializingSnapshots.contains(entry.snapshot()) == false) == false)) {\n+                if (snapshots != null && snapshots.entries().stream().anyMatch(entry -> entry.state() != State.INIT)) {\n                     throw new ConcurrentSnapshotExecutionException(repositoryName, snapshotName, \" a snapshot is already running\");\n                 }\n                 // Store newSnapshot here to be processed in clusterStateProcessed\n-                indices = Arrays.asList(indexNameExpressionResolver.concreteIndexNames(currentState,\n+                List<String> indices = Arrays.asList(indexNameExpressionResolver.concreteIndexNames(currentState,\n                     request.indicesOptions(), request.indices()));\n                 logger.trace(\"[{}][{}] creating snapshot for indices [{}]\", repositoryName, snapshotName, indices);\n-                newSnapshot = new SnapshotsInProgress.Entry(\n-                    new Snapshot(repositoryName, snapshotId),\n-                    request.includeGlobalState(), request.partial(),\n-                    State.INIT,\n-                    Collections.emptyList(), // We'll resolve the list of indices when moving to the STARTED state in #beginSnapshot\n-                    threadPool.absoluteTimeInMillis(),\n-                    RepositoryData.UNKNOWN_REPO_GEN,\n-                    null,\n-                    userMeta, Version.CURRENT\n-                );\n-                initializingSnapshots.add(newSnapshot.snapshot());\n-                snapshots = new SnapshotsInProgress(newSnapshot);\n-                return ClusterState.builder(currentState).putCustom(SnapshotsInProgress.TYPE, snapshots).build();\n+\n+                final List<IndexId> indexIds = repositoryData.resolveNewIndices(indices);\n+                final Version version = minCompatibleVersion(\n+                        clusterService.state().nodes().getMinNodeVersion(), repositoryData, null);\n+                ImmutableOpenMap<ShardId, ShardSnapshotStatus> shards =\n+                        shards(currentState, indexIds, useShardGenerations(version), repositoryData);\n+                SnapshotsInProgress.Entry newEntry = null;\n+                if (request.partial() == false) {\n+                    Tuple<Set<String>, Set<String>> indicesWithMissingShards = indicesWithMissingShards(shards,\n+                            currentState.metadata());\n+                    Set<String> missing = indicesWithMissingShards.v1();\n+                    Set<String> closed = indicesWithMissingShards.v2();\n+                    if (missing.isEmpty() == false || closed.isEmpty() == false) {\n+                        final StringBuilder failureMessage = new StringBuilder();\n+                        if (missing.isEmpty() == false) {\n+                            failureMessage.append(\"Indices don't have primary shards \");\n+                            failureMessage.append(missing);\n+                        }\n+                        if (closed.isEmpty() == false) {\n+                            if (failureMessage.length() > 0) {\n+                                failureMessage.append(\"; \");\n+                            }\n+                            failureMessage.append(\"Indices are closed \");\n+                        }\n+                        // TODO: We should just throw here instead of creating a FAILED and hence useless snapshot in the repository\n+                        newEntry = new SnapshotsInProgress.Entry(\n+                                new Snapshot(repositoryName, snapshotId), request.includeGlobalState(), false,\n+                                State.FAILED, indexIds, threadPool.absoluteTimeInMillis(), repositoryData.getGenId(), shards,\n+                                failureMessage.toString(), userMeta, version);\n+                    }\n+                }\n+                if (newEntry == null) {\n+                    newEntry = new SnapshotsInProgress.Entry(\n+                            new Snapshot(repositoryName, snapshotId), request.includeGlobalState(), request.partial(),\n+                            State.STARTED, indexIds, threadPool.absoluteTimeInMillis(), repositoryData.getGenId(), shards,\n+                            null, userMeta, version);\n+                }\n+                return ClusterState.builder(currentState).putCustom(SnapshotsInProgress.TYPE,\n+                        new SnapshotsInProgress(List.of(newEntry))).build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "273c21865cccfafc11c9344797e3403f0d70e5d7"}, "originalPosition": 111}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5NjIyNDc0OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMjowMzoxMVrOGN7qaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQxMjoyODozM1rOGQnCUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzI2MjE4NQ==", "bodyText": "I didn't want to make this change here yet, but I think it's a valid change. It's entirely pointless to keep writing these snapshots to the repo. It's against the spirit of what partial == false means IMO and it adds nothing but an unused cluster state and a bunch of unused index metadata to the repo for no good reason.", "url": "https://github.com/elastic/elasticsearch/pull/55918#discussion_r417262185", "createdAt": "2020-04-29T12:03:11Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java", "diffHunk": "@@ -193,66 +196,71 @@ public ClusterState execute(ClusterState currentState) {\n                 // Fail if there are any concurrently running snapshots. The only exception to this being a snapshot in INIT state from a\n                 // previous master that we can simply ignore and remove from the cluster state because we would clean it up from the\n                 // cluster state anyway in #applyClusterState.\n-                if (snapshots != null && snapshots.entries().stream().anyMatch(entry ->\n-                    (entry.state() == State.INIT && initializingSnapshots.contains(entry.snapshot()) == false) == false)) {\n+                if (snapshots != null && snapshots.entries().stream().anyMatch(entry -> entry.state() != State.INIT)) {\n                     throw new ConcurrentSnapshotExecutionException(repositoryName, snapshotName, \" a snapshot is already running\");\n                 }\n                 // Store newSnapshot here to be processed in clusterStateProcessed\n-                indices = Arrays.asList(indexNameExpressionResolver.concreteIndexNames(currentState,\n+                List<String> indices = Arrays.asList(indexNameExpressionResolver.concreteIndexNames(currentState,\n                     request.indicesOptions(), request.indices()));\n                 logger.trace(\"[{}][{}] creating snapshot for indices [{}]\", repositoryName, snapshotName, indices);\n-                newSnapshot = new SnapshotsInProgress.Entry(\n-                    new Snapshot(repositoryName, snapshotId),\n-                    request.includeGlobalState(), request.partial(),\n-                    State.INIT,\n-                    Collections.emptyList(), // We'll resolve the list of indices when moving to the STARTED state in #beginSnapshot\n-                    threadPool.absoluteTimeInMillis(),\n-                    RepositoryData.UNKNOWN_REPO_GEN,\n-                    null,\n-                    userMeta, Version.CURRENT\n-                );\n-                initializingSnapshots.add(newSnapshot.snapshot());\n-                snapshots = new SnapshotsInProgress(newSnapshot);\n-                return ClusterState.builder(currentState).putCustom(SnapshotsInProgress.TYPE, snapshots).build();\n+\n+                final List<IndexId> indexIds = repositoryData.resolveNewIndices(indices);\n+                final Version version = minCompatibleVersion(\n+                        clusterService.state().nodes().getMinNodeVersion(), repositoryData, null);\n+                ImmutableOpenMap<ShardId, ShardSnapshotStatus> shards =\n+                        shards(currentState, indexIds, useShardGenerations(version), repositoryData);\n+                SnapshotsInProgress.Entry newEntry = null;\n+                if (request.partial() == false) {\n+                    Tuple<Set<String>, Set<String>> indicesWithMissingShards = indicesWithMissingShards(shards,\n+                            currentState.metadata());\n+                    Set<String> missing = indicesWithMissingShards.v1();\n+                    Set<String> closed = indicesWithMissingShards.v2();\n+                    if (missing.isEmpty() == false || closed.isEmpty() == false) {\n+                        final StringBuilder failureMessage = new StringBuilder();\n+                        if (missing.isEmpty() == false) {\n+                            failureMessage.append(\"Indices don't have primary shards \");\n+                            failureMessage.append(missing);\n+                        }\n+                        if (closed.isEmpty() == false) {\n+                            if (failureMessage.length() > 0) {\n+                                failureMessage.append(\"; \");\n+                            }\n+                            failureMessage.append(\"Indices are closed \");\n+                        }\n+                        // TODO: We should just throw here instead of creating a FAILED and hence useless snapshot in the repository", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "273c21865cccfafc11c9344797e3403f0d70e5d7"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDA2OTk2OA==", "bodyText": "As discussed this morning we may want to validate this point with Cloud as it is useful to know which snapshot have failed. Besides this I can't remember any valid reason to write FAILED snapshot into the repository if the snapshot did not even start.", "url": "https://github.com/elastic/elasticsearch/pull/55918#discussion_r420069968", "createdAt": "2020-05-05T12:28:33Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java", "diffHunk": "@@ -193,66 +196,71 @@ public ClusterState execute(ClusterState currentState) {\n                 // Fail if there are any concurrently running snapshots. The only exception to this being a snapshot in INIT state from a\n                 // previous master that we can simply ignore and remove from the cluster state because we would clean it up from the\n                 // cluster state anyway in #applyClusterState.\n-                if (snapshots != null && snapshots.entries().stream().anyMatch(entry ->\n-                    (entry.state() == State.INIT && initializingSnapshots.contains(entry.snapshot()) == false) == false)) {\n+                if (snapshots != null && snapshots.entries().stream().anyMatch(entry -> entry.state() != State.INIT)) {\n                     throw new ConcurrentSnapshotExecutionException(repositoryName, snapshotName, \" a snapshot is already running\");\n                 }\n                 // Store newSnapshot here to be processed in clusterStateProcessed\n-                indices = Arrays.asList(indexNameExpressionResolver.concreteIndexNames(currentState,\n+                List<String> indices = Arrays.asList(indexNameExpressionResolver.concreteIndexNames(currentState,\n                     request.indicesOptions(), request.indices()));\n                 logger.trace(\"[{}][{}] creating snapshot for indices [{}]\", repositoryName, snapshotName, indices);\n-                newSnapshot = new SnapshotsInProgress.Entry(\n-                    new Snapshot(repositoryName, snapshotId),\n-                    request.includeGlobalState(), request.partial(),\n-                    State.INIT,\n-                    Collections.emptyList(), // We'll resolve the list of indices when moving to the STARTED state in #beginSnapshot\n-                    threadPool.absoluteTimeInMillis(),\n-                    RepositoryData.UNKNOWN_REPO_GEN,\n-                    null,\n-                    userMeta, Version.CURRENT\n-                );\n-                initializingSnapshots.add(newSnapshot.snapshot());\n-                snapshots = new SnapshotsInProgress(newSnapshot);\n-                return ClusterState.builder(currentState).putCustom(SnapshotsInProgress.TYPE, snapshots).build();\n+\n+                final List<IndexId> indexIds = repositoryData.resolveNewIndices(indices);\n+                final Version version = minCompatibleVersion(\n+                        clusterService.state().nodes().getMinNodeVersion(), repositoryData, null);\n+                ImmutableOpenMap<ShardId, ShardSnapshotStatus> shards =\n+                        shards(currentState, indexIds, useShardGenerations(version), repositoryData);\n+                SnapshotsInProgress.Entry newEntry = null;\n+                if (request.partial() == false) {\n+                    Tuple<Set<String>, Set<String>> indicesWithMissingShards = indicesWithMissingShards(shards,\n+                            currentState.metadata());\n+                    Set<String> missing = indicesWithMissingShards.v1();\n+                    Set<String> closed = indicesWithMissingShards.v2();\n+                    if (missing.isEmpty() == false || closed.isEmpty() == false) {\n+                        final StringBuilder failureMessage = new StringBuilder();\n+                        if (missing.isEmpty() == false) {\n+                            failureMessage.append(\"Indices don't have primary shards \");\n+                            failureMessage.append(missing);\n+                        }\n+                        if (closed.isEmpty() == false) {\n+                            if (failureMessage.length() > 0) {\n+                                failureMessage.append(\"; \");\n+                            }\n+                            failureMessage.append(\"Indices are closed \");\n+                        }\n+                        // TODO: We should just throw here instead of creating a FAILED and hence useless snapshot in the repository", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzI2MjE4NQ=="}, "originalCommit": {"oid": "273c21865cccfafc11c9344797e3403f0d70e5d7"}, "originalPosition": 97}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5NjI0NTMwOnYy", "diffSide": "LEFT", "path": "server/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMjowOToyM1rOGN72_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMjowOToyM1rOGN72_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzI2NTQwNw==", "bodyText": "No need to wait here anymore. If the snapshot was aborted during INIT, then that means it was already simply removed from the CS so no point in waiting here. This only made sense when we had the INIT state and would move INIT -> ABORT -> remove via https://github.com/elastic/elasticsearch/pull/55918/files#diff-a0853be4492c052f24917b5c1464003dL424 (or the apply CS method) which isn't a thing any longer without the INIT state.", "url": "https://github.com/elastic/elasticsearch/pull/55918#discussion_r417265407", "createdAt": "2020-04-29T12:09:23Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java", "diffHunk": "@@ -1111,12 +950,7 @@ public void clusterStateProcessed(String source, ClusterState oldState, ClusterS\n                                         result.v1().getGenId(), null, Priority.IMMEDIATE, listener));\n                     },\n                     e -> {\n-                        if (abortedDuringInit) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a87c679d669436160e9f774cd13195f78f9f3232"}, "originalPosition": 465}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5NjI0OTc5OnYy", "diffSide": "LEFT", "path": "server/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMjoxMDo0NVrOGN755w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMjoxMDo0NVrOGN755w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzI2NjE1MQ==", "bodyText": "This was only used to clean up INIT state snapshots", "url": "https://github.com/elastic/elasticsearch/pull/55918#discussion_r417266151", "createdAt": "2020-04-29T12:10:45Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java", "diffHunk": "@@ -296,172 +304,6 @@ private static void validate(final String repositoryName, final String snapshotN\n         }\n     }\n \n-    /**\n-     * Starts snapshot.\n-     * <p>\n-     * Creates snapshot in repository and updates snapshot metadata record with list of shards that needs to be processed.\n-     *\n-     * @param clusterState               cluster state\n-     * @param snapshot                   snapshot meta data\n-     * @param partial                    allow partial snapshots\n-     * @param userCreateSnapshotListener listener\n-     */\n-    private void beginSnapshot(final ClusterState clusterState,\n-                               final SnapshotsInProgress.Entry snapshot,\n-                               final boolean partial,\n-                               final List<String> indices,\n-                               final Repository repository,\n-                               final ActionListener<Snapshot> userCreateSnapshotListener) {\n-        threadPool.executor(ThreadPool.Names.SNAPSHOT).execute(new AbstractRunnable() {\n-\n-            boolean hadAbortedInitializations;\n-\n-            @Override\n-            protected void doRun() {\n-                assert initializingSnapshots.contains(snapshot.snapshot());\n-                if (repository.isReadOnly()) {\n-                    throw new RepositoryException(repository.getMetadata().name(), \"cannot create snapshot in a readonly repository\");\n-                }\n-                final String snapshotName = snapshot.snapshot().getSnapshotId().getName();\n-                final StepListener<RepositoryData> repositoryDataListener = new StepListener<>();\n-                repository.getRepositoryData(repositoryDataListener);\n-                repositoryDataListener.whenComplete(repositoryData -> {\n-                    // check if the snapshot name already exists in the repository\n-                    if (repositoryData.getSnapshotIds().stream().anyMatch(s -> s.getName().equals(snapshotName))) {\n-                        throw new InvalidSnapshotNameException(\n-                            repository.getMetadata().name(), snapshotName, \"snapshot with the same name already exists\");\n-                    }\n-\n-                    logger.info(\"snapshot [{}] started\", snapshot.snapshot());\n-                    final Version version =\n-                        minCompatibleVersion(clusterState.nodes().getMinNodeVersion(), snapshot.repository(), repositoryData, null);\n-                    if (indices.isEmpty()) {\n-                        // No indices in this snapshot - we are done\n-                        userCreateSnapshotListener.onResponse(snapshot.snapshot());\n-                        endSnapshot(new SnapshotsInProgress.Entry(\n-                            snapshot, State.STARTED, Collections.emptyList(), repositoryData.getGenId(), null, version,\n-                            null), clusterState.metadata());\n-                        return;\n-                    }\n-                    clusterService.submitStateUpdateTask(\"update_snapshot [\" + snapshot.snapshot() + \"]\", new ClusterStateUpdateTask() {\n-\n-                        @Override\n-                        public ClusterState execute(ClusterState currentState) {\n-                            SnapshotsInProgress snapshots = currentState.custom(SnapshotsInProgress.TYPE);\n-                            List<SnapshotsInProgress.Entry> entries = new ArrayList<>();\n-                            for (SnapshotsInProgress.Entry entry : snapshots.entries()) {\n-                                if (entry.snapshot().equals(snapshot.snapshot()) == false) {\n-                                    entries.add(entry);\n-                                    continue;\n-                                }\n-\n-                                if (entry.state() == State.ABORTED) {\n-                                    entries.add(entry);\n-                                    assert entry.shards().isEmpty();\n-                                    hadAbortedInitializations = true;\n-                                } else {\n-                                    final List<IndexId> indexIds = repositoryData.resolveNewIndices(indices);\n-                                    // Replace the snapshot that was just initialized\n-                                    ImmutableOpenMap<ShardId, ShardSnapshotStatus> shards =\n-                                        shards(currentState, indexIds, useShardGenerations(version), repositoryData);\n-                                    if (!partial) {\n-                                        Tuple<Set<String>, Set<String>> indicesWithMissingShards = indicesWithMissingShards(shards,\n-                                            currentState.metadata());\n-                                        Set<String> missing = indicesWithMissingShards.v1();\n-                                        Set<String> closed = indicesWithMissingShards.v2();\n-                                        if (missing.isEmpty() == false || closed.isEmpty() == false) {\n-                                            final StringBuilder failureMessage = new StringBuilder();\n-                                            if (missing.isEmpty() == false) {\n-                                                failureMessage.append(\"Indices don't have primary shards \");\n-                                                failureMessage.append(missing);\n-                                            }\n-                                            if (closed.isEmpty() == false) {\n-                                                if (failureMessage.length() > 0) {\n-                                                    failureMessage.append(\"; \");\n-                                                }\n-                                                failureMessage.append(\"Indices are closed \");\n-                                                failureMessage.append(closed);\n-                                            }\n-                                            entries.add(new SnapshotsInProgress.Entry(entry, State.FAILED, indexIds,\n-                                                repositoryData.getGenId(), shards, version, failureMessage.toString()));\n-                                            continue;\n-                                        }\n-                                    }\n-                                    entries.add(new SnapshotsInProgress.Entry(entry, State.STARTED, indexIds, repositoryData.getGenId(),\n-                                        shards, version, null));\n-                                }\n-                            }\n-                            return ClusterState.builder(currentState)\n-                                .putCustom(SnapshotsInProgress.TYPE, new SnapshotsInProgress(unmodifiableList(entries)))\n-                                .build();\n-                        }\n-\n-                        @Override\n-                        public void onFailure(String source, Exception e) {\n-                            logger.warn(() -> new ParameterizedMessage(\"[{}] failed to create snapshot\",\n-                                snapshot.snapshot().getSnapshotId()), e);\n-                            removeSnapshotFromClusterState(snapshot.snapshot(), e,\n-                                new CleanupAfterErrorListener(userCreateSnapshotListener, e));\n-                        }\n-\n-                        @Override\n-                        public void onNoLongerMaster(String source) {\n-                            // We are not longer a master - we shouldn't try to do any cleanup\n-                            // The new master will take care of it\n-                            logger.warn(\"[{}] failed to create snapshot - no longer a master\", snapshot.snapshot().getSnapshotId());\n-                            userCreateSnapshotListener.onFailure(\n-                                new SnapshotException(snapshot.snapshot(), \"master changed during snapshot initialization\"));\n-                        }\n-\n-                        @Override\n-                        public void clusterStateProcessed(String source, ClusterState oldState, ClusterState newState) {\n-                            // The userCreateSnapshotListener.onResponse() notifies caller that the snapshot was accepted\n-                            // for processing. If client wants to wait for the snapshot completion, it can register snapshot\n-                            // completion listener in this method. For the snapshot completion to work properly, the snapshot\n-                            // should still exist when listener is registered.\n-                            userCreateSnapshotListener.onResponse(snapshot.snapshot());\n-\n-                            if (hadAbortedInitializations) {\n-                                final SnapshotsInProgress snapshotsInProgress = newState.custom(SnapshotsInProgress.TYPE);\n-                                assert snapshotsInProgress != null;\n-                                final SnapshotsInProgress.Entry entry = snapshotsInProgress.snapshot(snapshot.snapshot());\n-                                assert entry != null;\n-                                endSnapshot(entry, newState.metadata());\n-                            }\n-                        }\n-                    });\n-                }, this::onFailure);\n-            }\n-\n-            @Override\n-            public void onFailure(Exception e) {\n-                logger.warn(() -> new ParameterizedMessage(\"failed to create snapshot [{}]\",\n-                    snapshot.snapshot().getSnapshotId()), e);\n-                removeSnapshotFromClusterState(snapshot.snapshot(), e,\n-                    new CleanupAfterErrorListener(userCreateSnapshotListener, e));\n-            }\n-        });\n-    }\n-\n-    private static class CleanupAfterErrorListener {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a87c679d669436160e9f774cd13195f78f9f3232"}, "originalPosition": 308}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2501, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}