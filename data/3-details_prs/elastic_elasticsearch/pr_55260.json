{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDAzOTM4MzU1", "number": 55260, "title": "[ML] partitions model definitions into chunks", "bodyText": "This paves the data layer way so that exceptionally large models are partitioned across multiple documents.\nThis change means that nodes before 7.8.0 will not be able to use trained inference models created on nodes on or after 7.8.0.\nI chose the definition document limit to be 100. This SHOULD be plenty for any large model. One of the largest models that I have created so far had the following stats:\n~314MB of inflated JSON, ~66MB when compressed, ~177MB of heap.\nWith the chunking sizes of 16 * 1024 * 1024 its compressed string could be partitioned to 5 documents.\nSupporting models 20 times this size (compressed) seems adequate for now.", "createdAt": "2020-04-15T19:10:14Z", "url": "https://github.com/elastic/elasticsearch/pull/55260", "merged": true, "mergeCommit": {"oid": "f72b2db29a41f4c10b8807beed1cca5bc4ea258b"}, "closed": true, "closedAt": "2020-04-20T19:13:24Z", "author": {"login": "benwtrent"}, "timelineItems": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcX8-fXAH2gAyNDAzOTM4MzU1OjM2NGIwZWRkYzg5NzE3YmZhZDQ4NDkzMmUzZjEzM2YxM2Y0ZmYxZWE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcZiJ4KgH2gAyNDAzOTM4MzU1OjU2MmUwYTQ1ZjQ1NmM2NmMzYjk3MGU5NmU2NDM0NmMyN2QwYjc0ZTc=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "364b0eddc89717bfad484932e3f133f13f4ff1ea", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/364b0eddc89717bfad484932e3f133f13f4ff1ea", "committedDate": "2020-04-15T19:08:54Z", "message": "[ML] partitions model definitions into chunks"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "532c236f76562c06e8eb44c7ced176936f34ee4a", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/532c236f76562c06e8eb44c7ced176936f34ee4a", "committedDate": "2020-04-16T11:52:30Z", "message": "add warning about bwc"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk2Mzk0OTIy", "url": "https://github.com/elastic/elasticsearch/pull/55260#pullrequestreview-396394922", "createdAt": "2020-04-20T12:12:09Z", "commit": {"oid": "532c236f76562c06e8eb44c7ced176936f34ee4a"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxMjoxMjoxMFrOGIRZuw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxMjo1MjozNFrOGIS7AA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTMyNjkwNw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            \"Creating a new model that all nodes are at least version [{}]\",\n          \n          \n            \n                            \"Creating a new model requires that all nodes are at least version [{}]\",", "url": "https://github.com/elastic/elasticsearch/pull/55260#discussion_r411326907", "createdAt": "2020-04-20T12:12:10Z", "author": {"login": "droberts195"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportPutTrainedModelAction.java", "diffHunk": "@@ -82,6 +82,15 @@ protected void masterOperation(Task task,\n                                    PutTrainedModelAction.Request request,\n                                    ClusterState state,\n                                    ActionListener<Response> listener) {\n+        // 7.8.0 introduced splitting the model definition across multiple documents.\n+        // This means that new models will not be usable on nodes that cannot handle multiple definition documents\n+        if (state.nodes().getMinNodeVersion().before(Version.V_7_8_0)) {\n+            listener.onFailure(ExceptionsHelper.badRequestException(\n+                \"Creating a new model that all nodes are at least version [{}]\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "532c236f76562c06e8eb44c7ced176936f34ee4a"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTMyODAzNQ==", "bodyText": "It should return here.", "url": "https://github.com/elastic/elasticsearch/pull/55260#discussion_r411328035", "createdAt": "2020-04-20T12:14:07Z", "author": {"login": "droberts195"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/persistence/TrainedModelProvider.java", "diffHunk": "@@ -138,30 +143,40 @@ public void storeTrainedModel(TrainedModelConfig trainedModelConfig,\n     private void storeTrainedModelAndDefinition(TrainedModelConfig trainedModelConfig,\n                                                 ActionListener<Boolean> listener) {\n \n-        TrainedModelDefinitionDoc trainedModelDefinitionDoc;\n+        List<TrainedModelDefinitionDoc> trainedModelDefinitionDocs = new ArrayList<>();\n         try {\n-            // TODO should we check length against allowed stream size???\n             String compressedString = trainedModelConfig.getCompressedDefinition();\n-            trainedModelDefinitionDoc = new TrainedModelDefinitionDoc.Builder()\n-                .setDocNum(0)\n-                .setModelId(trainedModelConfig.getModelId())\n-                .setCompressedString(compressedString)\n-                .setCompressionVersion(TrainedModelConfig.CURRENT_DEFINITION_COMPRESSION_VERSION)\n-                .setDefinitionLength(compressedString.length())\n-                .setTotalDefinitionLength(compressedString.length())\n-                .build();\n+            if (compressedString.length() > MAX_COMPRESSED_STRING_SIZE) {\n+                listener.onFailure(\n+                    ExceptionsHelper.badRequestException(\n+                        \"Unable to store model as compressed definition has length [{}] the limit is [{}]\",\n+                        compressedString.length(),\n+                        MAX_COMPRESSED_STRING_SIZE));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "532c236f76562c06e8eb44c7ced176936f34ee4a"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTM1MTgwOA==", "bodyText": "I am happy to merge this PR more-or-less as-is (see the two other minor comments I made).\nHowever, in the long term if we're expecting to deal with models whose compressed definition is of the order of a gigabyte then I think more optimisations will be needed.  For example:\n\nSuppose this method is dealing with a str of length 1000000000\nThat requires 2000000000 bytes to store as a UTF-16 String\nThen at the point this method returns every character has been copied into new strings but the original still exists so the memory usage at the point of return is over 4000000000 bytes\n\nSo we've gone from ~1GB of JSON model to temporarily using 4GB memory to manipulate it.\nSince the compressed model is Base64, if it was stored as UTF-8 then that would be 1 byte per character.  And if this was wrapped in a BytesReference instead of a String then the returned List<String> could be a List<BytesReference> where the raw data was not duplicated but just referenced in slices by the list elements.\nBasically, as we move from dealing with a few kilobytes of data to gigabytes we need to think much more about avoiding unnecessary duplication, most efficient character sets, etc.  But not in this PR, it can be done in a future one.", "url": "https://github.com/elastic/elasticsearch/pull/55260#discussion_r411351808", "createdAt": "2020-04-20T12:52:34Z", "author": {"login": "droberts195"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/persistence/TrainedModelProvider.java", "diffHunk": "@@ -677,13 +709,36 @@ private static QueryBuilder buildQueryIdExpressionQuery(String[] tokens, String\n     private static <T> T handleSearchItem(MultiSearchResponse.Item item,\n                                           String resourceId,\n                                           CheckedBiFunction<BytesReference, String, T, Exception> parseLeniently) throws Exception {\n+        return handleSearchItems(item, resourceId, parseLeniently).get(0);\n+    }\n+\n+    // NOTE: This ignores any results that are in a different index than the first one seen in the search response.\n+    private static <T> List<T> handleSearchItems(MultiSearchResponse.Item item,\n+                                                 String resourceId,\n+                                                 CheckedBiFunction<BytesReference, String, T, Exception> parseLeniently) throws Exception {\n         if (item.isFailure()) {\n             throw item.getFailure();\n         }\n         if (item.getResponse().getHits().getHits().length == 0) {\n             throw new ResourceNotFoundException(resourceId);\n         }\n-        return parseLeniently.apply(item.getResponse().getHits().getHits()[0].getSourceRef(), resourceId);\n+        List<T> results = new ArrayList<>(item.getResponse().getHits().getHits().length);\n+        String initialIndex = item.getResponse().getHits().getHits()[0].getIndex();\n+        for (SearchHit hit : item.getResponse().getHits().getHits()) {\n+            // We don't want to spread across multiple backing indices\n+            if (hit.getIndex().equals(initialIndex)) {\n+                results.add(parseLeniently.apply(hit.getSourceRef(), resourceId));\n+            }\n+        }\n+        return results;\n+    }\n+\n+    static List<String> chunkStringWithSize(String str, int chunkSize) {\n+        List<String> subStrings = new ArrayList<>((int)Math.ceil(str.length()/(double)chunkSize));\n+        for (int i = 0; i < str.length();i += chunkSize) {\n+            subStrings.add(str.substring(i, Math.min(i + chunkSize, str.length())));\n+        }\n+        return subStrings;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "532c236f76562c06e8eb44c7ced176936f34ee4a"}, "originalPosition": 208}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ac8a3fde0ffa55209cccb23cf5fb1c37d2516acf", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/ac8a3fde0ffa55209cccb23cf5fb1c37d2516acf", "committedDate": "2020-04-20T17:00:10Z", "message": "Merge branch 'master' into feature/ml-inference-split-inference-docs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "562e0a45f456c66c3b970e96e64346c27d0b74e7", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/562e0a45f456c66c3b970e96e64346c27d0b74e7", "committedDate": "2020-04-20T17:01:45Z", "message": "addressing PR comments"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3393, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}