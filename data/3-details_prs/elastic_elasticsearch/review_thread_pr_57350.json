{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI1MDQ2MzEz", "number": 57350, "reviewThreads": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxMToyNDo1OVrOEA2oCw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxNToxNjo0MlrOEA7stA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5MzMwNDQzOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxMToyNDo1OVrOGcY4iw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxMToyNDo1OVrOGcY4iw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjQyMTAwMw==", "bodyText": "Adjusted this because it's called more often now and translog.currentFileGeneration() actually does lock and create a ReleaseableLock instance", "url": "https://github.com/elastic/elasticsearch/pull/57350#discussion_r432421003", "createdAt": "2020-05-29T11:24:59Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "diffHunk": "@@ -485,11 +486,11 @@ private void recoverFromTranslogInternal(TranslogRecoveryRunner translogRecovery\n         // note: if opsRecovered == 0 and we have older translogs it means they are corrupted or 0 length.\n         assert pendingTranslogRecovery.get() : \"translogRecovery is not pending but should be\";\n         pendingTranslogRecovery.set(false); // we are good - now we can commit\n+        logger.trace(() -> new ParameterizedMessage(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "340b51b97685630b591dd5fc2cb0327aaded86f0"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5MzMwOTc1OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxMToyNjo1NVrOGcY73g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxMjozNjo1OFrOGca4AQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjQyMTg1NA==", "bodyText": "I kept this condition around the external refresh triggered here. Not sure if that optimization is necessary now to be honest, but removing it breaks a large number of unit tests that would now see two refreshes instead of one (since the flush also refreshes)", "url": "https://github.com/elastic/elasticsearch/pull/57350#discussion_r432421854", "createdAt": "2020-05-29T11:26:55Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "diffHunk": "@@ -485,11 +486,11 @@ private void recoverFromTranslogInternal(TranslogRecoveryRunner translogRecovery\n         // note: if opsRecovered == 0 and we have older translogs it means they are corrupted or 0 length.\n         assert pendingTranslogRecovery.get() : \"translogRecovery is not pending but should be\";\n         pendingTranslogRecovery.set(false); // we are good - now we can commit\n+        logger.trace(() -> new ParameterizedMessage(\n+                \"flushing post recovery from translog: ops recovered [{}], current translog generation [{}]\",\n+                opsRecovered, translog.currentFileGeneration()));\n+        flush(false, true);\n         if (opsRecovered > 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "340b51b97685630b591dd5fc2cb0327aaded86f0"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjQ0MzE0OQ==", "bodyText": "The refresh in the flush method is an internal refresh, not an external one. I don't think that the external refresh is actually necessary (we do the relevant refresh in IndexShard.postRecovery, which is called before moving the shard to started). What happens if you just remove the refresh call here?", "url": "https://github.com/elastic/elasticsearch/pull/57350#discussion_r432443149", "createdAt": "2020-05-29T12:16:01Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "diffHunk": "@@ -485,11 +486,11 @@ private void recoverFromTranslogInternal(TranslogRecoveryRunner translogRecovery\n         // note: if opsRecovered == 0 and we have older translogs it means they are corrupted or 0 length.\n         assert pendingTranslogRecovery.get() : \"translogRecovery is not pending but should be\";\n         pendingTranslogRecovery.set(false); // we are good - now we can commit\n+        logger.trace(() -> new ParameterizedMessage(\n+                \"flushing post recovery from translog: ops recovered [{}], current translog generation [{}]\",\n+                opsRecovered, translog.currentFileGeneration()));\n+        flush(false, true);\n         if (opsRecovered > 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjQyMTg1NA=="}, "originalCommit": {"oid": "340b51b97685630b591dd5fc2cb0327aaded86f0"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjQ1MzYzMw==", "bodyText": "It breaks a few tests that relied on the external refresh when recovering from translog, but it's a manageable number. I'll adjust those and run a few iterations of tests to make sure I didn't miss a spot.", "url": "https://github.com/elastic/elasticsearch/pull/57350#discussion_r432453633", "createdAt": "2020-05-29T12:36:58Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "diffHunk": "@@ -485,11 +486,11 @@ private void recoverFromTranslogInternal(TranslogRecoveryRunner translogRecovery\n         // note: if opsRecovered == 0 and we have older translogs it means they are corrupted or 0 length.\n         assert pendingTranslogRecovery.get() : \"translogRecovery is not pending but should be\";\n         pendingTranslogRecovery.set(false); // we are good - now we can commit\n+        logger.trace(() -> new ParameterizedMessage(\n+                \"flushing post recovery from translog: ops recovered [{}], current translog generation [{}]\",\n+                opsRecovered, translog.currentFileGeneration()));\n+        flush(false, true);\n         if (opsRecovered > 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjQyMTg1NA=="}, "originalCommit": {"oid": "340b51b97685630b591dd5fc2cb0327aaded86f0"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5MzMxMTkxOnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxMToyNzo0N1rOGcY9Og==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxMjo1NDowNFrOGcbamw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjQyMjIwMg==", "bodyText": "We discussed this on AoN, we're now potentially rolling the translog redundantly one additional time during flush.", "url": "https://github.com/elastic/elasticsearch/pull/57350#discussion_r432422202", "createdAt": "2020-05-29T11:27:47Z", "author": {"login": "original-brownbear"}, "path": "server/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java", "diffHunk": "@@ -1021,8 +1021,8 @@ private void finish() {\n                     assertNull(onFailure.get());\n                     assertThat(getTranslog(indexShard).getGeneration().translogFileGeneration,\n                         // if rollback happens we roll translog twice: one when we flush a commit before opening a read-only engine\n-                        // and one after replaying translog (upto the global checkpoint); otherwise we roll translog once.\n-                        either(equalTo(translogGen + 1)).or(equalTo(translogGen + 2)));\n+                        // and two or three times after replaying translog (upto the global checkpoint); otherwise we roll translog once.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "340b51b97685630b591dd5fc2cb0327aaded86f0"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjQyNTU5MQ==", "bodyText": "I looked at this, and think we can remove the redundant rollover with the following:\ndiff --cc server/src/main/java/org/elasticsearch/index/translog/Translog.java\nindex 0a8e38816fa,0a8e38816fa..60375d5b485\n--- a/server/src/main/java/org/elasticsearch/index/translog/Translog.java\n+++ b/server/src/main/java/org/elasticsearch/index/translog/Translog.java\n@@@ -1615,13 -1615,13 +1615,17 @@@ public class Translog extends AbstractI\n      }\n  \n      /**\n--     * Roll the current translog generation into a new generation. This does not commit the\n++     * Roll the current translog generation into a new generation if it's not empty. This does not commit the\n       * translog.\n       *\n       * @throws IOException if an I/O exception occurred during any file operations\n       */\n      public void rollGeneration() throws IOException {\n          syncBeforeRollGeneration();\n++        // no need to roll over when it's empty\n++        if (current.totalOperations() == 0) {\n++            return;\n++        }\n          try (Releasable ignored = writeLock.acquire()) {\n              ensureOpen();\n              try {\n\nThe reason we have the rollover in the first place is to make sue we no longer need to hold on to certain ops, or that we do not mix ops from different terms in the same generation. For  an empty translog generation, neither is necessary.", "url": "https://github.com/elastic/elasticsearch/pull/57350#discussion_r432425591", "createdAt": "2020-05-29T11:35:35Z", "author": {"login": "ywelsch"}, "path": "server/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java", "diffHunk": "@@ -1021,8 +1021,8 @@ private void finish() {\n                     assertNull(onFailure.get());\n                     assertThat(getTranslog(indexShard).getGeneration().translogFileGeneration,\n                         // if rollback happens we roll translog twice: one when we flush a commit before opening a read-only engine\n-                        // and one after replaying translog (upto the global checkpoint); otherwise we roll translog once.\n-                        either(equalTo(translogGen + 1)).or(equalTo(translogGen + 2)));\n+                        // and two or three times after replaying translog (upto the global checkpoint); otherwise we roll translog once.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjQyMjIwMg=="}, "originalCommit": {"oid": "340b51b97685630b591dd5fc2cb0327aaded86f0"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjQ2MjQ5MQ==", "bodyText": "This works fine I think. The only adjustment I had to make is to also check if the primary term is still in sync with the current writer in addition to the operations.", "url": "https://github.com/elastic/elasticsearch/pull/57350#discussion_r432462491", "createdAt": "2020-05-29T12:54:04Z", "author": {"login": "original-brownbear"}, "path": "server/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java", "diffHunk": "@@ -1021,8 +1021,8 @@ private void finish() {\n                     assertNull(onFailure.get());\n                     assertThat(getTranslog(indexShard).getGeneration().translogFileGeneration,\n                         // if rollback happens we roll translog twice: one when we flush a commit before opening a read-only engine\n-                        // and one after replaying translog (upto the global checkpoint); otherwise we roll translog once.\n-                        either(equalTo(translogGen + 1)).or(equalTo(translogGen + 2)));\n+                        // and two or three times after replaying translog (upto the global checkpoint); otherwise we roll translog once.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjQyMjIwMg=="}, "originalCommit": {"oid": "340b51b97685630b591dd5fc2cb0327aaded86f0"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5MzM5NzkyOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxMjowMDozMlrOGcZ0Hw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxMjo1NDo1M1rOGcbcPA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjQzNjI1NQ==", "bodyText": "This is very subtle, as the persisted local checkpoint is driven mainly by Translog fsyncing (even though both local checkpoints are initialized from what's in the safe commit), i.e. getPersistedLocalCheckpoint() means the local checkpoint last persisted by the translog, not Lucene. I'm inclined to instead use lastCommittedSegmentInfos.getUserData()... here and look at the actually last Lucene-persisted local checkpoint.", "url": "https://github.com/elastic/elasticsearch/pull/57350#discussion_r432436255", "createdAt": "2020-05-29T12:00:32Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "diffHunk": "@@ -1654,10 +1655,12 @@ public void flush(boolean force, boolean waitIfOngoing) throws EngineException {\n             }\n             try {\n                 // Only flush if (1) Lucene has uncommitted docs, or (2) forced by caller, or (3) the\n-                // newly created commit points to a different translog generation (can free translog)\n+                // newly created commit points to a different translog generation (can free translog),\n+                // or (4) the processed local checkpoint is ahead of the local checkpoint tracked in the safe commit\n                 boolean hasUncommittedChanges = indexWriter.hasUncommittedChanges();\n                 boolean shouldPeriodicallyFlush = shouldPeriodicallyFlush();\n-                if (hasUncommittedChanges || force || shouldPeriodicallyFlush) {\n+                if (hasUncommittedChanges || force || shouldPeriodicallyFlush\n+                        || getProcessedLocalCheckpoint() > getPersistedLocalCheckpoint()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "340b51b97685630b591dd5fc2cb0327aaded86f0"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjQ2MjkwOA==", "bodyText": "++ moved to reading it from the lastCommittedSegmentInfos", "url": "https://github.com/elastic/elasticsearch/pull/57350#discussion_r432462908", "createdAt": "2020-05-29T12:54:53Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "diffHunk": "@@ -1654,10 +1655,12 @@ public void flush(boolean force, boolean waitIfOngoing) throws EngineException {\n             }\n             try {\n                 // Only flush if (1) Lucene has uncommitted docs, or (2) forced by caller, or (3) the\n-                // newly created commit points to a different translog generation (can free translog)\n+                // newly created commit points to a different translog generation (can free translog),\n+                // or (4) the processed local checkpoint is ahead of the local checkpoint tracked in the safe commit\n                 boolean hasUncommittedChanges = indexWriter.hasUncommittedChanges();\n                 boolean shouldPeriodicallyFlush = shouldPeriodicallyFlush();\n-                if (hasUncommittedChanges || force || shouldPeriodicallyFlush) {\n+                if (hasUncommittedChanges || force || shouldPeriodicallyFlush\n+                        || getProcessedLocalCheckpoint() > getPersistedLocalCheckpoint()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjQzNjI1NQ=="}, "originalCommit": {"oid": "340b51b97685630b591dd5fc2cb0327aaded86f0"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5MzQwNDQwOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxMjowMzowNVrOGcZ4Qw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxMjowMzowNVrOGcZ4Qw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjQzNzMxNQ==", "bodyText": "It's unclear what the safe commit is in the case of calling this method. Instead I would say something along the lines of:\n// or (4) the local checkpoint information in the last commit is stale, which slows down future recoveries.", "url": "https://github.com/elastic/elasticsearch/pull/57350#discussion_r432437315", "createdAt": "2020-05-29T12:03:05Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "diffHunk": "@@ -1654,10 +1655,12 @@ public void flush(boolean force, boolean waitIfOngoing) throws EngineException {\n             }\n             try {\n                 // Only flush if (1) Lucene has uncommitted docs, or (2) forced by caller, or (3) the\n-                // newly created commit points to a different translog generation (can free translog)\n+                // newly created commit points to a different translog generation (can free translog),\n+                // or (4) the processed local checkpoint is ahead of the local checkpoint tracked in the safe commit", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "340b51b97685630b591dd5fc2cb0327aaded86f0"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5NDEzNTU2OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxNToxNjo0MlrOGchH0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxNToxNjo0MlrOGchH0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjU1NTk4NA==", "bodyText": "I am a bit concerned about the locking order inflush (readLock -> flushLock) and recoverFromTranslog (flushLock -> readLock). I think we can remove the flushLock in recoverFromTranslog as it's safe to flush during recovery.", "url": "https://github.com/elastic/elasticsearch/pull/57350#discussion_r432555984", "createdAt": "2020-05-29T15:16:42Z", "author": {"login": "dnhatn"}, "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "diffHunk": "@@ -485,13 +486,10 @@ private void recoverFromTranslogInternal(TranslogRecoveryRunner translogRecovery\n         // note: if opsRecovered == 0 and we have older translogs it means they are corrupted or 0 length.\n         assert pendingTranslogRecovery.get() : \"translogRecovery is not pending but should be\";\n         pendingTranslogRecovery.set(false); // we are good - now we can commit\n-        if (opsRecovered > 0) {\n-            logger.trace(\"flushing post recovery from translog: ops recovered [{}], current translog generation [{}]\",\n-                opsRecovered, translog.currentFileGeneration());\n-            commitIndexWriter(indexWriter, translog);\n-            refreshLastCommittedSegmentInfos();\n-            refresh(\"translog_recovery\");\n-        }\n+        logger.trace(() -> new ParameterizedMessage(\n+                \"flushing post recovery from translog: ops recovered [{}], current translog generation [{}]\",\n+                opsRecovered, translog.currentFileGeneration()));\n+        flush(false, true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "689a392977d91ce94a49a935e09fbc648d898901"}, "originalPosition": 22}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3887, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}