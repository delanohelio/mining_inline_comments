{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMyNzIyMTEz", "number": 57954, "title": "[DOCS] Reformat data streams intro and overview", "bodyText": "Changes:\n\n\nUpdates 'Data streams' intro page to focus on problem solution and\nbenefits.\n\n\nAdds 'Data streams overview' page to cover conceptual information,\nbased on existing content in the 'Data streams' intro.\n\n\nAdds diagrams for data streams and search/indexing request examples.\n\n\nMoves API jump list and API docs to a new 'Data streams APIs' page/section.\nLinks to these APIs will be available through tutorials.\n\n\nAdd xrefs to existing docs for concepts like generation, write index,\nand append-only.\n\n\nPreviews\nIntro page: https://elasticsearch_57954.docs-preview.app.elstc.co/guide/en/elasticsearch/reference/master/data-streams.html\nOverview page: https://elasticsearch_57954.docs-preview.app.elstc.co/guide/en/elasticsearch/reference/master/data-streams-overview.html\nData streams APIs page: https://elasticsearch_57954.docs-preview.app.elstc.co/guide/en/elasticsearch/reference/master/data-stream-apis.html", "createdAt": "2020-06-10T21:53:02Z", "url": "https://github.com/elastic/elasticsearch/pull/57954", "merged": true, "mergeCommit": {"oid": "30cc10d3ace0760e2bb22b30bee17ae1112727bc"}, "closed": true, "closedAt": "2020-06-11T15:17:22Z", "author": {"login": "jrodewig"}, "timelineItems": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcqAtKjAH2gAyNDMyNzIyMTEzOjE2NWU0MWNhNTkwYzJiZTQ2YTg2OGE2N2VjYWE4OTgxNWU4YTgxODA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcqPZZWgH2gAyNDMyNzIyMTEzOjFkYTA1YmQ2YWU5N2FkZmM1NWVmZGU2OWI5NjI2YTY0OTgyNTg0ZGM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "165e41ca590c2be46a868a67ecaa89815e8a8180", "author": {"user": {"login": "jrodewig", "name": "James Rodewig"}}, "url": "https://github.com/elastic/elasticsearch/commit/165e41ca590c2be46a868a67ecaa89815e8a8180", "committedDate": "2020-06-10T21:40:14Z", "message": "[DOCS] Reformat data streams intro and overview\n\nChanges:\n\n* Updates 'Data streams' intro page to focus on problem solution and\n  benefits.\n\n* Adds 'Data streams overview' page to cover conceptual information,\n  based on existing content in the 'Data streams' intro.\n\n* Adds diagrams for data streams and search/indexing request examples.\n\n* Moves API jump list and API docs to a new 'Data streams APIs' section.\n  Links to these APIs will be available through tutorials.\n\n* Add xrefs to existing docs for concepts like generation, write index,\n  and append-only."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b9f79cd0853b5bd79a72918f1af82bd7126aa0ee", "author": {"user": {"login": "jrodewig", "name": "James Rodewig"}}, "url": "https://github.com/elastic/elasticsearch/commit/b9f79cd0853b5bd79a72918f1af82bd7126aa0ee", "committedDate": "2020-06-10T22:27:37Z", "message": "patch"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "719e1b4ce979d03d50962cfe9b9e8b6b1c44a04f", "author": {"user": {"login": "jrodewig", "name": "James Rodewig"}}, "url": "https://github.com/elastic/elasticsearch/commit/719e1b4ce979d03d50962cfe9b9e8b6b1c44a04f", "committedDate": "2020-06-10T22:28:46Z", "message": "reorder"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7bb89f50412e46fb0c6058c1ad8486912b6cdf44", "author": {"user": {"login": "jrodewig", "name": "James Rodewig"}}, "url": "https://github.com/elastic/elasticsearch/commit/7bb89f50412e46fb0c6058c1ad8486912b6cdf44", "committedDate": "2020-06-10T22:33:14Z", "message": "reword"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4NDg5MjQ4", "url": "https://github.com/elastic/elasticsearch/pull/57954#pullrequestreview-428489248", "createdAt": "2020-06-10T23:12:07Z", "commit": {"oid": "7bb89f50412e46fb0c6058c1ad8486912b6cdf44"}, "state": "APPROVED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQyMzoxMjowN1rOGiJQpg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQyMzozNjozMVrOGiJsww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ1NjQ4Ng==", "bodyText": "It's a separate consideration whether to use a single data stream for time series data from multiple data sources or to use distinct data streams per source. For example, observability plans to use a separate data stream for each source. I think the salient point that you accurately make here is that storing a time series for all time in a single index is less efficient and cost-effective than splitting that same time series, whether from a single data source or many sources, across multiple time-based indices.", "url": "https://github.com/elastic/elasticsearch/pull/57954#discussion_r438456486", "createdAt": "2020-06-10T23:12:07Z", "author": {"login": "danhermann"}, "path": "docs/reference/data-streams/data-streams.asciidoc", "diffHunk": "@@ -1,67 +1,59 @@\n [[data-streams]]\n = Data streams\n+++++\n+<titleabbrev>Data streams</titleabbrev>\n+++++\n \n-[partintro]\n---\n-You can use data streams to index time-based data that's continuously generated.\n-A data stream groups indices from the same time-based data source.\n-A data stream tracks its indices, known as _backing indices_, using an ordered\n-list.\n+A _data stream_ is a convenient, scalable way to ingest, search, and manage\n+continuously generated time-series data.\n \n-A data stream's backing indices are <<index-hidden,hidden>>.\n-While all backing indices handle read requests, the most recently created\n-backing index is the data stream's only write index.  A data stream only\n-accepts <<docs-index_,index requests>> with `op_type` set to `create`. To update\n-or delete specific documents in a data stream, submit a <<docs-delete,delete>>\n-or <<docs-update,update>> API request to the backing index containing the\n-document.\n+Time-series data, such as logs, tends to grow over time, resulting in large\n+volumes of data. While using a single {es} index for each data source is\n+simpler, it is often more efficient and cost-effective to store a source's data\n+across multiple, time-based indices. Multiple indices let you move indices", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7bb89f50412e46fb0c6058c1ad8486912b6cdf44"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ1Njg0OA==", "bodyText": "Maybe replace \"less valuable data\" with \"less frequently queried data\"?", "url": "https://github.com/elastic/elasticsearch/pull/57954#discussion_r438456848", "createdAt": "2020-06-10T23:13:17Z", "author": {"login": "danhermann"}, "path": "docs/reference/data-streams/data-streams.asciidoc", "diffHunk": "@@ -1,67 +1,59 @@\n [[data-streams]]\n = Data streams\n+++++\n+<titleabbrev>Data streams</titleabbrev>\n+++++\n \n-[partintro]\n---\n-You can use data streams to index time-based data that's continuously generated.\n-A data stream groups indices from the same time-based data source.\n-A data stream tracks its indices, known as _backing indices_, using an ordered\n-list.\n+A _data stream_ is a convenient, scalable way to ingest, search, and manage\n+continuously generated time-series data.\n \n-A data stream's backing indices are <<index-hidden,hidden>>.\n-While all backing indices handle read requests, the most recently created\n-backing index is the data stream's only write index.  A data stream only\n-accepts <<docs-index_,index requests>> with `op_type` set to `create`. To update\n-or delete specific documents in a data stream, submit a <<docs-delete,delete>>\n-or <<docs-update,update>> API request to the backing index containing the\n-document.\n+Time-series data, such as logs, tends to grow over time, resulting in large\n+volumes of data. While using a single {es} index for each data source is\n+simpler, it is often more efficient and cost-effective to store a source's data\n+across multiple, time-based indices. Multiple indices let you move indices\n+containing older, less valuable data to less expensive hardware and delete", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7bb89f50412e46fb0c6058c1ad8486912b6cdf44"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ1OTIxMQ==", "bodyText": "In this image, I tend to read the graphics left to right which would imply that backing indices are numbered in descending order. I don't know if that's common, but if so, it would be better to show backing indices in increasing generation order from left to right.", "url": "https://github.com/elastic/elasticsearch/pull/57954#discussion_r438459211", "createdAt": "2020-06-10T23:21:04Z", "author": {"login": "danhermann"}, "path": "docs/reference/data-streams/data-streams-overview.asciidoc", "diffHunk": "@@ -0,0 +1,118 @@\n+[[data-streams-overview]]\n+== Data streams overview\n+++++\n+<titleabbrev>Overview</titleabbrev>\n+++++\n+\n+A data stream consists of one or more _backing indices_. Backing indices are\n+<<index-hidden,hidden>>, automatically-generated indices used to store a\n+stream's documents.\n+\n+image::images/data-streams/data-streams-diagram.svg[align=\"center\"]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7bb89f50412e46fb0c6058c1ad8486912b6cdf44"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ1OTM0Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              <<date,`date`>> or <<date_nanos,`date_nanos`>> field datatype and be\n          \n          \n            \n              <<date,`date`>> or <<date_nanos,`date_nanos`>> field datatype and must be", "url": "https://github.com/elastic/elasticsearch/pull/57954#discussion_r438459343", "createdAt": "2020-06-10T23:21:33Z", "author": {"login": "danhermann"}, "path": "docs/reference/data-streams/data-streams-overview.asciidoc", "diffHunk": "@@ -0,0 +1,118 @@\n+[[data-streams-overview]]\n+== Data streams overview\n+++++\n+<titleabbrev>Overview</titleabbrev>\n+++++\n+\n+A data stream consists of one or more _backing indices_. Backing indices are\n+<<index-hidden,hidden>>, automatically-generated indices used to store a\n+stream's documents.\n+\n+image::images/data-streams/data-streams-diagram.svg[align=\"center\"]\n+\n+The creation of a data stream requires an associated\n+<<indices-templates,composable template>>. This template acts as a blueprint for\n+the stream's backing indices. It contains:\n+\n+* A name or wildcard (`*`) pattern for the data stream.\n+\n+* The data stream's _timestamp field_. This field must be mapped as a\n+  <<date,`date`>> or <<date_nanos,`date_nanos`>> field datatype and be", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7bb89f50412e46fb0c6058c1ad8486912b6cdf44"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ2MjM0Mw==", "bodyText": "I believe we do allow indexing directly into backing indices that are not the write index so long as the op_type is not create. @martijnvg, can you confirm?\nEven if op_types other than create are permitted into older backing indices, they are allowed only to facilitate administrative workflows such as \"remove document containing personally-identifying information.\" Your larger point is correct that the typical use case for data streams is ingestion with op_type of \"create\" via the data stream name and those always go into the current write index.", "url": "https://github.com/elastic/elasticsearch/pull/57954#discussion_r438462343", "createdAt": "2020-06-10T23:31:43Z", "author": {"login": "danhermann"}, "path": "docs/reference/data-streams/data-streams-overview.asciidoc", "diffHunk": "@@ -0,0 +1,118 @@\n+[[data-streams-overview]]\n+== Data streams overview\n+++++\n+<titleabbrev>Overview</titleabbrev>\n+++++\n+\n+A data stream consists of one or more _backing indices_. Backing indices are\n+<<index-hidden,hidden>>, automatically-generated indices used to store a\n+stream's documents.\n+\n+image::images/data-streams/data-streams-diagram.svg[align=\"center\"]\n+\n+The creation of a data stream requires an associated\n+<<indices-templates,composable template>>. This template acts as a blueprint for\n+the stream's backing indices. It contains:\n+\n+* A name or wildcard (`*`) pattern for the data stream.\n+\n+* The data stream's _timestamp field_. This field must be mapped as a\n+  <<date,`date`>> or <<date_nanos,`date_nanos`>> field datatype and be\n+  included in every document indexed to the data stream.\n+\n+* The mappings and settings applied to each backing index when it's created.\n+\n+The same composable template can be used to create multiple data streams.\n+See <<set-up-a-data-stream>>.\n+\n+[discrete]\n+[[data-streams-generation]]\n+=== Generation\n+\n+Each data stream tracks its _generation_: a six-digit, zero-padded integer\n+that acts as a cumulative count of the data stream's backing indices. This count\n+includes any deleted indices for the stream. The generation is incremented\n+whenever a new backing index is added to the stream.\n+\n+When a backing index is created, the index is named using the following\n+convention:\n+\n+[source,text]\n+----\n+.ds-<data-stream>-<generation>\n+----\n+\n+.*Example*\n+[%collapsible]\n+====\n+The `web_server_logs` data stream has a generation of `34`. The most recently\n+created backing index for this data stream is named\n+`.ds-web_server_logs-000034`.\n+====\n+\n+Because the generation increments with each new backing index, backing indices\n+with a higher generation contain more recent data. Backing indices with a lower\n+generation contain older data.\n+\n+A backing index's name can change after its creation due to a\n+<<indices-shrink-index,shrink>>, <<snapshots-restore-snapshot,restore>>, or\n+other operations.\n+\n+[discrete]\n+[[data-stream-write-index]]\n+=== Write index\n+\n+When a read request is sent to a data stream, it routes the request to all its\n+backing indices. For example, a search request sent to a data stream would query\n+all its backing indices.\n+\n+image::images/data-streams/data-streams-search-request.svg[align=\"center\"]\n+\n+However, the most recently created backing index is the data stream\u2019s only\n+_write index_. The data stream routes all indexing requests to this index.\n+\n+image::images/data-streams/data-streams-index-request.svg[align=\"center\"]\n+\n+You cannot add new documents to a stream's other backing indices, even\n+by sending indexing requests directly to the index.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7bb89f50412e46fb0c6058c1ad8486912b6cdf44"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ2Mjk3Nw==", "bodyText": "We currently prohibit closing and deleting the write index and are going to prohibit freezing, shrinking, and any other operation that would prevent ingestion into the write index even if, as in the case of shrinking, ingestion would be prevented only temporarily.", "url": "https://github.com/elastic/elasticsearch/pull/57954#discussion_r438462977", "createdAt": "2020-06-10T23:33:53Z", "author": {"login": "danhermann"}, "path": "docs/reference/data-streams/data-streams-overview.asciidoc", "diffHunk": "@@ -0,0 +1,118 @@\n+[[data-streams-overview]]\n+== Data streams overview\n+++++\n+<titleabbrev>Overview</titleabbrev>\n+++++\n+\n+A data stream consists of one or more _backing indices_. Backing indices are\n+<<index-hidden,hidden>>, automatically-generated indices used to store a\n+stream's documents.\n+\n+image::images/data-streams/data-streams-diagram.svg[align=\"center\"]\n+\n+The creation of a data stream requires an associated\n+<<indices-templates,composable template>>. This template acts as a blueprint for\n+the stream's backing indices. It contains:\n+\n+* A name or wildcard (`*`) pattern for the data stream.\n+\n+* The data stream's _timestamp field_. This field must be mapped as a\n+  <<date,`date`>> or <<date_nanos,`date_nanos`>> field datatype and be\n+  included in every document indexed to the data stream.\n+\n+* The mappings and settings applied to each backing index when it's created.\n+\n+The same composable template can be used to create multiple data streams.\n+See <<set-up-a-data-stream>>.\n+\n+[discrete]\n+[[data-streams-generation]]\n+=== Generation\n+\n+Each data stream tracks its _generation_: a six-digit, zero-padded integer\n+that acts as a cumulative count of the data stream's backing indices. This count\n+includes any deleted indices for the stream. The generation is incremented\n+whenever a new backing index is added to the stream.\n+\n+When a backing index is created, the index is named using the following\n+convention:\n+\n+[source,text]\n+----\n+.ds-<data-stream>-<generation>\n+----\n+\n+.*Example*\n+[%collapsible]\n+====\n+The `web_server_logs` data stream has a generation of `34`. The most recently\n+created backing index for this data stream is named\n+`.ds-web_server_logs-000034`.\n+====\n+\n+Because the generation increments with each new backing index, backing indices\n+with a higher generation contain more recent data. Backing indices with a lower\n+generation contain older data.\n+\n+A backing index's name can change after its creation due to a\n+<<indices-shrink-index,shrink>>, <<snapshots-restore-snapshot,restore>>, or\n+other operations.\n+\n+[discrete]\n+[[data-stream-write-index]]\n+=== Write index\n+\n+When a read request is sent to a data stream, it routes the request to all its\n+backing indices. For example, a search request sent to a data stream would query\n+all its backing indices.\n+\n+image::images/data-streams/data-streams-search-request.svg[align=\"center\"]\n+\n+However, the most recently created backing index is the data stream\u2019s only\n+_write index_. The data stream routes all indexing requests to this index.\n+\n+image::images/data-streams/data-streams-index-request.svg[align=\"center\"]\n+\n+You cannot add new documents to a stream's other backing indices, even\n+by sending indexing requests directly to the index.\n+\n+Because it's the only index capable of handling indexing requests, you also\n+cannot <<indices-close,close>> a data stream's write index.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7bb89f50412e46fb0c6058c1ad8486912b6cdf44"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ2MzY4Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Because of this, data streams are designed to append-only. This means you can\n          \n          \n            \n            Because of this, data streams are designed to be append-only. This means you can", "url": "https://github.com/elastic/elasticsearch/pull/57954#discussion_r438463683", "createdAt": "2020-06-10T23:36:31Z", "author": {"login": "danhermann"}, "path": "docs/reference/data-streams/data-streams-overview.asciidoc", "diffHunk": "@@ -0,0 +1,118 @@\n+[[data-streams-overview]]\n+== Data streams overview\n+++++\n+<titleabbrev>Overview</titleabbrev>\n+++++\n+\n+A data stream consists of one or more _backing indices_. Backing indices are\n+<<index-hidden,hidden>>, automatically-generated indices used to store a\n+stream's documents.\n+\n+image::images/data-streams/data-streams-diagram.svg[align=\"center\"]\n+\n+The creation of a data stream requires an associated\n+<<indices-templates,composable template>>. This template acts as a blueprint for\n+the stream's backing indices. It contains:\n+\n+* A name or wildcard (`*`) pattern for the data stream.\n+\n+* The data stream's _timestamp field_. This field must be mapped as a\n+  <<date,`date`>> or <<date_nanos,`date_nanos`>> field datatype and be\n+  included in every document indexed to the data stream.\n+\n+* The mappings and settings applied to each backing index when it's created.\n+\n+The same composable template can be used to create multiple data streams.\n+See <<set-up-a-data-stream>>.\n+\n+[discrete]\n+[[data-streams-generation]]\n+=== Generation\n+\n+Each data stream tracks its _generation_: a six-digit, zero-padded integer\n+that acts as a cumulative count of the data stream's backing indices. This count\n+includes any deleted indices for the stream. The generation is incremented\n+whenever a new backing index is added to the stream.\n+\n+When a backing index is created, the index is named using the following\n+convention:\n+\n+[source,text]\n+----\n+.ds-<data-stream>-<generation>\n+----\n+\n+.*Example*\n+[%collapsible]\n+====\n+The `web_server_logs` data stream has a generation of `34`. The most recently\n+created backing index for this data stream is named\n+`.ds-web_server_logs-000034`.\n+====\n+\n+Because the generation increments with each new backing index, backing indices\n+with a higher generation contain more recent data. Backing indices with a lower\n+generation contain older data.\n+\n+A backing index's name can change after its creation due to a\n+<<indices-shrink-index,shrink>>, <<snapshots-restore-snapshot,restore>>, or\n+other operations.\n+\n+[discrete]\n+[[data-stream-write-index]]\n+=== Write index\n+\n+When a read request is sent to a data stream, it routes the request to all its\n+backing indices. For example, a search request sent to a data stream would query\n+all its backing indices.\n+\n+image::images/data-streams/data-streams-search-request.svg[align=\"center\"]\n+\n+However, the most recently created backing index is the data stream\u2019s only\n+_write index_. The data stream routes all indexing requests to this index.\n+\n+image::images/data-streams/data-streams-index-request.svg[align=\"center\"]\n+\n+You cannot add new documents to a stream's other backing indices, even\n+by sending indexing requests directly to the index.\n+\n+Because it's the only index capable of handling indexing requests, you also\n+cannot <<indices-close,close>> a data stream's write index.\n+\n+[discrete]\n+[[data-streams-rollover]]\n+=== Rollover\n+\n+When a data stream is created, one backing index is automatically created.\n+Because this single index is also the most recently created backing index, it\n+acts as the stream's write index.\n+\n+A <<indices-rollover-index,rollover>> creates a new backing index for a data\n+stream. This new backing index becomes the stream's write index, replacing\n+the current one, and increments the stream's generation.\n+\n+In most cases, we recommend using <<index-lifecycle-management,{ilm}\n+({ilm-init})>> to automate rollovers for data streams. This lets you\n+automatically roll over the current write index when it meets specified\n+criteria, such as a maximum age or size.\n+\n+However, you can also use the <<indices-rollover-index,rollover API>> to\n+manually perform a rollover. See <<manually-roll-over-a-data-stream>>.\n+\n+[discrete]\n+[[data-streams-append-only]]\n+=== Append-only\n+\n+For most time-series use cases, existing data is rarely, if ever, updated.\n+Because of this, data streams are designed to append-only. This means you can", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7bb89f50412e46fb0c6058c1ad8486912b6cdf44"}, "originalPosition": 107}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4NzQ2NDQ3", "url": "https://github.com/elastic/elasticsearch/pull/57954#pullrequestreview-428746447", "createdAt": "2020-06-11T09:32:12Z", "commit": {"oid": "7bb89f50412e46fb0c6058c1ad8486912b6cdf44"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4Nzc1MTkz", "url": "https://github.com/elastic/elasticsearch/pull/57954#pullrequestreview-428775193", "createdAt": "2020-06-11T10:13:01Z", "commit": {"oid": "7bb89f50412e46fb0c6058c1ad8486912b6cdf44"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMVQxMDoxMzowMVrOGiXFjw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMVQxMDoxMzowMVrOGiXFjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODY4MzAyMw==", "bodyText": "Shall we mention the composable templates here that create/manage the data stream and backing indices settings (ie. the ILM policy) somewhere? (I think as it stands now it might imply that you need a separate policy to manage these backing indices, as opposed to the one that sets up the data stream)", "url": "https://github.com/elastic/elasticsearch/pull/57954#discussion_r438683023", "createdAt": "2020-06-11T10:13:01Z", "author": {"login": "andreidan"}, "path": "docs/reference/data-streams/data-streams.asciidoc", "diffHunk": "@@ -1,67 +1,59 @@\n [[data-streams]]\n = Data streams\n+++++\n+<titleabbrev>Data streams</titleabbrev>\n+++++\n \n-[partintro]\n---\n-You can use data streams to index time-based data that's continuously generated.\n-A data stream groups indices from the same time-based data source.\n-A data stream tracks its indices, known as _backing indices_, using an ordered\n-list.\n+A _data stream_ is a convenient, scalable way to ingest, search, and manage\n+continuously generated time-series data.\n \n-A data stream's backing indices are <<index-hidden,hidden>>.\n-While all backing indices handle read requests, the most recently created\n-backing index is the data stream's only write index.  A data stream only\n-accepts <<docs-index_,index requests>> with `op_type` set to `create`. To update\n-or delete specific documents in a data stream, submit a <<docs-delete,delete>>\n-or <<docs-update,update>> API request to the backing index containing the\n-document.\n+Time-series data, such as logs, tends to grow over time, resulting in large\n+volumes of data. While using a single {es} index for each data source is\n+simpler, it is often more efficient and cost-effective to store a source's data\n+across multiple, time-based indices. Multiple indices let you move indices\n+containing older, less valuable data to less expensive hardware and delete\n+indices when they're not longer needed, reducing overhead and storage costs.\n \n-To create a data stream, set up a <<indices-templates,composable index\n-template>> containing:\n+A data stream is designed to give you the best of both worlds:\n \n-* A name or wildcard pattern for the data stream in the `index_patterns` property.\n-* A `data_stream` definition that contains the `timestamp_field` property.\n-  The `timestamp_field` must be the primary timestamp field\n-   for the data source. This field must be included in every\n-   document indexed to the data stream.\n+* The simplicity of a single, named resource you can use for requests\n+  related to a data source\n+* The storage, scalability, and cost-saving benefits of multiple indices \n \n-When you index one or more documents to a not-yet-existent target matching\n-the template's name or pattern, {es} automatically creates the corresponding\n-data stream. You can also manually create a data stream using the\n-<<indices-create-data-stream,create data stream API>>. However, a composable\n-template for the stream is still required.\n+You can submit indexing and search requests directly to a data stream. The\n+stream automatically routes the requests to a collection of hidden,\n+auto-generated indices that store the source's data.\n \n-You can use the <<indices-rollover-index,rollover API>> to roll a data stream\n-over to a new index when the current write index meets specified criteria, such\n-as a maximum age or size. A rollover creates a new backing index and updates the\n-data stream's list of backing indices. This new index then becomes the stream's\n-new write index. See <<rollover-data-stream-ex>>.\n+You can use <<index-lifecycle-management,{ilm} ({ilm-init})>> to automate the\n+management of these hidden indices. You can use {ilm-init} to spin up new\n+indices, allocate indices to different hardware, delete old indices, and take\n+other automatic actions based on age or size criteria you set. This lets you\n+seamlessly scale your data storage based on your budget, performance,\n+resiliency, and retention needs.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7bb89f50412e46fb0c6058c1ad8486912b6cdf44"}, "originalPosition": 62}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9c7f0d567bf4a9ddb3bd0e86cb9d14cc75d578b2", "author": {"user": {"login": "jrodewig", "name": "James Rodewig"}}, "url": "https://github.com/elastic/elasticsearch/commit/9c7f0d567bf4a9ddb3bd0e86cb9d14cc75d578b2", "committedDate": "2020-06-11T12:52:04Z", "message": "update images"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "039cecb4d0721b4f6baefcc61a5867db99f97961", "author": {"user": {"login": "jrodewig", "name": "James Rodewig"}}, "url": "https://github.com/elastic/elasticsearch/commit/039cecb4d0721b4f6baefcc61a5867db99f97961", "committedDate": "2020-06-11T13:37:23Z", "message": "Merge remote-tracking branch 'upstream/master' into docs__reformat-data-streams-intro"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "931c4f6205819cd03e731876a7eeb0093d4ea6b2", "author": {"user": {"login": "jrodewig", "name": "James Rodewig"}}, "url": "https://github.com/elastic/elasticsearch/commit/931c4f6205819cd03e731876a7eeb0093d4ea6b2", "committedDate": "2020-06-11T14:28:08Z", "message": "address feedback"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "119e77a04966bfdb6319fc643ff99870f38bd2d8", "author": {"user": {"login": "jrodewig", "name": "James Rodewig"}}, "url": "https://github.com/elastic/elasticsearch/commit/119e77a04966bfdb6319fc643ff99870f38bd2d8", "committedDate": "2020-06-11T14:37:57Z", "message": "fix typos"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "32b4355876c71da5cf82ea31f3b4155d7183fa7c", "author": {"user": {"login": "jrodewig", "name": "James Rodewig"}}, "url": "https://github.com/elastic/elasticsearch/commit/32b4355876c71da5cf82ea31f3b4155d7183fa7c", "committedDate": "2020-06-11T14:44:17Z", "message": "clarification"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ad3e04fd48189ba568cfa2dcd23d71804dff8858", "author": {"user": {"login": "jrodewig", "name": "James Rodewig"}}, "url": "https://github.com/elastic/elasticsearch/commit/ad3e04fd48189ba568cfa2dcd23d71804dff8858", "committedDate": "2020-06-11T14:46:39Z", "message": "punct fix"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1da05bd6ae97adfc55efde69b9626a64982584dc", "author": {"user": {"login": "jrodewig", "name": "James Rodewig"}}, "url": "https://github.com/elastic/elasticsearch/commit/1da05bd6ae97adfc55efde69b9626a64982584dc", "committedDate": "2020-06-11T14:47:13Z", "message": "typo"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 767, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}