{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg2OTEzMzc5", "number": 62345, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQyMTo1ODowOVrOEjVBrA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxMjo0ODozNVrOEjk01w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1NDgwMTA4OnYy", "diffSide": "LEFT", "path": "benchmarks/README.md", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQyMTo1ODowOVrOHRoD7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQyMTo1ODowOVrOHRoD7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODI0NDIwNw==", "bodyText": "This was just wrong.", "url": "https://github.com/elastic/elasticsearch/pull/62345#discussion_r488244207", "createdAt": "2020-09-14T21:58:09Z", "author": {"login": "nik9000"}, "path": "benchmarks/README.md", "diffHunk": "@@ -78,7 +78,6 @@ cd fcml*\n make\n cd example/hsdis\n make\n-cp .libs/libhsdis.so.0.0.0", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15471e6020f1803938521fa20eabacda64c68922"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1NDgwODE3OnYy", "diffSide": "RIGHT", "path": "benchmarks/src/main/java/org/elasticsearch/benchmark/search/aggregations/bucket/terms/StringTermsSerializationBenchmark.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQyMTo1OToyNFrOHRoHyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQyMTo1OToyNFrOHRoHyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODI0NTE5Mg==", "bodyText": "I'm unsure if we actually want this benchmark, especially compared to the one that @jimczi showed me. But it is fairly targeted which can be useful.", "url": "https://github.com/elastic/elasticsearch/pull/62345#discussion_r488245192", "createdAt": "2020-09-14T21:59:24Z", "author": {"login": "nik9000"}, "path": "benchmarks/src/main/java/org/elasticsearch/benchmark/search/aggregations/bucket/terms/StringTermsSerializationBenchmark.java", "diffHunk": "@@ -0,0 +1,77 @@\n+package org.elasticsearch.benchmark.search.aggregations.bucket.terms;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.io.stream.BytesStreamOutput;\n+import org.elasticsearch.common.io.stream.DelayableWriteable;\n+import org.elasticsearch.common.io.stream.NamedWriteableRegistry;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.BucketOrder;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.InternalAggregations;\n+import org.elasticsearch.search.aggregations.bucket.terms.StringTerms;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.Warmup;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+@Fork(2)\n+@Warmup(iterations = 10)\n+@Measurement(iterations = 5)\n+@BenchmarkMode(Mode.AverageTime)\n+@OutputTimeUnit(TimeUnit.MILLISECONDS)\n+@State(Scope.Benchmark)\n+public class StringTermsSerializationBenchmark {\n+    private static final NamedWriteableRegistry REGISTRY = new NamedWriteableRegistry(\n+        List.of(new NamedWriteableRegistry.Entry(InternalAggregation.class, StringTerms.NAME, StringTerms::new))\n+    );\n+    @Param(value = { \"1000\" })\n+    private int buckets;\n+\n+    private DelayableWriteable<InternalAggregations> results;\n+\n+    @Setup\n+    public void initResults() {\n+        results = DelayableWriteable.referencing(InternalAggregations.from(List.of(newTerms(true))));\n+    }\n+\n+    private StringTerms newTerms(boolean withNested) {\n+        List<StringTerms.Bucket> resultBuckets = new ArrayList<>(buckets);\n+        for (int i = 0; i < buckets; i++) {\n+            InternalAggregations inner = withNested ? InternalAggregations.from(List.of(newTerms(false))) : InternalAggregations.EMPTY;\n+            resultBuckets.add(new StringTerms.Bucket(new BytesRef(\"test\" + i), i, inner, false, 0, DocValueFormat.RAW));\n+        }\n+        return new StringTerms(\n+            \"test\",\n+            BucketOrder.key(true),\n+            BucketOrder.key(true),\n+            buckets,\n+            1,\n+            null,\n+            DocValueFormat.RAW,\n+            buckets,\n+            false,\n+            100000,\n+            resultBuckets,\n+            0\n+        );\n+    }\n+\n+    @Benchmark\n+    public DelayableWriteable<InternalAggregations> serialize() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15471e6020f1803938521fa20eabacda64c68922"}, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1NTI5NjE0OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwMDo0MzoyNlrOHRsYWg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwMDo0MzoyNlrOHRsYWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODMxNDk3MA==", "bodyText": "This gets compiled to lzcnt and the JVM's tableswitch. At this point the overhead of the buffer and BigArrays dominates the method.", "url": "https://github.com/elastic/elasticsearch/pull/62345#discussion_r488314970", "createdAt": "2020-09-15T00:43:26Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java", "diffHunk": "@@ -218,14 +218,85 @@ public void writeInt(int i) throws IOException {\n      * using {@link #writeInt}\n      */\n     public void writeVInt(int i) throws IOException {\n-        final byte[] buffer = scratch.get();\n-        int index = 0;\n-        while ((i & ~0x7F) != 0) {\n-            buffer[index++] = ((byte) ((i & 0x7f) | 0x80));\n-            i >>>= 7;\n+        /*\n+         * Pick the number of bytes that we need based on the value and then\n+         * encode the int, unrolling the loops by hand. This allows writing\n+         * small numbers to use `writeByte` which is simple and fast. The\n+         * unrolling saves a few comparisons and bitwise operations. All\n+         * together this saves quite a bit of time compared to a naive\n+         * implementation.\n+         */\n+        switch (Integer.numberOfLeadingZeros(i)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "929297f3a72d6d80e26b9a415e1204b413c52079"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1NTkzMjc4OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwNjoxMDozNlrOHRyJPA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxMjo1NzowMFrOHSAeNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODQwOTQwNA==", "bodyText": "I love this until here :) The fact that we can special case number of leading zeros > 24 is pretty significant and I can see the ~30% performance gain as well.\nHard coding all possible offsets below and doing all the buffer getting and writeBytes inline with those hard coded offsets I don't think is a good idea. This blows up the method size significantly for a tiny saving in CPU when it comes to evaluating the loop.\nI benchmarked both this version and:\n    public void writeVInt(int i) throws IOException {\n        if (Integer.numberOfLeadingZeros(i) > 24) {\n            writeByte((byte) i);\n        } else {\n            final byte[] buffer = scratch.get();\n            int index = 0;\n            do {\n                buffer[index++] = ((byte) ((i & 0x7f) | 0x80));\n                i >>>= 7;\n            } while ((i & ~0x7F) != 0);\n            buffer[index++] = ((byte) i);\n            writeBytes(buffer, 0, index);\n        }\n    }\nand I can't see statistically significant difference so that's not worth the complication IMO.\nI would in fact expect the above version with the loop to be faster than what is in this PR in the real world because the smaller method size has a better better chance of getting inlined in some places (73 vs 507 bytes on JDK14/Linux for me).\nI suppose you could work around the code bloat by doing this:\n        final int leadingZeros = Integer.numberOfLeadingZeros(i);\n        if (Integer.numberOfLeadingZeros(i) > 24) {\n            writeByte((byte) i);\n        } else {\n            final byte[] buffer = scratch.get();\n            final int length;\n            switch (leadingZeros) {\n                case 24:\n                case 23:\n                case 22:\n                case 21:\n                case 20:\n                case 19:\n                case 18:\n                    buffer[0] = (byte) (i & 0x7f | 0x80);\n                    buffer[1] = (byte) (i >>> 7);\n                    assert buffer[1] <= 0x7f;\n                    length = 2;\n                    break;\n                case 17:\n                case 16:\n                case 15:\n                case 14:\n                case 13:\n                case 12:\n                case 11:\n                    buffer[0] = (byte) (i & 0x7f | 0x80);\n                    buffer[1] = (byte) ((i >>> 7) & 0x7f | 0x80);\n                    buffer[2] = (byte) (i >>> 14);\n                    assert buffer[2] <= 0x7f;\n                    length = 3;\n                    break;\n                case 10:\n                case 9:\n                case 8:\n                case 7:\n                case 6:\n                case 5:\n                case 4:\n                    buffer[0] = (byte) (i & 0x7f | 0x80);\n                    buffer[1] = (byte) ((i >>> 7) & 0x7f | 0x80);\n                    buffer[2] = (byte) ((i >>> 14) & 0x7f | 0x80);\n                    buffer[3] = (byte) (i >>> 21);\n                    assert buffer[3] <= 0x7f;\n                    length = 4;\n                    break;\n                case 3:\n                case 2:\n                case 1:\n                case 0:\n                    buffer[0] = (byte) (i & 0x7f | 0x80);\n                    buffer[1] = (byte) ((i >>> 7) & 0x7f | 0x80);\n                    buffer[2] = (byte) ((i >>> 14) & 0x7f | 0x80);\n                    buffer[3] = (byte) ((i >>> 21) & 0x7f | 0x80);\n                    buffer[4] = (byte) (i >>> 28);\n                    assert buffer[4] <= 0x7f;\n                    length = 5;\n                    break;\n                default:\n                    throw new UnsupportedOperationException(\n                            \"Can't encode [\" + i + \"]. Missing case for [\" + Integer.numberOfLeadingZeros(i) + \"]?\"\n                    );\n            }\n            writeBytes(buffer, 0, length);\n        }\nbut I can't measure a performance difference to the loop at all so personally I'd go for the shorter loop just for simplicity's sake.", "url": "https://github.com/elastic/elasticsearch/pull/62345#discussion_r488409404", "createdAt": "2020-09-15T06:10:36Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java", "diffHunk": "@@ -218,14 +218,85 @@ public void writeInt(int i) throws IOException {\n      * using {@link #writeInt}\n      */\n     public void writeVInt(int i) throws IOException {\n-        final byte[] buffer = scratch.get();\n-        int index = 0;\n-        while ((i & ~0x7F) != 0) {\n-            buffer[index++] = ((byte) ((i & 0x7f) | 0x80));\n-            i >>>= 7;\n+        /*\n+         * Pick the number of bytes that we need based on the value and then\n+         * encode the int, unrolling the loops by hand. This allows writing\n+         * small numbers to use `writeByte` which is simple and fast. The\n+         * unrolling saves a few comparisons and bitwise operations. All\n+         * together this saves quite a bit of time compared to a naive\n+         * implementation.\n+         */\n+        switch (Integer.numberOfLeadingZeros(i)) {\n+            case 32:\n+            case 31:\n+            case 30:\n+            case 29:\n+            case 28:\n+            case 27:\n+            case 26:\n+            case 25:\n+                writeByte((byte) i);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca6cd67ccd78ea75546606e160ca7ffc5deb86c7"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODYzNzg2Ng==", "bodyText": "I think your right about your implementation being faster in practice. I put together a quick and dirty benchmark for writeVInt directly and my hand unrolled thing is faster there. By a pretty wide margin. But the benchmark for serializing the agg result is slower. I can see in the decompiled output that my method results in writeVInt not being inlined because it is too big like you say. And yours gets it inlined.\nOptimize for size\nBenchmark                                        (buckets)  Mode  Cnt   Score   Error  Units\nStringTermsSerializationBenchmark.serialize           1000  avgt   10  59.064 \u00b1 0.360  ms/op\nStringTermsSerializationBenchmark.serializeVint       1000  avgt   10  17.211 \u00b1 0.088  ms/op\n\nUnroll loops\nBenchmark                                        (buckets)  Mode  Cnt   Score   Error  Units\nStringTermsSerializationBenchmark.serialize           1000  avgt   10  61.560 \u00b1 0.124  ms/op\nStringTermsSerializationBenchmark.serializeVint       1000  avgt   10  11.775 \u00b1 0.048  ms/op\n\nUnroll loops with if instead of switch\nBenchmark                                        (buckets)  Mode  Cnt   Score   Error  Units\nStringTermsSerializationBenchmark.serialize           1000  avgt   10  60.794 \u00b1 1.069  ms/op\nStringTermsSerializationBenchmark.serializeVint       1000  avgt   10  17.703 \u00b1 0.075  ms/op\n\nCompromise\nBenchmark                                        (buckets)  Mode  Cnt   Score   Error  Units\nStringTermsSerializationBenchmark.serialize           1000  avgt   10  62.106 \u00b1 0.173  ms/op\nStringTermsSerializationBenchmark.serializeVint       1000  avgt   10  16.425 \u00b1 0.033  ms/op\n\nThe compromise solution doesn't seem to shrink the method enough.", "url": "https://github.com/elastic/elasticsearch/pull/62345#discussion_r488637866", "createdAt": "2020-09-15T12:47:55Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java", "diffHunk": "@@ -218,14 +218,85 @@ public void writeInt(int i) throws IOException {\n      * using {@link #writeInt}\n      */\n     public void writeVInt(int i) throws IOException {\n-        final byte[] buffer = scratch.get();\n-        int index = 0;\n-        while ((i & ~0x7F) != 0) {\n-            buffer[index++] = ((byte) ((i & 0x7f) | 0x80));\n-            i >>>= 7;\n+        /*\n+         * Pick the number of bytes that we need based on the value and then\n+         * encode the int, unrolling the loops by hand. This allows writing\n+         * small numbers to use `writeByte` which is simple and fast. The\n+         * unrolling saves a few comparisons and bitwise operations. All\n+         * together this saves quite a bit of time compared to a naive\n+         * implementation.\n+         */\n+        switch (Integer.numberOfLeadingZeros(i)) {\n+            case 32:\n+            case 31:\n+            case 30:\n+            case 29:\n+            case 28:\n+            case 27:\n+            case 26:\n+            case 25:\n+                writeByte((byte) i);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODQwOTQwNA=="}, "originalCommit": {"oid": "ca6cd67ccd78ea75546606e160ca7ffc5deb86c7"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODY0NDE0OA==", "bodyText": "Thanks for testing this!", "url": "https://github.com/elastic/elasticsearch/pull/62345#discussion_r488644148", "createdAt": "2020-09-15T12:57:00Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java", "diffHunk": "@@ -218,14 +218,85 @@ public void writeInt(int i) throws IOException {\n      * using {@link #writeInt}\n      */\n     public void writeVInt(int i) throws IOException {\n-        final byte[] buffer = scratch.get();\n-        int index = 0;\n-        while ((i & ~0x7F) != 0) {\n-            buffer[index++] = ((byte) ((i & 0x7f) | 0x80));\n-            i >>>= 7;\n+        /*\n+         * Pick the number of bytes that we need based on the value and then\n+         * encode the int, unrolling the loops by hand. This allows writing\n+         * small numbers to use `writeByte` which is simple and fast. The\n+         * unrolling saves a few comparisons and bitwise operations. All\n+         * together this saves quite a bit of time compared to a naive\n+         * implementation.\n+         */\n+        switch (Integer.numberOfLeadingZeros(i)) {\n+            case 32:\n+            case 31:\n+            case 30:\n+            case 29:\n+            case 28:\n+            case 27:\n+            case 26:\n+            case 25:\n+                writeByte((byte) i);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODQwOTQwNA=="}, "originalCommit": {"oid": "ca6cd67ccd78ea75546606e160ca7ffc5deb86c7"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1NzM4OTY3OnYy", "diffSide": "RIGHT", "path": "benchmarks/src/main/java/org/elasticsearch/benchmark/search/aggregations/bucket/terms/StringTermsSerializationBenchmark.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxMjo0ODozNVrOHSAHTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxMjo0ODozNVrOHSAHTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODYzODI4Ng==", "bodyText": "I think we probably don't want to keep this benchmark but I pushed it so you could see what I was using for the numbers I shared.", "url": "https://github.com/elastic/elasticsearch/pull/62345#discussion_r488638286", "createdAt": "2020-09-15T12:48:35Z", "author": {"login": "nik9000"}, "path": "benchmarks/src/main/java/org/elasticsearch/benchmark/search/aggregations/bucket/terms/StringTermsSerializationBenchmark.java", "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.benchmark.search.aggregations.bucket.terms;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.io.stream.BytesStreamOutput;\n+import org.elasticsearch.common.io.stream.DelayableWriteable;\n+import org.elasticsearch.common.io.stream.NamedWriteableRegistry;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.BucketOrder;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.InternalAggregations;\n+import org.elasticsearch.search.aggregations.bucket.terms.StringTerms;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.Warmup;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+@Fork(2)\n+@Warmup(iterations = 10)\n+@Measurement(iterations = 5)\n+@BenchmarkMode(Mode.AverageTime)\n+@OutputTimeUnit(TimeUnit.MILLISECONDS)\n+@State(Scope.Benchmark)\n+public class StringTermsSerializationBenchmark {\n+    private static final NamedWriteableRegistry REGISTRY = new NamedWriteableRegistry(\n+        List.of(new NamedWriteableRegistry.Entry(InternalAggregation.class, StringTerms.NAME, StringTerms::new))\n+    );\n+    @Param(value = { \"1000\" })\n+    private int buckets;\n+\n+    private DelayableWriteable<InternalAggregations> results;\n+\n+    @Setup\n+    public void initResults() {\n+        results = DelayableWriteable.referencing(InternalAggregations.from(List.of(newTerms(true))));\n+    }\n+\n+    private StringTerms newTerms(boolean withNested) {\n+        List<StringTerms.Bucket> resultBuckets = new ArrayList<>(buckets);\n+        for (int i = 0; i < buckets; i++) {\n+            InternalAggregations inner = withNested ? InternalAggregations.from(List.of(newTerms(false))) : InternalAggregations.EMPTY;\n+            resultBuckets.add(new StringTerms.Bucket(new BytesRef(\"test\" + i), i, inner, false, 0, DocValueFormat.RAW));\n+        }\n+        return new StringTerms(\n+            \"test\",\n+            BucketOrder.key(true),\n+            BucketOrder.key(true),\n+            buckets,\n+            1,\n+            null,\n+            DocValueFormat.RAW,\n+            buckets,\n+            false,\n+            100000,\n+            resultBuckets,\n+            0\n+        );\n+    }\n+\n+    @Benchmark\n+    public DelayableWriteable<InternalAggregations> serialize() {\n+        return results.asSerialized(InternalAggregations::readFrom, REGISTRY);\n+    }\n+\n+    @Benchmark\n+    public BytesReference serializeVint() throws IOException {\n+        try (BytesStreamOutput buffer = new BytesStreamOutput()) {\n+            buffer.setVersion(Version.CURRENT);\n+            for (int i = 0; i < 1000000; i++) {\n+                buffer.writeVInt(i);\n+                buffer.reset();\n+            }\n+            return buffer.bytes();\n+        }\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f6d4d8bc489c83898516777ae54085ba49cd34e"}, "originalPosition": 107}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1564, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}