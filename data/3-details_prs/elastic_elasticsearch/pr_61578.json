{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDczODY5MDMw", "number": 61578, "title": "[ML] adds new n_gram_encoding custom processor", "bodyText": "This adds a new n_gram_encoding feature processor for analytics and inference.\nThe focus of this processor is simple ngram encodings that allow:\n\nmultiple ngrams [1..5]\nPrefix, infix, suffix\n\nFormat\n\"n_gram_encoding\": {\n  \"field\": <input field name>,\n  \"n_grams\": <array of int indicating ngrams desired, required. Max val 5, min val 1>,\n  \"feature_prefix\": <optional feature name prefix. Defaults n_gram_<start>_<length>,\n  \"start\": optional start index. Defaults to 0. Can be negative to indicate suffix starting,\n  \"length\": optional string length to encode to ngrams. Default to 50, max 100,\n}\n\nExample usage:\nPUT _ml/data_frame/analytics/foo\n{\n  \"source\": {\n    \"index\": \"kibana_sample_data_flights\"\n  },\n  \"dest\": {\n    \"index\": \"goof\"\n  },\n  \"analysis\": {\n    \"regression\": {\n      \"dependent_variable\": \"DistanceKilometers\",\n      \"num_top_feature_importance_values\": 3,\n      \"feature_processors\": [{\n        \"n_gram_encoding\": {\n          \"field\": \"OriginCityName\",\n          \"n_grams\": [1, 2, 3],\n          \"feature_prefix\": \"f\"\n        }\n      }]\n    }\n  },\n  \"analyzed_fields\": {\"includes\": [\"OriginCityName\",\"DistanceKilometers\"]},\n  \"model_memory_limit\": \"1gb\"\n}\n\nThe features names returned from the encoding have the following format:\n<feature_prefix>.<n_gram><pos>\n\nExample:\nfor the string cat with feature_prefix: \"f\"\nf.20: \"ca\"", "createdAt": "2020-08-26T12:22:06Z", "url": "https://github.com/elastic/elasticsearch/pull/61578", "merged": true, "mergeCommit": {"oid": "2341b20fdc954e6ee9e00437dccd56abfff8f445"}, "closed": true, "closedAt": "2020-09-03T16:23:55Z", "author": {"login": "benwtrent"}, "timelineItems": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdCcEDPgH2gAyNDczODY5MDMwOjNiYjFjY2RhM2M1NDRlMzcxNjY5YzQ4MzY3NTYyNWMxMjNkNWViNDg=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdFRZaaAH2gAyNDczODY5MDMwOjY4NmY0NzMwMTA4ODAwNmZiYjUzNDNhMWY1ZDBlOTBlOTk1ZTFiYWY=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "3bb1ccda3c544e371669c483675625c123d5eb48", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/3bb1ccda3c544e371669c483675625c123d5eb48", "committedDate": "2020-08-25T19:06:51Z", "message": "[ML] adds new n_gram_encoding custom processor"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9fdf423485f6a675cd0249abf34e5bbd9f13ba8e", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/9fdf423485f6a675cd0249abf34e5bbd9f13ba8e", "committedDate": "2020-08-27T14:12:02Z", "message": "Merge remote-tracking branch 'upstream/master' into feature/ml-analytics-ngram-processor"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7de22cde934117533204ff21d5331166cc17862a", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/7de22cde934117533204ff21d5331166cc17862a", "committedDate": "2020-08-27T15:23:19Z", "message": "adding tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9481ffe782b103d7ae3c72830a5a8decd7388299", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/9481ffe782b103d7ae3c72830a5a8decd7388299", "committedDate": "2020-08-27T15:27:44Z", "message": "removing debug"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "69d925a9f823dd31a20933ecfaa5c078d91ce159", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/69d925a9f823dd31a20933ecfaa5c078d91ce159", "committedDate": "2020-08-27T17:26:03Z", "message": "Merge remote-tracking branch 'upstream/master' into feature/ml-analytics-ngram-processor"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6c4507b420a56bf334c1d2142a1b83a0e0c91771", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/6c4507b420a56bf334c1d2142a1b83a0e0c91771", "committedDate": "2020-08-27T18:07:17Z", "message": "fixing test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0618709d9bc8bffabc68f8a46ce332ea10a06678", "author": {"user": {"login": "elasticmachine", "name": "Elastic Machine"}}, "url": "https://github.com/elastic/elasticsearch/commit/0618709d9bc8bffabc68f8a46ce332ea10a06678", "committedDate": "2020-08-31T13:43:54Z", "message": "Merge branch 'master' into feature/ml-analytics-ngram-processor"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgxNjM0MTIy", "url": "https://github.com/elastic/elasticsearch/pull/61578#pullrequestreview-481634122", "createdAt": "2020-09-03T08:55:43Z", "commit": {"oid": "0618709d9bc8bffabc68f8a46ce332ea10a06678"}, "state": "APPROVED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QwODo1NTo0M1rOHMc3dw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QwOTozODoyMFrOHMelsw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjgxNzkxMQ==", "bodyText": "I can't see this field being used in the client.", "url": "https://github.com/elastic/elasticsearch/pull/61578#discussion_r482817911", "createdAt": "2020-09-03T08:55:43Z", "author": {"login": "davidkyle"}, "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/ml/inference/preprocessing/NGram.java", "diffHunk": "@@ -0,0 +1,213 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.elasticsearch.client.ml.inference.preprocessing;\n+\n+import org.apache.lucene.util.RamUsageEstimator;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Objects;\n+\n+\n+/**\n+ * PreProcessor for n-gram encoding a string\n+ */\n+public class NGram implements PreProcessor {\n+\n+    public static final long SHALLOW_SIZE = RamUsageEstimator.shallowSizeOfInstance(NGram.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0618709d9bc8bffabc68f8a46ce332ea10a06678"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjgyMTM4Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    if (Arrays.stream(this.nGrams).anyMatch(i -> i < 1)) {\n          \n          \n            \n                    if (Arrays.stream(this.nGrams).anyMatch(i -> (i < MIN_GRAM) || (i > MAX_GRAM))) {", "url": "https://github.com/elastic/elasticsearch/pull/61578#discussion_r482821386", "createdAt": "2020-09-03T09:01:03Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/preprocessing/NGram.java", "diffHunk": "@@ -0,0 +1,304 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.inference.preprocessing;\n+\n+import org.apache.lucene.util.RamUsageEstimator;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.mapper.TextFieldMapper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.function.Function;\n+import java.util.function.IntFunction;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+import static org.apache.lucene.util.RamUsageEstimator.sizeOf;\n+\n+/**\n+ * PreProcessor for n-gram encoding a string\n+ */\n+public class NGram implements LenientlyParsedPreProcessor, StrictlyParsedPreProcessor {\n+\n+    private static final int DEFAULT_START = 0;\n+    private static final int DEFAULT_LENGTH = 50;\n+    private static final int MAX_LENGTH = 100;\n+    private static final int MIN_GRAM = 1;\n+    private static final int MAX_GRAM = 5;\n+\n+    private static String defaultPrefix(Integer start, Integer length) {\n+        return \"ngram_\"\n+            + (start == null ? DEFAULT_START : start)\n+            + \"_\"\n+            + (length == null ? DEFAULT_LENGTH : length);\n+    }\n+\n+    public static final long SHALLOW_SIZE = RamUsageEstimator.shallowSizeOfInstance(NGram.class);\n+    public static final ParseField NAME = new ParseField(\"n_gram_encoding\");\n+    public static final ParseField FIELD = new ParseField(\"field\");\n+    public static final ParseField FEATURE_PREFIX = new ParseField(\"feature_prefix\");\n+    public static final ParseField NGRAMS = new ParseField(\"n_grams\");\n+    public static final ParseField START = new ParseField(\"start\");\n+    public static final ParseField LENGTH = new ParseField(\"length\");\n+    public static final ParseField CUSTOM = new ParseField(\"custom\");\n+\n+    private static final ConstructingObjectParser<NGram, PreProcessorParseContext> STRICT_PARSER = createParser(false);\n+    private static final ConstructingObjectParser<NGram, PreProcessorParseContext> LENIENT_PARSER = createParser(true);\n+\n+    @SuppressWarnings(\"unchecked\")\n+    private static ConstructingObjectParser<NGram, PreProcessorParseContext> createParser(boolean lenient) {\n+        ConstructingObjectParser<NGram, PreProcessorParseContext> parser = new ConstructingObjectParser<>(\n+            NAME.getPreferredName(),\n+            lenient,\n+            (a, c) -> new NGram((String)a[0],\n+                (List<Integer>)a[1],\n+                (Integer)a[2],\n+                (Integer)a[3],\n+                a[4] == null ? c.isCustomByDefault() : (Boolean)a[4],\n+                (String)a[5]));\n+        parser.declareString(ConstructingObjectParser.constructorArg(), FIELD);\n+        parser.declareIntArray(ConstructingObjectParser.constructorArg(), NGRAMS);\n+        parser.declareInt(ConstructingObjectParser.optionalConstructorArg(), START);\n+        parser.declareInt(ConstructingObjectParser.optionalConstructorArg(), LENGTH);\n+        parser.declareBoolean(ConstructingObjectParser.optionalConstructorArg(), CUSTOM);\n+        parser.declareString(ConstructingObjectParser.optionalConstructorArg(), FEATURE_PREFIX);\n+        return parser;\n+    }\n+\n+    public static NGram fromXContentStrict(XContentParser parser, PreProcessorParseContext context) {\n+        return STRICT_PARSER.apply(parser, context == null ?  PreProcessorParseContext.DEFAULT : context);\n+    }\n+\n+    public static NGram fromXContentLenient(XContentParser parser, PreProcessorParseContext context) {\n+        return LENIENT_PARSER.apply(parser, context == null ?  PreProcessorParseContext.DEFAULT : context);\n+    }\n+\n+    private final String field;\n+    private final String featurePrefix;\n+    private final int[] nGrams;\n+    private final int start;\n+    private final int length;\n+    private final boolean custom;\n+\n+    NGram(String field,\n+          List<Integer> nGrams,\n+          Integer start,\n+          Integer length,\n+          Boolean custom,\n+          String featurePrefix) {\n+        this(field,\n+            featurePrefix == null ? defaultPrefix(start, length) : featurePrefix,\n+            Sets.newHashSet(nGrams).stream().mapToInt(Integer::intValue).toArray(),\n+            start == null ? DEFAULT_START : start,\n+            length == null ? DEFAULT_LENGTH : length,\n+            custom != null && custom);\n+    }\n+\n+    public NGram(String field, String featurePrefix, int[] nGrams, int start, int length, boolean custom) {\n+        this.field = ExceptionsHelper.requireNonNull(field, FIELD);\n+        this.featurePrefix = ExceptionsHelper.requireNonNull(featurePrefix, FEATURE_PREFIX);\n+        this.nGrams = ExceptionsHelper.requireNonNull(nGrams, NGRAMS);\n+        if (Arrays.stream(this.nGrams).anyMatch(i -> i < 1)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0618709d9bc8bffabc68f8a46ce332ea10a06678"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjgyNjY2Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            if (startPos + i + nGram - 1 >= len) {\n          \n          \n            \n                            if (startPos + i + nGram > len) {", "url": "https://github.com/elastic/elasticsearch/pull/61578#discussion_r482826662", "createdAt": "2020-09-03T09:09:28Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/preprocessing/NGram.java", "diffHunk": "@@ -0,0 +1,304 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.inference.preprocessing;\n+\n+import org.apache.lucene.util.RamUsageEstimator;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.mapper.TextFieldMapper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.function.Function;\n+import java.util.function.IntFunction;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+import static org.apache.lucene.util.RamUsageEstimator.sizeOf;\n+\n+/**\n+ * PreProcessor for n-gram encoding a string\n+ */\n+public class NGram implements LenientlyParsedPreProcessor, StrictlyParsedPreProcessor {\n+\n+    private static final int DEFAULT_START = 0;\n+    private static final int DEFAULT_LENGTH = 50;\n+    private static final int MAX_LENGTH = 100;\n+    private static final int MIN_GRAM = 1;\n+    private static final int MAX_GRAM = 5;\n+\n+    private static String defaultPrefix(Integer start, Integer length) {\n+        return \"ngram_\"\n+            + (start == null ? DEFAULT_START : start)\n+            + \"_\"\n+            + (length == null ? DEFAULT_LENGTH : length);\n+    }\n+\n+    public static final long SHALLOW_SIZE = RamUsageEstimator.shallowSizeOfInstance(NGram.class);\n+    public static final ParseField NAME = new ParseField(\"n_gram_encoding\");\n+    public static final ParseField FIELD = new ParseField(\"field\");\n+    public static final ParseField FEATURE_PREFIX = new ParseField(\"feature_prefix\");\n+    public static final ParseField NGRAMS = new ParseField(\"n_grams\");\n+    public static final ParseField START = new ParseField(\"start\");\n+    public static final ParseField LENGTH = new ParseField(\"length\");\n+    public static final ParseField CUSTOM = new ParseField(\"custom\");\n+\n+    private static final ConstructingObjectParser<NGram, PreProcessorParseContext> STRICT_PARSER = createParser(false);\n+    private static final ConstructingObjectParser<NGram, PreProcessorParseContext> LENIENT_PARSER = createParser(true);\n+\n+    @SuppressWarnings(\"unchecked\")\n+    private static ConstructingObjectParser<NGram, PreProcessorParseContext> createParser(boolean lenient) {\n+        ConstructingObjectParser<NGram, PreProcessorParseContext> parser = new ConstructingObjectParser<>(\n+            NAME.getPreferredName(),\n+            lenient,\n+            (a, c) -> new NGram((String)a[0],\n+                (List<Integer>)a[1],\n+                (Integer)a[2],\n+                (Integer)a[3],\n+                a[4] == null ? c.isCustomByDefault() : (Boolean)a[4],\n+                (String)a[5]));\n+        parser.declareString(ConstructingObjectParser.constructorArg(), FIELD);\n+        parser.declareIntArray(ConstructingObjectParser.constructorArg(), NGRAMS);\n+        parser.declareInt(ConstructingObjectParser.optionalConstructorArg(), START);\n+        parser.declareInt(ConstructingObjectParser.optionalConstructorArg(), LENGTH);\n+        parser.declareBoolean(ConstructingObjectParser.optionalConstructorArg(), CUSTOM);\n+        parser.declareString(ConstructingObjectParser.optionalConstructorArg(), FEATURE_PREFIX);\n+        return parser;\n+    }\n+\n+    public static NGram fromXContentStrict(XContentParser parser, PreProcessorParseContext context) {\n+        return STRICT_PARSER.apply(parser, context == null ?  PreProcessorParseContext.DEFAULT : context);\n+    }\n+\n+    public static NGram fromXContentLenient(XContentParser parser, PreProcessorParseContext context) {\n+        return LENIENT_PARSER.apply(parser, context == null ?  PreProcessorParseContext.DEFAULT : context);\n+    }\n+\n+    private final String field;\n+    private final String featurePrefix;\n+    private final int[] nGrams;\n+    private final int start;\n+    private final int length;\n+    private final boolean custom;\n+\n+    NGram(String field,\n+          List<Integer> nGrams,\n+          Integer start,\n+          Integer length,\n+          Boolean custom,\n+          String featurePrefix) {\n+        this(field,\n+            featurePrefix == null ? defaultPrefix(start, length) : featurePrefix,\n+            Sets.newHashSet(nGrams).stream().mapToInt(Integer::intValue).toArray(),\n+            start == null ? DEFAULT_START : start,\n+            length == null ? DEFAULT_LENGTH : length,\n+            custom != null && custom);\n+    }\n+\n+    public NGram(String field, String featurePrefix, int[] nGrams, int start, int length, boolean custom) {\n+        this.field = ExceptionsHelper.requireNonNull(field, FIELD);\n+        this.featurePrefix = ExceptionsHelper.requireNonNull(featurePrefix, FEATURE_PREFIX);\n+        this.nGrams = ExceptionsHelper.requireNonNull(nGrams, NGRAMS);\n+        if (Arrays.stream(this.nGrams).anyMatch(i -> i < 1)) {\n+            throw ExceptionsHelper.badRequestException(\n+                \"[{}] is invalid [{}]; minimum supported value is [{}]; maximum supported value is [{}]\",\n+                NGRAMS.getPreferredName(),\n+                Arrays.stream(nGrams).mapToObj(String::valueOf).collect(Collectors.joining(\", \")),\n+                MIN_GRAM,\n+                MAX_GRAM);\n+        }\n+        this.start = start;\n+        if (start < 0 && length + start > 0) {\n+            throw ExceptionsHelper.badRequestException(\n+                \"if [start] is negative, [length] + [start] must be less than 0\");\n+        }\n+        this.length = length;\n+        if (length <= 0) {\n+            throw ExceptionsHelper.badRequestException(\"[{}] must be a positive integer\", LENGTH.getPreferredName());\n+        }\n+        if (length > MAX_LENGTH) {\n+            throw ExceptionsHelper.badRequestException(\"[{}] must be not be greater than [{}]\", LENGTH.getPreferredName(), MAX_LENGTH);\n+        }\n+        this.custom = custom;\n+    }\n+\n+    public NGram(StreamInput in) throws IOException {\n+        this.field = in.readString();\n+        this.featurePrefix = in.readString();\n+        this.nGrams = in.readIntArray();\n+        this.start = in.readInt();\n+        this.length = in.readVInt();\n+        this.custom = in.readBoolean();\n+    }\n+\n+    @Override\n+    public void writeTo(StreamOutput out) throws IOException {\n+        out.writeString(field);\n+        out.writeString(featurePrefix);\n+        out.writeIntArray(nGrams);\n+        out.writeInt(start);\n+        out.writeVInt(length);\n+        out.writeBoolean(custom);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return Strings.toString(this);\n+    }\n+\n+    @Override\n+    public List<String> inputFields() {\n+        return Collections.singletonList(field);\n+    }\n+\n+    @Override\n+    public List<String> outputFields() {\n+        return allPossibleNGramOutputFeatureNames();\n+    }\n+\n+    @Override\n+    public void process(Map<String, Object> fields) {\n+        Object value = fields.get(field);\n+        if (value == null) {\n+            return;\n+        }\n+        final String stringValue = value.toString();\n+        // String is too small for the starting point\n+        if (start > stringValue.length() || stringValue.length() + start < 0) {\n+            return;\n+        }\n+        final int startPos = start < 0 ? (stringValue.length() + start) : start;\n+        final int len = Math.min(startPos + length, stringValue.length());\n+        for (int i = 0; i < len; i++) {\n+            for (int nGram : nGrams) {\n+                if (startPos + i + nGram - 1 >= len) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0618709d9bc8bffabc68f8a46ce332ea10a06678"}, "originalPosition": 189}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjg0NjEzMQ==", "bodyText": "I found this confusing at first because I thought the analyzed fields should include the ngram f.x fields and exclude the TEXT_FIELD. setAnalyzedFields is now poorly named it is more like setFetchedFields.\nIs there a way of specifying which ngrams fields should be modelled or indeed for the output of any pre-processor which fields are used?", "url": "https://github.com/elastic/elasticsearch/pull/61578#discussion_r482846131", "createdAt": "2020-09-03T09:38:20Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/ml/qa/native-multi-node-tests/src/test/java/org/elasticsearch/xpack/ml/integration/DataFrameAnalysisCustomFeatureIT.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.integration;\n+\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.action.DocWriteRequest;\n+import org.elasticsearch.action.admin.indices.refresh.RefreshRequest;\n+import org.elasticsearch.action.bulk.BulkRequestBuilder;\n+import org.elasticsearch.action.bulk.BulkResponse;\n+import org.elasticsearch.action.get.GetResponse;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.search.SearchHit;\n+import org.elasticsearch.search.SearchModule;\n+import org.elasticsearch.search.fetch.subphase.FetchSourceContext;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsDest;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsSource;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.BoostedTreeParams;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.MlDataFrameAnalysisNamedXContentProvider;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.MlInferenceNamedXContentProvider;\n+import org.elasticsearch.xpack.core.ml.inference.preprocessing.NGram;\n+import org.elasticsearch.xpack.core.ml.utils.QueryProvider;\n+import org.junit.After;\n+import org.junit.Before;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.everyItem;\n+import static org.hamcrest.Matchers.hasKey;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.startsWith;\n+\n+public class DataFrameAnalysisCustomFeatureIT extends MlNativeDataFrameAnalyticsIntegTestCase {\n+\n+    private static final String BOOLEAN_FIELD = \"boolean-field\";\n+    private static final String NUMERICAL_FIELD = \"numerical-field\";\n+    private static final String DISCRETE_NUMERICAL_FIELD = \"discrete-numerical-field\";\n+    private static final String TEXT_FIELD = \"text-field\";\n+    private static final String KEYWORD_FIELD = \"keyword-field\";\n+    private static final String NESTED_FIELD = \"outer-field.inner-field\";\n+    private static final String ALIAS_TO_KEYWORD_FIELD = \"alias-to-keyword-field\";\n+    private static final String ALIAS_TO_NESTED_FIELD = \"alias-to-nested-field\";\n+    private static final List<Boolean> BOOLEAN_FIELD_VALUES = List.of(false, true);\n+    private static final List<Double> NUMERICAL_FIELD_VALUES = List.of(1.0, 2.0);\n+    private static final List<Integer> DISCRETE_NUMERICAL_FIELD_VALUES = List.of(10, 20);\n+    private static final List<String> KEYWORD_FIELD_VALUES = List.of(\"cat\", \"dog\");\n+\n+    private String jobId;\n+    private String sourceIndex;\n+    private String destIndex;\n+\n+    @Before\n+    public void setupLogging() {\n+        client().admin().cluster()\n+            .prepareUpdateSettings()\n+            .setTransientSettings(Settings.builder()\n+                .put(\"logger.org.elasticsearch.xpack.ml.dataframe\", \"DEBUG\")\n+                .put(\"logger.org.elasticsearch.xpack.core.ml.inference\", \"DEBUG\"))\n+            .get();\n+    }\n+\n+    @After\n+    public void cleanup() {\n+        cleanUp();\n+        client().admin().cluster()\n+            .prepareUpdateSettings()\n+            .setTransientSettings(Settings.builder()\n+                .putNull(\"logger.org.elasticsearch.xpack.ml.dataframe\")\n+                .putNull(\"logger.org.elasticsearch.xpack.core.ml.inference\"))\n+            .get();\n+    }\n+\n+    @Override\n+    protected NamedXContentRegistry xContentRegistry() {\n+        SearchModule searchModule = new SearchModule(Settings.EMPTY, Collections.emptyList());\n+        List<NamedXContentRegistry.Entry> entries = new ArrayList<>(searchModule.getNamedXContents());\n+        entries.addAll(new MlInferenceNamedXContentProvider().getNamedXContentParsers());\n+        entries.addAll(new MlDataFrameAnalysisNamedXContentProvider().getNamedXContentParsers());\n+        return new NamedXContentRegistry(entries);\n+    }\n+\n+    public void testNGramCustomFeature() throws Exception {\n+        initialize(\"test_ngram_feature_processor\");\n+        String predictedClassField = NUMERICAL_FIELD + \"_prediction\";\n+        indexData(sourceIndex, 300, 50, NUMERICAL_FIELD);\n+\n+        DataFrameAnalyticsConfig config = new DataFrameAnalyticsConfig.Builder()\n+            .setId(jobId)\n+            .setSource(new DataFrameAnalyticsSource(new String[] { sourceIndex },\n+                QueryProvider.fromParsedQuery(QueryBuilders.matchAllQuery()), null))\n+            .setDest(new DataFrameAnalyticsDest(destIndex, null))\n+            .setAnalysis(new Regression(NUMERICAL_FIELD,\n+                BoostedTreeParams.builder().setNumTopFeatureImportanceValues(6).build(),\n+                null,\n+                null,\n+                42L,\n+                null,\n+                null,\n+                Collections.singletonList(new NGram(TEXT_FIELD, \"f\", new int[]{1, 2}, 0, 2, true))))\n+            .setAnalyzedFields(new FetchSourceContext(true, new String[]{TEXT_FIELD, NUMERICAL_FIELD}, new String[]{}))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0618709d9bc8bffabc68f8a46ce332ea10a06678"}, "originalPosition": 115}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3150398bdb0457d57851061febdd0773a88a62f3", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/3150398bdb0457d57851061febdd0773a88a62f3", "committedDate": "2020-09-03T12:55:03Z", "message": "addressing pr comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "72fe14a0910e485e3fecfb5fcb1bf427e099ee1e", "author": {"user": {"login": "elasticmachine", "name": "Elastic Machine"}}, "url": "https://github.com/elastic/elasticsearch/commit/72fe14a0910e485e3fecfb5fcb1bf427e099ee1e", "committedDate": "2020-09-03T13:06:52Z", "message": "Merge branch 'master' into feature/ml-analytics-ngram-processor"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0baae5cbbb8a228530e2e1e80cb65a4e130dd6c0", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/0baae5cbbb8a228530e2e1e80cb65a4e130dd6c0", "committedDate": "2020-09-03T14:22:46Z", "message": "moving integration test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "686f47301088006fbb5343a1f5d0e90e995e1baf", "author": {"user": {"login": "benwtrent", "name": "Benjamin Trent"}}, "url": "https://github.com/elastic/elasticsearch/commit/686f47301088006fbb5343a1f5d0e90e995e1baf", "committedDate": "2020-09-03T14:23:00Z", "message": "Merge remote-tracking branch 'upstream/master' into feature/ml-analytics-ngram-processor"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4563, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}