{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDUxMTE2MDA0", "number": 59773, "title": "Add field type for version strings", "bodyText": "This PR adds a new 'version' field type that allows indexing string values\nrepresenting software versions similar to the ones defined in the Semantic\nVersioning definition (semver.org). The field behaves very similar to a\n'keyword' field but allows efficient sorting and range queries that take into\naccound the special ordering needed for version strings. For example, the main\nversion parts are sorted numerically (ie 2.0.0 < 11.0.0) whereas this wouldn't\nbe possible with 'keyword' fields today.\nValid version values are similar to the Semantic Versioning definition, with the\nnotable exception that in addition to the \"main\" version consiting of\nmajor.minor.patch, we allow less or more than three numeric identifiers, i.e.\n\"1.2\" or \"1.4.6.123.12\" are treated as valid too.\nRelates to #48878", "createdAt": "2020-07-17T13:12:17Z", "url": "https://github.com/elastic/elasticsearch/pull/59773", "merged": true, "mergeCommit": {"oid": "ea2dbd93b492b8032ef6919a55320206fde782a2"}, "closed": true, "closedAt": "2020-09-21T09:04:23Z", "author": {"login": "cbuescher"}, "timelineItems": {"totalCount": 76, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc10CH1gBqjM1NTgxODk4ODk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdKG6IOAH2gAyNDUxMTE2MDA0OjY4NDk1NTA4OTRkYTJiYzQxZmNkOTMwMGZjNDU5Y2UyZjk4NWRlNGY=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "43d470b5694449772c401c62f3379e3f05a797b0", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/43d470b5694449772c401c62f3379e3f05a797b0", "committedDate": "2020-07-17T13:09:32Z", "message": "Add field type for version strings\n\nThis PR adds a new 'version' field type that allows indexing string values\nrepresenting software versions similar to the ones defined in the Semantic\nVersioning definition (semver.org). The field behaves very similar to a\n'keyword' field but allows efficient sorting and range queries that take into\naccound the special ordering needed for version strings. For example, the main\nversion parts are sorted numerically (ie 2.0.0 < 11.0.0) whereas this wouldn't\nbe possible with 'keyword' fields today.\n\nValid version values are similar to the Semantic Versioning definition, with the\nnotable exception that in addition to the \"main\" version consiting of\nmajor.minor.patch, we allow less or more than three numeric identifiers, i.e.\n\"1.2\" or \"1.4.6.123.12\" are treated as valid too.\n\nRelates to #48878"}, "afterCommit": {"oid": "2cd8f1d3a5b96cb139cf93eb26f2ffcaa6ac8bba", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/2cd8f1d3a5b96cb139cf93eb26f2ffcaa6ac8bba", "committedDate": "2020-07-17T13:33:26Z", "message": "Add field type for version strings\n\nThis PR adds a new 'version' field type that allows indexing string values\nrepresenting software versions similar to the ones defined in the Semantic\nVersioning definition (semver.org). The field behaves very similar to a\n'keyword' field but allows efficient sorting and range queries that take into\naccound the special ordering needed for version strings. For example, the main\nversion parts are sorted numerically (ie 2.0.0 < 11.0.0) whereas this wouldn't\nbe possible with 'keyword' fields today.\n\nValid version values are similar to the Semantic Versioning definition, with the\nnotable exception that in addition to the \"main\" version consiting of\nmajor.minor.patch, we allow less or more than three numeric identifiers, i.e.\n\"1.2\" or \"1.4.6.123.12\" are treated as valid too.\n\nRelates to #48878"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "343310c129ff67a4cb6d2e034ca538b56bf9ae9c", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/343310c129ff67a4cb6d2e034ca538b56bf9ae9c", "committedDate": "2020-07-20T09:00:20Z", "message": "Add field type for version strings\n\nThis PR adds a new 'version' field type that allows indexing string values\nrepresenting software versions similar to the ones defined in the Semantic\nVersioning definition (semver.org). The field behaves very similar to a\n'keyword' field but allows efficient sorting and range queries that take into\naccound the special ordering needed for version strings. For example, the main\nversion parts are sorted numerically (ie 2.0.0 < 11.0.0) whereas this wouldn't\nbe possible with 'keyword' fields today.\n\nValid version values are similar to the Semantic Versioning definition, with the\nnotable exception that in addition to the \"main\" version consiting of\nmajor.minor.patch, we allow less or more than three numeric identifiers, i.e.\n\"1.2\" or \"1.4.6.123.12\" are treated as valid too.\n\nRelates to #48878"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2cd8f1d3a5b96cb139cf93eb26f2ffcaa6ac8bba", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/2cd8f1d3a5b96cb139cf93eb26f2ffcaa6ac8bba", "committedDate": "2020-07-17T13:33:26Z", "message": "Add field type for version strings\n\nThis PR adds a new 'version' field type that allows indexing string values\nrepresenting software versions similar to the ones defined in the Semantic\nVersioning definition (semver.org). The field behaves very similar to a\n'keyword' field but allows efficient sorting and range queries that take into\naccound the special ordering needed for version strings. For example, the main\nversion parts are sorted numerically (ie 2.0.0 < 11.0.0) whereas this wouldn't\nbe possible with 'keyword' fields today.\n\nValid version values are similar to the Semantic Versioning definition, with the\nnotable exception that in addition to the \"main\" version consiting of\nmajor.minor.patch, we allow less or more than three numeric identifiers, i.e.\n\"1.2\" or \"1.4.6.123.12\" are treated as valid too.\n\nRelates to #48878"}, "afterCommit": {"oid": "343310c129ff67a4cb6d2e034ca538b56bf9ae9c", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/343310c129ff67a4cb6d2e034ca538b56bf9ae9c", "committedDate": "2020-07-20T09:00:20Z", "message": "Add field type for version strings\n\nThis PR adds a new 'version' field type that allows indexing string values\nrepresenting software versions similar to the ones defined in the Semantic\nVersioning definition (semver.org). The field behaves very similar to a\n'keyword' field but allows efficient sorting and range queries that take into\naccound the special ordering needed for version strings. For example, the main\nversion parts are sorted numerically (ie 2.0.0 < 11.0.0) whereas this wouldn't\nbe possible with 'keyword' fields today.\n\nValid version values are similar to the Semantic Versioning definition, with the\nnotable exception that in addition to the \"main\" version consiting of\nmajor.minor.patch, we allow less or more than three numeric identifiers, i.e.\n\"1.2\" or \"1.4.6.123.12\" are treated as valid too.\n\nRelates to #48878"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "397a7c036827cbae0a7460da250d2df5e177d769", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/397a7c036827cbae0a7460da250d2df5e177d769", "committedDate": "2020-07-20T17:26:59Z", "message": "Add yaml for search, ranges and scripting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "08989e7c345da41fa7d75a93e56dcd17be413aba", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/08989e7c345da41fa7d75a93e56dcd17be413aba", "committedDate": "2020-07-22T17:17:57Z", "message": "Add brute force regex query support"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9b249a108a9859f66017610470a40b51fe52ccd5", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/9b249a108a9859f66017610470a40b51fe52ccd5", "committedDate": "2020-07-22T17:10:44Z", "message": "Add brute force regex query support"}, "afterCommit": {"oid": "08989e7c345da41fa7d75a93e56dcd17be413aba", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/08989e7c345da41fa7d75a93e56dcd17be413aba", "committedDate": "2020-07-22T17:17:57Z", "message": "Add brute force regex query support"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8a1acc28939452ec3fc6b6c9ee7165403dd944bf", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/8a1acc28939452ec3fc6b6c9ee7165403dd944bf", "committedDate": "2020-07-23T13:13:14Z", "message": "Add fuzzy query support"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bc972ad1474f5817f9ab6633f0059b30be621c0d", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/bc972ad1474f5817f9ab6633f0059b30be621c0d", "committedDate": "2020-07-23T13:36:07Z", "message": "Merge branch 'master' into add-version-field"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5bac78553dff91c4d2c8e4c5f9d1a92ff6453ceb", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/5bac78553dff91c4d2c8e4c5f9d1a92ff6453ceb", "committedDate": "2020-07-23T16:04:04Z", "message": "Remove some left-over commented code"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/8a7b43cadd5bf89d3e6069057290139f17a5bd3f", "committedDate": "2020-07-23T16:48:19Z", "message": "Adding tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU1NzkxOTc4", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-455791978", "createdAt": "2020-07-27T13:41:55Z", "commit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxMzo0MTo1NVrOG3i-Xg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxMzo0MTo1NVrOG3i-Xg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDg5Nzg4Ng==", "bodyText": "What's the need of  extra TypeParsers.parseMultiField on line 169 if TypeParsers.parseField on line 155 already takes care of multi-field?   Should we choose one of these 2 options?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r460897886", "createdAt": "2020-07-27T13:41:55Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,550 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.support.XContentMapValues;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+        private boolean storeMalformed = false;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        Builder storeMalformed(boolean storeMalformed) {\n+            this.storeMalformed = storeMalformed;\n+            return builder;\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            boolean validateVersion = storeMalformed == false;\n+            return new VersionStringFieldType(buildFullName(context), indexed, validateVersion, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                storeMalformed,\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                } else if (propName.equals(\"store_malformed\")) {\n+                    builder.storeMalformed(XContentMapValues.nodeBooleanValue(propNode, name + \".store_malformed\"));\n+                    iterator.remove();\n+                } else if (TypeParsers.parseMultiField(builder::addMultiField, name, parserContext, propName, propNode)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 169}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU1ODQ5MDgy", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-455849082", "createdAt": "2020-07-27T14:41:41Z", "commit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxNDo0MTo0MVrOG3lo-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxNDo0MTo0MVrOG3lo-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk0MTU2Mw==", "bodyText": "Should we override and disallow indexOptions in Builder, similarly how NumberFieldMapper#Builder does it?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r460941563", "createdAt": "2020-07-27T14:41:41Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,550 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.support.XContentMapValues;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+        private boolean storeMalformed = false;\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 103}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU1ODYwNzg1", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-455860785", "createdAt": "2020-07-27T14:53:52Z", "commit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxNDo1Mzo1MlrOG3mMlw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxNDo1Mzo1MlrOG3mMlw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk1MDY3OQ==", "bodyText": "Do we want to assign nullValue here as as well in cases where a string is empty or null?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r460950679", "createdAt": "2020-07-27T14:53:52Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,550 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.support.XContentMapValues;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+        private boolean storeMalformed = false;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        Builder storeMalformed(boolean storeMalformed) {\n+            this.storeMalformed = storeMalformed;\n+            return builder;\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            boolean validateVersion = storeMalformed == false;\n+            return new VersionStringFieldType(buildFullName(context), indexed, validateVersion, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                storeMalformed,\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                } else if (propName.equals(\"store_malformed\")) {\n+                    builder.storeMalformed(XContentMapValues.nodeBooleanValue(propNode, name + \".store_malformed\"));\n+                    iterator.remove();\n+                } else if (TypeParsers.parseMultiField(builder::addMultiField, name, parserContext, propName, propNode)) {\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        // if true, we want to throw errors on illegal versions at index and query time\n+        private boolean validateVersion = false;\n+\n+        public VersionStringFieldType(\n+            String name,\n+            boolean isSearchable,\n+            boolean validateVersion,\n+            Map<String, String> meta,\n+            float boost,\n+            FieldType fieldType\n+        ) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+            this.validateVersion = validateVersion;\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            EncodedVersion encodedVersion = encodeVersion(valueAsString);\n+            if (encodedVersion.isLegal == false && validateVersion) {\n+                throw new IllegalArgumentException(\"Illegal version string: \" + valueAsString);\n+            }\n+            return encodedVersion.bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private boolean storeMalformed;\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        boolean storeMalformed,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.storeMalformed = storeMalformed;\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 460}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU2MDY4NzA3", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-456068707", "createdAt": "2020-07-27T19:24:03Z", "commit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxOToyNDowM1rOG3wS1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QyMTo0Mzo0OVrOG30sBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTExNjExNg==", "bodyText": "RELESE -> RELEASE (and same issue below)", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461116116", "createdAt": "2020-07-27T19:24:03Z", "author": {"login": "jtibshirani"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantiv Versioning (https://semver.org/)\n+ *\n+ * Version strings are considered to consist of three parts:\n+ * <ul>\n+ *  <li> a numeric major.minor.patch part starting the version string (e.g. 1.2.3)\n+ *  <li> an optional \"pre-release\" part that starts with a `-` character and can consist of several alpha-numerical sections\n+ *  separated by dots (e.g. \"-alpha.2.3\")\n+ *  <li> an optional \"build\" part that starts with a `+` character. This will simply be treated as a prefix with no guaranteed ordering,\n+ *  (although the ordering should be alphabetical in most cases).\n+ * </ul>\n+ *\n+ * The version string is encoded such that the ordering works like the following:\n+ * <ul>\n+ *  <li> Major, minor, and patch versions are always compared numerically\n+ *  <li> pre-release version have lower precedence than a normal version. (e.g 1.0.0-alpha &lt; 1.0.0)\n+ *  <li> the precedence for pre-release versions with same main version is calculated comparing each dot separated identifier from\n+ *  left to right. Identifiers consisting of only digits are compared numerically and identifiers with letters or hyphens are compared\n+ *  lexically in ASCII sort order. Numeric identifiers always have lower precedence than non-numeric identifiers.\n+ * </ul>\n+ */\n+class VersionEncoder {\n+\n+    public static final byte NUMERIC_MARKER_BYTE = (byte) 0x01;\n+    public static final byte PRERELESE_SEPARATOR_BYTE = (byte) 0x02;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTExNjI4NA==", "bodyText": "Semantiv -> Semantic", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461116284", "createdAt": "2020-07-27T19:24:23Z", "author": {"login": "jtibshirani"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantiv Versioning (https://semver.org/)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTExNzYyOA==", "bodyText": "This will simply be treated as a prefix with no guaranteed ordering, (although the ordering should be alphabetical in most cases).\n\nI'm not sure what this part means, could you clarify the behavior?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461117628", "createdAt": "2020-07-27T19:26:56Z", "author": {"login": "jtibshirani"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantiv Versioning (https://semver.org/)\n+ *\n+ * Version strings are considered to consist of three parts:\n+ * <ul>\n+ *  <li> a numeric major.minor.patch part starting the version string (e.g. 1.2.3)\n+ *  <li> an optional \"pre-release\" part that starts with a `-` character and can consist of several alpha-numerical sections\n+ *  separated by dots (e.g. \"-alpha.2.3\")\n+ *  <li> an optional \"build\" part that starts with a `+` character. This will simply be treated as a prefix with no guaranteed ordering,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE2NzI3NQ==", "bodyText": "Super small comment, you could just return Map.of(VersionStringFieldMapper.CONTENT_TYPE, new VersionStringFieldMapper.TypeParser())?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461167275", "createdAt": "2020-07-27T21:01:07Z", "author": {"login": "jtibshirani"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionFieldPlugin.java", "diffHunk": "@@ -0,0 +1,28 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.plugins.MapperPlugin;\n+import org.elasticsearch.plugins.Plugin;\n+\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+public class VersionFieldPlugin extends Plugin implements MapperPlugin {\n+\n+    public VersionFieldPlugin(Settings settings) {}\n+\n+    @Override\n+    public Map<String, Mapper.TypeParser> getMappers() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE2ODUzNQ==", "bodyText": "Great unit test coverage!", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461168535", "createdAt": "2020-07-27T21:03:37Z", "author": {"login": "jtibshirani"}, "path": "x-pack/plugin/versionfield/src/test/java/org/elasticsearch/xpack/versionfield/VersionEncoderTests.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.util.Arrays;\n+\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.decodeVersion;\n+\n+public class VersionEncoderTests extends ESTestCase {\n+\n+    public void testEncodingOrderingSemver() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE4MjY0OQ==", "bodyText": "I actually wonder if this type should support null_value at all. I can't think of an example where it'd be useful to supply a default value for a version. And what could the default value even be?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461182649", "createdAt": "2020-07-27T21:32:14Z", "author": {"login": "jtibshirani"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,550 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.support.XContentMapValues;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+        private boolean storeMalformed = false;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        Builder storeMalformed(boolean storeMalformed) {\n+            this.storeMalformed = storeMalformed;\n+            return builder;\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            boolean validateVersion = storeMalformed == false;\n+            return new VersionStringFieldType(buildFullName(context), indexed, validateVersion, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                storeMalformed,\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                } else if (propName.equals(\"store_malformed\")) {\n+                    builder.storeMalformed(XContentMapValues.nodeBooleanValue(propNode, name + \".store_malformed\"));\n+                    iterator.remove();\n+                } else if (TypeParsers.parseMultiField(builder::addMultiField, name, parserContext, propName, propNode)) {\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        // if true, we want to throw errors on illegal versions at index and query time\n+        private boolean validateVersion = false;\n+\n+        public VersionStringFieldType(\n+            String name,\n+            boolean isSearchable,\n+            boolean validateVersion,\n+            Map<String, String> meta,\n+            float boost,\n+            FieldType fieldType\n+        ) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+            this.validateVersion = validateVersion;\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            EncodedVersion encodedVersion = encodeVersion(valueAsString);\n+            if (encodedVersion.isLegal == false && validateVersion) {\n+                throw new IllegalArgumentException(\"Illegal version string: \" + valueAsString);\n+            }\n+            return encodedVersion.bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private boolean storeMalformed;\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        boolean storeMalformed,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.storeMalformed = storeMalformed;\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk1MDY3OQ=="}, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 460}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE4ODEwMg==", "bodyText": "Small comment, maybe we could have a constructor (or static factory method) to create illegal versions, like EncodedVersion.createIllegalVersion(versionString) ? This would avoid exposing the option to create an illegal version plus parsed components.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461188102", "createdAt": "2020-07-27T21:43:49Z", "author": {"login": "jtibshirani"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantiv Versioning (https://semver.org/)\n+ *\n+ * Version strings are considered to consist of three parts:\n+ * <ul>\n+ *  <li> a numeric major.minor.patch part starting the version string (e.g. 1.2.3)\n+ *  <li> an optional \"pre-release\" part that starts with a `-` character and can consist of several alpha-numerical sections\n+ *  separated by dots (e.g. \"-alpha.2.3\")\n+ *  <li> an optional \"build\" part that starts with a `+` character. This will simply be treated as a prefix with no guaranteed ordering,\n+ *  (although the ordering should be alphabetical in most cases).\n+ * </ul>\n+ *\n+ * The version string is encoded such that the ordering works like the following:\n+ * <ul>\n+ *  <li> Major, minor, and patch versions are always compared numerically\n+ *  <li> pre-release version have lower precedence than a normal version. (e.g 1.0.0-alpha &lt; 1.0.0)\n+ *  <li> the precedence for pre-release versions with same main version is calculated comparing each dot separated identifier from\n+ *  left to right. Identifiers consisting of only digits are compared numerically and identifiers with letters or hyphens are compared\n+ *  lexically in ASCII sort order. Numeric identifiers always have lower precedence than non-numeric identifiers.\n+ * </ul>\n+ */\n+class VersionEncoder {\n+\n+    public static final byte NUMERIC_MARKER_BYTE = (byte) 0x01;\n+    public static final byte PRERELESE_SEPARATOR_BYTE = (byte) 0x02;\n+    public static final byte NO_PRERELESE_SEPARATOR_BYTE = (byte) 0x03;\n+\n+    private static final char PRERELESE_SEPARATOR = '-';\n+    private static final char DOT_SEPARATOR = '.';\n+    private static final char BUILD_SEPARATOR = '+';\n+\n+    // Regex to test relaxed Semver Main Version validity. Allows for more or less than three main version parts\n+    private static Pattern LEGAL_MAIN_VERSION_SEMVER = Pattern.compile(\"(0|[1-9]\\\\d*)(\\\\.(0|[1-9]\\\\d*))*\");\n+\n+    private static Pattern LEGAL_PRERELEASE_VERSION_SEMVER = Pattern.compile(\n+        \"(?:-((?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\\\\.(?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*))*))\"\n+    );\n+\n+    private static Pattern LEGAL_BUILDSUFFIX_SEMVER = Pattern.compile(\"(?:\\\\+([0-9a-zA-Z-]+(?:\\\\.[0-9a-zA-Z-]+)*))?\");\n+\n+    /**\n+     * Encodes a version string.\n+     */\n+    public static EncodedVersion encodeVersion(String versionString) {\n+        VersionParts versionParts = VersionParts.ofVersion(versionString);\n+\n+        // don't treat non-legal versions further, just mark them as illegal and return\n+        if (legalVersionString(versionParts) == false) {\n+            return new EncodedVersion(new BytesRef(versionString), false, true, 0, 0, 0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 64}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "910616e5ebf560c60e29d42d8b10e53c10781df7", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/910616e5ebf560c60e29d42d8b10e53c10781df7", "committedDate": "2020-07-28T13:01:32Z", "message": "Make string_stats work"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6d71b52424efa5423f9d4603a00706cb34561639", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/6d71b52424efa5423f9d4603a00706cb34561639", "committedDate": "2020-07-28T13:07:03Z", "message": "Merge branch 'master' into add-version-field"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU2NjM3ODkw", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-456637890", "createdAt": "2020-07-28T13:37:00Z", "commit": {"oid": "6d71b52424efa5423f9d4603a00706cb34561639"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxMzozNzowMFrOG4M7VA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxMzozNzowMFrOG4M7VA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTU4NTIzNg==", "bodyText": "may be worth separating this function into 2 functions: one that just prefix digit group with length and another one extracts main versions?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461585236", "createdAt": "2020-07-28T13:37:00Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantiv Versioning (https://semver.org/)\n+ *\n+ * Version strings are considered to consist of three parts:\n+ * <ul>\n+ *  <li> a numeric major.minor.patch part starting the version string (e.g. 1.2.3)\n+ *  <li> an optional \"pre-release\" part that starts with a `-` character and can consist of several alpha-numerical sections\n+ *  separated by dots (e.g. \"-alpha.2.3\")\n+ *  <li> an optional \"build\" part that starts with a `+` character. This will simply be treated as a prefix with no guaranteed ordering,\n+ *  (although the ordering should be alphabetical in most cases).\n+ * </ul>\n+ *\n+ * The version string is encoded such that the ordering works like the following:\n+ * <ul>\n+ *  <li> Major, minor, and patch versions are always compared numerically\n+ *  <li> pre-release version have lower precedence than a normal version. (e.g 1.0.0-alpha &lt; 1.0.0)\n+ *  <li> the precedence for pre-release versions with same main version is calculated comparing each dot separated identifier from\n+ *  left to right. Identifiers consisting of only digits are compared numerically and identifiers with letters or hyphens are compared\n+ *  lexically in ASCII sort order. Numeric identifiers always have lower precedence than non-numeric identifiers.\n+ * </ul>\n+ */\n+class VersionEncoder {\n+\n+    public static final byte NUMERIC_MARKER_BYTE = (byte) 0x01;\n+    public static final byte PRERELESE_SEPARATOR_BYTE = (byte) 0x02;\n+    public static final byte NO_PRERELESE_SEPARATOR_BYTE = (byte) 0x03;\n+\n+    private static final char PRERELESE_SEPARATOR = '-';\n+    private static final char DOT_SEPARATOR = '.';\n+    private static final char BUILD_SEPARATOR = '+';\n+\n+    // Regex to test relaxed Semver Main Version validity. Allows for more or less than three main version parts\n+    private static Pattern LEGAL_MAIN_VERSION_SEMVER = Pattern.compile(\"(0|[1-9]\\\\d*)(\\\\.(0|[1-9]\\\\d*))*\");\n+\n+    private static Pattern LEGAL_PRERELEASE_VERSION_SEMVER = Pattern.compile(\n+        \"(?:-((?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\\\\.(?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*))*))\"\n+    );\n+\n+    private static Pattern LEGAL_BUILDSUFFIX_SEMVER = Pattern.compile(\"(?:\\\\+([0-9a-zA-Z-]+(?:\\\\.[0-9a-zA-Z-]+)*))?\");\n+\n+    /**\n+     * Encodes a version string.\n+     */\n+    public static EncodedVersion encodeVersion(String versionString) {\n+        VersionParts versionParts = VersionParts.ofVersion(versionString);\n+\n+        // don't treat non-legal versions further, just mark them as illegal and return\n+        if (legalVersionString(versionParts) == false) {\n+            return new EncodedVersion(new BytesRef(versionString), false, true, 0, 0, 0);\n+        }\n+\n+        BytesRefBuilder encodedBytes = new BytesRefBuilder();\n+        Integer[] mainVersionParts = prefixDigitGroupsWithLength(versionParts.mainVersion, encodedBytes);\n+\n+        if (versionParts.preRelease != null) {\n+            encodedBytes.append(PRERELESE_SEPARATOR_BYTE);  // versions with pre-release part sort before ones without\n+            encodedBytes.append((byte) PRERELESE_SEPARATOR);\n+            String[] preReleaseParts = versionParts.preRelease.substring(1).split(\"\\\\.\");\n+            boolean first = true;\n+            for (String preReleasePart : preReleaseParts) {\n+                if (first == false) {\n+                    encodedBytes.append((byte) DOT_SEPARATOR);\n+                }\n+                boolean isNumeric = preReleasePart.chars().allMatch(x -> Character.isDigit(x));\n+                if (isNumeric) {\n+                    prefixDigitGroupsWithLength(preReleasePart, encodedBytes);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6d71b52424efa5423f9d4603a00706cb34561639"}, "originalPosition": 81}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU2NzU2Njk4", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-456756698", "createdAt": "2020-07-28T15:33:24Z", "commit": {"oid": "6d71b52424efa5423f9d4603a00706cb34561639"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxNTozMzoyNFrOG4Sdmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxNTozMzoyNFrOG4Sdmw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY3NTkzMQ==", "bodyText": "That's quite a clever encoding! Nice work! What I like about it is that it allows the decoding to the original values.\nAnother way to do encoding I was thinking of is to standardize main versions to 3 bytes (1 byte of each component), but standardization would not allow the decoding to the original values.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461675931", "createdAt": "2020-07-28T15:33:24Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantiv Versioning (https://semver.org/)\n+ *\n+ * Version strings are considered to consist of three parts:\n+ * <ul>\n+ *  <li> a numeric major.minor.patch part starting the version string (e.g. 1.2.3)\n+ *  <li> an optional \"pre-release\" part that starts with a `-` character and can consist of several alpha-numerical sections\n+ *  separated by dots (e.g. \"-alpha.2.3\")\n+ *  <li> an optional \"build\" part that starts with a `+` character. This will simply be treated as a prefix with no guaranteed ordering,\n+ *  (although the ordering should be alphabetical in most cases).\n+ * </ul>\n+ *\n+ * The version string is encoded such that the ordering works like the following:\n+ * <ul>\n+ *  <li> Major, minor, and patch versions are always compared numerically\n+ *  <li> pre-release version have lower precedence than a normal version. (e.g 1.0.0-alpha &lt; 1.0.0)\n+ *  <li> the precedence for pre-release versions with same main version is calculated comparing each dot separated identifier from\n+ *  left to right. Identifiers consisting of only digits are compared numerically and identifiers with letters or hyphens are compared\n+ *  lexically in ASCII sort order. Numeric identifiers always have lower precedence than non-numeric identifiers.\n+ * </ul>\n+ */\n+class VersionEncoder {\n+\n+    public static final byte NUMERIC_MARKER_BYTE = (byte) 0x01;\n+    public static final byte PRERELESE_SEPARATOR_BYTE = (byte) 0x02;\n+    public static final byte NO_PRERELESE_SEPARATOR_BYTE = (byte) 0x03;\n+\n+    private static final char PRERELESE_SEPARATOR = '-';\n+    private static final char DOT_SEPARATOR = '.';\n+    private static final char BUILD_SEPARATOR = '+';\n+\n+    // Regex to test relaxed Semver Main Version validity. Allows for more or less than three main version parts\n+    private static Pattern LEGAL_MAIN_VERSION_SEMVER = Pattern.compile(\"(0|[1-9]\\\\d*)(\\\\.(0|[1-9]\\\\d*))*\");\n+\n+    private static Pattern LEGAL_PRERELEASE_VERSION_SEMVER = Pattern.compile(\n+        \"(?:-((?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\\\\.(?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*))*))\"\n+    );\n+\n+    private static Pattern LEGAL_BUILDSUFFIX_SEMVER = Pattern.compile(\"(?:\\\\+([0-9a-zA-Z-]+(?:\\\\.[0-9a-zA-Z-]+)*))?\");\n+\n+    /**\n+     * Encodes a version string.\n+     */\n+    public static EncodedVersion encodeVersion(String versionString) {\n+        VersionParts versionParts = VersionParts.ofVersion(versionString);\n+\n+        // don't treat non-legal versions further, just mark them as illegal and return\n+        if (legalVersionString(versionParts) == false) {\n+            return new EncodedVersion(new BytesRef(versionString), false, true, 0, 0, 0);\n+        }\n+\n+        BytesRefBuilder encodedBytes = new BytesRefBuilder();\n+        Integer[] mainVersionParts = prefixDigitGroupsWithLength(versionParts.mainVersion, encodedBytes);\n+\n+        if (versionParts.preRelease != null) {\n+            encodedBytes.append(PRERELESE_SEPARATOR_BYTE);  // versions with pre-release part sort before ones without\n+            encodedBytes.append((byte) PRERELESE_SEPARATOR);\n+            String[] preReleaseParts = versionParts.preRelease.substring(1).split(\"\\\\.\");\n+            boolean first = true;\n+            for (String preReleasePart : preReleaseParts) {\n+                if (first == false) {\n+                    encodedBytes.append((byte) DOT_SEPARATOR);\n+                }\n+                boolean isNumeric = preReleasePart.chars().allMatch(x -> Character.isDigit(x));\n+                if (isNumeric) {\n+                    prefixDigitGroupsWithLength(preReleasePart, encodedBytes);\n+                } else {\n+                    encodedBytes.append(new BytesRef(preReleasePart));\n+                }\n+                first = false;\n+            }\n+        } else {\n+            encodedBytes.append(NO_PRERELESE_SEPARATOR_BYTE);\n+        }\n+\n+        if (versionParts.buildSuffix != null) {\n+            encodedBytes.append(new BytesRef(versionParts.buildSuffix));\n+        }\n+        return new EncodedVersion(\n+            encodedBytes.toBytesRef(),\n+            true,\n+            versionParts.preRelease != null,\n+            mainVersionParts[0],\n+            mainVersionParts[1],\n+            mainVersionParts[2]\n+        );\n+    }\n+\n+    private static Integer[] prefixDigitGroupsWithLength(String input, BytesRefBuilder result) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6d71b52424efa5423f9d4603a00706cb34561639"}, "originalPosition": 104}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "970085acc0c3cc275c91b66d9881d094456b280e", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/970085acc0c3cc275c91b66d9881d094456b280e", "committedDate": "2020-07-28T16:27:39Z", "message": "Adressing review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bdb89a2b1fa58da41732c5876494b3da23f54eee", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/bdb89a2b1fa58da41732c5876494b3da23f54eee", "committedDate": "2020-07-29T16:11:21Z", "message": "Remove 'store_malformed' option"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0b04c25e693bf8fd4f673455e5bdd5819f489031", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/0b04c25e693bf8fd4f673455e5bdd5819f489031", "committedDate": "2020-07-29T17:16:29Z", "message": "Add tests for handling empty string"}, "afterCommit": {"oid": "4433c5c49123f39806bcc5f43c2bf0c421a04c9e", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/4433c5c49123f39806bcc5f43c2bf0c421a04c9e", "committedDate": "2020-07-29T17:19:07Z", "message": "Add tests for handling empty string"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "81bb1146b555f27f8890ee876600e760dc51c963", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/81bb1146b555f27f8890ee876600e760dc51c963", "committedDate": "2020-07-29T17:25:26Z", "message": "Add tests for handling empty string"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4433c5c49123f39806bcc5f43c2bf0c421a04c9e", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/4433c5c49123f39806bcc5f43c2bf0c421a04c9e", "committedDate": "2020-07-29T17:19:07Z", "message": "Add tests for handling empty string"}, "afterCommit": {"oid": "81bb1146b555f27f8890ee876600e760dc51c963", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/81bb1146b555f27f8890ee876600e760dc51c963", "committedDate": "2020-07-29T17:25:26Z", "message": "Add tests for handling empty string"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5fcf8a73916f2aa635d5fe9b2a8ea557ad62c9ac", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/5fcf8a73916f2aa635d5fe9b2a8ea557ad62c9ac", "committedDate": "2020-07-30T10:19:09Z", "message": "fix yaml test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/1f3c99593c9812bdd9eae80872b5a3a7e8b5652c", "committedDate": "2020-07-30T10:19:15Z", "message": "Merge branch 'master' into add-version-field"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU4Mjc2MTQx", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-458276141", "createdAt": "2020-07-30T10:25:22Z", "commit": {"oid": "81bb1146b555f27f8890ee876600e760dc51c963"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxMDoyNjo0MFrOG5dSfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxMDo1MTozMFrOG5eBGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkwMTg4Nw==", "bodyText": "Should we index BinaryPoint only when indexOptions() != IndexOptions.NONE (because currently this field will be indexed even when IndexOptions.NONE and stored=true) ?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462901887", "createdAt": "2020-07-30T10:26:40Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);\n+            context.doc().add(field);\n+            // encode the first 16 bytes as points for efficient range query\n+            byte[] first16bytes = Arrays.copyOfRange(encodedVersion.bytes, encodedVersion.offset, 16);\n+            context.doc().add(new BinaryPoint(fieldType().name(), first16bytes));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 448}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkwMzI2OQ==", "bodyText": "Should we create this field only when hasDocValues() == true?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462903269", "createdAt": "2020-07-30T10:29:21Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);\n+            context.doc().add(field);\n+            // encode the first 16 bytes as points for efficient range query\n+            byte[] first16bytes = Arrays.copyOfRange(encodedVersion.bytes, encodedVersion.offset, 16);\n+            context.doc().add(new BinaryPoint(fieldType().name(), first16bytes));\n+        }\n+        context.doc().add(new SortedSetDocValuesField(fieldType().name(), encodedVersion));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 450}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkwMzc1Nw==", "bodyText": "Should we create all the fields below only when indexOptions() != IndexOptions.NONE  and SortedNumericDocValuesField when hasDocValues() == true?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462903757", "createdAt": "2020-07-30T10:30:15Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);\n+            context.doc().add(field);\n+            // encode the first 16 bytes as points for efficient range query\n+            byte[] first16bytes = Arrays.copyOfRange(encodedVersion.bytes, encodedVersion.offset, 16);\n+            context.doc().add(new BinaryPoint(fieldType().name(), first16bytes));\n+        }\n+        context.doc().add(new SortedSetDocValuesField(fieldType().name(), encodedVersion));\n+\n+        // add additional information extracted from version string", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 452}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkwOTAzOQ==", "bodyText": "I am wondering if this query still should be considering expensive if with  a binaryPoint query we can efficiently narrow down terms?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462909039", "createdAt": "2020-07-30T10:41:08Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 352}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkxMzgxOA==", "bodyText": "I was also wondering since lowerTerm and upperTerm represent valid versions can we extract major, minor, patch fields  and use them for querying to further narrow down terms?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462913818", "createdAt": "2020-07-30T10:51:30Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkwOTAzOQ=="}, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 352}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU4MzA0NDgy", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-458304482", "createdAt": "2020-07-30T11:12:26Z", "commit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxMToxMjoyNlrOG5en_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxMjoxOTo0M1rOG5gj2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkyMzc3Mg==", "bodyText": "I don't think we should apply this setting here. It's a specialized type so we should make this query fast and/or harmless if it's useful ?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462923772", "createdAt": "2020-07-30T11:12:26Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 188}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkzNzI2NQ==", "bodyText": "For specialized type we're trying to limit the number of options. It's perfectly ok to have a new field with no option at all so I think we should start with a clean state and discuss any addition.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462937265", "createdAt": "2020-07-30T11:41:07Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 151}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkzODgxNQ==", "bodyText": "I'd assume that we are in control and that the index_options are fixed. These options are not relevant in this context imo.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462938815", "createdAt": "2020-07-30T11:44:35Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 443}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk0MTkyMw==", "bodyText": "I don't see any use of these fields in queries. Is it for future optimizations ? That seems premature, the primary heuristic should be quite fast already.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462941923", "createdAt": "2020-07-30T11:51:28Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);\n+            context.doc().add(field);\n+            // encode the first 16 bytes as points for efficient range query\n+            byte[] first16bytes = Arrays.copyOfRange(encodedVersion.bytes, encodedVersion.offset, 16);\n+            context.doc().add(new BinaryPoint(fieldType().name(), first16bytes));\n+        }\n+        context.doc().add(new SortedSetDocValuesField(fieldType().name(), encodedVersion));\n+\n+        // add additional information extracted from version string\n+        context.doc().add(new Field(prereleaseSubField.name(), encoding.isPreRelease ? \"T\" : \"F\", BooleanFieldMapper.Defaults.FIELD_TYPE));\n+        context.doc().add(new SortedNumericDocValuesField(prereleaseSubField.name(), encoding.isPreRelease ? 1 : 0));\n+\n+        addVersionPartSubfield(context, majorVersionSubField.name(), encoding.major);\n+        addVersionPartSubfield(context, minorVersionSubField.name(), encoding.minor);\n+        addVersionPartSubfield(context, patchVersionSubField.name(), encoding.patch);\n+    }\n+\n+    private void addVersionPartSubfield(ParseContext context, String fieldName, Integer versionPart) {\n+        if (versionPart != null) {\n+            context.doc().addAll(NumberType.INTEGER.createFields(fieldName, versionPart, true, true, false));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 463}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk0MjM1NQ==", "bodyText": "There's also the cost of indexing three more points so I'd lean towards limiting the number of indexed/points fields.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462942355", "createdAt": "2020-07-30T11:52:19Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);\n+            context.doc().add(field);\n+            // encode the first 16 bytes as points for efficient range query\n+            byte[] first16bytes = Arrays.copyOfRange(encodedVersion.bytes, encodedVersion.offset, 16);\n+            context.doc().add(new BinaryPoint(fieldType().name(), first16bytes));\n+        }\n+        context.doc().add(new SortedSetDocValuesField(fieldType().name(), encodedVersion));\n+\n+        // add additional information extracted from version string\n+        context.doc().add(new Field(prereleaseSubField.name(), encoding.isPreRelease ? \"T\" : \"F\", BooleanFieldMapper.Defaults.FIELD_TYPE));\n+        context.doc().add(new SortedNumericDocValuesField(prereleaseSubField.name(), encoding.isPreRelease ? 1 : 0));\n+\n+        addVersionPartSubfield(context, majorVersionSubField.name(), encoding.major);\n+        addVersionPartSubfield(context, minorVersionSubField.name(), encoding.minor);\n+        addVersionPartSubfield(context, patchVersionSubField.name(), encoding.patch);\n+    }\n+\n+    private void addVersionPartSubfield(ParseContext context, String fieldName, Integer versionPart) {\n+        if (versionPart != null) {\n+            context.doc().addAll(NumberType.INTEGER.createFields(fieldName, versionPart, true, true, false));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk0MTkyMw=="}, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 463}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk0OTI1OA==", "bodyText": "That seems redundant. If I understand correctly, the encoded version is stored in three structures:\n\n\nFully encoded version in Postings\n\n\nThe first 16 bytes of the encoded version in Points\n\n\nFully encoded version in SortedSetDocValues\n\n\nThe main benefit of indexing Points is that you don't need the postings. We can use them as an approximation and rely on the doc values to validate matches in a range query. Prefix, wildcard, regex are more tricky to handle with Points so I guess that is why you also create an indexed Field. However, I think we should only pick one strategy. The current approach is too costly imo, we should control the indexing cost more carefully.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462949258", "createdAt": "2020-07-30T12:07:38Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 444}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk1NTQ4MQ==", "bodyText": "The two queries that you mixed are totally independent so the resulting boolean query is just more costly than a plain TermRangeQuery.\nThe idea behind using a prefix query on Points is that you can use the doc values to validate the matches. You can check how the wildcard field does  since it's very similar. The AutomatonQueryOnBinaryDv leverages the TwoPhaseIterator to only validate documents found by other filter (the point range query approximation).\nAs I said in previous comments, I think we need to make a choice. Relying on Points or Postings is ok but not both.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462955481", "createdAt": "2020-07-30T12:19:43Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 378}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU4NjMwMzQ2", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-458630346", "createdAt": "2020-07-30T17:55:35Z", "commit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxNzo1NTozNVrOG5tyYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxNzo1NTozNVrOG5tyYg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzE3MjE5NA==", "bodyText": "Do you need to register this format in NamedWriteableRegistry like we register other format in SearchModule#registerValueFormats?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r463172194", "createdAt": "2020-07-30T17:55:35Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);\n+            context.doc().add(field);\n+            // encode the first 16 bytes as points for efficient range query\n+            byte[] first16bytes = Arrays.copyOfRange(encodedVersion.bytes, encodedVersion.offset, 16);\n+            context.doc().add(new BinaryPoint(fieldType().name(), first16bytes));\n+        }\n+        context.doc().add(new SortedSetDocValuesField(fieldType().name(), encodedVersion));\n+\n+        // add additional information extracted from version string\n+        context.doc().add(new Field(prereleaseSubField.name(), encoding.isPreRelease ? \"T\" : \"F\", BooleanFieldMapper.Defaults.FIELD_TYPE));\n+        context.doc().add(new SortedNumericDocValuesField(prereleaseSubField.name(), encoding.isPreRelease ? 1 : 0));\n+\n+        addVersionPartSubfield(context, majorVersionSubField.name(), encoding.major);\n+        addVersionPartSubfield(context, minorVersionSubField.name(), encoding.minor);\n+        addVersionPartSubfield(context, patchVersionSubField.name(), encoding.patch);\n+    }\n+\n+    private void addVersionPartSubfield(ParseContext context, String fieldName, Integer versionPart) {\n+        if (versionPart != null) {\n+            context.doc().addAll(NumberType.INTEGER.createFields(fieldName, versionPart, true, true, false));\n+        }\n+    }\n+\n+    @Override\n+    protected void mergeOptions(FieldMapper other, List<String> conflicts) {\n+        VersionStringFieldMapper mergeWith = (VersionStringFieldMapper) other;\n+        this.nullValue = mergeWith.nullValue;\n+    }\n+\n+    @Override\n+    protected void doXContentBody(XContentBuilder builder, boolean includeDefaults, Params params) throws IOException {\n+        super.doXContentBody(builder, includeDefaults, params);\n+        if (nullValue != null) {\n+            builder.field(\"null_value\", nullValue);\n+        }\n+    }\n+\n+    @Override\n+    public Iterator<Mapper> iterator() {\n+        List<Mapper> subIterators = new ArrayList<>();\n+        subIterators.add(prereleaseSubField);\n+        subIterators.add(majorVersionSubField);\n+        subIterators.add(minorVersionSubField);\n+        subIterators.add(patchVersionSubField);\n+        @SuppressWarnings(\"unchecked\")\n+        Iterator<Mapper> concat = Iterators.concat(super.iterator(), subIterators.iterator());\n+        return concat;\n+    }\n+\n+    @Override\n+    protected Object parseSourceValue(Object value, String format) {\n+        if (format != null) {\n+            throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] doesn't support formats.\");\n+        }\n+        return value.toString();\n+    }\n+\n+    private static DocValueFormat VERSION_DOCVALUE = new DocValueFormat() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 501}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cfe2dbab69de9fd5e84c46de8a274f69c8514cf9", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/cfe2dbab69de9fd5e84c46de8a274f69c8514cf9", "committedDate": "2020-07-31T14:23:04Z", "message": "Change range query to points approximation and dv validation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c70e7c1d0d98915ec25d97cba02fb790dbd57c60", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/c70e7c1d0d98915ec25d97cba02fb790dbd57c60", "committedDate": "2020-07-31T19:36:25Z", "message": "Register DocValueFormat via plugin"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e45ef4a468063de43acedb7251be529ade0f2ae5", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/e45ef4a468063de43acedb7251be529ade0f2ae5", "committedDate": "2020-08-17T13:08:34Z", "message": "Merge branch 'master' into add-version-field"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "24651d17dbbc252a87eb75c70462b6f699a9b56f", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/24651d17dbbc252a87eb75c70462b6f699a9b56f", "committedDate": "2020-08-20T14:24:15Z", "message": "Merge branch 'master' into add-version-field"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "57b040f04cace55f54f3ecf40e37dbbbdb17ac05", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/57b040f04cace55f54f3ecf40e37dbbbdb17ac05", "committedDate": "2020-08-20T14:36:07Z", "message": "Add valueFetcher() method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c321e0dc4bb7c4124131fb8debcfa59bfe9e48bf", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/c321e0dc4bb7c4124131fb8debcfa59bfe9e48bf", "committedDate": "2020-08-21T09:28:56Z", "message": "Merge branch 'master' of github.com:elastic/elasticsearch into add-version-field"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5b902fb308a8e4c8144891bdb6983fe2b44dabeb", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/5b902fb308a8e4c8144891bdb6983fe2b44dabeb", "committedDate": "2020-08-21T18:12:47Z", "message": "Restrict field options by moving to ParametrizedFieldMapper"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "758b83494c7c08d165291556cfa60bb2f6223aed", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/758b83494c7c08d165291556cfa60bb2f6223aed", "committedDate": "2020-08-26T10:20:21Z", "message": "Merge branch 'master' into add-version-field"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eaa1ef8dd3ba0a8f4cd7ec646bf3ebecd726c801", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/eaa1ef8dd3ba0a8f4cd7ec646bf3ebecd726c801", "committedDate": "2020-08-26T10:26:11Z", "message": "Change range query validation part"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc4NDkwNjcx", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-478490671", "createdAt": "2020-08-31T10:25:34Z", "commit": {"oid": "eaa1ef8dd3ba0a8f4cd7ec646bf3ebecd726c801"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQxMDoyNTozNFrOHJy_-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQxMDoyNTozNFrOHJy_-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDAzNDgxMQ==", "bodyText": "You don't need to add the validation query if the lower and upper values have less than 17 bytes ?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r480034811", "createdAt": "2020-08-31T10:25:34Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,483 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.ConstantScoreQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery87;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type, false, false);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type, false, false);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type, false, false);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build(),\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int syntaxFlags,\n+            int matchFlags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery87 query = new RegexpQuery87(new Term(name(), new BytesRef(value)), syntaxFlags, matchFlags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query validationQuery = SortedSetDocValuesField.newSlowRangeQuery(name(), lower, upper, includeLower, includeUpper);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eaa1ef8dd3ba0a8f4cd7ec646bf3ebecd726c801"}, "originalPosition": 338}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "82a40abaaade4f96bf5bc84b5b37591fa544f770", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/82a40abaaade4f96bf5bc84b5b37591fa544f770", "committedDate": "2020-08-31T14:06:35Z", "message": "Small improvement to range query using points"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dacf8134bbb479673753d06b269cf0503b206de4", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/dacf8134bbb479673753d06b269cf0503b206de4", "committedDate": "2020-08-31T14:42:21Z", "message": "Merge branch 'master' into add-version-field"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e4b0728c0bae90c936bb1dd926d2ec4c6f247b81", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/e4b0728c0bae90c936bb1dd926d2ec4c6f247b81", "committedDate": "2020-09-02T16:22:31Z", "message": "Add helper methods to versions ScriptDocValues to help with version part extraction"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3c72862f77aceecd1648f6c058ac79473db6d4c4", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/3c72862f77aceecd1648f6c058ac79473db6d4c4", "committedDate": "2020-09-02T16:23:05Z", "message": "Merge branch 'master' into add-version-field"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4de9a2ed24d167c83974a2d29a0a0893183fe8be", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/4de9a2ed24d167c83974a2d29a0a0893183fe8be", "committedDate": "2020-09-08T12:23:30Z", "message": "Merge branch 'master' into add-version-field"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6c3266e055fd91ba16d22ecb72b9a5604b1724d3", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/6c3266e055fd91ba16d22ecb72b9a5604b1724d3", "committedDate": "2020-09-08T12:36:48Z", "message": "Removing points and subfields"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b26a3f1864d7f1fa2e9af3e9fced4beb941ab2d0", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/b26a3f1864d7f1fa2e9af3e9fced4beb941ab2d0", "committedDate": "2020-09-08T14:21:05Z", "message": "Add tests for new regex case-insensitivity option"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb", "committedDate": "2020-09-09T14:21:09Z", "message": "Adding docs"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg2MzA5MTU3", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-486309157", "createdAt": "2020-09-10T21:04:19Z", "commit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMTowNDoyMFrOHQFsMg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMTowNDoyMFrOHQFsMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjYzMjQ5OA==", "bodyText": "@cbuescher  I am curious why you considered version to be a part of keyword family?\nI would rather say that it should be a part of structured or other category?\nAlso curious what @jtibshirani  thinks as she worked on this organization.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r486632498", "createdAt": "2020-09-10T21:04:20Z", "author": {"login": "mayya-sharipova"}, "path": "docs/reference/mapping/types/keyword.asciidoc", "diffHunk": "@@ -129,3 +129,5 @@ The following parameters are accepted by `keyword` fields:\n include::constant-keyword.asciidoc[]\n \n include::wildcard.asciidoc[]\n+\n+include::version.asciidoc[]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg2MzExMjU2", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-486311256", "createdAt": "2020-09-10T21:07:39Z", "commit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMTowNzozOVrOHQFyjw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMTowNzozOVrOHQFyjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjYzNDEyNw==", "bodyText": "\"Not that\" => \"Note that\"?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r486634127", "createdAt": "2020-09-10T21:07:39Z", "author": {"login": "mayya-sharipova"}, "path": "docs/reference/mapping/types/version.asciidoc", "diffHunk": "@@ -0,0 +1,125 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[discrete]\n+[[version-field-type]]\n+=== Version field type\n+\n+The `version` field type is a specialization of the `keyword` field for\n+handling software version values and to support specialized precedence\n+rules for them. Precedence is defined following the rules outlined by\n+https://semver.org/[Semantic Versioning], which for example means that\n+major, minor and patch version parts are sorted numerically (i.e. \n+\"2.1.0\" < \"2.4.1\" < \"2.11.2\") and pre-release versions are sorted before\n+release versiond (i.e. \"1.0.0-alpha\" < \"1.0.0\").\n+\n+You index a `version` field as follows\n+\n+[source,console]\n+--------------------------------------------------\n+PUT my-index-000001\n+{\n+  \"mappings\": {\n+    \"properties\": {\n+      \"my_version\": {\n+        \"type\": \"version\"\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+\n+The field offers the same search capabilities as a regular keyword field. It \n+can e.g. be searched for exact matches using `match` or `term` queries and\n+supports prefix and wildcard searches. The main benefit is that `range` queries\n+will honour Semver ordering, so a `range` query between \"1.0.0\" and \"1.5.0\"\n+will include versions of \"1.2.3\" but not \"1.11.2\" for example. Not that this", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 36}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg2MzEyNTgw", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-486312580", "createdAt": "2020-09-10T21:09:54Z", "commit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMTowOTo1NFrOHQF2ow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMTowOTo1NFrOHQF2ow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjYzNTE3MQ==", "bodyText": "\"with regular alphabetical ordering\" =>  I am not quite sure what it means?  Are we sorting versions by an alphabetical ordering?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r486635171", "createdAt": "2020-09-10T21:09:54Z", "author": {"login": "mayya-sharipova"}, "path": "docs/reference/mapping/types/version.asciidoc", "diffHunk": "@@ -0,0 +1,125 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[discrete]\n+[[version-field-type]]\n+=== Version field type\n+\n+The `version` field type is a specialization of the `keyword` field for\n+handling software version values and to support specialized precedence\n+rules for them. Precedence is defined following the rules outlined by\n+https://semver.org/[Semantic Versioning], which for example means that\n+major, minor and patch version parts are sorted numerically (i.e. \n+\"2.1.0\" < \"2.4.1\" < \"2.11.2\") and pre-release versions are sorted before\n+release versiond (i.e. \"1.0.0-alpha\" < \"1.0.0\").\n+\n+You index a `version` field as follows\n+\n+[source,console]\n+--------------------------------------------------\n+PUT my-index-000001\n+{\n+  \"mappings\": {\n+    \"properties\": {\n+      \"my_version\": {\n+        \"type\": \"version\"\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+\n+The field offers the same search capabilities as a regular keyword field. It \n+can e.g. be searched for exact matches using `match` or `term` queries and\n+supports prefix and wildcard searches. The main benefit is that `range` queries\n+will honour Semver ordering, so a `range` query between \"1.0.0\" and \"1.5.0\"\n+will include versions of \"1.2.3\" but not \"1.11.2\" for example. Not that this\n+would be different when using a regular `keyword` field for indexing where ordering\n+is alphabetical.\n+\n+Software versions are expected to follow the\n+https://semver.org/[Semantic Versioning rules] schema and precedence rules with\n+the notable exception that more or less than three main version identifiers are\n+allowed (i.e. \"1.2\" or \"1.2.3.4\" qualify as valid versions while they wouldn't under\n+strict Semver rules). Version strings that are not valid under the Semver definition\n+(e.g. \"1.2.alpha.4\") can still be indexed and retrieved as exact matches, however they\n+will all appear _after_ any valid version with regular alphabetical ordering. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 46}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg2MzEzNTk1", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-486313595", "createdAt": "2020-09-10T21:11:42Z", "commit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMToxMTo0MlrOHQF6EQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMToxMTo0MlrOHQF6EQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjYzNjA0OQ==", "bodyText": "wildcard fields => version fields?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r486636049", "createdAt": "2020-09-10T21:11:42Z", "author": {"login": "mayya-sharipova"}, "path": "docs/reference/mapping/types/version.asciidoc", "diffHunk": "@@ -0,0 +1,125 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[discrete]\n+[[version-field-type]]\n+=== Version field type\n+\n+The `version` field type is a specialization of the `keyword` field for\n+handling software version values and to support specialized precedence\n+rules for them. Precedence is defined following the rules outlined by\n+https://semver.org/[Semantic Versioning], which for example means that\n+major, minor and patch version parts are sorted numerically (i.e. \n+\"2.1.0\" < \"2.4.1\" < \"2.11.2\") and pre-release versions are sorted before\n+release versiond (i.e. \"1.0.0-alpha\" < \"1.0.0\").\n+\n+You index a `version` field as follows\n+\n+[source,console]\n+--------------------------------------------------\n+PUT my-index-000001\n+{\n+  \"mappings\": {\n+    \"properties\": {\n+      \"my_version\": {\n+        \"type\": \"version\"\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+\n+The field offers the same search capabilities as a regular keyword field. It \n+can e.g. be searched for exact matches using `match` or `term` queries and\n+supports prefix and wildcard searches. The main benefit is that `range` queries\n+will honour Semver ordering, so a `range` query between \"1.0.0\" and \"1.5.0\"\n+will include versions of \"1.2.3\" but not \"1.11.2\" for example. Not that this\n+would be different when using a regular `keyword` field for indexing where ordering\n+is alphabetical.\n+\n+Software versions are expected to follow the\n+https://semver.org/[Semantic Versioning rules] schema and precedence rules with\n+the notable exception that more or less than three main version identifiers are\n+allowed (i.e. \"1.2\" or \"1.2.3.4\" qualify as valid versions while they wouldn't under\n+strict Semver rules). Version strings that are not valid under the Semver definition\n+(e.g. \"1.2.alpha.4\") can still be indexed and retrieved as exact matches, however they\n+will all appear _after_ any valid version with regular alphabetical ordering. \n+\n+[discrete]\n+[[version-params]]\n+==== Parameters for wildcard fields", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 50}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg3NjE4NDA1", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-487618405", "createdAt": "2020-09-14T10:23:49Z", "commit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMDoyMzo1MFrOHRNa6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMDoyMzo1MFrOHRNa6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzgwNzcyMg==", "bodyText": "Does this plugin need to implement ActionPlugin? It doesn't look like it provides new actions.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487807722", "createdAt": "2020-09-14T10:23:50Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionFieldPlugin.java", "diffHunk": "@@ -0,0 +1,39 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.elasticsearch.common.io.stream.NamedWriteableRegistry;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.plugins.ActionPlugin;\n+import org.elasticsearch.plugins.MapperPlugin;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.search.DocValueFormat;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+public class VersionFieldPlugin extends Plugin implements ActionPlugin, MapperPlugin {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 20}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg3NjM3MDQw", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-487637040", "createdAt": "2020-09-14T10:51:47Z", "commit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMDo1MTo0N1rOHROTyw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMDo1MTo0N1rOHROTyw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzgyMjI4Mw==", "bodyText": "I am wondering  if we should also have  a doc_values parameter?\nSince our range query doesn't depend on doc_values anymore, I am thinking may be a user can opt out of indexing doc_values if they don't need sorting, aggregation of this field, and script queries on pre-release, major, minor and patch", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487822283", "createdAt": "2020-09-14T10:51:47Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 93}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg3Njg1NjE2", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-487685616", "createdAt": "2020-09-14T12:06:36Z", "commit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjowNjozN1rOHRQnHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjowNjozN1rOHRQnHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg1OTk5OQ==", "bodyText": "may be also add a note about empty strings, where they will be in sorted order?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487859999", "createdAt": "2020-09-14T12:06:37Z", "author": {"login": "mayya-sharipova"}, "path": "docs/reference/mapping/types/version.asciidoc", "diffHunk": "@@ -0,0 +1,125 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[discrete]\n+[[version-field-type]]\n+=== Version field type\n+\n+The `version` field type is a specialization of the `keyword` field for\n+handling software version values and to support specialized precedence\n+rules for them. Precedence is defined following the rules outlined by\n+https://semver.org/[Semantic Versioning], which for example means that\n+major, minor and patch version parts are sorted numerically (i.e. \n+\"2.1.0\" < \"2.4.1\" < \"2.11.2\") and pre-release versions are sorted before\n+release versiond (i.e. \"1.0.0-alpha\" < \"1.0.0\").\n+\n+You index a `version` field as follows\n+\n+[source,console]\n+--------------------------------------------------\n+PUT my-index-000001\n+{\n+  \"mappings\": {\n+    \"properties\": {\n+      \"my_version\": {\n+        \"type\": \"version\"\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+\n+The field offers the same search capabilities as a regular keyword field. It \n+can e.g. be searched for exact matches using `match` or `term` queries and\n+supports prefix and wildcard searches. The main benefit is that `range` queries\n+will honour Semver ordering, so a `range` query between \"1.0.0\" and \"1.5.0\"\n+will include versions of \"1.2.3\" but not \"1.11.2\" for example. Not that this\n+would be different when using a regular `keyword` field for indexing where ordering\n+is alphabetical.\n+\n+Software versions are expected to follow the\n+https://semver.org/[Semantic Versioning rules] schema and precedence rules with\n+the notable exception that more or less than three main version identifiers are\n+allowed (i.e. \"1.2\" or \"1.2.3.4\" qualify as valid versions while they wouldn't under\n+strict Semver rules). Version strings that are not valid under the Semver definition\n+(e.g. \"1.2.alpha.4\") can still be indexed and retrieved as exact matches, however they", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 45}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg3Njg4NjMx", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-487688631", "createdAt": "2020-09-14T12:10:50Z", "commit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjoxMDo1MFrOHRQwSA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjoxMDo1MFrOHRQwSA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg2MjM0NA==", "bodyText": "if we decide to always index a field with doc values, this failIfNoDocValues() check seems unnecessary.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487862344", "createdAt": "2020-09-14T12:10:50Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build()\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int syntaxFlags,\n+            int matchFlags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), syntaxFlags, matchFlags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName, Supplier<SearchLookup> searchLookup) {\n+            failIfNoDocValues();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 280}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg3NjkxMTMw", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-487691130", "createdAt": "2020-09-14T12:14:27Z", "commit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjoxNDoyN1rOHRQ3_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjoxNDoyN1rOHRQ3_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg2NDMxOA==", "bodyText": "from your last benchmarking tests, rangeQuery doesn't seem to be expensive, so this check to allow expensive queries looks unnecessary to me. WDYT?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487864318", "createdAt": "2020-09-14T12:14:27Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build()\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int syntaxFlags,\n+            int matchFlags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), syntaxFlags, matchFlags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName, Supplier<SearchLookup> searchLookup) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 307}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg3NjkyMTQz", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-487692143", "createdAt": "2020-09-14T12:15:55Z", "commit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjoxNTo1NlrOHRQ7Fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjoxNTo1NlrOHRQ7Fw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg2NTExMQ==", "bodyText": "Doesn't seem that a user has an option not to index a field. So this check looks unnecessary", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487865111", "createdAt": "2020-09-14T12:15:56Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build()\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int syntaxFlags,\n+            int matchFlags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), syntaxFlags, matchFlags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName, Supplier<SearchLookup> searchLookup) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 314}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg3Njk4MTUw", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-487698150", "createdAt": "2020-09-14T12:24:21Z", "commit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjoyNDoyMVrOHRRNbw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjoyNDoyMVrOHRRNbw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg2OTgwNw==", "bodyText": "nit: \"rexexp\"  -> \"regexp\"", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487869807", "createdAt": "2020-09-14T12:24:21Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build()\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 159}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg3NzA5NTEx", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-487709511", "createdAt": "2020-09-14T12:38:51Z", "commit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjozODo1MVrOHRRwAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjozODo1MVrOHRRwAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg3ODY1Nw==", "bodyText": "For getMajor, getMinor, and getPatch functions should we provide more details, e.g \"returns Integer ... if a version is valid, or null otherwise..`", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487878657", "createdAt": "2020-09-14T12:38:51Z", "author": {"login": "mayya-sharipova"}, "path": "docs/reference/mapping/types/version.asciidoc", "diffHunk": "@@ -0,0 +1,125 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[discrete]\n+[[version-field-type]]\n+=== Version field type\n+\n+The `version` field type is a specialization of the `keyword` field for\n+handling software version values and to support specialized precedence\n+rules for them. Precedence is defined following the rules outlined by\n+https://semver.org/[Semantic Versioning], which for example means that\n+major, minor and patch version parts are sorted numerically (i.e. \n+\"2.1.0\" < \"2.4.1\" < \"2.11.2\") and pre-release versions are sorted before\n+release versiond (i.e. \"1.0.0-alpha\" < \"1.0.0\").\n+\n+You index a `version` field as follows\n+\n+[source,console]\n+--------------------------------------------------\n+PUT my-index-000001\n+{\n+  \"mappings\": {\n+    \"properties\": {\n+      \"my_version\": {\n+        \"type\": \"version\"\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+\n+The field offers the same search capabilities as a regular keyword field. It \n+can e.g. be searched for exact matches using `match` or `term` queries and\n+supports prefix and wildcard searches. The main benefit is that `range` queries\n+will honour Semver ordering, so a `range` query between \"1.0.0\" and \"1.5.0\"\n+will include versions of \"1.2.3\" but not \"1.11.2\" for example. Not that this\n+would be different when using a regular `keyword` field for indexing where ordering\n+is alphabetical.\n+\n+Software versions are expected to follow the\n+https://semver.org/[Semantic Versioning rules] schema and precedence rules with\n+the notable exception that more or less than three main version identifiers are\n+allowed (i.e. \"1.2\" or \"1.2.3.4\" qualify as valid versions while they wouldn't under\n+strict Semver rules). Version strings that are not valid under the Semver definition\n+(e.g. \"1.2.alpha.4\") can still be indexed and retrieved as exact matches, however they\n+will all appear _after_ any valid version with regular alphabetical ordering. \n+\n+[discrete]\n+[[version-params]]\n+==== Parameters for wildcard fields\n+\n+The following parameters are accepted by `version` fields:\n+\n+[horizontal]\n+\n+<<mapping-field-meta,`meta`>>::\n+\n+    Metadata about the field.\n+\n+[discrete]\n+==== Limitations\n+\n+This field type isn't optimized for heavy wildcard, regex or fuzzy searches. While those\n+type of queries work in this field, you should consider using a regular `keyword` field if\n+you strongly rely on these kind of queries.\n+\n+==== Script support\n+\n+TBD: The `version` fields offers some specialized access to detailed information derived from\n+valid version strings like the Major, Minor or Patch release number, whether the version value\n+is valid according to Semver or if it is a pre-release version. This can be helpful when e.g.\n+filtering for only released versions or running aggregations on parts of the version.\n+The following query, for example, filters for released versions and groups them by Major version\n+using a `terms` aggregation:\n+\n+[source,console]\n+--------------------------------------------------\n+POST my-index-000001/_search\n+{\n+  \"query\": {\n+    \"bool\": {\n+      \"filter\": [\n+        {\n+          \"script\": {\n+            \"script\": {\n+              \"source\": \"doc['my_version'].isPreRelease() == false\"\n+            }\n+          }\n+        }\n+      ]\n+    }\n+  },\n+  \"aggs\": {\n+    \"group_major\": {\n+      \"terms\": {\n+        \"script\": { \"source\": \"doc['my_version'].getMajor()\"},\n+        \"order\": {\n+          \"_key\": \"asc\"\n+        }\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+// TEST[continued]\n+\n+Functions available on via doc values in scripting are:\n+\n+[horizontal]\n+\n+isValid()::\n+    Returns `true` if the field contains a version thats legal according to the Semantic Versioning rules\n+\n+isPreRelease()::\n+    Returns `true` if the field contains a pre-release version\n+    \n+getMajor()::\n+    Returns the Major version for valid versions.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 119}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg3NzEwMzUy", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-487710352", "createdAt": "2020-09-14T12:39:56Z", "commit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjozOTo1NlrOHRRycg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjozOTo1NlrOHRRycg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg3OTI4Mg==", "bodyText": "should we also add that false is returned if a version is invalid? Or may be these functions should fail if the version is invalid than it will be up to a user to guard agains this?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487879282", "createdAt": "2020-09-14T12:39:56Z", "author": {"login": "mayya-sharipova"}, "path": "docs/reference/mapping/types/version.asciidoc", "diffHunk": "@@ -0,0 +1,125 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[discrete]\n+[[version-field-type]]\n+=== Version field type\n+\n+The `version` field type is a specialization of the `keyword` field for\n+handling software version values and to support specialized precedence\n+rules for them. Precedence is defined following the rules outlined by\n+https://semver.org/[Semantic Versioning], which for example means that\n+major, minor and patch version parts are sorted numerically (i.e. \n+\"2.1.0\" < \"2.4.1\" < \"2.11.2\") and pre-release versions are sorted before\n+release versiond (i.e. \"1.0.0-alpha\" < \"1.0.0\").\n+\n+You index a `version` field as follows\n+\n+[source,console]\n+--------------------------------------------------\n+PUT my-index-000001\n+{\n+  \"mappings\": {\n+    \"properties\": {\n+      \"my_version\": {\n+        \"type\": \"version\"\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+\n+The field offers the same search capabilities as a regular keyword field. It \n+can e.g. be searched for exact matches using `match` or `term` queries and\n+supports prefix and wildcard searches. The main benefit is that `range` queries\n+will honour Semver ordering, so a `range` query between \"1.0.0\" and \"1.5.0\"\n+will include versions of \"1.2.3\" but not \"1.11.2\" for example. Not that this\n+would be different when using a regular `keyword` field for indexing where ordering\n+is alphabetical.\n+\n+Software versions are expected to follow the\n+https://semver.org/[Semantic Versioning rules] schema and precedence rules with\n+the notable exception that more or less than three main version identifiers are\n+allowed (i.e. \"1.2\" or \"1.2.3.4\" qualify as valid versions while they wouldn't under\n+strict Semver rules). Version strings that are not valid under the Semver definition\n+(e.g. \"1.2.alpha.4\") can still be indexed and retrieved as exact matches, however they\n+will all appear _after_ any valid version with regular alphabetical ordering. \n+\n+[discrete]\n+[[version-params]]\n+==== Parameters for wildcard fields\n+\n+The following parameters are accepted by `version` fields:\n+\n+[horizontal]\n+\n+<<mapping-field-meta,`meta`>>::\n+\n+    Metadata about the field.\n+\n+[discrete]\n+==== Limitations\n+\n+This field type isn't optimized for heavy wildcard, regex or fuzzy searches. While those\n+type of queries work in this field, you should consider using a regular `keyword` field if\n+you strongly rely on these kind of queries.\n+\n+==== Script support\n+\n+TBD: The `version` fields offers some specialized access to detailed information derived from\n+valid version strings like the Major, Minor or Patch release number, whether the version value\n+is valid according to Semver or if it is a pre-release version. This can be helpful when e.g.\n+filtering for only released versions or running aggregations on parts of the version.\n+The following query, for example, filters for released versions and groups them by Major version\n+using a `terms` aggregation:\n+\n+[source,console]\n+--------------------------------------------------\n+POST my-index-000001/_search\n+{\n+  \"query\": {\n+    \"bool\": {\n+      \"filter\": [\n+        {\n+          \"script\": {\n+            \"script\": {\n+              \"source\": \"doc['my_version'].isPreRelease() == false\"\n+            }\n+          }\n+        }\n+      ]\n+    }\n+  },\n+  \"aggs\": {\n+    \"group_major\": {\n+      \"terms\": {\n+        \"script\": { \"source\": \"doc['my_version'].getMajor()\"},\n+        \"order\": {\n+          \"_key\": \"asc\"\n+        }\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+// TEST[continued]\n+\n+Functions available on via doc values in scripting are:\n+\n+[horizontal]\n+\n+isValid()::\n+    Returns `true` if the field contains a version thats legal according to the Semantic Versioning rules\n+\n+isPreRelease()::\n+    Returns `true` if the field contains a pre-release version", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 116}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg3NzEyODMy", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-487712832", "createdAt": "2020-09-14T12:43:08Z", "commit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjo0MzowOFrOHRR6BQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjo0MzowOFrOHRR6BQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg4MTIyMQ==", "bodyText": "For other script doc values, if a document doesn't have a value, we raise an error. I was wondering if we should do the same here, or keyword based fields behave differently?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487881221", "createdAt": "2020-09-14T12:43:08Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionScriptDocValues.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.index.SortedSetDocValues;\n+import org.apache.lucene.util.ArrayUtil;\n+import org.elasticsearch.index.fielddata.ScriptDocValues;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.VersionParts;\n+\n+import java.io.IOException;\n+\n+public final class VersionScriptDocValues extends ScriptDocValues<String> {\n+\n+    private final SortedSetDocValues in;\n+    private long[] ords = new long[0];\n+    private int count;\n+\n+    public VersionScriptDocValues(SortedSetDocValues in) {\n+        this.in = in;\n+    }\n+\n+    @Override\n+    public void setNextDocId(int docId) throws IOException {\n+        count = 0;\n+        if (in.advanceExact(docId)) {\n+            for (long ord = in.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = in.nextOrd()) {\n+                ords = ArrayUtil.grow(ords, count + 1);\n+                ords[count++] = ord;\n+            }\n+        }\n+    }\n+\n+    public String getValue() {\n+        if (count == 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 38}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d56499e2dc25ccfd36ca04bcf2b2b41deac96f6a", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/d56499e2dc25ccfd36ca04bcf2b2b41deac96f6a", "committedDate": "2020-09-14T13:09:03Z", "message": "Adressing review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7e2a4f5d424cac715748646d38da41ec626a9f6f", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/7e2a4f5d424cac715748646d38da41ec626a9f6f", "committedDate": "2020-09-14T13:18:05Z", "message": "Merge branch 'master' into add-version-field"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "94def2071ce68c386051a03cda6584892226bb14", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/94def2071ce68c386051a03cda6584892226bb14", "committedDate": "2020-09-15T12:44:47Z", "message": "Switch script method from isPreRelease to isRelease"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "67df1d387a55c795eaecacb8e49640d3a42d24b1", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/67df1d387a55c795eaecacb8e49640d3a42d24b1", "committedDate": "2020-09-15T12:46:04Z", "message": "Merge branch 'master' into add-version-field"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f1bf52f78fe9571e7299a516abe6f82988312a11", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/f1bf52f78fe9571e7299a516abe6f82988312a11", "committedDate": "2020-09-15T11:28:19Z", "message": "Switch script method from isPreRelease to isRelease"}, "afterCommit": {"oid": "67df1d387a55c795eaecacb8e49640d3a42d24b1", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/67df1d387a55c795eaecacb8e49640d3a42d24b1", "committedDate": "2020-09-15T12:46:04Z", "message": "Merge branch 'master' into add-version-field"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg4NzA2NzI0", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-488706724", "createdAt": "2020-09-15T13:52:26Z", "commit": {"oid": "67df1d387a55c795eaecacb8e49640d3a42d24b1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxMzo1MjoyNlrOHSC_GQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxMzo1MjoyNlrOHSC_GQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODY4NTMzNw==", "bodyText": "new String(new String( -> should there be only a single new String?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r488685337", "createdAt": "2020-09-15T13:52:26Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,226 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.commons.codec.Charsets;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantic Versioning (https://semver.org/)\n+ *\n+ * Version strings are considered to consist of three parts:\n+ * <ul>\n+ *  <li> a numeric major.minor.patch part starting the version string (e.g. 1.2.3)\n+ *  <li> an optional \"pre-release\" part that starts with a `-` character and can consist of several alphanumerical sections\n+ *  separated by dots (e.g. \"-alpha.2.3\")\n+ *  <li> an optional \"build\" part that starts with a `+` character. This will simply be treated as a suffix with ASCII sort order.\n+ * </ul>\n+ *\n+ * The version string is encoded such that the ordering works like the following:\n+ * <ul>\n+ *  <li> Major, minor, and patch versions are always compared numerically\n+ *  <li> pre-release version have lower precedence than a normal version. (e.g 1.0.0-alpha &lt; 1.0.0)\n+ *  <li> the precedence for pre-release versions with same main version is calculated comparing each dot separated identifier from\n+ *  left to right. Identifiers consisting of only digits are compared numerically and identifiers with letters or hyphens are compared\n+ *  lexically in ASCII sort order. Numeric identifiers always have lower precedence than non-numeric identifiers.\n+ * </ul>\n+ */\n+class VersionEncoder {\n+\n+    public static final byte NUMERIC_MARKER_BYTE = (byte) 0x01;\n+    public static final byte PRERELEASE_SEPARATOR_BYTE = (byte) 0x02;\n+    public static final byte NO_PRERELEASE_SEPARATOR_BYTE = (byte) 0x03;\n+\n+    private static final char PRERELEASE_SEPARATOR = '-';\n+    private static final char DOT_SEPARATOR = '.';\n+    private static final char BUILD_SEPARATOR = '+';\n+    private static final String ENCODED_EMPTY_STRING = new String(new String(new byte[] { NO_PRERELEASE_SEPARATOR_BYTE }, Charsets.UTF_8));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67df1d387a55c795eaecacb8e49640d3a42d24b1"}, "originalPosition": 46}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg4OTE2ODI3", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-488916827", "createdAt": "2020-09-15T17:38:00Z", "commit": {"oid": "67df1d387a55c795eaecacb8e49640d3a42d24b1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNzozODowMVrOHSM9HA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNzozODowMVrOHSM9HA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODg0ODY2OA==", "bodyText": "Do you think we need to add some illegal versions and test that sort ASC will put them at the end?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r488848668", "createdAt": "2020-09-15T17:38:01Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/test/java/org/elasticsearch/xpack/versionfield/VersionStringFieldTests.java", "diffHunk": "@@ -0,0 +1,498 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.search.SearchHit;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.bucket.terms.Terms;\n+import org.elasticsearch.search.aggregations.bucket.terms.Terms.Bucket;\n+import org.elasticsearch.search.aggregations.metrics.Cardinality;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.test.ESSingleNodeTestCase;\n+import org.elasticsearch.xpack.analytics.AnalyticsAggregationBuilders;\n+import org.elasticsearch.xpack.analytics.AnalyticsPlugin;\n+import org.elasticsearch.xpack.analytics.stringstats.InternalStringStats;\n+import org.elasticsearch.xpack.core.LocalStateCompositeXPackPlugin;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class VersionStringFieldTests extends ESSingleNodeTestCase {\n+\n+    @Override\n+    protected Collection<Class<? extends Plugin>> getPlugins() {\n+        return pluginList(VersionFieldPlugin.class, LocalStateCompositeXPackPlugin.class, AnalyticsPlugin.class);\n+    }\n+\n+    public String setUpIndex(String indexName) throws IOException {\n+        createIndex(indexName, Settings.builder().put(\"index.number_of_shards\", 1).build(), \"_doc\", \"version\", \"type=version\");\n+        ensureGreen(indexName);\n+\n+        client().prepareIndex(indexName).setId(\"1\").setSource(jsonBuilder().startObject().field(\"version\", \"11.1.0\").endObject()).get();\n+        client().prepareIndex(indexName).setId(\"2\").setSource(jsonBuilder().startObject().field(\"version\", \"1.0.0\").endObject()).get();\n+        client().prepareIndex(indexName)\n+            .setId(\"3\")\n+            .setSource(jsonBuilder().startObject().field(\"version\", \"1.3.0+build.1234567\").endObject())\n+            .get();\n+        client().prepareIndex(indexName)\n+            .setId(\"4\")\n+            .setSource(jsonBuilder().startObject().field(\"version\", \"2.1.0-alpha.beta\").endObject())\n+            .get();\n+        client().prepareIndex(indexName).setId(\"5\").setSource(jsonBuilder().startObject().field(\"version\", \"2.1.0\").endObject()).get();\n+        client().prepareIndex(indexName).setId(\"6\").setSource(jsonBuilder().startObject().field(\"version\", \"21.11.0\").endObject()).get();\n+        client().admin().indices().prepareRefresh(indexName).get();\n+        return indexName;\n+    }\n+\n+    public void testExactQueries() throws Exception {\n+        String indexName = \"test\";\n+        setUpIndex(indexName);\n+\n+        // match\n+        SearchResponse response = client().prepareSearch(indexName).setQuery(QueryBuilders.matchQuery(\"version\", (\"1.0.0\"))).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.matchQuery(\"version\", \"1.4.0\")).get();\n+        assertEquals(0, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.matchQuery(\"version\", \"1.3.0\")).get();\n+        assertEquals(0, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.matchQuery(\"version\", \"1.3.0+build.1234567\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        // term\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.termQuery(\"version\", \"1.0.0\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.termQuery(\"version\", \"1.4.0\")).get();\n+        assertEquals(0, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.termQuery(\"version\", \"1.3.0\")).get();\n+        assertEquals(0, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.termQuery(\"version\", \"1.3.0+build.1234567\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        // terms\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.termsQuery(\"version\", \"1.0.0\", \"1.3.0\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.termsQuery(\"version\", \"1.4.0\", \"1.3.0+build.1234567\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        // phrase query (just for keyword compatibility)\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.matchPhraseQuery(\"version\", \"2.1.0-alpha.beta\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+    }\n+\n+    public void testRangeQueries() throws Exception {\n+        String indexName = setUpIndex(\"test\");\n+        SearchResponse response = client().prepareSearch(indexName)\n+            .setQuery(QueryBuilders.rangeQuery(\"version\").from(\"1.0.0\").to(\"3.0.0\"))\n+            .get();\n+        assertEquals(4, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").from(\"1.1.0\").to(\"3.0.0\")).get();\n+        assertEquals(3, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName)\n+            .setQuery(QueryBuilders.rangeQuery(\"version\").from(\"0.1.0\").to(\"2.1.0-alpha.beta\"))\n+            .get();\n+        assertEquals(3, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").from(\"2.1.0\").to(\"3.0.0\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").from(\"3.0.0\").to(\"4.0.0\")).get();\n+        assertEquals(0, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName)\n+            .setQuery(QueryBuilders.rangeQuery(\"version\").from(\"1.3.0+build.1234569\").to(\"3.0.0\"))\n+            .get();\n+        assertEquals(2, response.getHits().getTotalHits().value);\n+\n+        // ranges excluding edges\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").from(\"1.0.0\", false).to(\"3.0.0\")).get();\n+        assertEquals(3, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").from(\"1.0.0\").to(\"2.1.0\", false)).get();\n+        assertEquals(3, response.getHits().getTotalHits().value);\n+\n+        // open ranges\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").from(\"1.4.0\")).get();\n+        assertEquals(4, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").to(\"1.4.0\")).get();\n+        assertEquals(2, response.getHits().getTotalHits().value);\n+    }\n+\n+    public void testPrefixQuery() throws IOException {\n+        String indexName = setUpIndex(\"test\");\n+        // prefix\n+        SearchResponse response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"1\")).get();\n+        assertEquals(3, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"2.1\")).get();\n+        assertEquals(2, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"2.1.0-\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"1.3.0+b\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"2\")).get();\n+        assertEquals(3, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"21\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"21.\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"21.1\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"21.11\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+    }\n+\n+    public void testSort() throws IOException {\n+        String indexName = setUpIndex(\"test\");\n+\n+        // sort based on version field\n+        SearchResponse response = client().prepareSearch(indexName)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67df1d387a55c795eaecacb8e49640d3a42d24b1"}, "originalPosition": 163}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg5MDQyODA1", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-489042805", "createdAt": "2020-09-15T20:24:43Z", "commit": {"oid": "67df1d387a55c795eaecacb8e49640d3a42d24b1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQyMDoyNDo0M1rOHSTO3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQyMDoyNDo0M1rOHSTO3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODk1MTUxOQ==", "bodyText": "@cbuescher This is a quite clever way to organize wildcard query!!! Good job here!!!\nFor this particular case of ? case, I think we need to add additional optional automata of PRERELEASE_SEPARATOR_BYTE and NO_PRERELEASE_SEPARATOR_BYTE.\nOtherwise,  a query \"1.2.3??\" can't match  a version like \"1.2.3+b\" or a version like \"1.2.3-a\"", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r488951519", "createdAt": "2020-09-15T20:24:43Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionFieldWildcardQuery.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.search.AutomatonQuery;\n+import org.apache.lucene.search.WildcardQuery;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.Automata;\n+import org.apache.lucene.util.automaton.Automaton;\n+import org.apache.lucene.util.automaton.Operations;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * A variation of the {@link WildcardQuery} than skips over meta characters introduced using {@link VersionEncoder}.\n+ */\n+class VersionFieldWildcardQuery extends AutomatonQuery {\n+\n+    private static final byte WILDCARD_STRING = '*';\n+\n+    private static final byte WILDCARD_CHAR = '?';\n+\n+    VersionFieldWildcardQuery(Term term) {\n+        super(term, toAutomaton(term), Integer.MAX_VALUE, true);\n+    }\n+\n+    private static Automaton toAutomaton(Term wildcardquery) {\n+        List<Automaton> automata = new ArrayList<>();\n+\n+        BytesRef wildcardText = wildcardquery.bytes();\n+        boolean containsPreReleaseSeparator = false;\n+\n+        for (int i = 0; i < wildcardText.length;) {\n+            final byte c = wildcardText.bytes[wildcardText.offset + i];\n+            int length = Character.charCount(c);\n+\n+            switch (c) {\n+                case WILDCARD_STRING:\n+                    automata.add(Automata.makeAnyString());\n+                    break;\n+                case WILDCARD_CHAR:\n+                    // this should also match leading digits, which have optional leading numeric marker and length bytes\n+                    automata.add(optionalNumericCharPrefix());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67df1d387a55c795eaecacb8e49640d3a42d24b1"}, "originalPosition": 49}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ce5148478d965fc4f3e4a85585301417348b2f26", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/ce5148478d965fc4f3e4a85585301417348b2f26", "committedDate": "2020-09-16T16:57:43Z", "message": "Another review iteration"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkwNjc2Mzk3", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-490676397", "createdAt": "2020-09-17T14:43:48Z", "commit": {"oid": "ce5148478d965fc4f3e4a85585301417348b2f26"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNDo0Mzo0OVrOHTl6Og==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNTowMjozMVrOHTnCCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDMwNjEwNg==", "bodyText": "Small comment: I think this check should be put in get(int index) function, as we can call get(int index) function without calling getValue.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490306106", "createdAt": "2020-09-17T14:43:49Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionScriptDocValues.java", "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.index.SortedSetDocValues;\n+import org.apache.lucene.util.ArrayUtil;\n+import org.elasticsearch.index.fielddata.ScriptDocValues;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.VersionParts;\n+\n+import java.io.IOException;\n+\n+public final class VersionScriptDocValues extends ScriptDocValues<String> {\n+\n+    private final SortedSetDocValues in;\n+    private long[] ords = new long[0];\n+    private int count;\n+\n+    public VersionScriptDocValues(SortedSetDocValues in) {\n+        this.in = in;\n+    }\n+\n+    @Override\n+    public void setNextDocId(int docId) throws IOException {\n+        count = 0;\n+        if (in.advanceExact(docId)) {\n+            for (long ord = in.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = in.nextOrd()) {\n+                ords = ArrayUtil.grow(ords, count + 1);\n+                ords[count++] = ord;\n+            }\n+        }\n+    }\n+\n+    public String getValue() {\n+        if (count == 0) {\n+            throw new IllegalStateException(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce5148478d965fc4f3e4a85585301417348b2f26"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDMyMDI0MA==", "bodyText": "this check for null for lowerTerm and upperTerm look unnecessary as it is already done above", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490320240", "createdAt": "2020-09-17T14:57:13Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,419 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build()\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"regexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int syntaxFlags,\n+            int matchFlags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), syntaxFlags, matchFlags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName, Supplier<SearchLookup> searchLookup) {\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+\n+            return new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce5148478d965fc4f3e4a85585301417348b2f26"}, "originalPosition": 307}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDMyNDQ5MQ==", "bodyText": "May be we can add to do for subsequent PRs to optimize these queries", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490324491", "createdAt": "2020-09-17T15:02:31Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,419 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build()\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"regexp\" queries on this field rare enough to brute-force this", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce5148478d965fc4f3e4a85585301417348b2f26"}, "originalPosition": 158}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "04ac11d32a63295e9ce6d7bc5dc7afb4a2a70f09", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/04ac11d32a63295e9ce6d7bc5dc7afb4a2a70f09", "committedDate": "2020-09-17T16:12:41Z", "message": "Another round of reviews"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ccebd6f470c99c824a84211ed122ba10f1f9629c", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/ccebd6f470c99c824a84211ed122ba10f1f9629c", "committedDate": "2020-09-17T18:10:44Z", "message": "Moving docs under 'structured'"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkxNDY1MTE4", "url": "https://github.com/elastic/elasticsearch/pull/59773#pullrequestreview-491465118", "createdAt": "2020-09-18T13:29:35Z", "commit": {"oid": "ccebd6f470c99c824a84211ed122ba10f1f9629c"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMzoyOTozNlrOHUNMVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMzozNTo0MlrOHUNbYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDk0OTcxNg==", "bodyText": "I understand how useful these functions can be but I'd prefer that we handle this in a follow up. It's unclear to me if these functions could be useful for other types as well (runtime or keyword field ?) so I think we should discuss this feature separately.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490949716", "createdAt": "2020-09-18T13:29:36Z", "author": {"login": "jimczi"}, "path": "docs/reference/mapping/types/version.asciidoc", "diffHunk": "@@ -0,0 +1,129 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[[version]]\n+=== Version field type\n+++++\n+<titleabbrev>Version</titleabbrev>\n+++++\n+\n+The `version` field type is a specialization of the `keyword` field for\n+handling software version values and to support specialized precedence\n+rules for them. Precedence is defined following the rules outlined by\n+https://semver.org/[Semantic Versioning], which for example means that\n+major, minor and patch version parts are sorted numerically (i.e. \n+\"2.1.0\" < \"2.4.1\" < \"2.11.2\") and pre-release versions are sorted before\n+release versiond (i.e. \"1.0.0-alpha\" < \"1.0.0\").\n+\n+You index a `version` field as follows\n+\n+[source,console]\n+--------------------------------------------------\n+PUT my-index-000001\n+{\n+  \"mappings\": {\n+    \"properties\": {\n+      \"my_version\": {\n+        \"type\": \"version\"\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+\n+The field offers the same search capabilities as a regular keyword field. It \n+can e.g. be searched for exact matches using `match` or `term` queries and\n+supports prefix and wildcard searches. The main benefit is that `range` queries\n+will honour Semver ordering, so a `range` query between \"1.0.0\" and \"1.5.0\"\n+will include versions of \"1.2.3\" but not \"1.11.2\" for example. Note that this\n+would be different when using a regular `keyword` field for indexing where ordering\n+is alphabetical.\n+\n+Software versions are expected to follow the\n+https://semver.org/[Semantic Versioning rules] schema and precedence rules with\n+the notable exception that more or less than three main version identifiers are\n+allowed (i.e. \"1.2\" or \"1.2.3.4\" qualify as valid versions while they wouldn't under\n+strict Semver rules). Version strings that are not valid under the Semver definition\n+(e.g. \"1.2.alpha.4\") can still be indexed and retrieved as exact matches, however they\n+will all appear _after_ any valid version with regular alphabetical ordering. The empty\n+String \"\" is considered invalid and sorted after all valid versions, but before other\n+invalid ones.\n+\n+[discrete]\n+[[version-params]]\n+==== Parameters for version fields\n+\n+The following parameters are accepted by `version` fields:\n+\n+[horizontal]\n+\n+<<mapping-field-meta,`meta`>>::\n+\n+    Metadata about the field.\n+\n+[discrete]\n+==== Limitations\n+\n+This field type isn't optimized for heavy wildcard, regex or fuzzy searches. While those\n+type of queries work in this field, you should consider using a regular `keyword` field if\n+you strongly rely on these kind of queries.\n+\n+==== Script support\n+\n+The `version` fields offers some specialized access to detailed information derived from\n+valid version strings like the Major, Minor or Patch release number, whether the version value\n+is valid according to Semver or if it is a pre-release version. This can be helpful when e.g.\n+filtering for only released versions or running aggregations on parts of the version.\n+The following query, for example, filters for released versions and groups them by Major version\n+using a `terms` aggregation:\n+\n+[source,console]\n+--------------------------------------------------\n+POST my-index-000001/_search\n+{\n+  \"query\": {\n+    \"bool\": {\n+      \"filter\": [\n+        {\n+          \"script\": {\n+            \"script\": {\n+              \"source\": \"doc['my_version'].isRelease() == true\"\n+            }\n+          }\n+        }\n+      ]\n+    }\n+  },\n+  \"aggs\": {\n+    \"group_major\": {\n+      \"terms\": {\n+        \"script\": { \"source\": \"doc['my_version'].getMajor()\"},\n+        \"order\": {\n+          \"_key\": \"asc\"\n+        }\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+// TEST[continued]\n+\n+Functions available on via doc values in scripting are:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ccebd6f470c99c824a84211ed122ba10f1f9629c"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDk1Mjk1Ng==", "bodyText": "Can you remove the check please", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490952956", "createdAt": "2020-09-18T13:34:47Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkyMzc3Mg=="}, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 188}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDk1MzU2OQ==", "bodyText": "This class is not needed anymore ?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490953569", "createdAt": "2020-09-18T13:35:42Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/ValidationOnSortedDv.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.index.DocValues;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.SortedSetDocValues;\n+import org.apache.lucene.search.ConstantScoreScorer;\n+import org.apache.lucene.search.ConstantScoreWeight;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.search.Scorer;\n+import org.apache.lucene.search.TwoPhaseIterator;\n+import org.apache.lucene.search.Weight;\n+import org.apache.lucene.util.BytesRef;\n+\n+import java.io.IOException;\n+import java.util.Objects;\n+\n+/**\n+ * Query that runs a validation for version ranges across sorted doc values.\n+ * Used in conjunction with more selective query clauses.\n+ */\n+class ValidationOnSortedDv extends Query {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ccebd6f470c99c824a84211ed122ba10f1f9629c"}, "originalPosition": 29}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b0abc83a228c5fdffadcddd30db6b6ad0875ce93", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/b0abc83a228c5fdffadcddd30db6b6ad0875ce93", "committedDate": "2020-09-18T14:21:33Z", "message": "Merge branch 'master' into add-version-field"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4c0b1e910c1c9a15b5d17e30b068c802f81bbf21", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/4c0b1e910c1c9a15b5d17e30b068c802f81bbf21", "committedDate": "2020-09-18T14:31:38Z", "message": "iter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6849550894da2bc41fcd9300fc459ce2f985de4f", "author": {"user": {"login": "cbuescher", "name": "Christoph B\u00fcscher"}}, "url": "https://github.com/elastic/elasticsearch/commit/6849550894da2bc41fcd9300fc459ce2f985de4f", "committedDate": "2020-09-18T14:59:24Z", "message": "Removing specialized script doc values functions"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4341, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}