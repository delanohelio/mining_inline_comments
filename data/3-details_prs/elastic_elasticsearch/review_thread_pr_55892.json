{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDEwMzMyMjU5", "number": 55892, "reviewThreads": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMToyNjo0MVrOD48oAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwOToyMDowOVrOD5Uf_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDQwMTI5OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/qa/native-multi-node-tests/src/test/java/org/elasticsearch/xpack/ml/integration/MlJobIT.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMToyNjo0MVrOGP8PxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMToyNjo0MVrOGP8PxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM2ODkwMA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    // check that the default shared index still exist but is empty\n          \n          \n            \n                    // check that the default shared index still exists but is empty", "url": "https://github.com/elastic/elasticsearch/pull/55892#discussion_r419368900", "createdAt": "2020-05-04T11:26:41Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/ml/qa/native-multi-node-tests/src/test/java/org/elasticsearch/xpack/ml/integration/MlJobIT.java", "diffHunk": "@@ -689,21 +689,17 @@ public void testMultiIndexDelete() throws Exception {\n \n         refreshAllIndices();\n \n-        // check that the indices still exist but are empty\n+        // check that the default shared index still exist but is empty", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c8dc854ed2fbb5905cac6613d1143e0ed02869a"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDgxNzcyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/integration/JobStorageDeletionTaskIT.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMzoyNjozMVrOGQANpQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMzoyNjozMVrOGQANpQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQzMzg5Mw==", "bodyText": "static?", "url": "https://github.com/elastic/elasticsearch/pull/55892#discussion_r419433893", "createdAt": "2020-05-04T13:26:31Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/integration/JobStorageDeletionTaskIT.java", "diffHunk": "@@ -46,4 +107,124 @@ public void testUnrelatedIndexNotTouched() throws Exception {\n \n         disableIndexBlock(UNRELATED_INDEX, IndexMetadata.SETTING_READ_ONLY);\n     }\n+\n+    public void testDeleteDedicatedJobWithDataInShared() throws Exception {\n+        internalCluster().ensureAtLeastNumDataNodes(1);\n+        ensureStableCluster(1);\n+        String jobIdDedicated = \"delete-test-job-dedicated\";\n+\n+        Job.Builder job = createJob(jobIdDedicated, new ByteSizeValue(2, ByteSizeUnit.MB))\n+            .setResultsIndexName(\"delete-test-job-dedicated\");\n+        client().execute(PutJobAction.INSTANCE, new PutJobAction.Request(job)).actionGet();\n+        client().execute(OpenJobAction.INSTANCE, new OpenJobAction.Request(job.getId())).actionGet();\n+        String dedicatedIndex = job.build().getInitialResultsIndexName();\n+        awaitJobOpenedAndAssigned(job.getId(), null);\n+        createBuckets(jobIdDedicated, 1, 10);\n+\n+        String jobIdShared = \"delete-test-job-shared\";\n+        job = createJob(jobIdShared, new ByteSizeValue(2, ByteSizeUnit.MB));\n+        client().execute(PutJobAction.INSTANCE, new PutJobAction.Request(job)).actionGet();\n+        client().execute(OpenJobAction.INSTANCE, new OpenJobAction.Request(job.getId())).actionGet();\n+        awaitJobOpenedAndAssigned(job.getId(), null);\n+        createBuckets(jobIdShared, 1, 10);\n+\n+        // Manually switching over alias info\n+        IndicesAliasesRequest aliasesRequest = new IndicesAliasesRequest();\n+        aliasesRequest.addAliasAction(IndicesAliasesRequest.AliasActions\n+                .add()\n+                .alias(AnomalyDetectorsIndex.jobResultsAliasedName(jobIdDedicated))\n+                .isHidden(true)\n+                .index(AnomalyDetectorsIndex.jobResultsIndexPrefix() + \"shared\")\n+                .writeIndex(false)\n+                .filter(QueryBuilders.boolQuery().filter(QueryBuilders.termQuery(Job.ID.getPreferredName(), jobIdDedicated))))\n+            .addAliasAction(IndicesAliasesRequest.AliasActions\n+                .add()\n+                .alias(AnomalyDetectorsIndex.resultsWriteAlias(jobIdDedicated))\n+                .index(AnomalyDetectorsIndex.jobResultsIndexPrefix() + \"shared\")\n+                .isHidden(true)\n+                .writeIndex(true))\n+            .addAliasAction(IndicesAliasesRequest.AliasActions\n+                .remove()\n+                .alias(AnomalyDetectorsIndex.resultsWriteAlias(jobIdDedicated))\n+                .index(dedicatedIndex));\n+\n+        client().admin().indices().aliases(aliasesRequest).actionGet();\n+\n+        createBuckets(jobIdDedicated, 11, 10);\n+        client().admin().indices().prepareRefresh(AnomalyDetectorsIndex.jobResultsIndexPrefix() + \"*\").get();\n+        AtomicReference<QueryPage<Bucket>> bucketHandler = new AtomicReference<>();\n+        AtomicReference<Exception> failureHandler = new AtomicReference<>();\n+        blockingCall(listener ->  jobResultsProvider.buckets(jobIdDedicated,\n+            new BucketsQueryBuilder().from(0).size(22),\n+            listener::onResponse,\n+            listener::onFailure,\n+            client()), bucketHandler, failureHandler);\n+        assertThat(failureHandler.get(), is(nullValue()));\n+        assertThat(bucketHandler.get().count(), equalTo(22L));\n+\n+        DeleteJobAction.Request deleteJobRequest = new DeleteJobAction.Request(jobIdDedicated);\n+        deleteJobRequest.setForce(true);\n+        client().execute(DeleteJobAction.INSTANCE, deleteJobRequest).get();\n+\n+        client().admin().indices().prepareRefresh(AnomalyDetectorsIndex.jobResultsIndexPrefix() + \"*\").get();\n+        // Make sure our shared index job is OK\n+        bucketHandler = new AtomicReference<>();\n+        failureHandler = new AtomicReference<>();\n+        blockingCall(listener ->  jobResultsProvider.buckets(jobIdShared,\n+            new BucketsQueryBuilder().from(0).size(21),\n+            listener::onResponse,\n+            listener::onFailure,\n+            client()), bucketHandler, failureHandler);\n+        assertThat(failureHandler.get(), is(nullValue()));\n+        assertThat(bucketHandler.get().count(), equalTo(11L));\n+\n+        // Make sure dedicated index is gone\n+        assertThat(client().admin()\n+            .indices()\n+            .prepareGetIndex()\n+            .setIndices(dedicatedIndex)\n+            .setIndicesOptions(IndicesOptions.LENIENT_EXPAND_OPEN)\n+            .get()\n+            .indices().length, equalTo(0));\n+\n+        // Make sure all results referencing the dedicated job are gone\n+        assertThat(client().prepareSearch()\n+            .setIndices(AnomalyDetectorsIndex.jobResultsIndexPrefix() + \"*\")\n+            .setIndicesOptions(IndicesOptions.lenientExpandOpenHidden())\n+            .setTrackTotalHits(true)\n+            .setSize(0)\n+            .setSource(SearchSourceBuilder.searchSource()\n+                .query(QueryBuilders.boolQuery().filter(QueryBuilders.termQuery(Job.ID.getPreferredName(), jobIdDedicated))))\n+            .get()\n+            .getHits()\n+            .getTotalHits()\n+            .value, equalTo(0L));\n+    }\n+\n+    private void createBuckets(String jobId, int from, int count) {\n+        JobResultsPersister.Builder builder = jobResultsPersister.bulkPersisterBuilder(jobId, () -> true);\n+        for (int i = from; i <= count + from; ++i) {\n+            Bucket bucket = new Bucket(jobId, new Date(bucketSpan * i), bucketSpan);\n+            builder.persistBucket(bucket);\n+        }\n+        builder.executeRequest();\n+    }\n+\n+    protected <T> void blockingCall(Consumer<ActionListener<T>> function, AtomicReference<T> response,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c8dc854ed2fbb5905cac6613d1143e0ed02869a"}, "originalPosition": 191}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDgyOTI2OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/integration/JobStorageDeletionTaskIT.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMzoyOTowMFrOGQAUig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMzoyOTowMFrOGQAUig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQzNTY1OA==", "bodyText": "static?", "url": "https://github.com/elastic/elasticsearch/pull/55892#discussion_r419435658", "createdAt": "2020-05-04T13:29:00Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/integration/JobStorageDeletionTaskIT.java", "diffHunk": "@@ -5,22 +5,83 @@\n  */\n package org.elasticsearch.xpack.ml.integration;\n \n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.admin.indices.alias.IndicesAliasesRequest;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.OriginSettingClient;\n import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.routing.OperationRouting;\n+import org.elasticsearch.cluster.service.ClusterApplierService;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.cluster.service.MasterService;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.unit.ByteSizeUnit;\n import org.elasticsearch.common.unit.ByteSizeValue;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.action.util.QueryPage;\n import org.elasticsearch.xpack.core.ml.action.DeleteJobAction;\n import org.elasticsearch.xpack.core.ml.action.OpenJobAction;\n import org.elasticsearch.xpack.core.ml.action.PutJobAction;\n+import org.elasticsearch.xpack.core.ml.job.config.AnalysisConfig;\n import org.elasticsearch.xpack.core.ml.job.config.Job;\n+import org.elasticsearch.xpack.core.ml.job.persistence.AnomalyDetectorsIndex;\n+import org.elasticsearch.xpack.core.ml.job.results.Bucket;\n+import org.elasticsearch.xpack.ml.inference.ingest.InferenceProcessor;\n+import org.elasticsearch.xpack.ml.job.persistence.BucketsQueryBuilder;\n+import org.elasticsearch.xpack.ml.job.persistence.JobResultsPersister;\n+import org.elasticsearch.xpack.ml.job.persistence.JobResultsProvider;\n+import org.elasticsearch.xpack.ml.notifications.AnomalyDetectionAuditor;\n import org.elasticsearch.xpack.ml.support.BaseMlIntegTestCase;\n+import org.elasticsearch.xpack.ml.utils.persistence.ResultsPersisterService;\n+import org.junit.Before;\n+\n+import java.util.Arrays;\n+import java.util.Date;\n+import java.util.HashSet;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Mockito.mock;\n \n /**\n  * Test that ML does not touch unnecessary indices when removing job index aliases\n  */\n public class JobStorageDeletionTaskIT extends BaseMlIntegTestCase {\n \n+    private long bucketSpan = AnalysisConfig.Builder.DEFAULT_BUCKET_SPAN.getMillis();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c8dc854ed2fbb5905cac6613d1143e0ed02869a"}, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDg0NDcxOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/integration/JobStorageDeletionTaskIT.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMzozMjowOVrOGQAdqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMzozMjowOVrOGQAdqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQzNzk5NA==", "bodyText": "Could you replace literal string with jobIdDedicated here?", "url": "https://github.com/elastic/elasticsearch/pull/55892#discussion_r419437994", "createdAt": "2020-05-04T13:32:09Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/integration/JobStorageDeletionTaskIT.java", "diffHunk": "@@ -46,4 +107,124 @@ public void testUnrelatedIndexNotTouched() throws Exception {\n \n         disableIndexBlock(UNRELATED_INDEX, IndexMetadata.SETTING_READ_ONLY);\n     }\n+\n+    public void testDeleteDedicatedJobWithDataInShared() throws Exception {\n+        internalCluster().ensureAtLeastNumDataNodes(1);\n+        ensureStableCluster(1);\n+        String jobIdDedicated = \"delete-test-job-dedicated\";\n+\n+        Job.Builder job = createJob(jobIdDedicated, new ByteSizeValue(2, ByteSizeUnit.MB))\n+            .setResultsIndexName(\"delete-test-job-dedicated\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c8dc854ed2fbb5905cac6613d1143e0ed02869a"}, "originalPosition": 95}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDg1NTc2OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/integration/JobStorageDeletionTaskIT.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMzozNDozNlrOGQAkQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMzozNDozNlrOGQAkQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQzOTY4Mw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    aliasesRequest.addAliasAction(IndicesAliasesRequest.AliasActions\n          \n          \n            \n                    aliasesRequest\n          \n          \n            \n                        .addAliasAction(IndicesAliasesRequest.AliasActions", "url": "https://github.com/elastic/elasticsearch/pull/55892#discussion_r419439683", "createdAt": "2020-05-04T13:34:36Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/integration/JobStorageDeletionTaskIT.java", "diffHunk": "@@ -46,4 +107,124 @@ public void testUnrelatedIndexNotTouched() throws Exception {\n \n         disableIndexBlock(UNRELATED_INDEX, IndexMetadata.SETTING_READ_ONLY);\n     }\n+\n+    public void testDeleteDedicatedJobWithDataInShared() throws Exception {\n+        internalCluster().ensureAtLeastNumDataNodes(1);\n+        ensureStableCluster(1);\n+        String jobIdDedicated = \"delete-test-job-dedicated\";\n+\n+        Job.Builder job = createJob(jobIdDedicated, new ByteSizeValue(2, ByteSizeUnit.MB))\n+            .setResultsIndexName(\"delete-test-job-dedicated\");\n+        client().execute(PutJobAction.INSTANCE, new PutJobAction.Request(job)).actionGet();\n+        client().execute(OpenJobAction.INSTANCE, new OpenJobAction.Request(job.getId())).actionGet();\n+        String dedicatedIndex = job.build().getInitialResultsIndexName();\n+        awaitJobOpenedAndAssigned(job.getId(), null);\n+        createBuckets(jobIdDedicated, 1, 10);\n+\n+        String jobIdShared = \"delete-test-job-shared\";\n+        job = createJob(jobIdShared, new ByteSizeValue(2, ByteSizeUnit.MB));\n+        client().execute(PutJobAction.INSTANCE, new PutJobAction.Request(job)).actionGet();\n+        client().execute(OpenJobAction.INSTANCE, new OpenJobAction.Request(job.getId())).actionGet();\n+        awaitJobOpenedAndAssigned(job.getId(), null);\n+        createBuckets(jobIdShared, 1, 10);\n+\n+        // Manually switching over alias info\n+        IndicesAliasesRequest aliasesRequest = new IndicesAliasesRequest();\n+        aliasesRequest.addAliasAction(IndicesAliasesRequest.AliasActions", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c8dc854ed2fbb5905cac6613d1143e0ed02869a"}, "originalPosition": 111}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDkwNjYyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportDeleteJobAction.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMzo0NTozOFrOGQBDAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMzo0NTozOFrOGQBDAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ0NzU1Mw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            for(String indexName : indexNames.get()) {\n          \n          \n            \n                            for (String indexName : indexNames.get()) {", "url": "https://github.com/elastic/elasticsearch/pull/55892#discussion_r419447553", "createdAt": "2020-05-04T13:45:38Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportDeleteJobAction.java", "diffHunk": "@@ -328,72 +330,97 @@ private void deleteJobDocuments(ParentTaskAssigningClient parentTaskClient, Stri\n                 },\n                 failureHandler);\n \n-        // Step 6. If we have any hits, that means we are NOT the only job on these indices, and should not delete the indices.\n-        // If we do not have any hits, we can drop the indices and then skip the DBQ and alias deletion.\n-        ActionListener<SearchResponse> customIndexSearchHandler = ActionListener.wrap(\n-                searchResponse -> {\n-                    if (searchResponse == null || searchResponse.getHits().getTotalHits().value > 0) {\n-                        deleteByQueryExecutor.onResponse(true); // We need to run DBQ and alias deletion\n-                    } else {\n-                        logger.info(\"Running DELETE Index on [\" + String.join(\", \", indexNames.get()) + \"] for job [\" + jobId + \"]\");\n-                        DeleteIndexRequest request = new DeleteIndexRequest(indexNames.get());\n-                        request.indicesOptions(IndicesOptions.lenientExpandOpen());\n-                        // If we have deleted the index, then we don't need to delete the aliases or run the DBQ\n-                        executeAsyncWithOrigin(\n-                                parentTaskClient.threadPool().getThreadContext(),\n-                                ML_ORIGIN,\n-                                request,\n-                                ActionListener.<AcknowledgedResponse>wrap(\n-                                        response -> deleteByQueryExecutor.onResponse(false), // skip DBQ && Alias\n-                                        failureHandler),\n-                                parentTaskClient.admin().indices()::delete);\n-                    }\n-                },\n-                failure -> {\n-                    if (ExceptionsHelper.unwrapCause(failure) instanceof IndexNotFoundException) { // assume the index is already deleted\n-                        deleteByQueryExecutor.onResponse(false); // skip DBQ && Alias\n-                    } else {\n-                        failureHandler.accept(failure);\n-                    }\n-                }\n+        // Step 6. Handle each multi-search response. There should be one response for each underlying index.\n+        // For each underlying index that contains results ONLY for the current job, we will delete that index.\n+        // If there exists at least 1 index that has another job's results, we will run DBQ.\n+        ActionListener<MultiSearchResponse> customIndexSearchHandler = ActionListener.wrap(\n+           multiSearchResponse -> {\n+               if (multiSearchResponse == null) {\n+                   deleteByQueryExecutor.onResponse(true); // We need to run DBQ and alias deletion\n+                   return;\n+               }\n+               String defaultSharedIndex = AnomalyDetectorsIndexFields.RESULTS_INDEX_PREFIX +\n+                   AnomalyDetectorsIndexFields.RESULTS_INDEX_DEFAULT;\n+               List<String> indicesToDelete = new ArrayList<>();\n+               boolean needToRunDBQTemp = false;\n+               assert multiSearchResponse.getResponses().length == indexNames.get().length;\n+               int i = 0;\n+               for (MultiSearchResponse.Item item : multiSearchResponse.getResponses()) {\n+                   if (item.isFailure()) {\n+                       ++i;\n+                       if (ExceptionsHelper.unwrapCause(item.getFailure()) instanceof IndexNotFoundException) {\n+                           // index is already deleted, no need to take action against it\n+                           continue;\n+                       } else {\n+                           failureHandler.accept(item.getFailure());\n+                           return;\n+                       }\n+                   }\n+                   SearchResponse searchResponse = item.getResponse();\n+                   if (searchResponse.getHits().getTotalHits().value > 0 || indexNames.get()[i].equals(defaultSharedIndex)) {\n+                       ++i;\n+                       needToRunDBQTemp = true;\n+                   } else {\n+                       indicesToDelete.add(indexNames.get()[i++]);\n+                   }\n+               }\n+               final boolean needToRunDBQ = needToRunDBQTemp;\n+               if (indicesToDelete.isEmpty()) {\n+                   deleteByQueryExecutor.onResponse(needToRunDBQ);\n+                   return;\n+               }\n+               logger.info(\"[{}] deleting the following indices directly {}\", jobId, indicesToDelete);\n+               DeleteIndexRequest request = new DeleteIndexRequest(indicesToDelete.toArray(String[]::new));\n+               request.indicesOptions(IndicesOptions.lenientExpandOpenHidden());\n+               executeAsyncWithOrigin(\n+                   parentTaskClient.threadPool().getThreadContext(),\n+                   ML_ORIGIN,\n+                   request,\n+                   ActionListener.<AcknowledgedResponse>wrap(\n+                       response -> deleteByQueryExecutor.onResponse(needToRunDBQ), // only run DBQ if there is a shared index\n+                       failureHandler),\n+                   parentTaskClient.admin().indices()::delete);\n+           },\n+           failure -> {\n+               if (ExceptionsHelper.unwrapCause(failure) instanceof IndexNotFoundException) { // assume the index is already deleted\n+                   deleteByQueryExecutor.onResponse(false); // skip DBQ && Alias\n+               } else {\n+                   failureHandler.accept(failure);\n+               }\n+           }\n         );\n \n-        // Step 5. Determine if we are on shared indices by looking at whether the initial index was \".ml-anomalies-shared\"\n-        // or whether the indices that the job's results alias points to contain any documents from other jobs.\n-        // TODO: this check is currently assuming that a job's results indices are either ALL shared or ALL\n-        // dedicated to the job.  We have considered functionality like rolling jobs that generate large\n-        // volumes of results from shared to dedicated indices.  On deletion such a job would have a mix of\n-        // shared indices requiring DBQ and dedicated indices that could be simply dropped.  The current\n-        // functionality would apply DBQ to all these indices, which is safe but suboptimal.  So this functionality\n-        // should be revisited when we add rolling results index functionality, especially if we add the ability\n-        // to switch a job over to a dedicated index for future results.\n+        // Step 5. If we successfully find a job, gather information about its result indices.\n+        // This will execute a multi-search action for every concrete index behind the job results alias.\n+        // If there are no concrete indices, take no action and go to the next step.\n         ActionListener<Job.Builder> getJobHandler = ActionListener.wrap(\n-                builder -> {\n-                    Job job = builder.build();\n-                    indexNames.set(indexNameExpressionResolver.concreteIndexNames(clusterService.state(),\n-                        IndicesOptions.lenientExpandOpen(), AnomalyDetectorsIndex.jobResultsAliasedName(jobId)));\n-                    // The job may no longer be using the initial shared index, but if it started off on a\n-                    // shared index then it will still be on a shared index even if it's been reindexed\n-                    if (job.getInitialResultsIndexName()\n-                            .equals(AnomalyDetectorsIndexFields.RESULTS_INDEX_PREFIX + AnomalyDetectorsIndexFields.RESULTS_INDEX_DEFAULT)) {\n-                        // don't bother searching the index any further, we are on the default shared\n-                        customIndexSearchHandler.onResponse(null);\n-                    } else if (indexNames.get().length == 0) {\n-                        // don't bother searching the index any further - it's already been closed or deleted\n-                        customIndexSearchHandler.onResponse(null);\n-                    } else {\n-                        SearchSourceBuilder source = new SearchSourceBuilder()\n-                                .size(1)\n-                                .trackTotalHits(true)\n-                                .query(QueryBuilders.boolQuery().filter(\n-                                        QueryBuilders.boolQuery().mustNot(QueryBuilders.termQuery(Job.ID.getPreferredName(), jobId))));\n-\n-                        SearchRequest searchRequest = new SearchRequest(indexNames.get());\n-                        searchRequest.source(source);\n-                        executeAsyncWithOrigin(parentTaskClient, ML_ORIGIN, SearchAction.INSTANCE, searchRequest, customIndexSearchHandler);\n-                    }\n-                },\n-                failureHandler\n+            builder -> {\n+                indexNames.set(indexNameExpressionResolver.concreteIndexNames(clusterService.state(),\n+                    IndicesOptions.lenientExpandOpen(), AnomalyDetectorsIndex.jobResultsAliasedName(jobId)));\n+                if (indexNames.get().length == 0) {\n+                    // don't bother searching the index any further - it's already been closed or deleted\n+                    customIndexSearchHandler.onResponse(null);\n+                    return;\n+                }\n+                MultiSearchRequest multiSearchRequest = new MultiSearchRequest();\n+                // It is important that the requests are in the same order as the index names.\n+                // This is because responses are ordered according to their request's.\n+                for(String indexName : indexNames.get()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c8dc854ed2fbb5905cac6613d1143e0ed02869a"}, "originalPosition": 177}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDkwODU5OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportDeleteJobAction.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMzo0NjowMlrOGQBEJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMzo0NjowMlrOGQBEJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ0Nzg0NQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            // This is because responses are ordered according to their request's.\n          \n          \n            \n                            // This is because responses are ordered according to their requests.", "url": "https://github.com/elastic/elasticsearch/pull/55892#discussion_r419447845", "createdAt": "2020-05-04T13:46:02Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportDeleteJobAction.java", "diffHunk": "@@ -328,72 +330,97 @@ private void deleteJobDocuments(ParentTaskAssigningClient parentTaskClient, Stri\n                 },\n                 failureHandler);\n \n-        // Step 6. If we have any hits, that means we are NOT the only job on these indices, and should not delete the indices.\n-        // If we do not have any hits, we can drop the indices and then skip the DBQ and alias deletion.\n-        ActionListener<SearchResponse> customIndexSearchHandler = ActionListener.wrap(\n-                searchResponse -> {\n-                    if (searchResponse == null || searchResponse.getHits().getTotalHits().value > 0) {\n-                        deleteByQueryExecutor.onResponse(true); // We need to run DBQ and alias deletion\n-                    } else {\n-                        logger.info(\"Running DELETE Index on [\" + String.join(\", \", indexNames.get()) + \"] for job [\" + jobId + \"]\");\n-                        DeleteIndexRequest request = new DeleteIndexRequest(indexNames.get());\n-                        request.indicesOptions(IndicesOptions.lenientExpandOpen());\n-                        // If we have deleted the index, then we don't need to delete the aliases or run the DBQ\n-                        executeAsyncWithOrigin(\n-                                parentTaskClient.threadPool().getThreadContext(),\n-                                ML_ORIGIN,\n-                                request,\n-                                ActionListener.<AcknowledgedResponse>wrap(\n-                                        response -> deleteByQueryExecutor.onResponse(false), // skip DBQ && Alias\n-                                        failureHandler),\n-                                parentTaskClient.admin().indices()::delete);\n-                    }\n-                },\n-                failure -> {\n-                    if (ExceptionsHelper.unwrapCause(failure) instanceof IndexNotFoundException) { // assume the index is already deleted\n-                        deleteByQueryExecutor.onResponse(false); // skip DBQ && Alias\n-                    } else {\n-                        failureHandler.accept(failure);\n-                    }\n-                }\n+        // Step 6. Handle each multi-search response. There should be one response for each underlying index.\n+        // For each underlying index that contains results ONLY for the current job, we will delete that index.\n+        // If there exists at least 1 index that has another job's results, we will run DBQ.\n+        ActionListener<MultiSearchResponse> customIndexSearchHandler = ActionListener.wrap(\n+           multiSearchResponse -> {\n+               if (multiSearchResponse == null) {\n+                   deleteByQueryExecutor.onResponse(true); // We need to run DBQ and alias deletion\n+                   return;\n+               }\n+               String defaultSharedIndex = AnomalyDetectorsIndexFields.RESULTS_INDEX_PREFIX +\n+                   AnomalyDetectorsIndexFields.RESULTS_INDEX_DEFAULT;\n+               List<String> indicesToDelete = new ArrayList<>();\n+               boolean needToRunDBQTemp = false;\n+               assert multiSearchResponse.getResponses().length == indexNames.get().length;\n+               int i = 0;\n+               for (MultiSearchResponse.Item item : multiSearchResponse.getResponses()) {\n+                   if (item.isFailure()) {\n+                       ++i;\n+                       if (ExceptionsHelper.unwrapCause(item.getFailure()) instanceof IndexNotFoundException) {\n+                           // index is already deleted, no need to take action against it\n+                           continue;\n+                       } else {\n+                           failureHandler.accept(item.getFailure());\n+                           return;\n+                       }\n+                   }\n+                   SearchResponse searchResponse = item.getResponse();\n+                   if (searchResponse.getHits().getTotalHits().value > 0 || indexNames.get()[i].equals(defaultSharedIndex)) {\n+                       ++i;\n+                       needToRunDBQTemp = true;\n+                   } else {\n+                       indicesToDelete.add(indexNames.get()[i++]);\n+                   }\n+               }\n+               final boolean needToRunDBQ = needToRunDBQTemp;\n+               if (indicesToDelete.isEmpty()) {\n+                   deleteByQueryExecutor.onResponse(needToRunDBQ);\n+                   return;\n+               }\n+               logger.info(\"[{}] deleting the following indices directly {}\", jobId, indicesToDelete);\n+               DeleteIndexRequest request = new DeleteIndexRequest(indicesToDelete.toArray(String[]::new));\n+               request.indicesOptions(IndicesOptions.lenientExpandOpenHidden());\n+               executeAsyncWithOrigin(\n+                   parentTaskClient.threadPool().getThreadContext(),\n+                   ML_ORIGIN,\n+                   request,\n+                   ActionListener.<AcknowledgedResponse>wrap(\n+                       response -> deleteByQueryExecutor.onResponse(needToRunDBQ), // only run DBQ if there is a shared index\n+                       failureHandler),\n+                   parentTaskClient.admin().indices()::delete);\n+           },\n+           failure -> {\n+               if (ExceptionsHelper.unwrapCause(failure) instanceof IndexNotFoundException) { // assume the index is already deleted\n+                   deleteByQueryExecutor.onResponse(false); // skip DBQ && Alias\n+               } else {\n+                   failureHandler.accept(failure);\n+               }\n+           }\n         );\n \n-        // Step 5. Determine if we are on shared indices by looking at whether the initial index was \".ml-anomalies-shared\"\n-        // or whether the indices that the job's results alias points to contain any documents from other jobs.\n-        // TODO: this check is currently assuming that a job's results indices are either ALL shared or ALL\n-        // dedicated to the job.  We have considered functionality like rolling jobs that generate large\n-        // volumes of results from shared to dedicated indices.  On deletion such a job would have a mix of\n-        // shared indices requiring DBQ and dedicated indices that could be simply dropped.  The current\n-        // functionality would apply DBQ to all these indices, which is safe but suboptimal.  So this functionality\n-        // should be revisited when we add rolling results index functionality, especially if we add the ability\n-        // to switch a job over to a dedicated index for future results.\n+        // Step 5. If we successfully find a job, gather information about its result indices.\n+        // This will execute a multi-search action for every concrete index behind the job results alias.\n+        // If there are no concrete indices, take no action and go to the next step.\n         ActionListener<Job.Builder> getJobHandler = ActionListener.wrap(\n-                builder -> {\n-                    Job job = builder.build();\n-                    indexNames.set(indexNameExpressionResolver.concreteIndexNames(clusterService.state(),\n-                        IndicesOptions.lenientExpandOpen(), AnomalyDetectorsIndex.jobResultsAliasedName(jobId)));\n-                    // The job may no longer be using the initial shared index, but if it started off on a\n-                    // shared index then it will still be on a shared index even if it's been reindexed\n-                    if (job.getInitialResultsIndexName()\n-                            .equals(AnomalyDetectorsIndexFields.RESULTS_INDEX_PREFIX + AnomalyDetectorsIndexFields.RESULTS_INDEX_DEFAULT)) {\n-                        // don't bother searching the index any further, we are on the default shared\n-                        customIndexSearchHandler.onResponse(null);\n-                    } else if (indexNames.get().length == 0) {\n-                        // don't bother searching the index any further - it's already been closed or deleted\n-                        customIndexSearchHandler.onResponse(null);\n-                    } else {\n-                        SearchSourceBuilder source = new SearchSourceBuilder()\n-                                .size(1)\n-                                .trackTotalHits(true)\n-                                .query(QueryBuilders.boolQuery().filter(\n-                                        QueryBuilders.boolQuery().mustNot(QueryBuilders.termQuery(Job.ID.getPreferredName(), jobId))));\n-\n-                        SearchRequest searchRequest = new SearchRequest(indexNames.get());\n-                        searchRequest.source(source);\n-                        executeAsyncWithOrigin(parentTaskClient, ML_ORIGIN, SearchAction.INSTANCE, searchRequest, customIndexSearchHandler);\n-                    }\n-                },\n-                failureHandler\n+            builder -> {\n+                indexNames.set(indexNameExpressionResolver.concreteIndexNames(clusterService.state(),\n+                    IndicesOptions.lenientExpandOpen(), AnomalyDetectorsIndex.jobResultsAliasedName(jobId)));\n+                if (indexNames.get().length == 0) {\n+                    // don't bother searching the index any further - it's already been closed or deleted\n+                    customIndexSearchHandler.onResponse(null);\n+                    return;\n+                }\n+                MultiSearchRequest multiSearchRequest = new MultiSearchRequest();\n+                // It is important that the requests are in the same order as the index names.\n+                // This is because responses are ordered according to their request's.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c8dc854ed2fbb5905cac6613d1143e0ed02869a"}, "originalPosition": 176}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDkzNzgyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportDeleteJobAction.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMzo1MTo1MVrOGQBUyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNDowNDo1NFrOGQB5Xg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ1MjEwNg==", "bodyText": "I'm not sure how it looks like in the rest of our codebase but I think assert should only be used to assert on the invariants implied directly by the code.\nIn this case we examine a response from an external service which can have a bug and therefore cause the assertion to fail. I don't know how such an exception would behave.\nWDYT?", "url": "https://github.com/elastic/elasticsearch/pull/55892#discussion_r419452106", "createdAt": "2020-05-04T13:51:51Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportDeleteJobAction.java", "diffHunk": "@@ -328,72 +330,97 @@ private void deleteJobDocuments(ParentTaskAssigningClient parentTaskClient, Stri\n                 },\n                 failureHandler);\n \n-        // Step 6. If we have any hits, that means we are NOT the only job on these indices, and should not delete the indices.\n-        // If we do not have any hits, we can drop the indices and then skip the DBQ and alias deletion.\n-        ActionListener<SearchResponse> customIndexSearchHandler = ActionListener.wrap(\n-                searchResponse -> {\n-                    if (searchResponse == null || searchResponse.getHits().getTotalHits().value > 0) {\n-                        deleteByQueryExecutor.onResponse(true); // We need to run DBQ and alias deletion\n-                    } else {\n-                        logger.info(\"Running DELETE Index on [\" + String.join(\", \", indexNames.get()) + \"] for job [\" + jobId + \"]\");\n-                        DeleteIndexRequest request = new DeleteIndexRequest(indexNames.get());\n-                        request.indicesOptions(IndicesOptions.lenientExpandOpen());\n-                        // If we have deleted the index, then we don't need to delete the aliases or run the DBQ\n-                        executeAsyncWithOrigin(\n-                                parentTaskClient.threadPool().getThreadContext(),\n-                                ML_ORIGIN,\n-                                request,\n-                                ActionListener.<AcknowledgedResponse>wrap(\n-                                        response -> deleteByQueryExecutor.onResponse(false), // skip DBQ && Alias\n-                                        failureHandler),\n-                                parentTaskClient.admin().indices()::delete);\n-                    }\n-                },\n-                failure -> {\n-                    if (ExceptionsHelper.unwrapCause(failure) instanceof IndexNotFoundException) { // assume the index is already deleted\n-                        deleteByQueryExecutor.onResponse(false); // skip DBQ && Alias\n-                    } else {\n-                        failureHandler.accept(failure);\n-                    }\n-                }\n+        // Step 6. Handle each multi-search response. There should be one response for each underlying index.\n+        // For each underlying index that contains results ONLY for the current job, we will delete that index.\n+        // If there exists at least 1 index that has another job's results, we will run DBQ.\n+        ActionListener<MultiSearchResponse> customIndexSearchHandler = ActionListener.wrap(\n+           multiSearchResponse -> {\n+               if (multiSearchResponse == null) {\n+                   deleteByQueryExecutor.onResponse(true); // We need to run DBQ and alias deletion\n+                   return;\n+               }\n+               String defaultSharedIndex = AnomalyDetectorsIndexFields.RESULTS_INDEX_PREFIX +\n+                   AnomalyDetectorsIndexFields.RESULTS_INDEX_DEFAULT;\n+               List<String> indicesToDelete = new ArrayList<>();\n+               boolean needToRunDBQTemp = false;\n+               assert multiSearchResponse.getResponses().length == indexNames.get().length;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c8dc854ed2fbb5905cac6613d1143e0ed02869a"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ2MTQ3MA==", "bodyText": "It could be a bug in the underlying service. OR it could be a bug in that we did not provide the correct number of clauses (\"invariants implied directly by the code\").\nOther places in our code base have similar assertions.", "url": "https://github.com/elastic/elasticsearch/pull/55892#discussion_r419461470", "createdAt": "2020-05-04T14:04:54Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportDeleteJobAction.java", "diffHunk": "@@ -328,72 +330,97 @@ private void deleteJobDocuments(ParentTaskAssigningClient parentTaskClient, Stri\n                 },\n                 failureHandler);\n \n-        // Step 6. If we have any hits, that means we are NOT the only job on these indices, and should not delete the indices.\n-        // If we do not have any hits, we can drop the indices and then skip the DBQ and alias deletion.\n-        ActionListener<SearchResponse> customIndexSearchHandler = ActionListener.wrap(\n-                searchResponse -> {\n-                    if (searchResponse == null || searchResponse.getHits().getTotalHits().value > 0) {\n-                        deleteByQueryExecutor.onResponse(true); // We need to run DBQ and alias deletion\n-                    } else {\n-                        logger.info(\"Running DELETE Index on [\" + String.join(\", \", indexNames.get()) + \"] for job [\" + jobId + \"]\");\n-                        DeleteIndexRequest request = new DeleteIndexRequest(indexNames.get());\n-                        request.indicesOptions(IndicesOptions.lenientExpandOpen());\n-                        // If we have deleted the index, then we don't need to delete the aliases or run the DBQ\n-                        executeAsyncWithOrigin(\n-                                parentTaskClient.threadPool().getThreadContext(),\n-                                ML_ORIGIN,\n-                                request,\n-                                ActionListener.<AcknowledgedResponse>wrap(\n-                                        response -> deleteByQueryExecutor.onResponse(false), // skip DBQ && Alias\n-                                        failureHandler),\n-                                parentTaskClient.admin().indices()::delete);\n-                    }\n-                },\n-                failure -> {\n-                    if (ExceptionsHelper.unwrapCause(failure) instanceof IndexNotFoundException) { // assume the index is already deleted\n-                        deleteByQueryExecutor.onResponse(false); // skip DBQ && Alias\n-                    } else {\n-                        failureHandler.accept(failure);\n-                    }\n-                }\n+        // Step 6. Handle each multi-search response. There should be one response for each underlying index.\n+        // For each underlying index that contains results ONLY for the current job, we will delete that index.\n+        // If there exists at least 1 index that has another job's results, we will run DBQ.\n+        ActionListener<MultiSearchResponse> customIndexSearchHandler = ActionListener.wrap(\n+           multiSearchResponse -> {\n+               if (multiSearchResponse == null) {\n+                   deleteByQueryExecutor.onResponse(true); // We need to run DBQ and alias deletion\n+                   return;\n+               }\n+               String defaultSharedIndex = AnomalyDetectorsIndexFields.RESULTS_INDEX_PREFIX +\n+                   AnomalyDetectorsIndexFields.RESULTS_INDEX_DEFAULT;\n+               List<String> indicesToDelete = new ArrayList<>();\n+               boolean needToRunDBQTemp = false;\n+               assert multiSearchResponse.getResponses().length == indexNames.get().length;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ1MjEwNg=="}, "originalCommit": {"oid": "7c8dc854ed2fbb5905cac6613d1143e0ed02869a"}, "originalPosition": 80}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDk1MjQyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportDeleteJobAction.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMzo1NTowNFrOGQBdWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNDowNToxN1rOGQB6og==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ1NDI5Nw==", "bodyText": "You seem to increment i in both branches. Could the increment statement be factored out into the line 366?", "url": "https://github.com/elastic/elasticsearch/pull/55892#discussion_r419454297", "createdAt": "2020-05-04T13:55:04Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportDeleteJobAction.java", "diffHunk": "@@ -328,72 +330,97 @@ private void deleteJobDocuments(ParentTaskAssigningClient parentTaskClient, Stri\n                 },\n                 failureHandler);\n \n-        // Step 6. If we have any hits, that means we are NOT the only job on these indices, and should not delete the indices.\n-        // If we do not have any hits, we can drop the indices and then skip the DBQ and alias deletion.\n-        ActionListener<SearchResponse> customIndexSearchHandler = ActionListener.wrap(\n-                searchResponse -> {\n-                    if (searchResponse == null || searchResponse.getHits().getTotalHits().value > 0) {\n-                        deleteByQueryExecutor.onResponse(true); // We need to run DBQ and alias deletion\n-                    } else {\n-                        logger.info(\"Running DELETE Index on [\" + String.join(\", \", indexNames.get()) + \"] for job [\" + jobId + \"]\");\n-                        DeleteIndexRequest request = new DeleteIndexRequest(indexNames.get());\n-                        request.indicesOptions(IndicesOptions.lenientExpandOpen());\n-                        // If we have deleted the index, then we don't need to delete the aliases or run the DBQ\n-                        executeAsyncWithOrigin(\n-                                parentTaskClient.threadPool().getThreadContext(),\n-                                ML_ORIGIN,\n-                                request,\n-                                ActionListener.<AcknowledgedResponse>wrap(\n-                                        response -> deleteByQueryExecutor.onResponse(false), // skip DBQ && Alias\n-                                        failureHandler),\n-                                parentTaskClient.admin().indices()::delete);\n-                    }\n-                },\n-                failure -> {\n-                    if (ExceptionsHelper.unwrapCause(failure) instanceof IndexNotFoundException) { // assume the index is already deleted\n-                        deleteByQueryExecutor.onResponse(false); // skip DBQ && Alias\n-                    } else {\n-                        failureHandler.accept(failure);\n-                    }\n-                }\n+        // Step 6. Handle each multi-search response. There should be one response for each underlying index.\n+        // For each underlying index that contains results ONLY for the current job, we will delete that index.\n+        // If there exists at least 1 index that has another job's results, we will run DBQ.\n+        ActionListener<MultiSearchResponse> customIndexSearchHandler = ActionListener.wrap(\n+           multiSearchResponse -> {\n+               if (multiSearchResponse == null) {\n+                   deleteByQueryExecutor.onResponse(true); // We need to run DBQ and alias deletion\n+                   return;\n+               }\n+               String defaultSharedIndex = AnomalyDetectorsIndexFields.RESULTS_INDEX_PREFIX +\n+                   AnomalyDetectorsIndexFields.RESULTS_INDEX_DEFAULT;\n+               List<String> indicesToDelete = new ArrayList<>();\n+               boolean needToRunDBQTemp = false;\n+               assert multiSearchResponse.getResponses().length == indexNames.get().length;\n+               int i = 0;\n+               for (MultiSearchResponse.Item item : multiSearchResponse.getResponses()) {\n+                   if (item.isFailure()) {\n+                       ++i;\n+                       if (ExceptionsHelper.unwrapCause(item.getFailure()) instanceof IndexNotFoundException) {\n+                           // index is already deleted, no need to take action against it\n+                           continue;\n+                       } else {\n+                           failureHandler.accept(item.getFailure());\n+                           return;\n+                       }\n+                   }\n+                   SearchResponse searchResponse = item.getResponse();\n+                   if (searchResponse.getHits().getTotalHits().value > 0 || indexNames.get()[i].equals(defaultSharedIndex)) {\n+                       ++i;\n+                       needToRunDBQTemp = true;\n+                   } else {\n+                       indicesToDelete.add(indexNames.get()[i++]);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c8dc854ed2fbb5905cac6613d1143e0ed02869a"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ2MTc5NA==", "bodyText": "for sure", "url": "https://github.com/elastic/elasticsearch/pull/55892#discussion_r419461794", "createdAt": "2020-05-04T14:05:17Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportDeleteJobAction.java", "diffHunk": "@@ -328,72 +330,97 @@ private void deleteJobDocuments(ParentTaskAssigningClient parentTaskClient, Stri\n                 },\n                 failureHandler);\n \n-        // Step 6. If we have any hits, that means we are NOT the only job on these indices, and should not delete the indices.\n-        // If we do not have any hits, we can drop the indices and then skip the DBQ and alias deletion.\n-        ActionListener<SearchResponse> customIndexSearchHandler = ActionListener.wrap(\n-                searchResponse -> {\n-                    if (searchResponse == null || searchResponse.getHits().getTotalHits().value > 0) {\n-                        deleteByQueryExecutor.onResponse(true); // We need to run DBQ and alias deletion\n-                    } else {\n-                        logger.info(\"Running DELETE Index on [\" + String.join(\", \", indexNames.get()) + \"] for job [\" + jobId + \"]\");\n-                        DeleteIndexRequest request = new DeleteIndexRequest(indexNames.get());\n-                        request.indicesOptions(IndicesOptions.lenientExpandOpen());\n-                        // If we have deleted the index, then we don't need to delete the aliases or run the DBQ\n-                        executeAsyncWithOrigin(\n-                                parentTaskClient.threadPool().getThreadContext(),\n-                                ML_ORIGIN,\n-                                request,\n-                                ActionListener.<AcknowledgedResponse>wrap(\n-                                        response -> deleteByQueryExecutor.onResponse(false), // skip DBQ && Alias\n-                                        failureHandler),\n-                                parentTaskClient.admin().indices()::delete);\n-                    }\n-                },\n-                failure -> {\n-                    if (ExceptionsHelper.unwrapCause(failure) instanceof IndexNotFoundException) { // assume the index is already deleted\n-                        deleteByQueryExecutor.onResponse(false); // skip DBQ && Alias\n-                    } else {\n-                        failureHandler.accept(failure);\n-                    }\n-                }\n+        // Step 6. Handle each multi-search response. There should be one response for each underlying index.\n+        // For each underlying index that contains results ONLY for the current job, we will delete that index.\n+        // If there exists at least 1 index that has another job's results, we will run DBQ.\n+        ActionListener<MultiSearchResponse> customIndexSearchHandler = ActionListener.wrap(\n+           multiSearchResponse -> {\n+               if (multiSearchResponse == null) {\n+                   deleteByQueryExecutor.onResponse(true); // We need to run DBQ and alias deletion\n+                   return;\n+               }\n+               String defaultSharedIndex = AnomalyDetectorsIndexFields.RESULTS_INDEX_PREFIX +\n+                   AnomalyDetectorsIndexFields.RESULTS_INDEX_DEFAULT;\n+               List<String> indicesToDelete = new ArrayList<>();\n+               boolean needToRunDBQTemp = false;\n+               assert multiSearchResponse.getResponses().length == indexNames.get().length;\n+               int i = 0;\n+               for (MultiSearchResponse.Item item : multiSearchResponse.getResponses()) {\n+                   if (item.isFailure()) {\n+                       ++i;\n+                       if (ExceptionsHelper.unwrapCause(item.getFailure()) instanceof IndexNotFoundException) {\n+                           // index is already deleted, no need to take action against it\n+                           continue;\n+                       } else {\n+                           failureHandler.accept(item.getFailure());\n+                           return;\n+                       }\n+                   }\n+                   SearchResponse searchResponse = item.getResponse();\n+                   if (searchResponse.getHits().getTotalHits().value > 0 || indexNames.get()[i].equals(defaultSharedIndex)) {\n+                       ++i;\n+                       needToRunDBQTemp = true;\n+                   } else {\n+                       indicesToDelete.add(indexNames.get()[i++]);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ1NDI5Nw=="}, "originalCommit": {"oid": "7c8dc854ed2fbb5905cac6613d1143e0ed02869a"}, "originalPosition": 98}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxNDMxMjk0OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/integration/JobStorageDeletionTaskIT.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwOToyMDowOVrOGQhGpA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwOToyMDowOVrOGQhGpA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTk3Mjc3Mg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private static long bucketSpan = AnalysisConfig.Builder.DEFAULT_BUCKET_SPAN.getMillis();\n          \n          \n            \n                private static long BUCKET_SPAN = AnalysisConfig.Builder.DEFAULT_BUCKET_SPAN.getMillis();", "url": "https://github.com/elastic/elasticsearch/pull/55892#discussion_r419972772", "createdAt": "2020-05-05T09:20:09Z", "author": {"login": "przemekwitek"}, "path": "x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/integration/JobStorageDeletionTaskIT.java", "diffHunk": "@@ -5,22 +5,80 @@\n  */\n package org.elasticsearch.xpack.ml.integration;\n \n+import org.elasticsearch.action.admin.indices.alias.IndicesAliasesRequest;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.OriginSettingClient;\n import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.routing.OperationRouting;\n+import org.elasticsearch.cluster.service.ClusterApplierService;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.cluster.service.MasterService;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.unit.ByteSizeUnit;\n import org.elasticsearch.common.unit.ByteSizeValue;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.action.util.QueryPage;\n import org.elasticsearch.xpack.core.ml.action.DeleteJobAction;\n import org.elasticsearch.xpack.core.ml.action.OpenJobAction;\n import org.elasticsearch.xpack.core.ml.action.PutJobAction;\n+import org.elasticsearch.xpack.core.ml.job.config.AnalysisConfig;\n import org.elasticsearch.xpack.core.ml.job.config.Job;\n+import org.elasticsearch.xpack.core.ml.job.persistence.AnomalyDetectorsIndex;\n+import org.elasticsearch.xpack.core.ml.job.results.Bucket;\n+import org.elasticsearch.xpack.ml.inference.ingest.InferenceProcessor;\n+import org.elasticsearch.xpack.ml.job.persistence.BucketsQueryBuilder;\n+import org.elasticsearch.xpack.ml.job.persistence.JobResultsPersister;\n+import org.elasticsearch.xpack.ml.job.persistence.JobResultsProvider;\n+import org.elasticsearch.xpack.ml.notifications.AnomalyDetectionAuditor;\n import org.elasticsearch.xpack.ml.support.BaseMlIntegTestCase;\n+import org.elasticsearch.xpack.ml.utils.persistence.ResultsPersisterService;\n+import org.junit.Before;\n+\n+import java.util.Arrays;\n+import java.util.Date;\n+import java.util.HashSet;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Mockito.mock;\n \n /**\n  * Test that ML does not touch unnecessary indices when removing job index aliases\n  */\n public class JobStorageDeletionTaskIT extends BaseMlIntegTestCase {\n \n+    private static long bucketSpan = AnalysisConfig.Builder.DEFAULT_BUCKET_SPAN.getMillis();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7555ea7d8e4d9f3aa6adf14616c62662b56fa7b1"}, "originalPosition": 53}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2484, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}