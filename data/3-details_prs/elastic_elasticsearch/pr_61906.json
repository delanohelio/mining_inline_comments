{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDc4NjA2MDgy", "number": 61906, "title": "Determine shard size before allocating shards recovering from snapshots", "bodyText": "Determines the shard size of shards before allocating shards that are recovering from snapshots. It ensures during shard allocation that the target node that is selected as recovery target will have enough free disk space for the recovery event.  This applies to regular restores, CCR bootstrap from remote, as well as mounting searchable snapshots.\nNote that this PR does not address an issues (we already have today) where a replica is being allocated without knowing how much disk space is being used by the primary. Ultimately an approach as taken by this PR (delaying allocation until disk space knowledge is established) should be pursued.", "createdAt": "2020-09-03T12:45:12Z", "url": "https://github.com/elastic/elasticsearch/pull/61906", "merged": true, "mergeCommit": {"oid": "2afec0d916c7de33c9a6c3cbe30a8a2ee61be765"}, "closed": true, "closedAt": "2020-10-06T15:29:42Z", "author": {"login": "ywelsch"}, "timelineItems": {"totalCount": 62, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdGgScGgBqjM3MzY0NTI5NzM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdP5_0sAFqTUwMzA4MDU5OQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6bca9a86ec92c33b7e0df747825a47dd33dd59e0", "author": {"user": {"login": "ywelsch", "name": "Yannick Welsch"}}, "url": "https://github.com/elastic/elasticsearch/commit/6bca9a86ec92c33b7e0df747825a47dd33dd59e0", "committedDate": "2020-09-03T12:43:25Z", "message": "Determine shard size before searchable snapshot shard allocation"}, "afterCommit": {"oid": "1268d7aaa5d28a182afb552613f688a23b079985", "author": {"user": {"login": "ywelsch", "name": "Yannick Welsch"}}, "url": "https://github.com/elastic/elasticsearch/commit/1268d7aaa5d28a182afb552613f688a23b079985", "committedDate": "2020-09-07T10:17:35Z", "message": "Determine shard size before searchable snapshot shard allocation"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "1268d7aaa5d28a182afb552613f688a23b079985", "author": {"user": {"login": "ywelsch", "name": "Yannick Welsch"}}, "url": "https://github.com/elastic/elasticsearch/commit/1268d7aaa5d28a182afb552613f688a23b079985", "committedDate": "2020-09-07T10:17:35Z", "message": "Determine shard size before searchable snapshot shard allocation"}, "afterCommit": {"oid": "99d2a2806285e590af136f7d8937d1afc93a27b5", "author": {"user": {"login": "ywelsch", "name": "Yannick Welsch"}}, "url": "https://github.com/elastic/elasticsearch/commit/99d2a2806285e590af136f7d8937d1afc93a27b5", "committedDate": "2020-09-07T12:41:37Z", "message": "Determine shard size before searchable snapshot shard allocation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4a999820dc192645bc8c024648343bcddc48fca6", "author": {"user": {"login": "ywelsch", "name": "Yannick Welsch"}}, "url": "https://github.com/elastic/elasticsearch/commit/4a999820dc192645bc8c024648343bcddc48fca6", "committedDate": "2020-09-07T15:27:58Z", "message": "Determine shard size before searchable snapshot shard allocation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "311d08f2b348911002873c328c9901cadc298aa5", "author": {"user": {"login": "ywelsch", "name": "Yannick Welsch"}}, "url": "https://github.com/elastic/elasticsearch/commit/311d08f2b348911002873c328c9901cadc298aa5", "committedDate": "2020-09-07T15:27:58Z", "message": "Add test for restore case"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0a5da06d09de6f92a3f6a370ab988a971baddf0d", "author": {"user": {"login": "ywelsch", "name": "Yannick Welsch"}}, "url": "https://github.com/elastic/elasticsearch/commit/0a5da06d09de6f92a3f6a370ab988a971baddf0d", "committedDate": "2020-09-07T13:21:51Z", "message": "Add test for restore case"}, "afterCommit": {"oid": "311d08f2b348911002873c328c9901cadc298aa5", "author": {"user": {"login": "ywelsch", "name": "Yannick Welsch"}}, "url": "https://github.com/elastic/elasticsearch/commit/311d08f2b348911002873c328c9901cadc298aa5", "committedDate": "2020-09-07T15:27:58Z", "message": "Add test for restore case"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "232cc2e3764b5b13f15320e2441da78094c4ba82", "author": {"user": {"login": "ywelsch", "name": "Yannick Welsch"}}, "url": "https://github.com/elastic/elasticsearch/commit/232cc2e3764b5b13f15320e2441da78094c4ba82", "committedDate": "2020-09-08T09:32:30Z", "message": "more  test fixes  + CCR integration"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e6a9a4717961129f8c5676727a87187552e312d7", "author": {"user": {"login": "ywelsch", "name": "Yannick Welsch"}}, "url": "https://github.com/elastic/elasticsearch/commit/e6a9a4717961129f8c5676727a87187552e312d7", "committedDate": "2020-09-08T11:18:18Z", "message": "checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f0c48e691cc50566a8267fe0fc13f2404d8d4d92", "author": {"user": {"login": "ywelsch", "name": "Yannick Welsch"}}, "url": "https://github.com/elastic/elasticsearch/commit/f0c48e691cc50566a8267fe0fc13f2404d8d4d92", "committedDate": "2020-09-08T11:19:02Z", "message": "Merge remote-tracking branch 'elastic/master' into snapshot-size-based-allocation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c596dac2b8e18068772118b07e6fe8b5da91a8ff", "author": {"user": {"login": "ywelsch", "name": "Yannick Welsch"}}, "url": "https://github.com/elastic/elasticsearch/commit/c596dac2b8e18068772118b07e6fe8b5da91a8ff", "committedDate": "2020-09-08T19:16:51Z", "message": "checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7fc0052540cb493e6921ec6dfd20cab7d0e04f00", "author": {"user": {"login": "ywelsch", "name": "Yannick Welsch"}}, "url": "https://github.com/elastic/elasticsearch/commit/7fc0052540cb493e6921ec6dfd20cab7d0e04f00", "committedDate": "2020-09-09T07:40:14Z", "message": "chasdada"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5e64f308895ac9bfb2f33e5d30701b59cf3eb3cb", "author": {"user": {"login": "ywelsch", "name": "Yannick Welsch"}}, "url": "https://github.com/elastic/elasticsearch/commit/5e64f308895ac9bfb2f33e5d30701b59cf3eb3cb", "committedDate": "2020-09-09T08:50:39Z", "message": "Merge remote-tracking branch 'elastic/master' into snapshot-size-based-allocation"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg0ODAwMzk1", "url": "https://github.com/elastic/elasticsearch/pull/61906#pullrequestreview-484800395", "createdAt": "2020-09-09T08:56:25Z", "commit": {"oid": "5e64f308895ac9bfb2f33e5d30701b59cf3eb3cb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQwODo1NjoyNVrOHO9kWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQwODo1NjoyNVrOHO9kWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTQ1MDg0Mw==", "bodyText": "I'm not sure which thread-pool to use here. SNAPSHOT wasn't great because I feared allocation could be delayed by long-running backups. ASYNC_FETCH thread pool could turn out to be problematic as it might interfere with recoveries of local primaries (although that threadpool is generously sized).", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r485450843", "createdAt": "2020-09-09T08:56:25Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,197 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesServiceSupplier;\n+    private final Supplier<RerouteService> rerouteServiceSupplier;\n+\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> snapshotShardSizes;\n+\n+    private final Set<SnapshotShard> fetchingShards = Sets.newConcurrentHashSet();\n+\n+    public InternalSnapshotsInfoService(ThreadPool threadPool, Supplier<RepositoriesService> repositoriesServiceSupplier,\n+                                        Supplier<RerouteService> rerouteServiceSupplier) {\n+        this.threadPool = threadPool;\n+        this.repositoriesServiceSupplier = repositoriesServiceSupplier;\n+        this.rerouteServiceSupplier = rerouteServiceSupplier;\n+        snapshotShardSizes = ImmutableOpenMap.of();\n+    }\n+\n+    public static class SnapshotShard {\n+\n+        private final Snapshot snapshot;\n+        private final IndexId index;\n+        private final int shardId;\n+\n+        public SnapshotShard(Snapshot snapshot, IndexId index, int shardId) {\n+            this.snapshot = snapshot;\n+            this.index = index;\n+            this.shardId = shardId;\n+        }\n+\n+        public Snapshot getSnapshot() {\n+            return snapshot;\n+        }\n+\n+        public IndexId getIndex() {\n+            return index;\n+        }\n+\n+        public int getShardId() {\n+            return shardId;\n+        }\n+\n+        @Override\n+        public boolean equals(Object o) {\n+            if (this == o) return true;\n+            if (o == null || getClass() != o.getClass()) return false;\n+            SnapshotShard that = (SnapshotShard) o;\n+            return shardId == that.shardId &&\n+                snapshot.equals(that.snapshot) &&\n+                index.equals(that.index);\n+        }\n+\n+        @Override\n+        public int hashCode() {\n+            return Objects.hash(snapshot, index, shardId);\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"SnapshotShard{\" +\n+                \"snapshot=\" + snapshot +\n+                \", index=\" + index +\n+                \", shardId=\" + shardId +\n+                '}';\n+        }\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(snapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> requiredSnapshotShards = new HashSet<>();\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.id());\n+                    requiredSnapshotShards.add(snapshotShard);\n+                    // check if already populated entry\n+                    if (snapshotShardSizes.get(snapshotShard) == null) {\n+                        // check if already fetching snapshot info in progress\n+                        if (fetchingShards.add(snapshotShard)) {\n+                            // TODO: Use a dedicated threadpool here? Use FETCH thread pool?\n+                            threadPool.generic().execute(new AbstractRunnable() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5e64f308895ac9bfb2f33e5d30701b59cf3eb3cb"}, "originalPosition": 138}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7dda136a6f4c6aa3696be30be4d196d31fb5c352", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/7dda136a6f4c6aa3696be30be4d196d31fb5c352", "committedDate": "2020-09-28T10:56:09Z", "message": "Merge branch 'master' into snapshot-size-based-allocation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ef544ce81231bb5d36ae883e8c2135fb99bd9f9b", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/ef544ce81231bb5d36ae883e8c2135fb99bd9f9b", "committedDate": "2020-09-28T11:07:38Z", "message": "Fix DataTierAllocationDeciderTests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d1d805782b65f3d0e5376f0cb23ae3205a6b2bd9", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/d1d805782b65f3d0e5376f0cb23ae3205a6b2bd9", "committedDate": "2020-09-28T13:36:40Z", "message": "Apply some feedback and cosmetics"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk3NTAwMjU2", "url": "https://github.com/elastic/elasticsearch/pull/61906#pullrequestreview-497500256", "createdAt": "2020-09-28T13:16:43Z", "commit": {"oid": "ef544ce81231bb5d36ae883e8c2135fb99bd9f9b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOFQxMzoxNjo0M1rOHY9Mgg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOFQxMzoxNjo0M1rOHY9Mgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTkzMDQ5OA==", "bodyText": "I agree with not using the SNAPSHOT thread pool here. I think we should reuse FETCH_SHARD_STORE or add a new one.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r495930498", "createdAt": "2020-09-28T13:16:43Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,197 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesServiceSupplier;\n+    private final Supplier<RerouteService> rerouteServiceSupplier;\n+\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> snapshotShardSizes;\n+\n+    private final Set<SnapshotShard> fetchingShards = Sets.newConcurrentHashSet();\n+\n+    public InternalSnapshotsInfoService(ThreadPool threadPool, Supplier<RepositoriesService> repositoriesServiceSupplier,\n+                                        Supplier<RerouteService> rerouteServiceSupplier) {\n+        this.threadPool = threadPool;\n+        this.repositoriesServiceSupplier = repositoriesServiceSupplier;\n+        this.rerouteServiceSupplier = rerouteServiceSupplier;\n+        snapshotShardSizes = ImmutableOpenMap.of();\n+    }\n+\n+    public static class SnapshotShard {\n+\n+        private final Snapshot snapshot;\n+        private final IndexId index;\n+        private final int shardId;\n+\n+        public SnapshotShard(Snapshot snapshot, IndexId index, int shardId) {\n+            this.snapshot = snapshot;\n+            this.index = index;\n+            this.shardId = shardId;\n+        }\n+\n+        public Snapshot getSnapshot() {\n+            return snapshot;\n+        }\n+\n+        public IndexId getIndex() {\n+            return index;\n+        }\n+\n+        public int getShardId() {\n+            return shardId;\n+        }\n+\n+        @Override\n+        public boolean equals(Object o) {\n+            if (this == o) return true;\n+            if (o == null || getClass() != o.getClass()) return false;\n+            SnapshotShard that = (SnapshotShard) o;\n+            return shardId == that.shardId &&\n+                snapshot.equals(that.snapshot) &&\n+                index.equals(that.index);\n+        }\n+\n+        @Override\n+        public int hashCode() {\n+            return Objects.hash(snapshot, index, shardId);\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"SnapshotShard{\" +\n+                \"snapshot=\" + snapshot +\n+                \", index=\" + index +\n+                \", shardId=\" + shardId +\n+                '}';\n+        }\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(snapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> requiredSnapshotShards = new HashSet<>();\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.id());\n+                    requiredSnapshotShards.add(snapshotShard);\n+                    // check if already populated entry\n+                    if (snapshotShardSizes.get(snapshotShard) == null) {\n+                        // check if already fetching snapshot info in progress\n+                        if (fetchingShards.add(snapshotShard)) {\n+                            // TODO: Use a dedicated threadpool here? Use FETCH thread pool?\n+                            threadPool.generic().execute(new AbstractRunnable() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTQ1MDg0Mw=="}, "originalCommit": {"oid": "5e64f308895ac9bfb2f33e5d30701b59cf3eb3cb"}, "originalPosition": 138}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cb6daa1f9262d2b11f68ee18775db67c074b7da7", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/cb6daa1f9262d2b11f68ee18775db67c074b7da7", "committedDate": "2020-09-28T14:50:31Z", "message": "Fix imports"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk4NjU5NzQw", "url": "https://github.com/elastic/elasticsearch/pull/61906#pullrequestreview-498659740", "createdAt": "2020-09-29T16:14:37Z", "commit": {"oid": "cb6daa1f9262d2b11f68ee18775db67c074b7da7"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjoxNDozN1rOHZ2JDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjozMzo1MVrOHZ3L6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg2MzUwMg==", "bodyText": "On failures, every reroute will trigger another round of fetch of shard size(s) and lead to more warning logs. And in the meantime, the cluster is yellow due to ClusterShardHealth.getInactivePrimaryHealth.\nIn particular if this happens together with the bursts described below, it could be a burdensome load on the master node?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r496863502", "createdAt": "2020-09-29T16:14:37Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesServiceSupplier;\n+    private final Supplier<RerouteService> rerouteServiceSupplier;\n+\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> snapshotShardSizes;\n+\n+    private final Set<SnapshotShard> fetchingShards = Sets.newConcurrentHashSet();\n+\n+    public InternalSnapshotsInfoService(ThreadPool threadPool, Supplier<RepositoriesService> repositoriesServiceSupplier,\n+                                        Supplier<RerouteService> rerouteServiceSupplier) {\n+        this.threadPool = threadPool;\n+        this.repositoriesServiceSupplier = repositoriesServiceSupplier;\n+        this.rerouteServiceSupplier = rerouteServiceSupplier;\n+        snapshotShardSizes = ImmutableOpenMap.of();\n+    }\n+\n+    public static class SnapshotShard {\n+\n+        private final Snapshot snapshot;\n+        private final IndexId index;\n+        private final int shardId;\n+\n+        public SnapshotShard(Snapshot snapshot, IndexId index, int shardId) {\n+            this.snapshot = snapshot;\n+            this.index = index;\n+            this.shardId = shardId;\n+        }\n+\n+        public Snapshot getSnapshot() {\n+            return snapshot;\n+        }\n+\n+        public IndexId getIndex() {\n+            return index;\n+        }\n+\n+        public int getShardId() {\n+            return shardId;\n+        }\n+\n+        @Override\n+        public boolean equals(Object o) {\n+            if (this == o) {\n+                return true;\n+            }\n+            if (o == null || getClass() != o.getClass()) {\n+                return false;\n+            }\n+            final SnapshotShard that = (SnapshotShard) o;\n+            return shardId == that.shardId\n+                && snapshot.equals(that.snapshot)\n+                && index.equals(that.index);\n+        }\n+\n+        @Override\n+        public int hashCode() {\n+            return Objects.hash(snapshot, index, shardId);\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"SnapshotShard{\" +\n+                \"snapshot=\" + snapshot +\n+                \", index=\" + index +\n+                \", shardId=\" + shardId +\n+                '}';\n+        }\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(snapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> requiredSnapshotShards = new HashSet<>();\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.id());\n+                    requiredSnapshotShards.add(snapshotShard);\n+                    // check if already populated entry\n+                    if (snapshotShardSizes.get(snapshotShard) == null) {\n+                        // check if already fetching snapshot info in progress\n+                        if (fetchingShards.add(snapshotShard)) {\n+                            // TODO: Use a dedicated threadpool here? Use FETCH thread pool?\n+                            threadPool.generic().execute(new AbstractRunnable() {\n+                                @Override\n+                                public void onFailure(Exception e) {\n+                                    logger.warn(new ParameterizedMessage(\"failed to retrieve shard size information for {}\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb6daa1f9262d2b11f68ee18775db67c074b7da7"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg4MDYxNw==", "bodyText": "I think this will lead to a burst of many requests to the blob store to get the shard size whenever a node holding searchable snapshots fails or is restarted.\nThis could block the generic thread pool for a while, potentially causing other issues. Similarly if moving to the FETCH_SHARD_STORE pool it might interfere with recoveries of primaries.\nGeneric pool has minimum 128 threads, which does mean a decent amount of parallel fetching from blobstore, but going for other pools would likely lower this considerably.\nIt also feels like a bad spot in our allocation to have a dependency on an external blob store, in particular if it responds very slowly for odd reasons. Once persistent cache is in place, we should be able to recover on our own without accessing the blob store.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r496880617", "createdAt": "2020-09-29T16:33:51Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesServiceSupplier;\n+    private final Supplier<RerouteService> rerouteServiceSupplier;\n+\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> snapshotShardSizes;\n+\n+    private final Set<SnapshotShard> fetchingShards = Sets.newConcurrentHashSet();\n+\n+    public InternalSnapshotsInfoService(ThreadPool threadPool, Supplier<RepositoriesService> repositoriesServiceSupplier,\n+                                        Supplier<RerouteService> rerouteServiceSupplier) {\n+        this.threadPool = threadPool;\n+        this.repositoriesServiceSupplier = repositoriesServiceSupplier;\n+        this.rerouteServiceSupplier = rerouteServiceSupplier;\n+        snapshotShardSizes = ImmutableOpenMap.of();\n+    }\n+\n+    public static class SnapshotShard {\n+\n+        private final Snapshot snapshot;\n+        private final IndexId index;\n+        private final int shardId;\n+\n+        public SnapshotShard(Snapshot snapshot, IndexId index, int shardId) {\n+            this.snapshot = snapshot;\n+            this.index = index;\n+            this.shardId = shardId;\n+        }\n+\n+        public Snapshot getSnapshot() {\n+            return snapshot;\n+        }\n+\n+        public IndexId getIndex() {\n+            return index;\n+        }\n+\n+        public int getShardId() {\n+            return shardId;\n+        }\n+\n+        @Override\n+        public boolean equals(Object o) {\n+            if (this == o) {\n+                return true;\n+            }\n+            if (o == null || getClass() != o.getClass()) {\n+                return false;\n+            }\n+            final SnapshotShard that = (SnapshotShard) o;\n+            return shardId == that.shardId\n+                && snapshot.equals(that.snapshot)\n+                && index.equals(that.index);\n+        }\n+\n+        @Override\n+        public int hashCode() {\n+            return Objects.hash(snapshot, index, shardId);\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"SnapshotShard{\" +\n+                \"snapshot=\" + snapshot +\n+                \", index=\" + index +\n+                \", shardId=\" + shardId +\n+                '}';\n+        }\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(snapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> requiredSnapshotShards = new HashSet<>();\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.id());\n+                    requiredSnapshotShards.add(snapshotShard);\n+                    // check if already populated entry\n+                    if (snapshotShardSizes.get(snapshotShard) == null) {\n+                        // check if already fetching snapshot info in progress\n+                        if (fetchingShards.add(snapshotShard)) {\n+                            // TODO: Use a dedicated threadpool here? Use FETCH thread pool?\n+                            threadPool.generic().execute(new AbstractRunnable() {\n+                                @Override\n+                                public void onFailure(Exception e) {\n+                                    logger.warn(new ParameterizedMessage(\"failed to retrieve shard size information for {}\",\n+                                        shardRouting), e);\n+                                }\n+\n+                                @Override\n+                                protected void doRun() {\n+                                    final RepositoriesService repositories = repositoriesServiceSupplier.get();\n+                                    assert repositories != null;\n+                                    final Repository repository = repositories.repository(snapshotShard.snapshot.getRepository());\n+                                    final IndexShardSnapshotStatus status =\n+                                        repository.getShardSnapshotStatus(snapshotRecoverySource.snapshot().getSnapshotId(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb6daa1f9262d2b11f68ee18775db67c074b7da7"}, "originalPosition": 155}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8f5c2abdb1454b863fab860274ef1c201f9274ca", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/8f5c2abdb1454b863fab860274ef1c201f9274ca", "committedDate": "2020-10-05T07:57:01Z", "message": "Bound concurrent snapshot shard size retrievals"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f5ea5a9d9059598248ed25e0e383d3d242794269", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/f5ea5a9d9059598248ed25e0e383d3d242794269", "committedDate": "2020-10-05T07:57:38Z", "message": "Merge branch 'master' into snapshot-size-based-allocation"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAxODE3NTc4", "url": "https://github.com/elastic/elasticsearch/pull/61906#pullrequestreview-501817578", "createdAt": "2020-10-05T08:15:38Z", "commit": {"oid": "f5ea5a9d9059598248ed25e0e383d3d242794269"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQwODoxNTozOFrOHcSIUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQwODozMTo0MFrOHcSrPw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTQxOTIxNw==", "bodyText": "This only need to be added on master nodes right? (relates #63223)", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499419217", "createdAt": "2020-10-05T08:15:38Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,308 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.concurrent.AdjustableSemaphore;\n+import org.elasticsearch.common.util.concurrent.RunOnce;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private final AdjustableSemaphore semaphore;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.semaphore = new AdjustableSemaphore(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings), false);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        clusterService.addListener(this);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f5ea5a9d9059598248ed25e0e383d3d242794269"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTQyODE1OQ==", "bodyText": "Do we really need a Semaphore here? Can't we just have these tasks increment a counter with incrementAndGet whenever we try to start one and if it's below the current limit + 1 we start a task? Then we only need to decrement the counter when we poll a null from the queue and it's all a lot easier isn't it?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499428159", "createdAt": "2020-10-05T08:31:40Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,308 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.concurrent.AdjustableSemaphore;\n+import org.elasticsearch.common.util.concurrent.RunOnce;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private final AdjustableSemaphore semaphore;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.semaphore = new AdjustableSemaphore(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings), false);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        clusterService.addListener(this);\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        semaphore.setMaxPermits(maxConcurrentFetches);\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, semaphore.getMaxPermits());\n+            for (int i = 0; i < nbFetchers; i++) {\n+                fetchNextSnapshotShard();\n+            }\n+        } else {\n+            synchronized (this) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        if (semaphore.tryAcquire()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f5ea5a9d9059598248ed25e0e383d3d242794269"}, "originalPosition": 171}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9aea78a9c829d69f0d01829127e3c07b36d66687", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/9aea78a9c829d69f0d01829127e3c07b36d66687", "committedDate": "2020-10-05T09:08:54Z", "message": "Revert"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910", "committedDate": "2020-10-05T09:15:41Z", "message": "apply feedback"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAxOTMzNjMw", "url": "https://github.com/elastic/elasticsearch/pull/61906#pullrequestreview-501933630", "createdAt": "2020-10-05T10:48:03Z", "commit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "state": "COMMENTED", "comments": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMDo0ODowNFrOHcXjGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMTo1Nzo0MFrOHcZwqA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUwNzk5Mw==", "bodyText": "NIT: we could make this ActionListener just a static constant?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499507993", "createdAt": "2020-10-05T10:48:04Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {\n+                    fetchNextSnapshotShard();\n+                } else {\n+                    final int value = concurrentFetches.decrementAndGet();\n+                    assert value >= 0 : \"Unexpected value: \" + value;\n+                }\n+            }\n+        } else {\n+            synchronized (this) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        boolean success = false;\n+        try {\n+            final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n+            if (snapshotShard != null) {\n+                threadPool.executor(executorName()).execute(new AbstractRunnable() {\n+                    @Override\n+                    protected void doRun() {\n+                        if (clusterService.state().nodes().isLocalNodeElectedMaster() == false) {\n+                            logger.debug(\"skipping snapshot shard size retrieval for {} as node is no longer master\", snapshotShard);\n+                            return;\n+                        }\n+\n+                        final RepositoriesService repositories = repositoriesService.get();\n+                        assert repositories != null;\n+                        final Repository repository = repositories.repository(snapshotShard.snapshot.getRepository());\n+\n+                        logger.debug(\"fetching snapshot shard size for {}\", snapshotShard);\n+                        final IndexShardSnapshotStatus status = repository.getShardSnapshotStatus(\n+                            snapshotShard.snapshot().getSnapshotId(),\n+                            snapshotShard.index(),\n+                            snapshotShard.shardId()\n+                        );\n+\n+                        final long snapshotShardSize = status.asCopy().getTotalSize();\n+                        logger.debug(\"snapshot shard size for {}: {} bytes\", snapshotShard, snapshotShardSize);\n+\n+                        boolean updated = false;\n+                        synchronized (InternalSnapshotsInfoService.this) {\n+                            if (isMaster) {\n+                                final ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes =\n+                                    ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                                updated = newSnapshotShardSizes.put(snapshotShard, snapshotShardSize) == null;\n+                                knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                            }\n+                        }\n+                        if (updated) {\n+                            rerouteService.get().reroute(\"snapshot shard size updated\", Priority.HIGH,\n+                                ActionListener.wrap(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 218}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUxMDczOQ==", "bodyText": "This method can just be inlined, we never overwrite it?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499510739", "createdAt": "2020-10-05T10:53:46Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUxMzU2Ng==", "bodyText": "Maybe extract these two lines into a method releaseFetcher or so and with a one liner describing what this does since we use this in two spots?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499513566", "createdAt": "2020-10-05T10:59:05Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {\n+                    fetchNextSnapshotShard();\n+                } else {\n+                    final int value = concurrentFetches.decrementAndGet();\n+                    assert value >= 0 : \"Unexpected value: \" + value;\n+                }\n+            }\n+        } else {\n+            synchronized (this) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        boolean success = false;\n+        try {\n+            final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n+            if (snapshotShard != null) {\n+                threadPool.executor(executorName()).execute(new AbstractRunnable() {\n+                    @Override\n+                    protected void doRun() {\n+                        if (clusterService.state().nodes().isLocalNodeElectedMaster() == false) {\n+                            logger.debug(\"skipping snapshot shard size retrieval for {} as node is no longer master\", snapshotShard);\n+                            return;\n+                        }\n+\n+                        final RepositoriesService repositories = repositoriesService.get();\n+                        assert repositories != null;\n+                        final Repository repository = repositories.repository(snapshotShard.snapshot.getRepository());\n+\n+                        logger.debug(\"fetching snapshot shard size for {}\", snapshotShard);\n+                        final IndexShardSnapshotStatus status = repository.getShardSnapshotStatus(\n+                            snapshotShard.snapshot().getSnapshotId(),\n+                            snapshotShard.index(),\n+                            snapshotShard.shardId()\n+                        );\n+\n+                        final long snapshotShardSize = status.asCopy().getTotalSize();\n+                        logger.debug(\"snapshot shard size for {}: {} bytes\", snapshotShard, snapshotShardSize);\n+\n+                        boolean updated = false;\n+                        synchronized (InternalSnapshotsInfoService.this) {\n+                            if (isMaster) {\n+                                final ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes =\n+                                    ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                                updated = newSnapshotShardSizes.put(snapshotShard, snapshotShardSize) == null;\n+                                knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                            }\n+                        }\n+                        if (updated) {\n+                            rerouteService.get().reroute(\"snapshot shard size updated\", Priority.HIGH,\n+                                ActionListener.wrap(\n+                                    r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+                                    e -> logger.debug(\"reroute after snapshot shard size update failed\", e)));\n+                        }\n+                    }\n+\n+                    @Override\n+                    public void onFailure(Exception e) {\n+                        logger.warn(() -> new ParameterizedMessage(\"failed to retrieve shard size for {}\", snapshotShard), e);\n+                    }\n+\n+                    @Override\n+                    public void onAfter() {\n+                        unknownSnapshotShards.remove(snapshotShard);\n+                        fetchNextSnapshotShard();\n+                    }\n+                });\n+                success = true;\n+            }\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            logger.warn(\"snapshot shard size fetcher has been interrupted\", e);\n+        } finally {\n+            if (success == false) {\n+                final int value = concurrentFetches.decrementAndGet();\n+                assert value >= 0 : \"Unexpected value: \" + value;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 243}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUxNjE1Mg==", "bodyText": "Maybe just make this a one liner with the above since we never really use status otherwise:\n                        final long snapshotShardSize = repository.getShardSnapshotStatus(\n                                snapshotShard.snapshot().getSnapshotId(),\n                                snapshotShard.index(),\n                                snapshotShard.shardId()\n                        ).asCopy().getTotalSize();", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499516152", "createdAt": "2020-10-05T11:04:32Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {\n+                    fetchNextSnapshotShard();\n+                } else {\n+                    final int value = concurrentFetches.decrementAndGet();\n+                    assert value >= 0 : \"Unexpected value: \" + value;\n+                }\n+            }\n+        } else {\n+            synchronized (this) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        boolean success = false;\n+        try {\n+            final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n+            if (snapshotShard != null) {\n+                threadPool.executor(executorName()).execute(new AbstractRunnable() {\n+                    @Override\n+                    protected void doRun() {\n+                        if (clusterService.state().nodes().isLocalNodeElectedMaster() == false) {\n+                            logger.debug(\"skipping snapshot shard size retrieval for {} as node is no longer master\", snapshotShard);\n+                            return;\n+                        }\n+\n+                        final RepositoriesService repositories = repositoriesService.get();\n+                        assert repositories != null;\n+                        final Repository repository = repositories.repository(snapshotShard.snapshot.getRepository());\n+\n+                        logger.debug(\"fetching snapshot shard size for {}\", snapshotShard);\n+                        final IndexShardSnapshotStatus status = repository.getShardSnapshotStatus(\n+                            snapshotShard.snapshot().getSnapshotId(),\n+                            snapshotShard.index(),\n+                            snapshotShard.shardId()\n+                        );\n+\n+                        final long snapshotShardSize = status.asCopy().getTotalSize();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 204}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUxODEzNQ==", "bodyText": "NIT: Maybe just if (isMaster == false) ?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499518135", "createdAt": "2020-10-05T11:08:36Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {\n+                    fetchNextSnapshotShard();\n+                } else {\n+                    final int value = concurrentFetches.decrementAndGet();\n+                    assert value >= 0 : \"Unexpected value: \" + value;\n+                }\n+            }\n+        } else {\n+            synchronized (this) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        boolean success = false;\n+        try {\n+            final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n+            if (snapshotShard != null) {\n+                threadPool.executor(executorName()).execute(new AbstractRunnable() {\n+                    @Override\n+                    protected void doRun() {\n+                        if (clusterService.state().nodes().isLocalNodeElectedMaster() == false) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 188}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUyMTc4MA==", "bodyText": "Should we make sure to return the same size for the same shard consistently? (and maybe also assert that we are indeed dealing with a snapshot recovery routing here?)", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499521780", "createdAt": "2020-10-05T11:15:25Z", "author": {"login": "original-brownbear"}, "path": "test/framework/src/main/java/org/elasticsearch/cluster/ESAllocationTestCase.java", "diffHunk": "@@ -55,6 +58,14 @@\n     private static final ClusterSettings EMPTY_CLUSTER_SETTINGS =\n         new ClusterSettings(Settings.EMPTY, ClusterSettings.BUILT_IN_CLUSTER_SETTINGS);\n \n+    public static final SnapshotsInfoService SNAPSHOT_INFO_SERVICE_WITH_SHARD_SIZES = () ->\n+        new SnapshotShardSizeInfo(ImmutableOpenMap.of()) {\n+            @Override\n+            public Long getShardSize(ShardRouting shardRouting) {\n+                return randomNonNegativeLong();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUzNTE2Nw==", "bodyText": "Isn't updated always true since we won't double schedule a job for a certain shard's size ever?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499535167", "createdAt": "2020-10-05T11:41:08Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {\n+                    fetchNextSnapshotShard();\n+                } else {\n+                    final int value = concurrentFetches.decrementAndGet();\n+                    assert value >= 0 : \"Unexpected value: \" + value;\n+                }\n+            }\n+        } else {\n+            synchronized (this) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        boolean success = false;\n+        try {\n+            final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n+            if (snapshotShard != null) {\n+                threadPool.executor(executorName()).execute(new AbstractRunnable() {\n+                    @Override\n+                    protected void doRun() {\n+                        if (clusterService.state().nodes().isLocalNodeElectedMaster() == false) {\n+                            logger.debug(\"skipping snapshot shard size retrieval for {} as node is no longer master\", snapshotShard);\n+                            return;\n+                        }\n+\n+                        final RepositoriesService repositories = repositoriesService.get();\n+                        assert repositories != null;\n+                        final Repository repository = repositories.repository(snapshotShard.snapshot.getRepository());\n+\n+                        logger.debug(\"fetching snapshot shard size for {}\", snapshotShard);\n+                        final IndexShardSnapshotStatus status = repository.getShardSnapshotStatus(\n+                            snapshotShard.snapshot().getSnapshotId(),\n+                            snapshotShard.index(),\n+                            snapshotShard.shardId()\n+                        );\n+\n+                        final long snapshotShardSize = status.asCopy().getTotalSize();\n+                        logger.debug(\"snapshot shard size for {}: {} bytes\", snapshotShard, snapshotShardSize);\n+\n+                        boolean updated = false;\n+                        synchronized (InternalSnapshotsInfoService.this) {\n+                            if (isMaster) {\n+                                final ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes =\n+                                    ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                                updated = newSnapshotShardSizes.put(snapshotShard, snapshotShardSize) == null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 212}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUzNzE2Nw==", "bodyText": "Should we assert that this returned true?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499537167", "createdAt": "2020-10-05T11:44:53Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {\n+                    fetchNextSnapshotShard();\n+                } else {\n+                    final int value = concurrentFetches.decrementAndGet();\n+                    assert value >= 0 : \"Unexpected value: \" + value;\n+                }\n+            }\n+        } else {\n+            synchronized (this) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        boolean success = false;\n+        try {\n+            final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n+            if (snapshotShard != null) {\n+                threadPool.executor(executorName()).execute(new AbstractRunnable() {\n+                    @Override\n+                    protected void doRun() {\n+                        if (clusterService.state().nodes().isLocalNodeElectedMaster() == false) {\n+                            logger.debug(\"skipping snapshot shard size retrieval for {} as node is no longer master\", snapshotShard);\n+                            return;\n+                        }\n+\n+                        final RepositoriesService repositories = repositoriesService.get();\n+                        assert repositories != null;\n+                        final Repository repository = repositories.repository(snapshotShard.snapshot.getRepository());\n+\n+                        logger.debug(\"fetching snapshot shard size for {}\", snapshotShard);\n+                        final IndexShardSnapshotStatus status = repository.getShardSnapshotStatus(\n+                            snapshotShard.snapshot().getSnapshotId(),\n+                            snapshotShard.index(),\n+                            snapshotShard.shardId()\n+                        );\n+\n+                        final long snapshotShardSize = status.asCopy().getTotalSize();\n+                        logger.debug(\"snapshot shard size for {}: {} bytes\", snapshotShard, snapshotShardSize);\n+\n+                        boolean updated = false;\n+                        synchronized (InternalSnapshotsInfoService.this) {\n+                            if (isMaster) {\n+                                final ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes =\n+                                    ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                                updated = newSnapshotShardSizes.put(snapshotShard, snapshotShardSize) == null;\n+                                knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                            }\n+                        }\n+                        if (updated) {\n+                            rerouteService.get().reroute(\"snapshot shard size updated\", Priority.HIGH,\n+                                ActionListener.wrap(\n+                                    r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+                                    e -> logger.debug(\"reroute after snapshot shard size update failed\", e)));\n+                        }\n+                    }\n+\n+                    @Override\n+                    public void onFailure(Exception e) {\n+                        logger.warn(() -> new ParameterizedMessage(\"failed to retrieve shard size for {}\", snapshotShard), e);\n+                    }\n+\n+                    @Override\n+                    public void onAfter() {\n+                        unknownSnapshotShards.remove(snapshotShard);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 231}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUzOTY3Mw==", "bodyText": "NIT: } else if (event.previousState().nodes().isLocalNodeElectedMaster()) { maybe so we don't execute this over and over?\nI also wonder if we even need to do this? Maybe we should instead just clean out unnecessary items in the map on event.routingTableChanged() if we're not master to not have to repopulate the map over and over in an unstable master situation where it might jump in and out of the cluster a few times (which would be really painful if we're dealing with a large number of shards)?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499539673", "createdAt": "2020-10-05T11:49:26Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {\n+                    fetchNextSnapshotShard();\n+                } else {\n+                    final int value = concurrentFetches.decrementAndGet();\n+                    assert value >= 0 : \"Unexpected value: \" + value;\n+                }\n+            }\n+        } else {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 171}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU0MDE3NQ==", "bodyText": "NIT: space after null,", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499540175", "createdAt": "2020-10-05T11:50:16Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/cluster/routing/allocation/DataTierAllocationDeciderTests.java", "diffHunk": "@@ -553,7 +551,7 @@ public void testClusterAndIndex() {\n                 .put(DataTierAllocationDecider.INDEX_ROUTING_INCLUDE, \"data_warm,data_cold\")\n                 .build());\n         RoutingAllocation allocation = new RoutingAllocation(allocationDeciders, state.getRoutingNodes(), state,\n-            null, 0);\n+            null, null,0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 126}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU0MDM4OQ==", "bodyText": "NIT: Missing space here", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499540389", "createdAt": "2020-10-05T11:50:38Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/cluster/routing/allocation/DataTierAllocationDeciderTests.java", "diffHunk": "@@ -181,7 +183,7 @@ public void testIndexRequires() {\n                 .put(DataTierAllocationDecider.INDEX_ROUTING_REQUIRE, \"data_hot\")\n                 .build());\n         RoutingAllocation allocation = new RoutingAllocation(allocationDeciders, state.getRoutingNodes(), state,\n-            null, 0);\n+            null, null,0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU0MDQyMg==", "bodyText": "NIT: Missing space here", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499540422", "createdAt": "2020-10-05T11:50:42Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/cluster/routing/allocation/DataTierAllocationDeciderTests.java", "diffHunk": "@@ -143,7 +145,7 @@ public void testClusterIncludes() {\n     public void testClusterExcludes() {\n         ClusterState state = prepareState(service.reroute(ClusterState.EMPTY_STATE, \"initial state\"));\n         RoutingAllocation allocation = new RoutingAllocation(allocationDeciders, state.getRoutingNodes(), state,\n-            null, 0);\n+            null, null,0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU0MDQ0Mg==", "bodyText": "NIT: Missing space here", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499540442", "createdAt": "2020-10-05T11:50:44Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/cluster/routing/allocation/DataTierAllocationDeciderTests.java", "diffHunk": "@@ -108,7 +110,7 @@ public void testClusterRequires() {\n     public void testClusterIncludes() {\n         ClusterState state = prepareState(service.reroute(ClusterState.EMPTY_STATE, \"initial state\"));\n         RoutingAllocation allocation = new RoutingAllocation(allocationDeciders, state.getRoutingNodes(), state,\n-            null, 0);\n+            null, null,0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU0MDQ3MQ==", "bodyText": "NIT: Missing space here", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499540471", "createdAt": "2020-10-05T11:50:48Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/cluster/routing/allocation/DataTierAllocationDeciderTests.java", "diffHunk": "@@ -74,7 +76,7 @@\n     public void testClusterRequires() {\n         ClusterState state = prepareState(service.reroute(ClusterState.EMPTY_STATE, \"initial state\"));\n         RoutingAllocation allocation = new RoutingAllocation(allocationDeciders, state.getRoutingNodes(), state,\n-            null, 0);\n+            null, null,0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU0MTEyMw==", "bodyText": "NIT: use org.elasticsearch.threadpool.ThreadPool#terminate(java.util.concurrent.ExecutorService, long, java.util.concurrent.TimeUnit) and assert it returns true?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499541123", "createdAt": "2020-10-05T11:51:58Z", "author": {"login": "original-brownbear"}, "path": "server/src/test/java/org/elasticsearch/snapshots/InternalSnapshotsInfoServiceTests.java", "diffHunk": "@@ -0,0 +1,336 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.node.DiscoveryNodes;\n+import org.elasticsearch.cluster.routing.IndexRoutingTable;\n+import org.elasticsearch.cluster.routing.IndexShardRoutingTable;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.RoutingTable;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.TestShardRouting;\n+import org.elasticsearch.cluster.service.ClusterApplier;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.FilterRepository;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.test.ClusterServiceUtils;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.threadpool.TestThreadPool;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.threadpool.ThreadPoolStats;\n+\n+import java.util.Collections;\n+import java.util.Locale;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Function;\n+\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_CREATION_DATE;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_REPLICAS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_SHARDS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_VERSION_CREATED;\n+import static org.elasticsearch.snapshots.InternalSnapshotsInfoService.INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING;\n+import static org.hamcrest.Matchers.allOf;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.lessThan;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Matchers.anyString;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+public class InternalSnapshotsInfoServiceTests extends ESTestCase {\n+\n+    private TestThreadPool threadPool;\n+    private ClusterService clusterService;\n+    private RepositoriesService repositoriesService;\n+    private RerouteService rerouteService;\n+\n+    @Override\n+    public void setUp() throws Exception {\n+        super.setUp();\n+        threadPool = new TestThreadPool(getTestName());\n+        clusterService = ClusterServiceUtils.createClusterService(threadPool);\n+        repositoriesService = mock(RepositoriesService.class);\n+        rerouteService = mock(RerouteService.class);\n+        doAnswer(invocation -> {\n+            @SuppressWarnings(\"unchecked\")\n+            final ActionListener<ClusterState> listener = (ActionListener<ClusterState>) invocation.getArguments()[2];\n+            listener.onResponse(clusterService.state());\n+            return null;\n+        }).when(rerouteService).reroute(anyString(), any(Priority.class), any());\n+    }\n+\n+    @Override\n+    public void tearDown() throws Exception {\n+        super.tearDown();\n+        threadPool.shutdownNow();\n+        threadPool.awaitTermination(30L, TimeUnit.SECONDS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU0NDIzMg==", "bodyText": "NIT: Could do this in one go with the utilities we have as (also avoid mixing our own concurrency primitives with the JDK's):\n        PlainActionFuture.get(future -> clusterService.getClusterApplierService().onNewClusterState(reason,\n                () -> applier.apply(clusterService.state()),\n                new ClusterApplier.ClusterApplyListener() {\n                    @Override\n                    public void onSuccess(String source) {\n                        future.onResponse(source);\n                    }\n\n                    @Override\n                    public void onFailure(String source, Exception e) {\n                        future.onFailure(e);\n                    }\n                }));", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499544232", "createdAt": "2020-10-05T11:57:40Z", "author": {"login": "original-brownbear"}, "path": "server/src/test/java/org/elasticsearch/snapshots/InternalSnapshotsInfoServiceTests.java", "diffHunk": "@@ -0,0 +1,336 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.node.DiscoveryNodes;\n+import org.elasticsearch.cluster.routing.IndexRoutingTable;\n+import org.elasticsearch.cluster.routing.IndexShardRoutingTable;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.RoutingTable;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.TestShardRouting;\n+import org.elasticsearch.cluster.service.ClusterApplier;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.FilterRepository;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.test.ClusterServiceUtils;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.threadpool.TestThreadPool;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.threadpool.ThreadPoolStats;\n+\n+import java.util.Collections;\n+import java.util.Locale;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Function;\n+\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_CREATION_DATE;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_REPLICAS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_SHARDS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_VERSION_CREATED;\n+import static org.elasticsearch.snapshots.InternalSnapshotsInfoService.INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING;\n+import static org.hamcrest.Matchers.allOf;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.lessThan;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Matchers.anyString;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+public class InternalSnapshotsInfoServiceTests extends ESTestCase {\n+\n+    private TestThreadPool threadPool;\n+    private ClusterService clusterService;\n+    private RepositoriesService repositoriesService;\n+    private RerouteService rerouteService;\n+\n+    @Override\n+    public void setUp() throws Exception {\n+        super.setUp();\n+        threadPool = new TestThreadPool(getTestName());\n+        clusterService = ClusterServiceUtils.createClusterService(threadPool);\n+        repositoriesService = mock(RepositoriesService.class);\n+        rerouteService = mock(RerouteService.class);\n+        doAnswer(invocation -> {\n+            @SuppressWarnings(\"unchecked\")\n+            final ActionListener<ClusterState> listener = (ActionListener<ClusterState>) invocation.getArguments()[2];\n+            listener.onResponse(clusterService.state());\n+            return null;\n+        }).when(rerouteService).reroute(anyString(), any(Priority.class), any());\n+    }\n+\n+    @Override\n+    public void tearDown() throws Exception {\n+        super.tearDown();\n+        threadPool.shutdownNow();\n+        threadPool.awaitTermination(30L, TimeUnit.SECONDS);\n+        clusterService.close();\n+    }\n+\n+    public void testSnapshotShardSizes() throws Exception {\n+        final int maxConcurrentFetches = randomIntBetween(1, 10);\n+        final InternalSnapshotsInfoService snapshotsInfoService =\n+            new InternalSnapshotsInfoService(Settings.builder()\n+                .put(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.getKey(), maxConcurrentFetches)\n+                .build(), clusterService, () -> repositoriesService, () -> rerouteService);\n+\n+        final int numberOfShards = randomIntBetween(1, 50);\n+        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final long[] expectedShardSizes = new long[numberOfShards];\n+        for (int i = 0; i < expectedShardSizes.length; i++) {\n+            expectedShardSizes[i] = randomNonNegativeLong();\n+        }\n+\n+        final CountDownLatch latch = new CountDownLatch(1);\n+        when(repositoriesService.repository(\"_repo\"))\n+            .thenReturn(new FilterRepository(mock(Repository.class)) {\n+                @Override\n+                public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId shardId) {\n+                    try {\n+                        assertThat(indexId.getName(), equalTo(indexName));\n+                        assertThat(shardId.id(), allOf(greaterThanOrEqualTo(0), lessThan(numberOfShards)));\n+                        latch.await();\n+                        return IndexShardSnapshotStatus.newDone(0L, 0L, 0, 0, 0L, expectedShardSizes[shardId.id()], null);\n+                    } catch (InterruptedException e) {\n+                        throw new AssertionError(e);\n+                    }\n+                }\n+            });\n+\n+        applyClusterState(\"add-unassigned-shards\", clusterState -> addUnassignedShards(clusterState, indexName, numberOfShards));\n+        waitForMaxActiveGenericThreads(Math.min(numberOfShards, maxConcurrentFetches));\n+\n+        assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(numberOfShards));\n+        assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(0));\n+\n+        latch.countDown();\n+        waitForMaxActiveGenericThreads(0);\n+\n+        assertBusy(() -> {\n+            assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(numberOfShards));\n+            assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(0));\n+        });\n+        verify(rerouteService, times(numberOfShards)).reroute(anyString(), any(Priority.class), any());\n+\n+        for (int i = 0; i < numberOfShards; i++) {\n+            final ShardRouting shardRouting = clusterService.state().routingTable().index(indexName).shard(i).primaryShard();\n+            assertThat(snapshotsInfoService.snapshotShardSizes().getShardSize(shardRouting), equalTo(expectedShardSizes[i]));\n+        }\n+    }\n+\n+    public void testErroneousSnapshotShardSizes() throws Exception {\n+        final InternalSnapshotsInfoService snapshotsInfoService =\n+            new InternalSnapshotsInfoService(Settings.builder()\n+                .put(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.getKey(), randomIntBetween(1, 10))\n+                .build(), clusterService, () -> repositoriesService, () -> rerouteService);\n+\n+        final Set<InternalSnapshotsInfoService.SnapshotShard> succeed = Sets.newConcurrentHashSet();\n+        final Set<InternalSnapshotsInfoService.SnapshotShard> failed = Sets.newConcurrentHashSet();\n+        when(repositoriesService.repository(\"_repo\"))\n+            .thenReturn(new FilterRepository(mock(Repository.class)) {\n+                @Override\n+                public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId shardId) {\n+                    final InternalSnapshotsInfoService.SnapshotShard snapshotShard =\n+                        new InternalSnapshotsInfoService.SnapshotShard(new Snapshot(\"_repo\", snapshotId), indexId, shardId);\n+                    if (randomBoolean()) {\n+                        failed.add(snapshotShard);\n+                        throw new SnapshotException(snapshotShard.snapshot(), \"simulated\");\n+                    } else {\n+                        succeed.add(snapshotShard);\n+                        return IndexShardSnapshotStatus.newDone(0L, 0L, 0, 0, 0L, randomNonNegativeLong(), null);\n+                    }\n+                }\n+            });\n+\n+        final int maxShardsToCreate = scaledRandomIntBetween(10, 500);\n+        final Thread addSnapshotRestoreIndicesThread = new Thread(() -> {\n+            int remainingShards = maxShardsToCreate;\n+            while (remainingShards > 0) {\n+                final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+                final int numberOfShards = randomIntBetween(1, maxShardsToCreate);\n+                try {\n+                    applyClusterState(\"add-more-unassigned-shards-for-\" + indexName,\n+                        clusterState -> addUnassignedShards(clusterState, indexName, numberOfShards));\n+                } catch (Exception e) {\n+                    throw new AssertionError(e);\n+                } finally {\n+                    remainingShards -= numberOfShards;\n+                }\n+            }\n+        });\n+        addSnapshotRestoreIndicesThread.start();\n+\n+        assertBusy(() -> {\n+            assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(succeed.size()));\n+            assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(0));\n+        });\n+\n+        addSnapshotRestoreIndicesThread.join();\n+    }\n+\n+    public void testNoLongerMaster() throws Exception {\n+        final InternalSnapshotsInfoService snapshotsInfoService =\n+            new InternalSnapshotsInfoService(Settings.EMPTY, clusterService, () -> repositoriesService, () -> rerouteService);\n+\n+        when(repositoriesService.repository(\"_repo\"))\n+            .thenReturn(new FilterRepository(mock(Repository.class)) {\n+                @Override\n+                public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId shardId) {\n+                    return IndexShardSnapshotStatus.newDone(0L, 0L, 0, 0, 0L, randomNonNegativeLong(), null);\n+                }\n+            });\n+\n+        for (int i = 0; i < randomIntBetween(1, 10); i++) {\n+            final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+            final int nbShards =  randomIntBetween(1, 5);\n+            applyClusterState(\"restore-indices-when-master-\" + indexName,\n+                clusterState -> addUnassignedShards(clusterState, indexName, nbShards));\n+        }\n+\n+        applyClusterState(\"demote-current-master\", this::demoteMasterNode);\n+\n+        for (int i = 0; i < randomIntBetween(1, 10); i++) {\n+            final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+            final int nbShards =  randomIntBetween(1, 5);\n+            applyClusterState(\"restore-indices-when-no-longer-master-\" + indexName,\n+                clusterState -> addUnassignedShards(clusterState, indexName, nbShards));\n+        }\n+\n+        assertBusy(() -> {\n+            assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(0));\n+            assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(0));\n+        });\n+    }\n+\n+    private void applyClusterState(final String reason, final Function<ClusterState, ClusterState> applier) throws Exception {\n+        final CompletableFuture<String> future = new CompletableFuture<>();\n+        clusterService.getClusterApplierService().onNewClusterState(reason,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 252}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAxOTkwMTAz", "url": "https://github.com/elastic/elasticsearch/pull/61906#pullrequestreview-501990103", "createdAt": "2020-10-05T12:10:29Z", "commit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMjoxMDoyOVrOHcaJuw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMjoxMDoyOVrOHcaJuw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU1MDY1MQ==", "bodyText": "I think there is a race here, in that if all threads polled and found out that queue is empty but did not count down the counter yet, we could add to the queue here and risk that the increment results in a number higher than maxConcurrentFetches?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499550651", "createdAt": "2020-10-05T12:10:29Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 164}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bfd352c3757230037fee9344ff202f293ce648de", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/bfd352c3757230037fee9344ff202f293ce648de", "committedDate": "2020-10-05T12:44:07Z", "message": "listener as a constant"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f9ed97469d10f6d5473c56d351421ecdb54c5bbc", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/f9ed97469d10f6d5473c56d351421ecdb54c5bbc", "committedDate": "2020-10-05T12:45:04Z", "message": "remove left over"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "866ba36c7ec8a02b7a2ca2e69b0f5c3826691541", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/866ba36c7ec8a02b7a2ca2e69b0f5c3826691541", "committedDate": "2020-10-05T12:46:37Z", "message": "inline snapshotShardSize"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7343b63aafb0b19510e0b4f7236628f4dd41aebf", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/7343b63aafb0b19510e0b4f7236628f4dd41aebf", "committedDate": "2020-10-05T12:48:37Z", "message": "isMaster == false"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAyMDI1NzE0", "url": "https://github.com/elastic/elasticsearch/pull/61906#pullrequestreview-502025714", "createdAt": "2020-10-05T12:55:40Z", "commit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMjo1NTo0MFrOHcbvig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMjo1NTo0MFrOHcbvig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU3NjcxNA==", "bodyText": "I think there is a race with unknownSnapshotShards. It does take something extreme but in this case I think we might not read one of the shard sizes:\n\nA cluster state change results in queuing a read for a shard.\nThe read happens and populates knownSnapshotShards, but the thread is halted before removing from unkonwnSnapshotShards.\nA cluster state change removes the need for the shard (deleted index?).\nA cluster state change reintroduces the need to read the shard sizes. This will not add to queue, since this line did not complete yet on the original read.\nThe fetch thread removes shard from unknownSnapshotShards", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499576714", "createdAt": "2020-10-05T12:55:40Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {\n+                    fetchNextSnapshotShard();\n+                } else {\n+                    final int value = concurrentFetches.decrementAndGet();\n+                    assert value >= 0 : \"Unexpected value: \" + value;\n+                }\n+            }\n+        } else {\n+            synchronized (this) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        boolean success = false;\n+        try {\n+            final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n+            if (snapshotShard != null) {\n+                threadPool.executor(executorName()).execute(new AbstractRunnable() {\n+                    @Override\n+                    protected void doRun() {\n+                        if (clusterService.state().nodes().isLocalNodeElectedMaster() == false) {\n+                            logger.debug(\"skipping snapshot shard size retrieval for {} as node is no longer master\", snapshotShard);\n+                            return;\n+                        }\n+\n+                        final RepositoriesService repositories = repositoriesService.get();\n+                        assert repositories != null;\n+                        final Repository repository = repositories.repository(snapshotShard.snapshot.getRepository());\n+\n+                        logger.debug(\"fetching snapshot shard size for {}\", snapshotShard);\n+                        final IndexShardSnapshotStatus status = repository.getShardSnapshotStatus(\n+                            snapshotShard.snapshot().getSnapshotId(),\n+                            snapshotShard.index(),\n+                            snapshotShard.shardId()\n+                        );\n+\n+                        final long snapshotShardSize = status.asCopy().getTotalSize();\n+                        logger.debug(\"snapshot shard size for {}: {} bytes\", snapshotShard, snapshotShardSize);\n+\n+                        boolean updated = false;\n+                        synchronized (InternalSnapshotsInfoService.this) {\n+                            if (isMaster) {\n+                                final ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes =\n+                                    ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                                updated = newSnapshotShardSizes.put(snapshotShard, snapshotShardSize) == null;\n+                                knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                            }\n+                        }\n+                        if (updated) {\n+                            rerouteService.get().reroute(\"snapshot shard size updated\", Priority.HIGH,\n+                                ActionListener.wrap(\n+                                    r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+                                    e -> logger.debug(\"reroute after snapshot shard size update failed\", e)));\n+                        }\n+                    }\n+\n+                    @Override\n+                    public void onFailure(Exception e) {\n+                        logger.warn(() -> new ParameterizedMessage(\"failed to retrieve shard size for {}\", snapshotShard), e);\n+                    }\n+\n+                    @Override\n+                    public void onAfter() {\n+                        unknownSnapshotShards.remove(snapshotShard);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 231}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "28de2d67de1b28c7d3e29e46bda50e2bef38baa9", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/28de2d67de1b28c7d3e29e46bda50e2bef38baa9", "committedDate": "2020-10-05T13:40:29Z", "message": "add assert + throw UOE"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2faf52519a6d663559eacac5592a7cbe6a317f80", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/2faf52519a6d663559eacac5592a7cbe6a317f80", "committedDate": "2020-10-05T13:45:24Z", "message": "assert updated"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a3dcb20796c2dec4189289bd6a7e2fcc554bbf93", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/a3dcb20796c2dec4189289bd6a7e2fcc554bbf93", "committedDate": "2020-10-05T13:47:12Z", "message": "assert removed"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b942b2db21b646f910664c935f11e3919d329945", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/b942b2db21b646f910664c935f11e3919d329945", "committedDate": "2020-10-05T13:51:05Z", "message": "spaces"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "be18fad0a34ae29242e2414d1f36f01d7d19c127", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/be18fad0a34ae29242e2414d1f36f01d7d19c127", "committedDate": "2020-10-05T13:51:44Z", "message": "terminate()"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAyMDQ2MjQ2", "url": "https://github.com/elastic/elasticsearch/pull/61906#pullrequestreview-502046246", "createdAt": "2020-10-05T13:18:54Z", "commit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMzoxODo1NFrOHccpdQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMzoxODo1NFrOHccpdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU5MTU0MQ==", "bodyText": "This is unused?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499591541", "createdAt": "2020-10-05T13:18:54Z", "author": {"login": "DaveCTurner"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshots.java", "diffHunk": "@@ -150,6 +150,7 @@\n     private final SetOnce<BlobStoreCacheService> blobStoreCacheService = new SetOnce<>();\n     private final SetOnce<CacheService> cacheService = new SetOnce<>();\n     private final SetOnce<ThreadPool> threadPool = new SetOnce<>();\n+    private final SetOnce<ClusterService> clusterService = new SetOnce<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ada6dd50fd6c550822361263efe8e943bae6e13f", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/ada6dd50fd6c550822361263efe8e943bae6e13f", "committedDate": "2020-10-05T13:59:03Z", "message": "isLocalNodeElectedMaster + TODO"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ae5895ce811addbc5094133031dabec540882c02", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/ae5895ce811addbc5094133031dabec540882c02", "committedDate": "2020-10-05T14:03:01Z", "message": "Remove SetOnce<ClusterService>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6dcff94a1e851651bf8c954f07276426cbedb970", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/6dcff94a1e851651bf8c954f07276426cbedb970", "committedDate": "2020-10-05T14:05:31Z", "message": "PlainActionFuture.get()"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "674d6c9387d90f492eaf3d04bd573616b06d5327", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/674d6c9387d90f492eaf3d04bd573616b06d5327", "committedDate": "2020-10-05T16:13:57Z", "message": "another shot at concurrent fetches"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b", "author": {"user": {"login": "elasticmachine", "name": "Elastic Machine"}}, "url": "https://github.com/elastic/elasticsearch/commit/291831f02ced1131a8aecb2104f6ca89853ae69b", "committedDate": "2020-10-05T18:51:54Z", "message": "Merge branch 'master' into snapshot-size-based-allocation"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAyNTQ0MjUw", "url": "https://github.com/elastic/elasticsearch/pull/61906#pullrequestreview-502544250", "createdAt": "2020-10-06T02:36:22Z", "commit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwMjozNjoyMlrOHcz9Vg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwMjo1MDoxNVrOHc0KcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTk3MzQ2Mg==", "bodyText": "NIT: revert", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499973462", "createdAt": "2020-10-06T02:36:22Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/cluster/ClusterInfo.java", "diffHunk": "@@ -22,7 +22,6 @@\n import com.carrotsearch.hppc.ObjectHashSet;\n import com.carrotsearch.hppc.cursors.ObjectCursor;\n import com.carrotsearch.hppc.cursors.ObjectObjectCursor;\n-", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTk3NTY0MQ==", "bodyText": "We can save some code here now that we have the mutex and don't need a concurrent collection any longer?\ne.g.\ndiff --git a/server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java b/server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java\nindex 43cd8cd11b1..a1917c3544b 100644\n--- a/server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java\n+++ b/server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java\n@@ -46,13 +46,12 @@ import org.elasticsearch.repositories.Repository;\n import org.elasticsearch.threadpool.ThreadPool;\n \n import java.util.Collections;\n+import java.util.Deque;\n import java.util.HashSet;\n import java.util.LinkedHashSet;\n+import java.util.LinkedList;\n import java.util.Objects;\n import java.util.Set;\n-import java.util.concurrent.BlockingQueue;\n-import java.util.concurrent.LinkedBlockingQueue;\n-import java.util.concurrent.TimeUnit;\n import java.util.function.Supplier;\n \n public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n@@ -81,7 +80,7 @@ public class InternalSnapshotsInfoService implements ClusterStateListener, Snaps\n     private final Set<SnapshotShard> unknownSnapshotShards;\n \n     /** a blocking queue used for concurrent fetching **/\n-    private final BlockingQueue<SnapshotShard> queue;\n+    private final Deque<SnapshotShard> queue;\n \n     private volatile int maxConcurrentFetches;\n     private volatile int activeFetches;\n@@ -99,7 +98,7 @@ public class InternalSnapshotsInfoService implements ClusterStateListener, Snaps\n         this.rerouteService = rerouteServiceSupplier;\n         this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n         this.unknownSnapshotShards  = new LinkedHashSet<>();\n-        this.queue = new LinkedBlockingQueue<>();\n+        this.queue = new LinkedList<>();\n         this.mutex = new Object();\n         this.activeFetches = 0;\n         this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n@@ -159,15 +158,10 @@ public class InternalSnapshotsInfoService implements ClusterStateListener, Snaps\n     private void fetchNextSnapshotShard() {\n         synchronized (mutex) {\n             if (activeFetches < maxConcurrentFetches) {\n-                try {\n-                    final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n-                    if (snapshotShard != null) {\n-                        threadPool.generic().execute(new FetchingSnapshotShardSizeRunnable(snapshotShard));\n-                        activeFetches += 1;\n-                    }\n-                } catch (InterruptedException e) {\n-                    Thread.currentThread().interrupt();\n-                    logger.warn(\"snapshot shard size fetcher has been interrupted\", e);\n+                final SnapshotShard snapshotShard = queue.pollFirst();\n+                if (snapshotShard != null) {\n+                    threadPool.generic().execute(new FetchingSnapshotShardSizeRunnable(snapshotShard));\n+                    activeFetches += 1;\n                 }\n             }\n             assert assertNumberOfConcurrentFetches();", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499975641", "createdAt": "2020-10-06T02:45:24Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private static final ActionListener<ClusterState> REROUTE_LISTENER = ActionListener.wrap(\n+        r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+        e -> logger.debug(\"reroute after snapshot shard size update failed\", e)\n+    );\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private volatile int activeFetches;\n+\n+    private final Object mutex;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = new LinkedHashSet<>();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.mutex = new Object();\n+        this.activeFetches = 0;\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = listOfSnapshotShards(event.state());\n+\n+            int unknownShards = 0;\n+            synchronized (mutex) {\n+                isMaster = true;\n+                for (SnapshotShard snapshotShard : onGoingSnapshotRecoveries) {\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+                // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+                cleanUpKnownSnapshotShardSizes(onGoingSnapshotRecoveries);\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                fetchNextSnapshotShard();\n+            }\n+        } else if (event.previousState().nodes().isLocalNodeElectedMaster()) {\n+            // TODO Maybe just clear out non-ongoing snapshot recoveries is the node is master eligible, so that we don't\n+            // have to repopulate the data over and over in an unstable master situation?\n+            synchronized (mutex) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        synchronized (mutex) {\n+            if (activeFetches < maxConcurrentFetches) {\n+                try {\n+                    final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 163}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTk3NjEzOA==", "bodyText": "This should now synchronise on the mutex as well shouldn't it?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499976138", "createdAt": "2020-10-06T02:47:30Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private static final ActionListener<ClusterState> REROUTE_LISTENER = ActionListener.wrap(\n+        r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+        e -> logger.debug(\"reroute after snapshot shard size update failed\", e)\n+    );\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private volatile int activeFetches;\n+\n+    private final Object mutex;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = new LinkedHashSet<>();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.mutex = new Object();\n+        this.activeFetches = 0;\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = listOfSnapshotShards(event.state());\n+\n+            int unknownShards = 0;\n+            synchronized (mutex) {\n+                isMaster = true;\n+                for (SnapshotShard snapshotShard : onGoingSnapshotRecoveries) {\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+                // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+                cleanUpKnownSnapshotShardSizes(onGoingSnapshotRecoveries);\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                fetchNextSnapshotShard();\n+            }\n+        } else if (event.previousState().nodes().isLocalNodeElectedMaster()) {\n+            // TODO Maybe just clear out non-ongoing snapshot recoveries is the node is master eligible, so that we don't\n+            // have to repopulate the data over and over in an unstable master situation?\n+            synchronized (mutex) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        synchronized (mutex) {\n+            if (activeFetches < maxConcurrentFetches) {\n+                try {\n+                    final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n+                    if (snapshotShard != null) {\n+                        threadPool.generic().execute(new FetchingSnapshotShardSizeRunnable(snapshotShard));\n+                        activeFetches += 1;\n+                    }\n+                } catch (InterruptedException e) {\n+                    Thread.currentThread().interrupt();\n+                    logger.warn(\"snapshot shard size fetcher has been interrupted\", e);\n+                }\n+            }\n+            assert assertNumberOfConcurrentFetches();\n+        }\n+    }\n+\n+    private class FetchingSnapshotShardSizeRunnable extends AbstractRunnable {\n+\n+        private final SnapshotShard snapshotShard;\n+        private boolean removed;\n+\n+        FetchingSnapshotShardSizeRunnable(SnapshotShard snapshotShard) {\n+            super();\n+            this.snapshotShard = snapshotShard;\n+            this.removed = false;\n+        }\n+\n+        @Override\n+        protected void doRun() throws Exception {\n+            final RepositoriesService repositories = repositoriesService.get();\n+            assert repositories != null;\n+            final Repository repository = repositories.repository(snapshotShard.snapshot.getRepository());\n+\n+            logger.debug(\"fetching snapshot shard size for {}\", snapshotShard);\n+            final long snapshotShardSize = repository.getShardSnapshotStatus(\n+                snapshotShard.snapshot().getSnapshotId(),\n+                snapshotShard.index(),\n+                snapshotShard.shardId()\n+            ).asCopy().getTotalSize();\n+\n+            logger.debug(\"snapshot shard size for {}: {} bytes\", snapshotShard, snapshotShardSize);\n+\n+            boolean updated = false;\n+            synchronized (mutex) {\n+                removed = unknownSnapshotShards.remove(snapshotShard);\n+                assert removed : \"snapshot shard to remove does not exist \" + snapshotShardSize;\n+                if (isMaster) {\n+                    final ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes =\n+                        ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                    updated = newSnapshotShardSizes.put(snapshotShard, snapshotShardSize) == null;\n+                    assert updated : \"snapshot shard size already exists for \" + snapshotShard;\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+                activeFetches -= 1;\n+                assert assertNumberOfConcurrentFetches();\n+            }\n+            if (updated) {\n+                rerouteService.get().reroute(\"snapshot shard size updated\", Priority.HIGH, REROUTE_LISTENER);\n+            }\n+        }\n+\n+        @Override\n+        public void onFailure(Exception e) {\n+            logger.warn(() -> new ParameterizedMessage(\"failed to retrieve shard size for {}\", snapshotShard), e);\n+            synchronized (mutex) {\n+                if (removed == false) {\n+                    unknownSnapshotShards.remove(snapshotShard);\n+                }\n+                activeFetches -= 1;\n+                assert assertNumberOfConcurrentFetches();\n+            }\n+        }\n+\n+        @Override\n+        public void onAfter() {\n+            fetchNextSnapshotShard();\n+        }\n+    }\n+\n+    private void cleanUpKnownSnapshotShardSizes(Set<SnapshotShard> requiredSnapshotShards) {\n+        assert Thread.holdsLock(mutex);\n+        ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+        for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+            if (requiredSnapshotShards.contains(shard.value) == false) {\n+                if (newSnapshotShardSizes == null) {\n+                    newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                }\n+                newSnapshotShardSizes.remove(shard.value);\n+            }\n+        }\n+        if (newSnapshotShardSizes != null) {\n+            knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+        }\n+    }\n+\n+    private boolean assertNumberOfConcurrentFetches() {\n+        assert activeFetches >= 0 : \"active fetches should be greater than or equal to zero but got: \" + activeFetches;\n+        assert activeFetches <= maxConcurrentFetches : activeFetches + \" <= \" + maxConcurrentFetches;\n+        return true;\n+    }\n+\n+    // used in tests\n+    int numberOfUnknownSnapshotShardSizes() {\n+        return unknownSnapshotShards.size();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 264}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTk3NjgxNg==", "bodyText": "Should we also clear queue here?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499976816", "createdAt": "2020-10-06T02:50:15Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private static final ActionListener<ClusterState> REROUTE_LISTENER = ActionListener.wrap(\n+        r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+        e -> logger.debug(\"reroute after snapshot shard size update failed\", e)\n+    );\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private volatile int activeFetches;\n+\n+    private final Object mutex;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = new LinkedHashSet<>();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.mutex = new Object();\n+        this.activeFetches = 0;\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = listOfSnapshotShards(event.state());\n+\n+            int unknownShards = 0;\n+            synchronized (mutex) {\n+                isMaster = true;\n+                for (SnapshotShard snapshotShard : onGoingSnapshotRecoveries) {\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+                // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+                cleanUpKnownSnapshotShardSizes(onGoingSnapshotRecoveries);\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                fetchNextSnapshotShard();\n+            }\n+        } else if (event.previousState().nodes().isLocalNodeElectedMaster()) {\n+            // TODO Maybe just clear out non-ongoing snapshot recoveries is the node is master eligible, so that we don't\n+            // have to repopulate the data over and over in an unstable master situation?\n+            synchronized (mutex) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 153}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAyNTg4ODg5", "url": "https://github.com/elastic/elasticsearch/pull/61906#pullrequestreview-502588889", "createdAt": "2020-10-06T05:16:21Z", "commit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "state": "COMMENTED", "comments": {"totalCount": 18, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNToxNjoyMVrOHc2OCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNzo0ODo1OVrOHc6Abg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAxMDUwNg==", "bodyText": "AFAICS, this is now fully protected by mutex.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500010506", "createdAt": "2020-10-06T05:16:21Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private static final ActionListener<ClusterState> REROUTE_LISTENER = ActionListener.wrap(\n+        r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+        e -> logger.debug(\"reroute after snapshot shard size update failed\", e)\n+    );\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private volatile int activeFetches;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAyNzcwNw==", "bodyText": "This seems to assume that we only get here for unassigned shards, never for initializing shards. I have not found a smoking gun where we could get here in that case, but I would prefer to be more specific in the condition above to only go here for unassigned shards.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500027707", "createdAt": "2020-10-06T06:13:58Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java", "diffHunk": "@@ -482,6 +484,12 @@ public static long getExpectedShardSize(ShardRouting shard, long defaultValue, C\n             }\n             return targetShardSize == 0 ? defaultValue : targetShardSize;\n         } else {\n+            if (shard.active() == false\n+                && shard.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                final Long shardSize = snapshotShardSizeInfo.getShardSize(shard);\n+                assert shardSize != null : \"no shard size provided for \" + shard;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAzNDAwMQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    RoutingAllocation routingAllocation = new RoutingAllocation(null, null, clusterState, null, null,0);\n          \n          \n            \n                    RoutingAllocation routingAllocation = new RoutingAllocation(null, null, clusterState, null, null, 0);", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500034001", "createdAt": "2020-10-06T06:30:47Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/cluster/routing/allocation/ResizeAllocationDeciderTests.java", "diffHunk": "@@ -104,7 +106,7 @@ private ClusterState createInitialClusterState(boolean startShards) {\n     public void testNonResizeRouting() {\n         ClusterState clusterState = createInitialClusterState(true);\n         ResizeAllocationDecider resizeAllocationDecider = new ResizeAllocationDecider();\n-        RoutingAllocation routingAllocation = new RoutingAllocation(null, null, clusterState, null, 0);\n+        RoutingAllocation routingAllocation = new RoutingAllocation(null, null, clusterState, null, null,0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAzNDEwNg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    RoutingAllocation routingAllocation = new RoutingAllocation(null, null, clusterState, null, null,0);\n          \n          \n            \n                    RoutingAllocation routingAllocation = new RoutingAllocation(null, null, clusterState, null, null, 0);", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500034106", "createdAt": "2020-10-06T06:31:01Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/cluster/routing/allocation/ResizeAllocationDeciderTests.java", "diffHunk": "@@ -128,7 +130,7 @@ public void testShrink() { // we don't handle shrink yet\n         Index idx = clusterState.metadata().index(\"target\").getIndex();\n \n         ResizeAllocationDecider resizeAllocationDecider = new ResizeAllocationDecider();\n-        RoutingAllocation routingAllocation = new RoutingAllocation(null, null, clusterState, null, 0);\n+        RoutingAllocation routingAllocation = new RoutingAllocation(null, null, clusterState, null, null,0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAzNDE4Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    RoutingAllocation routingAllocation = new RoutingAllocation(null, clusterState.getRoutingNodes(), clusterState, null, null,0);\n          \n          \n            \n                    RoutingAllocation routingAllocation = new RoutingAllocation(null, clusterState.getRoutingNodes(), clusterState, null, null, 0);", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500034186", "createdAt": "2020-10-06T06:31:14Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/cluster/routing/allocation/ResizeAllocationDeciderTests.java", "diffHunk": "@@ -156,7 +158,7 @@ public void testSourceNotActive() {\n \n \n         ResizeAllocationDecider resizeAllocationDecider = new ResizeAllocationDecider();\n-        RoutingAllocation routingAllocation = new RoutingAllocation(null, clusterState.getRoutingNodes(), clusterState, null, 0);\n+        RoutingAllocation routingAllocation = new RoutingAllocation(null, clusterState.getRoutingNodes(), clusterState, null, null,0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAzNDI3OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    RoutingAllocation routingAllocation = new RoutingAllocation(null, clusterState.getRoutingNodes(), clusterState, null, null,0);\n          \n          \n            \n                    RoutingAllocation routingAllocation = new RoutingAllocation(null, clusterState.getRoutingNodes(), clusterState, null, null, 0);", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500034279", "createdAt": "2020-10-06T06:31:29Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/cluster/routing/allocation/ResizeAllocationDeciderTests.java", "diffHunk": "@@ -196,7 +198,7 @@ public void testSourcePrimaryActive() {\n \n \n         ResizeAllocationDecider resizeAllocationDecider = new ResizeAllocationDecider();\n-        RoutingAllocation routingAllocation = new RoutingAllocation(null, clusterState.getRoutingNodes(), clusterState, null, 0);\n+        RoutingAllocation routingAllocation = new RoutingAllocation(null, clusterState.getRoutingNodes(), clusterState, null, null,0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAzODk4Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        null, null,0);\n          \n          \n            \n                        null, null, 0);", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500038983", "createdAt": "2020-10-06T06:43:03Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/FilterAllocationDeciderTests.java", "diffHunk": "@@ -73,7 +75,7 @@ public void testFilterInitialRecovery() {\n \n         // after failing the shard we are unassigned since the node is blacklisted and we can't initialize on the other node\n         RoutingAllocation allocation = new RoutingAllocation(allocationDeciders, state.getRoutingNodes(), state,\n-            null, 0);\n+            null, null,0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAzOTE0Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        null, null,0);\n          \n          \n            \n                        null, null, 0);", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500039142", "createdAt": "2020-10-06T06:43:28Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/FilterAllocationDeciderTests.java", "diffHunk": "@@ -124,7 +126,7 @@ public void testFilterInitialRecovery() {\n         assertEquals(routingTable.index(\"idx\").shard(0).primaryShard().currentNodeId(), \"node1\");\n \n         allocation = new RoutingAllocation(allocationDeciders, state.getRoutingNodes(), state,\n-            null, 0);\n+            null, null,0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAzOTI0MA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        clusterState.getRoutingNodes(), clusterState, null, null,0L);\n          \n          \n            \n                        clusterState.getRoutingNodes(), clusterState, null, null, 0L);", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500039240", "createdAt": "2020-10-06T06:43:44Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/RestoreInProgressAllocationDeciderTests.java", "diffHunk": "@@ -193,7 +193,7 @@ private ClusterState createInitialClusterState() {\n     private Decision executeAllocation(final ClusterState clusterState, final ShardRouting shardRouting) {\n         final AllocationDecider decider = new RestoreInProgressAllocationDecider();\n         final RoutingAllocation allocation = new RoutingAllocation(new AllocationDeciders(Collections.singleton(decider)),\n-            clusterState.getRoutingNodes(), clusterState, null, 0L);\n+            clusterState.getRoutingNodes(), clusterState, null, null,0L);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAzOTQwOA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    RoutingAllocation allocation = getRestoreRoutingAllocation(yesAllocationDeciders(), randomLong(),\"allocId\");\n          \n          \n            \n                    RoutingAllocation allocation = getRestoreRoutingAllocation(yesAllocationDeciders(), randomLong(), \"allocId\");", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500039408", "createdAt": "2020-10-06T06:44:09Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/gateway/PrimaryShardAllocatorTests.java", "diffHunk": "@@ -341,7 +343,7 @@ public void testFoundAllocationButNoDecider() {\n      * deciders say yes, we allocate to that node.\n      */\n     public void testRestore() {\n-        RoutingAllocation allocation = getRestoreRoutingAllocation(yesAllocationDeciders(), \"allocId\");\n+        RoutingAllocation allocation = getRestoreRoutingAllocation(yesAllocationDeciders(), randomLong(),\"allocId\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAzOTQ5NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    RoutingAllocation allocation = getRestoreRoutingAllocation(throttleAllocationDeciders(), randomLong(),\"allocId\");\n          \n          \n            \n                    RoutingAllocation allocation = getRestoreRoutingAllocation(throttleAllocationDeciders(), randomLong(), \"allocId\");", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500039495", "createdAt": "2020-10-06T06:44:18Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/gateway/PrimaryShardAllocatorTests.java", "diffHunk": "@@ -355,7 +357,7 @@ public void testRestore() {\n      * deciders say throttle, we add it to ignored shards.\n      */\n     public void testRestoreThrottle() {\n-        RoutingAllocation allocation = getRestoreRoutingAllocation(throttleAllocationDeciders(), \"allocId\");\n+        RoutingAllocation allocation = getRestoreRoutingAllocation(throttleAllocationDeciders(), randomLong(),\"allocId\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA0MTM1Mw==", "bodyText": "I find this name confusing, since this service has no shard sizes? Should it be ...WITH_NO_SHARD_SIZES?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500041353", "createdAt": "2020-10-06T06:48:34Z", "author": {"login": "henningandersen"}, "path": "test/framework/src/main/java/org/elasticsearch/cluster/ESAllocationTestCase.java", "diffHunk": "@@ -55,6 +59,16 @@\n     private static final ClusterSettings EMPTY_CLUSTER_SETTINGS =\n         new ClusterSettings(Settings.EMPTY, ClusterSettings.BUILT_IN_CLUSTER_SETTINGS);\n \n+    public static final SnapshotsInfoService SNAPSHOT_INFO_SERVICE_WITH_SHARD_SIZES = () ->", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA0Njc5OA==", "bodyText": "I think we are missing a test for this.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500046798", "createdAt": "2020-10-06T06:59:58Z", "author": {"login": "henningandersen"}, "path": "x-pack/plugin/ccr/src/main/java/org/elasticsearch/xpack/ccr/repository/CcrRepository.java", "diffHunk": "@@ -429,8 +433,23 @@ void acquireRetentionLeaseOnLeader(\n     }\n \n     @Override\n-    public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId leaderShardId) {\n-        throw new UnsupportedOperationException(\"Unsupported for repository of type: \" + TYPE);\n+    public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId index, ShardId shardId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA0ODc3NQ==", "bodyText": "This change seems odd to me. I suppose the allocationDeciders are effectively unused, but in that case I would still prefer to pass down allocationDeciders.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500048775", "createdAt": "2020-10-06T07:04:18Z", "author": {"login": "henningandersen"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ilm/AllocationRoutedStep.java", "diffHunk": "@@ -70,8 +70,8 @@ public Result isConditionMet(Index index, ClusterState clusterState) {\n     static int getPendingAllocations(Index index, AllocationDeciders allocationDeciders, ClusterState clusterState) {\n         // All the allocation attributes are already set so just need to check\n         // if the allocation has happened\n-        RoutingAllocation allocation = new RoutingAllocation(allocationDeciders, clusterState.getRoutingNodes(), clusterState, null,\n-            System.nanoTime());\n+        RoutingAllocation allocation = new RoutingAllocation(ALLOCATION_DECIDERS, clusterState.getRoutingNodes(), clusterState, null,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA1OTg5NA==", "bodyText": "I would think that assertBusy is unnecessary here, given that we wait for generic thread pool to be unused?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500059894", "createdAt": "2020-10-06T07:26:41Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/snapshots/InternalSnapshotsInfoServiceTests.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.node.DiscoveryNodes;\n+import org.elasticsearch.cluster.routing.IndexRoutingTable;\n+import org.elasticsearch.cluster.routing.IndexShardRoutingTable;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.RoutingTable;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.TestShardRouting;\n+import org.elasticsearch.cluster.service.ClusterApplier;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.FilterRepository;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.test.ClusterServiceUtils;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.threadpool.TestThreadPool;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.threadpool.ThreadPoolStats;\n+\n+import java.util.Collections;\n+import java.util.Locale;\n+import java.util.Set;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Function;\n+\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_CREATION_DATE;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_REPLICAS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_SHARDS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_VERSION_CREATED;\n+import static org.elasticsearch.snapshots.InternalSnapshotsInfoService.INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING;\n+import static org.hamcrest.Matchers.allOf;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.lessThan;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Matchers.anyString;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+public class InternalSnapshotsInfoServiceTests extends ESTestCase {\n+\n+    private TestThreadPool threadPool;\n+    private ClusterService clusterService;\n+    private RepositoriesService repositoriesService;\n+    private RerouteService rerouteService;\n+\n+    @Override\n+    public void setUp() throws Exception {\n+        super.setUp();\n+        threadPool = new TestThreadPool(getTestName());\n+        clusterService = ClusterServiceUtils.createClusterService(threadPool);\n+        repositoriesService = mock(RepositoriesService.class);\n+        rerouteService = mock(RerouteService.class);\n+        doAnswer(invocation -> {\n+            @SuppressWarnings(\"unchecked\")\n+            final ActionListener<ClusterState> listener = (ActionListener<ClusterState>) invocation.getArguments()[2];\n+            listener.onResponse(clusterService.state());\n+            return null;\n+        }).when(rerouteService).reroute(anyString(), any(Priority.class), any());\n+    }\n+\n+    @Override\n+    public void tearDown() throws Exception {\n+        super.tearDown();\n+        final boolean terminated = terminate(threadPool);\n+        assert terminated;\n+        clusterService.close();\n+    }\n+\n+    public void testSnapshotShardSizes() throws Exception {\n+        final int maxConcurrentFetches = randomIntBetween(1, 10);\n+        final InternalSnapshotsInfoService snapshotsInfoService =\n+            new InternalSnapshotsInfoService(Settings.builder()\n+                .put(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.getKey(), maxConcurrentFetches)\n+                .build(), clusterService, () -> repositoriesService, () -> rerouteService);\n+\n+        final int numberOfShards = randomIntBetween(1, 50);\n+        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final long[] expectedShardSizes = new long[numberOfShards];\n+        for (int i = 0; i < expectedShardSizes.length; i++) {\n+            expectedShardSizes[i] = randomNonNegativeLong();\n+        }\n+\n+        final CountDownLatch latch = new CountDownLatch(1);\n+        when(repositoriesService.repository(\"_repo\"))\n+            .thenReturn(new FilterRepository(mock(Repository.class)) {\n+                @Override\n+                public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId shardId) {\n+                    try {\n+                        assertThat(indexId.getName(), equalTo(indexName));\n+                        assertThat(shardId.id(), allOf(greaterThanOrEqualTo(0), lessThan(numberOfShards)));\n+                        latch.await();\n+                        return IndexShardSnapshotStatus.newDone(0L, 0L, 0, 0, 0L, expectedShardSizes[shardId.id()], null);\n+                    } catch (InterruptedException e) {\n+                        throw new AssertionError(e);\n+                    }\n+                }\n+            });\n+\n+        applyClusterState(\"add-unassigned-shards\", clusterState -> addUnassignedShards(clusterState, indexName, numberOfShards));\n+        waitForMaxActiveGenericThreads(Math.min(numberOfShards, maxConcurrentFetches));\n+\n+        assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(numberOfShards));\n+        assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(0));\n+\n+        latch.countDown();\n+        waitForMaxActiveGenericThreads(0);\n+\n+        assertBusy(() -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 154}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA2NTc4Mg==", "bodyText": "I think we risk these two assertions being OK if they run before any of the threads start adding anything? If that happens on most runs, the test does not verify anything.\nI wonder if it was good enough to just do this after the join below? Or keep it here but add it below the join too.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500065782", "createdAt": "2020-10-06T07:37:09Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/snapshots/InternalSnapshotsInfoServiceTests.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.node.DiscoveryNodes;\n+import org.elasticsearch.cluster.routing.IndexRoutingTable;\n+import org.elasticsearch.cluster.routing.IndexShardRoutingTable;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.RoutingTable;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.TestShardRouting;\n+import org.elasticsearch.cluster.service.ClusterApplier;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.FilterRepository;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.test.ClusterServiceUtils;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.threadpool.TestThreadPool;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.threadpool.ThreadPoolStats;\n+\n+import java.util.Collections;\n+import java.util.Locale;\n+import java.util.Set;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Function;\n+\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_CREATION_DATE;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_REPLICAS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_SHARDS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_VERSION_CREATED;\n+import static org.elasticsearch.snapshots.InternalSnapshotsInfoService.INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING;\n+import static org.hamcrest.Matchers.allOf;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.lessThan;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Matchers.anyString;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+public class InternalSnapshotsInfoServiceTests extends ESTestCase {\n+\n+    private TestThreadPool threadPool;\n+    private ClusterService clusterService;\n+    private RepositoriesService repositoriesService;\n+    private RerouteService rerouteService;\n+\n+    @Override\n+    public void setUp() throws Exception {\n+        super.setUp();\n+        threadPool = new TestThreadPool(getTestName());\n+        clusterService = ClusterServiceUtils.createClusterService(threadPool);\n+        repositoriesService = mock(RepositoriesService.class);\n+        rerouteService = mock(RerouteService.class);\n+        doAnswer(invocation -> {\n+            @SuppressWarnings(\"unchecked\")\n+            final ActionListener<ClusterState> listener = (ActionListener<ClusterState>) invocation.getArguments()[2];\n+            listener.onResponse(clusterService.state());\n+            return null;\n+        }).when(rerouteService).reroute(anyString(), any(Priority.class), any());\n+    }\n+\n+    @Override\n+    public void tearDown() throws Exception {\n+        super.tearDown();\n+        final boolean terminated = terminate(threadPool);\n+        assert terminated;\n+        clusterService.close();\n+    }\n+\n+    public void testSnapshotShardSizes() throws Exception {\n+        final int maxConcurrentFetches = randomIntBetween(1, 10);\n+        final InternalSnapshotsInfoService snapshotsInfoService =\n+            new InternalSnapshotsInfoService(Settings.builder()\n+                .put(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.getKey(), maxConcurrentFetches)\n+                .build(), clusterService, () -> repositoriesService, () -> rerouteService);\n+\n+        final int numberOfShards = randomIntBetween(1, 50);\n+        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final long[] expectedShardSizes = new long[numberOfShards];\n+        for (int i = 0; i < expectedShardSizes.length; i++) {\n+            expectedShardSizes[i] = randomNonNegativeLong();\n+        }\n+\n+        final CountDownLatch latch = new CountDownLatch(1);\n+        when(repositoriesService.repository(\"_repo\"))\n+            .thenReturn(new FilterRepository(mock(Repository.class)) {\n+                @Override\n+                public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId shardId) {\n+                    try {\n+                        assertThat(indexId.getName(), equalTo(indexName));\n+                        assertThat(shardId.id(), allOf(greaterThanOrEqualTo(0), lessThan(numberOfShards)));\n+                        latch.await();\n+                        return IndexShardSnapshotStatus.newDone(0L, 0L, 0, 0, 0L, expectedShardSizes[shardId.id()], null);\n+                    } catch (InterruptedException e) {\n+                        throw new AssertionError(e);\n+                    }\n+                }\n+            });\n+\n+        applyClusterState(\"add-unassigned-shards\", clusterState -> addUnassignedShards(clusterState, indexName, numberOfShards));\n+        waitForMaxActiveGenericThreads(Math.min(numberOfShards, maxConcurrentFetches));\n+\n+        assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(numberOfShards));\n+        assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(0));\n+\n+        latch.countDown();\n+        waitForMaxActiveGenericThreads(0);\n+\n+        assertBusy(() -> {\n+            assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(numberOfShards));\n+            assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(0));\n+        });\n+        verify(rerouteService, times(numberOfShards)).reroute(anyString(), any(Priority.class), any());\n+\n+        for (int i = 0; i < numberOfShards; i++) {\n+            final ShardRouting shardRouting = clusterService.state().routingTable().index(indexName).shard(i).primaryShard();\n+            assertThat(snapshotsInfoService.snapshotShardSizes().getShardSize(shardRouting), equalTo(expectedShardSizes[i]));\n+        }\n+    }\n+\n+    public void testErroneousSnapshotShardSizes() throws Exception {\n+        final InternalSnapshotsInfoService snapshotsInfoService =\n+            new InternalSnapshotsInfoService(Settings.builder()\n+                .put(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.getKey(), randomIntBetween(1, 10))\n+                .build(), clusterService, () -> repositoriesService, () -> rerouteService);\n+\n+        final Set<InternalSnapshotsInfoService.SnapshotShard> succeed = Sets.newConcurrentHashSet();\n+        final Set<InternalSnapshotsInfoService.SnapshotShard> failed = Sets.newConcurrentHashSet();\n+        when(repositoriesService.repository(\"_repo\"))\n+            .thenReturn(new FilterRepository(mock(Repository.class)) {\n+                @Override\n+                public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId shardId) {\n+                    final InternalSnapshotsInfoService.SnapshotShard snapshotShard =\n+                        new InternalSnapshotsInfoService.SnapshotShard(new Snapshot(\"_repo\", snapshotId), indexId, shardId);\n+                    if (randomBoolean()) {\n+                        failed.add(snapshotShard);\n+                        throw new SnapshotException(snapshotShard.snapshot(), \"simulated\");\n+                    } else {\n+                        succeed.add(snapshotShard);\n+                        return IndexShardSnapshotStatus.newDone(0L, 0L, 0, 0, 0L, randomNonNegativeLong(), null);\n+                    }\n+                }\n+            });\n+\n+        final int maxShardsToCreate = scaledRandomIntBetween(10, 500);\n+        final Thread addSnapshotRestoreIndicesThread = new Thread(() -> {\n+            int remainingShards = maxShardsToCreate;\n+            while (remainingShards > 0) {\n+                final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+                final int numberOfShards = randomIntBetween(1, maxShardsToCreate);\n+                try {\n+                    applyClusterState(\"add-more-unassigned-shards-for-\" + indexName,\n+                        clusterState -> addUnassignedShards(clusterState, indexName, numberOfShards));\n+                } catch (Exception e) {\n+                    throw new AssertionError(e);\n+                } finally {\n+                    remainingShards -= numberOfShards;\n+                }\n+            }\n+        });\n+        addSnapshotRestoreIndicesThread.start();\n+\n+        assertBusy(() -> {\n+            assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(succeed.size()));\n+            assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(0));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 210}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA3MDAwNg==", "bodyText": "I suppose this is somewhat verified by the reroute count check below, but I would like to add a counter for how many times getShardSnapshotStatus was called too and verify that it is correct.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500070006", "createdAt": "2020-10-06T07:44:29Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/snapshots/InternalSnapshotsInfoServiceTests.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.node.DiscoveryNodes;\n+import org.elasticsearch.cluster.routing.IndexRoutingTable;\n+import org.elasticsearch.cluster.routing.IndexShardRoutingTable;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.RoutingTable;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.TestShardRouting;\n+import org.elasticsearch.cluster.service.ClusterApplier;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.FilterRepository;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.test.ClusterServiceUtils;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.threadpool.TestThreadPool;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.threadpool.ThreadPoolStats;\n+\n+import java.util.Collections;\n+import java.util.Locale;\n+import java.util.Set;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Function;\n+\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_CREATION_DATE;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_REPLICAS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_SHARDS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_VERSION_CREATED;\n+import static org.elasticsearch.snapshots.InternalSnapshotsInfoService.INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING;\n+import static org.hamcrest.Matchers.allOf;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.lessThan;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Matchers.anyString;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+public class InternalSnapshotsInfoServiceTests extends ESTestCase {\n+\n+    private TestThreadPool threadPool;\n+    private ClusterService clusterService;\n+    private RepositoriesService repositoriesService;\n+    private RerouteService rerouteService;\n+\n+    @Override\n+    public void setUp() throws Exception {\n+        super.setUp();\n+        threadPool = new TestThreadPool(getTestName());\n+        clusterService = ClusterServiceUtils.createClusterService(threadPool);\n+        repositoriesService = mock(RepositoriesService.class);\n+        rerouteService = mock(RerouteService.class);\n+        doAnswer(invocation -> {\n+            @SuppressWarnings(\"unchecked\")\n+            final ActionListener<ClusterState> listener = (ActionListener<ClusterState>) invocation.getArguments()[2];\n+            listener.onResponse(clusterService.state());\n+            return null;\n+        }).when(rerouteService).reroute(anyString(), any(Priority.class), any());\n+    }\n+\n+    @Override\n+    public void tearDown() throws Exception {\n+        super.tearDown();\n+        final boolean terminated = terminate(threadPool);\n+        assert terminated;\n+        clusterService.close();\n+    }\n+\n+    public void testSnapshotShardSizes() throws Exception {\n+        final int maxConcurrentFetches = randomIntBetween(1, 10);\n+        final InternalSnapshotsInfoService snapshotsInfoService =\n+            new InternalSnapshotsInfoService(Settings.builder()\n+                .put(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.getKey(), maxConcurrentFetches)\n+                .build(), clusterService, () -> repositoriesService, () -> rerouteService);\n+\n+        final int numberOfShards = randomIntBetween(1, 50);\n+        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final long[] expectedShardSizes = new long[numberOfShards];\n+        for (int i = 0; i < expectedShardSizes.length; i++) {\n+            expectedShardSizes[i] = randomNonNegativeLong();\n+        }\n+\n+        final CountDownLatch latch = new CountDownLatch(1);\n+        when(repositoriesService.repository(\"_repo\"))\n+            .thenReturn(new FilterRepository(mock(Repository.class)) {\n+                @Override\n+                public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId shardId) {\n+                    try {\n+                        assertThat(indexId.getName(), equalTo(indexName));\n+                        assertThat(shardId.id(), allOf(greaterThanOrEqualTo(0), lessThan(numberOfShards)));\n+                        latch.await();\n+                        return IndexShardSnapshotStatus.newDone(0L, 0L, 0, 0, 0L, expectedShardSizes[shardId.id()], null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA3MjU1OA==", "bodyText": "Can we add more shards (or just one) here to verify that the deduplication works? We can verify that there is nothing on the queue and at the end that we get the right amount of repo calls.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500072558", "createdAt": "2020-10-06T07:48:59Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/snapshots/InternalSnapshotsInfoServiceTests.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.node.DiscoveryNodes;\n+import org.elasticsearch.cluster.routing.IndexRoutingTable;\n+import org.elasticsearch.cluster.routing.IndexShardRoutingTable;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.RoutingTable;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.TestShardRouting;\n+import org.elasticsearch.cluster.service.ClusterApplier;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.FilterRepository;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.test.ClusterServiceUtils;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.threadpool.TestThreadPool;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.threadpool.ThreadPoolStats;\n+\n+import java.util.Collections;\n+import java.util.Locale;\n+import java.util.Set;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Function;\n+\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_CREATION_DATE;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_REPLICAS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_SHARDS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_VERSION_CREATED;\n+import static org.elasticsearch.snapshots.InternalSnapshotsInfoService.INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING;\n+import static org.hamcrest.Matchers.allOf;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.lessThan;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Matchers.anyString;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+public class InternalSnapshotsInfoServiceTests extends ESTestCase {\n+\n+    private TestThreadPool threadPool;\n+    private ClusterService clusterService;\n+    private RepositoriesService repositoriesService;\n+    private RerouteService rerouteService;\n+\n+    @Override\n+    public void setUp() throws Exception {\n+        super.setUp();\n+        threadPool = new TestThreadPool(getTestName());\n+        clusterService = ClusterServiceUtils.createClusterService(threadPool);\n+        repositoriesService = mock(RepositoriesService.class);\n+        rerouteService = mock(RerouteService.class);\n+        doAnswer(invocation -> {\n+            @SuppressWarnings(\"unchecked\")\n+            final ActionListener<ClusterState> listener = (ActionListener<ClusterState>) invocation.getArguments()[2];\n+            listener.onResponse(clusterService.state());\n+            return null;\n+        }).when(rerouteService).reroute(anyString(), any(Priority.class), any());\n+    }\n+\n+    @Override\n+    public void tearDown() throws Exception {\n+        super.tearDown();\n+        final boolean terminated = terminate(threadPool);\n+        assert terminated;\n+        clusterService.close();\n+    }\n+\n+    public void testSnapshotShardSizes() throws Exception {\n+        final int maxConcurrentFetches = randomIntBetween(1, 10);\n+        final InternalSnapshotsInfoService snapshotsInfoService =\n+            new InternalSnapshotsInfoService(Settings.builder()\n+                .put(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.getKey(), maxConcurrentFetches)\n+                .build(), clusterService, () -> repositoriesService, () -> rerouteService);\n+\n+        final int numberOfShards = randomIntBetween(1, 50);\n+        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final long[] expectedShardSizes = new long[numberOfShards];\n+        for (int i = 0; i < expectedShardSizes.length; i++) {\n+            expectedShardSizes[i] = randomNonNegativeLong();\n+        }\n+\n+        final CountDownLatch latch = new CountDownLatch(1);\n+        when(repositoriesService.repository(\"_repo\"))\n+            .thenReturn(new FilterRepository(mock(Repository.class)) {\n+                @Override\n+                public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId shardId) {\n+                    try {\n+                        assertThat(indexId.getName(), equalTo(indexName));\n+                        assertThat(shardId.id(), allOf(greaterThanOrEqualTo(0), lessThan(numberOfShards)));\n+                        latch.await();\n+                        return IndexShardSnapshotStatus.newDone(0L, 0L, 0, 0, 0L, expectedShardSizes[shardId.id()], null);\n+                    } catch (InterruptedException e) {\n+                        throw new AssertionError(e);\n+                    }\n+                }\n+            });\n+\n+        applyClusterState(\"add-unassigned-shards\", clusterState -> addUnassignedShards(clusterState, indexName, numberOfShards));\n+        waitForMaxActiveGenericThreads(Math.min(numberOfShards, maxConcurrentFetches));\n+\n+        assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(numberOfShards));\n+        assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(0));\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 150}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "881f6210a9e1dccba37497555a1a7fbb68f8b410", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/881f6210a9e1dccba37497555a1a7fbb68f8b410", "committedDate": "2020-10-06T11:02:28Z", "message": "revert extra line"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a777c126e10c17f3ae0f5c07ec607cde49ed3c23", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/a777c126e10c17f3ae0f5c07ec607cde49ed3c23", "committedDate": "2020-10-06T11:02:28Z", "message": "mutex for unknowns"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "528a8485fbf3501f0770c702c7693538e359115e", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/528a8485fbf3501f0770c702c7693538e359115e", "committedDate": "2020-10-06T11:02:28Z", "message": "non blocking queue"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4a716b02cce940402831cb20fdd6155d5badbd18", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/4a716b02cce940402831cb20fdd6155d5badbd18", "committedDate": "2020-10-06T11:02:28Z", "message": "clear queue"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a8e7475afc25dc2877012ae195f30418e5437f61", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/a8e7475afc25dc2877012ae195f30418e5437f61", "committedDate": "2020-10-06T11:02:29Z", "message": "activeFetches"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0aaf829e30b0c3a0c869843650f866357731d6d7", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/0aaf829e30b0c3a0c869843650f866357731d6d7", "committedDate": "2020-10-06T11:02:29Z", "message": "check unassigned"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "42ba44f71085aed68965e1f74a26ab30f2f10723", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/42ba44f71085aed68965e1f74a26ab30f2f10723", "committedDate": "2020-10-06T11:02:29Z", "message": "spaces"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "212c8e397dd9fac63587f6c39e12317c624c6667", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/212c8e397dd9fac63587f6c39e12317c624c6667", "committedDate": "2020-10-06T11:02:29Z", "message": "SNAPSHOT_INFO_SERVICE_WITH_NO_SHARD_SIZES"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3dd593d203c328882683e2febcd7dbd37cc0f62b", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/3dd593d203c328882683e2febcd7dbd37cc0f62b", "committedDate": "2020-10-06T11:02:29Z", "message": "allocationDeciders"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "39da08724cd8cecdb4338a6daccce374971a6e16", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/39da08724cd8cecdb4338a6daccce374971a6e16", "committedDate": "2020-10-06T11:02:30Z", "message": "remove wait for zero active threads"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3732dd28962b074c1c0ec9ac48e7534e5d4d3b08", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/3732dd28962b074c1c0ec9ac48e7534e5d4d3b08", "committedDate": "2020-10-06T11:02:30Z", "message": "move assertBusy()"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ac45f178bbd0b3907c6e2dc2d9feac1de90cfd61", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/ac45f178bbd0b3907c6e2dc2d9feac1de90cfd61", "committedDate": "2020-10-06T11:02:30Z", "message": "getShardSnapshotStatusCount"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "465c8fb893c6af46757c40c17354cd8f50bb12dd", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/465c8fb893c6af46757c40c17354cd8f50bb12dd", "committedDate": "2020-10-06T11:02:30Z", "message": "check deduplication"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "59ab20c3c3a450f4233753c131d62938bc602daa", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/59ab20c3c3a450f4233753c131d62938bc602daa", "committedDate": "2020-10-06T11:02:30Z", "message": "SnapshotResiliencyTests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAyODgwOTc1", "url": "https://github.com/elastic/elasticsearch/pull/61906#pullrequestreview-502880975", "createdAt": "2020-10-06T12:23:26Z", "commit": {"oid": "59ab20c3c3a450f4233753c131d62938bc602daa"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxMjoyMzoyNlrOHdDtJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxMjozNToxN1rOHdEKNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDIzMTQ2MQ==", "bodyText": "I think this needs to be done before spawning the task: we assert that this is \u22650 elsewhere but that assertion will fail if it's decremented by the completion of the runnable before it's incremented here.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500231461", "createdAt": "2020-10-06T12:23:26Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,342 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.LinkedList;\n+import java.util.Objects;\n+import java.util.Queue;\n+import java.util.Set;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private static final ActionListener<ClusterState> REROUTE_LISTENER = ActionListener.wrap(\n+        r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+        e -> logger.debug(\"reroute after snapshot shard size update failed\", e)\n+    );\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final Queue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private int activeFetches;\n+\n+    private final Object mutex;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = new LinkedHashSet<>();\n+        this.queue = new LinkedList<>();\n+        this.mutex = new Object();\n+        this.activeFetches = 0;\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = listOfSnapshotShards(event.state());\n+\n+            int unknownShards = 0;\n+            synchronized (mutex) {\n+                isMaster = true;\n+                for (SnapshotShard snapshotShard : onGoingSnapshotRecoveries) {\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+                // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+                cleanUpKnownSnapshotShardSizes(onGoingSnapshotRecoveries);\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                fetchNextSnapshotShard();\n+            }\n+        } else if (event.previousState().nodes().isLocalNodeElectedMaster()) {\n+            // TODO Maybe just clear out non-ongoing snapshot recoveries is the node is master eligible, so that we don't\n+            // have to repopulate the data over and over in an unstable master situation?\n+            synchronized (mutex) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+                final Iterator<SnapshotShard> iterator = queue.iterator();\n+                while (iterator.hasNext()) {\n+                    final SnapshotShard snapshotShard = iterator.next();\n+                    final boolean removed = unknownSnapshotShards.remove(snapshotShard);\n+                    assert removed : \"snapshot shard to remove does not exist \" + snapshotShard;\n+                    iterator.remove();\n+                }\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        synchronized (mutex) {\n+            if (activeFetches < maxConcurrentFetches) {\n+                final SnapshotShard snapshotShard = queue.poll();\n+                if (snapshotShard != null) {\n+                    threadPool.generic().execute(new FetchingSnapshotShardSizeRunnable(snapshotShard));\n+                    activeFetches += 1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "59ab20c3c3a450f4233753c131d62938bc602daa"}, "originalPosition": 172}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDIzNTk2Nw==", "bodyText": "Why not drain the queue using .poll() until it's empty?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500235967", "createdAt": "2020-10-06T12:30:32Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,342 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.LinkedList;\n+import java.util.Objects;\n+import java.util.Queue;\n+import java.util.Set;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private static final ActionListener<ClusterState> REROUTE_LISTENER = ActionListener.wrap(\n+        r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+        e -> logger.debug(\"reroute after snapshot shard size update failed\", e)\n+    );\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final Queue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private int activeFetches;\n+\n+    private final Object mutex;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = new LinkedHashSet<>();\n+        this.queue = new LinkedList<>();\n+        this.mutex = new Object();\n+        this.activeFetches = 0;\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = listOfSnapshotShards(event.state());\n+\n+            int unknownShards = 0;\n+            synchronized (mutex) {\n+                isMaster = true;\n+                for (SnapshotShard snapshotShard : onGoingSnapshotRecoveries) {\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+                // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+                cleanUpKnownSnapshotShardSizes(onGoingSnapshotRecoveries);\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                fetchNextSnapshotShard();\n+            }\n+        } else if (event.previousState().nodes().isLocalNodeElectedMaster()) {\n+            // TODO Maybe just clear out non-ongoing snapshot recoveries is the node is master eligible, so that we don't\n+            // have to repopulate the data over and over in an unstable master situation?\n+            synchronized (mutex) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+                final Iterator<SnapshotShard> iterator = queue.iterator();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "59ab20c3c3a450f4233753c131d62938bc602daa"}, "originalPosition": 155}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDIzODkwMQ==", "bodyText": "can we assert something about the state if neither of the previous if blocks matched (so this node isn't/wasn't just the master): isMaster == false, queue and unknownSnapshotShards and knownSnapshotShardSizes are all empty, ...", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500238901", "createdAt": "2020-10-06T12:35:17Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,342 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.LinkedList;\n+import java.util.Objects;\n+import java.util.Queue;\n+import java.util.Set;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private static final ActionListener<ClusterState> REROUTE_LISTENER = ActionListener.wrap(\n+        r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+        e -> logger.debug(\"reroute after snapshot shard size update failed\", e)\n+    );\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final Queue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private int activeFetches;\n+\n+    private final Object mutex;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = new LinkedHashSet<>();\n+        this.queue = new LinkedList<>();\n+        this.mutex = new Object();\n+        this.activeFetches = 0;\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = listOfSnapshotShards(event.state());\n+\n+            int unknownShards = 0;\n+            synchronized (mutex) {\n+                isMaster = true;\n+                for (SnapshotShard snapshotShard : onGoingSnapshotRecoveries) {\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+                // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+                cleanUpKnownSnapshotShardSizes(onGoingSnapshotRecoveries);\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                fetchNextSnapshotShard();\n+            }\n+        } else if (event.previousState().nodes().isLocalNodeElectedMaster()) {\n+            // TODO Maybe just clear out non-ongoing snapshot recoveries is the node is master eligible, so that we don't\n+            // have to repopulate the data over and over in an unstable master situation?\n+            synchronized (mutex) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+                final Iterator<SnapshotShard> iterator = queue.iterator();\n+                while (iterator.hasNext()) {\n+                    final SnapshotShard snapshotShard = iterator.next();\n+                    final boolean removed = unknownSnapshotShards.remove(snapshotShard);\n+                    assert removed : \"snapshot shard to remove does not exist \" + snapshotShard;\n+                    iterator.remove();\n+                }\n+            }\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "59ab20c3c3a450f4233753c131d62938bc602daa"}, "originalPosition": 163}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0d9917489f22a731cd69ba33311dca9e9134aee1", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/0d9917489f22a731cd69ba33311dca9e9134aee1", "committedDate": "2020-10-06T13:53:21Z", "message": "handle snapshot shard size failures"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAzMDU5Mjcy", "url": "https://github.com/elastic/elasticsearch/pull/61906#pullrequestreview-503059272", "createdAt": "2020-10-06T14:57:35Z", "commit": {"oid": "0d9917489f22a731cd69ba33311dca9e9134aee1"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAzMDY0MTUx", "url": "https://github.com/elastic/elasticsearch/pull/61906#pullrequestreview-503064151", "createdAt": "2020-10-06T15:02:00Z", "commit": {"oid": "0d9917489f22a731cd69ba33311dca9e9134aee1"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAzMDgwNTk5", "url": "https://github.com/elastic/elasticsearch/pull/61906#pullrequestreview-503080599", "createdAt": "2020-10-06T15:17:43Z", "commit": {"oid": "0d9917489f22a731cd69ba33311dca9e9134aee1"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxNToxNzo0M1rOHdMx7Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxNToxNzo0M1rOHdMx7Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDM4MDE0MQ==", "bodyText": "I think we should also remove this in cleanUpKnownSnapshotShardSizes to avoid this eventually potentially leading to a memory issue. We can do this in a follow-up too, no need to hold merging this PR.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500380141", "createdAt": "2020-10-06T15:17:43Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -132,6 +142,7 @@ public void clusterChanged(ClusterChangedEvent event) {\n                     if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n                         // check if already fetching snapshot info in progress\n                         if (unknownSnapshotShards.add(snapshotShard)) {\n+                            failedSnapshotShards.remove(snapshotShard); // retry the failed shard", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d9917489f22a731cd69ba33311dca9e9134aee1"}, "originalPosition": 46}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4813, "cost": 1, "resetAt": "2021-10-28T19:08:13Z"}}}