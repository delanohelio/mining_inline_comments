{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI0ODg3NzEx", "number": 65328, "title": "Introduce an additional hasher (PBKDF2_STRETCH)", "bodyText": "Security providers, when set in FIPS 140 mode, might enforce\na limit on the minimum entropy (112 bits) for the passwords\nused as input for a PBKDF2 function according to the\nrequirements dictated by FIPS 140-2 for encryption keys.\nWhile this might be applicable to the use of PBKDF2 for key\nderivation, it enforces the same limitation for password hashing.\nThis commit introduces a new password hasher, named\n\"pbkdf2_stretch\", that will stretch the input (by an extra round of\na sha512 algorithm hashing) to a certain length before passing\nit to the key derivation function (for hashing and verification),\nin order to be compatible with such security providers.", "createdAt": "2020-11-20T18:43:52Z", "url": "https://github.com/elastic/elasticsearch/pull/65328", "merged": true, "mergeCommit": {"oid": "c758dc7f4a6b2998db327baaaa753f0e389660cd"}, "closed": true, "closedAt": "2020-11-26T12:29:19Z", "author": {"login": "BigPandaToo"}, "timelineItems": {"totalCount": 22, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdebtA3AH2gAyNTI0ODg3NzExOjFhOGUxNDAyNWMxYzY2MTY1MDFkY2M4YWU1OGI1YjZjZWU1MDE1YWE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdgRHXzgH2gAyNTI0ODg3NzExOjM0ZWIzYzA3Nzc4OTg0ODVjMDVlZDk3NzQ4ZWY1ODhmMzg5NDVlNDE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "1a8e14025c1c6616501dcc8ae58b5b6cee5015aa", "author": {"user": {"login": "BigPandaToo", "name": "Lyudmila Fokina"}}, "url": "https://github.com/elastic/elasticsearch/commit/1a8e14025c1c6616501dcc8ae58b5b6cee5015aa", "committedDate": "2020-11-20T18:31:34Z", "message": "Introduce an additional hasher that is PBKDF2 but pads the input to > 14 chars before hashing to comply with FIPS Approve Only mode"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM1OTU3NjAx", "url": "https://github.com/elastic/elasticsearch/pull/65328#pullrequestreview-535957601", "createdAt": "2020-11-21T10:46:27Z", "commit": {"oid": "1a8e14025c1c6616501dcc8ae58b5b6cee5015aa"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMVQxMDo0NjoyOFrOH3tnQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMVQxMTo1Nzo0MFrOH3uCGw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODE4MTA1OQ==", "bodyText": "Since we're modifying the method's signature, I think it's preferrable to always pass the prefix from the caller of this method, instead of allowing null and doing the comparison here.", "url": "https://github.com/elastic/elasticsearch/pull/65328#discussion_r528181059", "createdAt": "2020-11-21T10:46:28Z", "author": {"login": "jkakavas"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/security/authc/support/Hasher.java", "diffHunk": "@@ -497,12 +608,13 @@ public static boolean verifyHash(SecureString data, char[] hash) {\n         return hasher.verify(data, hash);\n     }\n \n-    private static char[] getPbkdf2Hash(SecureString data, int cost) {\n+    private static char[] getPbkdf2Hash(SecureString data, int cost, @Nullable String prefix) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a8e14025c1c6616501dcc8ae58b5b6cee5015aa"}, "originalPosition": 253}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODE4MTQ5OQ==", "bodyText": "Suggestion for the ENUMs here:\nreturn getPbkdf2Hash(data, PBKDF2_DEFAULT_COST, PBKDF2_APPROVED_ONLY_PREFIX );\n\nIf you think this is a good idea,  we don't need the getPbkdf2ApprovedOnlyHash() and getPbkdf2ApprovedOnlyHash() ones any more.", "url": "https://github.com/elastic/elasticsearch/pull/65328#discussion_r528181499", "createdAt": "2020-11-21T10:51:25Z", "author": {"login": "jkakavas"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/security/authc/support/Hasher.java", "diffHunk": "@@ -185,90 +186,181 @@ public boolean verify(SecureString text, char[] hash) {\n     PBKDF2() {\n         @Override\n         public char[] hash(SecureString data) {\n-            return getPbkdf2Hash(data, PBKDF2_DEFAULT_COST);\n+            return getPbkdf2Hash(data, PBKDF2_DEFAULT_COST, null);\n         }\n \n         @Override\n         public boolean verify(SecureString data, char[] hash) {\n-            return verifyPbkdf2Hash(data, hash);\n+            return verifyPbkdf2Hash(data, hash, null);\n         }\n \n     },\n \n     PBKDF2_1000() {\n         @Override\n         public char[] hash(SecureString data) {\n-            return getPbkdf2Hash(data, 1000);\n+            return getPbkdf2Hash(data, 1000, null);\n         }\n \n         @Override\n         public boolean verify(SecureString data, char[] hash) {\n-            return verifyPbkdf2Hash(data, hash);\n+            return verifyPbkdf2Hash(data, hash, null);\n         }\n \n     },\n \n     PBKDF2_10000() {\n         @Override\n         public char[] hash(SecureString data) {\n-            return getPbkdf2Hash(data, 10000);\n+            return getPbkdf2Hash(data, 10000, null);\n         }\n \n         @Override\n         public boolean verify(SecureString data, char[] hash) {\n-            return verifyPbkdf2Hash(data, hash);\n+            return verifyPbkdf2Hash(data, hash, null);\n         }\n \n     },\n \n     PBKDF2_50000() {\n         @Override\n         public char[] hash(SecureString data) {\n-            return getPbkdf2Hash(data, 50000);\n+            return getPbkdf2Hash(data, 50000, null);\n         }\n \n         @Override\n         public boolean verify(SecureString data, char[] hash) {\n-            return verifyPbkdf2Hash(data, hash);\n+            return verifyPbkdf2Hash(data, hash, null);\n         }\n \n     },\n \n     PBKDF2_100000() {\n         @Override\n         public char[] hash(SecureString data) {\n-            return getPbkdf2Hash(data, 100000);\n+            return getPbkdf2Hash(data, 100000, null);\n         }\n \n         @Override\n         public boolean verify(SecureString data, char[] hash) {\n-            return verifyPbkdf2Hash(data, hash);\n+            return verifyPbkdf2Hash(data, hash, null);\n         }\n \n     },\n \n     PBKDF2_500000() {\n         @Override\n         public char[] hash(SecureString data) {\n-            return getPbkdf2Hash(data, 500000);\n+            return getPbkdf2Hash(data, 500000, null);\n         }\n \n         @Override\n         public boolean verify(SecureString data, char[] hash) {\n-            return verifyPbkdf2Hash(data, hash);\n+            return verifyPbkdf2Hash(data, hash, null);\n         }\n \n     },\n \n     PBKDF2_1000000() {\n         @Override\n         public char[] hash(SecureString data) {\n-            return getPbkdf2Hash(data, 1000000);\n+            return getPbkdf2Hash(data, 1000000, null);\n         }\n \n         @Override\n         public boolean verify(SecureString data, char[] hash) {\n-            return verifyPbkdf2Hash(data, hash);\n+            return verifyPbkdf2Hash(data, hash, null);\n+        }\n+\n+    },\n+\n+    PBKDF2_APPROVED_ONLY() {\n+        @Override\n+        public char[] hash(SecureString data) {\n+            return getPbkdf2ApprovedOnlyHash(data, PBKDF2_DEFAULT_COST);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a8e14025c1c6616501dcc8ae58b5b6cee5015aa"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODE4MTY4Ng==", "bodyText": "I'll echo Fabio's comment here. We need a name that's indicative of what this hasher does and not something that alludes to where it can be used, as I think this will be clearer for the users. We have been referring to this as pbkdf2_stretch in our initial discussions and I think it's a good name, but I'm open to suggested alternatives.", "url": "https://github.com/elastic/elasticsearch/pull/65328#discussion_r528181686", "createdAt": "2020-11-21T10:53:43Z", "author": {"login": "jkakavas"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/security/authc/support/Hasher.java", "diffHunk": "@@ -185,90 +186,181 @@ public boolean verify(SecureString text, char[] hash) {\n     PBKDF2() {\n         @Override\n         public char[] hash(SecureString data) {\n-            return getPbkdf2Hash(data, PBKDF2_DEFAULT_COST);\n+            return getPbkdf2Hash(data, PBKDF2_DEFAULT_COST, null);\n         }\n \n         @Override\n         public boolean verify(SecureString data, char[] hash) {\n-            return verifyPbkdf2Hash(data, hash);\n+            return verifyPbkdf2Hash(data, hash, null);\n         }\n \n     },\n \n     PBKDF2_1000() {\n         @Override\n         public char[] hash(SecureString data) {\n-            return getPbkdf2Hash(data, 1000);\n+            return getPbkdf2Hash(data, 1000, null);\n         }\n \n         @Override\n         public boolean verify(SecureString data, char[] hash) {\n-            return verifyPbkdf2Hash(data, hash);\n+            return verifyPbkdf2Hash(data, hash, null);\n         }\n \n     },\n \n     PBKDF2_10000() {\n         @Override\n         public char[] hash(SecureString data) {\n-            return getPbkdf2Hash(data, 10000);\n+            return getPbkdf2Hash(data, 10000, null);\n         }\n \n         @Override\n         public boolean verify(SecureString data, char[] hash) {\n-            return verifyPbkdf2Hash(data, hash);\n+            return verifyPbkdf2Hash(data, hash, null);\n         }\n \n     },\n \n     PBKDF2_50000() {\n         @Override\n         public char[] hash(SecureString data) {\n-            return getPbkdf2Hash(data, 50000);\n+            return getPbkdf2Hash(data, 50000, null);\n         }\n \n         @Override\n         public boolean verify(SecureString data, char[] hash) {\n-            return verifyPbkdf2Hash(data, hash);\n+            return verifyPbkdf2Hash(data, hash, null);\n         }\n \n     },\n \n     PBKDF2_100000() {\n         @Override\n         public char[] hash(SecureString data) {\n-            return getPbkdf2Hash(data, 100000);\n+            return getPbkdf2Hash(data, 100000, null);\n         }\n \n         @Override\n         public boolean verify(SecureString data, char[] hash) {\n-            return verifyPbkdf2Hash(data, hash);\n+            return verifyPbkdf2Hash(data, hash, null);\n         }\n \n     },\n \n     PBKDF2_500000() {\n         @Override\n         public char[] hash(SecureString data) {\n-            return getPbkdf2Hash(data, 500000);\n+            return getPbkdf2Hash(data, 500000, null);\n         }\n \n         @Override\n         public boolean verify(SecureString data, char[] hash) {\n-            return verifyPbkdf2Hash(data, hash);\n+            return verifyPbkdf2Hash(data, hash, null);\n         }\n \n     },\n \n     PBKDF2_1000000() {\n         @Override\n         public char[] hash(SecureString data) {\n-            return getPbkdf2Hash(data, 1000000);\n+            return getPbkdf2Hash(data, 1000000, null);\n         }\n \n         @Override\n         public boolean verify(SecureString data, char[] hash) {\n-            return verifyPbkdf2Hash(data, hash);\n+            return verifyPbkdf2Hash(data, hash, null);\n+        }\n+\n+    },\n+\n+    PBKDF2_APPROVED_ONLY() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a8e14025c1c6616501dcc8ae58b5b6cee5015aa"}, "originalPosition": 114}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODE4NTU0Mg==", "bodyText": "Suggestion: PBKDF2_STRETCH_MIN_CHARS", "url": "https://github.com/elastic/elasticsearch/pull/65328#discussion_r528185542", "createdAt": "2020-11-21T11:33:49Z", "author": {"login": "jkakavas"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/security/authc/support/Hasher.java", "diffHunk": "@@ -388,10 +480,12 @@ public boolean verify(SecureString text, char[] hash) {\n     private static final String MD5_PREFIX = \"{MD5}\";\n     private static final String SSHA256_PREFIX = \"{SSHA256}\";\n     private static final String PBKDF2_PREFIX = \"{PBKDF2}\";\n+    private static final String PBKDF2_APPROVED_ONLY_PREFIX = \"{PBKDF2_APPROVED_ONLY}\";\n     private static final int PBKDF2_DEFAULT_COST = 10000;\n     private static final int PBKDF2_KEY_LENGTH = 256;\n     private static final int BCRYPT_DEFAULT_COST = 10;\n     private static final SecureRandom SECURE_RANDOM = new SecureRandom();\n+    private static final int PBKDF2_APPROVED_ONLY_PWD_LIMIT = 14;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a8e14025c1c6616501dcc8ae58b5b6cee5015aa"}, "originalPosition": 213}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODE4NzEyMg==", "bodyText": "s/getPadedPassword/getPaddedPassword\nAlso can we add a test in HasherTests to ensure that short inputs get padded to 14 while larger ones are unaffected?", "url": "https://github.com/elastic/elasticsearch/pull/65328#discussion_r528187122", "createdAt": "2020-11-21T11:49:32Z", "author": {"login": "jkakavas"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/security/authc/support/Hasher.java", "diffHunk": "@@ -597,4 +718,16 @@ private static boolean verifyBcryptHash(SecureString text, char[] hash) {\n         SECURE_RANDOM.nextBytes(salt);\n         return salt;\n     }\n+\n+    private static SecureString getPadedPassword(SecureString data) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a8e14025c1c6616501dcc8ae58b5b6cee5015aa"}, "originalPosition": 310}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODE4NzkzMQ==", "bodyText": "This is slightly more nuanced. The \"> 14 chars\" that we used while discussing included some amount of hand waiving.\nThe security providers, according to FIPS 140 limitations will actually enforce that any password used must encode to at least 14 bytes (112 bits), not that it has a lenght of 14 characters. For instance, for UTF-8 strings , a character encodes to 2 bytes. i.e. \"\u03ba\u03b1\u03bb\u03b7\u03bc\u03ad\u03c1\u03b1\" is a perfectly fine password to be used for PBKDF2 under FIPS 140 because it encodes to 16 bytes even though the CharArray you'd get with toCharArray() has a length of 8.\nThat said, I see no benefit of trying to handle this here. Worst case scenario is that we unecessarily pad input that would be otherwise fine. Since this should be transparent to any consumers of this hasher, I see no issues with that but I'm bringing this up in case it raises any bells/warnings. At least, we should add some javadoc here to mark that this has been considered and that we're padding based on char length as a good enough measure.", "url": "https://github.com/elastic/elasticsearch/pull/65328#discussion_r528187931", "createdAt": "2020-11-21T11:57:40Z", "author": {"login": "jkakavas"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/security/authc/support/Hasher.java", "diffHunk": "@@ -597,4 +718,16 @@ private static boolean verifyBcryptHash(SecureString text, char[] hash) {\n         SECURE_RANDOM.nextBytes(salt);\n         return salt;\n     }\n+\n+    private static SecureString getPadedPassword(SecureString data) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a8e14025c1c6616501dcc8ae58b5b6cee5015aa"}, "originalPosition": 310}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM1OTYzOTYy", "url": "https://github.com/elastic/elasticsearch/pull/65328#pullrequestreview-535963962", "createdAt": "2020-11-21T12:45:31Z", "commit": {"oid": "1a8e14025c1c6616501dcc8ae58b5b6cee5015aa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMVQxMjo0NTozMVrOH3uT9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMVQxMjo0NTozMVrOH3uT9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODE5MjUwMg==", "bodyText": "Stretching done this way effectively means that there are at least two passwords that can be verified against a single entry. For example, if the user password is 123456, it will be stretched to 12345612345612. So you can use either of them to login. It is worse when the actual legit password is the longer version, i.e. 12345612345612, but we allow the much shorter version, 123456, to verified for it. In addtion, 123456123456 is also equivalent.\nThe chance of this happening may be low. But this is essentially hash collision and given how sensitive this part of data is, I suggest we should employ a more robust padding mechanism, something similar to PKCS#7 padding, essentially add padding for all passwords regardless of its length.", "url": "https://github.com/elastic/elasticsearch/pull/65328#discussion_r528192502", "createdAt": "2020-11-21T12:45:31Z", "author": {"login": "ywangd"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/security/authc/support/Hasher.java", "diffHunk": "@@ -597,4 +718,16 @@ private static boolean verifyBcryptHash(SecureString text, char[] hash) {\n         SECURE_RANDOM.nextBytes(salt);\n         return salt;\n     }\n+\n+    private static SecureString getPadedPassword(SecureString data) {\n+        if (data.length() < PBKDF2_APPROVED_ONLY_PWD_LIMIT) {\n+            final int size = data.length();\n+            final char[] paddedPassword = new char[PBKDF2_APPROVED_ONLY_PWD_LIMIT];\n+            for (int i = 0; i < PBKDF2_APPROVED_ONLY_PWD_LIMIT; i++) {\n+                paddedPassword[i] = data.getChars()[i%size];\n+            }\n+            data = new SecureString(paddedPassword);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a8e14025c1c6616501dcc8ae58b5b6cee5015aa"}, "originalPosition": 317}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "79e163c0e56c49b35256f029ab68a599aa9a0065", "author": {"user": {"login": "BigPandaToo", "name": "Lyudmila Fokina"}}, "url": "https://github.com/elastic/elasticsearch/commit/79e163c0e56c49b35256f029ab68a599aa9a0065", "committedDate": "2020-11-23T12:07:15Z", "message": "Introduce an additional hasher that is PBKDF2 but pads the input to > 14 chars before hashing to comply with FIPS Approve Only mode"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f2ed61f751a06ea1098e9bbd9656925075672492", "author": {"user": {"login": "elasticmachine", "name": "Elastic Machine"}}, "url": "https://github.com/elastic/elasticsearch/commit/f2ed61f751a06ea1098e9bbd9656925075672492", "committedDate": "2020-11-23T13:07:13Z", "message": "Merge branch 'master' into FIBS_AO_PSW"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM2OTMzODYz", "url": "https://github.com/elastic/elasticsearch/pull/65328#pullrequestreview-536933863", "createdAt": "2020-11-23T23:49:34Z", "commit": {"oid": "f2ed61f751a06ea1098e9bbd9656925075672492"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QyMzo0OTozNVrOH4j6EQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QyMzo0OTozNVrOH4j6EQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTA3MDYwOQ==", "bodyText": "Nit: I understand this follows an existing pattern for pbkdf2. But strictly speaking I think it is incorrect. We have an explicit entry of PBKDF2_STRETCH_10000 and it should be returned here. This currently works because default cost is 10K. But the PBKDF2_DEFAULT_COST parameter has no inherent connection to the string of \"pbkdf2_stretch_10000\". That is, if someone updates PBKDF2_DEFAULT_COST, there is no guarantee or enforcement that this part of code would be updated accordingly as well.", "url": "https://github.com/elastic/elasticsearch/pull/65328#discussion_r529070609", "createdAt": "2020-11-23T23:49:35Z", "author": {"login": "ywangd"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/security/authc/support/Hasher.java", "diffHunk": "@@ -442,6 +552,20 @@ public static Hasher resolve(String name) {\n                 return PBKDF2_500000;\n             case \"pbkdf2_1000000\":\n                 return PBKDF2_1000000;\n+            case \"pbkdf2_stretch\":\n+                return PBKDF2_STRETCH;\n+            case \"pbkdf2_stretch_1000\":\n+                return PBKDF2_STRETCH_1000;\n+            case \"pbkdf2_stretch_10000\":\n+                return PBKDF2_STRETCH;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f2ed61f751a06ea1098e9bbd9656925075672492"}, "originalPosition": 238}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM3NTU2MDg5", "url": "https://github.com/elastic/elasticsearch/pull/65328#pullrequestreview-537556089", "createdAt": "2020-11-24T14:38:42Z", "commit": {"oid": "f2ed61f751a06ea1098e9bbd9656925075672492"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxNDozODo0MlrOH5D2UA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxNDo0MDo0MlrOH5D8NA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTU5MzkzNg==", "bodyText": "I don't think we need this introduced here as part of the ENUM. There is no use for it and it might confuse someone to actually use it for password hashing while they should not. I suggest a private method for the hashing ( we don't need the verification part ) and calling that from the hash() and verify() of the newly introduced hasher.  We should probably remove the SHA256 from here and I shouldn't have added it in the first place. ( Can do the latter in an unrelated PR )\nUnless we feel there is need/value in exposing unsalted SHA256 / SHA512 for caching hash algorithms but I don't think we should.", "url": "https://github.com/elastic/elasticsearch/pull/65328#discussion_r529593936", "createdAt": "2020-11-24T14:38:42Z", "author": {"login": "jkakavas"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/security/authc/support/Hasher.java", "diffHunk": "@@ -370,6 +461,24 @@ public boolean verify(SecureString text, char[] hash) {\n             return CharArrays.constantTimeEquals(Base64.getUrlEncoder().withoutPadding().encodeToString(md.digest()).toCharArray(), hash);\n         }\n     },\n+    /*\n+     * Unsalted SHA-512 , not suited for password storage.\n+     */\n+    SHA512() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f2ed61f751a06ea1098e9bbd9656925075672492"}, "originalPosition": 203}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTU5NTQ0NA==", "bodyText": "Agreed with Tim, but also +1 to change this line as Yang suggests.", "url": "https://github.com/elastic/elasticsearch/pull/65328#discussion_r529595444", "createdAt": "2020-11-24T14:40:42Z", "author": {"login": "jkakavas"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/security/authc/support/Hasher.java", "diffHunk": "@@ -442,6 +552,20 @@ public static Hasher resolve(String name) {\n                 return PBKDF2_500000;\n             case \"pbkdf2_1000000\":\n                 return PBKDF2_1000000;\n+            case \"pbkdf2_stretch\":\n+                return PBKDF2_STRETCH;\n+            case \"pbkdf2_stretch_1000\":\n+                return PBKDF2_STRETCH_1000;\n+            case \"pbkdf2_stretch_10000\":\n+                return PBKDF2_STRETCH;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTA3MDYwOQ=="}, "originalCommit": {"oid": "f2ed61f751a06ea1098e9bbd9656925075672492"}, "originalPosition": 238}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b9dd1c93cef7f6d64ad35e2e61362505c752956d", "author": {"user": {"login": "BigPandaToo", "name": "Lyudmila Fokina"}}, "url": "https://github.com/elastic/elasticsearch/commit/b9dd1c93cef7f6d64ad35e2e61362505c752956d", "committedDate": "2020-11-24T20:25:18Z", "message": "Addressing the PR feedback\nadding doc changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c58ba67ab0cca2fd8e66d040949cae7257b7ff0d", "author": {"user": {"login": "BigPandaToo", "name": "Lyudmila Fokina"}}, "url": "https://github.com/elastic/elasticsearch/commit/c58ba67ab0cca2fd8e66d040949cae7257b7ff0d", "committedDate": "2020-11-24T20:27:00Z", "message": "Merge branch 'FIBS_AO_PSW' of github.com:BigPandaToo/elasticsearch into FIBS_AO_PSW"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM3ODg0MDM5", "url": "https://github.com/elastic/elasticsearch/pull/65328#pullrequestreview-537884039", "createdAt": "2020-11-24T20:36:52Z", "commit": {"oid": "c58ba67ab0cca2fd8e66d040949cae7257b7ff0d"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQyMDozNjo1MlrOH5UPOA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQyMDozOTozNlrOH5UUfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTg2MjQ1Ng==", "bodyText": "I think we need to add some hint to the stretching here, otherwise folks would be confused as to why we added  all these new hashers that do the same with the existing ones.", "url": "https://github.com/elastic/elasticsearch/pull/65328#discussion_r529862456", "createdAt": "2020-11-24T20:36:52Z", "author": {"login": "jkakavas"}, "path": "docs/reference/settings/security-hash-settings.asciidoc", "diffHunk": "@@ -12,32 +12,46 @@ hashing algorithm by setting the <<static-cluster-setting,static>>\n [[cache-hash-algo]]\n .Cache hash algorithms\n |=======================\n-| Algorithm           | | | Description\n-| `ssha256`           | | | Uses a salted `sha-256` algorithm (default).\n-| `md5`               | | | Uses `MD5` algorithm.\n-| `sha1`              | | | Uses `SHA1` algorithm.\n-| `bcrypt`            | | | Uses `bcrypt` algorithm with salt generated in 1024 rounds.\n-| `bcrypt4`           | | | Uses `bcrypt` algorithm with salt generated in 16 rounds.\n-| `bcrypt5`           | | | Uses `bcrypt` algorithm with salt generated in 32 rounds.\n-| `bcrypt6`           | | | Uses `bcrypt` algorithm with salt generated in 64 rounds.\n-| `bcrypt7`           | | | Uses `bcrypt` algorithm with salt generated in 128 rounds.\n-| `bcrypt8`           | | | Uses `bcrypt` algorithm with salt generated in 256 rounds.\n-| `bcrypt9`           | | | Uses `bcrypt` algorithm with salt generated in 512 rounds.\n-| `pbkdf2`            | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n+| Algorithm               | | | Description\n+| `ssha256`               | | | Uses a salted `sha-256` algorithm (default).\n+| `md5`                   | | | Uses `MD5` algorithm.\n+| `sha1`                  | | | Uses `SHA1` algorithm.\n+| `bcrypt`                | | | Uses `bcrypt` algorithm with salt generated in 1024 rounds.\n+| `bcrypt4`               | | | Uses `bcrypt` algorithm with salt generated in 16 rounds.\n+| `bcrypt5`               | | | Uses `bcrypt` algorithm with salt generated in 32 rounds.\n+| `bcrypt6`               | | | Uses `bcrypt` algorithm with salt generated in 64 rounds.\n+| `bcrypt7`               | | | Uses `bcrypt` algorithm with salt generated in 128 rounds.\n+| `bcrypt8`               | | | Uses `bcrypt` algorithm with salt generated in 256 rounds.\n+| `bcrypt9`               | | | Uses `bcrypt` algorithm with salt generated in 512 rounds.\n+| `pbkdf2`                | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n                              pseudorandom function using 10000 iterations.\n-| `pbkdf2_1000`       | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n-                             pseudorandom function using 1000 iterations.\n-| `pbkdf2_10000`      | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n-                             pseudorandom function using 10000 iterations.\n-| `pbkdf2_50000`      | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n-                             pseudorandom function using 50000 iterations.\n-| `pbkdf2_100000`     | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n-                             pseudorandom function using 100000 iterations.\n-| `pbkdf2_500000`     | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n-                              pseudorandom function using 500000 iterations.\n-| `pbkdf2_1000000`    | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n-                             pseudorandom function using 1000000 iterations.\n-| `noop`,`clear_text` | | | Doesn't hash the credentials and keeps it in clear text in\n+| `pbkdf2_1000`           | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n+                             pseudorandom function over SHA512 hash using 1000 iterations.\n+| `pbkdf2_10000`          | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n+                             pseudorandom function over SHA512 hash using 10000 iterations.\n+| `pbkdf2_50000`          | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n+                             pseudorandom function over SHA512 hash using 50000 iterations.\n+| `pbkdf2_100000`         | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n+                             pseudorandom function over SHA512 hash using 100000 iterations.\n+| `pbkdf2_500000`         | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n+                              pseudorandom function over SHA512 hash using 500000 iterations.\n+| `pbkdf2_1000000`        | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n+                             pseudorandom function over SHA512 hash using 1000000 iterations.\n+| `pbkdf2_stretch`        | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n+                             pseudorandom function over SHA512 hash using 10000 iterations.\n+| `pbkdf2_stretch_1000`   | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c58ba67ab0cca2fd8e66d040949cae7257b7ff0d"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTg2MzgwNw==", "bodyText": "nit:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private static char[] hashSha512NoSalt(SecureString text) {\n          \n          \n            \n                private static char[] sha512Hash(SecureString text) {\n          \n      \n    \n    \n  \n\n(hashing doesn't inherently include a salt, so it feels strange calling it out in the method name )", "url": "https://github.com/elastic/elasticsearch/pull/65328#discussion_r529863807", "createdAt": "2020-11-24T20:39:36Z", "author": {"login": "jkakavas"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/security/authc/support/Hasher.java", "diffHunk": "@@ -724,4 +706,10 @@ private static boolean verifyBcryptHash(SecureString text, char[] hash) {\n         SECURE_RANDOM.nextBytes(salt);\n         return salt;\n     }\n+\n+    private static char[] hashSha512NoSalt(SecureString text) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c58ba67ab0cca2fd8e66d040949cae7257b7ff0d"}, "originalPosition": 144}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4b2e901a1afdc486201f2ae0a97e00222f5f64d1", "author": {"user": {"login": "elasticmachine", "name": "Elastic Machine"}}, "url": "https://github.com/elastic/elasticsearch/commit/4b2e901a1afdc486201f2ae0a97e00222f5f64d1", "committedDate": "2020-11-25T10:12:55Z", "message": "Merge branch 'master' into FIBS_AO_PSW"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3779f1a04c09849805907035375122bfc178d70c", "author": {"user": {"login": "elasticmachine", "name": "Elastic Machine"}}, "url": "https://github.com/elastic/elasticsearch/commit/3779f1a04c09849805907035375122bfc178d70c", "committedDate": "2020-11-25T14:25:38Z", "message": "Merge branch 'master' into FIBS_AO_PSW"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2b611ca33085ae95f3a09a5326afaa543a7c355d", "author": {"user": {"login": "BigPandaToo", "name": "Lyudmila Fokina"}}, "url": "https://github.com/elastic/elasticsearch/commit/2b611ca33085ae95f3a09a5326afaa543a7c355d", "committedDate": "2020-11-25T14:27:06Z", "message": "Renaming the hash function + rephrasing the doc descriptions"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "583f01fcbdcba0fdc3d4cf0227498e24bae4f71f", "author": {"user": {"login": "BigPandaToo", "name": "Lyudmila Fokina"}}, "url": "https://github.com/elastic/elasticsearch/commit/583f01fcbdcba0fdc3d4cf0227498e24bae4f71f", "committedDate": "2020-11-25T14:27:46Z", "message": "Merge branch 'FIBS_AO_PSW' of github.com:BigPandaToo/elasticsearch into FIBS_AO_PSW"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM4NTU3MjQz", "url": "https://github.com/elastic/elasticsearch/pull/65328#pullrequestreview-538557243", "createdAt": "2020-11-25T14:31:34Z", "commit": {"oid": "583f01fcbdcba0fdc3d4cf0227498e24bae4f71f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxNDozMTozNFrOH52CCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxNDozMTozNFrOH52CCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQxNjEzOA==", "bodyText": "leftover over SHA512 hash  in the pbkdf2_ hasher descriptions", "url": "https://github.com/elastic/elasticsearch/pull/65328#discussion_r530416138", "createdAt": "2020-11-25T14:31:34Z", "author": {"login": "jkakavas"}, "path": "docs/reference/settings/security-hash-settings.asciidoc", "diffHunk": "@@ -12,32 +12,53 @@ hashing algorithm by setting the <<static-cluster-setting,static>>\n [[cache-hash-algo]]\n .Cache hash algorithms\n |=======================\n-| Algorithm           | | | Description\n-| `ssha256`           | | | Uses a salted `sha-256` algorithm (default).\n-| `md5`               | | | Uses `MD5` algorithm.\n-| `sha1`              | | | Uses `SHA1` algorithm.\n-| `bcrypt`            | | | Uses `bcrypt` algorithm with salt generated in 1024 rounds.\n-| `bcrypt4`           | | | Uses `bcrypt` algorithm with salt generated in 16 rounds.\n-| `bcrypt5`           | | | Uses `bcrypt` algorithm with salt generated in 32 rounds.\n-| `bcrypt6`           | | | Uses `bcrypt` algorithm with salt generated in 64 rounds.\n-| `bcrypt7`           | | | Uses `bcrypt` algorithm with salt generated in 128 rounds.\n-| `bcrypt8`           | | | Uses `bcrypt` algorithm with salt generated in 256 rounds.\n-| `bcrypt9`           | | | Uses `bcrypt` algorithm with salt generated in 512 rounds.\n-| `pbkdf2`            | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n+| Algorithm               | | | Description\n+| `ssha256`               | | | Uses a salted `sha-256` algorithm (default).\n+| `md5`                   | | | Uses `MD5` algorithm.\n+| `sha1`                  | | | Uses `SHA1` algorithm.\n+| `bcrypt`                | | | Uses `bcrypt` algorithm with salt generated in 1024 rounds.\n+| `bcrypt4`               | | | Uses `bcrypt` algorithm with salt generated in 16 rounds.\n+| `bcrypt5`               | | | Uses `bcrypt` algorithm with salt generated in 32 rounds.\n+| `bcrypt6`               | | | Uses `bcrypt` algorithm with salt generated in 64 rounds.\n+| `bcrypt7`               | | | Uses `bcrypt` algorithm with salt generated in 128 rounds.\n+| `bcrypt8`               | | | Uses `bcrypt` algorithm with salt generated in 256 rounds.\n+| `bcrypt9`               | | | Uses `bcrypt` algorithm with salt generated in 512 rounds.\n+| `pbkdf2`                | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n                              pseudorandom function using 10000 iterations.\n-| `pbkdf2_1000`       | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n-                             pseudorandom function using 1000 iterations.\n-| `pbkdf2_10000`      | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n-                             pseudorandom function using 10000 iterations.\n-| `pbkdf2_50000`      | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n-                             pseudorandom function using 50000 iterations.\n-| `pbkdf2_100000`     | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n-                             pseudorandom function using 100000 iterations.\n-| `pbkdf2_500000`     | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n-                              pseudorandom function using 500000 iterations.\n-| `pbkdf2_1000000`    | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n-                             pseudorandom function using 1000000 iterations.\n-| `noop`,`clear_text` | | | Doesn't hash the credentials and keeps it in clear text in\n+| `pbkdf2_1000`           | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n+                             pseudorandom function over SHA512 hash using 1000 iterations.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "583f01fcbdcba0fdc3d4cf0227498e24bae4f71f"}, "originalPosition": 43}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "806131075e01180f27a3449cc20ae8023a61ff01", "author": {"user": {"login": "BigPandaToo", "name": "Lyudmila Fokina"}}, "url": "https://github.com/elastic/elasticsearch/commit/806131075e01180f27a3449cc20ae8023a61ff01", "committedDate": "2020-11-25T15:02:44Z", "message": "Removing leftover from the doc"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM4NjA2NTE3", "url": "https://github.com/elastic/elasticsearch/pull/65328#pullrequestreview-538606517", "createdAt": "2020-11-25T15:21:54Z", "commit": {"oid": "806131075e01180f27a3449cc20ae8023a61ff01"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxNToyMTo1NFrOH54SaA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxNToyMTo1NFrOH54SaA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ1MzA5Ng==", "bodyText": "This will start failing in FIPS 140 mode in the CI, when #64024 is merged, if a PBKDF2 hasher is passed and randomAlphaOfLength returns anything less than 14. I can also take care of this as part of #64024", "url": "https://github.com/elastic/elasticsearch/pull/65328#discussion_r530453096", "createdAt": "2020-11-25T15:21:54Z", "author": {"login": "jkakavas"}, "path": "x-pack/plugin/security/src/test/java/org/elasticsearch/xpack/security/authc/support/HasherTests.java", "diffHunk": "@@ -132,11 +146,35 @@ public void testResolveFromHash() {\n         assertThat(Hasher.resolveFromHash(\n             \"{PBKDF2}1000000$UuyhtjDEzWmE2wyY80akZKPWWpy2r2X50so41YML82U=$WFasYLelqbjQwt3EqFlUcwHiC38EZC45Iu/Iz0xL1GQ=\".toCharArray()),\n             sameInstance(Hasher.PBKDF2_1000000));\n+        assertThat(Hasher.resolveFromHash(\n+            \"{PBKDF2_STRETCH}1000$sTyix9e0zNINzq2aDZ+GD5+QlO94xVyf/bv4pWNhBxo=$4KuzGPy9HXnhY3ANHn8rcIRQuJHPB6cEtLwnOhDI5d4=\"\n+                .toCharArray()),\n+            sameInstance(Hasher.PBKDF2_STRETCH_1000));\n+        assertThat(Hasher.resolveFromHash(\n+            \"{PBKDF2_STRETCH}10000$8M9+Ww0xkdY250CROEutsd8UP6CrJESw7ZAFu1NGORo=$ai0gxBPtHTfZU/nbNGwL5zjC+eo2/ANQM17L/tllVeo=\"\n+                .toCharArray()),\n+            sameInstance(Hasher.PBKDF2_STRETCH));\n+        assertThat(Hasher.resolveFromHash(\n+            \"{PBKDF2_STRETCH}50000$uupwXiq8W0+jrLtC3/aqzuvyZlRarlmx1+CQGEnomlk=$by8q/+oRPPWwDE6an7B9/ndz7UZ1UQpaGY4CGurtPTI=\"\n+                .toCharArray()),\n+            sameInstance(Hasher.PBKDF2_STRETCH_50000));\n+        assertThat(Hasher.resolveFromHash(\n+            \"{PBKDF2_STRETCH}100000$E9VqtV76PcrQuCZ6wOMMNvs4CMPcANTpzRw8Wjd24PU=$j56uKUvwbvmgQgNFkbV7SRQVZ2QOarokAgBeA8xcFD8=\"\n+                .toCharArray()),\n+            sameInstance(Hasher.PBKDF2_STRETCH_100000));\n+        assertThat(Hasher.resolveFromHash(\n+            \"{PBKDF2_STRETCH}500000$4dpTEbu4jfjhDOjWY6xdsnxuQs4dg4QbNzZJ0Z1Tm4s=$Us/yrlCxVaW7mz0go1qIygFqGgcfUMgCZfIl2AvI4I8=\"\n+                .toCharArray()),\n+            sameInstance(Hasher.PBKDF2_STRETCH_500000));\n+        assertThat(Hasher.resolveFromHash(\n+            \"{PBKDF2_STRETCH}1000000$eKeQvMztiIcqBynTNDFBseOBww3GBpHDZI6EPPVHYUw=$4587yrxUa02RZ1jeW1WOaMjRn5qT9iQ5/DIHk0nW2bE=\"\n+                .toCharArray()),\n+            sameInstance(Hasher.PBKDF2_STRETCH_1000000));\n         assertThat(Hasher.resolveFromHash(\"notavalidhashformat\".toCharArray()), sameInstance(Hasher.NOOP));\n     }\n \n     private static void testHasherSelfGenerated(Hasher hasher) {\n-        SecureString passwd = new SecureString(randomAlphaOfLength(10).toCharArray());\n+        SecureString passwd = new SecureString(randomAlphaOfLength(between(6, 15)).toCharArray());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "806131075e01180f27a3449cc20ae8023a61ff01"}, "originalPosition": 61}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM4NjA3NDU0", "url": "https://github.com/elastic/elasticsearch/pull/65328#pullrequestreview-538607454", "createdAt": "2020-11-25T15:22:56Z", "commit": {"oid": "806131075e01180f27a3449cc20ae8023a61ff01"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM4OTEwOTY5", "url": "https://github.com/elastic/elasticsearch/pull/65328#pullrequestreview-538910969", "createdAt": "2020-11-25T23:56:13Z", "commit": {"oid": "806131075e01180f27a3449cc20ae8023a61ff01"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQyMzo1NjoxNFrOH6HTpg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwMDowMToyMVrOH6HYnw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDY5OTE3NA==", "bodyText": "This is probably minor, but I'd prefer to use return MessageDigests.toHexCharArray(md.digest());, the reasons being:\n\nIt is an intermediate result which does not need a storage friendly base64 format. toHexCharArray should also be marginally more efficient.\nBase64 encoding gives a char array of length 86, while toHexCharArray give a char array of length 128. A trivial security gain.\ntoHexCharArray avoids creating an intermediate String. This is probably not as critical since this is a hashed result anyway. But given the purpose of SecureString is to avoid creating an actual string, it makes more sense if we don't create one before it. Also I believe pbkdf2 implementation internally does not use any String either, so it might be better if we do the same.", "url": "https://github.com/elastic/elasticsearch/pull/65328#discussion_r530699174", "createdAt": "2020-11-25T23:56:14Z", "author": {"login": "ywangd"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/security/authc/support/Hasher.java", "diffHunk": "@@ -597,4 +706,10 @@ private static boolean verifyBcryptHash(SecureString text, char[] hash) {\n         SECURE_RANDOM.nextBytes(salt);\n         return salt;\n     }\n+\n+    private static char[] hashSha512(SecureString text) {\n+        MessageDigest md = MessageDigests.sha512();\n+        md.update(CharArrays.toUtf8Bytes(text.getChars()));\n+        return Base64.getUrlEncoder().withoutPadding().encodeToString(md.digest()).toCharArray();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "806131075e01180f27a3449cc20ae8023a61ff01"}, "originalPosition": 283}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDcwMDQ0Nw==", "bodyText": "Technically we don't block the use of PBKDF2_STRETCH for non-FIPS clusters. So it seems to me that we should test it regardlessly, i.e. add it to the randomFrom list when inFipsJvm() is false as well.", "url": "https://github.com/elastic/elasticsearch/pull/65328#discussion_r530700447", "createdAt": "2020-11-26T00:01:21Z", "author": {"login": "ywangd"}, "path": "x-pack/qa/security-tools-tests/src/test/java/org/elasticsearch/xpack/security/authc/file/tool/UsersToolTests.java", "diffHunk": "@@ -70,7 +70,7 @@ public void setupHome() throws IOException {\n         IOUtils.rm(homeDir);\n         confDir = homeDir.resolve(\"config\");\n         Files.createDirectories(confDir);\n-        hasher = inFipsJvm() ? randomFrom(Hasher.PBKDF2, Hasher.PBKDF2_1000)\n+        hasher = inFipsJvm() ? randomFrom(Hasher.PBKDF2, Hasher.PBKDF2_1000, Hasher.PBKDF2_STRETCH)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "806131075e01180f27a3449cc20ae8023a61ff01"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM4OTc5MzQ3", "url": "https://github.com/elastic/elasticsearch/pull/65328#pullrequestreview-538979347", "createdAt": "2020-11-26T04:01:49Z", "commit": {"oid": "806131075e01180f27a3449cc20ae8023a61ff01"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwNDowMTo1MFrOH6LEyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwNDowMTo1MFrOH6LEyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDc2MDkwNA==", "bodyText": "I find the order of this sentence to be strange - it explains the hashing process in reverse.\nMy suggestion:\n| `pbkdf2_stretch_{n}`    | | | First stretches the input password by passing it through a SHA512 hash\n                             and then applies the `PBKDF2` key derivation function with `HMAC-SHA512` as a\n                             pseudorandom function using {n} iterations.", "url": "https://github.com/elastic/elasticsearch/pull/65328#discussion_r530760904", "createdAt": "2020-11-26T04:01:50Z", "author": {"login": "tvernum"}, "path": "docs/reference/settings/security-hash-settings.asciidoc", "diffHunk": "@@ -12,32 +12,46 @@ hashing algorithm by setting the <<static-cluster-setting,static>>\n [[cache-hash-algo]]\n .Cache hash algorithms\n |=======================\n-| Algorithm           | | | Description\n-| `ssha256`           | | | Uses a salted `sha-256` algorithm (default).\n-| `md5`               | | | Uses `MD5` algorithm.\n-| `sha1`              | | | Uses `SHA1` algorithm.\n-| `bcrypt`            | | | Uses `bcrypt` algorithm with salt generated in 1024 rounds.\n-| `bcrypt4`           | | | Uses `bcrypt` algorithm with salt generated in 16 rounds.\n-| `bcrypt5`           | | | Uses `bcrypt` algorithm with salt generated in 32 rounds.\n-| `bcrypt6`           | | | Uses `bcrypt` algorithm with salt generated in 64 rounds.\n-| `bcrypt7`           | | | Uses `bcrypt` algorithm with salt generated in 128 rounds.\n-| `bcrypt8`           | | | Uses `bcrypt` algorithm with salt generated in 256 rounds.\n-| `bcrypt9`           | | | Uses `bcrypt` algorithm with salt generated in 512 rounds.\n-| `pbkdf2`            | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n+| Algorithm               | | | Description\n+| `ssha256`               | | | Uses a salted `sha-256` algorithm (default).\n+| `md5`                   | | | Uses `MD5` algorithm.\n+| `sha1`                  | | | Uses `SHA1` algorithm.\n+| `bcrypt`                | | | Uses `bcrypt` algorithm with salt generated in 1024 rounds.\n+| `bcrypt4`               | | | Uses `bcrypt` algorithm with salt generated in 16 rounds.\n+| `bcrypt5`               | | | Uses `bcrypt` algorithm with salt generated in 32 rounds.\n+| `bcrypt6`               | | | Uses `bcrypt` algorithm with salt generated in 64 rounds.\n+| `bcrypt7`               | | | Uses `bcrypt` algorithm with salt generated in 128 rounds.\n+| `bcrypt8`               | | | Uses `bcrypt` algorithm with salt generated in 256 rounds.\n+| `bcrypt9`               | | | Uses `bcrypt` algorithm with salt generated in 512 rounds.\n+| `pbkdf2`                | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n                              pseudorandom function using 10000 iterations.\n-| `pbkdf2_1000`       | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n-                             pseudorandom function using 1000 iterations.\n-| `pbkdf2_10000`      | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n-                             pseudorandom function using 10000 iterations.\n-| `pbkdf2_50000`      | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n-                             pseudorandom function using 50000 iterations.\n-| `pbkdf2_100000`     | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n-                             pseudorandom function using 100000 iterations.\n-| `pbkdf2_500000`     | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n-                              pseudorandom function using 500000 iterations.\n-| `pbkdf2_1000000`    | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n-                             pseudorandom function using 1000000 iterations.\n-| `noop`,`clear_text` | | | Doesn't hash the credentials and keeps it in clear text in\n+| `pbkdf2_1000`           | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n+                             pseudorandom function over SHA512 hash using 1000 iterations.\n+| `pbkdf2_10000`          | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n+                             pseudorandom function over SHA512 hash using 10000 iterations.\n+| `pbkdf2_50000`          | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n+                             pseudorandom function over SHA512 hash using 50000 iterations.\n+| `pbkdf2_100000`         | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n+                             pseudorandom function over SHA512 hash using 100000 iterations.\n+| `pbkdf2_500000`         | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n+                              pseudorandom function over SHA512 hash using 500000 iterations.\n+| `pbkdf2_1000000`        | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n+                             pseudorandom function over SHA512 hash using 1000000 iterations.\n+| `pbkdf2_stretch`        | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a\n+                             pseudorandom function over SHA512 hash using 10000 iterations.\n+| `pbkdf2_stretch_1000`   | | | Uses `PBKDF2` key derivation function with `HMAC-SHA512` as a", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTg2MjQ1Ng=="}, "originalCommit": {"oid": "c58ba67ab0cca2fd8e66d040949cae7257b7ff0d"}, "originalPosition": 56}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM5MDY5OTYy", "url": "https://github.com/elastic/elasticsearch/pull/65328#pullrequestreview-539069962", "createdAt": "2020-11-26T08:04:13Z", "commit": {"oid": "806131075e01180f27a3449cc20ae8023a61ff01"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "34eb3c0777898485c05ed97748ef588f38945e41", "author": {"user": {"login": "BigPandaToo", "name": "Lyudmila Fokina"}}, "url": "https://github.com/elastic/elasticsearch/commit/34eb3c0777898485c05ed97748ef588f38945e41", "committedDate": "2020-11-26T11:19:15Z", "message": "Return HexCharArray instead of Base64 encoding and avoid intermediate\nString"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 923, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}