{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzc2NjU0NjM5", "number": 52479, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQxMDo0NToyN1rODhBe8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQxMDo0NToyN1rODhBe8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1OTUzOTA3OnYy", "diffSide": "RIGHT", "path": "plugins/repository-gcs/src/main/java/org/elasticsearch/repositories/gcs/GoogleCloudStorageRetryingInputStream.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQxMDo0NToyN1rOFrjbhA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQxMTowMjoxOFrOFrj9gQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTIxMzU3Mg==", "bodyText": "Maybe only seek if currentOffset > 0L?", "url": "https://github.com/elastic/elasticsearch/pull/52479#discussion_r381213572", "createdAt": "2020-02-19T10:45:27Z", "author": {"login": "tlrx"}, "path": "plugins/repository-gcs/src/main/java/org/elasticsearch/repositories/gcs/GoogleCloudStorageRetryingInputStream.java", "diffHunk": "@@ -0,0 +1,179 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.elasticsearch.repositories.gcs;\n+\n+import com.google.cloud.ReadChannel;\n+import com.google.cloud.storage.BlobId;\n+import com.google.cloud.storage.Storage;\n+import com.google.cloud.storage.StorageException;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.common.SuppressForbidden;\n+import org.elasticsearch.core.internal.io.IOUtils;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.Channels;\n+import java.nio.channels.ReadableByteChannel;\n+import java.nio.file.NoSuchFileException;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import static java.net.HttpURLConnection.HTTP_NOT_FOUND;\n+\n+/**\n+ * Wrapper around reads from GCS that will retry blob downloads that fail part-way through, resuming from where the failure occurred.\n+ * This should be handled by the SDK but it isn't today. This should be revisited in the future (e.g. before removing\n+ * the {@link org.elasticsearch.Version#V_7_0_0} version constant) and removed if the SDK handles retries itself in the future.\n+ */\n+class GoogleCloudStorageRetryingInputStream extends InputStream {\n+\n+    private static final Logger logger = LogManager.getLogger(GoogleCloudStorageRetryingInputStream.class);\n+\n+    static final int MAX_SUPPRESSED_EXCEPTIONS = 10;\n+\n+    private final Storage client;\n+\n+    private final BlobId blobId;\n+\n+    private final int maxRetries;\n+\n+    private InputStream currentStream;\n+    private int attempt = 1;\n+    private List<StorageException> failures = new ArrayList<>(MAX_SUPPRESSED_EXCEPTIONS);\n+    private long currentOffset;\n+    private boolean closed;\n+\n+    GoogleCloudStorageRetryingInputStream(Storage client, BlobId blobId) throws IOException {\n+        this.client = client;\n+        this.blobId = blobId;\n+        this.maxRetries = client.getOptions().getRetrySettings().getMaxAttempts() + 1;\n+        currentStream = openStream();\n+    }\n+\n+    private InputStream openStream() throws IOException {\n+        try {\n+            final ReadChannel readChannel = SocketAccess.doPrivilegedIOException(() -> client.reader(blobId));\n+            readChannel.seek(currentOffset);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e6815fa07328e5d68c40f96d099441408c2e6460"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTIxODc3MQ==", "bodyText": "This doesn't have any IO impact in the SDK (it just sets an long field that is then used when firing off the actual request) so I figured why do 3 lines instead of 1 unless we have to? :)", "url": "https://github.com/elastic/elasticsearch/pull/52479#discussion_r381218771", "createdAt": "2020-02-19T10:55:37Z", "author": {"login": "original-brownbear"}, "path": "plugins/repository-gcs/src/main/java/org/elasticsearch/repositories/gcs/GoogleCloudStorageRetryingInputStream.java", "diffHunk": "@@ -0,0 +1,179 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.elasticsearch.repositories.gcs;\n+\n+import com.google.cloud.ReadChannel;\n+import com.google.cloud.storage.BlobId;\n+import com.google.cloud.storage.Storage;\n+import com.google.cloud.storage.StorageException;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.common.SuppressForbidden;\n+import org.elasticsearch.core.internal.io.IOUtils;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.Channels;\n+import java.nio.channels.ReadableByteChannel;\n+import java.nio.file.NoSuchFileException;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import static java.net.HttpURLConnection.HTTP_NOT_FOUND;\n+\n+/**\n+ * Wrapper around reads from GCS that will retry blob downloads that fail part-way through, resuming from where the failure occurred.\n+ * This should be handled by the SDK but it isn't today. This should be revisited in the future (e.g. before removing\n+ * the {@link org.elasticsearch.Version#V_7_0_0} version constant) and removed if the SDK handles retries itself in the future.\n+ */\n+class GoogleCloudStorageRetryingInputStream extends InputStream {\n+\n+    private static final Logger logger = LogManager.getLogger(GoogleCloudStorageRetryingInputStream.class);\n+\n+    static final int MAX_SUPPRESSED_EXCEPTIONS = 10;\n+\n+    private final Storage client;\n+\n+    private final BlobId blobId;\n+\n+    private final int maxRetries;\n+\n+    private InputStream currentStream;\n+    private int attempt = 1;\n+    private List<StorageException> failures = new ArrayList<>(MAX_SUPPRESSED_EXCEPTIONS);\n+    private long currentOffset;\n+    private boolean closed;\n+\n+    GoogleCloudStorageRetryingInputStream(Storage client, BlobId blobId) throws IOException {\n+        this.client = client;\n+        this.blobId = blobId;\n+        this.maxRetries = client.getOptions().getRetrySettings().getMaxAttempts() + 1;\n+        currentStream = openStream();\n+    }\n+\n+    private InputStream openStream() throws IOException {\n+        try {\n+            final ReadChannel readChannel = SocketAccess.doPrivilegedIOException(() -> client.reader(blobId));\n+            readChannel.seek(currentOffset);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTIxMzU3Mg=="}, "originalCommit": {"oid": "e6815fa07328e5d68c40f96d099441408c2e6460"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTIyMjI3Mw==", "bodyText": "I figured why do 3 lines instead of 1 unless we have to? :)\n\nI see things differently, why always seek to the beginning when most of the time it's not necessary? :)\nAnyway, it's nitpicking so do as you prefer :)", "url": "https://github.com/elastic/elasticsearch/pull/52479#discussion_r381222273", "createdAt": "2020-02-19T11:02:18Z", "author": {"login": "tlrx"}, "path": "plugins/repository-gcs/src/main/java/org/elasticsearch/repositories/gcs/GoogleCloudStorageRetryingInputStream.java", "diffHunk": "@@ -0,0 +1,179 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.elasticsearch.repositories.gcs;\n+\n+import com.google.cloud.ReadChannel;\n+import com.google.cloud.storage.BlobId;\n+import com.google.cloud.storage.Storage;\n+import com.google.cloud.storage.StorageException;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.common.SuppressForbidden;\n+import org.elasticsearch.core.internal.io.IOUtils;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.Channels;\n+import java.nio.channels.ReadableByteChannel;\n+import java.nio.file.NoSuchFileException;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import static java.net.HttpURLConnection.HTTP_NOT_FOUND;\n+\n+/**\n+ * Wrapper around reads from GCS that will retry blob downloads that fail part-way through, resuming from where the failure occurred.\n+ * This should be handled by the SDK but it isn't today. This should be revisited in the future (e.g. before removing\n+ * the {@link org.elasticsearch.Version#V_7_0_0} version constant) and removed if the SDK handles retries itself in the future.\n+ */\n+class GoogleCloudStorageRetryingInputStream extends InputStream {\n+\n+    private static final Logger logger = LogManager.getLogger(GoogleCloudStorageRetryingInputStream.class);\n+\n+    static final int MAX_SUPPRESSED_EXCEPTIONS = 10;\n+\n+    private final Storage client;\n+\n+    private final BlobId blobId;\n+\n+    private final int maxRetries;\n+\n+    private InputStream currentStream;\n+    private int attempt = 1;\n+    private List<StorageException> failures = new ArrayList<>(MAX_SUPPRESSED_EXCEPTIONS);\n+    private long currentOffset;\n+    private boolean closed;\n+\n+    GoogleCloudStorageRetryingInputStream(Storage client, BlobId blobId) throws IOException {\n+        this.client = client;\n+        this.blobId = blobId;\n+        this.maxRetries = client.getOptions().getRetrySettings().getMaxAttempts() + 1;\n+        currentStream = openStream();\n+    }\n+\n+    private InputStream openStream() throws IOException {\n+        try {\n+            final ReadChannel readChannel = SocketAccess.doPrivilegedIOException(() -> client.reader(blobId));\n+            readChannel.seek(currentOffset);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTIxMzU3Mg=="}, "originalCommit": {"oid": "e6815fa07328e5d68c40f96d099441408c2e6460"}, "originalPosition": 75}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3946, "cost": 1, "resetAt": "2021-11-12T19:05:54Z"}}}