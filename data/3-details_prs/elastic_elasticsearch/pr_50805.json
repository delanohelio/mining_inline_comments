{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYxMDUxMTA4", "number": 50805, "title": "Make cluster state writer resilient to disk issues", "bodyText": "Adds handling to make the cluster state writer resilient to disk issues. Relates to #48701", "createdAt": "2020-01-09T16:36:39Z", "url": "https://github.com/elastic/elasticsearch/pull/50805", "merged": true, "mergeCommit": {"oid": "bfb878a22067fa968a13711696349693e45d0678"}, "closed": true, "closedAt": "2020-01-10T16:48:10Z", "author": {"login": "ywelsch"}, "timelineItems": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb4sm6kgH2gAyMzYxMDUxMTA4Ojc1ZWMzZWViZGM0OTJkM2U0M2U4NmZkNGMxOTRkMzI4N2Q2NGMwMTc=", "endCursor": "Y3Vyc29yOnYyOpPPAAABb5A9hwgFqTM0MTI2NjgzNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "75ec3eebdc492d3e43e86fd4c194d3287d64c017", "author": {"user": {"login": "ywelsch", "name": "Yannick Welsch"}}, "url": "https://github.com/elastic/elasticsearch/commit/75ec3eebdc492d3e43e86fd4c194d3287d64c017", "committedDate": "2020-01-09T16:33:01Z", "message": "Make cluster state writer resilient to disk issues"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1c7eb4c7dc61c3bfc41e111b4d9c5313c43a3e5c", "author": {"user": {"login": "ywelsch", "name": "Yannick Welsch"}}, "url": "https://github.com/elastic/elasticsearch/commit/1c7eb4c7dc61c3bfc41e111b4d9c5313c43a3e5c", "committedDate": "2020-01-09T17:00:26Z", "message": "checkstyle"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQxMDg0MDM4", "url": "https://github.com/elastic/elasticsearch/pull/50805#pullrequestreview-341084038", "createdAt": "2020-01-10T10:44:32Z", "commit": {"oid": "1c7eb4c7dc61c3bfc41e111b4d9c5313c43a3e5c"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxMDo0NDozM1rOFcQgdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxMToyNTowNlrOFcRbyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTE3NDkwMA==", "bodyText": "Suggest suppressing exceptions while closing so we get to see the original exception too:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            writer.close();\n          \n          \n            \n                            IOUtils.close(e, writer);", "url": "https://github.com/elastic/elasticsearch/pull/50805#discussion_r365174900", "createdAt": "2020-01-10T10:44:33Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/gateway/GatewayMetaState.java", "diffHunk": "@@ -406,7 +412,14 @@ boolean allPendingAsyncStatesWritten() {\n             // In the common case it's actually sufficient to commit() the existing state and not do any indexing. For instance,\n             // this is true if there's only one data path on this master node, and the commit we just loaded was already written out\n             // by this version of Elasticsearch. TODO TBD should we avoid indexing when possible?\n-            persistenceWriter.writeFullStateAndCommit(currentTerm, lastAcceptedState);\n+            final PersistedClusterStateService.Writer writer = persistedClusterStateService.createWriter();\n+            try {\n+                writer.writeFullStateAndCommit(currentTerm, lastAcceptedState);\n+            } catch (Exception e) {\n+                writer.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c7eb4c7dc61c3bfc41e111b4d9c5313c43a3e5c"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTE3NjEyMw==", "bodyText": "This is subsumed by the previous suggestion.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            throw e;", "url": "https://github.com/elastic/elasticsearch/pull/50805#discussion_r365176123", "createdAt": "2020-01-10T10:47:33Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/gateway/GatewayMetaState.java", "diffHunk": "@@ -406,7 +412,14 @@ boolean allPendingAsyncStatesWritten() {\n             // In the common case it's actually sufficient to commit() the existing state and not do any indexing. For instance,\n             // this is true if there's only one data path on this master node, and the commit we just loaded was already written out\n             // by this version of Elasticsearch. TODO TBD should we avoid indexing when possible?\n-            persistenceWriter.writeFullStateAndCommit(currentTerm, lastAcceptedState);\n+            final PersistedClusterStateService.Writer writer = persistedClusterStateService.createWriter();\n+            try {\n+                writer.writeFullStateAndCommit(currentTerm, lastAcceptedState);\n+            } catch (Exception e) {\n+                writer.close();\n+                throw e;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c7eb4c7dc61c3bfc41e111b4d9c5313c43a3e5c"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTE4MzI0Mg==", "bodyText": "I suggest combining this with getWriterSafe(), because in all cases we call reloadWriterIfNecessary() followed (essentially) immediately by getWriterSafe(). Why not return the writer from this method instead?", "url": "https://github.com/elastic/elasticsearch/pull/50805#discussion_r365183242", "createdAt": "2020-01-10T11:05:30Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/gateway/GatewayMetaState.java", "diffHunk": "@@ -419,34 +432,77 @@ public ClusterState getLastAcceptedState() {\n             return lastAcceptedState;\n         }\n \n+        private PersistedClusterStateService.Writer getWriterSafe() {\n+            PersistedClusterStateService.Writer writer = persistenceWriter.get();\n+            if (writer == null) {\n+                throw new AlreadyClosedException(\"persisted state has been closed\");\n+            }\n+            return writer;\n+        }\n+\n         @Override\n         public void setCurrentTerm(long currentTerm) {\n-            persistenceWriter.commit(currentTerm, lastAcceptedState.version());\n+            reloadWriterIfNecessary();\n+            try {\n+                if (writeNextStateFully) {\n+                    getWriterSafe().writeFullStateAndCommit(currentTerm, lastAcceptedState);\n+                    writeNextStateFully = false;\n+                } else {\n+                    getWriterSafe().commit(currentTerm, lastAcceptedState.version());\n+                }\n+            } catch (Exception e) {\n+                handleExceptionOnWrite(e);\n+            }\n             this.currentTerm = currentTerm;\n         }\n \n         @Override\n         public void setLastAcceptedState(ClusterState clusterState) {\n+            reloadWriterIfNecessary();\n             try {\n-                if (clusterState.term() != lastAcceptedState.term()) {\n-                    assert clusterState.term() > lastAcceptedState.term() : clusterState.term() + \" vs \" + lastAcceptedState.term();\n-                    // In a new currentTerm, we cannot compare the persisted metadata's lastAcceptedVersion to those in the new state, so\n-                    // it's simplest to write everything again.\n-                    persistenceWriter.writeFullStateAndCommit(currentTerm, clusterState);\n+                if (writeNextStateFully) {\n+                    getWriterSafe().writeFullStateAndCommit(currentTerm, clusterState);\n+                    writeNextStateFully = false;\n                 } else {\n-                    // Within the same currentTerm, we _can_ use metadata versions to skip unnecessary writing.\n-                    persistenceWriter.writeIncrementalStateAndCommit(currentTerm, lastAcceptedState, clusterState);\n+                    if (clusterState.term() != lastAcceptedState.term()) {\n+                        assert clusterState.term() > lastAcceptedState.term() : clusterState.term() + \" vs \" + lastAcceptedState.term();\n+                        // In a new currentTerm, we cannot compare the persisted metadata's lastAcceptedVersion to those in the new state,\n+                        // so it's simplest to write everything again.\n+                        getWriterSafe().writeFullStateAndCommit(currentTerm, clusterState);\n+                    } else {\n+                        // Within the same currentTerm, we _can_ use metadata versions to skip unnecessary writing.\n+                        getWriterSafe().writeIncrementalStateAndCommit(currentTerm, lastAcceptedState, clusterState);\n+                    }\n                 }\n-            } catch (IOException e) {\n-                throw new UncheckedIOException(e);\n+            } catch (Exception e) {\n+                handleExceptionOnWrite(e);\n             }\n \n             lastAcceptedState = clusterState;\n         }\n \n+        private void reloadWriterIfNecessary() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c7eb4c7dc61c3bfc41e111b4d9c5313c43a3e5c"}, "originalPosition": 149}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTE4NTk3Nw==", "bodyText": "Continuing here seems risky -- at least, it's outside what we have modelled for correctness. If we successfully write the data to disk then fail (e.g. unrelated fsync failure) then continue then we will treat that as if we didn't update the last-accepted state and maybe emit some further messages based on that older state, but a reboot will pick up the newer state.", "url": "https://github.com/elastic/elasticsearch/pull/50805#discussion_r365185977", "createdAt": "2020-01-10T11:13:10Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/gateway/PersistedClusterStateService.java", "diffHunk": "@@ -634,23 +667,23 @@ private void addMetaData(MetaData metaData) throws IOException {\n             }\n         }\n \n-        public void commit(long currentTerm, long lastAcceptedVersion) {\n+        public void commit(long currentTerm, long lastAcceptedVersion) throws IOException {\n+            ensureOpen();\n             try {\n                 for (MetaDataIndexWriter metaDataIndexWriter : metaDataIndexWriters) {\n                     metaDataIndexWriter.commit(nodeId, currentTerm, lastAcceptedVersion);\n                 }\n-            } catch (IOException e) {\n-                // The commit() call has similar semantics to a fsync(): although it's atomic, if it fails then we've no idea whether the\n-                // data on disk is now the old version or the new version, and this is a disaster. It's safest to fail the whole node and\n-                // retry from the beginning.\n-                throw new IOError(e);\n+            } finally {\n+                closeIfAnyIndexWriterHasTragedyOrIsClosed();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c7eb4c7dc61c3bfc41e111b4d9c5313c43a3e5c"}, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTE4ODgyMw==", "bodyText": "I'm surprised we need to check for a tragic exception ourselves here, since the IndexWriter checks this already. Can you clarify?", "url": "https://github.com/elastic/elasticsearch/pull/50805#discussion_r365188823", "createdAt": "2020-01-10T11:21:27Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/gateway/PersistedClusterStateService.java", "diffHunk": "@@ -520,30 +521,62 @@ public void close() throws IOException {\n         private final BigArrays bigArrays;\n \n         boolean fullStateWritten = false;\n+        private final AtomicBoolean closed = new AtomicBoolean();\n \n         private Writer(List<MetaDataIndexWriter> metaDataIndexWriters, String nodeId, BigArrays bigArrays) {\n             this.metaDataIndexWriters = metaDataIndexWriters;\n             this.nodeId = nodeId;\n             this.bigArrays = bigArrays;\n         }\n \n+        private void ensureOpen() {\n+            if (closed.get()) {\n+                throw new AlreadyClosedException(\"cluster state writer is closed already\");\n+            }\n+        }\n+\n+        public boolean isOpen() {\n+            return closed.get() == false;\n+        }\n+\n+        private void closeIfAnyIndexWriterHasTragedyOrIsClosed() {\n+            if (metaDataIndexWriters.stream().map(writer -> writer.indexWriter)\n+                .anyMatch(iw -> iw.getTragicException() != null || iw.isOpen() == false)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c7eb4c7dc61c3bfc41e111b4d9c5313c43a3e5c"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTE5MDA4OQ==", "bodyText": "I'm surprised we need to check this, given that the caller has already checked we're open in reloadWriterIfNecessary(). Can you clarify?", "url": "https://github.com/elastic/elasticsearch/pull/50805#discussion_r365190089", "createdAt": "2020-01-10T11:25:06Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/gateway/PersistedClusterStateService.java", "diffHunk": "@@ -520,30 +521,62 @@ public void close() throws IOException {\n         private final BigArrays bigArrays;\n \n         boolean fullStateWritten = false;\n+        private final AtomicBoolean closed = new AtomicBoolean();\n \n         private Writer(List<MetaDataIndexWriter> metaDataIndexWriters, String nodeId, BigArrays bigArrays) {\n             this.metaDataIndexWriters = metaDataIndexWriters;\n             this.nodeId = nodeId;\n             this.bigArrays = bigArrays;\n         }\n \n+        private void ensureOpen() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c7eb4c7dc61c3bfc41e111b4d9c5313c43a3e5c"}, "originalPosition": 36}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "333f42a417882d3d34a3daf25788f5110ead26f1", "author": {"user": {"login": "ywelsch", "name": "Yannick Welsch"}}, "url": "https://github.com/elastic/elasticsearch/commit/333f42a417882d3d34a3daf25788f5110ead26f1", "committedDate": "2020-01-10T13:36:28Z", "message": "inline reloadWriterIfNecessary"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7082947b86ac9d95cf66b98c83025c03a84e892e", "author": {"user": {"login": "ywelsch", "name": "Yannick Welsch"}}, "url": "https://github.com/elastic/elasticsearch/commit/7082947b86ac9d95cf66b98c83025c03a84e892e", "committedDate": "2020-01-10T14:39:15Z", "message": "David likes crashes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "069730c015f3904309f961e5bf9946ec254c8394", "author": {"user": {"login": "ywelsch", "name": "Yannick Welsch"}}, "url": "https://github.com/elastic/elasticsearch/commit/069730c015f3904309f961e5bf9946ec254c8394", "committedDate": "2020-01-10T14:53:13Z", "message": "too fancy for Java"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQxMjE4MDA5", "url": "https://github.com/elastic/elasticsearch/pull/50805#pullrequestreview-341218009", "createdAt": "2020-01-10T15:02:04Z", "commit": {"oid": "069730c015f3904309f961e5bf9946ec254c8394"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNTowMjowNVrOFcWn3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNTowMjowNVrOFcWn3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTI3NTEwMw==", "bodyText": "Only throws an IOError if close() throws an exception?", "url": "https://github.com/elastic/elasticsearch/pull/50805#discussion_r365275103", "createdAt": "2020-01-10T15:02:05Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/gateway/PersistedClusterStateService.java", "diffHunk": "@@ -634,23 +672,48 @@ private void addMetaData(MetaData metaData) throws IOException {\n             }\n         }\n \n-        public void commit(long currentTerm, long lastAcceptedVersion) {\n+        public void commit(long currentTerm, long lastAcceptedVersion) throws IOException {\n+            ensureOpen();\n             try {\n                 for (MetaDataIndexWriter metaDataIndexWriter : metaDataIndexWriters) {\n-                    metaDataIndexWriter.commit(nodeId, currentTerm, lastAcceptedVersion);\n+                    metaDataIndexWriter.prepareCommit(nodeId, currentTerm, lastAcceptedVersion);\n+                }\n+            } catch (Exception e) {\n+                try {\n+                    close();\n+                } catch (Exception e2) {\n+                    logger.warn(\"failed on closing cluster state writer\", e2);\n+                    e.addSuppressed(e2);\n+                }\n+                throw e;\n+            } finally {\n+                closeIfAnyIndexWriterHasTragedyOrIsClosed();\n+            }\n+            try {\n+                for (MetaDataIndexWriter metaDataIndexWriter : metaDataIndexWriters) {\n+                    metaDataIndexWriter.commit();\n                 }\n             } catch (IOException e) {\n                 // The commit() call has similar semantics to a fsync(): although it's atomic, if it fails then we've no idea whether the\n                 // data on disk is now the old version or the new version, and this is a disaster. It's safest to fail the whole node and\n                 // retry from the beginning.\n-                throw new IOError(e);\n+                try {\n+                    close();\n+                } catch (Exception e2) {\n+                    e.addSuppressed(e2);\n+                    throw new IOError(e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "069730c015f3904309f961e5bf9946ec254c8394"}, "originalPosition": 139}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8a9c8641afa0abde44afd8cd70f46c07f4d5ca73", "author": {"user": {"login": "ywelsch", "name": "Yannick Welsch"}}, "url": "https://github.com/elastic/elasticsearch/commit/8a9c8641afa0abde44afd8cd70f46c07f4d5ca73", "committedDate": "2020-01-10T15:05:21Z", "message": "duh"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQxMjY2ODM3", "url": "https://github.com/elastic/elasticsearch/pull/50805#pullrequestreview-341266837", "createdAt": "2020-01-10T16:13:27Z", "commit": {"oid": "8a9c8641afa0abde44afd8cd70f46c07f4d5ca73"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNjoxMzoyN1rOFcY2dg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNjoxNTowOFrOFcY5kw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTMxMTYwNg==", "bodyText": "Maybe we should be asserting that it's open instead?", "url": "https://github.com/elastic/elasticsearch/pull/50805#discussion_r365311606", "createdAt": "2020-01-10T16:13:27Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/gateway/PersistedClusterStateService.java", "diffHunk": "@@ -520,30 +521,62 @@ public void close() throws IOException {\n         private final BigArrays bigArrays;\n \n         boolean fullStateWritten = false;\n+        private final AtomicBoolean closed = new AtomicBoolean();\n \n         private Writer(List<MetaDataIndexWriter> metaDataIndexWriters, String nodeId, BigArrays bigArrays) {\n             this.metaDataIndexWriters = metaDataIndexWriters;\n             this.nodeId = nodeId;\n             this.bigArrays = bigArrays;\n         }\n \n+        private void ensureOpen() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTE5MDA4OQ=="}, "originalCommit": {"oid": "1c7eb4c7dc61c3bfc41e111b4d9c5313c43a3e5c"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTMxMjQwMw==", "bodyText": "Ok I see what you mean, let's leave it like this. This is trappier than I expected.", "url": "https://github.com/elastic/elasticsearch/pull/50805#discussion_r365312403", "createdAt": "2020-01-10T16:15:08Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/gateway/PersistedClusterStateService.java", "diffHunk": "@@ -520,30 +521,62 @@ public void close() throws IOException {\n         private final BigArrays bigArrays;\n \n         boolean fullStateWritten = false;\n+        private final AtomicBoolean closed = new AtomicBoolean();\n \n         private Writer(List<MetaDataIndexWriter> metaDataIndexWriters, String nodeId, BigArrays bigArrays) {\n             this.metaDataIndexWriters = metaDataIndexWriters;\n             this.nodeId = nodeId;\n             this.bigArrays = bigArrays;\n         }\n \n+        private void ensureOpen() {\n+            if (closed.get()) {\n+                throw new AlreadyClosedException(\"cluster state writer is closed already\");\n+            }\n+        }\n+\n+        public boolean isOpen() {\n+            return closed.get() == false;\n+        }\n+\n+        private void closeIfAnyIndexWriterHasTragedyOrIsClosed() {\n+            if (metaDataIndexWriters.stream().map(writer -> writer.indexWriter)\n+                .anyMatch(iw -> iw.getTragicException() != null || iw.isOpen() == false)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTE4ODgyMw=="}, "originalCommit": {"oid": "1c7eb4c7dc61c3bfc41e111b4d9c5313c43a3e5c"}, "originalPosition": 48}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3709, "cost": 1, "resetAt": "2021-10-28T19:08:13Z"}}}