{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI3MzM3NjY3", "number": 57616, "title": "ILM add data stream support to the Shrink action", "bodyText": "The shrink action creates a shrunken index with the target number of shards.\nThis makes the shrink action data stream aware. If the ILM managed index is\npart of a data stream the shrink action will make sure to swap the original\nmanaged index with the shrunken one as part of the data stream's backing\nindices and then delete the original index.\nThis also relaxes the validation of data stream backing indices names to\nallow for prefixed indices.\nRelates to #53100", "createdAt": "2020-06-03T17:03:48Z", "url": "https://github.com/elastic/elasticsearch/pull/57616", "merged": true, "mergeCommit": {"oid": "99aeed6acf4ae7cbdd97a3bcfe54c5d37ab7a574"}, "closed": true, "closedAt": "2020-06-09T10:58:08Z", "author": {"login": "andreidan"}, "timelineItems": {"totalCount": 23, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcnsffigH2gAyNDI3MzM3NjY3OjdhYTRjOTdiODk0NGZhZjJjZWZiMGZhYzIzMTFkNDQ4NTkyOTkwZTY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcph1UcgH2gAyNDI3MzM3NjY3Ojg2YmZmMWQxZDViZmI5NTlkNGJmNDU2MjBlZmQ2MzI2YThhMzlmOWU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "7aa4c97b8944faf2cefb0fac2311d448592990e6", "author": {"user": {"login": "andreidan", "name": "Andrei Dan"}}, "url": "https://github.com/elastic/elasticsearch/commit/7aa4c97b8944faf2cefb0fac2311d448592990e6", "committedDate": "2020-06-03T16:59:21Z", "message": "ILM add data stream support to the Shrink action\n\nThe shrink action creates a shrunken index with the target number of shards.\nThis makes the shrink action data stream aware. If the ILM managed index is\npart of a data stream the shrink action will make sure to swap the original\nmanaged index with the shrunken one as part of the data stream's backing\nindices and then delete the original index.\n\nThis also relaxes the validation of data stream backing indices names to\nallow for prefixed indices."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e8937fa4a1980570d8730cd359646da642a14f22", "author": {"user": {"login": "andreidan", "name": "Andrei Dan"}}, "url": "https://github.com/elastic/elasticsearch/commit/e8937fa4a1980570d8730cd359646da642a14f22", "committedDate": "2020-06-03T17:14:43Z", "message": "Fix line length"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "93646c674e2bb2ebf13cbc118add1b99f7383c61", "author": {"user": {"login": "elasticmachine", "name": "Elastic Machine"}}, "url": "https://github.com/elastic/elasticsearch/commit/93646c674e2bb2ebf13cbc118add1b99f7383c61", "committedDate": "2020-06-03T18:30:00Z", "message": "Merge branch 'master' into ilm-shrink-datastream"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIzODIyMDky", "url": "https://github.com/elastic/elasticsearch/pull/57616#pullrequestreview-423822092", "createdAt": "2020-06-03T18:30:03Z", "commit": {"oid": "e8937fa4a1980570d8730cd359646da642a14f22"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QxODozMDowM1rOGeoVMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QxODozMDowM1rOGeoVMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc3MTI0OA==", "bodyText": "We can definitely relax the logic on the naming of backing indices, but I think the write index needs to stay the same. In other words, ILM may trigger a rollover which creates a new write index, but the current write index should always conform to the naming scheme and ILM should not shrink or otherwise modify that one.", "url": "https://github.com/elastic/elasticsearch/pull/57616#discussion_r434771248", "createdAt": "2020-06-03T18:30:03Z", "author": {"login": "danhermann"}, "path": "server/src/main/java/org/elasticsearch/cluster/metadata/DataStream.java", "diffHunk": "@@ -48,7 +48,7 @@ public DataStream(String name, String timeStampField, List<Index> indices, long\n         this.indices = indices;\n         this.generation = generation;\n         assert indices.size() > 0;\n-        assert indices.get(indices.size() - 1).getName().equals(getBackingIndexName(name, generation));\n+        assert indices.get(indices.size() - 1).getName().endsWith(getBackingIndexName(name, generation));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e8937fa4a1980570d8730cd359646da642a14f22"}, "originalPosition": 5}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "be54fb4b60d957d8500f527f88eacad84cf1fd65", "author": {"user": {"login": "elasticmachine", "name": "Elastic Machine"}}, "url": "https://github.com/elastic/elasticsearch/commit/be54fb4b60d957d8500f527f88eacad84cf1fd65", "committedDate": "2020-06-04T08:38:43Z", "message": "Merge branch 'master' into ilm-shrink-datastream"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9f1f8516b103aeb08cbc6898032fa50f069b6a1e", "author": {"user": {"login": "andreidan", "name": "Andrei Dan"}}, "url": "https://github.com/elastic/elasticsearch/commit/9f1f8516b103aeb08cbc6898032fa50f069b6a1e", "committedDate": "2020-06-04T13:39:40Z", "message": "Extract manual rollover api in the rest driver"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "17ffc98476fb5758bb156139fac3d1bc80639c84", "author": {"user": {"login": "andreidan", "name": "Andrei Dan"}}, "url": "https://github.com/elastic/elasticsearch/commit/17ffc98476fb5758bb156139fac3d1bc80639c84", "committedDate": "2020-06-04T13:39:40Z", "message": "Prohibit shrinking the write index"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2845d59edeaf13ff1cbfb6638878906dea939d99", "author": {"user": {"login": "andreidan", "name": "Andrei Dan"}}, "url": "https://github.com/elastic/elasticsearch/commit/2845d59edeaf13ff1cbfb6638878906dea939d99", "committedDate": "2020-06-04T13:50:03Z", "message": "Update assertion to not allow renaming of the write index"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8ce25f092845413761178ed8d3b6ce6e5a7d56d8", "author": {"user": {"login": "elasticmachine", "name": "Elastic Machine"}}, "url": "https://github.com/elastic/elasticsearch/commit/8ce25f092845413761178ed8d3b6ce6e5a7d56d8", "committedDate": "2020-06-04T13:54:44Z", "message": "Merge branch 'master' into ilm-shrink-datastream"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8dde7af20939177307ffc4fce883d61899d18062", "author": {"user": {"login": "andreidan", "name": "Andrei Dan"}}, "url": "https://github.com/elastic/elasticsearch/commit/8dde7af20939177307ffc4fce883d61899d18062", "committedDate": "2020-06-04T14:18:31Z", "message": "Fix line length"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "96857c086a5e0ce8fdab6e9eb473144eab036c1a", "author": {"user": {"login": "andreidan", "name": "Andrei Dan"}}, "url": "https://github.com/elastic/elasticsearch/commit/96857c086a5e0ce8fdab6e9eb473144eab036c1a", "committedDate": "2020-06-04T17:09:10Z", "message": "Extract `createFullPolicy` into TimeSeriesRestDriver"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0ab909d960da5e44c78db1bf9d2309df57944b4f", "author": {"user": {"login": "andreidan", "name": "Andrei Dan"}}, "url": "https://github.com/elastic/elasticsearch/commit/0ab909d960da5e44c78db1bf9d2309df57944b4f", "committedDate": "2020-06-04T17:15:23Z", "message": "Validate write index target on first conditional shrink step"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI0Njc5NDA0", "url": "https://github.com/elastic/elasticsearch/pull/57616#pullrequestreview-424679404", "createdAt": "2020-06-04T17:37:56Z", "commit": {"oid": "0ab909d960da5e44c78db1bf9d2309df57944b4f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQxNzozNzo1NlrOGfQsew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQxNzozNzo1NlrOGfQsew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQzMjU3MQ==", "bodyText": "we still need to be lenient here as, in the case where we're replacing a backing index with one that has a prefix, the source backing index will be detected as a conflict (it'll usually be the case, thinking of shrinking and searchable snapshot indices, that we'll promptly delete the source backing index so this is a temporary state)", "url": "https://github.com/elastic/elasticsearch/pull/57616#discussion_r435432571", "createdAt": "2020-06-04T17:37:56Z", "author": {"login": "andreidan"}, "path": "server/src/main/java/org/elasticsearch/cluster/metadata/Metadata.java", "diffHunk": "@@ -1463,7 +1463,7 @@ private void validateDataStreams(SortedMap<String, IndexAbstraction> indicesLook\n                         List<String> conflicts = new ArrayList<>();\n                         for (Map.Entry<String, IndexAbstraction> entry : potentialConflicts.entrySet()) {\n                             if (entry.getValue().getType() != IndexAbstraction.Type.CONCRETE_INDEX ||\n-                                indexNames.contains(entry.getKey()) == false) {\n+                                indexNames.stream().noneMatch(name -> name.endsWith(entry.getKey()))) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ab909d960da5e44c78db1bf9d2309df57944b4f"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI0Njc5NjYw", "url": "https://github.com/elastic/elasticsearch/pull/57616#pullrequestreview-424679660", "createdAt": "2020-06-04T17:38:16Z", "commit": {"oid": "0ab909d960da5e44c78db1bf9d2309df57944b4f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQxNzozODoxNlrOGfQtTA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQxNzozODoxNlrOGfQtTA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQzMjc4MA==", "bodyText": "this is just formatting", "url": "https://github.com/elastic/elasticsearch/pull/57616#discussion_r435432780", "createdAt": "2020-06-04T17:38:16Z", "author": {"login": "andreidan"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ilm/BranchingStep.java", "diffHunk": "@@ -49,17 +49,22 @@ public BranchingStep(StepKey key, StepKey nextStepKeyOnFalse, StepKey nextStepKe\n         this.predicateValue = new SetOnce<>();\n     }\n \n-   @Override\n-   public ClusterState performAction(Index index, ClusterState clusterState) {\n-       IndexMetadata indexMetadata = clusterState.metadata().index(index);\n-       if (indexMetadata == null) {\n-           // Index must have been since deleted, ignore it\n-           logger.debug(\"[{}] lifecycle action for index [{}] executed but index no longer exists\", getKey().getAction(), index.getName());\n-           return clusterState;\n-       }\n-       predicateValue.set(predicate.test(index, clusterState));\n-       return clusterState;\n-   }\n+    @Override\n+    public boolean isRetryable() {\n+        return true;\n+    }\n+\n+    @Override\n+    public ClusterState performAction(Index index, ClusterState clusterState) {\n+        IndexMetadata indexMetadata = clusterState.metadata().index(index);\n+        if (indexMetadata == null) {\n+            // Index must have been since deleted, ignore it\n+            logger.debug(\"[{}] lifecycle action for index [{}] executed but index no longer exists\", getKey().getAction(), index.getName());\n+            return clusterState;\n+        }\n+        predicateValue.set(predicate.test(index, clusterState));\n+        return clusterState;\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ab909d960da5e44c78db1bf9d2309df57944b4f"}, "originalPosition": 30}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI0ODcxNjc5", "url": "https://github.com/elastic/elasticsearch/pull/57616#pullrequestreview-424871679", "createdAt": "2020-06-04T22:13:19Z", "commit": {"oid": "0ab909d960da5e44c78db1bf9d2309df57944b4f"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQyMjoxMzoxOVrOGfZyxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQyMjozMzo1NVrOGfaPHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4MTYzNg==", "bodyText": "This code is a bit difficult to read (in that it's difficult for me to understand what we're validating, and also exactly what we're checking for), I think some comments would be really helpful to signal behavior and intent, can you add comments for this (especially so it doesn't get reverted in the future)?", "url": "https://github.com/elastic/elasticsearch/pull/57616#discussion_r435581636", "createdAt": "2020-06-04T22:13:19Z", "author": {"login": "dakrone"}, "path": "server/src/main/java/org/elasticsearch/cluster/metadata/Metadata.java", "diffHunk": "@@ -1463,7 +1463,7 @@ private void validateDataStreams(SortedMap<String, IndexAbstraction> indicesLook\n                         List<String> conflicts = new ArrayList<>();\n                         for (Map.Entry<String, IndexAbstraction> entry : potentialConflicts.entrySet()) {\n                             if (entry.getValue().getType() != IndexAbstraction.Type.CONCRETE_INDEX ||\n-                                indexNames.contains(entry.getKey()) == false) {\n+                                indexNames.stream().noneMatch(name -> name.endsWith(entry.getKey()))) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQzMjU3MQ=="}, "originalCommit": {"oid": "0ab909d960da5e44c78db1bf9d2309df57944b4f"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4Mzg3OA==", "bodyText": "I think just to be safe we need a null check for these two here, probably with a better message than an NPE further down the line", "url": "https://github.com/elastic/elasticsearch/pull/57616#discussion_r435583878", "createdAt": "2020-06-04T22:19:33Z", "author": {"login": "dakrone"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ilm/ReplaceDataStreamBackingIndexStep.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ilm;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexAbstraction;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.index.Index;\n+\n+import java.util.Locale;\n+import java.util.Objects;\n+\n+/**\n+ * This step replaces a data stream backing index with the target index, as part of the data stream's backing indices.\n+ * Eg. if data stream `foo-stream` is backed by indices [`foo-stream-000001`, `foo-stream-000002`] and we'd like to replace the first\n+ * generation index, `foo-stream-000001`, with `shrink-foo-stream-000001`, after this step the `foo-stream` data stream will contain\n+ * the following indices\n+ * <p>\n+ * [`shrink-foo-stream-000001`, `foo-stream-000002`]\n+ * <p>\n+ * The `foo-stream-000001` index will continue to exist but will not be part of the data stream anymore.\n+ * <p>\n+ * As the last generation is the write index of the data stream, replacing the last generation index is not allowed.\n+ * <p>\n+ * This is useful in scenarios following a restore from snapshot operation where the restored index will take the place of the source\n+ * index in the ILM lifecycle or in the case where we shrink an index and the shrunk index will take the place of the original index.\n+ */\n+public class ReplaceDataStreamBackingIndexStep extends ClusterStateActionStep {\n+    public static final String NAME = \"replace-datastream-backing-index\";\n+    private static final Logger logger = LogManager.getLogger(ReplaceDataStreamBackingIndexStep.class);\n+\n+    private final String targetIndexPrefix;\n+\n+    public ReplaceDataStreamBackingIndexStep(StepKey key, StepKey nextStepKey, String targetIndexPrefix) {\n+        super(key, nextStepKey);\n+        this.targetIndexPrefix = targetIndexPrefix;\n+    }\n+\n+    @Override\n+    public boolean isRetryable() {\n+        return true;\n+    }\n+\n+    public String getTargetIndexPrefix() {\n+        return targetIndexPrefix;\n+    }\n+\n+    @Override\n+    public ClusterState performAction(Index index, ClusterState clusterState) {\n+        String originalIndex = index.getName();\n+        final String targetIndexName = targetIndexPrefix + originalIndex;\n+        IndexMetadata targetIndexMetadata = clusterState.metadata().index(targetIndexName);\n+\n+        IndexMetadata originalIndexMetadata = clusterState.metadata().index(index);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ab909d960da5e44c78db1bf9d2309df57944b4f"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4NDc1Nw==", "bodyText": "Ah I see you already have a null check for the target, we should check the original also (and maybe move the existing null check up here so it doesn't accidentally get used and cause an NPE?)", "url": "https://github.com/elastic/elasticsearch/pull/57616#discussion_r435584757", "createdAt": "2020-06-04T22:22:04Z", "author": {"login": "dakrone"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ilm/ReplaceDataStreamBackingIndexStep.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ilm;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexAbstraction;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.index.Index;\n+\n+import java.util.Locale;\n+import java.util.Objects;\n+\n+/**\n+ * This step replaces a data stream backing index with the target index, as part of the data stream's backing indices.\n+ * Eg. if data stream `foo-stream` is backed by indices [`foo-stream-000001`, `foo-stream-000002`] and we'd like to replace the first\n+ * generation index, `foo-stream-000001`, with `shrink-foo-stream-000001`, after this step the `foo-stream` data stream will contain\n+ * the following indices\n+ * <p>\n+ * [`shrink-foo-stream-000001`, `foo-stream-000002`]\n+ * <p>\n+ * The `foo-stream-000001` index will continue to exist but will not be part of the data stream anymore.\n+ * <p>\n+ * As the last generation is the write index of the data stream, replacing the last generation index is not allowed.\n+ * <p>\n+ * This is useful in scenarios following a restore from snapshot operation where the restored index will take the place of the source\n+ * index in the ILM lifecycle or in the case where we shrink an index and the shrunk index will take the place of the original index.\n+ */\n+public class ReplaceDataStreamBackingIndexStep extends ClusterStateActionStep {\n+    public static final String NAME = \"replace-datastream-backing-index\";\n+    private static final Logger logger = LogManager.getLogger(ReplaceDataStreamBackingIndexStep.class);\n+\n+    private final String targetIndexPrefix;\n+\n+    public ReplaceDataStreamBackingIndexStep(StepKey key, StepKey nextStepKey, String targetIndexPrefix) {\n+        super(key, nextStepKey);\n+        this.targetIndexPrefix = targetIndexPrefix;\n+    }\n+\n+    @Override\n+    public boolean isRetryable() {\n+        return true;\n+    }\n+\n+    public String getTargetIndexPrefix() {\n+        return targetIndexPrefix;\n+    }\n+\n+    @Override\n+    public ClusterState performAction(Index index, ClusterState clusterState) {\n+        String originalIndex = index.getName();\n+        final String targetIndexName = targetIndexPrefix + originalIndex;\n+        IndexMetadata targetIndexMetadata = clusterState.metadata().index(targetIndexName);\n+\n+        IndexMetadata originalIndexMetadata = clusterState.metadata().index(index);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4Mzg3OA=="}, "originalCommit": {"oid": "0ab909d960da5e44c78db1bf9d2309df57944b4f"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4NTY5Ng==", "bodyText": "We usually have a null check here for indices that have been deleted immediately prior to this execution", "url": "https://github.com/elastic/elasticsearch/pull/57616#discussion_r435585696", "createdAt": "2020-06-04T22:24:59Z", "author": {"login": "dakrone"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ilm/ShrinkAction.java", "diffHunk": "@@ -85,31 +96,77 @@ public boolean isSafeAction() {\n     public List<Step> toSteps(Client client, String phase, Step.StepKey nextStepKey) {\n         Settings readOnlySettings = Settings.builder().put(IndexMetadata.SETTING_BLOCKS_WRITE, true).build();\n \n-        StepKey branchingKey = new StepKey(phase, NAME, BranchingStep.NAME);\n+        StepKey preShrinkBranchingKey = new StepKey(phase, NAME, CONDITIONAL_SKIP_SHRINK_STEP);\n         StepKey waitForNoFollowerStepKey = new StepKey(phase, NAME, WaitForNoFollowersStep.NAME);\n         StepKey readOnlyKey = new StepKey(phase, NAME, ReadOnlyAction.NAME);\n         StepKey setSingleNodeKey = new StepKey(phase, NAME, SetSingleNodeAllocateStep.NAME);\n         StepKey allocationRoutedKey = new StepKey(phase, NAME, CheckShrinkReadyStep.NAME);\n         StepKey shrinkKey = new StepKey(phase, NAME, ShrinkStep.NAME);\n         StepKey enoughShardsKey = new StepKey(phase, NAME, ShrunkShardsAllocatedStep.NAME);\n         StepKey copyMetadataKey = new StepKey(phase, NAME, CopyExecutionStateStep.NAME);\n+        StepKey dataStreamCheckBranchingKey = new StepKey(phase, NAME, CONDITIONAL_DATASTREAM_CHECK_KEY);\n         StepKey aliasKey = new StepKey(phase, NAME, ShrinkSetAliasStep.NAME);\n         StepKey isShrunkIndexKey = new StepKey(phase, NAME, ShrunkenIndexCheckStep.NAME);\n+        StepKey replaceDataStreamIndexKey = new StepKey(phase, NAME, ReplaceDataStreamBackingIndexStep.NAME);\n+        StepKey deleteIndexKey = new StepKey(phase, NAME, DeleteStep.NAME);\n \n-        BranchingStep conditionalSkipShrinkStep = new BranchingStep(branchingKey, waitForNoFollowerStepKey, nextStepKey,\n-            (index, clusterState) -> clusterState.getMetadata().index(index).getNumberOfShards() == numberOfShards);\n+        BranchingStep conditionalSkipShrinkStep = new BranchingStep(preShrinkBranchingKey, waitForNoFollowerStepKey, nextStepKey,\n+            getSkipShrinkStepPredicate(numberOfShards));\n         WaitForNoFollowersStep waitForNoFollowersStep = new WaitForNoFollowersStep(waitForNoFollowerStepKey, readOnlyKey, client);\n         UpdateSettingsStep readOnlyStep = new UpdateSettingsStep(readOnlyKey, setSingleNodeKey, client, readOnlySettings);\n         SetSingleNodeAllocateStep setSingleNodeStep = new SetSingleNodeAllocateStep(setSingleNodeKey, allocationRoutedKey, client);\n         CheckShrinkReadyStep checkShrinkReadyStep = new CheckShrinkReadyStep(allocationRoutedKey, shrinkKey);\n         ShrinkStep shrink = new ShrinkStep(shrinkKey, enoughShardsKey, client, numberOfShards, SHRUNKEN_INDEX_PREFIX);\n         ShrunkShardsAllocatedStep allocated = new ShrunkShardsAllocatedStep(enoughShardsKey, copyMetadataKey, SHRUNKEN_INDEX_PREFIX);\n-        CopyExecutionStateStep copyMetadata = new CopyExecutionStateStep(copyMetadataKey, aliasKey, SHRUNKEN_INDEX_PREFIX,\n-            ShrunkenIndexCheckStep.NAME);\n+        CopyExecutionStateStep copyMetadata = new CopyExecutionStateStep(copyMetadataKey, dataStreamCheckBranchingKey,\n+            SHRUNKEN_INDEX_PREFIX, ShrunkenIndexCheckStep.NAME);\n+        // by the time we get to this step we have 2 indices, the source and the shrunken one. we now need to choose an index\n+        // swapping strategy such that the shrunken index takes the place of the source index (which is also deleted).\n+        // if the source index is part of a data stream it's a matter of replacing it with the shrunken index one in the data stream and\n+        // then deleting the source index; otherwise we'll use the alias management api to atomically transfer the aliases from source to\n+        // the shrunken index and delete the source\n+        BranchingStep isDataStreamBranchingStep = new BranchingStep(dataStreamCheckBranchingKey, aliasKey, replaceDataStreamIndexKey,\n+            (index, clusterState) -> {\n+                IndexAbstraction indexAbstraction = clusterState.metadata().getIndicesLookup().get(index.getName());\n+                assert indexAbstraction != null : \"invalid cluster metadata. index [\" + index.getName() + \"] was not found\";\n+                return indexAbstraction.getParentDataStream() != null;\n+            });\n         ShrinkSetAliasStep aliasSwapAndDelete = new ShrinkSetAliasStep(aliasKey, isShrunkIndexKey, client, SHRUNKEN_INDEX_PREFIX);\n+        ReplaceDataStreamBackingIndexStep replaceDataStreamBackingIndex = new ReplaceDataStreamBackingIndexStep(replaceDataStreamIndexKey,\n+            deleteIndexKey, SHRUNKEN_INDEX_PREFIX);\n+        DeleteStep deleteSourceIndexStep = new DeleteStep(deleteIndexKey, isShrunkIndexKey, client);\n         ShrunkenIndexCheckStep waitOnShrinkTakeover = new ShrunkenIndexCheckStep(isShrunkIndexKey, nextStepKey, SHRUNKEN_INDEX_PREFIX);\n         return Arrays.asList(conditionalSkipShrinkStep, waitForNoFollowersStep, readOnlyStep, setSingleNodeStep, checkShrinkReadyStep,\n-            shrink, allocated, copyMetadata, aliasSwapAndDelete, waitOnShrinkTakeover);\n+            shrink, allocated, copyMetadata, isDataStreamBranchingStep, aliasSwapAndDelete, waitOnShrinkTakeover,\n+            replaceDataStreamBackingIndex, deleteSourceIndexStep);\n+    }\n+\n+    static BiPredicate<Index, ClusterState> getSkipShrinkStepPredicate(int targetNumberOfShards) {\n+        return (index, clusterState) -> {\n+            IndexMetadata indexMetadata = clusterState.getMetadata().index(index);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ab909d960da5e44c78db1bf9d2309df57944b4f"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4NjIxNg==", "bodyText": "I think rather than wrapping and all that, you can do:\nif (indexMetadata.getNumberOfShards() == targetNumberOfShards) {\n    return true;\n}\n\nAnd then not have to wrap the below parts", "url": "https://github.com/elastic/elasticsearch/pull/57616#discussion_r435586216", "createdAt": "2020-06-04T22:26:27Z", "author": {"login": "dakrone"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ilm/ShrinkAction.java", "diffHunk": "@@ -85,31 +96,77 @@ public boolean isSafeAction() {\n     public List<Step> toSteps(Client client, String phase, Step.StepKey nextStepKey) {\n         Settings readOnlySettings = Settings.builder().put(IndexMetadata.SETTING_BLOCKS_WRITE, true).build();\n \n-        StepKey branchingKey = new StepKey(phase, NAME, BranchingStep.NAME);\n+        StepKey preShrinkBranchingKey = new StepKey(phase, NAME, CONDITIONAL_SKIP_SHRINK_STEP);\n         StepKey waitForNoFollowerStepKey = new StepKey(phase, NAME, WaitForNoFollowersStep.NAME);\n         StepKey readOnlyKey = new StepKey(phase, NAME, ReadOnlyAction.NAME);\n         StepKey setSingleNodeKey = new StepKey(phase, NAME, SetSingleNodeAllocateStep.NAME);\n         StepKey allocationRoutedKey = new StepKey(phase, NAME, CheckShrinkReadyStep.NAME);\n         StepKey shrinkKey = new StepKey(phase, NAME, ShrinkStep.NAME);\n         StepKey enoughShardsKey = new StepKey(phase, NAME, ShrunkShardsAllocatedStep.NAME);\n         StepKey copyMetadataKey = new StepKey(phase, NAME, CopyExecutionStateStep.NAME);\n+        StepKey dataStreamCheckBranchingKey = new StepKey(phase, NAME, CONDITIONAL_DATASTREAM_CHECK_KEY);\n         StepKey aliasKey = new StepKey(phase, NAME, ShrinkSetAliasStep.NAME);\n         StepKey isShrunkIndexKey = new StepKey(phase, NAME, ShrunkenIndexCheckStep.NAME);\n+        StepKey replaceDataStreamIndexKey = new StepKey(phase, NAME, ReplaceDataStreamBackingIndexStep.NAME);\n+        StepKey deleteIndexKey = new StepKey(phase, NAME, DeleteStep.NAME);\n \n-        BranchingStep conditionalSkipShrinkStep = new BranchingStep(branchingKey, waitForNoFollowerStepKey, nextStepKey,\n-            (index, clusterState) -> clusterState.getMetadata().index(index).getNumberOfShards() == numberOfShards);\n+        BranchingStep conditionalSkipShrinkStep = new BranchingStep(preShrinkBranchingKey, waitForNoFollowerStepKey, nextStepKey,\n+            getSkipShrinkStepPredicate(numberOfShards));\n         WaitForNoFollowersStep waitForNoFollowersStep = new WaitForNoFollowersStep(waitForNoFollowerStepKey, readOnlyKey, client);\n         UpdateSettingsStep readOnlyStep = new UpdateSettingsStep(readOnlyKey, setSingleNodeKey, client, readOnlySettings);\n         SetSingleNodeAllocateStep setSingleNodeStep = new SetSingleNodeAllocateStep(setSingleNodeKey, allocationRoutedKey, client);\n         CheckShrinkReadyStep checkShrinkReadyStep = new CheckShrinkReadyStep(allocationRoutedKey, shrinkKey);\n         ShrinkStep shrink = new ShrinkStep(shrinkKey, enoughShardsKey, client, numberOfShards, SHRUNKEN_INDEX_PREFIX);\n         ShrunkShardsAllocatedStep allocated = new ShrunkShardsAllocatedStep(enoughShardsKey, copyMetadataKey, SHRUNKEN_INDEX_PREFIX);\n-        CopyExecutionStateStep copyMetadata = new CopyExecutionStateStep(copyMetadataKey, aliasKey, SHRUNKEN_INDEX_PREFIX,\n-            ShrunkenIndexCheckStep.NAME);\n+        CopyExecutionStateStep copyMetadata = new CopyExecutionStateStep(copyMetadataKey, dataStreamCheckBranchingKey,\n+            SHRUNKEN_INDEX_PREFIX, ShrunkenIndexCheckStep.NAME);\n+        // by the time we get to this step we have 2 indices, the source and the shrunken one. we now need to choose an index\n+        // swapping strategy such that the shrunken index takes the place of the source index (which is also deleted).\n+        // if the source index is part of a data stream it's a matter of replacing it with the shrunken index one in the data stream and\n+        // then deleting the source index; otherwise we'll use the alias management api to atomically transfer the aliases from source to\n+        // the shrunken index and delete the source\n+        BranchingStep isDataStreamBranchingStep = new BranchingStep(dataStreamCheckBranchingKey, aliasKey, replaceDataStreamIndexKey,\n+            (index, clusterState) -> {\n+                IndexAbstraction indexAbstraction = clusterState.metadata().getIndicesLookup().get(index.getName());\n+                assert indexAbstraction != null : \"invalid cluster metadata. index [\" + index.getName() + \"] was not found\";\n+                return indexAbstraction.getParentDataStream() != null;\n+            });\n         ShrinkSetAliasStep aliasSwapAndDelete = new ShrinkSetAliasStep(aliasKey, isShrunkIndexKey, client, SHRUNKEN_INDEX_PREFIX);\n+        ReplaceDataStreamBackingIndexStep replaceDataStreamBackingIndex = new ReplaceDataStreamBackingIndexStep(replaceDataStreamIndexKey,\n+            deleteIndexKey, SHRUNKEN_INDEX_PREFIX);\n+        DeleteStep deleteSourceIndexStep = new DeleteStep(deleteIndexKey, isShrunkIndexKey, client);\n         ShrunkenIndexCheckStep waitOnShrinkTakeover = new ShrunkenIndexCheckStep(isShrunkIndexKey, nextStepKey, SHRUNKEN_INDEX_PREFIX);\n         return Arrays.asList(conditionalSkipShrinkStep, waitForNoFollowersStep, readOnlyStep, setSingleNodeStep, checkShrinkReadyStep,\n-            shrink, allocated, copyMetadata, aliasSwapAndDelete, waitOnShrinkTakeover);\n+            shrink, allocated, copyMetadata, isDataStreamBranchingStep, aliasSwapAndDelete, waitOnShrinkTakeover,\n+            replaceDataStreamBackingIndex, deleteSourceIndexStep);\n+    }\n+\n+    static BiPredicate<Index, ClusterState> getSkipShrinkStepPredicate(int targetNumberOfShards) {\n+        return (index, clusterState) -> {\n+            IndexMetadata indexMetadata = clusterState.getMetadata().index(index);\n+            boolean skipShrink = indexMetadata.getNumberOfShards() == targetNumberOfShards;\n+\n+            if (skipShrink == false) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ab909d960da5e44c78db1bf9d2309df57944b4f"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4NzExNg==", "bodyText": "I think this can happen if the index was deleted, it would be good to check whether the index's metadata still exists in the cluster state, and just moving on otherwise (we have this check in our other ClusterStateActionSteps)", "url": "https://github.com/elastic/elasticsearch/pull/57616#discussion_r435587116", "createdAt": "2020-06-04T22:29:04Z", "author": {"login": "dakrone"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ilm/ShrinkAction.java", "diffHunk": "@@ -85,31 +96,77 @@ public boolean isSafeAction() {\n     public List<Step> toSteps(Client client, String phase, Step.StepKey nextStepKey) {\n         Settings readOnlySettings = Settings.builder().put(IndexMetadata.SETTING_BLOCKS_WRITE, true).build();\n \n-        StepKey branchingKey = new StepKey(phase, NAME, BranchingStep.NAME);\n+        StepKey preShrinkBranchingKey = new StepKey(phase, NAME, CONDITIONAL_SKIP_SHRINK_STEP);\n         StepKey waitForNoFollowerStepKey = new StepKey(phase, NAME, WaitForNoFollowersStep.NAME);\n         StepKey readOnlyKey = new StepKey(phase, NAME, ReadOnlyAction.NAME);\n         StepKey setSingleNodeKey = new StepKey(phase, NAME, SetSingleNodeAllocateStep.NAME);\n         StepKey allocationRoutedKey = new StepKey(phase, NAME, CheckShrinkReadyStep.NAME);\n         StepKey shrinkKey = new StepKey(phase, NAME, ShrinkStep.NAME);\n         StepKey enoughShardsKey = new StepKey(phase, NAME, ShrunkShardsAllocatedStep.NAME);\n         StepKey copyMetadataKey = new StepKey(phase, NAME, CopyExecutionStateStep.NAME);\n+        StepKey dataStreamCheckBranchingKey = new StepKey(phase, NAME, CONDITIONAL_DATASTREAM_CHECK_KEY);\n         StepKey aliasKey = new StepKey(phase, NAME, ShrinkSetAliasStep.NAME);\n         StepKey isShrunkIndexKey = new StepKey(phase, NAME, ShrunkenIndexCheckStep.NAME);\n+        StepKey replaceDataStreamIndexKey = new StepKey(phase, NAME, ReplaceDataStreamBackingIndexStep.NAME);\n+        StepKey deleteIndexKey = new StepKey(phase, NAME, DeleteStep.NAME);\n \n-        BranchingStep conditionalSkipShrinkStep = new BranchingStep(branchingKey, waitForNoFollowerStepKey, nextStepKey,\n-            (index, clusterState) -> clusterState.getMetadata().index(index).getNumberOfShards() == numberOfShards);\n+        BranchingStep conditionalSkipShrinkStep = new BranchingStep(preShrinkBranchingKey, waitForNoFollowerStepKey, nextStepKey,\n+            getSkipShrinkStepPredicate(numberOfShards));\n         WaitForNoFollowersStep waitForNoFollowersStep = new WaitForNoFollowersStep(waitForNoFollowerStepKey, readOnlyKey, client);\n         UpdateSettingsStep readOnlyStep = new UpdateSettingsStep(readOnlyKey, setSingleNodeKey, client, readOnlySettings);\n         SetSingleNodeAllocateStep setSingleNodeStep = new SetSingleNodeAllocateStep(setSingleNodeKey, allocationRoutedKey, client);\n         CheckShrinkReadyStep checkShrinkReadyStep = new CheckShrinkReadyStep(allocationRoutedKey, shrinkKey);\n         ShrinkStep shrink = new ShrinkStep(shrinkKey, enoughShardsKey, client, numberOfShards, SHRUNKEN_INDEX_PREFIX);\n         ShrunkShardsAllocatedStep allocated = new ShrunkShardsAllocatedStep(enoughShardsKey, copyMetadataKey, SHRUNKEN_INDEX_PREFIX);\n-        CopyExecutionStateStep copyMetadata = new CopyExecutionStateStep(copyMetadataKey, aliasKey, SHRUNKEN_INDEX_PREFIX,\n-            ShrunkenIndexCheckStep.NAME);\n+        CopyExecutionStateStep copyMetadata = new CopyExecutionStateStep(copyMetadataKey, dataStreamCheckBranchingKey,\n+            SHRUNKEN_INDEX_PREFIX, ShrunkenIndexCheckStep.NAME);\n+        // by the time we get to this step we have 2 indices, the source and the shrunken one. we now need to choose an index\n+        // swapping strategy such that the shrunken index takes the place of the source index (which is also deleted).\n+        // if the source index is part of a data stream it's a matter of replacing it with the shrunken index one in the data stream and\n+        // then deleting the source index; otherwise we'll use the alias management api to atomically transfer the aliases from source to\n+        // the shrunken index and delete the source\n+        BranchingStep isDataStreamBranchingStep = new BranchingStep(dataStreamCheckBranchingKey, aliasKey, replaceDataStreamIndexKey,\n+            (index, clusterState) -> {\n+                IndexAbstraction indexAbstraction = clusterState.metadata().getIndicesLookup().get(index.getName());\n+                assert indexAbstraction != null : \"invalid cluster metadata. index [\" + index.getName() + \"] was not found\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ab909d960da5e44c78db1bf9d2309df57944b4f"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4ODg5NA==", "bodyText": "I think (but I'm not sure), that this might fail for the alias case, because the index will already have been deleted in the ShrinkSetAliasStep, so we may need changes in DeleteStep to ignore deleting an index that doesn't exist", "url": "https://github.com/elastic/elasticsearch/pull/57616#discussion_r435588894", "createdAt": "2020-06-04T22:33:55Z", "author": {"login": "dakrone"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ilm/ShrinkAction.java", "diffHunk": "@@ -85,31 +96,77 @@ public boolean isSafeAction() {\n     public List<Step> toSteps(Client client, String phase, Step.StepKey nextStepKey) {\n         Settings readOnlySettings = Settings.builder().put(IndexMetadata.SETTING_BLOCKS_WRITE, true).build();\n \n-        StepKey branchingKey = new StepKey(phase, NAME, BranchingStep.NAME);\n+        StepKey preShrinkBranchingKey = new StepKey(phase, NAME, CONDITIONAL_SKIP_SHRINK_STEP);\n         StepKey waitForNoFollowerStepKey = new StepKey(phase, NAME, WaitForNoFollowersStep.NAME);\n         StepKey readOnlyKey = new StepKey(phase, NAME, ReadOnlyAction.NAME);\n         StepKey setSingleNodeKey = new StepKey(phase, NAME, SetSingleNodeAllocateStep.NAME);\n         StepKey allocationRoutedKey = new StepKey(phase, NAME, CheckShrinkReadyStep.NAME);\n         StepKey shrinkKey = new StepKey(phase, NAME, ShrinkStep.NAME);\n         StepKey enoughShardsKey = new StepKey(phase, NAME, ShrunkShardsAllocatedStep.NAME);\n         StepKey copyMetadataKey = new StepKey(phase, NAME, CopyExecutionStateStep.NAME);\n+        StepKey dataStreamCheckBranchingKey = new StepKey(phase, NAME, CONDITIONAL_DATASTREAM_CHECK_KEY);\n         StepKey aliasKey = new StepKey(phase, NAME, ShrinkSetAliasStep.NAME);\n         StepKey isShrunkIndexKey = new StepKey(phase, NAME, ShrunkenIndexCheckStep.NAME);\n+        StepKey replaceDataStreamIndexKey = new StepKey(phase, NAME, ReplaceDataStreamBackingIndexStep.NAME);\n+        StepKey deleteIndexKey = new StepKey(phase, NAME, DeleteStep.NAME);\n \n-        BranchingStep conditionalSkipShrinkStep = new BranchingStep(branchingKey, waitForNoFollowerStepKey, nextStepKey,\n-            (index, clusterState) -> clusterState.getMetadata().index(index).getNumberOfShards() == numberOfShards);\n+        BranchingStep conditionalSkipShrinkStep = new BranchingStep(preShrinkBranchingKey, waitForNoFollowerStepKey, nextStepKey,\n+            getSkipShrinkStepPredicate(numberOfShards));\n         WaitForNoFollowersStep waitForNoFollowersStep = new WaitForNoFollowersStep(waitForNoFollowerStepKey, readOnlyKey, client);\n         UpdateSettingsStep readOnlyStep = new UpdateSettingsStep(readOnlyKey, setSingleNodeKey, client, readOnlySettings);\n         SetSingleNodeAllocateStep setSingleNodeStep = new SetSingleNodeAllocateStep(setSingleNodeKey, allocationRoutedKey, client);\n         CheckShrinkReadyStep checkShrinkReadyStep = new CheckShrinkReadyStep(allocationRoutedKey, shrinkKey);\n         ShrinkStep shrink = new ShrinkStep(shrinkKey, enoughShardsKey, client, numberOfShards, SHRUNKEN_INDEX_PREFIX);\n         ShrunkShardsAllocatedStep allocated = new ShrunkShardsAllocatedStep(enoughShardsKey, copyMetadataKey, SHRUNKEN_INDEX_PREFIX);\n-        CopyExecutionStateStep copyMetadata = new CopyExecutionStateStep(copyMetadataKey, aliasKey, SHRUNKEN_INDEX_PREFIX,\n-            ShrunkenIndexCheckStep.NAME);\n+        CopyExecutionStateStep copyMetadata = new CopyExecutionStateStep(copyMetadataKey, dataStreamCheckBranchingKey,\n+            SHRUNKEN_INDEX_PREFIX, ShrunkenIndexCheckStep.NAME);\n+        // by the time we get to this step we have 2 indices, the source and the shrunken one. we now need to choose an index\n+        // swapping strategy such that the shrunken index takes the place of the source index (which is also deleted).\n+        // if the source index is part of a data stream it's a matter of replacing it with the shrunken index one in the data stream and\n+        // then deleting the source index; otherwise we'll use the alias management api to atomically transfer the aliases from source to\n+        // the shrunken index and delete the source\n+        BranchingStep isDataStreamBranchingStep = new BranchingStep(dataStreamCheckBranchingKey, aliasKey, replaceDataStreamIndexKey,\n+            (index, clusterState) -> {\n+                IndexAbstraction indexAbstraction = clusterState.metadata().getIndicesLookup().get(index.getName());\n+                assert indexAbstraction != null : \"invalid cluster metadata. index [\" + index.getName() + \"] was not found\";\n+                return indexAbstraction.getParentDataStream() != null;\n+            });\n         ShrinkSetAliasStep aliasSwapAndDelete = new ShrinkSetAliasStep(aliasKey, isShrunkIndexKey, client, SHRUNKEN_INDEX_PREFIX);\n+        ReplaceDataStreamBackingIndexStep replaceDataStreamBackingIndex = new ReplaceDataStreamBackingIndexStep(replaceDataStreamIndexKey,\n+            deleteIndexKey, SHRUNKEN_INDEX_PREFIX);\n+        DeleteStep deleteSourceIndexStep = new DeleteStep(deleteIndexKey, isShrunkIndexKey, client);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ab909d960da5e44c78db1bf9d2309df57944b4f"}, "originalPosition": 86}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dcb97055b987aa35f7ba44e570de543a3d64b71a", "author": {"user": {"login": "andreidan", "name": "Andrei Dan"}}, "url": "https://github.com/elastic/elasticsearch/commit/dcb97055b987aa35f7ba44e570de543a3d64b71a", "committedDate": "2020-06-05T10:53:34Z", "message": "Add checks for index missing"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e3a2a20f6a632496e93ef31ab8e67de0f71b34ea", "author": {"user": {"login": "andreidan", "name": "Andrei Dan"}}, "url": "https://github.com/elastic/elasticsearch/commit/e3a2a20f6a632496e93ef31ab8e67de0f71b34ea", "committedDate": "2020-06-05T12:37:09Z", "message": "Document eased of validation for backing indices naming"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ac6b0f0509e5d1e81247d78f143f162f1f13b4f0", "author": {"user": {"login": "andreidan", "name": "Andrei Dan"}}, "url": "https://github.com/elastic/elasticsearch/commit/ac6b0f0509e5d1e81247d78f143f162f1f13b4f0", "committedDate": "2020-06-08T10:18:33Z", "message": "Merge branch 'master' into ilm-shrink-datastream"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI2NjgyOTAw", "url": "https://github.com/elastic/elasticsearch/pull/57616#pullrequestreview-426682900", "createdAt": "2020-06-08T23:12:18Z", "commit": {"oid": "ac6b0f0509e5d1e81247d78f143f162f1f13b4f0"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQyMzoxMjoxOFrOGgzdXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQyMzoxMjoxOFrOGgzdXA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA1MDcxNg==", "bodyText": "Super minor, but I think we should add a debug log that shrink is being skipped because the targeted number of shards has already been met", "url": "https://github.com/elastic/elasticsearch/pull/57616#discussion_r437050716", "createdAt": "2020-06-08T23:12:18Z", "author": {"login": "dakrone"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ilm/ShrinkAction.java", "diffHunk": "@@ -85,31 +96,83 @@ public boolean isSafeAction() {\n     public List<Step> toSteps(Client client, String phase, Step.StepKey nextStepKey) {\n         Settings readOnlySettings = Settings.builder().put(IndexMetadata.SETTING_BLOCKS_WRITE, true).build();\n \n-        StepKey branchingKey = new StepKey(phase, NAME, BranchingStep.NAME);\n+        StepKey preShrinkBranchingKey = new StepKey(phase, NAME, CONDITIONAL_SKIP_SHRINK_STEP);\n         StepKey waitForNoFollowerStepKey = new StepKey(phase, NAME, WaitForNoFollowersStep.NAME);\n         StepKey readOnlyKey = new StepKey(phase, NAME, ReadOnlyAction.NAME);\n         StepKey setSingleNodeKey = new StepKey(phase, NAME, SetSingleNodeAllocateStep.NAME);\n         StepKey allocationRoutedKey = new StepKey(phase, NAME, CheckShrinkReadyStep.NAME);\n         StepKey shrinkKey = new StepKey(phase, NAME, ShrinkStep.NAME);\n         StepKey enoughShardsKey = new StepKey(phase, NAME, ShrunkShardsAllocatedStep.NAME);\n         StepKey copyMetadataKey = new StepKey(phase, NAME, CopyExecutionStateStep.NAME);\n+        StepKey dataStreamCheckBranchingKey = new StepKey(phase, NAME, CONDITIONAL_DATASTREAM_CHECK_KEY);\n         StepKey aliasKey = new StepKey(phase, NAME, ShrinkSetAliasStep.NAME);\n         StepKey isShrunkIndexKey = new StepKey(phase, NAME, ShrunkenIndexCheckStep.NAME);\n+        StepKey replaceDataStreamIndexKey = new StepKey(phase, NAME, ReplaceDataStreamBackingIndexStep.NAME);\n+        StepKey deleteIndexKey = new StepKey(phase, NAME, DeleteStep.NAME);\n \n-        BranchingStep conditionalSkipShrinkStep = new BranchingStep(branchingKey, waitForNoFollowerStepKey, nextStepKey,\n-            (index, clusterState) -> clusterState.getMetadata().index(index).getNumberOfShards() == numberOfShards);\n+        BranchingStep conditionalSkipShrinkStep = new BranchingStep(preShrinkBranchingKey, waitForNoFollowerStepKey, nextStepKey,\n+            getSkipShrinkStepPredicate(numberOfShards));\n         WaitForNoFollowersStep waitForNoFollowersStep = new WaitForNoFollowersStep(waitForNoFollowerStepKey, readOnlyKey, client);\n         UpdateSettingsStep readOnlyStep = new UpdateSettingsStep(readOnlyKey, setSingleNodeKey, client, readOnlySettings);\n         SetSingleNodeAllocateStep setSingleNodeStep = new SetSingleNodeAllocateStep(setSingleNodeKey, allocationRoutedKey, client);\n         CheckShrinkReadyStep checkShrinkReadyStep = new CheckShrinkReadyStep(allocationRoutedKey, shrinkKey);\n         ShrinkStep shrink = new ShrinkStep(shrinkKey, enoughShardsKey, client, numberOfShards, SHRUNKEN_INDEX_PREFIX);\n         ShrunkShardsAllocatedStep allocated = new ShrunkShardsAllocatedStep(enoughShardsKey, copyMetadataKey, SHRUNKEN_INDEX_PREFIX);\n-        CopyExecutionStateStep copyMetadata = new CopyExecutionStateStep(copyMetadataKey, aliasKey, SHRUNKEN_INDEX_PREFIX,\n-            ShrunkenIndexCheckStep.NAME);\n+        CopyExecutionStateStep copyMetadata = new CopyExecutionStateStep(copyMetadataKey, dataStreamCheckBranchingKey,\n+            SHRUNKEN_INDEX_PREFIX, ShrunkenIndexCheckStep.NAME);\n+        // by the time we get to this step we have 2 indices, the source and the shrunken one. we now need to choose an index\n+        // swapping strategy such that the shrunken index takes the place of the source index (which is also deleted).\n+        // if the source index is part of a data stream it's a matter of replacing it with the shrunken index one in the data stream and\n+        // then deleting the source index; otherwise we'll use the alias management api to atomically transfer the aliases from source to\n+        // the shrunken index and delete the source\n+        BranchingStep isDataStreamBranchingStep = new BranchingStep(dataStreamCheckBranchingKey, aliasKey, replaceDataStreamIndexKey,\n+            (index, clusterState) -> {\n+                IndexAbstraction indexAbstraction = clusterState.metadata().getIndicesLookup().get(index.getName());\n+                assert indexAbstraction != null : \"invalid cluster metadata. index [\" + index.getName() + \"] was not found\";\n+                return indexAbstraction.getParentDataStream() != null;\n+            });\n         ShrinkSetAliasStep aliasSwapAndDelete = new ShrinkSetAliasStep(aliasKey, isShrunkIndexKey, client, SHRUNKEN_INDEX_PREFIX);\n+        ReplaceDataStreamBackingIndexStep replaceDataStreamBackingIndex = new ReplaceDataStreamBackingIndexStep(replaceDataStreamIndexKey,\n+            deleteIndexKey, SHRUNKEN_INDEX_PREFIX);\n+        DeleteStep deleteSourceIndexStep = new DeleteStep(deleteIndexKey, isShrunkIndexKey, client);\n         ShrunkenIndexCheckStep waitOnShrinkTakeover = new ShrunkenIndexCheckStep(isShrunkIndexKey, nextStepKey, SHRUNKEN_INDEX_PREFIX);\n         return Arrays.asList(conditionalSkipShrinkStep, waitForNoFollowersStep, readOnlyStep, setSingleNodeStep, checkShrinkReadyStep,\n-            shrink, allocated, copyMetadata, aliasSwapAndDelete, waitOnShrinkTakeover);\n+            shrink, allocated, copyMetadata, isDataStreamBranchingStep, aliasSwapAndDelete, waitOnShrinkTakeover,\n+            replaceDataStreamBackingIndex, deleteSourceIndexStep);\n+    }\n+\n+    static BiPredicate<Index, ClusterState> getSkipShrinkStepPredicate(int targetNumberOfShards) {\n+        return (index, clusterState) -> {\n+            IndexMetadata indexMetadata = clusterState.getMetadata().index(index);\n+            if (indexMetadata == null) {\n+                // Index must have been since deleted, skip the shrink action\n+                logger.debug(\"[{}] lifecycle action for index [{}] executed but index no longer exists\", NAME, index.getName());\n+                return true;\n+            }\n+\n+            if (indexMetadata.getNumberOfShards() == targetNumberOfShards) {\n+                return true;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ac6b0f0509e5d1e81247d78f143f162f1f13b4f0"}, "originalPosition": 104}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f68429427dce129ac244beb3b4254b50eb775f11", "author": {"user": {"login": "andreidan", "name": "Andrei Dan"}}, "url": "https://github.com/elastic/elasticsearch/commit/f68429427dce129ac244beb3b4254b50eb775f11", "committedDate": "2020-06-09T09:03:43Z", "message": "Debug log when skipping Shrink action"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "983232a118558670e5e217fe5d3549e66a17bb08", "author": {"user": {"login": "andreidan", "name": "Andrei Dan"}}, "url": "https://github.com/elastic/elasticsearch/commit/983232a118558670e5e217fe5d3549e66a17bb08", "committedDate": "2020-06-09T09:10:52Z", "message": "Merge branch 'master' into ilm-shrink-datastream"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cc929c99c869cc0adf916962218eb62eec4b7eba", "author": {"user": {"login": "andreidan", "name": "Andrei Dan"}}, "url": "https://github.com/elastic/elasticsearch/commit/cc929c99c869cc0adf916962218eb62eec4b7eba", "committedDate": "2020-06-09T09:13:18Z", "message": "Fix master merge"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "86bff1d1d5bfb959d4bf45620efd6326a8a39f9e", "author": {"user": {"login": "andreidan", "name": "Andrei Dan"}}, "url": "https://github.com/elastic/elasticsearch/commit/86bff1d1d5bfb959d4bf45620efd6326a8a39f9e", "committedDate": "2020-06-09T09:42:05Z", "message": "Tests: use DataStream.getDefaultBackingIndexName"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3860, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}