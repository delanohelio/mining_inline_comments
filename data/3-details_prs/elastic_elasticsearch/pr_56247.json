{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDEzNzYwMTU4", "number": 56247, "title": "Fix enrich coordinator to reject documents instead of deadlocking", "bodyText": "This PR removes the blocking call to insert ingest documents into a queue in the coordinator. It replaces it with an offer call which will throw a rejection exception in the event that the queue is full. This prevents deadlocks of the write threads when the queue fills to capacity and there are more than one enrich processors in a pipeline.\nRelates #55634\nThis does not solve the entire issue we have with #55634 - we still need to find a way to process the results of the search results not on search threads and in a way that does not flood the write  thread pool queue with small tasks. We are weighing options and will be fixing that problem soon.", "createdAt": "2020-05-05T21:22:42Z", "url": "https://github.com/elastic/elasticsearch/pull/56247", "merged": true, "mergeCommit": {"oid": "9f5c06deef57dd6ababafcb459d7538f4c6a7ac7"}, "closed": true, "closedAt": "2020-05-26T18:05:44Z", "author": {"login": "jbaiera"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcea0ltgH2gAyNDEzNzYwMTU4OjViZjQ4MTA1M2UyNWQ0Y2YxMTEwOTYwZDBlYmZjOWVkYzZjZGRkYWU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABci31sYAH2gAyNDEzNzYwMTU4OmQwMDRjNGU5YWVlN2QzN2FjYmQ4ZTliOTg4YmQ0ZTQ0MWU5NDM3MTg=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "5bf481053e25d4cf1110960d0ebfc9edc6cdddae", "author": {"user": {"login": "jbaiera", "name": "James Baiera"}}, "url": "https://github.com/elastic/elasticsearch/commit/5bf481053e25d4cf1110960d0ebfc9edc6cdddae", "committedDate": "2020-05-05T21:18:47Z", "message": "Fix enrich coordinator to reject documents instead of deadlocking"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA2NDM1MDAx", "url": "https://github.com/elastic/elasticsearch/pull/56247#pullrequestreview-406435001", "createdAt": "2020-05-06T09:16:06Z", "commit": {"oid": "5bf481053e25d4cf1110960d0ebfc9edc6cdddae"}, "state": "APPROVED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNlQwOToxNjowN1rOGRKf9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNlQwOToyOToxMFrOGRK8rA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDY1MDk5Nw==", "bodyText": "nit: accepted == false instead?", "url": "https://github.com/elastic/elasticsearch/pull/56247#discussion_r420650997", "createdAt": "2020-05-06T09:16:07Z", "author": {"login": "martijnvg"}, "path": "x-pack/plugin/enrich/src/main/java/org/elasticsearch/xpack/enrich/action/EnrichCoordinatorProxyAction.java", "diffHunk": "@@ -99,21 +102,24 @@ public Coordinator(Client client, Settings settings) {\n             this.lookupFunction = lookupFunction;\n             this.maxLookupsPerRequest = maxLookupsPerRequest;\n             this.maxNumberOfConcurrentRequests = maxNumberOfConcurrentRequests;\n+            this.queueCapacity = queueCapacity;\n             this.queue = new ArrayBlockingQueue<>(queueCapacity);\n         }\n \n         void schedule(SearchRequest searchRequest, ActionListener<SearchResponse> listener) {\n-            // Use put(...), because if queue is full then this method will wait until a free slot becomes available\n-            // The calling thread here is a write thread (write tp is used by ingest) and\n-            // this will create natural back pressure from the enrich processor.\n-            // If there are no write threads available then write requests with ingestion will fail with 429 error code.\n-            try {\n-                queue.put(new Slot(searchRequest, listener));\n-            } catch (InterruptedException e) {\n-                Thread.currentThread().interrupt();\n-                throw new RuntimeException(\"unable to add item to queue\", e);\n-            }\n+            // Use offer(...) instead of put(...). We are on a write thread and blocking here can be dangerous,\n+            // especially since the logic to kick off draining the queue is located right after this section. If we\n+            // cannot insert a request to the queue, we should reject the document with a 429 error code.\n+            boolean accepted = queue.offer(new Slot(searchRequest, listener));\n+            int queueSize = queue.size();\n+\n+            // coordinate lookups no matter what, even if queues were full\n             coordinateLookups();\n+\n+            if (!accepted) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5bf481053e25d4cf1110960d0ebfc9edc6cdddae"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDY1MzM1Nw==", "bodyText": "Can describe why it is important to coordicate lookups even the queue is full?", "url": "https://github.com/elastic/elasticsearch/pull/56247#discussion_r420653357", "createdAt": "2020-05-06T09:20:23Z", "author": {"login": "martijnvg"}, "path": "x-pack/plugin/enrich/src/main/java/org/elasticsearch/xpack/enrich/action/EnrichCoordinatorProxyAction.java", "diffHunk": "@@ -99,21 +102,24 @@ public Coordinator(Client client, Settings settings) {\n             this.lookupFunction = lookupFunction;\n             this.maxLookupsPerRequest = maxLookupsPerRequest;\n             this.maxNumberOfConcurrentRequests = maxNumberOfConcurrentRequests;\n+            this.queueCapacity = queueCapacity;\n             this.queue = new ArrayBlockingQueue<>(queueCapacity);\n         }\n \n         void schedule(SearchRequest searchRequest, ActionListener<SearchResponse> listener) {\n-            // Use put(...), because if queue is full then this method will wait until a free slot becomes available\n-            // The calling thread here is a write thread (write tp is used by ingest) and\n-            // this will create natural back pressure from the enrich processor.\n-            // If there are no write threads available then write requests with ingestion will fail with 429 error code.\n-            try {\n-                queue.put(new Slot(searchRequest, listener));\n-            } catch (InterruptedException e) {\n-                Thread.currentThread().interrupt();\n-                throw new RuntimeException(\"unable to add item to queue\", e);\n-            }\n+            // Use offer(...) instead of put(...). We are on a write thread and blocking here can be dangerous,\n+            // especially since the logic to kick off draining the queue is located right after this section. If we\n+            // cannot insert a request to the queue, we should reject the document with a 429 error code.\n+            boolean accepted = queue.offer(new Slot(searchRequest, listener));\n+            int queueSize = queue.size();\n+\n+            // coordinate lookups no matter what, even if queues were full", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5bf481053e25d4cf1110960d0ebfc9edc6cdddae"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDY1Mzk3Mw==", "bodyText": "\ud83d\udc4d", "url": "https://github.com/elastic/elasticsearch/pull/56247#discussion_r420653973", "createdAt": "2020-05-06T09:21:32Z", "author": {"login": "martijnvg"}, "path": "x-pack/plugin/enrich/src/main/java/org/elasticsearch/xpack/enrich/action/EnrichCoordinatorProxyAction.java", "diffHunk": "@@ -99,21 +102,24 @@ public Coordinator(Client client, Settings settings) {\n             this.lookupFunction = lookupFunction;\n             this.maxLookupsPerRequest = maxLookupsPerRequest;\n             this.maxNumberOfConcurrentRequests = maxNumberOfConcurrentRequests;\n+            this.queueCapacity = queueCapacity;\n             this.queue = new ArrayBlockingQueue<>(queueCapacity);\n         }\n \n         void schedule(SearchRequest searchRequest, ActionListener<SearchResponse> listener) {\n-            // Use put(...), because if queue is full then this method will wait until a free slot becomes available\n-            // The calling thread here is a write thread (write tp is used by ingest) and\n-            // this will create natural back pressure from the enrich processor.\n-            // If there are no write threads available then write requests with ingestion will fail with 429 error code.\n-            try {\n-                queue.put(new Slot(searchRequest, listener));\n-            } catch (InterruptedException e) {\n-                Thread.currentThread().interrupt();\n-                throw new RuntimeException(\"unable to add item to queue\", e);\n-            }\n+            // Use offer(...) instead of put(...). We are on a write thread and blocking here can be dangerous,\n+            // especially since the logic to kick off draining the queue is located right after this section. If we\n+            // cannot insert a request to the queue, we should reject the document with a 429 error code.\n+            boolean accepted = queue.offer(new Slot(searchRequest, listener));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5bf481053e25d4cf1110960d0ebfc9edc6cdddae"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDY1NjgzMg==", "bodyText": "perhaps assert that the docs that have been successfully enriched (having both enrich_value_1 and enrich_value_2 fields) is equal to the number of successful bulk items?", "url": "https://github.com/elastic/elasticsearch/pull/56247#discussion_r420656832", "createdAt": "2020-05-06T09:26:33Z", "author": {"login": "martijnvg"}, "path": "x-pack/plugin/enrich/src/test/java/org/elasticsearch/xpack/enrich/EnrichResiliencyTests.java", "diffHunk": "@@ -0,0 +1,249 @@\n+package org.elasticsearch.xpack.enrich;\n+\n+import org.elasticsearch.action.admin.indices.create.CreateIndexRequest;\n+import org.elasticsearch.action.admin.indices.refresh.RefreshRequest;\n+import org.elasticsearch.action.bulk.BulkItemResponse;\n+import org.elasticsearch.action.bulk.BulkRequest;\n+import org.elasticsearch.action.bulk.BulkResponse;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.ingest.PutPipelineAction;\n+import org.elasticsearch.action.ingest.PutPipelineRequest;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentType;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.index.reindex.ReindexPlugin;\n+import org.elasticsearch.ingest.common.IngestCommonPlugin;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.test.ESSingleNodeTestCase;\n+import org.elasticsearch.xpack.core.XPackSettings;\n+import org.elasticsearch.xpack.core.enrich.EnrichPolicy;\n+import org.elasticsearch.xpack.core.enrich.action.ExecuteEnrichPolicyAction;\n+import org.elasticsearch.xpack.core.enrich.action.PutEnrichPolicyAction;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.hamcrest.Matchers.*;\n+\n+public class EnrichResiliencyTests extends ESSingleNodeTestCase {\n+\n+    @Override\n+    protected Collection<Class<? extends Plugin>> getPlugins() {\n+        return List.of(ReindexPlugin.class, IngestCommonPlugin.class, LocalStateEnrich.class);\n+    }\n+\n+    @Override\n+    protected Settings nodeSettings() {\n+        // Severely throttle the processing throughput to reach max capacity easier\n+        return Settings.builder()\n+            .put(XPackSettings.ENRICH_ENABLED_SETTING.getKey(), true)\n+            .put(EnrichPlugin.COORDINATOR_PROXY_MAX_CONCURRENT_REQUESTS.getKey(), 1)\n+            .put(EnrichPlugin.COORDINATOR_PROXY_MAX_LOOKUPS_PER_REQUEST.getKey(), 1)\n+            .put(EnrichPlugin.COORDINATOR_PROXY_QUEUE_CAPACITY.getKey(), 10)\n+            .build();\n+    }\n+\n+    public void testWriteThreadLivenessBackToBack() throws Exception {\n+        ensureGreen();\n+\n+        long testSuffix = System.currentTimeMillis();\n+        String enrichIndexName = \"enrich_lookup_\" + testSuffix;\n+        String enrichPolicyName = \"enrich_policy_\" + testSuffix;\n+        String enrichPipelineName = \"enrich_pipeline_\" + testSuffix;\n+        String enrichedIndexName = \"enrich_results_\" + testSuffix;\n+\n+        client().index(new IndexRequest(enrichIndexName).source(\n+            JsonXContent.contentBuilder().startObject().field(\"my_key\", \"key\").field(\"my_value\", \"data\").endObject()))\n+            .actionGet();\n+\n+        client().admin().indices().refresh(new RefreshRequest(enrichIndexName)).actionGet();\n+\n+        client().execute(PutEnrichPolicyAction.INSTANCE, new PutEnrichPolicyAction.Request(\n+            enrichPolicyName,\n+            new EnrichPolicy(EnrichPolicy.MATCH_TYPE, null, List.of(enrichIndexName), \"my_key\", List.of(\"my_value\"))\n+        )).actionGet();\n+\n+        client().execute(ExecuteEnrichPolicyAction.INSTANCE, new ExecuteEnrichPolicyAction.Request(enrichPolicyName)\n+            .setWaitForCompletion(true)).actionGet();\n+\n+        XContentBuilder pipe1 = JsonXContent.contentBuilder();\n+        pipe1.startObject();\n+        {\n+            pipe1.startArray(\"processors\");\n+            {\n+                pipe1.startObject();\n+                {\n+                    pipe1.startObject(\"enrich\");\n+                    {\n+                        pipe1.field(\"policy_name\", enrichPolicyName);\n+                        pipe1.field(\"field\", \"custom_id\");\n+                        pipe1.field(\"target_field\", \"enrich_value_1\");\n+                    }\n+                    pipe1.endObject();\n+                }\n+                pipe1.endObject();\n+                pipe1.startObject();\n+                {\n+                    pipe1.startObject(\"enrich\");\n+                    {\n+                        pipe1.field(\"policy_name\", enrichPolicyName);\n+                        pipe1.field(\"field\", \"custom_id\");\n+                        pipe1.field(\"target_field\", \"enrich_value_2\");\n+                    }\n+                    pipe1.endObject();\n+                }\n+                pipe1.endObject();\n+            }\n+            pipe1.endArray();\n+        }\n+        pipe1.endObject();\n+\n+        client().execute(PutPipelineAction.INSTANCE, new PutPipelineRequest(\n+            enrichPipelineName,\n+            BytesReference.bytes(pipe1),\n+            XContentType.JSON\n+        )).actionGet();\n+\n+        client().admin().indices().create(new CreateIndexRequest(enrichedIndexName)).actionGet();\n+\n+        XContentBuilder doc = JsonXContent.contentBuilder().startObject().field(\"custom_id\", \"key\").endObject();\n+\n+        BulkRequest bulk = new BulkRequest(enrichedIndexName);\n+        bulk.timeout(new TimeValue(10, TimeUnit.SECONDS));\n+        for (int idx = 0; idx < 50; idx++) {\n+            bulk.add(new IndexRequest().source(doc).setPipeline(enrichPipelineName));\n+        }\n+\n+        BulkResponse bulkItemResponses = client().bulk(bulk).actionGet(new TimeValue(30, TimeUnit.SECONDS));\n+\n+        assertTrue(bulkItemResponses.hasFailures());\n+        for (BulkItemResponse item : bulkItemResponses.getItems()) {\n+            if (item.isFailed()) {\n+                assertThat(item.getFailure().getStatus().getStatus(), is(equalTo(429)));\n+                assertThat(item.getFailureMessage(), containsString(\"Could not perform enrichment, enrich coordination queue at capacity\"));\n+                break;\n+            }\n+        }\n+\n+        client().admin().indices().refresh(new RefreshRequest(enrichedIndexName)).actionGet();\n+        logger.info(client().search(new SearchRequest(enrichedIndexName)).actionGet().toString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5bf481053e25d4cf1110960d0ebfc9edc6cdddae"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDY1NzYwOQ==", "bodyText": "I don't that that checkstyle allows wildcard imports.", "url": "https://github.com/elastic/elasticsearch/pull/56247#discussion_r420657609", "createdAt": "2020-05-06T09:27:57Z", "author": {"login": "martijnvg"}, "path": "x-pack/plugin/enrich/src/test/java/org/elasticsearch/xpack/enrich/EnrichResiliencyTests.java", "diffHunk": "@@ -0,0 +1,249 @@\n+package org.elasticsearch.xpack.enrich;\n+\n+import org.elasticsearch.action.admin.indices.create.CreateIndexRequest;\n+import org.elasticsearch.action.admin.indices.refresh.RefreshRequest;\n+import org.elasticsearch.action.bulk.BulkItemResponse;\n+import org.elasticsearch.action.bulk.BulkRequest;\n+import org.elasticsearch.action.bulk.BulkResponse;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.ingest.PutPipelineAction;\n+import org.elasticsearch.action.ingest.PutPipelineRequest;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentType;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.index.reindex.ReindexPlugin;\n+import org.elasticsearch.ingest.common.IngestCommonPlugin;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.test.ESSingleNodeTestCase;\n+import org.elasticsearch.xpack.core.XPackSettings;\n+import org.elasticsearch.xpack.core.enrich.EnrichPolicy;\n+import org.elasticsearch.xpack.core.enrich.action.ExecuteEnrichPolicyAction;\n+import org.elasticsearch.xpack.core.enrich.action.PutEnrichPolicyAction;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.hamcrest.Matchers.*;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5bf481053e25d4cf1110960d0ebfc9edc6cdddae"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDY1ODM0OA==", "bodyText": "Maybe add a comment here describing why we for now temporarily allow search tp here?", "url": "https://github.com/elastic/elasticsearch/pull/56247#discussion_r420658348", "createdAt": "2020-05-06T09:29:10Z", "author": {"login": "martijnvg"}, "path": "x-pack/plugin/enrich/src/main/java/org/elasticsearch/xpack/enrich/action/EnrichCoordinatorProxyAction.java", "diffHunk": "@@ -66,6 +67,7 @@ protected void doExecute(Task task, SearchRequest request, ActionListener<Search\n             // Write tp is expected when executing enrich processor from index / bulk api\n             // Management tp is expected when executing enrich processor from ingest simulate api\n             assert Thread.currentThread().getName().contains(ThreadPool.Names.WRITE)\n+                || Thread.currentThread().getName().contains(ThreadPool.Names.SEARCH)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5bf481053e25d4cf1110960d0ebfc9edc6cdddae"}, "originalPosition": 12}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9b2130dfd7936739d1f89b75a0d753e68a6e27ba", "author": {"user": {"login": "jbaiera", "name": "James Baiera"}}, "url": "https://github.com/elastic/elasticsearch/commit/9b2130dfd7936739d1f89b75a0d753e68a6e27ba", "committedDate": "2020-05-08T02:43:52Z", "message": "Fixing PR review feedback and tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e2563dd61a01a07484015e3db8d462369c100c4b", "author": {"user": {"login": "jbaiera", "name": "James Baiera"}}, "url": "https://github.com/elastic/elasticsearch/commit/e2563dd61a01a07484015e3db8d462369c100c4b", "committedDate": "2020-05-08T15:55:02Z", "message": "Make the rest of precommit happy"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "52a86397120a40001cc6563f834bc583a3c86e3f", "author": {"user": {"login": "jbaiera", "name": "James Baiera"}}, "url": "https://github.com/elastic/elasticsearch/commit/52a86397120a40001cc6563f834bc583a3c86e3f", "committedDate": "2020-05-14T19:55:17Z", "message": "Merge branch 'master' into fix-enrich-queue-rejections"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "381e72b4f2c9bd6df6cfa5b8700519dcbedb424c", "author": {"user": {"login": "jbaiera", "name": "James Baiera"}}, "url": "https://github.com/elastic/elasticsearch/commit/381e72b4f2c9bd6df6cfa5b8700519dcbedb424c", "committedDate": "2020-05-15T21:13:53Z", "message": "Fixing build failure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d004c4e9aee7d37acbd8e9b988bd4e441e943718", "author": {"user": {"login": "jbaiera", "name": "James Baiera"}}, "url": "https://github.com/elastic/elasticsearch/commit/d004c4e9aee7d37acbd8e9b988bd4e441e943718", "committedDate": "2020-05-19T17:22:56Z", "message": "Merge branch 'master' into fix-enrich-queue-rejections"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 134, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}