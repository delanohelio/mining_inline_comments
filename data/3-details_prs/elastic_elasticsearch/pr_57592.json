{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI3MTY3NTMx", "number": 57592, "title": "Add models for search to ModelLoadingService", "bodyText": "ModelLoadingService only caches models if they are referenced by an ingest pipeline. For models used in search we want to always cache the models and rely on TTL to evict them. Additionally when an ingest pipeline is deleted the model it references should not be evicted if it is used in search.\nI've changed the public interface to have 2 methods getModelForPipeline and getModelForSearch which account for the different caching strategies. Most of the change is refactoring.", "createdAt": "2020-06-03T12:24:05Z", "url": "https://github.com/elastic/elasticsearch/pull/57592", "merged": true, "mergeCommit": {"oid": "8306caf630cc8d4b18fcf26d18cdcc07ef1e85ba"}, "closed": true, "closedAt": "2020-06-10T08:27:34Z", "author": {"login": "davidkyle"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcoCZGqgFqTQyMzU2MjMzMg==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcprjb4AFqTQyNzU0MjQzNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIzNTYyMzMy", "url": "https://github.com/elastic/elasticsearch/pull/57592#pullrequestreview-423562332", "createdAt": "2020-06-03T13:39:47Z", "commit": {"oid": "990d5a67db47d1263bfc7719e142e8bfd0e3d8e7"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QxMzozOTo0N1rOGecR_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQxODoyNjo0OFrOGfSilA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDU3MzgyMw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        // explicit declaration of the listener lambda necessary for Eclipse IDE 4.14", "url": "https://github.com/elastic/elasticsearch/pull/57592#discussion_r434573823", "createdAt": "2020-06-03T13:39:47Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/ModelLoadingService.java", "diffHunk": "@@ -112,104 +130,130 @@ public ModelLoadingService(TrainedModelProvider trainedModelProvider,\n         this.modelStatsService = modelStatsService;\n         this.shouldNotAudit = new HashSet<>();\n         this.namedXContentRegistry = namedXContentRegistry;\n-        this.localModelCache = CacheBuilder.<String, LocalModel>builder()\n+        this.localModelCache = CacheBuilder.<String, ModelAndConsumer>builder()\n             .setMaximumWeight(this.maxCacheSize.getBytes())\n-            .weigher((id, localModel) -> localModel.ramBytesUsed())\n+            .weigher((id, modelAndConsumer) -> modelAndConsumer.model.ramBytesUsed())\n             // explicit declaration of the listener lambda necessary for Eclipse IDE 4.14", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "990d5a67db47d1263bfc7719e142e8bfd0e3d8e7"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQ1MDI5OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public boolean modelIsCached(String modelId) {\n          \n          \n            \n                boolean modelIsCached(String modelId) {\n          \n      \n    \n    \n  \n\nLets make this package private so folks aren't tempted to use it. In a real scenario, this could return true, and then the model is removed when the caller attempts to get it.", "url": "https://github.com/elastic/elasticsearch/pull/57592#discussion_r435450298", "createdAt": "2020-06-04T18:07:42Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/ModelLoadingService.java", "diffHunk": "@@ -112,104 +130,130 @@ public ModelLoadingService(TrainedModelProvider trainedModelProvider,\n         this.modelStatsService = modelStatsService;\n         this.shouldNotAudit = new HashSet<>();\n         this.namedXContentRegistry = namedXContentRegistry;\n-        this.localModelCache = CacheBuilder.<String, LocalModel>builder()\n+        this.localModelCache = CacheBuilder.<String, ModelAndConsumer>builder()\n             .setMaximumWeight(this.maxCacheSize.getBytes())\n-            .weigher((id, localModel) -> localModel.ramBytesUsed())\n+            .weigher((id, modelAndConsumer) -> modelAndConsumer.model.ramBytesUsed())\n             // explicit declaration of the listener lambda necessary for Eclipse IDE 4.14\n-            .removalListener(notification -> cacheEvictionListener(notification))\n+            .removalListener(this::cacheEvictionListener)\n             .setExpireAfterAccess(INFERENCE_MODEL_CACHE_TTL.get(settings))\n             .build();\n         clusterService.addListener(this);\n         this.localNode = localNode;\n     }\n \n+    public boolean modelIsCached(String modelId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "990d5a67db47d1263bfc7719e142e8bfd0e3d8e7"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQ1NTc0NA==", "bodyText": "There is a pretty frustrating race condition here, unsure if it is worth fixing.\n\nModelAndConsumer cachedModel = localModelCache.get(modelId); returns from cache successfully\nModel is removed from cache as it is only referenced by a pipeline (updated via cluster state change)\nSearch adds itself as a consume too late and it is evicted\n\nThe referenced model from the get call will still be around. But the next call for the same model will load from the index again :/.\nThe only way I could see of fixing this is locking here (which defeats the purpose of the fast get). Since the cost is low, it might just be OK to have this as it is recoverable later.", "url": "https://github.com/elastic/elasticsearch/pull/57592#discussion_r435455744", "createdAt": "2020-06-04T18:17:34Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/ModelLoadingService.java", "diffHunk": "@@ -112,104 +130,130 @@ public ModelLoadingService(TrainedModelProvider trainedModelProvider,\n         this.modelStatsService = modelStatsService;\n         this.shouldNotAudit = new HashSet<>();\n         this.namedXContentRegistry = namedXContentRegistry;\n-        this.localModelCache = CacheBuilder.<String, LocalModel>builder()\n+        this.localModelCache = CacheBuilder.<String, ModelAndConsumer>builder()\n             .setMaximumWeight(this.maxCacheSize.getBytes())\n-            .weigher((id, localModel) -> localModel.ramBytesUsed())\n+            .weigher((id, modelAndConsumer) -> modelAndConsumer.model.ramBytesUsed())\n             // explicit declaration of the listener lambda necessary for Eclipse IDE 4.14\n-            .removalListener(notification -> cacheEvictionListener(notification))\n+            .removalListener(this::cacheEvictionListener)\n             .setExpireAfterAccess(INFERENCE_MODEL_CACHE_TTL.get(settings))\n             .build();\n         clusterService.addListener(this);\n         this.localNode = localNode;\n     }\n \n+    public boolean modelIsCached(String modelId) {\n+        return localModelCache.get(modelId) != null;\n+    }\n+\n     /**\n-     * Gets the model referenced by `modelId` and responds to the listener.\n+     * Load the model for use by an ingest pipeline. The model will not be cached if there is no\n+     * ingest pipeline referencing it i.e. it is used in simulate mode\n+     *\n+     * @param modelId  the model to get\n+     * @param modelActionListener the listener to alert when the model has been retrieved\n+     */\n+    public void getModelForPipeline(String modelId, ActionListener<Model> modelActionListener) {\n+        getModel(modelId, Consumer.PIPELINE, modelActionListener);\n+    }\n+\n+    /**\n+     * Load the model for use by at search. Models requested by search are always cached.\n      *\n+     * @param modelId  the model to get\n+     * @param modelActionListener the listener to alert when the model has been retrieved\n+     */\n+    public void getModelForSearch(String modelId, ActionListener<Model> modelActionListener) {\n+        getModel(modelId, Consumer.SEARCH, modelActionListener);\n+    }\n+\n+    /**\n+     * Gets the model referenced by `modelId` and responds to the listener.\n+     * <p>\n      * This method first checks the local LRU cache for the model. If it is present, it is returned from cache.\n+     * <p>\n+     * In the case of search if the model is not present one of the following occurs:\n+     * - If it is currently being loaded the `modelActionListener`\n+     * is added to the list of listeners to be alerted when the model is fully loaded.\n+     * - Otherwise the model is loaded and cached\n      *\n-     * If it is not present, one of the following occurs:\n+     * In the case of an ingest processor if it is not present, one of the following occurs:\n+     * <p>\n+     * - If the model is referenced by a pipeline and is currently being loaded, the `modelActionListener`\n+     * is added to the list of listeners to be alerted when the model is fully loaded.\n+     * - If the model is referenced by a pipeline and is currently NOT being loaded, a new load attempt is made and the resulting\n+     * model will attempt to be cached for future reference\n+     * - If the models is NOT referenced by a pipeline, the model is simply loaded from the index and given to the listener.\n+     * It is not cached.\n      *\n-     *  - If the model is referenced by a pipeline and is currently being loaded, the `modelActionListener`\n-     *    is added to the list of listeners to be alerted when the model is fully loaded.\n-     *  - If the model is referenced by a pipeline and is currently NOT being loaded, a new load attempt is made and the resulting\n-     *    model will attempt to be cached for future reference\n-     *  - If the models is NOT referenced by a pipeline, the model is simply loaded from the index and given to the listener.\n-     *    It is not cached.\n+     * The main difference being that models for search are always cached whereas pipeline models\n+     * are only cached if they are referenced by an ingest pipeline\n      *\n-     * @param modelId the model to get\n+     * @param modelId             the model to get\n+     * @param consumer            which feature is requesting the model\n      * @param modelActionListener the listener to alert when the model has been retrieved.\n      */\n-    public void getModel(String modelId, ActionListener<Model> modelActionListener) {\n-        LocalModel cachedModel = localModelCache.get(modelId);\n+    private void getModel(String modelId, Consumer consumer, ActionListener<Model> modelActionListener) {\n+        ModelAndConsumer cachedModel = localModelCache.get(modelId);\n         if (cachedModel != null) {\n-            modelActionListener.onResponse(cachedModel);\n+            cachedModel.consumers.add(consumer);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "990d5a67db47d1263bfc7719e142e8bfd0e3d8e7"}, "originalPosition": 157}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQ1Nzg0Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    if (loadModelIfNecessary(modelId, consumer, modelActionListener) == false) {\n          \n          \n            \n                    if (loadModelIfNecessary(modelId, consumer, modelActionListener)) {\n          \n      \n    \n    \n  \n\nReturning true from the method means it is loaded or already loading. As the logging message suggests :).", "url": "https://github.com/elastic/elasticsearch/pull/57592#discussion_r435457847", "createdAt": "2020-06-04T18:20:56Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/ModelLoadingService.java", "diffHunk": "@@ -112,104 +130,130 @@ public ModelLoadingService(TrainedModelProvider trainedModelProvider,\n         this.modelStatsService = modelStatsService;\n         this.shouldNotAudit = new HashSet<>();\n         this.namedXContentRegistry = namedXContentRegistry;\n-        this.localModelCache = CacheBuilder.<String, LocalModel>builder()\n+        this.localModelCache = CacheBuilder.<String, ModelAndConsumer>builder()\n             .setMaximumWeight(this.maxCacheSize.getBytes())\n-            .weigher((id, localModel) -> localModel.ramBytesUsed())\n+            .weigher((id, modelAndConsumer) -> modelAndConsumer.model.ramBytesUsed())\n             // explicit declaration of the listener lambda necessary for Eclipse IDE 4.14\n-            .removalListener(notification -> cacheEvictionListener(notification))\n+            .removalListener(this::cacheEvictionListener)\n             .setExpireAfterAccess(INFERENCE_MODEL_CACHE_TTL.get(settings))\n             .build();\n         clusterService.addListener(this);\n         this.localNode = localNode;\n     }\n \n+    public boolean modelIsCached(String modelId) {\n+        return localModelCache.get(modelId) != null;\n+    }\n+\n     /**\n-     * Gets the model referenced by `modelId` and responds to the listener.\n+     * Load the model for use by an ingest pipeline. The model will not be cached if there is no\n+     * ingest pipeline referencing it i.e. it is used in simulate mode\n+     *\n+     * @param modelId  the model to get\n+     * @param modelActionListener the listener to alert when the model has been retrieved\n+     */\n+    public void getModelForPipeline(String modelId, ActionListener<Model> modelActionListener) {\n+        getModel(modelId, Consumer.PIPELINE, modelActionListener);\n+    }\n+\n+    /**\n+     * Load the model for use by at search. Models requested by search are always cached.\n      *\n+     * @param modelId  the model to get\n+     * @param modelActionListener the listener to alert when the model has been retrieved\n+     */\n+    public void getModelForSearch(String modelId, ActionListener<Model> modelActionListener) {\n+        getModel(modelId, Consumer.SEARCH, modelActionListener);\n+    }\n+\n+    /**\n+     * Gets the model referenced by `modelId` and responds to the listener.\n+     * <p>\n      * This method first checks the local LRU cache for the model. If it is present, it is returned from cache.\n+     * <p>\n+     * In the case of search if the model is not present one of the following occurs:\n+     * - If it is currently being loaded the `modelActionListener`\n+     * is added to the list of listeners to be alerted when the model is fully loaded.\n+     * - Otherwise the model is loaded and cached\n      *\n-     * If it is not present, one of the following occurs:\n+     * In the case of an ingest processor if it is not present, one of the following occurs:\n+     * <p>\n+     * - If the model is referenced by a pipeline and is currently being loaded, the `modelActionListener`\n+     * is added to the list of listeners to be alerted when the model is fully loaded.\n+     * - If the model is referenced by a pipeline and is currently NOT being loaded, a new load attempt is made and the resulting\n+     * model will attempt to be cached for future reference\n+     * - If the models is NOT referenced by a pipeline, the model is simply loaded from the index and given to the listener.\n+     * It is not cached.\n      *\n-     *  - If the model is referenced by a pipeline and is currently being loaded, the `modelActionListener`\n-     *    is added to the list of listeners to be alerted when the model is fully loaded.\n-     *  - If the model is referenced by a pipeline and is currently NOT being loaded, a new load attempt is made and the resulting\n-     *    model will attempt to be cached for future reference\n-     *  - If the models is NOT referenced by a pipeline, the model is simply loaded from the index and given to the listener.\n-     *    It is not cached.\n+     * The main difference being that models for search are always cached whereas pipeline models\n+     * are only cached if they are referenced by an ingest pipeline\n      *\n-     * @param modelId the model to get\n+     * @param modelId             the model to get\n+     * @param consumer            which feature is requesting the model\n      * @param modelActionListener the listener to alert when the model has been retrieved.\n      */\n-    public void getModel(String modelId, ActionListener<Model> modelActionListener) {\n-        LocalModel cachedModel = localModelCache.get(modelId);\n+    private void getModel(String modelId, Consumer consumer, ActionListener<Model> modelActionListener) {\n+        ModelAndConsumer cachedModel = localModelCache.get(modelId);\n         if (cachedModel != null) {\n-            modelActionListener.onResponse(cachedModel);\n+            cachedModel.consumers.add(consumer);\n+            modelActionListener.onResponse(cachedModel.model);\n             logger.trace(() -> new ParameterizedMessage(\"[{}] loaded from cache\", modelId));\n             return;\n         }\n-        if (loadModelIfNecessary(modelId, modelActionListener) == false) {\n-            // If we the model is not loaded and we did not kick off a new loading attempt, this means that we may be getting called\n-            // by a simulated pipeline\n-            logger.trace(() -> new ParameterizedMessage(\"[{}] not actively loading, eager loading without cache\", modelId));\n-            provider.getTrainedModel(modelId, true, ActionListener.wrap(\n-                trainedModelConfig -> {\n-                    trainedModelConfig.ensureParsedDefinition(namedXContentRegistry);\n-                    InferenceConfig inferenceConfig = trainedModelConfig.getInferenceConfig() == null ?\n-                        inferenceConfigFromTargetType(trainedModelConfig.getModelDefinition().getTrainedModel().targetType()) :\n-                        trainedModelConfig.getInferenceConfig();\n-                    modelActionListener.onResponse(new LocalModel(\n-                        trainedModelConfig.getModelId(),\n-                        localNode,\n-                        trainedModelConfig.getModelDefinition(),\n-                        trainedModelConfig.getInput(),\n-                        trainedModelConfig.getDefaultFieldMap(),\n-                        inferenceConfig,\n-                        modelStatsService));\n-                },\n-                modelActionListener::onFailure\n-            ));\n-        } else {\n+\n+        if (loadModelIfNecessary(modelId, consumer, modelActionListener) == false) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "990d5a67db47d1263bfc7719e142e8bfd0e3d8e7"}, "originalPosition": 185}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQ2MjU5MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        removedModels.forEach(modleId -> {\n          \n          \n            \n                        removedModels.forEach(modelId -> {", "url": "https://github.com/elastic/elasticsearch/pull/57592#discussion_r435462591", "createdAt": "2020-06-04T18:26:25Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/ModelLoadingService.java", "diffHunk": "@@ -313,7 +378,13 @@ public void clusterChanged(ClusterChangedEvent event) {\n             removedModels = Sets.difference(referencedModelsBeforeClusterState, allReferencedModelKeys);\n \n             // Remove all cached models that are not referenced by any processors\n-            removedModels.forEach(localModelCache::invalidate);\n+            // and are not used in search\n+            removedModels.forEach(modleId -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "990d5a67db47d1263bfc7719e142e8bfd0e3d8e7"}, "originalPosition": 334}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQ2MjcwMw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            ModelAndConsumer modelAndConsumer = localModelCache.get(modleId);\n          \n          \n            \n                            ModelAndConsumer modelAndConsumer = localModelCache.get(modelId);", "url": "https://github.com/elastic/elasticsearch/pull/57592#discussion_r435462703", "createdAt": "2020-06-04T18:26:36Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/ModelLoadingService.java", "diffHunk": "@@ -313,7 +378,13 @@ public void clusterChanged(ClusterChangedEvent event) {\n             removedModels = Sets.difference(referencedModelsBeforeClusterState, allReferencedModelKeys);\n \n             // Remove all cached models that are not referenced by any processors\n-            removedModels.forEach(localModelCache::invalidate);\n+            // and are not used in search\n+            removedModels.forEach(modleId -> {\n+                ModelAndConsumer modelAndConsumer = localModelCache.get(modleId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "990d5a67db47d1263bfc7719e142e8bfd0e3d8e7"}, "originalPosition": 335}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQ2MjgwNA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                localModelCache.invalidate(modleId);\n          \n          \n            \n                                localModelCache.invalidate(modelId);", "url": "https://github.com/elastic/elasticsearch/pull/57592#discussion_r435462804", "createdAt": "2020-06-04T18:26:48Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/loadingservice/ModelLoadingService.java", "diffHunk": "@@ -313,7 +378,13 @@ public void clusterChanged(ClusterChangedEvent event) {\n             removedModels = Sets.difference(referencedModelsBeforeClusterState, allReferencedModelKeys);\n \n             // Remove all cached models that are not referenced by any processors\n-            removedModels.forEach(localModelCache::invalidate);\n+            // and are not used in search\n+            removedModels.forEach(modleId -> {\n+                ModelAndConsumer modelAndConsumer = localModelCache.get(modleId);\n+                if (modelAndConsumer != null && modelAndConsumer.consumers.contains(Consumer.SEARCH) == false) {\n+                    localModelCache.invalidate(modleId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "990d5a67db47d1263bfc7719e142e8bfd0e3d8e7"}, "originalPosition": 337}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b581a33e07227f1d3dc5f0a45d9537cdb8f64918", "author": {"user": {"login": "davidkyle", "name": "David Kyle"}}, "url": "https://github.com/elastic/elasticsearch/commit/b581a33e07227f1d3dc5f0a45d9537cdb8f64918", "committedDate": "2020-06-05T07:24:40Z", "message": "Address review comments"}, "afterCommit": {"oid": "348a7bd9de60a73ea6e2b19d0703c65f8a241771", "author": {"user": {"login": "davidkyle", "name": "David Kyle"}}, "url": "https://github.com/elastic/elasticsearch/commit/348a7bd9de60a73ea6e2b19d0703c65f8a241771", "committedDate": "2020-06-05T07:27:04Z", "message": "Address review comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "348a7bd9de60a73ea6e2b19d0703c65f8a241771", "author": {"user": {"login": "davidkyle", "name": "David Kyle"}}, "url": "https://github.com/elastic/elasticsearch/commit/348a7bd9de60a73ea6e2b19d0703c65f8a241771", "committedDate": "2020-06-05T07:27:04Z", "message": "Address review comments"}, "afterCommit": {"oid": "7452010218958a5fe6a8ebee3b8f425cc812895b", "author": {"user": {"login": "davidkyle", "name": "David Kyle"}}, "url": "https://github.com/elastic/elasticsearch/commit/7452010218958a5fe6a8ebee3b8f425cc812895b", "committedDate": "2020-06-05T17:54:14Z", "message": "adjust for rebase"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bf92ce2299c197c9e5c5103c6e46b43fa2b9d759", "author": {"user": {"login": "davidkyle", "name": "David Kyle"}}, "url": "https://github.com/elastic/elasticsearch/commit/bf92ce2299c197c9e5c5103c6e46b43fa2b9d759", "committedDate": "2020-06-09T12:45:01Z", "message": "Add method for search models to service"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7d51ee30e6a83cb120442ba619680071dfbc62da", "author": {"user": {"login": "davidkyle", "name": "David Kyle"}}, "url": "https://github.com/elastic/elasticsearch/commit/7d51ee30e6a83cb120442ba619680071dfbc62da", "committedDate": "2020-06-09T12:45:01Z", "message": "Address review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "55a269f5257210154c82b945fe95f8a9e2baefab", "author": {"user": {"login": "davidkyle", "name": "David Kyle"}}, "url": "https://github.com/elastic/elasticsearch/commit/55a269f5257210154c82b945fe95f8a9e2baefab", "committedDate": "2020-06-09T12:45:02Z", "message": "adjust for rebase"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "48e76ce301f3691019552fe4e95b55a3b4184b27", "author": {"user": {"login": "davidkyle", "name": "David Kyle"}}, "url": "https://github.com/elastic/elasticsearch/commit/48e76ce301f3691019552fe4e95b55a3b4184b27", "committedDate": "2020-06-09T12:45:02Z", "message": "Synchronised checks for model in cache"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8a402fd1bd3ea3234500e4ef6c4a8886b347edc3", "author": {"user": {"login": "davidkyle", "name": "David Kyle"}}, "url": "https://github.com/elastic/elasticsearch/commit/8a402fd1bd3ea3234500e4ef6c4a8886b347edc3", "committedDate": "2020-06-05T17:59:16Z", "message": "Synchronised checks for model in cache"}, "afterCommit": {"oid": "48e76ce301f3691019552fe4e95b55a3b4184b27", "author": {"user": {"login": "davidkyle", "name": "David Kyle"}}, "url": "https://github.com/elastic/elasticsearch/commit/48e76ce301f3691019552fe4e95b55a3b4184b27", "committedDate": "2020-06-09T12:45:02Z", "message": "Synchronised checks for model in cache"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "36ed6bdeeb64529beffbfde49ab928ea27c6b4f8", "author": {"user": {"login": "davidkyle", "name": "David Kyle"}}, "url": "https://github.com/elastic/elasticsearch/commit/36ed6bdeeb64529beffbfde49ab928ea27c6b4f8", "committedDate": "2020-06-09T16:47:26Z", "message": "adjust for rebase"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5dfdeab7ebdc1a01615fcf24fa4013cb296cc2af", "author": {"user": {"login": "davidkyle", "name": "David Kyle"}}, "url": "https://github.com/elastic/elasticsearch/commit/5dfdeab7ebdc1a01615fcf24fa4013cb296cc2af", "committedDate": "2020-06-09T19:43:56Z", "message": "Reinstate fast lookup code"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI3NTQyNDM0", "url": "https://github.com/elastic/elasticsearch/pull/57592#pullrequestreview-427542434", "createdAt": "2020-06-09T21:01:36Z", "commit": {"oid": "5dfdeab7ebdc1a01615fcf24fa4013cb296cc2af"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4001, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}