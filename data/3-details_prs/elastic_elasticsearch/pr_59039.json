{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ0MzkzNDg3", "number": 59039, "title": "Extract recovery files details to its own class", "bodyText": "", "createdAt": "2020-07-05T11:18:12Z", "url": "https://github.com/elastic/elasticsearch/pull/59039", "merged": true, "mergeCommit": {"oid": "2e3f3c0fce87cc3a1016ca707d948764351942d8"}, "closed": true, "closedAt": "2020-07-07T08:50:25Z", "author": {"login": "fcofdez"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcx6vSdgH2gAyNDQ0MzkzNDg3OjgxNWJlNjU1MTZjZWYyMWJiNDRkZmI3ZDFlZmQ2NDQ3OTQ5NmJkMGQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcygdt5gFqTQ0MzYxODM4Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "815be65516cef21bb44dfb7d1efd64479496bd0d", "author": {"user": {"login": "fcofdez", "name": "Francisco Fern\u00e1ndez Casta\u00f1o"}}, "url": "https://github.com/elastic/elasticsearch/commit/815be65516cef21bb44dfb7d1efd64479496bd0d", "committedDate": "2020-07-05T11:14:31Z", "message": "Extract recovery files details to its own class."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQyODY0ODcw", "url": "https://github.com/elastic/elasticsearch/pull/59039#pullrequestreview-442864870", "createdAt": "2020-07-06T08:17:07Z", "commit": {"oid": "815be65516cef21bb44dfb7d1efd64479496bd0d"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwODoxNzowOFrOGtNUuA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwODoxOToxM1rOGtNZTw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDA1NzQwMA==", "bodyText": "Think it'd be better to move this to a constructor RecoveryFilesDetails(StreamInput in), and similarly implement RecoveryFileDetails#writeTo instead of implementing the serialization here.", "url": "https://github.com/elastic/elasticsearch/pull/59039#discussion_r450057400", "createdAt": "2020-07-06T08:17:08Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/indices/recovery/RecoveryState.java", "diffHunk": "@@ -716,7 +749,7 @@ public Index(StreamInput in) throws IOException {\n             int size = in.readVInt();\n             for (int i = 0; i < size; i++) {\n                 File file = new File(in);\n-                fileDetails.put(file.name, file);\n+                fileDetails.addFileDetails(file.name, file);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "815be65516cef21bb44dfb7d1efd64479496bd0d"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDA1NzY2Nw==", "bodyText": "This feels like it should belong to RecoveryFilesDetails too?", "url": "https://github.com/elastic/elasticsearch/pull/59039#discussion_r450057667", "createdAt": "2020-07-06T08:17:36Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/indices/recovery/RecoveryState.java", "diffHunk": "@@ -698,9 +699,41 @@ public String toString() {\n         }\n     }\n \n-    public static class Index extends Timer implements ToXContentFragment, Writeable {\n-\n+    public static class RecoveryFilesDetails {\n         private final Map<String, File> fileDetails = new HashMap<>();\n+\n+        public File addFileDetails(String name, File file) {\n+            return fileDetails.put(name, file);\n+        }\n+\n+        public void addRecoveredBytesToFile(String name, long bytes) {\n+            File file = fileDetails.get(name);\n+            file.addRecoveredBytes(bytes);\n+        }\n+\n+        public File get(String name) {\n+            return fileDetails.get(name);\n+        }\n+\n+        public int size() {\n+            return fileDetails.size();\n+        }\n+\n+        public boolean isEmpty() {\n+            return fileDetails.isEmpty();\n+        }\n+\n+        public void clear() {\n+            fileDetails.clear();\n+        }\n+\n+        public Collection<File> values() {\n+            return fileDetails.values();\n+        }\n+    }\n+\n+    public static class Index extends Timer implements ToXContentFragment, Writeable {\n+        private final RecoveryFilesDetails fileDetails = new RecoveryFilesDetails();\n         private boolean fileDetailsComplete;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "815be65516cef21bb44dfb7d1efd64479496bd0d"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDA1ODU3NQ==", "bodyText": "This assertion feels like it belongs in RecoveryFileDetails too, as does the one that asserts fileDetailsComplete == false.", "url": "https://github.com/elastic/elasticsearch/pull/59039#discussion_r450058575", "createdAt": "2020-07-06T08:19:13Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/indices/recovery/RecoveryState.java", "diffHunk": "@@ -761,7 +794,7 @@ public synchronized void reset() {\n         public synchronized void addFileDetail(String name, long length, boolean reused) {\n             assert fileDetailsComplete == false : \"addFileDetail for [\" + name + \"] when file details are already complete\";\n             File file = new File(name, length, reused);\n-            File existing = fileDetails.put(name, file);\n+            File existing = fileDetails.addFileDetails(name, file);\n             assert existing == null : \"file [\" + name + \"] is already reported\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "815be65516cef21bb44dfb7d1efd64479496bd0d"}, "originalPosition": 67}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQyODg4MDky", "url": "https://github.com/elastic/elasticsearch/pull/59039#pullrequestreview-442888092", "createdAt": "2020-07-06T08:49:05Z", "commit": {"oid": "815be65516cef21bb44dfb7d1efd64479496bd0d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwODo0OTowNVrOGtObgg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwODo0OTowNVrOGtObgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDA3NTUyMg==", "bodyText": "Can we instantiate the File - and check that it does not previously existed - directly within this method?", "url": "https://github.com/elastic/elasticsearch/pull/59039#discussion_r450075522", "createdAt": "2020-07-06T08:49:05Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/indices/recovery/RecoveryState.java", "diffHunk": "@@ -698,9 +699,41 @@ public String toString() {\n         }\n     }\n \n-    public static class Index extends Timer implements ToXContentFragment, Writeable {\n-\n+    public static class RecoveryFilesDetails {\n         private final Map<String, File> fileDetails = new HashMap<>();\n+\n+        public File addFileDetails(String name, File file) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "815be65516cef21bb44dfb7d1efd64479496bd0d"}, "originalPosition": 17}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fef55be0ae020442a28ff76aa36151f36c8cdb2c", "author": {"user": {"login": "fcofdez", "name": "Francisco Fern\u00e1ndez Casta\u00f1o"}}, "url": "https://github.com/elastic/elasticsearch/commit/fef55be0ae020442a28ff76aa36151f36c8cdb2c", "committedDate": "2020-07-06T09:59:14Z", "message": "Move logic to RecoveryFilesDetails (serialization, invariants)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bc92cdb4740ea17b003b166f6fb5657f9c06b037", "author": {"user": {"login": "fcofdez", "name": "Francisco Fern\u00e1ndez Casta\u00f1o"}}, "url": "https://github.com/elastic/elasticsearch/commit/bc92cdb4740ea17b003b166f6fb5657f9c06b037", "committedDate": "2020-07-06T10:02:06Z", "message": "Minor refactor"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQyOTY4MTU3", "url": "https://github.com/elastic/elasticsearch/pull/59039#pullrequestreview-442968157", "createdAt": "2020-07-06T10:46:06Z", "commit": {"oid": "bc92cdb4740ea17b003b166f6fb5657f9c06b037"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQxMDo0NjowNlrOGtSR0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQxMDo1MTo1NFrOGtScLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDEzODU3Nw==", "bodyText": "can we assert that file is not null and prints the name if it is?", "url": "https://github.com/elastic/elasticsearch/pull/59039#discussion_r450138577", "createdAt": "2020-07-06T10:46:06Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/indices/recovery/RecoveryState.java", "diffHunk": "@@ -698,50 +699,123 @@ public String toString() {\n         }\n     }\n \n-    public static class Index extends Timer implements ToXContentFragment, Writeable {\n-\n+    public static class RecoveryFilesDetails implements ToXContentFragment, Writeable {\n         private final Map<String, File> fileDetails = new HashMap<>();\n-        private boolean fileDetailsComplete;\n-\n-        public static final long UNKNOWN = -1L;\n+        private boolean complete;\n \n-        private long sourceThrottlingInNanos = UNKNOWN;\n-        private long targetThrottleTimeInNanos = UNKNOWN;\n-\n-        public Index() {\n+        RecoveryFilesDetails() {\n         }\n \n-        public Index(StreamInput in) throws IOException {\n-            super(in);\n+        RecoveryFilesDetails(StreamInput in) throws IOException {\n             int size = in.readVInt();\n             for (int i = 0; i < size; i++) {\n                 File file = new File(in);\n                 fileDetails.put(file.name, file);\n             }\n             if (in.getVersion().onOrAfter(StoreStats.RESERVED_BYTES_VERSION)) {\n-                fileDetailsComplete = in.readBoolean();\n+                complete = in.readBoolean();\n             } else {\n                 // This flag is used by disk-based allocation to decide whether the remaining bytes measurement is accurate or not; if not\n                 // then it falls back on an estimate. There's only a very short window in which the file details are present but incomplete\n                 // so this is a reasonable approximation, and the stats reported to the disk-based allocator don't hit this code path\n                 // anyway since they always use IndexShard#getRecoveryState which is never transported over the wire.\n-                fileDetailsComplete = fileDetails.isEmpty() == false;\n+                complete = fileDetails.isEmpty() == false;\n             }\n-            sourceThrottlingInNanos = in.readLong();\n-            targetThrottleTimeInNanos = in.readLong();\n         }\n \n         @Override\n-        public synchronized void writeTo(StreamOutput out) throws IOException {\n-            super.writeTo(out);\n-            final File[] files = fileDetails.values().toArray(new File[0]);\n+        public void writeTo(StreamOutput out) throws IOException {\n+            final File[] files = values().toArray(new File[0]);\n             out.writeVInt(files.length);\n             for (File file : files) {\n                 file.writeTo(out);\n             }\n             if (out.getVersion().onOrAfter(StoreStats.RESERVED_BYTES_VERSION)) {\n-                out.writeBoolean(fileDetailsComplete);\n+                out.writeBoolean(complete);\n             }\n+        }\n+\n+        @Override\n+        public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n+            if (params.paramAsBoolean(\"detailed\", false)) {\n+                builder.startArray(Fields.DETAILS);\n+                for (File file : values()) {\n+                    file.toXContent(builder, params);\n+                }\n+                builder.endArray();\n+            }\n+\n+            return builder;\n+        }\n+\n+        public void addFileDetails(String name, long length, boolean reused) {\n+            addFileDetails(name, new File(name, length, reused));\n+        }\n+\n+        public void addFileDetails(String name, File file) {\n+            assert complete == false : \"addFileDetail for [\" + name + \"] when file details are already complete\";\n+            File existing = fileDetails.put(name, file);\n+            assert existing == null : \"file [\" + name + \"] is already reported\";\n+        }\n+\n+        public void addRecoveredBytesToFile(String name, long bytes) {\n+            File file = fileDetails.get(name);\n+            file.addRecoveredBytes(bytes);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc92cdb4740ea17b003b166f6fb5657f9c06b037"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDEzOTg3OQ==", "bodyText": "We're not consistent in the codebase about this, but I'd prefer isComplete() as we have setComplete()", "url": "https://github.com/elastic/elasticsearch/pull/59039#discussion_r450139879", "createdAt": "2020-07-06T10:49:06Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/indices/recovery/RecoveryState.java", "diffHunk": "@@ -698,50 +699,123 @@ public String toString() {\n         }\n     }\n \n-    public static class Index extends Timer implements ToXContentFragment, Writeable {\n-\n+    public static class RecoveryFilesDetails implements ToXContentFragment, Writeable {\n         private final Map<String, File> fileDetails = new HashMap<>();\n-        private boolean fileDetailsComplete;\n-\n-        public static final long UNKNOWN = -1L;\n+        private boolean complete;\n \n-        private long sourceThrottlingInNanos = UNKNOWN;\n-        private long targetThrottleTimeInNanos = UNKNOWN;\n-\n-        public Index() {\n+        RecoveryFilesDetails() {\n         }\n \n-        public Index(StreamInput in) throws IOException {\n-            super(in);\n+        RecoveryFilesDetails(StreamInput in) throws IOException {\n             int size = in.readVInt();\n             for (int i = 0; i < size; i++) {\n                 File file = new File(in);\n                 fileDetails.put(file.name, file);\n             }\n             if (in.getVersion().onOrAfter(StoreStats.RESERVED_BYTES_VERSION)) {\n-                fileDetailsComplete = in.readBoolean();\n+                complete = in.readBoolean();\n             } else {\n                 // This flag is used by disk-based allocation to decide whether the remaining bytes measurement is accurate or not; if not\n                 // then it falls back on an estimate. There's only a very short window in which the file details are present but incomplete\n                 // so this is a reasonable approximation, and the stats reported to the disk-based allocator don't hit this code path\n                 // anyway since they always use IndexShard#getRecoveryState which is never transported over the wire.\n-                fileDetailsComplete = fileDetails.isEmpty() == false;\n+                complete = fileDetails.isEmpty() == false;\n             }\n-            sourceThrottlingInNanos = in.readLong();\n-            targetThrottleTimeInNanos = in.readLong();\n         }\n \n         @Override\n-        public synchronized void writeTo(StreamOutput out) throws IOException {\n-            super.writeTo(out);\n-            final File[] files = fileDetails.values().toArray(new File[0]);\n+        public void writeTo(StreamOutput out) throws IOException {\n+            final File[] files = values().toArray(new File[0]);\n             out.writeVInt(files.length);\n             for (File file : files) {\n                 file.writeTo(out);\n             }\n             if (out.getVersion().onOrAfter(StoreStats.RESERVED_BYTES_VERSION)) {\n-                out.writeBoolean(fileDetailsComplete);\n+                out.writeBoolean(complete);\n             }\n+        }\n+\n+        @Override\n+        public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n+            if (params.paramAsBoolean(\"detailed\", false)) {\n+                builder.startArray(Fields.DETAILS);\n+                for (File file : values()) {\n+                    file.toXContent(builder, params);\n+                }\n+                builder.endArray();\n+            }\n+\n+            return builder;\n+        }\n+\n+        public void addFileDetails(String name, long length, boolean reused) {\n+            addFileDetails(name, new File(name, length, reused));\n+        }\n+\n+        public void addFileDetails(String name, File file) {\n+            assert complete == false : \"addFileDetail for [\" + name + \"] when file details are already complete\";\n+            File existing = fileDetails.put(name, file);\n+            assert existing == null : \"file [\" + name + \"] is already reported\";\n+        }\n+\n+        public void addRecoveredBytesToFile(String name, long bytes) {\n+            File file = fileDetails.get(name);\n+            file.addRecoveredBytes(bytes);\n+        }\n+\n+        public File get(String name) {\n+            return fileDetails.get(name);\n+        }\n+\n+        public void setComplete() {\n+            complete = true;\n+        }\n+\n+        public int size() {\n+            return fileDetails.size();\n+        }\n+\n+        public boolean isEmpty() {\n+            return fileDetails.isEmpty();\n+        }\n+\n+        public void clear() {\n+            fileDetails.clear();\n+            complete = false;\n+        }\n+\n+        public Collection<File> values() {\n+            return fileDetails.values();\n+        }\n+\n+        public boolean complete() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc92cdb4740ea17b003b166f6fb5657f9c06b037"}, "originalPosition": 120}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDE0MTIzMA==", "bodyText": "Can we merge the two addFileDetails() together?", "url": "https://github.com/elastic/elasticsearch/pull/59039#discussion_r450141230", "createdAt": "2020-07-06T10:51:54Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/indices/recovery/RecoveryState.java", "diffHunk": "@@ -698,50 +699,123 @@ public String toString() {\n         }\n     }\n \n-    public static class Index extends Timer implements ToXContentFragment, Writeable {\n-\n+    public static class RecoveryFilesDetails implements ToXContentFragment, Writeable {\n         private final Map<String, File> fileDetails = new HashMap<>();\n-        private boolean fileDetailsComplete;\n-\n-        public static final long UNKNOWN = -1L;\n+        private boolean complete;\n \n-        private long sourceThrottlingInNanos = UNKNOWN;\n-        private long targetThrottleTimeInNanos = UNKNOWN;\n-\n-        public Index() {\n+        RecoveryFilesDetails() {\n         }\n \n-        public Index(StreamInput in) throws IOException {\n-            super(in);\n+        RecoveryFilesDetails(StreamInput in) throws IOException {\n             int size = in.readVInt();\n             for (int i = 0; i < size; i++) {\n                 File file = new File(in);\n                 fileDetails.put(file.name, file);\n             }\n             if (in.getVersion().onOrAfter(StoreStats.RESERVED_BYTES_VERSION)) {\n-                fileDetailsComplete = in.readBoolean();\n+                complete = in.readBoolean();\n             } else {\n                 // This flag is used by disk-based allocation to decide whether the remaining bytes measurement is accurate or not; if not\n                 // then it falls back on an estimate. There's only a very short window in which the file details are present but incomplete\n                 // so this is a reasonable approximation, and the stats reported to the disk-based allocator don't hit this code path\n                 // anyway since they always use IndexShard#getRecoveryState which is never transported over the wire.\n-                fileDetailsComplete = fileDetails.isEmpty() == false;\n+                complete = fileDetails.isEmpty() == false;\n             }\n-            sourceThrottlingInNanos = in.readLong();\n-            targetThrottleTimeInNanos = in.readLong();\n         }\n \n         @Override\n-        public synchronized void writeTo(StreamOutput out) throws IOException {\n-            super.writeTo(out);\n-            final File[] files = fileDetails.values().toArray(new File[0]);\n+        public void writeTo(StreamOutput out) throws IOException {\n+            final File[] files = values().toArray(new File[0]);\n             out.writeVInt(files.length);\n             for (File file : files) {\n                 file.writeTo(out);\n             }\n             if (out.getVersion().onOrAfter(StoreStats.RESERVED_BYTES_VERSION)) {\n-                out.writeBoolean(fileDetailsComplete);\n+                out.writeBoolean(complete);\n             }\n+        }\n+\n+        @Override\n+        public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n+            if (params.paramAsBoolean(\"detailed\", false)) {\n+                builder.startArray(Fields.DETAILS);\n+                for (File file : values()) {\n+                    file.toXContent(builder, params);\n+                }\n+                builder.endArray();\n+            }\n+\n+            return builder;\n+        }\n+\n+        public void addFileDetails(String name, long length, boolean reused) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc92cdb4740ea17b003b166f6fb5657f9c06b037"}, "originalPosition": 80}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "34ff2ad9aa07c585f77f9ba95e1d6c562748a398", "author": {"user": {"login": "fcofdez", "name": "Francisco Fern\u00e1ndez Casta\u00f1o"}}, "url": "https://github.com/elastic/elasticsearch/commit/34ff2ad9aa07c585f77f9ba95e1d6c562748a398", "committedDate": "2020-07-06T11:07:28Z", "message": "Address review comments."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d9a219d29d7f6e04a41b86e71d3623e295dd2e46", "author": {"user": {"login": "elasticmachine", "name": "Elastic Machine"}}, "url": "https://github.com/elastic/elasticsearch/commit/d9a219d29d7f6e04a41b86e71d3623e295dd2e46", "committedDate": "2020-07-06T16:59:54Z", "message": "Merge branch 'master' into extract-recovery-file-details-to-class"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQzNjE2NDY3", "url": "https://github.com/elastic/elasticsearch/pull/59039#pullrequestreview-443616467", "createdAt": "2020-07-07T07:08:35Z", "commit": {"oid": "d9a219d29d7f6e04a41b86e71d3623e295dd2e46"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQzNjE4Mzg3", "url": "https://github.com/elastic/elasticsearch/pull/59039#pullrequestreview-443618387", "createdAt": "2020-07-07T07:11:43Z", "commit": {"oid": "d9a219d29d7f6e04a41b86e71d3623e295dd2e46"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2272, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}