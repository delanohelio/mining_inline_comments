{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI3NzI3Mjg5", "number": 65520, "title": "Autoscaling reactive storage decider", "bodyText": "The reactive storage decider will request additional capacity\nproportional to the size of shards that are either:\n\nunassigned and unable to be allocated with only reason being storage\non a node\nshards that cannot remain where they are with only reason being\nstorage and cannot be allocated anywhere else\nshards that cannot remain where they are and cannot be allocated\non any node and at least one node has storage as the only reason for\nunable to allocate.\n\nThe reactive storage decider does not try to look into the future, thus\nat the time the reactive decider asks to scale up, the cluster is\nalready in a need for more storage.", "createdAt": "2020-11-25T22:48:01Z", "url": "https://github.com/elastic/elasticsearch/pull/65520", "merged": true, "mergeCommit": {"oid": "5e20c0a52904b8e44fbc6586a8e1e39bc9557052"}, "closed": true, "closedAt": "2020-12-13T19:22:38Z", "author": {"login": "henningandersen"}, "timelineItems": {"totalCount": 43, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdgGWkzAH2gAyNTI3NzI3Mjg5OmE1ZTVmNDNhZmM2OTY3ZDk3OWY5Mjk0OWI3NDkwOGNhODljZTEzMDk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdl0Xn7AH2gAyNTI3NzI3Mjg5OjdiNWYzNzBkNzBiYTdlOWIwN2FiMGEzMGZkMWYxZTQ5NDRmYTMxOGI=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "a5e5f43afc6967d979f92949b74908ca89ce1309", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/a5e5f43afc6967d979f92949b74908ca89ce1309", "committedDate": "2020-11-25T22:46:54Z", "message": "Autoscaling reactive storage decider\n\nThe reactive storage decider will request additional capacity\nproportional to the size of shards that are either:\n* unassigned and unable to be allocated with only reason being storage\non a node\n* shards that cannot remain where they are with only reason being\nstorage and cannot be allocated anywhere else\n* shards that cannot remain where they are and cannot be allocated\non any node and at least one node has storage as the only reason for\nunable to allocate.\n\nThe reactive storage decider does not try to look into the future, thus\nat the time the reactive decider asks to scale up, the cluster is\nalready in a need for more storage."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bf2d27e613b6b2af240fec6c46b26c5b49120cc0", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/bf2d27e613b6b2af240fec6c46b26c5b49120cc0", "committedDate": "2020-11-26T11:02:06Z", "message": "Extract DiskUsageIntegTestCase\n\nExtracted DiskUsageIntegTestCase from DiskThresholdDeciderIT to allow\nother tests to easily test functionality relying on disk usage.\n\nRelates #65520"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7fadd0b6257ca124e90f396bf78537ad8bb4ec00", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/7fadd0b6257ca124e90f396bf78537ad8bb4ec00", "committedDate": "2020-11-26T11:02:24Z", "message": "Added integration test."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9f6a430f48b058675cbb7c419a6211a18323b396", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/9f6a430f48b058675cbb7c419a6211a18323b396", "committedDate": "2020-11-26T12:16:52Z", "message": "Added node minimum size too."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3083ff0248d1293a306a26a1440a972b54e9eca0", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/3083ff0248d1293a306a26a1440a972b54e9eca0", "committedDate": "2020-11-26T12:18:50Z", "message": "Spotless."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d06378e54d366bf273c52082fde91a4b144fd17e", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/d06378e54d366bf273c52082fde91a4b144fd17e", "committedDate": "2020-11-26T17:00:47Z", "message": "whitespace"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2c78a0e0e2f294700ce347603b4caf21eeb4e2d2", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/2c78a0e0e2f294700ce347603b4caf21eeb4e2d2", "committedDate": "2020-11-26T18:21:35Z", "message": "cleanup:\n\nallocationDeciders are now given to service at construction time.\nFew test fixes."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e36f6e86d89699ffe9505b43df7e690b646f30c5", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/e36f6e86d89699ffe9505b43df7e690b646f30c5", "committedDate": "2020-11-26T20:45:05Z", "message": "cleanup:\n\nremove context.roles()\nfix unmovable test."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM5NzI4NDQy", "url": "https://github.com/elastic/elasticsearch/pull/65520#pullrequestreview-539728442", "createdAt": "2020-11-27T06:13:12Z", "commit": {"oid": "e36f6e86d89699ffe9505b43df7e690b646f30c5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yN1QwNjoxMzoxMlrOH6yG1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yN1QwNjoxMzoxMlrOH6yG1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTQwMDQwNw==", "bodyText": "The changes in this class does not need review, they are contained in #65540 and will be merged before this is merged.", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r531400407", "createdAt": "2020-11-27T06:13:12Z", "author": {"login": "henningandersen"}, "path": "server/src/internalClusterTest/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderIT.java", "diffHunk": "@@ -37,107 +34,47 @@\n import org.elasticsearch.cluster.routing.allocation.decider.EnableAllocationDecider.Rebalance;\n import org.elasticsearch.cluster.service.ClusterService;\n import org.elasticsearch.common.Priority;\n-import org.elasticsearch.common.io.PathUtils;\n-import org.elasticsearch.common.io.PathUtilsForTesting;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.unit.ByteSizeUnit;\n import org.elasticsearch.common.unit.ByteSizeValue;\n-import org.elasticsearch.core.internal.io.IOUtils;\n-import org.elasticsearch.env.Environment;\n import org.elasticsearch.env.NodeEnvironment;\n-import org.elasticsearch.monitor.fs.FsService;\n-import org.elasticsearch.plugins.Plugin;\n import org.elasticsearch.repositories.fs.FsRepository;\n import org.elasticsearch.snapshots.RestoreInfo;\n import org.elasticsearch.snapshots.SnapshotInfo;\n import org.elasticsearch.snapshots.SnapshotState;\n import org.elasticsearch.test.ESIntegTestCase;\n-import org.elasticsearch.test.InternalSettingsPlugin;\n import org.hamcrest.Matcher;\n-import org.junit.After;\n-import org.junit.Before;\n-\n-import java.io.FileNotFoundException;\n-import java.io.IOException;\n-import java.nio.file.DirectoryStream;\n-import java.nio.file.FileStore;\n-import java.nio.file.FileSystem;\n-import java.nio.file.Files;\n-import java.nio.file.NoSuchFileException;\n-import java.nio.file.NotDirectoryException;\n-import java.nio.file.Path;\n+\n import java.util.Arrays;\n-import java.util.Collection;\n import java.util.HashSet;\n-import java.util.List;\n import java.util.Locale;\n-import java.util.Map;\n import java.util.Set;\n import java.util.concurrent.TimeUnit;\n-import java.util.stream.Collectors;\n import java.util.stream.StreamSupport;\n \n-import static org.elasticsearch.common.util.concurrent.ConcurrentCollections.newConcurrentMap;\n import static org.elasticsearch.index.store.Store.INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING;\n import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;\n-import static org.hamcrest.Matchers.anyOf;\n import static org.hamcrest.Matchers.empty;\n import static org.hamcrest.Matchers.equalTo;\n-import static org.hamcrest.Matchers.greaterThan;\n import static org.hamcrest.Matchers.hasSize;\n import static org.hamcrest.Matchers.is;\n \n @ESIntegTestCase.ClusterScope(scope = ESIntegTestCase.Scope.TEST, numDataNodes = 0)\n-public class DiskThresholdDeciderIT extends ESIntegTestCase {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e36f6e86d89699ffe9505b43df7e690b646f30c5"}, "originalPosition": 73}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM5NzI4NTE0", "url": "https://github.com/elastic/elasticsearch/pull/65520#pullrequestreview-539728514", "createdAt": "2020-11-27T06:13:26Z", "commit": {"oid": "e36f6e86d89699ffe9505b43df7e690b646f30c5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yN1QwNjoxMzoyNlrOH6yHAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yN1QwNjoxMzoyNlrOH6yHAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTQwMDQ0OA==", "bodyText": "The changes in this class does not need review, they are contained in #65540 and will be merged before this is merged.", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r531400448", "createdAt": "2020-11-27T06:13:26Z", "author": {"login": "henningandersen"}, "path": "test/framework/src/main/java/org/elasticsearch/cluster/DiskUsageIntegTestCase.java", "diffHunk": "@@ -0,0 +1,236 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.cluster;\n+\n+import org.apache.lucene.mockfile.FilterFileStore;\n+import org.apache.lucene.mockfile.FilterFileSystemProvider;\n+import org.apache.lucene.mockfile.FilterPath;\n+import org.apache.lucene.util.Constants;\n+import org.elasticsearch.common.io.PathUtils;\n+import org.elasticsearch.common.io.PathUtilsForTesting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.core.internal.io.IOUtils;\n+import org.elasticsearch.env.Environment;\n+import org.elasticsearch.monitor.fs.FsService;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.test.ESIntegTestCase;\n+import org.elasticsearch.test.InternalSettingsPlugin;\n+import org.junit.After;\n+import org.junit.Before;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.nio.file.DirectoryStream;\n+import java.nio.file.FileStore;\n+import java.nio.file.FileSystem;\n+import java.nio.file.Files;\n+import java.nio.file.NoSuchFileException;\n+import java.nio.file.NotDirectoryException;\n+import java.nio.file.Path;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import static org.elasticsearch.common.util.concurrent.ConcurrentCollections.newConcurrentMap;\n+import static org.hamcrest.Matchers.anyOf;\n+import static org.hamcrest.Matchers.greaterThan;\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.is;\n+\n+/**\n+ * An integration test case that allows mocking the disk usage per node. Notice that only files count towards disk usage and translog and\n+ * state files are disregarded.\n+ */\n+public class DiskUsageIntegTestCase extends ESIntegTestCase {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e36f6e86d89699ffe9505b43df7e690b646f30c5"}, "originalPosition": 63}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ca90d2c50053db10eb9ebf79c490a9a5b83a4cb2", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/ca90d2c50053db10eb9ebf79c490a9a5b83a4cb2", "committedDate": "2020-11-27T13:57:13Z", "message": "cleanup:\n\nUse roles rather than node name in test.\nRemove unused logger."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "55e96e3522d20c93e534f97bdf32d79f7f7e79c7", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/55e96e3522d20c93e534f97bdf32d79f7f7e79c7", "committedDate": "2020-11-27T14:06:22Z", "message": "Remove AllocationState.state()"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c3f17bb486a376f983ca95156584159990e8ca96", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/c3f17bb486a376f983ca95156584159990e8ca96", "committedDate": "2020-11-27T14:08:53Z", "message": "Make AllocationState package private."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d72b70ab725ee59419df9b5472643427863d8e6e", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/d72b70ab725ee59419df9b5472643427863d8e6e", "committedDate": "2020-11-27T14:12:00Z", "message": "spotless"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0567d0b6b83cd7338f4c61da3ba5a00539e538f6", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/0567d0b6b83cd7338f4c61da3ba5a00539e538f6", "committedDate": "2020-11-27T14:16:46Z", "message": "No copyShards"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ea2198963032f17db06c66de9c09824065feb397", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/ea2198963032f17db06c66de9c09824065feb397", "committedDate": "2020-11-27T14:18:39Z", "message": "spelling"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2a85928862aa5bb8a850adc9358e36dbb0453997", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/2a85928862aa5bb8a850adc9358e36dbb0453997", "committedDate": "2020-11-27T14:20:15Z", "message": "ClusterInfo.EMPTY"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0990564f6759c5200c9feb4736bf83e7b7901c3f", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/0990564f6759c5200c9feb4736bf83e7b7901c3f", "committedDate": "2020-11-28T17:39:57Z", "message": "simplify nodesInTier"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8aa29ee1dbab94eb6dd25c68c6c44e597248078a", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/8aa29ee1dbab94eb6dd25c68c6c44e597248078a", "committedDate": "2020-11-28T20:32:04Z", "message": "spotless"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9cade4f269cb323131d344342ff9e401d829ee61", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/9cade4f269cb323131d344342ff9e401d829ee61", "committedDate": "2020-11-28T20:33:46Z", "message": "Remove bad comment"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1a9fcc20184ed8fba2366cdf5ef6581a1460bf99", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/1a9fcc20184ed8fba2366cdf5ef6581a1460bf99", "committedDate": "2020-11-28T20:37:22Z", "message": "nodes are unnecessary for snapshot"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "592117e9f0f1b879ae160418df4a4383be1308ca", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/592117e9f0f1b879ae160418df4a4383be1308ca", "committedDate": "2020-11-28T20:51:22Z", "message": "Add assert message to explain"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b716fefa977fcbef2fe230d8a004843572c8db1b", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/b716fefa977fcbef2fe230d8a004843572c8db1b", "committedDate": "2020-11-28T21:06:22Z", "message": "Use withRoutingAllocation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d51abebc3113fd26fd754742dcad3459ab46394c", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/d51abebc3113fd26fd754742dcad3459ab46394c", "committedDate": "2020-11-28T21:31:06Z", "message": "private and VerificationSubject"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b93deb5bab184e0063188bc593982c7d5fafa163", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/b93deb5bab184e0063188bc593982c7d5fafa163", "committedDate": "2020-11-28T21:36:14Z", "message": "do not create deciders twice"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "96aa72741c62987ada6d6df3785edf843b7a39b7", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/96aa72741c62987ada6d6df3785edf843b7a39b7", "committedDate": "2020-11-28T21:48:53Z", "message": "private and remove unused"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "699c9dc12372ebd3af17917b30052c727cc71886", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/699c9dc12372ebd3af17917b30052c727cc71886", "committedDate": "2020-11-28T21:52:17Z", "message": "final and expression lambda"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "281b1d3f50dbb0d3d215f42848040f34992eaedc", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/281b1d3f50dbb0d3d215f42848040f34992eaedc", "committedDate": "2020-11-28T21:56:50Z", "message": "ws"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "692f39f6642c5efbaeb9cf774e2e0288962b81db", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/692f39f6642c5efbaeb9cf774e2e0288962b81db", "committedDate": "2020-11-28T22:08:36Z", "message": "Method order"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "59b7f9efc1e1af1b5e34e5f59fc4b4dc0f33f5a0", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/59b7f9efc1e1af1b5e34e5f59fc4b4dc0f33f5a0", "committedDate": "2020-11-28T22:11:52Z", "message": "Merge remote-tracking branch 'origin/master' into enhance_reactive_storage_autoscaler_pr_final"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "51a09f32f80390dbf3b579ff6edc9954e1e855de", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/51a09f32f80390dbf3b579ff6edc9954e1e855de", "committedDate": "2020-11-28T23:08:14Z", "message": "cs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5738ed325539e4d5feac77cade2e2ebff01272e5", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/5738ed325539e4d5feac77cade2e2ebff01272e5", "committedDate": "2020-12-04T07:35:37Z", "message": "Merge remote-tracking branch 'origin/master' into enhance_reactive_storage_autoscaler_pr_final"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "381c46348c027edd98b1d85bdfe913fed46b70fd", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/381c46348c027edd98b1d85bdfe913fed46b70fd", "committedDate": "2020-12-07T11:23:38Z", "message": "Wire serialization tests for reactive"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fa0f2b7caadb7fc40fabb861492d6764a8f0736f", "author": {"user": {"login": "elasticmachine", "name": "Elastic Machine"}}, "url": "https://github.com/elastic/elasticsearch/commit/fa0f2b7caadb7fc40fabb861492d6764a8f0736f", "committedDate": "2020-12-07T15:21:06Z", "message": "Merge branch 'master' into enhance_reactive_storage_autoscaler_pr_final"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5ec44064832aaefe1cf35b803d405b68ff549180", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/5ec44064832aaefe1cf35b803d405b68ff549180", "committedDate": "2020-12-09T21:22:40Z", "message": "Merge remote-tracking branch 'origin/master' into enhance_reactive_storage_autoscaler_pr_final"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "35a937e237d12b94d0caeec49d01480e1fbd3dee", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/35a937e237d12b94d0caeec49d01480e1fbd3dee", "committedDate": "2020-12-09T21:23:19Z", "message": "Merge branch 'enhance_reactive_storage_autoscaler_pr_final' of github.com:henningandersen/elasticsearch into enhance_reactive_storage_autoscaler_pr_final"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f28fb9a0ed9cc82720505c884887107b0cb96270", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/f28fb9a0ed9cc82720505c884887107b0cb96270", "committedDate": "2020-12-10T10:03:12Z", "message": "Merge remote-tracking branch 'origin/master' into enhance_reactive_storage_autoscaler_pr_final"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUwOTIwMDkx", "url": "https://github.com/elastic/elasticsearch/pull/65520#pullrequestreview-550920091", "createdAt": "2020-12-13T13:20:55Z", "commit": {"oid": "f28fb9a0ed9cc82720505c884887107b0cb96270"}, "state": "APPROVED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xM1QxMzoyMDo1NVrOIE0cXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xM1QxMzo0ODo1NlrOIE0vig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyNDQ0Ng==", "bodyText": "Could you add Javadocs to these new methods, and also state?", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541924446", "createdAt": "2020-12-13T13:20:55Z", "author": {"login": "jasontedor"}, "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/capacity/AutoscalingDeciderContext.java", "diffHunk": "@@ -24,4 +26,8 @@\n      * Return the nodes governed by the policy.\n      */\n     Set<DiscoveryNode> nodes();\n+\n+    ClusterInfo info();\n+\n+    SnapshotShardSizeInfo snapshotShardSizeInfo();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f28fb9a0ed9cc82720505c884887107b0cb96270"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyNTI3OQ==", "bodyText": "We'll probably want a test that collects all the roles that return true for DiscoveryNodeRole#canContainData and ensure they are returned in this list. I'm thinking of when we add a role for frozen, ensuring that this list is maintained properly.", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541925279", "createdAt": "2020-12-13T13:25:35Z", "author": {"login": "jasontedor"}, "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.ClusterInfo;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.DiskUsage;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.cluster.routing.allocation.decider.Decision;\n+import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.snapshots.SnapshotShardSizeInfo;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class ReactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"reactive_storage\";\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ReactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<Setting<?>> deciderSettings() {\n+        return List.of();\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(\n+            DiscoveryNodeRole.DATA_ROLE,\n+            DataTier.DATA_CONTENT_NODE_ROLE,\n+            DataTier.DATA_HOT_NODE_ROLE,\n+            DataTier.DATA_WARM_NODE_ROLE,\n+            DataTier.DATA_COLD_NODE_ROLE", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f28fb9a0ed9cc82720505c884887107b0cb96270"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyNjE3NA==", "bodyText": "\ud83d\udc4d", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541926174", "createdAt": "2020-12-13T13:30:46Z", "author": {"login": "jasontedor"}, "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.ClusterInfo;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.DiskUsage;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.cluster.routing.allocation.decider.Decision;\n+import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.snapshots.SnapshotShardSizeInfo;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class ReactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"reactive_storage\";\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ReactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<Setting<?>> deciderSettings() {\n+        return List.of();\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(\n+            DiscoveryNodeRole.DATA_ROLE,\n+            DataTier.DATA_CONTENT_NODE_ROLE,\n+            DataTier.DATA_HOT_NODE_ROLE,\n+            DataTier.DATA_WARM_NODE_ROLE,\n+            DataTier.DATA_COLD_NODE_ROLE\n+        );\n+    }\n+\n+    @Override\n+    public AutoscalingDeciderResult scale(Settings configuration, AutoscalingDeciderContext context) {\n+        AutoscalingCapacity autoscalingCapacity = context.currentCapacity();\n+        if (autoscalingCapacity == null || autoscalingCapacity.total().storage() == null) {\n+            return new AutoscalingDeciderResult(null, new ReactiveReason(\"current capacity not available\", -1, -1));\n+        }\n+\n+        AllocationState allocationState = new AllocationState(context, diskThresholdSettings, allocationDeciders);\n+        long unassigned = allocationState.storagePreventsAllocation();\n+        long assigned = allocationState.storagePreventsRemainOrMove();\n+        long maxShard = allocationState.maxShardSize();\n+        assert assigned >= 0;\n+        assert unassigned >= 0;\n+        assert maxShard >= 0;\n+        String message = unassigned > 0 || assigned > 0 ? \"not enough storage available, needs \" + (unassigned + assigned) : \"storage ok\";\n+        AutoscalingCapacity requiredCapacity = AutoscalingCapacity.builder()\n+            .total(autoscalingCapacity.total().storage().getBytes() + unassigned + assigned, null)\n+            .node(maxShard, null)\n+            .build();\n+        return new AutoscalingDeciderResult(requiredCapacity, new ReactiveReason(message, unassigned, assigned));\n+    }\n+\n+    static boolean isDiskOnlyNoDecision(Decision decision) {\n+        // we consider throttling==yes, throttling should be temporary.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f28fb9a0ed9cc82720505c884887107b0cb96270"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyODI2Mw==", "bodyText": "Can you leave a comment explaining why we need to enable allocation debugging here?", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541928263", "createdAt": "2020-12-13T13:42:25Z", "author": {"login": "jasontedor"}, "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.ClusterInfo;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.DiskUsage;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.cluster.routing.allocation.decider.Decision;\n+import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.snapshots.SnapshotShardSizeInfo;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class ReactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"reactive_storage\";\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ReactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<Setting<?>> deciderSettings() {\n+        return List.of();\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(\n+            DiscoveryNodeRole.DATA_ROLE,\n+            DataTier.DATA_CONTENT_NODE_ROLE,\n+            DataTier.DATA_HOT_NODE_ROLE,\n+            DataTier.DATA_WARM_NODE_ROLE,\n+            DataTier.DATA_COLD_NODE_ROLE\n+        );\n+    }\n+\n+    @Override\n+    public AutoscalingDeciderResult scale(Settings configuration, AutoscalingDeciderContext context) {\n+        AutoscalingCapacity autoscalingCapacity = context.currentCapacity();\n+        if (autoscalingCapacity == null || autoscalingCapacity.total().storage() == null) {\n+            return new AutoscalingDeciderResult(null, new ReactiveReason(\"current capacity not available\", -1, -1));\n+        }\n+\n+        AllocationState allocationState = new AllocationState(context, diskThresholdSettings, allocationDeciders);\n+        long unassigned = allocationState.storagePreventsAllocation();\n+        long assigned = allocationState.storagePreventsRemainOrMove();\n+        long maxShard = allocationState.maxShardSize();\n+        assert assigned >= 0;\n+        assert unassigned >= 0;\n+        assert maxShard >= 0;\n+        String message = unassigned > 0 || assigned > 0 ? \"not enough storage available, needs \" + (unassigned + assigned) : \"storage ok\";\n+        AutoscalingCapacity requiredCapacity = AutoscalingCapacity.builder()\n+            .total(autoscalingCapacity.total().storage().getBytes() + unassigned + assigned, null)\n+            .node(maxShard, null)\n+            .build();\n+        return new AutoscalingDeciderResult(requiredCapacity, new ReactiveReason(message, unassigned, assigned));\n+    }\n+\n+    static boolean isDiskOnlyNoDecision(Decision decision) {\n+        // we consider throttling==yes, throttling should be temporary.\n+        List<Decision> nos = decision.getDecisions()\n+            .stream()\n+            .filter(single -> single.type() == Decision.Type.NO)\n+            .collect(Collectors.toList());\n+        return nos.size() == 1 && DiskThresholdDecider.NAME.equals(nos.get(0).label());\n+    }\n+\n+    static class AllocationState {\n+        private final ClusterState state;\n+        private final AllocationDeciders allocationDeciders;\n+        private final DiskThresholdSettings diskThresholdSettings;\n+        private final ClusterInfo info;\n+        private final SnapshotShardSizeInfo shardSizeInfo;\n+        private final Predicate<DiscoveryNode> nodeTierPredicate;\n+        private final Set<DiscoveryNode> nodes;\n+\n+        AllocationState(\n+            AutoscalingDeciderContext context,\n+            DiskThresholdSettings diskThresholdSettings,\n+            AllocationDeciders allocationDeciders\n+        ) {\n+            this(\n+                context.state(),\n+                allocationDeciders,\n+                diskThresholdSettings,\n+                context.info(),\n+                context.snapshotShardSizeInfo(),\n+                context.nodes()\n+            );\n+        }\n+\n+        AllocationState(\n+            ClusterState state,\n+            AllocationDeciders allocationDeciders,\n+            DiskThresholdSettings diskThresholdSettings,\n+            ClusterInfo info,\n+            SnapshotShardSizeInfo shardSizeInfo,\n+            Set<DiscoveryNode> nodes\n+        ) {\n+            this.state = state;\n+            this.allocationDeciders = allocationDeciders;\n+            this.diskThresholdSettings = diskThresholdSettings;\n+            this.info = info;\n+            this.shardSizeInfo = shardSizeInfo;\n+            this.nodes = nodes;\n+            this.nodeTierPredicate = nodes::contains;\n+        }\n+\n+        public long storagePreventsAllocation() {\n+            RoutingNodes routingNodes = new RoutingNodes(state, false);\n+            RoutingAllocation allocation = new RoutingAllocation(\n+                allocationDeciders,\n+                routingNodes,\n+                state,\n+                info,\n+                shardSizeInfo,\n+                System.nanoTime()\n+            );\n+            return StreamSupport.stream(state.getRoutingNodes().unassigned().spliterator(), false)\n+                .filter(shard -> canAllocate(shard, allocation) == false)\n+                .filter(shard -> cannotAllocateDueToStorage(shard, allocation))\n+                .mapToLong(this::sizeOf)\n+                .sum();\n+        }\n+\n+        public long storagePreventsRemainOrMove() {\n+            RoutingNodes routingNodes = new RoutingNodes(state, false);\n+            RoutingAllocation allocation = new RoutingAllocation(\n+                allocationDeciders,\n+                routingNodes,\n+                state,\n+                info,\n+                shardSizeInfo,\n+                System.nanoTime()\n+            );\n+            List<ShardRouting> candidates = state.getRoutingNodes()\n+                .shardsWithState(ShardRoutingState.STARTED)\n+                .stream()\n+                .filter(shard -> allocationDeciders.canRemain(shard, routingNodes.node(shard.currentNodeId()), allocation) == Decision.NO)\n+                .filter(shard -> canAllocate(shard, allocation) == false)\n+                .collect(Collectors.toList());\n+\n+            // track these to ensure we do not double account if they both cannot remain and allocated due to storage.\n+            Set<ShardRouting> unmovableShards = candidates.stream()\n+                .filter(s -> allocatedToTier(s, allocation))\n+                .filter(s -> cannotRemainDueToStorage(s, allocation))\n+                .collect(Collectors.toSet());\n+            long unmovableBytes = unmovableShards.stream()\n+                .collect(Collectors.groupingBy(ShardRouting::currentNodeId))\n+                .entrySet()\n+                .stream()\n+                .mapToLong(e -> unmovableSize(e.getKey(), e.getValue()))\n+                .sum();\n+\n+            long unallocatableBytes = candidates.stream()\n+                .filter(Predicate.not(unmovableShards::contains))\n+                .filter(s1 -> cannotAllocateDueToStorage(s1, allocation))\n+                .mapToLong(this::sizeOf)\n+                .sum();\n+\n+            return unallocatableBytes + unmovableBytes;\n+        }\n+\n+        private boolean allocatedToTier(ShardRouting s, RoutingAllocation allocation) {\n+            return nodeTierPredicate.test(allocation.routingNodes().node(s.currentNodeId()).node());\n+        }\n+\n+        /**\n+         * Check that disk decider is only decider for a node preventing allocation of the shard.\n+         * @return true if and only if a node exists in the tier where only disk decider prevents allocation\n+         */\n+        private boolean cannotAllocateDueToStorage(ShardRouting shard, RoutingAllocation allocation) {\n+            assert allocation.debugDecision() == false;\n+            allocation.debugDecision(true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f28fb9a0ed9cc82720505c884887107b0cb96270"}, "originalPosition": 216}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyODI4NA==", "bodyText": "Can you leave a comment explaining why we need to enable allocation debugging here?", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541928284", "createdAt": "2020-12-13T13:42:30Z", "author": {"login": "jasontedor"}, "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.ClusterInfo;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.DiskUsage;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.cluster.routing.allocation.decider.Decision;\n+import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.snapshots.SnapshotShardSizeInfo;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class ReactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"reactive_storage\";\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ReactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<Setting<?>> deciderSettings() {\n+        return List.of();\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(\n+            DiscoveryNodeRole.DATA_ROLE,\n+            DataTier.DATA_CONTENT_NODE_ROLE,\n+            DataTier.DATA_HOT_NODE_ROLE,\n+            DataTier.DATA_WARM_NODE_ROLE,\n+            DataTier.DATA_COLD_NODE_ROLE\n+        );\n+    }\n+\n+    @Override\n+    public AutoscalingDeciderResult scale(Settings configuration, AutoscalingDeciderContext context) {\n+        AutoscalingCapacity autoscalingCapacity = context.currentCapacity();\n+        if (autoscalingCapacity == null || autoscalingCapacity.total().storage() == null) {\n+            return new AutoscalingDeciderResult(null, new ReactiveReason(\"current capacity not available\", -1, -1));\n+        }\n+\n+        AllocationState allocationState = new AllocationState(context, diskThresholdSettings, allocationDeciders);\n+        long unassigned = allocationState.storagePreventsAllocation();\n+        long assigned = allocationState.storagePreventsRemainOrMove();\n+        long maxShard = allocationState.maxShardSize();\n+        assert assigned >= 0;\n+        assert unassigned >= 0;\n+        assert maxShard >= 0;\n+        String message = unassigned > 0 || assigned > 0 ? \"not enough storage available, needs \" + (unassigned + assigned) : \"storage ok\";\n+        AutoscalingCapacity requiredCapacity = AutoscalingCapacity.builder()\n+            .total(autoscalingCapacity.total().storage().getBytes() + unassigned + assigned, null)\n+            .node(maxShard, null)\n+            .build();\n+        return new AutoscalingDeciderResult(requiredCapacity, new ReactiveReason(message, unassigned, assigned));\n+    }\n+\n+    static boolean isDiskOnlyNoDecision(Decision decision) {\n+        // we consider throttling==yes, throttling should be temporary.\n+        List<Decision> nos = decision.getDecisions()\n+            .stream()\n+            .filter(single -> single.type() == Decision.Type.NO)\n+            .collect(Collectors.toList());\n+        return nos.size() == 1 && DiskThresholdDecider.NAME.equals(nos.get(0).label());\n+    }\n+\n+    static class AllocationState {\n+        private final ClusterState state;\n+        private final AllocationDeciders allocationDeciders;\n+        private final DiskThresholdSettings diskThresholdSettings;\n+        private final ClusterInfo info;\n+        private final SnapshotShardSizeInfo shardSizeInfo;\n+        private final Predicate<DiscoveryNode> nodeTierPredicate;\n+        private final Set<DiscoveryNode> nodes;\n+\n+        AllocationState(\n+            AutoscalingDeciderContext context,\n+            DiskThresholdSettings diskThresholdSettings,\n+            AllocationDeciders allocationDeciders\n+        ) {\n+            this(\n+                context.state(),\n+                allocationDeciders,\n+                diskThresholdSettings,\n+                context.info(),\n+                context.snapshotShardSizeInfo(),\n+                context.nodes()\n+            );\n+        }\n+\n+        AllocationState(\n+            ClusterState state,\n+            AllocationDeciders allocationDeciders,\n+            DiskThresholdSettings diskThresholdSettings,\n+            ClusterInfo info,\n+            SnapshotShardSizeInfo shardSizeInfo,\n+            Set<DiscoveryNode> nodes\n+        ) {\n+            this.state = state;\n+            this.allocationDeciders = allocationDeciders;\n+            this.diskThresholdSettings = diskThresholdSettings;\n+            this.info = info;\n+            this.shardSizeInfo = shardSizeInfo;\n+            this.nodes = nodes;\n+            this.nodeTierPredicate = nodes::contains;\n+        }\n+\n+        public long storagePreventsAllocation() {\n+            RoutingNodes routingNodes = new RoutingNodes(state, false);\n+            RoutingAllocation allocation = new RoutingAllocation(\n+                allocationDeciders,\n+                routingNodes,\n+                state,\n+                info,\n+                shardSizeInfo,\n+                System.nanoTime()\n+            );\n+            return StreamSupport.stream(state.getRoutingNodes().unassigned().spliterator(), false)\n+                .filter(shard -> canAllocate(shard, allocation) == false)\n+                .filter(shard -> cannotAllocateDueToStorage(shard, allocation))\n+                .mapToLong(this::sizeOf)\n+                .sum();\n+        }\n+\n+        public long storagePreventsRemainOrMove() {\n+            RoutingNodes routingNodes = new RoutingNodes(state, false);\n+            RoutingAllocation allocation = new RoutingAllocation(\n+                allocationDeciders,\n+                routingNodes,\n+                state,\n+                info,\n+                shardSizeInfo,\n+                System.nanoTime()\n+            );\n+            List<ShardRouting> candidates = state.getRoutingNodes()\n+                .shardsWithState(ShardRoutingState.STARTED)\n+                .stream()\n+                .filter(shard -> allocationDeciders.canRemain(shard, routingNodes.node(shard.currentNodeId()), allocation) == Decision.NO)\n+                .filter(shard -> canAllocate(shard, allocation) == false)\n+                .collect(Collectors.toList());\n+\n+            // track these to ensure we do not double account if they both cannot remain and allocated due to storage.\n+            Set<ShardRouting> unmovableShards = candidates.stream()\n+                .filter(s -> allocatedToTier(s, allocation))\n+                .filter(s -> cannotRemainDueToStorage(s, allocation))\n+                .collect(Collectors.toSet());\n+            long unmovableBytes = unmovableShards.stream()\n+                .collect(Collectors.groupingBy(ShardRouting::currentNodeId))\n+                .entrySet()\n+                .stream()\n+                .mapToLong(e -> unmovableSize(e.getKey(), e.getValue()))\n+                .sum();\n+\n+            long unallocatableBytes = candidates.stream()\n+                .filter(Predicate.not(unmovableShards::contains))\n+                .filter(s1 -> cannotAllocateDueToStorage(s1, allocation))\n+                .mapToLong(this::sizeOf)\n+                .sum();\n+\n+            return unallocatableBytes + unmovableBytes;\n+        }\n+\n+        private boolean allocatedToTier(ShardRouting s, RoutingAllocation allocation) {\n+            return nodeTierPredicate.test(allocation.routingNodes().node(s.currentNodeId()).node());\n+        }\n+\n+        /**\n+         * Check that disk decider is only decider for a node preventing allocation of the shard.\n+         * @return true if and only if a node exists in the tier where only disk decider prevents allocation\n+         */\n+        private boolean cannotAllocateDueToStorage(ShardRouting shard, RoutingAllocation allocation) {\n+            assert allocation.debugDecision() == false;\n+            allocation.debugDecision(true);\n+            try {\n+                return nodesInTier(allocation.routingNodes()).map(node -> allocationDeciders.canAllocate(shard, node, allocation))\n+                    .anyMatch(ReactiveStorageDeciderService::isDiskOnlyNoDecision);\n+            } finally {\n+                allocation.debugDecision(false);\n+            }\n+        }\n+\n+        /**\n+         * Check that the disk decider is only decider that says NO to let shard remain on current node.\n+         * @return true if and only if disk decider is only decider that says NO to canRemain.\n+         */\n+        private boolean cannotRemainDueToStorage(ShardRouting shard, RoutingAllocation allocation) {\n+            assert allocation.debugDecision() == false;\n+            allocation.debugDecision(true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f28fb9a0ed9cc82720505c884887107b0cb96270"}, "originalPosition": 231}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyODU5Mw==", "bodyText": "Minor nit: since these represent bytes and not a count of shards, could we clarify the names: unassignedBytes, assignedBytes, and maxShardSize?", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541928593", "createdAt": "2020-12-13T13:44:30Z", "author": {"login": "jasontedor"}, "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.ClusterInfo;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.DiskUsage;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.cluster.routing.allocation.decider.Decision;\n+import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.snapshots.SnapshotShardSizeInfo;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class ReactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"reactive_storage\";\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ReactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<Setting<?>> deciderSettings() {\n+        return List.of();\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(\n+            DiscoveryNodeRole.DATA_ROLE,\n+            DataTier.DATA_CONTENT_NODE_ROLE,\n+            DataTier.DATA_HOT_NODE_ROLE,\n+            DataTier.DATA_WARM_NODE_ROLE,\n+            DataTier.DATA_COLD_NODE_ROLE\n+        );\n+    }\n+\n+    @Override\n+    public AutoscalingDeciderResult scale(Settings configuration, AutoscalingDeciderContext context) {\n+        AutoscalingCapacity autoscalingCapacity = context.currentCapacity();\n+        if (autoscalingCapacity == null || autoscalingCapacity.total().storage() == null) {\n+            return new AutoscalingDeciderResult(null, new ReactiveReason(\"current capacity not available\", -1, -1));\n+        }\n+\n+        AllocationState allocationState = new AllocationState(context, diskThresholdSettings, allocationDeciders);\n+        long unassigned = allocationState.storagePreventsAllocation();\n+        long assigned = allocationState.storagePreventsRemainOrMove();\n+        long maxShard = allocationState.maxShardSize();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f28fb9a0ed9cc82720505c884887107b0cb96270"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyOTI3OA==", "bodyText": "I wonder if this should be human readable bytes? So new ByteSizeValue(unassigned + assigned).toString()?", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541929278", "createdAt": "2020-12-13T13:48:32Z", "author": {"login": "jasontedor"}, "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.ClusterInfo;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.DiskUsage;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.cluster.routing.allocation.decider.Decision;\n+import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.snapshots.SnapshotShardSizeInfo;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class ReactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"reactive_storage\";\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ReactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<Setting<?>> deciderSettings() {\n+        return List.of();\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(\n+            DiscoveryNodeRole.DATA_ROLE,\n+            DataTier.DATA_CONTENT_NODE_ROLE,\n+            DataTier.DATA_HOT_NODE_ROLE,\n+            DataTier.DATA_WARM_NODE_ROLE,\n+            DataTier.DATA_COLD_NODE_ROLE\n+        );\n+    }\n+\n+    @Override\n+    public AutoscalingDeciderResult scale(Settings configuration, AutoscalingDeciderContext context) {\n+        AutoscalingCapacity autoscalingCapacity = context.currentCapacity();\n+        if (autoscalingCapacity == null || autoscalingCapacity.total().storage() == null) {\n+            return new AutoscalingDeciderResult(null, new ReactiveReason(\"current capacity not available\", -1, -1));\n+        }\n+\n+        AllocationState allocationState = new AllocationState(context, diskThresholdSettings, allocationDeciders);\n+        long unassigned = allocationState.storagePreventsAllocation();\n+        long assigned = allocationState.storagePreventsRemainOrMove();\n+        long maxShard = allocationState.maxShardSize();\n+        assert assigned >= 0;\n+        assert unassigned >= 0;\n+        assert maxShard >= 0;\n+        String message = unassigned > 0 || assigned > 0 ? \"not enough storage available, needs \" + (unassigned + assigned) : \"storage ok\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f28fb9a0ed9cc82720505c884887107b0cb96270"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyOTM1NA==", "bodyText": "And if not,  bytes should be appended to the message.", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541929354", "createdAt": "2020-12-13T13:48:56Z", "author": {"login": "jasontedor"}, "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.ClusterInfo;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.DiskUsage;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.cluster.routing.allocation.decider.Decision;\n+import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.snapshots.SnapshotShardSizeInfo;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class ReactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"reactive_storage\";\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ReactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<Setting<?>> deciderSettings() {\n+        return List.of();\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(\n+            DiscoveryNodeRole.DATA_ROLE,\n+            DataTier.DATA_CONTENT_NODE_ROLE,\n+            DataTier.DATA_HOT_NODE_ROLE,\n+            DataTier.DATA_WARM_NODE_ROLE,\n+            DataTier.DATA_COLD_NODE_ROLE\n+        );\n+    }\n+\n+    @Override\n+    public AutoscalingDeciderResult scale(Settings configuration, AutoscalingDeciderContext context) {\n+        AutoscalingCapacity autoscalingCapacity = context.currentCapacity();\n+        if (autoscalingCapacity == null || autoscalingCapacity.total().storage() == null) {\n+            return new AutoscalingDeciderResult(null, new ReactiveReason(\"current capacity not available\", -1, -1));\n+        }\n+\n+        AllocationState allocationState = new AllocationState(context, diskThresholdSettings, allocationDeciders);\n+        long unassigned = allocationState.storagePreventsAllocation();\n+        long assigned = allocationState.storagePreventsRemainOrMove();\n+        long maxShard = allocationState.maxShardSize();\n+        assert assigned >= 0;\n+        assert unassigned >= 0;\n+        assert maxShard >= 0;\n+        String message = unassigned > 0 || assigned > 0 ? \"not enough storage available, needs \" + (unassigned + assigned) : \"storage ok\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyOTI3OA=="}, "originalCommit": {"oid": "f28fb9a0ed9cc82720505c884887107b0cb96270"}, "originalPosition": 93}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "22456be13356107f7d98e09b40a593d2a8de3220", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/22456be13356107f7d98e09b40a593d2a8de3220", "committedDate": "2020-12-13T15:05:19Z", "message": "Javadoc on AutoscalingDeciderContext"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "555991a425f911d289a21c0a30c7e3834b9e2fd5", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/555991a425f911d289a21c0a30c7e3834b9e2fd5", "committedDate": "2020-12-13T15:18:21Z", "message": "Test roles()."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6a9c5cb37b021a45c592c283ebb00078eb1990ef", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/6a9c5cb37b021a45c592c283ebb00078eb1990ef", "committedDate": "2020-12-13T15:21:22Z", "message": "comment why we need debug decisions."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b58d29462a12559caaeef09b7aae0193a4a65ef9", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/b58d29462a12559caaeef09b7aae0193a4a65ef9", "committedDate": "2020-12-13T16:53:17Z", "message": "Include byte unit in base message."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7b5f370d70ba7e9b07ab0a30fd1f1e4944fa318b", "author": {"user": {"login": "henningandersen", "name": "Henning Andersen"}}, "url": "https://github.com/elastic/elasticsearch/commit/7b5f370d70ba7e9b07ab0a30fd1f1e4944fa318b", "committedDate": "2020-12-13T17:13:18Z", "message": "Merge remote-tracking branch 'origin/master' into enhance_reactive_storage_autoscaler_pr_final"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4295, "cost": 1, "resetAt": "2021-10-28T19:08:13Z"}}}