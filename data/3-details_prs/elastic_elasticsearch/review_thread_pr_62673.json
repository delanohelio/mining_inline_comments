{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg5NTgwNDQ3", "number": 62673, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOVQwNzo1MDowNFrOElMuIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQwNTo0MToyOVrOEo4GlA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3NDQxMTg0OnYy", "diffSide": "RIGHT", "path": "modules/transport-netty4/src/main/java/org/elasticsearch/transport/NettyByteBufSizer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOVQwNzo1MDowNFrOHUjr3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOVQwNzo1MDowNFrOHUjr3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTMxODIzOQ==", "bodyText": "Cache buf.maxFastWritableBytes() and buf.readableBytes() to variables?", "url": "https://github.com/elastic/elasticsearch/pull/62673#discussion_r491318239", "createdAt": "2020-09-19T07:50:04Z", "author": {"login": "original-brownbear"}, "path": "modules/transport-netty4/src/main/java/org/elasticsearch/transport/NettyByteBufSizer.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.transport;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.channel.ChannelHandler;\n+import io.netty.channel.ChannelHandlerContext;\n+import io.netty.handler.codec.MessageToMessageDecoder;\n+\n+import java.util.List;\n+\n+@ChannelHandler.Sharable\n+public class NettyByteBufSizer extends MessageToMessageDecoder<ByteBuf> {\n+\n+    @Override\n+    protected void decode(ChannelHandlerContext ctx, ByteBuf buf, List<Object> out) {\n+        // If max fast writeable bytes is greater than the number of readable bytes, this buffer is at least\n+        // twice as big as necessary to contain the data. If that is the case, allocate a new buffer and\n+        // copy.\n+        int estimatedSize = buf.maxFastWritableBytes() + buf.writerIndex();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "73699e2e75a88127cf431f02e8caa76066515c2f"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3NDQxNzM1OnYy", "diffSide": "RIGHT", "path": "modules/transport-netty4/src/main/java/org/elasticsearch/transport/NettyByteBufSizer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOVQwNzo1Mjo1N1rOHUjvVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQxNjoyMzoyMlrOHXi0QA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTMxOTEyNA==", "bodyText": "Might give us more optimally sized buffers if we set the max capacity as well through\nvia ctx.alloc().heapBuffer(length, length); ?", "url": "https://github.com/elastic/elasticsearch/pull/62673#discussion_r491319124", "createdAt": "2020-09-19T07:52:57Z", "author": {"login": "original-brownbear"}, "path": "modules/transport-netty4/src/main/java/org/elasticsearch/transport/NettyByteBufSizer.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.transport;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.channel.ChannelHandler;\n+import io.netty.channel.ChannelHandlerContext;\n+import io.netty.handler.codec.MessageToMessageDecoder;\n+\n+import java.util.List;\n+\n+@ChannelHandler.Sharable\n+public class NettyByteBufSizer extends MessageToMessageDecoder<ByteBuf> {\n+\n+    @Override\n+    protected void decode(ChannelHandlerContext ctx, ByteBuf buf, List<Object> out) {\n+        // If max fast writeable bytes is greater than the number of readable bytes, this buffer is at least\n+        // twice as big as necessary to contain the data. If that is the case, allocate a new buffer and\n+        // copy.\n+        int estimatedSize = buf.maxFastWritableBytes() + buf.writerIndex();\n+        if (estimatedSize > 1024 && buf.maxFastWritableBytes() >= buf.readableBytes()) {\n+            ByteBuf newBuffer = ctx.alloc().heapBuffer(buf.readableBytes());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "73699e2e75a88127cf431f02e8caa76066515c2f"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDQ0OTcyOA==", "bodyText": "The max capacity does not impact the allocation size. It is essentially a limit for future expansion (reallocations) of the buffer.", "url": "https://github.com/elastic/elasticsearch/pull/62673#discussion_r494449728", "createdAt": "2020-09-24T16:23:22Z", "author": {"login": "tbrooks8"}, "path": "modules/transport-netty4/src/main/java/org/elasticsearch/transport/NettyByteBufSizer.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.transport;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.channel.ChannelHandler;\n+import io.netty.channel.ChannelHandlerContext;\n+import io.netty.handler.codec.MessageToMessageDecoder;\n+\n+import java.util.List;\n+\n+@ChannelHandler.Sharable\n+public class NettyByteBufSizer extends MessageToMessageDecoder<ByteBuf> {\n+\n+    @Override\n+    protected void decode(ChannelHandlerContext ctx, ByteBuf buf, List<Object> out) {\n+        // If max fast writeable bytes is greater than the number of readable bytes, this buffer is at least\n+        // twice as big as necessary to contain the data. If that is the case, allocate a new buffer and\n+        // copy.\n+        int estimatedSize = buf.maxFastWritableBytes() + buf.writerIndex();\n+        if (estimatedSize > 1024 && buf.maxFastWritableBytes() >= buf.readableBytes()) {\n+            ByteBuf newBuffer = ctx.alloc().heapBuffer(buf.readableBytes());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTMxOTEyNA=="}, "originalCommit": {"oid": "73699e2e75a88127cf431f02e8caa76066515c2f"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3NDQxOTkyOnYy", "diffSide": "RIGHT", "path": "modules/transport-netty4/src/main/java/org/elasticsearch/transport/NettyByteBufSizer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOVQwNzo1NDo0NVrOHUjxEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQxNjoyMzowM1rOHXiziw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTMxOTU3MQ==", "bodyText": "Should we really do this in general? It seems only makes sense for REST handlers that don't copy the buffers to unpooled anyway (search and bulk only as of right now). Maybe we should just copy those requests to new pooled buffers of appropriate size and leave the rest of them alone since we're releasing them on the io thread right away anyway?", "url": "https://github.com/elastic/elasticsearch/pull/62673#discussion_r491319571", "createdAt": "2020-09-19T07:54:45Z", "author": {"login": "original-brownbear"}, "path": "modules/transport-netty4/src/main/java/org/elasticsearch/transport/NettyByteBufSizer.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.transport;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.channel.ChannelHandler;\n+import io.netty.channel.ChannelHandlerContext;\n+import io.netty.handler.codec.MessageToMessageDecoder;\n+\n+import java.util.List;\n+\n+@ChannelHandler.Sharable\n+public class NettyByteBufSizer extends MessageToMessageDecoder<ByteBuf> {\n+\n+    @Override\n+    protected void decode(ChannelHandlerContext ctx, ByteBuf buf, List<Object> out) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "73699e2e75a88127cf431f02e8caa76066515c2f"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDQ0OTU0Nw==", "bodyText": "As discussed in the meeting, this is valuable as large messages can be aggregated for a period of time, hurting the memory ratios without this change.", "url": "https://github.com/elastic/elasticsearch/pull/62673#discussion_r494449547", "createdAt": "2020-09-24T16:23:03Z", "author": {"login": "tbrooks8"}, "path": "modules/transport-netty4/src/main/java/org/elasticsearch/transport/NettyByteBufSizer.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.transport;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.channel.ChannelHandler;\n+import io.netty.channel.ChannelHandlerContext;\n+import io.netty.handler.codec.MessageToMessageDecoder;\n+\n+import java.util.List;\n+\n+@ChannelHandler.Sharable\n+public class NettyByteBufSizer extends MessageToMessageDecoder<ByteBuf> {\n+\n+    @Override\n+    protected void decode(ChannelHandlerContext ctx, ByteBuf buf, List<Object> out) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTMxOTU3MQ=="}, "originalCommit": {"oid": "73699e2e75a88127cf431f02e8caa76066515c2f"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExMjk3Njg0OnYy", "diffSide": "RIGHT", "path": "modules/transport-netty4/src/main/java/org/elasticsearch/transport/NettyByteBufSizer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQwNTo0MToyOVrOHaOApQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQxNjo0NTo0NVrOHamdOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzI1NDU2NQ==", "bodyText": "Couldn't we, instead of rolling our own copying here, just use a call to ByteBuf#capacity and make Netty resize things? I.e. just do something like:\n    @Override\n    protected void decode(ChannelHandlerContext ctx, ByteBuf buf, List<Object> out) {\n        final int readableBytes = buf.readableBytes();\n        out.add(buf.discardReadBytes().capacity(readableBytes).retain()); \n    }\nAt least in some quick experimentation with the debugger that method seems to accomplish a similar if not the same thing we do here but with less copying in case the reader index is 0 (which it probably is most of the time?) but maybe I'm missing something?", "url": "https://github.com/elastic/elasticsearch/pull/62673#discussion_r497254565", "createdAt": "2020-09-30T05:41:29Z", "author": {"login": "original-brownbear"}, "path": "modules/transport-netty4/src/main/java/org/elasticsearch/transport/NettyByteBufSizer.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.transport;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.channel.ChannelHandler;\n+import io.netty.channel.ChannelHandlerContext;\n+import io.netty.handler.codec.MessageToMessageDecoder;\n+\n+import java.util.List;\n+\n+@ChannelHandler.Sharable\n+public class NettyByteBufSizer extends MessageToMessageDecoder<ByteBuf> {\n+\n+    @Override\n+    protected void decode(ChannelHandlerContext ctx, ByteBuf buf, List<Object> out) {\n+        final int maxFastWritableBytes = buf.maxFastWritableBytes();\n+        final int readableBytes = buf.readableBytes();\n+        // If max fast writeable bytes is greater than the number of readable bytes, this buffer is at least\n+        // twice as big as necessary to contain the data. If that is the case, allocate a new buffer and\n+        // copy.\n+        int estimatedSize = maxFastWritableBytes + buf.writerIndex();\n+        if (estimatedSize > 1024 && maxFastWritableBytes >= readableBytes) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "806e766c1c4496df715831bd4eb074058ee70cb2"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzY1NTA5Nw==", "bodyText": "This seems fine. I guarded against less than 1024 because capacity will always copy small arrays which seems unnecessary.", "url": "https://github.com/elastic/elasticsearch/pull/62673#discussion_r497655097", "createdAt": "2020-09-30T16:45:45Z", "author": {"login": "tbrooks8"}, "path": "modules/transport-netty4/src/main/java/org/elasticsearch/transport/NettyByteBufSizer.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.transport;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.channel.ChannelHandler;\n+import io.netty.channel.ChannelHandlerContext;\n+import io.netty.handler.codec.MessageToMessageDecoder;\n+\n+import java.util.List;\n+\n+@ChannelHandler.Sharable\n+public class NettyByteBufSizer extends MessageToMessageDecoder<ByteBuf> {\n+\n+    @Override\n+    protected void decode(ChannelHandlerContext ctx, ByteBuf buf, List<Object> out) {\n+        final int maxFastWritableBytes = buf.maxFastWritableBytes();\n+        final int readableBytes = buf.readableBytes();\n+        // If max fast writeable bytes is greater than the number of readable bytes, this buffer is at least\n+        // twice as big as necessary to contain the data. If that is the case, allocate a new buffer and\n+        // copy.\n+        int estimatedSize = maxFastWritableBytes + buf.writerIndex();\n+        if (estimatedSize > 1024 && maxFastWritableBytes >= readableBytes) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzI1NDU2NQ=="}, "originalCommit": {"oid": "806e766c1c4496df715831bd4eb074058ee70cb2"}, "originalPosition": 40}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3496, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}