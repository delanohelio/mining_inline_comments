{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDEyMjkxMjE4", "number": 56072, "title": "Avoid copying file chunks in peer covery", "bodyText": "A follow-up of #55353 to avoid copying file chunks before sending them to the network layer.", "createdAt": "2020-05-01T20:35:53Z", "url": "https://github.com/elastic/elasticsearch/pull/56072", "merged": true, "mergeCommit": {"oid": "601617a3fc07a4a72deced0ef1bae961cad15073"}, "closed": true, "closedAt": "2020-05-05T01:30:46Z", "author": {"login": "dnhatn"}, "timelineItems": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcdHwYaAH2gAyNDEyMjkxMjE4OmQ3OTM0ODViOWUzNzRmZWI1MjNjOTlkNGUwNzI0MGY1OTM0YjNlZjI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcdIb-cgFqTQwNDQwNjI0NQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "d793485b9e374feb523c99d4e07240f5934b3ef2", "author": {"user": {"login": "dnhatn", "name": "Nhat Nguyen"}}, "url": "https://github.com/elastic/elasticsearch/commit/d793485b9e374feb523c99d4e07240f5934b3ef2", "committedDate": "2020-05-01T20:32:04Z", "message": "Avoid copying file chunks in peer covery"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA0NDA2MjQ1", "url": "https://github.com/elastic/elasticsearch/pull/56072#pullrequestreview-404406245", "createdAt": "2020-05-01T21:18:28Z", "commit": {"oid": "d793485b9e374feb523c99d4e07240f5934b3ef2"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wMVQyMToxODoyOFrOGPWADQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wMVQyMToxODoyOFrOGPWADQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODc0MjI4NQ==", "bodyText": "NIT: I guess technically if lastChunk == true we could just not add the buffer back to the queue and just use () -> {} here? (not sure it matters much but for 500k buffers it might be worth it?)", "url": "https://github.com/elastic/elasticsearch/pull/56072#discussion_r418742285", "createdAt": "2020-05-01T21:18:28Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java", "diffHunk": "@@ -868,12 +878,14 @@ public void close() throws IOException {\n                 protected FileChunk nextChunkRequest(StoreFileMetadata md) throws IOException {\n                     assert Transports.assertNotTransportThread(\"read file chunk\");\n                     cancellableThreads.checkForCancel();\n+                    final byte[] buffer = Objects.requireNonNullElseGet(buffers.pollFirst(), () -> new byte[chunkSizeInBytes]);\n                     final int bytesRead = currentInput.read(buffer);\n                     if (bytesRead == -1) {\n                         throw new CorruptIndexException(\"file truncated; length=\" + md.length() + \" offset=\" + offset, md.name());\n                     }\n                     final boolean lastChunk = offset + bytesRead == md.length();\n-                    final FileChunk chunk = new FileChunk(md, new BytesArray(buffer, 0, bytesRead), offset, lastChunk);\n+                    final FileChunk chunk = new FileChunk(md, new BytesArray(buffer, 0, bytesRead), offset, lastChunk,\n+                        () -> buffers.addFirst(buffer));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d793485b9e374feb523c99d4e07240f5934b3ef2"}, "originalPosition": 67}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 187, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}