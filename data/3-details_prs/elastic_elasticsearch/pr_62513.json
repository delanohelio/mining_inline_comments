{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg4MzQ4NzI2", "number": 62513, "title": "Do not block Translog add on file write", "bodyText": "Currently a TranslogWriter add operation is synchronized. This operation\nadds the bytes to the file output stream buffer and issues a write\nsystem call if the buffer is filled. This happens every 8KB which means\nthat we routinely block other add calls on system writes.\nThis commit modifies the add operation to simply place the operation in\nan array list. The array list if flushed when the sync call occurs or\nwhen 4MB is buffered.", "createdAt": "2020-09-17T01:37:55Z", "url": "https://github.com/elastic/elasticsearch/pull/62513", "merged": true, "mergeCommit": {"oid": "13a073dca33def6c6975dbf2ab734911c3851993"}, "closed": true, "closedAt": "2020-10-02T19:26:34Z", "author": {"login": "tbrooks8"}, "timelineItems": {"totalCount": 25, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdI7OQaAH2gAyNDg4MzQ4NzI2OjkwZGQzM2ExN2JiOTA4MTc2MjZhNmUxZDNjYjUxM2Y5Y2ZiY2FkYTY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdOqTjsgH2gAyNDg4MzQ4NzI2OmQ3YjhkN2UzMWQwNjIwZjUxMTExNGI1OGQzZDYxYTBiODVkYzBkZGU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "90dd33a17bb90817626a6e1d3cb513f9cfbcada6", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/90dd33a17bb90817626a6e1d3cb513f9cfbcada6", "committedDate": "2020-09-14T22:48:36Z", "message": "Changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "019a56a290aecca8a01ef522ba41a4a14e616635", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/019a56a290aecca8a01ef522ba41a4a14e616635", "committedDate": "2020-09-14T22:58:05Z", "message": "Changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "97b19a4b7b4912d4d364197f32b02da6caaa2c0e", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/97b19a4b7b4912d4d364197f32b02da6caaa2c0e", "committedDate": "2020-09-15T17:24:23Z", "message": "WIP"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fa227d7cfc859f786708078ea93904401fde64d1", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/fa227d7cfc859f786708078ea93904401fde64d1", "committedDate": "2020-09-17T01:36:25Z", "message": "Changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "67c5f183fa75e7082307a76eda51b761ff89cd81", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/67c5f183fa75e7082307a76eda51b761ff89cd81", "committedDate": "2020-09-17T02:16:16Z", "message": "Forbidden"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "77970f72e3cc6fb86a6c4dba431e9806ee1ccf71", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/77970f72e3cc6fb86a6c4dba431e9806ee1ccf71", "committedDate": "2020-09-17T04:10:38Z", "message": "Merge remote-tracking branch 'upstream/master' into translog_less_blocking"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cfb438b9d4d2a36d12bebd56ab9cb0c0c9df42b1", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/cfb438b9d4d2a36d12bebd56ab9cb0c0c9df42b1", "committedDate": "2020-09-17T19:52:18Z", "message": "Changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9295d9276ec87cc372365ffa7924cdb6162eee6e", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/9295d9276ec87cc372365ffa7924cdb6162eee6e", "committedDate": "2020-09-17T20:13:58Z", "message": "Merge remote-tracking branch 'upstream/master' into translog_less_blocking"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ea6e609a0002454c8c262c0acd8c8791f1f8c8cc", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/ea6e609a0002454c8c262c0acd8c8791f1f8c8cc", "committedDate": "2020-09-22T23:39:37Z", "message": "Merge remote-tracking branch 'upstream/master' into translog_less_blocking"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8023a859e08e5b1553f26598623204ef553da52d", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/8023a859e08e5b1553f26598623204ef553da52d", "committedDate": "2020-09-28T15:07:36Z", "message": "Merge remote-tracking branch 'upstream/master' into translog_less_blocking"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk4Nzk2Nzg4", "url": "https://github.com/elastic/elasticsearch/pull/62513#pullrequestreview-498796788", "createdAt": "2020-09-29T19:09:24Z", "commit": {"oid": "8023a859e08e5b1553f26598623204ef553da52d"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxOTowOToyNFrOHZ84Cw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQwNjo0NDoyM1rOHaPVng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njk3MzgzNQ==", "bodyText": "Can we assert that we are on a write thread to ensure we do not get more buffers than write-threads?", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r496973835", "createdAt": "2020-09-29T19:09:24Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/common/io/DirectPool.java", "diffHunk": "@@ -0,0 +1,38 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.common.io;\n+\n+import org.elasticsearch.common.unit.ByteSizeValue;\n+\n+import java.nio.ByteBuffer;\n+\n+public class DirectPool {\n+\n+    public static final int BUFFER_SIZE = StrictMath.toIntExact(ByteSizeValue.parseBytesSizeValue(\n+        System.getProperty(\"es.direct.buffer.size\", \"256KB\"), \"es.direct.buffer.size\").getBytes());\n+\n+    private static final ThreadLocal<ByteBuffer> ioBufferPool = ThreadLocal.withInitial(() -> ByteBuffer.allocateDirect(BUFFER_SIZE));\n+\n+    public static ByteBuffer getIoBuffer() {\n+        ByteBuffer ioBuffer = ioBufferPool.get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8023a859e08e5b1553f26598623204ef553da52d"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzI1NzMyMg==", "bodyText": "I wonder if we should in this PR keep the buffer size as is, i.e. let FORCE_WRITE_THRESHOLD still be taken from TranslogConfig.getBufferSize().\nHaving up to 4MB of buffer per translog seems like it could add up (much like the previous solution where the buffer size were increased)?", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r497257322", "createdAt": "2020-09-30T05:50:52Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/index/translog/TranslogWriter.java", "diffHunk": "@@ -48,6 +54,9 @@\n import java.util.function.LongSupplier;\n \n public class TranslogWriter extends BaseTranslogReader implements Closeable {\n+\n+    private static final int FORCE_WRITE_THRESHOLD = 4 * 1024 * 1024;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8023a859e08e5b1553f26598623204ef553da52d"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzI1OTM2NQ==", "bodyText": "This makes TranslogConfig.getBufferSize unused. I slightly prefer to keep this in TranslogConfig but can be persuaded both ways given that it is not configurable today anyway. But I think we need to either use it or remove the method/field from TranslogConfig.", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r497259365", "createdAt": "2020-09-30T05:57:24Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/index/translog/Translog.java", "diffHunk": "@@ -506,7 +506,6 @@ TranslogWriter createWriter(long fileGeneration, long initialMinTranslogGen, lon\n                 fileGeneration,\n                 location.resolve(getFilename(fileGeneration)),\n                 getChannelFactory(),\n-                config.getBufferSize(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8023a859e08e5b1553f26598623204ef553da52d"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzI3NjMxOA==", "bodyText": "Would we not risk several threads waiting on the writeLock, because they each determine they need to write buffered ops? Not sure it is a big issue in practice. But I wonder if moving the data to write out of the \"main buffer\" and into a \"to-write-buffer\" inside the lock above would help make sure only one of the threads need to do the write (the one moving the buffer over promises to also write).", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r497276318", "createdAt": "2020-09-30T06:44:23Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/index/translog/TranslogWriter.java", "diffHunk": "@@ -174,34 +177,35 @@ private synchronized void closeWithTragicEvent(final Exception ex) {\n      * @return the location the bytes were written to\n      * @throws IOException if writing to the translog resulted in an I/O exception\n      */\n-    public synchronized Translog.Location add(final BytesReference data, final long seqNo) throws IOException {\n-        ensureOpen();\n-        final long offset = totalOffset;\n-        try {\n-            data.writeTo(outputStream);\n-        } catch (final Exception ex) {\n-            closeWithTragicEvent(ex);\n-            throw ex;\n-        }\n-        totalOffset += data.length();\n+    public Translog.Location add(final ReleasableBytesReference data, final long seqNo) throws IOException {\n+        final Translog.Location location;\n+        final long bytesBufferedAfterAdd;\n+        synchronized (this) {\n+            ensureOpen();\n+            final long offset = totalOffset;\n+            totalOffset += data.length();\n+            bufferedBytes += data.length();\n+            bufferedOps.add(new Operation(seqNo, data.retain()));\n \n-        if (minSeqNo == SequenceNumbers.NO_OPS_PERFORMED) {\n-            assert operationCounter == 0;\n-        }\n-        if (maxSeqNo == SequenceNumbers.NO_OPS_PERFORMED) {\n-            assert operationCounter == 0;\n-        }\n+            assert minSeqNo != SequenceNumbers.NO_OPS_PERFORMED || operationCounter == 0;\n+            assert maxSeqNo != SequenceNumbers.NO_OPS_PERFORMED || operationCounter == 0;\n \n-        minSeqNo = SequenceNumbers.min(minSeqNo, seqNo);\n-        maxSeqNo = SequenceNumbers.max(maxSeqNo, seqNo);\n+            minSeqNo = SequenceNumbers.min(minSeqNo, seqNo);\n+            maxSeqNo = SequenceNumbers.max(maxSeqNo, seqNo);\n \n-        nonFsyncedSequenceNumbers.add(seqNo);\n+            operationCounter++;\n \n-        operationCounter++;\n+            assert assertNoSeqNumberConflict(seqNo, data);\n \n-        assert assertNoSeqNumberConflict(seqNo, data);\n+            location = new Translog.Location(generation, offset, data.length());\n+            bytesBufferedAfterAdd = bufferedBytes;\n+        }\n+\n+        if (bytesBufferedAfterAdd >= FORCE_WRITE_THRESHOLD) {\n+            writeBufferedOps(Long.MAX_VALUE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8023a859e08e5b1553f26598623204ef553da52d"}, "originalPosition": 171}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ebb6e2f5b847133df89a8a692ca2ed5c1ce9d455", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/ebb6e2f5b847133df89a8a692ca2ed5c1ce9d455", "committedDate": "2020-09-30T18:36:39Z", "message": "Merge remote-tracking branch 'upstream/master' into translog_less_blocking"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "79b888afca8c9453ce2700ec0578ca0b1a9ef9a2", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/79b888afca8c9453ce2700ec0578ca0b1a9ef9a2", "committedDate": "2020-09-30T21:28:16Z", "message": "Changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bfceaced1872f305674a25984dafb2b787b7d57f", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/bfceaced1872f305674a25984dafb2b787b7d57f", "committedDate": "2020-09-30T21:39:19Z", "message": "Changes"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAwNjE4MzI0", "url": "https://github.com/elastic/elasticsearch/pull/62513#pullrequestreview-500618324", "createdAt": "2020-10-01T18:37:12Z", "commit": {"oid": "bfceaced1872f305674a25984dafb2b787b7d57f"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMVQxODozNzoxMlrOHbWh7g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMVQyMDoxMDo0NFrOHbZRDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ0MjczNA==", "bodyText": "I would like to limit the max buffer size (also if writing the buffer is slow), perhaps something like this:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        writeBufferedOps(Long.MAX_VALUE, false);\n          \n          \n            \n                        writeBufferedOps(Long.MAX_VALUE, bytesBufferedAfterAdd >= forceWriteThreshold * 2);", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r498442734", "createdAt": "2020-10-01T18:37:12Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/index/translog/TranslogWriter.java", "diffHunk": "@@ -174,34 +181,35 @@ private synchronized void closeWithTragicEvent(final Exception ex) {\n      * @return the location the bytes were written to\n      * @throws IOException if writing to the translog resulted in an I/O exception\n      */\n-    public synchronized Translog.Location add(final BytesReference data, final long seqNo) throws IOException {\n-        ensureOpen();\n-        final long offset = totalOffset;\n-        try {\n-            data.writeTo(outputStream);\n-        } catch (final Exception ex) {\n-            closeWithTragicEvent(ex);\n-            throw ex;\n-        }\n-        totalOffset += data.length();\n+    public Translog.Location add(final ReleasableBytesReference data, final long seqNo) throws IOException {\n+        final Translog.Location location;\n+        final long bytesBufferedAfterAdd;\n+        synchronized (this) {\n+            ensureOpen();\n+            final long offset = totalOffset;\n+            totalOffset += data.length();\n+            bufferedBytes += data.length();\n+            bufferedOps.add(new Operation(seqNo, data.retain()));\n \n-        if (minSeqNo == SequenceNumbers.NO_OPS_PERFORMED) {\n-            assert operationCounter == 0;\n-        }\n-        if (maxSeqNo == SequenceNumbers.NO_OPS_PERFORMED) {\n-            assert operationCounter == 0;\n-        }\n+            assert minSeqNo != SequenceNumbers.NO_OPS_PERFORMED || operationCounter == 0;\n+            assert maxSeqNo != SequenceNumbers.NO_OPS_PERFORMED || operationCounter == 0;\n+\n+            minSeqNo = SequenceNumbers.min(minSeqNo, seqNo);\n+            maxSeqNo = SequenceNumbers.max(maxSeqNo, seqNo);\n \n-        minSeqNo = SequenceNumbers.min(minSeqNo, seqNo);\n-        maxSeqNo = SequenceNumbers.max(maxSeqNo, seqNo);\n+            operationCounter++;\n \n-        nonFsyncedSequenceNumbers.add(seqNo);\n+            assert assertNoSeqNumberConflict(seqNo, data);\n \n-        operationCounter++;\n+            location = new Translog.Location(generation, offset, data.length());\n+            bytesBufferedAfterAdd = bufferedBytes;\n+        }\n \n-        assert assertNoSeqNumberConflict(seqNo, data);\n+        if (bytesBufferedAfterAdd >= forceWriteThreshold) {\n+            writeBufferedOps(Long.MAX_VALUE, false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bfceaced1872f305674a25984dafb2b787b7d57f"}, "originalPosition": 153}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ2MTk3MA==", "bodyText": "nit: I think the synchronized block only need to go around the two new lines?", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r498461970", "createdAt": "2020-10-01T19:15:49Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/index/translog/TranslogWriter.java", "diffHunk": "@@ -449,8 +532,10 @@ protected final void ensureOpen() {\n     }\n \n     @Override\n-    public final void close() throws IOException {\n+    public final synchronized void close() throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bfceaced1872f305674a25984dafb2b787b7d57f"}, "originalPosition": 375}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ4MTk5NQ==", "bodyText": "Can we also assert that totalOps == getWrittenOffset()?", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r498481995", "createdAt": "2020-10-01T19:58:34Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/index/translog/TranslogWriter.java", "diffHunk": "@@ -309,28 +317,34 @@ public long sizeInBytes() {\n     public TranslogReader closeIntoReader() throws IOException {\n         // make sure to acquire the sync lock first, to prevent dead locks with threads calling\n         // syncUpTo() , where the sync lock is acquired first, following by the synchronize(this)\n+        // After the sync lock we acquire the write lock to avoid deadlocks with threads writing where\n+        // the write lock is acquired first followed by synchronize(this).\n         //\n         // Note: While this is not strictly needed as this method is called while blocking all ops on the translog,\n         //       we do this to for correctness and preventing future issues.\n         synchronized (syncLock) {\n-            synchronized (this) {\n-                try {\n-                    sync(); // sync before we close..\n-                } catch (final Exception ex) {\n-                    closeWithTragicEvent(ex);\n-                    throw ex;\n-                }\n-                if (closed.compareAndSet(false, true)) {\n+            try (ReleasableLock toClose = writeLock.acquire()) {\n+                synchronized (this) {\n                     try {\n-                        checkpointChannel.close();\n+                        sync(); // sync before we close..\n                     } catch (final Exception ex) {\n                         closeWithTragicEvent(ex);\n                         throw ex;\n                     }\n-                    return new TranslogReader(getLastSyncedCheckpoint(), channel, path, header);\n-                } else {\n-                    throw new AlreadyClosedException(\"translog [\" + getGeneration() + \"] is already closed (path [\" + path + \"]\",\n+                    // If we reached this point, all of the buffered ops should have been flushed successfully.\n+                    assert bufferedOps.size() == 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bfceaced1872f305674a25984dafb2b787b7d57f"}, "originalPosition": 213}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ4Mjg3Ng==", "bodyText": "I think the assert on bufferedOps size and totalOps above can also go here?", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r498482876", "createdAt": "2020-10-01T20:00:24Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/index/translog/TranslogWriter.java", "diffHunk": "@@ -341,15 +355,19 @@ public TranslogReader closeIntoReader() throws IOException {\n     public TranslogSnapshot newSnapshot() {\n         // make sure to acquire the sync lock first, to prevent dead locks with threads calling\n         // syncUpTo() , where the sync lock is acquired first, following by the synchronize(this)\n+        // After the sync lock we acquire the write lock to avoid deadlocks with threads writing where\n+        // the write lock is acquired first followed by synchronize(this).\n         synchronized (syncLock) {\n-            synchronized (this) {\n-                ensureOpen();\n-                try {\n-                    sync();\n-                } catch (IOException e) {\n-                    throw new TranslogException(shardId, \"exception while syncing before creating a snapshot\", e);\n+            try (ReleasableLock toClose = writeLock.acquire()) {\n+                synchronized (this) {\n+                    ensureOpen();\n+                    try {\n+                        sync();\n+                    } catch (IOException e) {\n+                        throw new TranslogException(shardId, \"exception while syncing before creating a snapshot\", e);\n+                    }\n+                    return super.newSnapshot();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bfceaced1872f305674a25984dafb2b787b7d57f"}, "originalPosition": 250}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ4NTQwOQ==", "bodyText": "I do like to separate out the flush/write threads. I am equally concerned about the direct memory use and the memory usage. For instance the generic thread pool can be resized and if we are unfortunate, we could leak many direct buffers for the GC to collect.\nSo I would suggest to use a direct byte buffer for the flush/write/system-flush/system-write pools and then use heap based byte buffer for the rest.", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r498485409", "createdAt": "2020-10-01T20:05:58Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/common/io/DirectPool.java", "diffHunk": "@@ -0,0 +1,38 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.common.io;\n+\n+import org.elasticsearch.common.unit.ByteSizeValue;\n+\n+import java.nio.ByteBuffer;\n+\n+public class DirectPool {\n+\n+    public static final int BUFFER_SIZE = StrictMath.toIntExact(ByteSizeValue.parseBytesSizeValue(\n+        System.getProperty(\"es.direct.buffer.size\", \"256KB\"), \"es.direct.buffer.size\").getBytes());\n+\n+    private static final ThreadLocal<ByteBuffer> ioBufferPool = ThreadLocal.withInitial(() -> ByteBuffer.allocateDirect(BUFFER_SIZE));\n+\n+    public static ByteBuffer getIoBuffer() {\n+        ByteBuffer ioBuffer = ioBufferPool.get();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njk3MzgzNQ=="}, "originalCommit": {"oid": "8023a859e08e5b1553f26598623204ef553da52d"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ4NzU2NA==", "bodyText": "revert this?", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r498487564", "createdAt": "2020-10-01T20:10:44Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/index/translog/Translog.java", "diffHunk": "@@ -544,7 +546,8 @@ public Location add(final Operation operation) throws IOException {\n                     throw new IllegalArgumentException(\"Operation term is newer than the current term; \"\n                         + \"current term[\" + current.getPrimaryTerm() + \"], operation term[\" + operation + \"]\");\n                 }\n-                return current.add(bytes, operation.seqNo());\n+                final Location location = current.add(bytes, operation.seqNo());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bfceaced1872f305674a25984dafb2b787b7d57f"}, "originalPosition": 40}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9db760a88420d07cba63f178aebbd8282979e5cf", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/9db760a88420d07cba63f178aebbd8282979e5cf", "committedDate": "2020-10-01T20:22:49Z", "message": "Merge remote-tracking branch 'upstream/master' into translog_less_blocking"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ba61c8a69c282065e35cbf8c66590558c5ecbfdb", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/ba61c8a69c282065e35cbf8c66590558c5ecbfdb", "committedDate": "2020-10-01T20:58:21Z", "message": "Changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cfa38a51aefdbddbeaa2f867cbdf17da268223a7", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/cfa38a51aefdbddbeaa2f867cbdf17da268223a7", "committedDate": "2020-10-01T21:52:33Z", "message": "Fix test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAwODI2MTc5", "url": "https://github.com/elastic/elasticsearch/pull/62513#pullrequestreview-500826179", "createdAt": "2020-10-02T02:18:10Z", "commit": {"oid": "cfa38a51aefdbddbeaa2f867cbdf17da268223a7"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAwODY3Nzc3", "url": "https://github.com/elastic/elasticsearch/pull/62513#pullrequestreview-500867777", "createdAt": "2020-10-02T05:31:50Z", "commit": {"oid": "bfceaced1872f305674a25984dafb2b787b7d57f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwNTozMTo1MFrOHbhl_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwNTozMTo1MFrOHbhl_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODYyMzk5Nw==", "bodyText": "I think the added assert is fine. But the main property I were after validating was that the accounting we do for totalOffset in add ends up matching what goes into the file. This new assert does not verify that since the checkpoint is constructed from the totalOffset value.\nWould it be an option to assert based on a method and then catch the IOException in that and return true on exception?", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r498623997", "createdAt": "2020-10-02T05:31:50Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/index/translog/TranslogWriter.java", "diffHunk": "@@ -309,28 +317,34 @@ public long sizeInBytes() {\n     public TranslogReader closeIntoReader() throws IOException {\n         // make sure to acquire the sync lock first, to prevent dead locks with threads calling\n         // syncUpTo() , where the sync lock is acquired first, following by the synchronize(this)\n+        // After the sync lock we acquire the write lock to avoid deadlocks with threads writing where\n+        // the write lock is acquired first followed by synchronize(this).\n         //\n         // Note: While this is not strictly needed as this method is called while blocking all ops on the translog,\n         //       we do this to for correctness and preventing future issues.\n         synchronized (syncLock) {\n-            synchronized (this) {\n-                try {\n-                    sync(); // sync before we close..\n-                } catch (final Exception ex) {\n-                    closeWithTragicEvent(ex);\n-                    throw ex;\n-                }\n-                if (closed.compareAndSet(false, true)) {\n+            try (ReleasableLock toClose = writeLock.acquire()) {\n+                synchronized (this) {\n                     try {\n-                        checkpointChannel.close();\n+                        sync(); // sync before we close..\n                     } catch (final Exception ex) {\n                         closeWithTragicEvent(ex);\n                         throw ex;\n                     }\n-                    return new TranslogReader(getLastSyncedCheckpoint(), channel, path, header);\n-                } else {\n-                    throw new AlreadyClosedException(\"translog [\" + getGeneration() + \"] is already closed (path [\" + path + \"]\",\n+                    // If we reached this point, all of the buffered ops should have been flushed successfully.\n+                    assert bufferedOps.size() == 0;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ4MTk5NQ=="}, "originalCommit": {"oid": "bfceaced1872f305674a25984dafb2b787b7d57f"}, "originalPosition": 213}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "520485610a795dc73f842aaae52d660ffa563ad3", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/520485610a795dc73f842aaae52d660ffa563ad3", "committedDate": "2020-10-02T16:17:00Z", "message": "Review"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ed443a25a7f8635604353167d0a21c1a66666cf9", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/ed443a25a7f8635604353167d0a21c1a66666cf9", "committedDate": "2020-10-02T16:17:12Z", "message": "Merge remote-tracking branch 'upstream/master' into translog_less_blocking"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4cc7c9419a1807603bb3cc99a4d8ebe6812b8e03", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/4cc7c9419a1807603bb3cc99a4d8ebe6812b8e03", "committedDate": "2020-10-02T16:42:37Z", "message": "Remove serr"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAxMzQ2MTEx", "url": "https://github.com/elastic/elasticsearch/pull/62513#pullrequestreview-501346111", "createdAt": "2020-10-02T18:11:42Z", "commit": {"oid": "520485610a795dc73f842aaae52d660ffa563ad3"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQxODoxMTo0M1rOHb2_Vg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQxODoxMTo0M1rOHb2_Vg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODk3NDU1MA==", "bodyText": "I think we need a latch to ensure that the thread did do the locking and is inside write or force?", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r498974550", "createdAt": "2020-10-02T18:11:43Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/index/translog/TranslogTests.java", "diffHunk": "@@ -1316,6 +1315,100 @@ public void testTranslogWriter() throws IOException {\n         IOUtils.close(writer);\n     }\n \n+    public void testTranslogWriterDoesNotBlockAddsOnWrite() throws IOException, InterruptedException {\n+        Path tempDir = createTempDir();\n+        System.err.println(tempDir);\n+        final TranslogConfig config = getTranslogConfig(tempDir);\n+        final AtomicBoolean startBlocking = new AtomicBoolean(false);\n+        final CountDownLatch blocker = new CountDownLatch(1);\n+        final Set<Long> persistedSeqNos = new HashSet<>();\n+\n+        final ChannelFactory channelFactory = (file, openOption) -> {\n+            FileChannel delegate = FileChannel.open(file, openOption);\n+            boolean success = false;\n+            try {\n+                // don't do partial writes for checkpoints we rely on the fact that the bytes are written as an atomic operation\n+                final boolean isCkpFile = file.getFileName().toString().endsWith(\".ckp\");\n+\n+                final FileChannel channel;\n+                if (isCkpFile) {\n+                    channel = delegate;\n+                } else {\n+                    channel = new FilterFileChannel(delegate) {\n+\n+                        @Override\n+                        public int write(ByteBuffer src) throws IOException {\n+                            if (startBlocking.get()) {\n+                                try {\n+                                    blocker.await();\n+                                } catch (InterruptedException e) {\n+                                    // Ignore\n+                                }\n+                            }\n+                            return super.write(src);\n+                        }\n+\n+                        @Override\n+                        public void force(boolean metaData) throws IOException {\n+                            if (startBlocking.get()) {\n+                                try {\n+                                    blocker.await();\n+                                } catch (InterruptedException e) {\n+                                    // Ignore\n+                                }\n+                            }\n+                            super.force(metaData);\n+                        }\n+                    };\n+                }\n+                success = true;\n+                return channel;\n+            } finally {\n+                if (success == false) {\n+                    IOUtils.closeWhileHandlingException(delegate);\n+                }\n+            }\n+        };\n+        String translogUUID = Translog.createEmptyTranslog(\n+            config.getTranslogPath(), SequenceNumbers.NO_OPS_PERFORMED, shardId, channelFactory, primaryTerm.get());\n+\n+        try (Translog translog = new Translog(config, translogUUID, new TranslogDeletionPolicy(),\n+            () -> SequenceNumbers.NO_OPS_PERFORMED, primaryTerm::get, persistedSeqNos::add) {\n+            @Override\n+            ChannelFactory getChannelFactory() {\n+                return channelFactory;\n+            }\n+        }) {\n+            try (TranslogWriter writer = translog.createWriter(translog.currentFileGeneration() + 1)) {\n+                byte[] bytes = new byte[4];\n+                ByteArrayDataOutput out = new ByteArrayDataOutput(new byte[4]);\n+                out.writeInt(1);\n+                writer.add(ReleasableBytesReference.wrap(new BytesArray(bytes)), 1);\n+                assertThat(persistedSeqNos, empty());\n+                startBlocking.set(true);\n+                Thread thread = new Thread(() -> {\n+                    try {\n+                        writer.sync();\n+                    } catch (IOException e) {\n+                        throw new AssertionError(e);\n+                    }\n+                });\n+                thread.start();\n+\n+                // Add will not block even though we are currently writing/syncing\n+                writer.add(ReleasableBytesReference.wrap(new BytesArray(bytes)), 2);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "520485610a795dc73f842aaae52d660ffa563ad3"}, "originalPosition": 110}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d7b8d7e31d0620f511114b58d3d61a0b85dc0dde", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/d7b8d7e31d0620f511114b58d3d61a0b85dc0dde", "committedDate": "2020-10-02T18:29:33Z", "message": "Wait for write"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3614, "cost": 1, "resetAt": "2021-10-28T19:08:13Z"}}}