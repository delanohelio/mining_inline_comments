{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYwNjkzNTMw", "number": 50769, "title": "Do not force refresh when write indexing buffer", "bodyText": "Today we periodically check the indexing buffer memory every 5 seconds or after we have used 1/30 of the configured memory. If the total used memory is over the threshold, then we refresh the \"largest\" shards. If refreshing takes longer these intervals (i.e., 5s or 1/30 buffer), then we continue to enqueue refreshes to these shards. This leads to two issues:\n\nThe refresh thread pool can be exhausted and other shards can't refresh\nExecute too many refreshes for the \"largest\" shards\n\nWith this change, we only refresh the largest shards if they are not refreshing. Here we rely on the periodic check to trigger another refresh if needed. We can harden this by making the ongoing refresh triggers the memory check when it's completed. I opted out this option in this PR for simplicity.\nSee: https://discuss.elastic.co/t/write-queue-continue-to-rise/213652/", "createdAt": "2020-01-08T22:59:50Z", "url": "https://github.com/elastic/elasticsearch/pull/50769", "merged": true, "mergeCommit": {"oid": "0510af87868fd4951449ed224758d4cc184b6680"}, "closed": true, "closedAt": "2020-01-09T23:18:24Z", "author": {"login": "dnhatn"}, "timelineItems": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb4c-ywgH2gAyMzYwNjkzNTMwOjJmMWY2MWU1OTY1MTNjYmE3MmU5MDRhMjY3ZTNjMWIzZjE2NmM1NjE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABb4t0x-AH2gAyMzYwNjkzNTMwOjRkMDRlOTdjMjE0NjI2ZmQxODRkZTE1MWQ2ZmUzNjk0OWUwMjY3Y2I=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "2f1f61e596513cba72e904a267e3c1b3f166c561", "author": {"user": {"login": "dnhatn", "name": "Nhat Nguyen"}}, "url": "https://github.com/elastic/elasticsearch/commit/2f1f61e596513cba72e904a267e3c1b3f166c561", "committedDate": "2020-01-08T22:20:37Z", "message": "Do not force refresh when write indexing buffer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2261b3f32e9165209ffd711bde3a8815d735de1d", "author": {"user": {"login": "dnhatn", "name": "Nhat Nguyen"}}, "url": "https://github.com/elastic/elasticsearch/commit/2261b3f32e9165209ffd711bde3a8815d735de1d", "committedDate": "2020-01-08T23:03:03Z", "message": "Merge branch 'master' into indexing-memory"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQwMjAyMTY3", "url": "https://github.com/elastic/elasticsearch/pull/50769#pullrequestreview-340202167", "createdAt": "2020-01-08T23:04:01Z", "commit": {"oid": "2261b3f32e9165209ffd711bde3a8815d735de1d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQyMzowNDowMVrOFbmi_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQyMzowNDowMVrOFbmi_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDQ4NzQyMQ==", "bodyText": "I only added this new test. Other tests are unchanged.", "url": "https://github.com/elastic/elasticsearch/pull/50769#discussion_r364487421", "createdAt": "2020-01-08T23:04:01Z", "author": {"login": "dnhatn"}, "path": "server/src/test/java/org/elasticsearch/indices/IndexingMemoryControllerTests.java", "diffHunk": "@@ -346,117 +328,83 @@ public void testThrottling() throws Exception {\n         controller.forceCheck();\n         controller.assertNotThrottled(shard0);\n         controller.assertNotThrottled(shard1);\n+        closeShards(shard0, shard1);\n     }\n \n-    // #10312\n-    public void testDeletesAloneCanTriggerRefresh() throws Exception {\n-        createIndex(\"index\",\n-                    Settings.builder().put(\"index.number_of_shards\", 1)\n-                                      .put(\"index.number_of_replicas\", 0)\n-                                      .put(\"index.refresh_interval\", -1)\n-                                      .build());\n-        ensureGreen();\n-\n-        IndicesService indicesService = getInstanceFromNode(IndicesService.class);\n-        IndexService indexService = indicesService.indexService(resolveIndex(\"index\"));\n-        IndexShard shard = indexService.getShardOrNull(0);\n-        assertNotNull(shard);\n-\n-        for (int i = 0; i < 100; i++) {\n-            String id = Integer.toString(i);\n-            client().prepareIndex(\"index\").setId(id).setSource(\"field\", \"value\").get();\n-        }\n-\n-        // Force merge so we know all merges are done before we start deleting:\n-        ForceMergeResponse r = client().admin().indices().prepareForceMerge().setMaxNumSegments(1).execute().actionGet();\n-        assertNoFailures(r);\n-\n-        // Make a shell of an IMC to check up on indexing buffer usage:\n-        Settings settings = Settings.builder().put(\"indices.memory.index_buffer_size\", \"1kb\").build();\n+    EngineConfig configWithRefreshListener(EngineConfig config, ReferenceManager.RefreshListener listener) {\n+        final List<ReferenceManager.RefreshListener> internalRefreshListener = new ArrayList<>(config.getInternalRefreshListener());;\n+        internalRefreshListener.add(listener);\n+        return new EngineConfig(config.getShardId(), config.getAllocationId(), config.getThreadPool(),\n+            config.getIndexSettings(), config.getWarmer(), config.getStore(), config.getMergePolicy(), config.getAnalyzer(),\n+            config.getSimilarity(), new CodecService(null, logger), config.getEventListener(), config.getQueryCache(),\n+            config.getQueryCachingPolicy(), config.getTranslogConfig(), config.getFlushMergesAfter(),\n+            config.getExternalRefreshListener(), internalRefreshListener, config.getIndexSort(),\n+            config.getCircuitBreakerService(), config.getGlobalCheckpointSupplier(), config.retentionLeasesSupplier(),\n+            config.getPrimaryTermSupplier(), config.getTombstoneDocSupplier());\n+    }\n \n-        // TODO: would be cleaner if I could pass this 1kb setting to the single node this test created....\n-        IndexingMemoryController imc = new IndexingMemoryController(settings, null, null) {\n+    public void testSkipRefreshIfShardIsRefreshingAlready() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2261b3f32e9165209ffd711bde3a8815d735de1d"}, "originalPosition": 176}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e6839093339bc1b9ca15b174adec03486d3c1ac2", "author": {"user": {"login": "dnhatn", "name": "Nhat Nguyen"}}, "url": "https://github.com/elastic/elasticsearch/commit/e6839093339bc1b9ca15b174adec03486d3c1ac2", "committedDate": "2020-01-09T02:51:38Z", "message": "do not check for rejected"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f0a05f98d63cac908023df9c91955a84a55e39f1", "author": {"user": {"login": "dnhatn", "name": "Nhat Nguyen"}}, "url": "https://github.com/elastic/elasticsearch/commit/f0a05f98d63cac908023df9c91955a84a55e39f1", "committedDate": "2020-01-09T02:52:48Z", "message": "Merge branch 'master' into indexing-memory"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQwMzcwNTU2", "url": "https://github.com/elastic/elasticsearch/pull/50769#pullrequestreview-340370556", "createdAt": "2020-01-09T09:02:09Z", "commit": {"oid": "f0a05f98d63cac908023df9c91955a84a55e39f1"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQwMzY4ODgz", "url": "https://github.com/elastic/elasticsearch/pull/50769#pullrequestreview-340368883", "createdAt": "2020-01-09T08:58:57Z", "commit": {"oid": "f0a05f98d63cac908023df9c91955a84a55e39f1"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOVQwODo1ODo1N1rOFbuukw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOVQwOToxNzowNFrOFbvMZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDYyMTQ1OQ==", "bodyText": "nit: I prefer to find the stats object to assert on first and then assert to ensure we get a NPE if stats for some reason do not contain \"refresh\" rather than pass the test.", "url": "https://github.com/elastic/elasticsearch/pull/50769#discussion_r364621459", "createdAt": "2020-01-09T08:58:57Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/indices/IndexingMemoryControllerTests.java", "diffHunk": "@@ -346,117 +328,81 @@ public void testThrottling() throws Exception {\n         controller.forceCheck();\n         controller.assertNotThrottled(shard0);\n         controller.assertNotThrottled(shard1);\n+        closeShards(shard0, shard1);\n     }\n \n-    // #10312\n-    public void testDeletesAloneCanTriggerRefresh() throws Exception {\n-        createIndex(\"index\",\n-                    Settings.builder().put(\"index.number_of_shards\", 1)\n-                                      .put(\"index.number_of_replicas\", 0)\n-                                      .put(\"index.refresh_interval\", -1)\n-                                      .build());\n-        ensureGreen();\n-\n-        IndicesService indicesService = getInstanceFromNode(IndicesService.class);\n-        IndexService indexService = indicesService.indexService(resolveIndex(\"index\"));\n-        IndexShard shard = indexService.getShardOrNull(0);\n-        assertNotNull(shard);\n-\n-        for (int i = 0; i < 100; i++) {\n-            String id = Integer.toString(i);\n-            client().prepareIndex(\"index\").setId(id).setSource(\"field\", \"value\").get();\n-        }\n-\n-        // Force merge so we know all merges are done before we start deleting:\n-        ForceMergeResponse r = client().admin().indices().prepareForceMerge().setMaxNumSegments(1).execute().actionGet();\n-        assertNoFailures(r);\n-\n-        // Make a shell of an IMC to check up on indexing buffer usage:\n-        Settings settings = Settings.builder().put(\"indices.memory.index_buffer_size\", \"1kb\").build();\n+    EngineConfig configWithRefreshListener(EngineConfig config, ReferenceManager.RefreshListener listener) {\n+        final List<ReferenceManager.RefreshListener> internalRefreshListener = new ArrayList<>(config.getInternalRefreshListener());;\n+        internalRefreshListener.add(listener);\n+        return new EngineConfig(config.getShardId(), config.getAllocationId(), config.getThreadPool(),\n+            config.getIndexSettings(), config.getWarmer(), config.getStore(), config.getMergePolicy(), config.getAnalyzer(),\n+            config.getSimilarity(), new CodecService(null, logger), config.getEventListener(), config.getQueryCache(),\n+            config.getQueryCachingPolicy(), config.getTranslogConfig(), config.getFlushMergesAfter(),\n+            config.getExternalRefreshListener(), internalRefreshListener, config.getIndexSort(),\n+            config.getCircuitBreakerService(), config.getGlobalCheckpointSupplier(), config.retentionLeasesSupplier(),\n+            config.getPrimaryTermSupplier(), config.getTombstoneDocSupplier());\n+    }\n \n-        // TODO: would be cleaner if I could pass this 1kb setting to the single node this test created....\n-        IndexingMemoryController imc = new IndexingMemoryController(settings, null, null) {\n+    public void testSkipRefreshIfShardIsRefreshingAlready() throws Exception {\n+        SetOnce<CountDownLatch> refreshLatch = new SetOnce<>();\n+        ReferenceManager.RefreshListener refreshListener = new ReferenceManager.RefreshListener() {\n             @Override\n-            protected List<IndexShard> availableShards() {\n-                return Collections.singletonList(shard);\n+            public void beforeRefresh() {\n+                if (refreshLatch.get() != null) {\n+                    try {\n+                        refreshLatch.get().await();\n+                    } catch (InterruptedException e) {\n+                        throw new AssertionError(e);\n+                    }\n+                }\n             }\n \n             @Override\n-            protected long getIndexBufferRAMBytesUsed(IndexShard shard) {\n-                return shard.getIndexBufferRAMBytesUsed();\n-            }\n+            public void afterRefresh(boolean didRefresh) {\n \n+            }\n+        };\n+        IndexShard shard = newStartedShard(randomBoolean(), Settings.EMPTY,\n+            config -> new InternalEngine(configWithRefreshListener(config, refreshListener)));\n+        refreshLatch.set(new CountDownLatch(1)); // block refresh\n+        final RefreshStats refreshStats = shard.refreshStats();\n+        final IndexingMemoryController controller = new IndexingMemoryController(\n+            Settings.builder().put(\"indices.memory.interval\", \"200h\") // disable it\n+                .put(\"indices.memory.index_buffer_size\", \"1024b\").build(),\n+            threadPool,\n+            Collections.singleton(shard)) {\n             @Override\n-            protected void writeIndexingBufferAsync(IndexShard shard) {\n-                // just do it sync'd for this test\n-                shard.writeIndexingBuffer();\n+            protected long getIndexBufferRAMBytesUsed(IndexShard shard) {\n+                return randomLongBetween(1025, 10 * 1024 * 1024);\n             }\n \n             @Override\n-            protected Cancellable scheduleTask(ThreadPool threadPool) {\n-                return null;\n+            protected long getShardWritingBytes(IndexShard shard) {\n+                return 0L;\n             }\n         };\n-\n-        for (int i = 0; i < 100; i++) {\n-            String id = Integer.toString(i);\n-            client().prepareDelete(\"index\", id).get();\n+        int iterations = randomIntBetween(10, 100);\n+        for (int i = 0; i < iterations; i++) {\n+            controller.forceCheck();\n         }\n-\n-        final long indexingBufferBytes1 = shard.getIndexBufferRAMBytesUsed();\n-\n-        imc.forceCheck();\n-\n-        // We must assertBusy because the writeIndexingBufferAsync is done in background (REFRESH) thread pool:\n         assertBusy(() -> {\n-            try (Engine.Searcher s2 = shard.acquireSearcher(\"index\")) {\n-                // 100 buffered deletes will easily exceed our 1 KB indexing buffer so it should trigger a write:\n-                final long indexingBufferBytes2 = shard.getIndexBufferRAMBytesUsed();\n-                assertTrue(indexingBufferBytes2 < indexingBufferBytes1);\n+            for (ThreadPoolStats.Stats stats : threadPool.stats()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f0a05f98d63cac908023df9c91955a84a55e39f1"}, "originalPosition": 243}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDYyOTA5NQ==", "bodyText": "I think there is a (very small) risk that the IndexingMemoryController created by the node was triggered on one  of the deletes and that this causes the writeIndexingBuffer/refresh call triggered here to return immediately. It does take a lot of bad circumstances though (of which the heap size alone will likely prevent this), but I still think we should address it. Maybe the TODO above is doable if this test is moved to its own class? Or we could simply add a node-setting that essentially disables it by setting the limit very high?", "url": "https://github.com/elastic/elasticsearch/pull/50769#discussion_r364629095", "createdAt": "2020-01-09T09:17:04Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/indices/IndexingMemoryControllerIT.java", "diffHunk": "@@ -0,0 +1,163 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.elasticsearch.indices;\n+\n+import org.apache.lucene.index.DirectoryReader;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.admin.indices.forcemerge.ForceMergeResponse;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.common.CheckedFunction;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.xcontent.XContentType;\n+import org.elasticsearch.index.IndexService;\n+import org.elasticsearch.index.engine.Engine;\n+import org.elasticsearch.index.shard.IndexShard;\n+import org.elasticsearch.index.shard.IndexShardIT;\n+import org.elasticsearch.index.shard.IndexShardTestCase;\n+import org.elasticsearch.indices.breaker.NoneCircuitBreakerService;\n+import org.elasticsearch.indices.recovery.RecoveryState;\n+import org.elasticsearch.test.ESSingleNodeTestCase;\n+import org.elasticsearch.threadpool.Scheduler.Cancellable;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static java.util.Collections.emptyMap;\n+import static java.util.Collections.emptySet;\n+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;\n+\n+public class IndexingMemoryControllerIT extends ESSingleNodeTestCase {\n+\n+    // #10312\n+    public void testDeletesAloneCanTriggerRefresh() throws Exception {\n+        createIndex(\"index\",\n+                    Settings.builder().put(\"index.number_of_shards\", 1)\n+                                      .put(\"index.number_of_replicas\", 0)\n+                                      .put(\"index.refresh_interval\", -1)\n+                                      .build());\n+        ensureGreen();\n+\n+        IndicesService indicesService = getInstanceFromNode(IndicesService.class);\n+        IndexService indexService = indicesService.indexService(resolveIndex(\"index\"));\n+        IndexShard shard = indexService.getShardOrNull(0);\n+        assertNotNull(shard);\n+\n+        for (int i = 0; i < 100; i++) {\n+            String id = Integer.toString(i);\n+            client().prepareIndex(\"index\").setId(id).setSource(\"field\", \"value\").get();\n+        }\n+\n+        // Force merge so we know all merges are done before we start deleting:\n+        ForceMergeResponse r = client().admin().indices().prepareForceMerge().setMaxNumSegments(1).execute().actionGet();\n+        assertNoFailures(r);\n+\n+        // Make a shell of an IMC to check up on indexing buffer usage:\n+        Settings settings = Settings.builder().put(\"indices.memory.index_buffer_size\", \"1kb\").build();\n+\n+        // TODO: would be cleaner if I could pass this 1kb setting to the single node this test created....\n+        IndexingMemoryController imc = new IndexingMemoryController(settings, null, null) {\n+            @Override\n+            protected List<IndexShard> availableShards() {\n+                return Collections.singletonList(shard);\n+            }\n+\n+            @Override\n+            protected long getIndexBufferRAMBytesUsed(IndexShard shard) {\n+                return shard.getIndexBufferRAMBytesUsed();\n+            }\n+\n+            @Override\n+            protected void writeIndexingBufferAsync(IndexShard shard) {\n+                // just do it sync'd for this test\n+                shard.writeIndexingBuffer();\n+            }\n+\n+            @Override\n+            protected Cancellable scheduleTask(ThreadPool threadPool) {\n+                return null;\n+            }\n+        };\n+\n+        for (int i = 0; i < 100; i++) {\n+            String id = Integer.toString(i);\n+            client().prepareDelete(\"index\", id).get();\n+        }\n+\n+        final long indexingBufferBytes1 = shard.getIndexBufferRAMBytesUsed();\n+\n+        imc.forceCheck();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f0a05f98d63cac908023df9c91955a84a55e39f1"}, "originalPosition": 109}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "747551513e5712883168a48d4916d2ec6e4202e7", "author": {"user": {"login": "dnhatn", "name": "Nhat Nguyen"}}, "url": "https://github.com/elastic/elasticsearch/commit/747551513e5712883168a48d4916d2ec6e4202e7", "committedDate": "2020-01-09T13:52:11Z", "message": "ensure refresh threadpool stats exist"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4d04e97c214626fd184de151d6fe36949e0267cb", "author": {"user": {"login": "dnhatn", "name": "Nhat Nguyen"}}, "url": "https://github.com/elastic/elasticsearch/commit/4d04e97c214626fd184de151d6fe36949e0267cb", "committedDate": "2020-01-09T17:58:04Z", "message": "arrange tests"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3673, "cost": 1, "resetAt": "2021-10-28T19:08:13Z"}}}