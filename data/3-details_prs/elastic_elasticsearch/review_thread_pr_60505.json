{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDYwMDEyODM4", "number": 60505, "reviewThreads": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwNzo1OToxOFrOEUgW4A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQwOToyNzo1OFrOEU659w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5OTM3MTIwOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwNzo1OToxOFrOG6vw7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwNzo1OToxOFrOG6vw7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDI1MzE2Nw==", "bodyText": "what's the point of this private method? It's just delegating a single call, yet introducing an unnecessary abstraction", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r464253167", "createdAt": "2020-08-03T07:59:18Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -387,58 +395,73 @@ private void cleanExistingRegularShardFiles() {\n         }\n     }\n \n+    private void onPreWarmFinished() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a6ce58dfe8ce55b4b96c396069abc2a593d3a4a"}, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5OTM5Mzc1OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwODowNjo0MVrOG6v-Sg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwODowNjo0MVrOG6v-Sg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDI1NjU4Ng==", "bodyText": "Inline this into prewarmCache? Especially as it's duplicating the iteration logic down below.", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r464256586", "createdAt": "2020-08-03T08:06:41Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -455,6 +478,19 @@ private void prewarmNext(final Executor executor, final BlockingQueue<Tuple<Acti\n         }\n     }\n \n+    private void addRecoveryFileDetails() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a6ce58dfe8ce55b4b96c396069abc2a593d3a4a"}, "originalPosition": 169}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5OTQyNTEwOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/SearchableSnapshotDirectoryTests.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwODoxNzowOVrOG6wRTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwODoxNzowOVrOG6wRTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDI2MTQ1NA==", "bodyText": "KeptOpen?", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r464261454", "createdAt": "2020-08-03T08:17:09Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/SearchableSnapshotDirectoryTests.java", "diffHunk": "@@ -736,6 +765,74 @@ public void testRequiresAdditionalSettings() {\n         }\n     }\n \n+    public void testRecoveryStateIsKeepOpenAfterPreWarmFailures() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a6ce58dfe8ce55b4b96c396069abc2a593d3a4a"}, "originalPosition": 117}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5OTQ0ODkyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshotsConstants.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwODoyNDoyOVrOG6wfjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwODoyNDoyOVrOG6wfjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDI2NTEwMQ==", "bodyText": "With the change in behavior of this PR, rename this perhaps to \"snapshot_prewarm\".", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r464265101", "createdAt": "2020-08-03T08:24:29Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshotsConstants.java", "diffHunk": "@@ -30,6 +30,8 @@\n \n     public static final String SNAPSHOT_DIRECTORY_FACTORY_KEY = \"snapshot\";\n \n+    public static final String SNAPSHOT_RECOVERY_STATE_FACTORY_KEY = \"on_demand\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a6ce58dfe8ce55b4b96c396069abc2a593d3a4a"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5OTQ4NDU5OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwODozNToxNFrOG6w1Qw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwODozNToxNFrOG6w1Qw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDI3MDY1OQ==", "bodyText": "This assumes that noone is touching the index setting index.recovery.type. Perhaps we should also throw an explicit exception here when assertions are not enabled?", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r464270659", "createdAt": "2020-08-03T08:35:14Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -176,7 +180,9 @@ protected final boolean assertCurrentThreadMayLoadSnapshot() {\n      *\n      * @return true if the snapshot was loaded by executing this method, false otherwise\n      */\n-    public boolean loadSnapshot() {\n+    public boolean loadSnapshot(RecoveryState recoveryState) {\n+        assert recoveryState != null;\n+        assert recoveryState instanceof SearchableSnapshotRecoveryState;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a6ce58dfe8ce55b4b96c396069abc2a593d3a4a"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5OTUwODY4OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/SearchableSnapshotDirectoryTests.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwODo0Mjo0NlrOG6xD6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwODo0Mjo0NlrOG6xD6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDI3NDQwOQ==", "bodyText": "maybe just choose a random subset of  these, and then check later that fileDetails does  not contain any of the subset  chosen? THis test  here would currently be trivially satisfied if the code was to just ignore all files whenever excluded files existed.", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r464274409", "createdAt": "2020-08-03T08:42:46Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/SearchableSnapshotDirectoryTests.java", "diffHunk": "@@ -736,6 +765,74 @@ public void testRequiresAdditionalSettings() {\n         }\n     }\n \n+    public void testRecoveryStateIsKeepOpenAfterPreWarmFailures() throws Exception {\n+        FileSystem fileSystem = PathUtils.getDefaultFileSystem();\n+        FaultyReadsFileSystem disruptFileSystemProvider = new FaultyReadsFileSystem(fileSystem);\n+        fileSystem = disruptFileSystemProvider.getFileSystem(null);\n+        PathUtilsForTesting.installMock(fileSystem);\n+\n+        try {\n+            SearchableSnapshotRecoveryState recoveryState = createRecoveryState();\n+            testDirectories(true, true, recoveryState, Settings.EMPTY, (directory, snapshotDirectory) -> {\n+                ThreadPoolExecutor executor = (ThreadPoolExecutor) snapshotDirectory.cacheFetchAsyncExecutor();\n+                assertBusy(() -> {\n+                    assertThat(executor.getActiveCount(), equalTo(0));\n+                    assertThat(executor.getQueue().size(), equalTo(0));\n+                });\n+\n+                assertThat(recoveryState.getStage(), equalTo(RecoveryState.Stage.FINALIZE));\n+                // All pre-warm tasks failed\n+                assertThat(recoveryState.getIndex().recoveredBytes(), equalTo(0L));\n+            });\n+        } finally {\n+            PathUtilsForTesting.teardown();\n+        }\n+    }\n+\n+    public void testRecoveryStateIsEmptyWhenTheCacheIsNotPreWarmed() throws Exception {\n+        SearchableSnapshotRecoveryState recoveryState = createRecoveryState();\n+        testDirectories(true, false, recoveryState, Settings.EMPTY, (directory, snapshotDirectory) -> {\n+            assertThat(recoveryState.getStage(), equalTo(RecoveryState.Stage.DONE));\n+            assertThat(recoveryState.getIndex().recoveredBytes(), equalTo(0L));\n+            assertThat(recoveryState.getIndex().totalRecoverFiles(), equalTo(0));\n+        });\n+    }\n+\n+    public void testNonCachedFilesAreExcludedFromRecoveryState() throws Exception {\n+        SearchableSnapshotRecoveryState recoveryState = createRecoveryState();\n+\n+        List<String> allFileExtensions = List.of(\n+            \"fdt\",\n+            \"fdx\",\n+            \"nvd\",\n+            \"dvd\",\n+            \"tip\",\n+            \"cfs\",\n+            \"dim\",\n+            \"fnm\",\n+            \"dvm\",\n+            \"tmd\",\n+            \"doc\",\n+            \"tim\",\n+            \"pos\",\n+            \"cfe\",\n+            \"fdm\",\n+            \"nvm\"\n+        );\n+        Settings settings = Settings.builder().putList(SNAPSHOT_CACHE_EXCLUDED_FILE_TYPES_SETTING.getKey(), allFileExtensions).build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a6ce58dfe8ce55b4b96c396069abc2a593d3a4a"}, "originalPosition": 171}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5OTUyNjg3OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshotsIntegTests.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwODo0ODowM1rOG6xO0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwODo0ODowM1rOG6xO0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDI3NzIwMA==", "bodyText": "is this info-level logging still needed?", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r464277200", "createdAt": "2020-08-03T08:48:03Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshotsIntegTests.java", "diffHunk": "@@ -703,6 +700,29 @@ private void assertRecovered(String indexName, TotalHits originalAllHits, TotalH\n         }\n     }\n \n+    private void assertRecoveryStats(String indexName, boolean preWarmEnabled) {\n+        int shardCount = getNumShards(indexName).totalNumShards;\n+        final RecoveryResponse recoveryResponse = client().admin().indices().prepareRecoveries(indexName).get();\n+        assertThat(recoveryResponse.shardRecoveryStates().get(indexName).size(), equalTo(shardCount));\n+\n+        for (List<RecoveryState> recoveryStates : recoveryResponse.shardRecoveryStates().values()) {\n+            for (RecoveryState recoveryState : recoveryStates) {\n+                logger.info(\"Checking {}[{}]\", recoveryState.getShardId(), recoveryState.getPrimary() ? \"p\" : \"r\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a6ce58dfe8ce55b4b96c396069abc2a593d3a4a"}, "originalPosition": 161}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5OTUzMjAwOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshotsIntegTests.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwODo0OTozMlrOG6xR1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwOTowNDozN1rOG6xyzg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDI3Nzk3NQ==", "bodyText": "That's not true anymore with the latest approach? Shouldn't it always be DONE?", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r464277975", "createdAt": "2020-08-03T08:49:32Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshotsIntegTests.java", "diffHunk": "@@ -703,6 +700,29 @@ private void assertRecovered(String indexName, TotalHits originalAllHits, TotalH\n         }\n     }\n \n+    private void assertRecoveryStats(String indexName, boolean preWarmEnabled) {\n+        int shardCount = getNumShards(indexName).totalNumShards;\n+        final RecoveryResponse recoveryResponse = client().admin().indices().prepareRecoveries(indexName).get();\n+        assertThat(recoveryResponse.shardRecoveryStates().get(indexName).size(), equalTo(shardCount));\n+\n+        for (List<RecoveryState> recoveryStates : recoveryResponse.shardRecoveryStates().values()) {\n+            for (RecoveryState recoveryState : recoveryStates) {\n+                logger.info(\"Checking {}[{}]\", recoveryState.getShardId(), recoveryState.getPrimary() ? \"p\" : \"r\");\n+                ByteSizeValue cacheSize = getCacheSizeForShard(recoveryState.getShardId());\n+                boolean largeCache = cacheSize.compareTo(new ByteSizeValue(1, ByteSizeUnit.MB)) >= 0;\n+                assertThat(\n+                    Strings.toString(recoveryState),\n+                    recoveryState.getIndex().recoveredFileCount(),\n+                    preWarmEnabled && largeCache ? greaterThan(0) : greaterThanOrEqualTo(0)\n+                );\n+\n+                // Since the cache size is variable, the pre-warm phase might fail as some of the files can be evicted\n+                // while a part is pre-fetched, in that case the recovery state is left as FINALIZE.\n+                assertThat(recoveryState.getStage(), anyOf(equalTo(RecoveryState.Stage.DONE), equalTo(RecoveryState.Stage.FINALIZE)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a6ce58dfe8ce55b4b96c396069abc2a593d3a4a"}, "originalPosition": 172}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDI4NDg1MQ==", "bodyText": "In those tests the cache size is set randomly, meaning that's possible that in some test instances the cache won't have room for all the files in the index therefore some of the pre-warming tasks would fail.", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r464284851", "createdAt": "2020-08-03T09:01:45Z", "author": {"login": "fcofdez"}, "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshotsIntegTests.java", "diffHunk": "@@ -703,6 +700,29 @@ private void assertRecovered(String indexName, TotalHits originalAllHits, TotalH\n         }\n     }\n \n+    private void assertRecoveryStats(String indexName, boolean preWarmEnabled) {\n+        int shardCount = getNumShards(indexName).totalNumShards;\n+        final RecoveryResponse recoveryResponse = client().admin().indices().prepareRecoveries(indexName).get();\n+        assertThat(recoveryResponse.shardRecoveryStates().get(indexName).size(), equalTo(shardCount));\n+\n+        for (List<RecoveryState> recoveryStates : recoveryResponse.shardRecoveryStates().values()) {\n+            for (RecoveryState recoveryState : recoveryStates) {\n+                logger.info(\"Checking {}[{}]\", recoveryState.getShardId(), recoveryState.getPrimary() ? \"p\" : \"r\");\n+                ByteSizeValue cacheSize = getCacheSizeForShard(recoveryState.getShardId());\n+                boolean largeCache = cacheSize.compareTo(new ByteSizeValue(1, ByteSizeUnit.MB)) >= 0;\n+                assertThat(\n+                    Strings.toString(recoveryState),\n+                    recoveryState.getIndex().recoveredFileCount(),\n+                    preWarmEnabled && largeCache ? greaterThan(0) : greaterThanOrEqualTo(0)\n+                );\n+\n+                // Since the cache size is variable, the pre-warm phase might fail as some of the files can be evicted\n+                // while a part is pre-fetched, in that case the recovery state is left as FINALIZE.\n+                assertThat(recoveryState.getStage(), anyOf(equalTo(RecoveryState.Stage.DONE), equalTo(RecoveryState.Stage.FINALIZE)));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDI3Nzk3NQ=="}, "originalCommit": {"oid": "1a6ce58dfe8ce55b4b96c396069abc2a593d3a4a"}, "originalPosition": 172}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDI4NjQxNA==", "bodyText": "Can we make a stronger assertion here then in case where the cache is set to unbounded?", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r464286414", "createdAt": "2020-08-03T09:04:37Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshotsIntegTests.java", "diffHunk": "@@ -703,6 +700,29 @@ private void assertRecovered(String indexName, TotalHits originalAllHits, TotalH\n         }\n     }\n \n+    private void assertRecoveryStats(String indexName, boolean preWarmEnabled) {\n+        int shardCount = getNumShards(indexName).totalNumShards;\n+        final RecoveryResponse recoveryResponse = client().admin().indices().prepareRecoveries(indexName).get();\n+        assertThat(recoveryResponse.shardRecoveryStates().get(indexName).size(), equalTo(shardCount));\n+\n+        for (List<RecoveryState> recoveryStates : recoveryResponse.shardRecoveryStates().values()) {\n+            for (RecoveryState recoveryState : recoveryStates) {\n+                logger.info(\"Checking {}[{}]\", recoveryState.getShardId(), recoveryState.getPrimary() ? \"p\" : \"r\");\n+                ByteSizeValue cacheSize = getCacheSizeForShard(recoveryState.getShardId());\n+                boolean largeCache = cacheSize.compareTo(new ByteSizeValue(1, ByteSizeUnit.MB)) >= 0;\n+                assertThat(\n+                    Strings.toString(recoveryState),\n+                    recoveryState.getIndex().recoveredFileCount(),\n+                    preWarmEnabled && largeCache ? greaterThan(0) : greaterThanOrEqualTo(0)\n+                );\n+\n+                // Since the cache size is variable, the pre-warm phase might fail as some of the files can be evicted\n+                // while a part is pre-fetched, in that case the recovery state is left as FINALIZE.\n+                assertThat(recoveryState.getStage(), anyOf(equalTo(RecoveryState.Stage.DONE), equalTo(RecoveryState.Stage.FINALIZE)));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDI3Nzk3NQ=="}, "originalCommit": {"oid": "1a6ce58dfe8ce55b4b96c396069abc2a593d3a4a"}, "originalPosition": 172}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5OTUzMzIyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshotsIntegTests.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwODo0OTo1M1rOG6xSmQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwODo0OTo1M1rOG6xSmQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDI3ODE2OQ==", "bodyText": "Is still relevant with the latest approach?", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r464278169", "createdAt": "2020-08-03T08:49:53Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshotsIntegTests.java", "diffHunk": "@@ -703,6 +700,29 @@ private void assertRecovered(String indexName, TotalHits originalAllHits, TotalH\n         }\n     }\n \n+    private void assertRecoveryStats(String indexName, boolean preWarmEnabled) {\n+        int shardCount = getNumShards(indexName).totalNumShards;\n+        final RecoveryResponse recoveryResponse = client().admin().indices().prepareRecoveries(indexName).get();\n+        assertThat(recoveryResponse.shardRecoveryStates().get(indexName).size(), equalTo(shardCount));\n+\n+        for (List<RecoveryState> recoveryStates : recoveryResponse.shardRecoveryStates().values()) {\n+            for (RecoveryState recoveryState : recoveryStates) {\n+                logger.info(\"Checking {}[{}]\", recoveryState.getShardId(), recoveryState.getPrimary() ? \"p\" : \"r\");\n+                ByteSizeValue cacheSize = getCacheSizeForShard(recoveryState.getShardId());\n+                boolean largeCache = cacheSize.compareTo(new ByteSizeValue(1, ByteSizeUnit.MB)) >= 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a6ce58dfe8ce55b4b96c396069abc2a593d3a4a"}, "originalPosition": 163}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwMzY4NTU1OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQwOToxODoxMlrOG7YOow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQwODoyNDoxOVrOG7_c1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDkxNjEzMQ==", "bodyText": "In case where file.metadata().hashEqualsContents(), I wonder if we should just mark those files as recovered (reused = true) (as they are subsequently available), i.e. recoveryState.getIndex().addFileDetail(file.physicalName(), file.length(), true);.", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r464916131", "createdAt": "2020-08-04T09:18:12Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -388,57 +398,70 @@ private void cleanExistingRegularShardFiles() {\n     }\n \n     private void prewarmCache() {\n-        if (prewarmCache) {\n-            final BlockingQueue<Tuple<ActionListener<Void>, CheckedRunnable<Exception>>> queue = new LinkedBlockingQueue<>();\n-            final Executor executor = prewarmExecutor();\n+        if (prewarmCache == false) {\n+            recoveryState.preWarmFinished();\n+            return;\n+        }\n \n-            for (BlobStoreIndexShardSnapshot.FileInfo file : snapshot().indexFiles()) {\n-                if (file.metadata().hashEqualsContents() || isExcludedFromCache(file.physicalName())) {\n-                    continue;\n-                }\n-                try {\n-                    final IndexInput input = openInput(file.physicalName(), CachedBlobContainerIndexInput.CACHE_WARMING_CONTEXT);\n-                    assert input instanceof CachedBlobContainerIndexInput : \"expected cached index input but got \" + input.getClass();\n-\n-                    final int numberOfParts = Math.toIntExact(file.numberOfParts());\n-                    final GroupedActionListener<Void> listener = new GroupedActionListener<>(\n-                        ActionListener.wrap(voids -> input.close(), e -> IOUtils.closeWhileHandlingException(input)),\n-                        numberOfParts\n-                    );\n-\n-                    for (int p = 0; p < numberOfParts; p++) {\n-                        final int part = p;\n-                        queue.add(Tuple.tuple(listener, () -> {\n-                            ensureOpen();\n-\n-                            logger.trace(\"{} warming cache for [{}] part [{}/{}]\", shardId, file.physicalName(), part + 1, numberOfParts);\n-                            final long startTimeInNanos = statsCurrentTimeNanosSupplier.getAsLong();\n-                            ((CachedBlobContainerIndexInput) input).prefetchPart(part);\n-\n-                            logger.trace(\n-                                () -> new ParameterizedMessage(\n-                                    \"{} part [{}/{}] of [{}] warmed in [{}] ms\",\n-                                    shardId,\n-                                    part + 1,\n-                                    numberOfParts,\n-                                    file.physicalName(),\n-                                    TimeValue.timeValueNanos(statsCurrentTimeNanosSupplier.getAsLong() - startTimeInNanos).millis()\n-                                )\n-                            );\n-                        }));\n-                    }\n-                } catch (IOException e) {\n-                    logger.warn(() -> new ParameterizedMessage(\"{} unable to prewarm file [{}]\", shardId, file.physicalName()), e);\n+        final BlockingQueue<Tuple<ActionListener<Void>, CheckedRunnable<Exception>>> queue = new LinkedBlockingQueue<>();\n+        final Executor executor = prewarmExecutor();\n+\n+        final GroupedActionListener<Void> completionListener = new GroupedActionListener<>(\n+            ActionListener.wrap(voids -> recoveryState.preWarmFinished(), e -> {}), // Ignore pre-warm errors\n+            snapshot().totalFileCount()\n+        );\n+\n+        for (BlobStoreIndexShardSnapshot.FileInfo file : snapshot().indexFiles()) {\n+            if (file.metadata().hashEqualsContents() || isExcludedFromCache(file.physicalName())) {\n+                recoveryState.ignoreFile(file.physicalName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2989f667ca763500b9c6311ec03af81aeb2ef38"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDkzMTg0MQ==", "bodyText": "I think that's a good idea.", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r464931841", "createdAt": "2020-08-04T09:45:33Z", "author": {"login": "fcofdez"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -388,57 +398,70 @@ private void cleanExistingRegularShardFiles() {\n     }\n \n     private void prewarmCache() {\n-        if (prewarmCache) {\n-            final BlockingQueue<Tuple<ActionListener<Void>, CheckedRunnable<Exception>>> queue = new LinkedBlockingQueue<>();\n-            final Executor executor = prewarmExecutor();\n+        if (prewarmCache == false) {\n+            recoveryState.preWarmFinished();\n+            return;\n+        }\n \n-            for (BlobStoreIndexShardSnapshot.FileInfo file : snapshot().indexFiles()) {\n-                if (file.metadata().hashEqualsContents() || isExcludedFromCache(file.physicalName())) {\n-                    continue;\n-                }\n-                try {\n-                    final IndexInput input = openInput(file.physicalName(), CachedBlobContainerIndexInput.CACHE_WARMING_CONTEXT);\n-                    assert input instanceof CachedBlobContainerIndexInput : \"expected cached index input but got \" + input.getClass();\n-\n-                    final int numberOfParts = Math.toIntExact(file.numberOfParts());\n-                    final GroupedActionListener<Void> listener = new GroupedActionListener<>(\n-                        ActionListener.wrap(voids -> input.close(), e -> IOUtils.closeWhileHandlingException(input)),\n-                        numberOfParts\n-                    );\n-\n-                    for (int p = 0; p < numberOfParts; p++) {\n-                        final int part = p;\n-                        queue.add(Tuple.tuple(listener, () -> {\n-                            ensureOpen();\n-\n-                            logger.trace(\"{} warming cache for [{}] part [{}/{}]\", shardId, file.physicalName(), part + 1, numberOfParts);\n-                            final long startTimeInNanos = statsCurrentTimeNanosSupplier.getAsLong();\n-                            ((CachedBlobContainerIndexInput) input).prefetchPart(part);\n-\n-                            logger.trace(\n-                                () -> new ParameterizedMessage(\n-                                    \"{} part [{}/{}] of [{}] warmed in [{}] ms\",\n-                                    shardId,\n-                                    part + 1,\n-                                    numberOfParts,\n-                                    file.physicalName(),\n-                                    TimeValue.timeValueNanos(statsCurrentTimeNanosSupplier.getAsLong() - startTimeInNanos).millis()\n-                                )\n-                            );\n-                        }));\n-                    }\n-                } catch (IOException e) {\n-                    logger.warn(() -> new ParameterizedMessage(\"{} unable to prewarm file [{}]\", shardId, file.physicalName()), e);\n+        final BlockingQueue<Tuple<ActionListener<Void>, CheckedRunnable<Exception>>> queue = new LinkedBlockingQueue<>();\n+        final Executor executor = prewarmExecutor();\n+\n+        final GroupedActionListener<Void> completionListener = new GroupedActionListener<>(\n+            ActionListener.wrap(voids -> recoveryState.preWarmFinished(), e -> {}), // Ignore pre-warm errors\n+            snapshot().totalFileCount()\n+        );\n+\n+        for (BlobStoreIndexShardSnapshot.FileInfo file : snapshot().indexFiles()) {\n+            if (file.metadata().hashEqualsContents() || isExcludedFromCache(file.physicalName())) {\n+                recoveryState.ignoreFile(file.physicalName());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDkxNjEzMQ=="}, "originalCommit": {"oid": "b2989f667ca763500b9c6311ec03af81aeb2ef38"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTU0NzkyNA==", "bodyText": "Is this behavior tested anywhere?", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r465547924", "createdAt": "2020-08-05T08:05:13Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -388,57 +398,70 @@ private void cleanExistingRegularShardFiles() {\n     }\n \n     private void prewarmCache() {\n-        if (prewarmCache) {\n-            final BlockingQueue<Tuple<ActionListener<Void>, CheckedRunnable<Exception>>> queue = new LinkedBlockingQueue<>();\n-            final Executor executor = prewarmExecutor();\n+        if (prewarmCache == false) {\n+            recoveryState.preWarmFinished();\n+            return;\n+        }\n \n-            for (BlobStoreIndexShardSnapshot.FileInfo file : snapshot().indexFiles()) {\n-                if (file.metadata().hashEqualsContents() || isExcludedFromCache(file.physicalName())) {\n-                    continue;\n-                }\n-                try {\n-                    final IndexInput input = openInput(file.physicalName(), CachedBlobContainerIndexInput.CACHE_WARMING_CONTEXT);\n-                    assert input instanceof CachedBlobContainerIndexInput : \"expected cached index input but got \" + input.getClass();\n-\n-                    final int numberOfParts = Math.toIntExact(file.numberOfParts());\n-                    final GroupedActionListener<Void> listener = new GroupedActionListener<>(\n-                        ActionListener.wrap(voids -> input.close(), e -> IOUtils.closeWhileHandlingException(input)),\n-                        numberOfParts\n-                    );\n-\n-                    for (int p = 0; p < numberOfParts; p++) {\n-                        final int part = p;\n-                        queue.add(Tuple.tuple(listener, () -> {\n-                            ensureOpen();\n-\n-                            logger.trace(\"{} warming cache for [{}] part [{}/{}]\", shardId, file.physicalName(), part + 1, numberOfParts);\n-                            final long startTimeInNanos = statsCurrentTimeNanosSupplier.getAsLong();\n-                            ((CachedBlobContainerIndexInput) input).prefetchPart(part);\n-\n-                            logger.trace(\n-                                () -> new ParameterizedMessage(\n-                                    \"{} part [{}/{}] of [{}] warmed in [{}] ms\",\n-                                    shardId,\n-                                    part + 1,\n-                                    numberOfParts,\n-                                    file.physicalName(),\n-                                    TimeValue.timeValueNanos(statsCurrentTimeNanosSupplier.getAsLong() - startTimeInNanos).millis()\n-                                )\n-                            );\n-                        }));\n-                    }\n-                } catch (IOException e) {\n-                    logger.warn(() -> new ParameterizedMessage(\"{} unable to prewarm file [{}]\", shardId, file.physicalName()), e);\n+        final BlockingQueue<Tuple<ActionListener<Void>, CheckedRunnable<Exception>>> queue = new LinkedBlockingQueue<>();\n+        final Executor executor = prewarmExecutor();\n+\n+        final GroupedActionListener<Void> completionListener = new GroupedActionListener<>(\n+            ActionListener.wrap(voids -> recoveryState.preWarmFinished(), e -> {}), // Ignore pre-warm errors\n+            snapshot().totalFileCount()\n+        );\n+\n+        for (BlobStoreIndexShardSnapshot.FileInfo file : snapshot().indexFiles()) {\n+            if (file.metadata().hashEqualsContents() || isExcludedFromCache(file.physicalName())) {\n+                recoveryState.ignoreFile(file.physicalName());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDkxNjEzMQ=="}, "originalCommit": {"oid": "b2989f667ca763500b9c6311ec03af81aeb2ef38"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTU1ODc0MQ==", "bodyText": "No, I'll add a test that covers files with file.metadata().hashEqualsContents() property, thanks!", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r465558741", "createdAt": "2020-08-05T08:24:19Z", "author": {"login": "fcofdez"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -388,57 +398,70 @@ private void cleanExistingRegularShardFiles() {\n     }\n \n     private void prewarmCache() {\n-        if (prewarmCache) {\n-            final BlockingQueue<Tuple<ActionListener<Void>, CheckedRunnable<Exception>>> queue = new LinkedBlockingQueue<>();\n-            final Executor executor = prewarmExecutor();\n+        if (prewarmCache == false) {\n+            recoveryState.preWarmFinished();\n+            return;\n+        }\n \n-            for (BlobStoreIndexShardSnapshot.FileInfo file : snapshot().indexFiles()) {\n-                if (file.metadata().hashEqualsContents() || isExcludedFromCache(file.physicalName())) {\n-                    continue;\n-                }\n-                try {\n-                    final IndexInput input = openInput(file.physicalName(), CachedBlobContainerIndexInput.CACHE_WARMING_CONTEXT);\n-                    assert input instanceof CachedBlobContainerIndexInput : \"expected cached index input but got \" + input.getClass();\n-\n-                    final int numberOfParts = Math.toIntExact(file.numberOfParts());\n-                    final GroupedActionListener<Void> listener = new GroupedActionListener<>(\n-                        ActionListener.wrap(voids -> input.close(), e -> IOUtils.closeWhileHandlingException(input)),\n-                        numberOfParts\n-                    );\n-\n-                    for (int p = 0; p < numberOfParts; p++) {\n-                        final int part = p;\n-                        queue.add(Tuple.tuple(listener, () -> {\n-                            ensureOpen();\n-\n-                            logger.trace(\"{} warming cache for [{}] part [{}/{}]\", shardId, file.physicalName(), part + 1, numberOfParts);\n-                            final long startTimeInNanos = statsCurrentTimeNanosSupplier.getAsLong();\n-                            ((CachedBlobContainerIndexInput) input).prefetchPart(part);\n-\n-                            logger.trace(\n-                                () -> new ParameterizedMessage(\n-                                    \"{} part [{}/{}] of [{}] warmed in [{}] ms\",\n-                                    shardId,\n-                                    part + 1,\n-                                    numberOfParts,\n-                                    file.physicalName(),\n-                                    TimeValue.timeValueNanos(statsCurrentTimeNanosSupplier.getAsLong() - startTimeInNanos).millis()\n-                                )\n-                            );\n-                        }));\n-                    }\n-                } catch (IOException e) {\n-                    logger.warn(() -> new ParameterizedMessage(\"{} unable to prewarm file [{}]\", shardId, file.physicalName()), e);\n+        final BlockingQueue<Tuple<ActionListener<Void>, CheckedRunnable<Exception>>> queue = new LinkedBlockingQueue<>();\n+        final Executor executor = prewarmExecutor();\n+\n+        final GroupedActionListener<Void> completionListener = new GroupedActionListener<>(\n+            ActionListener.wrap(voids -> recoveryState.preWarmFinished(), e -> {}), // Ignore pre-warm errors\n+            snapshot().totalFileCount()\n+        );\n+\n+        for (BlobStoreIndexShardSnapshot.FileInfo file : snapshot().indexFiles()) {\n+            if (file.metadata().hashEqualsContents() || isExcludedFromCache(file.physicalName())) {\n+                recoveryState.ignoreFile(file.physicalName());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDkxNjEzMQ=="}, "originalCommit": {"oid": "b2989f667ca763500b9c6311ec03af81aeb2ef38"}, "originalPosition": 107}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwMzY5NzY0OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/indices/recovery/SearchableSnapshotRecoveryState.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQwOToyMTozM1rOG7YWFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQwOTo0MTo0MlrOG7ZDYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDkxODAzOQ==", "bodyText": "should we throw an exception here if the stage is currently not FINALIZE, i.e. validateCurrentStage(FINALIZE)?", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r464918039", "createdAt": "2020-08-04T09:21:33Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/indices/recovery/SearchableSnapshotRecoveryState.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.indices.recovery;\n+\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.common.Nullable;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+public final class SearchableSnapshotRecoveryState extends RecoveryState {\n+    private boolean preWarmFinished;\n+\n+    public SearchableSnapshotRecoveryState(ShardRouting shardRouting, DiscoveryNode targetNode, @Nullable DiscoveryNode sourceNode) {\n+        super(shardRouting, targetNode, sourceNode, new Index());\n+    }\n+\n+    @Override\n+    public synchronized RecoveryState setStage(Stage stage) {\n+        // The transition to the final state was done by #prewarmCompleted, just ignore the transition\n+        if (getStage() == Stage.DONE) {\n+            return this;\n+        }\n+\n+        // Pre-warm is still running, hold the state transition\n+        // until the pre-warm process finishes\n+        if (preWarmFinished == false && stage == Stage.DONE) {\n+            return this;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2989f667ca763500b9c6311ec03af81aeb2ef38"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDkyOTYzNQ==", "bodyText": "+1", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r464929635", "createdAt": "2020-08-04T09:41:42Z", "author": {"login": "fcofdez"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/indices/recovery/SearchableSnapshotRecoveryState.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.indices.recovery;\n+\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.common.Nullable;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+public final class SearchableSnapshotRecoveryState extends RecoveryState {\n+    private boolean preWarmFinished;\n+\n+    public SearchableSnapshotRecoveryState(ShardRouting shardRouting, DiscoveryNode targetNode, @Nullable DiscoveryNode sourceNode) {\n+        super(shardRouting, targetNode, sourceNode, new Index());\n+    }\n+\n+    @Override\n+    public synchronized RecoveryState setStage(Stage stage) {\n+        // The transition to the final state was done by #prewarmCompleted, just ignore the transition\n+        if (getStage() == Stage.DONE) {\n+            return this;\n+        }\n+\n+        // Pre-warm is still running, hold the state transition\n+        // until the pre-warm process finishes\n+        if (preWarmFinished == false && stage == Stage.DONE) {\n+            return this;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDkxODAzOQ=="}, "originalCommit": {"oid": "b2989f667ca763500b9c6311ec03af81aeb2ef38"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwMzcwNTIxOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/indices/recovery/SearchableSnapshotRecoveryState.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQwOToyMzo0MVrOG7Yayg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQwOTo0NDowNlrOG7ZIww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDkxOTI0Mg==", "bodyText": "do we not need to implement this method, which  gets called when a peer recovery retries?", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r464919242", "createdAt": "2020-08-04T09:23:41Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/indices/recovery/SearchableSnapshotRecoveryState.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.indices.recovery;\n+\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.common.Nullable;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+public final class SearchableSnapshotRecoveryState extends RecoveryState {\n+    private boolean preWarmFinished;\n+\n+    public SearchableSnapshotRecoveryState(ShardRouting shardRouting, DiscoveryNode targetNode, @Nullable DiscoveryNode sourceNode) {\n+        super(shardRouting, targetNode, sourceNode, new Index());\n+    }\n+\n+    @Override\n+    public synchronized RecoveryState setStage(Stage stage) {\n+        // The transition to the final state was done by #prewarmCompleted, just ignore the transition\n+        if (getStage() == Stage.DONE) {\n+            return this;\n+        }\n+\n+        // Pre-warm is still running, hold the state transition\n+        // until the pre-warm process finishes\n+        if (preWarmFinished == false && stage == Stage.DONE) {\n+            return this;\n+        }\n+\n+        return super.setStage(stage);\n+    }\n+\n+    public synchronized void preWarmFinished() {\n+        // For small shards it's possible that the\n+        // cache is pre-warmed before the stage has transitioned\n+        // to FINALIZE, so the transition to the final state is delayed until\n+        // the recovery process catches up.\n+        if (getStage() == Stage.FINALIZE) {\n+            super.setStage(Stage.DONE);\n+        }\n+\n+        SearchableSnapshotRecoveryState.Index index = (Index) getIndex();\n+        index.stopTimer();\n+        preWarmFinished = true;\n+    }\n+\n+    public synchronized void ignoreFile(String name) {\n+        SearchableSnapshotRecoveryState.Index index = (Index) getIndex();\n+        index.addFileToIgnore(name);\n+    }\n+\n+    private static final class Index extends RecoveryState.Index {\n+        // We ignore the files that won't be part of the pre-warming\n+        // phase since the information for those files won't be\n+        // updated and marking them as reused might be confusing,\n+        // as they are fetched on-demand from the underlying repository.\n+        private final Set<String> filesToIgnore = new HashSet<>();\n+\n+        private Index() {\n+            super(new SearchableSnapshotRecoveryFilesDetails());\n+            // We start loading data just at the beginning\n+            super.start();\n+        }\n+\n+        private synchronized void addFileToIgnore(String name) {\n+            filesToIgnore.add(name);\n+        }\n+\n+        @Override\n+        public synchronized void addFileDetail(String name, long length, boolean reused) {\n+            if (filesToIgnore.contains(name)) {\n+                return;\n+            }\n+\n+            super.addFileDetail(name, length, reused);\n+        }\n+\n+        // We have to bypass all the calls to the timer\n+        @Override\n+        public synchronized void start() {}\n+\n+        @Override\n+        public synchronized void stop() {}\n+\n+        @Override\n+        public synchronized void reset() {}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2989f667ca763500b9c6311ec03af81aeb2ef38"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDkzMTAxMQ==", "bodyText": "The behavior don't change during peer recovery, the cache starts pre-warming as soon as the directory is created if I'm not mistaken.", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r464931011", "createdAt": "2020-08-04T09:44:06Z", "author": {"login": "fcofdez"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/indices/recovery/SearchableSnapshotRecoveryState.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.indices.recovery;\n+\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.common.Nullable;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+public final class SearchableSnapshotRecoveryState extends RecoveryState {\n+    private boolean preWarmFinished;\n+\n+    public SearchableSnapshotRecoveryState(ShardRouting shardRouting, DiscoveryNode targetNode, @Nullable DiscoveryNode sourceNode) {\n+        super(shardRouting, targetNode, sourceNode, new Index());\n+    }\n+\n+    @Override\n+    public synchronized RecoveryState setStage(Stage stage) {\n+        // The transition to the final state was done by #prewarmCompleted, just ignore the transition\n+        if (getStage() == Stage.DONE) {\n+            return this;\n+        }\n+\n+        // Pre-warm is still running, hold the state transition\n+        // until the pre-warm process finishes\n+        if (preWarmFinished == false && stage == Stage.DONE) {\n+            return this;\n+        }\n+\n+        return super.setStage(stage);\n+    }\n+\n+    public synchronized void preWarmFinished() {\n+        // For small shards it's possible that the\n+        // cache is pre-warmed before the stage has transitioned\n+        // to FINALIZE, so the transition to the final state is delayed until\n+        // the recovery process catches up.\n+        if (getStage() == Stage.FINALIZE) {\n+            super.setStage(Stage.DONE);\n+        }\n+\n+        SearchableSnapshotRecoveryState.Index index = (Index) getIndex();\n+        index.stopTimer();\n+        preWarmFinished = true;\n+    }\n+\n+    public synchronized void ignoreFile(String name) {\n+        SearchableSnapshotRecoveryState.Index index = (Index) getIndex();\n+        index.addFileToIgnore(name);\n+    }\n+\n+    private static final class Index extends RecoveryState.Index {\n+        // We ignore the files that won't be part of the pre-warming\n+        // phase since the information for those files won't be\n+        // updated and marking them as reused might be confusing,\n+        // as they are fetched on-demand from the underlying repository.\n+        private final Set<String> filesToIgnore = new HashSet<>();\n+\n+        private Index() {\n+            super(new SearchableSnapshotRecoveryFilesDetails());\n+            // We start loading data just at the beginning\n+            super.start();\n+        }\n+\n+        private synchronized void addFileToIgnore(String name) {\n+            filesToIgnore.add(name);\n+        }\n+\n+        @Override\n+        public synchronized void addFileDetail(String name, long length, boolean reused) {\n+            if (filesToIgnore.contains(name)) {\n+                return;\n+            }\n+\n+            super.addFileDetail(name, length, reused);\n+        }\n+\n+        // We have to bypass all the calls to the timer\n+        @Override\n+        public synchronized void start() {}\n+\n+        @Override\n+        public synchronized void stop() {}\n+\n+        @Override\n+        public synchronized void reset() {}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDkxOTI0Mg=="}, "originalCommit": {"oid": "b2989f667ca763500b9c6311ec03af81aeb2ef38"}, "originalPosition": 92}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwMzcxNDQ0OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/indices/recovery/SearchableSnapshotRecoveryState.java", "isResolved": false, "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQwOToyNjowM1rOG7YgVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMDo0NzozNVrOG8EQ2w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDkyMDY2MA==", "bodyText": "This means that the reused flag is not overridden, but based on what it was initially set?", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r464920660", "createdAt": "2020-08-04T09:26:03Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/indices/recovery/SearchableSnapshotRecoveryState.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.indices.recovery;\n+\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.common.Nullable;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+public final class SearchableSnapshotRecoveryState extends RecoveryState {\n+    private boolean preWarmFinished;\n+\n+    public SearchableSnapshotRecoveryState(ShardRouting shardRouting, DiscoveryNode targetNode, @Nullable DiscoveryNode sourceNode) {\n+        super(shardRouting, targetNode, sourceNode, new Index());\n+    }\n+\n+    @Override\n+    public synchronized RecoveryState setStage(Stage stage) {\n+        // The transition to the final state was done by #prewarmCompleted, just ignore the transition\n+        if (getStage() == Stage.DONE) {\n+            return this;\n+        }\n+\n+        // Pre-warm is still running, hold the state transition\n+        // until the pre-warm process finishes\n+        if (preWarmFinished == false && stage == Stage.DONE) {\n+            return this;\n+        }\n+\n+        return super.setStage(stage);\n+    }\n+\n+    public synchronized void preWarmFinished() {\n+        // For small shards it's possible that the\n+        // cache is pre-warmed before the stage has transitioned\n+        // to FINALIZE, so the transition to the final state is delayed until\n+        // the recovery process catches up.\n+        if (getStage() == Stage.FINALIZE) {\n+            super.setStage(Stage.DONE);\n+        }\n+\n+        SearchableSnapshotRecoveryState.Index index = (Index) getIndex();\n+        index.stopTimer();\n+        preWarmFinished = true;\n+    }\n+\n+    public synchronized void ignoreFile(String name) {\n+        SearchableSnapshotRecoveryState.Index index = (Index) getIndex();\n+        index.addFileToIgnore(name);\n+    }\n+\n+    private static final class Index extends RecoveryState.Index {\n+        // We ignore the files that won't be part of the pre-warming\n+        // phase since the information for those files won't be\n+        // updated and marking them as reused might be confusing,\n+        // as they are fetched on-demand from the underlying repository.\n+        private final Set<String> filesToIgnore = new HashSet<>();\n+\n+        private Index() {\n+            super(new SearchableSnapshotRecoveryFilesDetails());\n+            // We start loading data just at the beginning\n+            super.start();\n+        }\n+\n+        private synchronized void addFileToIgnore(String name) {\n+            filesToIgnore.add(name);\n+        }\n+\n+        @Override\n+        public synchronized void addFileDetail(String name, long length, boolean reused) {\n+            if (filesToIgnore.contains(name)) {\n+                return;\n+            }\n+\n+            super.addFileDetail(name, length, reused);\n+        }\n+\n+        // We have to bypass all the calls to the timer\n+        @Override\n+        public synchronized void start() {}\n+\n+        @Override\n+        public synchronized void stop() {}\n+\n+        @Override\n+        public synchronized void reset() {}\n+\n+        private synchronized void stopTimer() {\n+            super.stop();\n+        }\n+    }\n+\n+    private static class SearchableSnapshotRecoveryFilesDetails extends RecoveryFilesDetails {\n+        @Override\n+        public void addFileDetails(String name, long length, boolean reused) {\n+            // We allow reporting the same file details multiple times as we populate the file\n+            // details before the recovery is executed and therefore we ignore the rest\n+            // of the calls for the same files.\n+            fileDetails.computeIfAbsent(name, n -> new FileDetail(name, length, reused));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2989f667ca763500b9c6311ec03af81aeb2ef38"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDkzMDMwNg==", "bodyText": "That's correct.", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r464930306", "createdAt": "2020-08-04T09:42:50Z", "author": {"login": "fcofdez"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/indices/recovery/SearchableSnapshotRecoveryState.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.indices.recovery;\n+\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.common.Nullable;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+public final class SearchableSnapshotRecoveryState extends RecoveryState {\n+    private boolean preWarmFinished;\n+\n+    public SearchableSnapshotRecoveryState(ShardRouting shardRouting, DiscoveryNode targetNode, @Nullable DiscoveryNode sourceNode) {\n+        super(shardRouting, targetNode, sourceNode, new Index());\n+    }\n+\n+    @Override\n+    public synchronized RecoveryState setStage(Stage stage) {\n+        // The transition to the final state was done by #prewarmCompleted, just ignore the transition\n+        if (getStage() == Stage.DONE) {\n+            return this;\n+        }\n+\n+        // Pre-warm is still running, hold the state transition\n+        // until the pre-warm process finishes\n+        if (preWarmFinished == false && stage == Stage.DONE) {\n+            return this;\n+        }\n+\n+        return super.setStage(stage);\n+    }\n+\n+    public synchronized void preWarmFinished() {\n+        // For small shards it's possible that the\n+        // cache is pre-warmed before the stage has transitioned\n+        // to FINALIZE, so the transition to the final state is delayed until\n+        // the recovery process catches up.\n+        if (getStage() == Stage.FINALIZE) {\n+            super.setStage(Stage.DONE);\n+        }\n+\n+        SearchableSnapshotRecoveryState.Index index = (Index) getIndex();\n+        index.stopTimer();\n+        preWarmFinished = true;\n+    }\n+\n+    public synchronized void ignoreFile(String name) {\n+        SearchableSnapshotRecoveryState.Index index = (Index) getIndex();\n+        index.addFileToIgnore(name);\n+    }\n+\n+    private static final class Index extends RecoveryState.Index {\n+        // We ignore the files that won't be part of the pre-warming\n+        // phase since the information for those files won't be\n+        // updated and marking them as reused might be confusing,\n+        // as they are fetched on-demand from the underlying repository.\n+        private final Set<String> filesToIgnore = new HashSet<>();\n+\n+        private Index() {\n+            super(new SearchableSnapshotRecoveryFilesDetails());\n+            // We start loading data just at the beginning\n+            super.start();\n+        }\n+\n+        private synchronized void addFileToIgnore(String name) {\n+            filesToIgnore.add(name);\n+        }\n+\n+        @Override\n+        public synchronized void addFileDetail(String name, long length, boolean reused) {\n+            if (filesToIgnore.contains(name)) {\n+                return;\n+            }\n+\n+            super.addFileDetail(name, length, reused);\n+        }\n+\n+        // We have to bypass all the calls to the timer\n+        @Override\n+        public synchronized void start() {}\n+\n+        @Override\n+        public synchronized void stop() {}\n+\n+        @Override\n+        public synchronized void reset() {}\n+\n+        private synchronized void stopTimer() {\n+            super.stop();\n+        }\n+    }\n+\n+    private static class SearchableSnapshotRecoveryFilesDetails extends RecoveryFilesDetails {\n+        @Override\n+        public void addFileDetails(String name, long length, boolean reused) {\n+            // We allow reporting the same file details multiple times as we populate the file\n+            // details before the recovery is executed and therefore we ignore the rest\n+            // of the calls for the same files.\n+            fileDetails.computeIfAbsent(name, n -> new FileDetail(name, length, reused));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDkyMDY2MA=="}, "originalCommit": {"oid": "b2989f667ca763500b9c6311ec03af81aeb2ef38"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTU0OTM0MQ==", "bodyText": "This sounds wrong then, as we would have reused == true for all files (as we initially fake that all files are present), which is wrong as we can only reuse what we actually locally have.", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r465549341", "createdAt": "2020-08-05T08:07:51Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/indices/recovery/SearchableSnapshotRecoveryState.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.indices.recovery;\n+\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.common.Nullable;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+public final class SearchableSnapshotRecoveryState extends RecoveryState {\n+    private boolean preWarmFinished;\n+\n+    public SearchableSnapshotRecoveryState(ShardRouting shardRouting, DiscoveryNode targetNode, @Nullable DiscoveryNode sourceNode) {\n+        super(shardRouting, targetNode, sourceNode, new Index());\n+    }\n+\n+    @Override\n+    public synchronized RecoveryState setStage(Stage stage) {\n+        // The transition to the final state was done by #prewarmCompleted, just ignore the transition\n+        if (getStage() == Stage.DONE) {\n+            return this;\n+        }\n+\n+        // Pre-warm is still running, hold the state transition\n+        // until the pre-warm process finishes\n+        if (preWarmFinished == false && stage == Stage.DONE) {\n+            return this;\n+        }\n+\n+        return super.setStage(stage);\n+    }\n+\n+    public synchronized void preWarmFinished() {\n+        // For small shards it's possible that the\n+        // cache is pre-warmed before the stage has transitioned\n+        // to FINALIZE, so the transition to the final state is delayed until\n+        // the recovery process catches up.\n+        if (getStage() == Stage.FINALIZE) {\n+            super.setStage(Stage.DONE);\n+        }\n+\n+        SearchableSnapshotRecoveryState.Index index = (Index) getIndex();\n+        index.stopTimer();\n+        preWarmFinished = true;\n+    }\n+\n+    public synchronized void ignoreFile(String name) {\n+        SearchableSnapshotRecoveryState.Index index = (Index) getIndex();\n+        index.addFileToIgnore(name);\n+    }\n+\n+    private static final class Index extends RecoveryState.Index {\n+        // We ignore the files that won't be part of the pre-warming\n+        // phase since the information for those files won't be\n+        // updated and marking them as reused might be confusing,\n+        // as they are fetched on-demand from the underlying repository.\n+        private final Set<String> filesToIgnore = new HashSet<>();\n+\n+        private Index() {\n+            super(new SearchableSnapshotRecoveryFilesDetails());\n+            // We start loading data just at the beginning\n+            super.start();\n+        }\n+\n+        private synchronized void addFileToIgnore(String name) {\n+            filesToIgnore.add(name);\n+        }\n+\n+        @Override\n+        public synchronized void addFileDetail(String name, long length, boolean reused) {\n+            if (filesToIgnore.contains(name)) {\n+                return;\n+            }\n+\n+            super.addFileDetail(name, length, reused);\n+        }\n+\n+        // We have to bypass all the calls to the timer\n+        @Override\n+        public synchronized void start() {}\n+\n+        @Override\n+        public synchronized void stop() {}\n+\n+        @Override\n+        public synchronized void reset() {}\n+\n+        private synchronized void stopTimer() {\n+            super.stop();\n+        }\n+    }\n+\n+    private static class SearchableSnapshotRecoveryFilesDetails extends RecoveryFilesDetails {\n+        @Override\n+        public void addFileDetails(String name, long length, boolean reused) {\n+            // We allow reporting the same file details multiple times as we populate the file\n+            // details before the recovery is executed and therefore we ignore the rest\n+            // of the calls for the same files.\n+            fileDetails.computeIfAbsent(name, n -> new FileDetail(name, length, reused));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDkyMDY2MA=="}, "originalCommit": {"oid": "b2989f667ca763500b9c6311ec03af81aeb2ef38"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTU1Mjc0MQ==", "bodyText": "Those file details are populated first on SearchableSnapshotDirectory#prewarmCache, and that process is triggered before the recovery process starts. Meaning that they should contain the correct information.", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r465552741", "createdAt": "2020-08-05T08:14:04Z", "author": {"login": "fcofdez"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/indices/recovery/SearchableSnapshotRecoveryState.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.indices.recovery;\n+\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.common.Nullable;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+public final class SearchableSnapshotRecoveryState extends RecoveryState {\n+    private boolean preWarmFinished;\n+\n+    public SearchableSnapshotRecoveryState(ShardRouting shardRouting, DiscoveryNode targetNode, @Nullable DiscoveryNode sourceNode) {\n+        super(shardRouting, targetNode, sourceNode, new Index());\n+    }\n+\n+    @Override\n+    public synchronized RecoveryState setStage(Stage stage) {\n+        // The transition to the final state was done by #prewarmCompleted, just ignore the transition\n+        if (getStage() == Stage.DONE) {\n+            return this;\n+        }\n+\n+        // Pre-warm is still running, hold the state transition\n+        // until the pre-warm process finishes\n+        if (preWarmFinished == false && stage == Stage.DONE) {\n+            return this;\n+        }\n+\n+        return super.setStage(stage);\n+    }\n+\n+    public synchronized void preWarmFinished() {\n+        // For small shards it's possible that the\n+        // cache is pre-warmed before the stage has transitioned\n+        // to FINALIZE, so the transition to the final state is delayed until\n+        // the recovery process catches up.\n+        if (getStage() == Stage.FINALIZE) {\n+            super.setStage(Stage.DONE);\n+        }\n+\n+        SearchableSnapshotRecoveryState.Index index = (Index) getIndex();\n+        index.stopTimer();\n+        preWarmFinished = true;\n+    }\n+\n+    public synchronized void ignoreFile(String name) {\n+        SearchableSnapshotRecoveryState.Index index = (Index) getIndex();\n+        index.addFileToIgnore(name);\n+    }\n+\n+    private static final class Index extends RecoveryState.Index {\n+        // We ignore the files that won't be part of the pre-warming\n+        // phase since the information for those files won't be\n+        // updated and marking them as reused might be confusing,\n+        // as they are fetched on-demand from the underlying repository.\n+        private final Set<String> filesToIgnore = new HashSet<>();\n+\n+        private Index() {\n+            super(new SearchableSnapshotRecoveryFilesDetails());\n+            // We start loading data just at the beginning\n+            super.start();\n+        }\n+\n+        private synchronized void addFileToIgnore(String name) {\n+            filesToIgnore.add(name);\n+        }\n+\n+        @Override\n+        public synchronized void addFileDetail(String name, long length, boolean reused) {\n+            if (filesToIgnore.contains(name)) {\n+                return;\n+            }\n+\n+            super.addFileDetail(name, length, reused);\n+        }\n+\n+        // We have to bypass all the calls to the timer\n+        @Override\n+        public synchronized void start() {}\n+\n+        @Override\n+        public synchronized void stop() {}\n+\n+        @Override\n+        public synchronized void reset() {}\n+\n+        private synchronized void stopTimer() {\n+            super.stop();\n+        }\n+    }\n+\n+    private static class SearchableSnapshotRecoveryFilesDetails extends RecoveryFilesDetails {\n+        @Override\n+        public void addFileDetails(String name, long length, boolean reused) {\n+            // We allow reporting the same file details multiple times as we populate the file\n+            // details before the recovery is executed and therefore we ignore the rest\n+            // of the calls for the same files.\n+            fileDetails.computeIfAbsent(name, n -> new FileDetail(name, length, reused));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDkyMDY2MA=="}, "originalCommit": {"oid": "b2989f667ca763500b9c6311ec03af81aeb2ef38"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTU1NjgxOQ==", "bodyText": "Can we assert something to that effect?", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r465556819", "createdAt": "2020-08-05T08:21:13Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/indices/recovery/SearchableSnapshotRecoveryState.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.indices.recovery;\n+\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.common.Nullable;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+public final class SearchableSnapshotRecoveryState extends RecoveryState {\n+    private boolean preWarmFinished;\n+\n+    public SearchableSnapshotRecoveryState(ShardRouting shardRouting, DiscoveryNode targetNode, @Nullable DiscoveryNode sourceNode) {\n+        super(shardRouting, targetNode, sourceNode, new Index());\n+    }\n+\n+    @Override\n+    public synchronized RecoveryState setStage(Stage stage) {\n+        // The transition to the final state was done by #prewarmCompleted, just ignore the transition\n+        if (getStage() == Stage.DONE) {\n+            return this;\n+        }\n+\n+        // Pre-warm is still running, hold the state transition\n+        // until the pre-warm process finishes\n+        if (preWarmFinished == false && stage == Stage.DONE) {\n+            return this;\n+        }\n+\n+        return super.setStage(stage);\n+    }\n+\n+    public synchronized void preWarmFinished() {\n+        // For small shards it's possible that the\n+        // cache is pre-warmed before the stage has transitioned\n+        // to FINALIZE, so the transition to the final state is delayed until\n+        // the recovery process catches up.\n+        if (getStage() == Stage.FINALIZE) {\n+            super.setStage(Stage.DONE);\n+        }\n+\n+        SearchableSnapshotRecoveryState.Index index = (Index) getIndex();\n+        index.stopTimer();\n+        preWarmFinished = true;\n+    }\n+\n+    public synchronized void ignoreFile(String name) {\n+        SearchableSnapshotRecoveryState.Index index = (Index) getIndex();\n+        index.addFileToIgnore(name);\n+    }\n+\n+    private static final class Index extends RecoveryState.Index {\n+        // We ignore the files that won't be part of the pre-warming\n+        // phase since the information for those files won't be\n+        // updated and marking them as reused might be confusing,\n+        // as they are fetched on-demand from the underlying repository.\n+        private final Set<String> filesToIgnore = new HashSet<>();\n+\n+        private Index() {\n+            super(new SearchableSnapshotRecoveryFilesDetails());\n+            // We start loading data just at the beginning\n+            super.start();\n+        }\n+\n+        private synchronized void addFileToIgnore(String name) {\n+            filesToIgnore.add(name);\n+        }\n+\n+        @Override\n+        public synchronized void addFileDetail(String name, long length, boolean reused) {\n+            if (filesToIgnore.contains(name)) {\n+                return;\n+            }\n+\n+            super.addFileDetail(name, length, reused);\n+        }\n+\n+        // We have to bypass all the calls to the timer\n+        @Override\n+        public synchronized void start() {}\n+\n+        @Override\n+        public synchronized void stop() {}\n+\n+        @Override\n+        public synchronized void reset() {}\n+\n+        private synchronized void stopTimer() {\n+            super.stop();\n+        }\n+    }\n+\n+    private static class SearchableSnapshotRecoveryFilesDetails extends RecoveryFilesDetails {\n+        @Override\n+        public void addFileDetails(String name, long length, boolean reused) {\n+            // We allow reporting the same file details multiple times as we populate the file\n+            // details before the recovery is executed and therefore we ignore the rest\n+            // of the calls for the same files.\n+            fileDetails.computeIfAbsent(name, n -> new FileDetail(name, length, reused));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDkyMDY2MA=="}, "originalCommit": {"oid": "b2989f667ca763500b9c6311ec03af81aeb2ef38"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTU1OTk0Mg==", "bodyText": "I'm thinking that maybe the intent will be clearer if we set a flag after the information is populated in SearchableSnapshotDirectory#prewarmCache and we bypass the calls to this method once that flag is true, wdyt?", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r465559942", "createdAt": "2020-08-05T08:26:17Z", "author": {"login": "fcofdez"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/indices/recovery/SearchableSnapshotRecoveryState.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.indices.recovery;\n+\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.common.Nullable;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+public final class SearchableSnapshotRecoveryState extends RecoveryState {\n+    private boolean preWarmFinished;\n+\n+    public SearchableSnapshotRecoveryState(ShardRouting shardRouting, DiscoveryNode targetNode, @Nullable DiscoveryNode sourceNode) {\n+        super(shardRouting, targetNode, sourceNode, new Index());\n+    }\n+\n+    @Override\n+    public synchronized RecoveryState setStage(Stage stage) {\n+        // The transition to the final state was done by #prewarmCompleted, just ignore the transition\n+        if (getStage() == Stage.DONE) {\n+            return this;\n+        }\n+\n+        // Pre-warm is still running, hold the state transition\n+        // until the pre-warm process finishes\n+        if (preWarmFinished == false && stage == Stage.DONE) {\n+            return this;\n+        }\n+\n+        return super.setStage(stage);\n+    }\n+\n+    public synchronized void preWarmFinished() {\n+        // For small shards it's possible that the\n+        // cache is pre-warmed before the stage has transitioned\n+        // to FINALIZE, so the transition to the final state is delayed until\n+        // the recovery process catches up.\n+        if (getStage() == Stage.FINALIZE) {\n+            super.setStage(Stage.DONE);\n+        }\n+\n+        SearchableSnapshotRecoveryState.Index index = (Index) getIndex();\n+        index.stopTimer();\n+        preWarmFinished = true;\n+    }\n+\n+    public synchronized void ignoreFile(String name) {\n+        SearchableSnapshotRecoveryState.Index index = (Index) getIndex();\n+        index.addFileToIgnore(name);\n+    }\n+\n+    private static final class Index extends RecoveryState.Index {\n+        // We ignore the files that won't be part of the pre-warming\n+        // phase since the information for those files won't be\n+        // updated and marking them as reused might be confusing,\n+        // as they are fetched on-demand from the underlying repository.\n+        private final Set<String> filesToIgnore = new HashSet<>();\n+\n+        private Index() {\n+            super(new SearchableSnapshotRecoveryFilesDetails());\n+            // We start loading data just at the beginning\n+            super.start();\n+        }\n+\n+        private synchronized void addFileToIgnore(String name) {\n+            filesToIgnore.add(name);\n+        }\n+\n+        @Override\n+        public synchronized void addFileDetail(String name, long length, boolean reused) {\n+            if (filesToIgnore.contains(name)) {\n+                return;\n+            }\n+\n+            super.addFileDetail(name, length, reused);\n+        }\n+\n+        // We have to bypass all the calls to the timer\n+        @Override\n+        public synchronized void start() {}\n+\n+        @Override\n+        public synchronized void stop() {}\n+\n+        @Override\n+        public synchronized void reset() {}\n+\n+        private synchronized void stopTimer() {\n+            super.stop();\n+        }\n+    }\n+\n+    private static class SearchableSnapshotRecoveryFilesDetails extends RecoveryFilesDetails {\n+        @Override\n+        public void addFileDetails(String name, long length, boolean reused) {\n+            // We allow reporting the same file details multiple times as we populate the file\n+            // details before the recovery is executed and therefore we ignore the rest\n+            // of the calls for the same files.\n+            fileDetails.computeIfAbsent(name, n -> new FileDetail(name, length, reused));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDkyMDY2MA=="}, "originalCommit": {"oid": "b2989f667ca763500b9c6311ec03af81aeb2ef38"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTU2NTc1Mg==", "bodyText": "yes", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r465565752", "createdAt": "2020-08-05T08:36:19Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/indices/recovery/SearchableSnapshotRecoveryState.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.indices.recovery;\n+\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.common.Nullable;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+public final class SearchableSnapshotRecoveryState extends RecoveryState {\n+    private boolean preWarmFinished;\n+\n+    public SearchableSnapshotRecoveryState(ShardRouting shardRouting, DiscoveryNode targetNode, @Nullable DiscoveryNode sourceNode) {\n+        super(shardRouting, targetNode, sourceNode, new Index());\n+    }\n+\n+    @Override\n+    public synchronized RecoveryState setStage(Stage stage) {\n+        // The transition to the final state was done by #prewarmCompleted, just ignore the transition\n+        if (getStage() == Stage.DONE) {\n+            return this;\n+        }\n+\n+        // Pre-warm is still running, hold the state transition\n+        // until the pre-warm process finishes\n+        if (preWarmFinished == false && stage == Stage.DONE) {\n+            return this;\n+        }\n+\n+        return super.setStage(stage);\n+    }\n+\n+    public synchronized void preWarmFinished() {\n+        // For small shards it's possible that the\n+        // cache is pre-warmed before the stage has transitioned\n+        // to FINALIZE, so the transition to the final state is delayed until\n+        // the recovery process catches up.\n+        if (getStage() == Stage.FINALIZE) {\n+            super.setStage(Stage.DONE);\n+        }\n+\n+        SearchableSnapshotRecoveryState.Index index = (Index) getIndex();\n+        index.stopTimer();\n+        preWarmFinished = true;\n+    }\n+\n+    public synchronized void ignoreFile(String name) {\n+        SearchableSnapshotRecoveryState.Index index = (Index) getIndex();\n+        index.addFileToIgnore(name);\n+    }\n+\n+    private static final class Index extends RecoveryState.Index {\n+        // We ignore the files that won't be part of the pre-warming\n+        // phase since the information for those files won't be\n+        // updated and marking them as reused might be confusing,\n+        // as they are fetched on-demand from the underlying repository.\n+        private final Set<String> filesToIgnore = new HashSet<>();\n+\n+        private Index() {\n+            super(new SearchableSnapshotRecoveryFilesDetails());\n+            // We start loading data just at the beginning\n+            super.start();\n+        }\n+\n+        private synchronized void addFileToIgnore(String name) {\n+            filesToIgnore.add(name);\n+        }\n+\n+        @Override\n+        public synchronized void addFileDetail(String name, long length, boolean reused) {\n+            if (filesToIgnore.contains(name)) {\n+                return;\n+            }\n+\n+            super.addFileDetail(name, length, reused);\n+        }\n+\n+        // We have to bypass all the calls to the timer\n+        @Override\n+        public synchronized void start() {}\n+\n+        @Override\n+        public synchronized void stop() {}\n+\n+        @Override\n+        public synchronized void reset() {}\n+\n+        private synchronized void stopTimer() {\n+            super.stop();\n+        }\n+    }\n+\n+    private static class SearchableSnapshotRecoveryFilesDetails extends RecoveryFilesDetails {\n+        @Override\n+        public void addFileDetails(String name, long length, boolean reused) {\n+            // We allow reporting the same file details multiple times as we populate the file\n+            // details before the recovery is executed and therefore we ignore the rest\n+            // of the calls for the same files.\n+            fileDetails.computeIfAbsent(name, n -> new FileDetail(name, length, reused));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDkyMDY2MA=="}, "originalCommit": {"oid": "b2989f667ca763500b9c6311ec03af81aeb2ef38"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTYzNzU5NQ==", "bodyText": "Finally I've kept the same approach as it's possible that during peer recoveries an additional segments_n file is sent over as after restore the index is marked with a new history uuid generating a new segments_ file that's unknown to the target peer. So I've added a stronger assertion to ensure that if the file was already added it has the same length.", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r465637595", "createdAt": "2020-08-05T10:47:35Z", "author": {"login": "fcofdez"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/indices/recovery/SearchableSnapshotRecoveryState.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.indices.recovery;\n+\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.common.Nullable;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+public final class SearchableSnapshotRecoveryState extends RecoveryState {\n+    private boolean preWarmFinished;\n+\n+    public SearchableSnapshotRecoveryState(ShardRouting shardRouting, DiscoveryNode targetNode, @Nullable DiscoveryNode sourceNode) {\n+        super(shardRouting, targetNode, sourceNode, new Index());\n+    }\n+\n+    @Override\n+    public synchronized RecoveryState setStage(Stage stage) {\n+        // The transition to the final state was done by #prewarmCompleted, just ignore the transition\n+        if (getStage() == Stage.DONE) {\n+            return this;\n+        }\n+\n+        // Pre-warm is still running, hold the state transition\n+        // until the pre-warm process finishes\n+        if (preWarmFinished == false && stage == Stage.DONE) {\n+            return this;\n+        }\n+\n+        return super.setStage(stage);\n+    }\n+\n+    public synchronized void preWarmFinished() {\n+        // For small shards it's possible that the\n+        // cache is pre-warmed before the stage has transitioned\n+        // to FINALIZE, so the transition to the final state is delayed until\n+        // the recovery process catches up.\n+        if (getStage() == Stage.FINALIZE) {\n+            super.setStage(Stage.DONE);\n+        }\n+\n+        SearchableSnapshotRecoveryState.Index index = (Index) getIndex();\n+        index.stopTimer();\n+        preWarmFinished = true;\n+    }\n+\n+    public synchronized void ignoreFile(String name) {\n+        SearchableSnapshotRecoveryState.Index index = (Index) getIndex();\n+        index.addFileToIgnore(name);\n+    }\n+\n+    private static final class Index extends RecoveryState.Index {\n+        // We ignore the files that won't be part of the pre-warming\n+        // phase since the information for those files won't be\n+        // updated and marking them as reused might be confusing,\n+        // as they are fetched on-demand from the underlying repository.\n+        private final Set<String> filesToIgnore = new HashSet<>();\n+\n+        private Index() {\n+            super(new SearchableSnapshotRecoveryFilesDetails());\n+            // We start loading data just at the beginning\n+            super.start();\n+        }\n+\n+        private synchronized void addFileToIgnore(String name) {\n+            filesToIgnore.add(name);\n+        }\n+\n+        @Override\n+        public synchronized void addFileDetail(String name, long length, boolean reused) {\n+            if (filesToIgnore.contains(name)) {\n+                return;\n+            }\n+\n+            super.addFileDetail(name, length, reused);\n+        }\n+\n+        // We have to bypass all the calls to the timer\n+        @Override\n+        public synchronized void start() {}\n+\n+        @Override\n+        public synchronized void stop() {}\n+\n+        @Override\n+        public synchronized void reset() {}\n+\n+        private synchronized void stopTimer() {\n+            super.stop();\n+        }\n+    }\n+\n+    private static class SearchableSnapshotRecoveryFilesDetails extends RecoveryFilesDetails {\n+        @Override\n+        public void addFileDetails(String name, long length, boolean reused) {\n+            // We allow reporting the same file details multiple times as we populate the file\n+            // details before the recovery is executed and therefore we ignore the rest\n+            // of the calls for the same files.\n+            fileDetails.computeIfAbsent(name, n -> new FileDetail(name, length, reused));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDkyMDY2MA=="}, "originalCommit": {"oid": "b2989f667ca763500b9c6311ec03af81aeb2ef38"}, "originalPosition": 105}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwMzcyMDg3OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/SearchableSnapshotDirectoryTests.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQwOToyNzo1OFrOG7Yklg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQwOToyNzo1OFrOG7Yklg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDkyMTc1MA==", "bodyText": "simpler to just assertFalse(fileHasExcludedType)", "url": "https://github.com/elastic/elasticsearch/pull/60505#discussion_r464921750", "createdAt": "2020-08-04T09:27:58Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/SearchableSnapshotDirectoryTests.java", "diffHunk": "@@ -736,6 +765,79 @@ public void testRequiresAdditionalSettings() {\n         }\n     }\n \n+    public void testRecoveryStateIsKeptOpenAfterPreWarmFailures() throws Exception {\n+        FileSystem fileSystem = PathUtils.getDefaultFileSystem();\n+        FaultyReadsFileSystem disruptFileSystemProvider = new FaultyReadsFileSystem(fileSystem);\n+        fileSystem = disruptFileSystemProvider.getFileSystem(null);\n+        PathUtilsForTesting.installMock(fileSystem);\n+\n+        try {\n+            SearchableSnapshotRecoveryState recoveryState = createRecoveryState();\n+            testDirectories(true, true, recoveryState, Settings.EMPTY, (directory, snapshotDirectory) -> {\n+                ThreadPoolExecutor executor = (ThreadPoolExecutor) snapshotDirectory.cacheFetchAsyncExecutor();\n+                assertBusy(() -> {\n+                    assertThat(executor.getActiveCount(), equalTo(0));\n+                    assertThat(executor.getQueue().size(), equalTo(0));\n+                });\n+\n+                assertThat(recoveryState.getStage(), equalTo(RecoveryState.Stage.FINALIZE));\n+                // All pre-warm tasks failed\n+                assertThat(recoveryState.getIndex().recoveredBytes(), equalTo(0L));\n+            });\n+        } finally {\n+            PathUtilsForTesting.teardown();\n+        }\n+    }\n+\n+    public void testRecoveryStateIsEmptyWhenTheCacheIsNotPreWarmed() throws Exception {\n+        SearchableSnapshotRecoveryState recoveryState = createRecoveryState();\n+        testDirectories(true, false, recoveryState, Settings.EMPTY, (directory, snapshotDirectory) -> {\n+            assertThat(recoveryState.getStage(), equalTo(RecoveryState.Stage.DONE));\n+            assertThat(recoveryState.getIndex().recoveredBytes(), equalTo(0L));\n+            assertThat(recoveryState.getIndex().totalRecoverFiles(), equalTo(0));\n+        });\n+    }\n+\n+    public void testNonCachedFilesAreExcludedFromRecoveryState() throws Exception {\n+        SearchableSnapshotRecoveryState recoveryState = createRecoveryState();\n+\n+        List<String> allFileExtensions = List.of(\n+            \"fdt\",\n+            \"fdx\",\n+            \"nvd\",\n+            \"dvd\",\n+            \"tip\",\n+            \"cfs\",\n+            \"dim\",\n+            \"fnm\",\n+            \"dvm\",\n+            \"tmd\",\n+            \"doc\",\n+            \"tim\",\n+            \"pos\",\n+            \"cfe\",\n+            \"fdm\",\n+            \"nvm\"\n+        );\n+        List<String> fileTypesExcludedFromCaching = randomSubsetOf(allFileExtensions);\n+        Settings settings = Settings.builder()\n+            .putList(SNAPSHOT_CACHE_EXCLUDED_FILE_TYPES_SETTING.getKey(), fileTypesExcludedFromCaching)\n+            .build();\n+        testDirectories(true, true, recoveryState, settings, (directory, snapshotDirectory) -> {\n+            ThreadPoolExecutor executor = (ThreadPoolExecutor) snapshotDirectory.prewarmExecutor();\n+            assertBusy(() -> {\n+                assertThat(executor.getActiveCount(), equalTo(0));\n+                assertThat(executor.getQueue().size(), equalTo(0));\n+            });\n+\n+            assertThat(recoveryState.getStage(), equalTo(RecoveryState.Stage.DONE));\n+            for (RecoveryState.FileDetail fileDetail : recoveryState.getIndex().fileDetails()) {\n+                boolean fileHasExcludedType = fileTypesExcludedFromCaching.stream().anyMatch(type -> fileDetail.name().endsWith(type));\n+                assertThat(fileHasExcludedType, equalTo(false));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2989f667ca763500b9c6311ec03af81aeb2ef38"}, "originalPosition": 185}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2668, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}