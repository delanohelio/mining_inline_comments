{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM4MzY2MzQ1", "number": 58405, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwNzowOTowOFrOEH1z1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwNzowOTozNVrOEH10VQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NjU3MTA5OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/cluster/coordination/PublicationTransportHandler.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwNzowOTowOFrOGncDbg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwNzowOTowOFrOGncDbg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDAwNzI3OA==", "bodyText": "Reworded comment", "url": "https://github.com/elastic/elasticsearch/pull/58405#discussion_r444007278", "createdAt": "2020-06-23T07:09:08Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/cluster/coordination/PublicationTransportHandler.java", "diffHunk": "@@ -406,4 +198,216 @@ private PublishWithJoinResponse acceptState(ClusterState incomingState) {\n         }\n         return handlePublishRequest.apply(new PublishRequest(incomingState));\n     }\n+\n+    public PublicationContext newPublicationContext(ClusterChangedEvent clusterChangedEvent) {\n+        final PublicationContext publicationContext = new PublicationContext(clusterChangedEvent);\n+\n+        // Build the serializations we expect to need now, early in the process, so that an error during serialization fails the publication\n+        // straight away. This isn't watertight since we send diffs on a best-effort basis and may fall back to sending a full state (and\n+        // therefore serializing it) if the diff-based publication fails.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2f33afbebe7bb774afbca40cc91485d15ca9197f"}, "originalPosition": 225}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NjU3MjA1OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/cluster/coordination/PublicationTransportHandler.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwNzowOToyNlrOGncEBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwNzowOToyNlrOGncEBA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDAwNzQyOA==", "bodyText": "Added a TRACE log to record the size of the state here.", "url": "https://github.com/elastic/elasticsearch/pull/58405#discussion_r444007428", "createdAt": "2020-06-23T07:09:26Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/cluster/coordination/PublicationTransportHandler.java", "diffHunk": "@@ -406,4 +198,216 @@ private PublishWithJoinResponse acceptState(ClusterState incomingState) {\n         }\n         return handlePublishRequest.apply(new PublishRequest(incomingState));\n     }\n+\n+    public PublicationContext newPublicationContext(ClusterChangedEvent clusterChangedEvent) {\n+        final PublicationContext publicationContext = new PublicationContext(clusterChangedEvent);\n+\n+        // Build the serializations we expect to need now, early in the process, so that an error during serialization fails the publication\n+        // straight away. This isn't watertight since we send diffs on a best-effort basis and may fall back to sending a full state (and\n+        // therefore serializing it) if the diff-based publication fails.\n+        publicationContext.buildDiffAndSerializeStates();\n+        return publicationContext;\n+    }\n+\n+    private static BytesReference serializeFullClusterState(ClusterState clusterState, Version nodeVersion) throws IOException {\n+        final BytesStreamOutput bStream = new BytesStreamOutput();\n+        try (StreamOutput stream = CompressorFactory.COMPRESSOR.streamOutput(bStream)) {\n+            stream.setVersion(nodeVersion);\n+            stream.writeBoolean(true);\n+            clusterState.writeTo(stream);\n+        }\n+        final BytesReference serializedState = bStream.bytes();\n+        logger.trace(\"serialized full cluster state version [{}] for node version [{}] with size [{}]\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2f33afbebe7bb774afbca40cc91485d15ca9197f"}, "originalPosition": 238}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NjU3MjM3OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/cluster/coordination/PublicationTransportHandler.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwNzowOTozNVrOGncEPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwNzowOTozNVrOGncEPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDAwNzQ4NQ==", "bodyText": "Added a TRACE log to record the size of the state here.", "url": "https://github.com/elastic/elasticsearch/pull/58405#discussion_r444007485", "createdAt": "2020-06-23T07:09:35Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/cluster/coordination/PublicationTransportHandler.java", "diffHunk": "@@ -406,4 +198,216 @@ private PublishWithJoinResponse acceptState(ClusterState incomingState) {\n         }\n         return handlePublishRequest.apply(new PublishRequest(incomingState));\n     }\n+\n+    public PublicationContext newPublicationContext(ClusterChangedEvent clusterChangedEvent) {\n+        final PublicationContext publicationContext = new PublicationContext(clusterChangedEvent);\n+\n+        // Build the serializations we expect to need now, early in the process, so that an error during serialization fails the publication\n+        // straight away. This isn't watertight since we send diffs on a best-effort basis and may fall back to sending a full state (and\n+        // therefore serializing it) if the diff-based publication fails.\n+        publicationContext.buildDiffAndSerializeStates();\n+        return publicationContext;\n+    }\n+\n+    private static BytesReference serializeFullClusterState(ClusterState clusterState, Version nodeVersion) throws IOException {\n+        final BytesStreamOutput bStream = new BytesStreamOutput();\n+        try (StreamOutput stream = CompressorFactory.COMPRESSOR.streamOutput(bStream)) {\n+            stream.setVersion(nodeVersion);\n+            stream.writeBoolean(true);\n+            clusterState.writeTo(stream);\n+        }\n+        final BytesReference serializedState = bStream.bytes();\n+        logger.trace(\"serialized full cluster state version [{}] for node version [{}] with size [{}]\",\n+            clusterState.version(), nodeVersion, serializedState.length());\n+        return serializedState;\n+    }\n+\n+    private static BytesReference serializeDiffClusterState(Diff<ClusterState> diff, Version nodeVersion) throws IOException {\n+        final BytesStreamOutput bStream = new BytesStreamOutput();\n+        try (StreamOutput stream = CompressorFactory.COMPRESSOR.streamOutput(bStream)) {\n+            stream.setVersion(nodeVersion);\n+            stream.writeBoolean(false);\n+            diff.writeTo(stream);\n+        }\n+        return bStream.bytes();\n+    }\n+\n+    /**\n+     * Publishing a cluster state typically involves sending the same cluster state (or diff) to every node, so the work of diffing,\n+     * serializing, and compressing the state can be done once and the results shared across publish requests. The\n+     * {@code PublicationContext} implements this sharing.\n+     */\n+    public class PublicationContext {\n+\n+        private final DiscoveryNodes discoveryNodes;\n+        private final ClusterState newState;\n+        private final ClusterState previousState;\n+        private final boolean sendFullVersion;\n+        private final Map<Version, BytesReference> serializedStates = new HashMap<>();\n+        private final Map<Version, BytesReference> serializedDiffs = new HashMap<>();\n+\n+        PublicationContext(ClusterChangedEvent clusterChangedEvent) {\n+            discoveryNodes = clusterChangedEvent.state().nodes();\n+            newState = clusterChangedEvent.state();\n+            previousState = clusterChangedEvent.previousState();\n+            sendFullVersion = previousState.getBlocks().disableStatePersistence();\n+        }\n+\n+        void buildDiffAndSerializeStates() {\n+            Diff<ClusterState> diff = null;\n+            for (DiscoveryNode node : discoveryNodes) {\n+                try {\n+                    if (sendFullVersion || previousState.nodes().nodeExists(node) == false) {\n+                        if (serializedStates.containsKey(node.getVersion()) == false) {\n+                            serializedStates.put(node.getVersion(), serializeFullClusterState(newState, node.getVersion()));\n+                        }\n+                    } else {\n+                        // will send a diff\n+                        if (diff == null) {\n+                            diff = newState.diff(previousState);\n+                        }\n+                        if (serializedDiffs.containsKey(node.getVersion()) == false) {\n+                            final BytesReference serializedDiff = serializeDiffClusterState(diff, node.getVersion());\n+                            serializedDiffs.put(node.getVersion(), serializedDiff);\n+                            logger.trace(\"serialized cluster state diff for version [{}] in for node version [{}] with size [{}]\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2f33afbebe7bb774afbca40cc91485d15ca9197f"}, "originalPosition": 290}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1363, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}