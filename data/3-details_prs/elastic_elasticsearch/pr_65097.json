{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTIxODE0MTUw", "number": 65097, "title": "Skip range optimization if it'd be slower", "bodyText": "Don't run the date_histogram and range aggregations as a filters\naggregation if the cost of the filters is high. This should prevent\nthe optimization from de-optimizing when it bumps into runtime fields\nwhich don't have index structures to speed their queries. For runtime\nfields we're better off running date_histogram and range using the\nnative range aggregator. We detect this situation using cost on\nthe BulkScorer from the queries to keep the change general. So it'll\ndetect other sorts of queries that might be a poor choice for\noptimization.", "createdAt": "2020-11-16T17:23:53Z", "url": "https://github.com/elastic/elasticsearch/pull/65097", "merged": true, "mergeCommit": {"oid": "91cbb9d330289252f6ca63ed5bb502462651a7ed"}, "closed": true, "closedAt": "2020-11-25T21:20:29Z", "author": {"login": "nik9000"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdb2m9UgH2gAyNTIxODE0MTUwOjU3ZDc5NmMxOWRlNmRlNWMwYjU0ZjYzMzI2N2EwMzc3MjQ0NTM0YmQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdeE6_YgFqTUzNDU5MTY2Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "57d796c19de6de5c0b54f633267a0377244534bd", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/57d796c19de6de5c0b54f633267a0377244534bd", "committedDate": "2020-11-12T18:10:37Z", "message": "WIP"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bdf6bde304a1085e1e4a179068869ce26eae438e", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/bdf6bde304a1085e1e4a179068869ce26eae438e", "committedDate": "2020-11-12T18:18:11Z", "message": "Merge branch 'master' into skip_optimization_if_pricey"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e8b0f61428adebcde7352d4570fb29efe5ba65fb", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/e8b0f61428adebcde7352d4570fb29efe5ba65fb", "committedDate": "2020-11-12T22:37:42Z", "message": "Emite estimated cost"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "302d3165647592a4bf2aa634c5da16f77316e0aa", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/302d3165647592a4bf2aa634c5da16f77316e0aa", "committedDate": "2020-11-16T13:51:24Z", "message": "Cache scorers"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1a9e915a2251e88142b5645f70ef1b8b842dd749", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/1a9e915a2251e88142b5645f70ef1b8b842dd749", "committedDate": "2020-11-16T17:09:08Z", "message": "TEst"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9fe8d5204cc38bbeea6f3d661ba54895aa88c9ce", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/9fe8d5204cc38bbeea6f3d661ba54895aa88c9ce", "committedDate": "2020-11-16T17:18:57Z", "message": "Guard debug capture"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0NTkxNjYy", "url": "https://github.com/elastic/elasticsearch/pull/65097#pullrequestreview-534591662", "createdAt": "2020-11-19T15:55:14Z", "commit": {"oid": "9fe8d5204cc38bbeea6f3d661ba54895aa88c9ce"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxNTo1NToxNFrOH2laqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxNTo1NToxNFrOH2laqA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjk5ODE4NA==", "bodyText": "Any reason not to just early terminate the loop if we've hit the limit?", "url": "https://github.com/elastic/elasticsearch/pull/65097#discussion_r526998184", "createdAt": "2020-11-19T15:55:14Z", "author": {"login": "not-napoleon"}, "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/filter/FiltersAggregator.java", "diffHunk": "@@ -286,6 +299,57 @@ public InternalAggregation buildEmptyAggregation() {\n         ) throws IOException {\n             super(name, AggregatorFactories.EMPTY, keys, keyed, null, context, parent, cardinality, metadata);\n             this.filters = filters;\n+            this.profiling = context.getProfilers() != null;\n+        }\n+\n+        /**\n+         * Estimate the number of documents that this aggregation must visit. We'll\n+         * stop counting once we've passed {@code maxEstimatedCost} if we aren't profiling.\n+         */\n+        public long estimateCost(long maxCost) throws IOException {\n+            this.maxCost = maxCost;\n+            if (estimatedCost != -1) {\n+                return estimatedCost;\n+            }\n+            long limit = profiling ? Long.MAX_VALUE : maxCost;\n+            long start = profiling ? System.nanoTime() : 0;\n+            estimatedCost = 0;\n+            weights = buildWeights(topLevelQuery(), filters);\n+            List<LeafReaderContext> leaves = searcher().getIndexReader().leaves();\n+            /*\n+             * Its important that we save a copy of the BulkScorer because for\n+             * queries like PointInRangeQuery building the scorer can be a big\n+             * chunk of the run time.\n+             */\n+            scorers = new BulkScorer[leaves.size()][];\n+            for (LeafReaderContext ctx : leaves) {\n+                scorers[ctx.ord] = new BulkScorer[filters.length];\n+                for (int f = 0; f < filters.length; f++) {\n+                    scorers[ctx.ord][f] = weights[f].bulkScorer(ctx);\n+                    if (scorers[ctx.ord][f] == null) {\n+                        // Doesn't find anything in this leaf\n+                        continue;\n+                    }\n+                    if (estimatedCost >= 0 && estimatedCost <= limit) {\n+                        // If we've overflowed or are past the limit skip the cost\n+                        estimatedCost += scorers[ctx.ord][f].cost();\n+                    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9fe8d5204cc38bbeea6f3d661ba54895aa88c9ce"}, "originalPosition": 76}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 939, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}