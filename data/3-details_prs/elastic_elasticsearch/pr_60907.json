{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY1NTQ1ODg0", "number": 60907, "title": "Merge FetchSubPhase hitsExecute and hitExecute methods", "bodyText": "FetchSubPhase has two 'execute' methods, one which takes all hits to be examined,\nand one which takes a single HitContext.  It's not obvious which one should be implemented\nby a given sub-phase, or if implementing both is a possibility; nor is it obvious that we first\nrun the hitExecute methods of all subphases, and then subsequently call all the\nhitsExecute methods.\nThis PR removes hitExecute entirely, and changes the signature of hitsExecute to take\nan array of HitContext objects, instead of an array of SearchHit.  A convenience method\nis added to simply execute the previous hitExecute method against each hit context in\nturn.  HitContext's fields are now final.", "createdAt": "2020-08-10T14:43:59Z", "url": "https://github.com/elastic/elasticsearch/pull/60907", "merged": true, "mergeCommit": {"oid": "e6b62930db612202d15dd58d008a03801e638752"}, "closed": true, "closedAt": "2020-09-03T09:21:40Z", "author": {"login": "romseygeek"}, "timelineItems": {"totalCount": 29, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc9jMPzgH2gAyNDY1NTQ1ODg0OmI3NTU3YjVhMTRiN2M5MjAzZTRiZmUxYTViZDg0YTk3ZmUzYjk0NTc=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdFMOKNgH2gAyNDY1NTQ1ODg0Ojg5N2U3OGIxYzQyNTQwZDgzZmQ3YmI4NTIyNmFmNDZlYTk2NjAyOTU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "b7557b5a14b7c9203e4bfe1a5bd84a97fe3b9457", "author": {"user": {"login": "romseygeek", "name": "Alan Woodward"}}, "url": "https://github.com/elastic/elasticsearch/commit/b7557b5a14b7c9203e4bfe1a5bd84a97fe3b9457", "committedDate": "2020-08-10T14:35:31Z", "message": "Merge FetchSubPhase hitsExecute and hitExecute methods"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "72a1cd70bffbf8bd12e57a5aa92af2486ae0d94e", "author": {"user": {"login": "romseygeek", "name": "Alan Woodward"}}, "url": "https://github.com/elastic/elasticsearch/commit/72a1cd70bffbf8bd12e57a5aa92af2486ae0d94e", "committedDate": "2020-08-10T21:06:38Z", "message": "Merge remote-tracking branch 'origin/master' into fetch/hitexecute"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "220724300e534d77094978fe402d0290f90104be", "author": {"user": {"login": "romseygeek", "name": "Alan Woodward"}}, "url": "https://github.com/elastic/elasticsearch/commit/220724300e534d77094978fe402d0290f90104be", "committedDate": "2020-08-11T14:49:44Z", "message": "WIP: percolator needs work to compile"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "22edcdcc2f0604cee27a30de8f2eaaddd0ed47e1", "author": {"user": {"login": "romseygeek", "name": "Alan Woodward"}}, "url": "https://github.com/elastic/elasticsearch/commit/22edcdcc2f0604cee27a30de8f2eaaddd0ed47e1", "committedDate": "2020-08-12T11:08:03Z", "message": "still some compilation failures in percolator tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "43d93d7a3c9ecd9db82995c189b08759b2cf7778", "author": {"user": {"login": "romseygeek", "name": "Alan Woodward"}}, "url": "https://github.com/elastic/elasticsearch/commit/43d93d7a3c9ecd9db82995c189b08759b2cf7778", "committedDate": "2020-08-17T08:45:54Z", "message": "Merge remote-tracking branch 'origin/master' into fetch/hitexecute"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "06495cf076e0d1705410b48bf769a776be3b7620", "author": {"user": {"login": "romseygeek", "name": "Alan Woodward"}}, "url": "https://github.com/elastic/elasticsearch/commit/06495cf076e0d1705410b48bf769a776be3b7620", "committedDate": "2020-08-17T15:04:04Z", "message": "fix percolator"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8ced182b104367084fcef7a1846a0734f0cabc0d", "author": {"user": {"login": "romseygeek", "name": "Alan Woodward"}}, "url": "https://github.com/elastic/elasticsearch/commit/8ced182b104367084fcef7a1846a0734f0cabc0d", "committedDate": "2020-08-17T15:26:41Z", "message": "checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5b913ef5768877a0a08d64c72008bb48c01e11d5", "author": {"user": {"login": "romseygeek", "name": "Alan Woodward"}}, "url": "https://github.com/elastic/elasticsearch/commit/5b913ef5768877a0a08d64c72008bb48c01e11d5", "committedDate": "2020-08-17T15:33:15Z", "message": "checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "da36dfc2b6ac38b46abe58da898db87fd21ecece", "author": {"user": {"login": "romseygeek", "name": "Alan Woodward"}}, "url": "https://github.com/elastic/elasticsearch/commit/da36dfc2b6ac38b46abe58da898db87fd21ecece", "committedDate": "2020-08-19T15:04:26Z", "message": "javadocs; use unrewritten query in highlight"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4f574db14f528b8287dddc95762ecf2b815267be", "author": {"user": {"login": "romseygeek", "name": "Alan Woodward"}}, "url": "https://github.com/elastic/elasticsearch/commit/4f574db14f528b8287dddc95762ecf2b815267be", "committedDate": "2020-08-19T15:20:26Z", "message": "Merge remote-tracking branch 'origin/master' into fetch/hitexecute"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcxMDIwMDYz", "url": "https://github.com/elastic/elasticsearch/pull/60907#pullrequestreview-471020063", "createdAt": "2020-08-19T22:58:47Z", "commit": {"oid": "4f574db14f528b8287dddc95762ecf2b815267be"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQyMjo1ODo0N1rOHDerhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQwMDozMzoxMlrOHDipFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQxMDQzNw==", "bodyText": "Just a personal preference, but I don't think this class FetchPhaseExecutor adds much in terms of clarity + modularity. We could easily inline these loops in FetchPhase#execute.", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r473410437", "createdAt": "2020-08-19T22:58:47Z", "author": {"login": "jtibshirani"}, "path": "server/src/main/java/org/elasticsearch/search/fetch/FetchPhaseExecutor.java", "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.search.fetch;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.elasticsearch.search.internal.SearchContext;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+public class FetchPhaseExecutor {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f574db14f528b8287dddc95762ecf2b815267be"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQxODYyNw==", "bodyText": "Small comment, it would be nice move the root doc lookup into this method too:\n      int rootDocId = findRootDocumentIfNested(context, readerContext, subDocId);", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r473418627", "createdAt": "2020-08-19T23:10:11Z", "author": {"login": "jtibshirani"}, "path": "server/src/main/java/org/elasticsearch/search/fetch/FetchPhase.java", "diffHunk": "@@ -223,23 +217,34 @@ private int findRootDocumentIfNested(SearchContext context, LeafReaderContext su\n         return -1;\n     }\n \n+    private HitContext prepareHitContext(SearchContext context, FieldsVisitor fieldsVisitor, int docId,\n+                                         int subDocId, int rootDocId, Map<String, Set<String>> storedToRequestedFields,\n+                                         LeafReaderContext subReaderContext, Map<String, Object> sharedCache) throws IOException {\n+        if (rootDocId == -1) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f574db14f528b8287dddc95762ecf2b815267be"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQyMTI2NA==", "bodyText": "Small clarification: 'doc ID order' ?", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r473421264", "createdAt": "2020-08-19T23:14:07Z", "author": {"login": "jtibshirani"}, "path": "server/src/main/java/org/elasticsearch/search/fetch/FetchSubPhaseExecutor.java", "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.search.fetch;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.elasticsearch.search.fetch.FetchSubPhase.HitContext;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Executes the logic for a {@link FetchSubPhase} against a particular leaf reader and hit\n+ */\n+public interface FetchSubPhaseExecutor {\n+\n+    /**\n+     * Called when moving to the next {@link LeafReaderContext} for a set of hits\n+     */\n+    void setNextReader(LeafReaderContext readerContext) throws IOException;\n+\n+    /**\n+     * Called in doc order for each hit in a leaf reader", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f574db14f528b8287dddc95762ecf2b815267be"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQyMjM2OA==", "bodyText": "Is it okay to remove these catch and finally blocks?", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r473422368", "createdAt": "2020-08-19T23:15:40Z", "author": {"login": "jtibshirani"}, "path": "server/src/main/java/org/elasticsearch/search/fetch/subphase/ExplainPhase.java", "diffHunk": "@@ -32,24 +33,27 @@\n public final class ExplainPhase implements FetchSubPhase {\n \n     @Override\n-    public void hitExecute(SearchContext context, HitContext hitContext) {\n+    public FetchSubPhaseExecutor getExecutor(SearchContext context) {\n         if (context.explain() == false || context.hasOnlySuggest()) {\n-            return;\n+            return null;\n         }\n-        try {\n-            final int topLevelDocId = hitContext.hit().docId();\n-            Explanation explanation = context.searcher().explain(context.query(), topLevelDocId);\n+        return new FetchSubPhaseExecutor() {\n+            @Override\n+            public void setNextReader(LeafReaderContext readerContext) {\n \n-            for (RescoreContext rescore : context.rescore()) {\n-                explanation = rescore.rescorer().explain(topLevelDocId, context.searcher(), rescore, explanation);\n             }\n-            // we use the top level doc id, since we work with the top level searcher\n-            hitContext.hit().explanation(explanation);\n-        } catch (IOException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f574db14f528b8287dddc95762ecf2b815267be"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQyODUxNw==", "bodyText": "Should we assert or throw if scorerSupplier is null here? It looks like previously we threw an IllegalStateException. The same question holds for the advance call below.", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r473428517", "createdAt": "2020-08-19T23:24:29Z", "author": {"login": "jtibshirani"}, "path": "server/src/main/java/org/elasticsearch/search/fetch/subphase/FetchScorePhase.java", "diffHunk": "@@ -25,48 +25,44 @@\n import org.apache.lucene.search.Scorer;\n import org.apache.lucene.search.ScorerSupplier;\n import org.apache.lucene.search.Weight;\n-import org.elasticsearch.search.SearchHit;\n import org.elasticsearch.search.fetch.FetchSubPhase;\n+import org.elasticsearch.search.fetch.FetchSubPhaseExecutor;\n import org.elasticsearch.search.internal.SearchContext;\n \n import java.io.IOException;\n-import java.util.Iterator;\n \n public class FetchScorePhase implements FetchSubPhase {\n \n     @Override\n-    public void hitsExecute(SearchContext context, SearchHit[] hits) throws IOException {\n-        if (context.trackScores() == false || hits.length == 0 ||\n-                // scores were already computed since they are needed on the coordinated node to merge top hits\n-                context.sort() == null) {\n-            return;\n+    public FetchSubPhaseExecutor getExecutor(SearchContext context) throws IOException {\n+        if (context.trackScores() == false || context.docIdsToLoadSize() == 0 ||\n+            // scores were already computed since they are needed on the coordinated node to merge top hits\n+            context.sort() == null) {\n+            return null;\n         }\n-\n         final IndexSearcher searcher = context.searcher();\n         final Weight weight = searcher.createWeight(searcher.rewrite(context.query()), ScoreMode.COMPLETE, 1);\n-        Iterator<LeafReaderContext> leafContextIterator = searcher.getIndexReader().leaves().iterator();\n-        LeafReaderContext leafContext = null;\n-        Scorer scorer = null;\n-        for (SearchHit hit : hits) {\n-            if (leafContext == null || leafContext.docBase + leafContext.reader().maxDoc() <= hit.docId()) {\n-                do {\n-                    leafContext = leafContextIterator.next();\n-                } while (leafContext == null || leafContext.docBase + leafContext.reader().maxDoc() <= hit.docId());\n-                ScorerSupplier scorerSupplier = weight.scorerSupplier(leafContext);\n+        return new FetchSubPhaseExecutor() {\n+\n+            Scorer scorer;\n+\n+            @Override\n+            public void setNextReader(LeafReaderContext readerContext) throws IOException {\n+                ScorerSupplier scorerSupplier = weight.scorerSupplier(readerContext);\n                 if (scorerSupplier == null) {\n-                    throw new IllegalStateException(\"Can't compute score on document \" + hit + \" as it doesn't match the query\");\n+                    scorer = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f574db14f528b8287dddc95762ecf2b815267be"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQ3NTM1MQ==", "bodyText": "I assume this is okay, but wanted to check -- before we looped over fields then hits, but now we loop over hits then fields. This means that we hold onto a (potentially large) number of doc values iterators for the duration of the fetch phase. Are there any concerns around this change?", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r473475351", "createdAt": "2020-08-20T00:33:12Z", "author": {"login": "jtibshirani"}, "path": "server/src/main/java/org/elasticsearch/search/fetch/subphase/FetchDocValuesPhase.java", "diffHunk": "@@ -51,103 +48,191 @@\n public final class FetchDocValuesPhase implements FetchSubPhase {\n \n     @Override\n-    public void hitsExecute(SearchContext context, SearchHit[] hits) throws IOException {\n-\n+    public FetchSubPhaseExecutor getExecutor(SearchContext context) throws IOException {\n         if (context.collapse() != null) {\n             // retrieve the `doc_value` associated with the collapse field\n             String name = context.collapse().getFieldName();\n             if (context.docValuesContext() == null) {\n                 context.docValuesContext(new FetchDocValuesContext(\n-                        Collections.singletonList(new FieldAndFormat(name, null))));\n+                    Collections.singletonList(new FieldAndFormat(name, null))));\n             } else if (context.docValuesContext().fields().stream().map(ff -> ff.field).anyMatch(name::equals) == false) {\n                 context.docValuesContext().fields().add(new FieldAndFormat(name, null));\n             }\n         }\n \n         if (context.docValuesContext() == null) {\n-            return;\n+            return null;\n         }\n \n+        List<DocValueField> fields = new ArrayList<>();\n         for (FieldAndFormat fieldAndFormat : context.docValuesContext().fields()) {\n-            String field = fieldAndFormat.field;\n-            MappedFieldType fieldType = context.mapperService().fieldType(field);\n-            if (fieldType != null) {\n-                final IndexFieldData<?> indexFieldData = context.getForField(fieldType);\n-                final boolean isNanosecond;\n-                if (indexFieldData instanceof IndexNumericFieldData) {\n-                    isNanosecond = ((IndexNumericFieldData) indexFieldData).getNumericType() == NumericType.DATE_NANOSECONDS;\n-                } else {\n-                    isNanosecond = false;\n-                }\n-                final DocValueFormat format;\n-                String formatDesc = fieldAndFormat.format;\n-                if (isNanosecond) {\n-                    format = withNanosecondResolution(fieldType.docValueFormat(formatDesc, null));\n-                } else {\n-                    format = fieldType.docValueFormat(formatDesc, null);\n+            DocValueField f = buildField(context, fieldAndFormat);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f574db14f528b8287dddc95762ecf2b815267be"}, "originalPosition": 64}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2cc3fa4667881ed8ad26c9ed44d48944d1c69a7b", "author": {"user": {"login": "romseygeek", "name": "Alan Woodward"}}, "url": "https://github.com/elastic/elasticsearch/commit/2cc3fa4667881ed8ad26c9ed44d48944d1c69a7b", "committedDate": "2020-08-20T12:12:38Z", "message": "feedback"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fbb22456d8af2f548318bcdf13dc4ed489b4075e", "author": {"user": {"login": "romseygeek", "name": "Alan Woodward"}}, "url": "https://github.com/elastic/elasticsearch/commit/fbb22456d8af2f548318bcdf13dc4ed489b4075e", "committedDate": "2020-08-20T12:12:56Z", "message": "Merge remote-tracking branch 'origin/master' into fetch/hitexecute"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcyMzM0MTg0", "url": "https://github.com/elastic/elasticsearch/pull/60907#pullrequestreview-472334184", "createdAt": "2020-08-21T09:15:40Z", "commit": {"oid": "fbb22456d8af2f548318bcdf13dc4ed489b4075e"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQwOToxNTo0MFrOHElA2w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQwOToxODo0N1rOHElLSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU2Mjc3OQ==", "bodyText": "Is it still needed ? From what I understand this is now a global cache for the sub phases but I don't see where it is used as such. Do you have specific plans for this cache, maybe we can remove it now that sub phases can have a state ?", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r474562779", "createdAt": "2020-08-21T09:15:40Z", "author": {"login": "jimczi"}, "path": "server/src/main/java/org/elasticsearch/search/fetch/FetchSubPhase.java", "diffHunk": "@@ -36,19 +35,21 @@\n public interface FetchSubPhase {\n \n     class HitContext {\n-        private SearchHit hit;\n-        private IndexSearcher searcher;\n-        private LeafReaderContext readerContext;\n-        private int docId;\n+        private final SearchHit hit;\n+        private final IndexSearcher searcher;\n+        private final LeafReaderContext readerContext;\n+        private final int docId;\n         private final SourceLookup sourceLookup = new SourceLookup();\n-        private Map<String, Object> cache;\n+        private final Map<String, Object> cache;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fbb22456d8af2f548318bcdf13dc4ed489b4075e"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU2NTQ1MA==", "bodyText": "Maybe FetchSubPhaseCollector since it \"collects\" top hits ?", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r474565450", "createdAt": "2020-08-21T09:18:47Z", "author": {"login": "jimczi"}, "path": "server/src/main/java/org/elasticsearch/search/fetch/FetchSubPhaseExecutor.java", "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.search.fetch;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.elasticsearch.search.fetch.FetchSubPhase.HitContext;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Executes the logic for a {@link FetchSubPhase} against a particular leaf reader and hit\n+ */\n+public interface FetchSubPhaseExecutor {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fbb22456d8af2f548318bcdf13dc4ed489b4075e"}, "originalPosition": 30}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a7457ac466f40b15247159671b4e27f9083a6dba", "author": {"user": {"login": "romseygeek", "name": "Alan Woodward"}}, "url": "https://github.com/elastic/elasticsearch/commit/a7457ac466f40b15247159671b4e27f9083a6dba", "committedDate": "2020-08-24T09:13:48Z", "message": "Merge remote-tracking branch 'origin/master' into fetch/hitexecute"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "453277799ee694829dedad23fe53f57217c2eb7f", "author": {"user": {"login": "romseygeek", "name": "Alan Woodward"}}, "url": "https://github.com/elastic/elasticsearch/commit/453277799ee694829dedad23fe53f57217c2eb7f", "committedDate": "2020-08-24T16:02:34Z", "message": "rename; fix nested source reads"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "82803f11d7d1f7271e541f03e54d670c40a63713", "author": {"user": {"login": "romseygeek", "name": "Alan Woodward"}}, "url": "https://github.com/elastic/elasticsearch/commit/82803f11d7d1f7271e541f03e54d670c40a63713", "committedDate": "2020-08-24T17:26:06Z", "message": "highlight through aliases"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ec6fef29c344eac67c7d63906335efb616697763", "author": {"user": {"login": "romseygeek", "name": "Alan Woodward"}}, "url": "https://github.com/elastic/elasticsearch/commit/ec6fef29c344eac67c7d63906335efb616697763", "committedDate": "2020-08-25T09:59:42Z", "message": "preserve highlight fields ordering"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9c747bdbacb9ce9ad8bedad57dd1b8dabf5a7a0e", "author": {"user": {"login": "romseygeek", "name": "Alan Woodward"}}, "url": "https://github.com/elastic/elasticsearch/commit/9c747bdbacb9ce9ad8bedad57dd1b8dabf5a7a0e", "committedDate": "2020-08-25T10:04:44Z", "message": "Merge remote-tracking branch 'origin/master' into fetch/hitexecute"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6d4a5b24ab2593197bf433a3d74745f0f3ee3ea1", "author": {"user": {"login": "romseygeek", "name": "Alan Woodward"}}, "url": "https://github.com/elastic/elasticsearch/commit/6d4a5b24ab2593197bf433a3d74745f0f3ee3ea1", "committedDate": "2020-08-25T10:16:32Z", "message": "getCollector -> getProcessor"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "218a15a4b1168d111a4d1e7a7a40e02074c886eb", "author": {"user": {"login": "romseygeek", "name": "Alan Woodward"}}, "url": "https://github.com/elastic/elasticsearch/commit/218a15a4b1168d111a4d1e7a7a40e02074c886eb", "committedDate": "2020-08-25T11:29:29Z", "message": "matching queries"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc0OTIwNzQ5", "url": "https://github.com/elastic/elasticsearch/pull/60907#pullrequestreview-474920749", "createdAt": "2020-08-25T21:19:14Z", "commit": {"oid": "218a15a4b1168d111a4d1e7a7a40e02074c886eb"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQyMToxOToxNFrOHGqITw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQyMjoxMzowMVrOHGs4zw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njc0Mzc1OQ==", "bodyText": "Small comment, this could be private (or we could just inline it).", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r476743759", "createdAt": "2020-08-25T21:19:14Z", "author": {"login": "jtibshirani"}, "path": "server/src/internalClusterTest/java/org/elasticsearch/search/fetch/FetchSubPhasePluginIT.java", "diffHunk": "@@ -113,6 +114,20 @@ public void testPlugin() throws Exception {\n         private static final String NAME = \"term_vectors_fetch\";\n \n         @Override\n+        public FetchSubPhaseProcessor getProcessor(SearchContext searchContext) {\n+            return new FetchSubPhaseProcessor() {\n+                @Override\n+                public void setNextReader(LeafReaderContext readerContext) {\n+\n+                }\n+\n+                @Override\n+                public void process(HitContext hitContext) {\n+                    hitExecute(searchContext, hitContext);\n+                }\n+            };\n+        }\n+\n         public void hitExecute(SearchContext context, HitContext hitContext) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "218a15a4b1168d111a4d1e7a7a40e02074c886eb"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njc1MDA4Ng==", "bodyText": "Very small comment, it's a bit unusual to have an else after a throw ?", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r476750086", "createdAt": "2020-08-25T21:26:07Z", "author": {"login": "jtibshirani"}, "path": "server/src/main/java/org/elasticsearch/search/fetch/subphase/FetchScorePhase.java", "diffHunk": "@@ -25,48 +25,44 @@\n import org.apache.lucene.search.Scorer;\n import org.apache.lucene.search.ScorerSupplier;\n import org.apache.lucene.search.Weight;\n-import org.elasticsearch.search.SearchHit;\n import org.elasticsearch.search.fetch.FetchSubPhase;\n+import org.elasticsearch.search.fetch.FetchSubPhaseProcessor;\n import org.elasticsearch.search.internal.SearchContext;\n \n import java.io.IOException;\n-import java.util.Iterator;\n \n public class FetchScorePhase implements FetchSubPhase {\n \n     @Override\n-    public void hitsExecute(SearchContext context, SearchHit[] hits) throws IOException {\n-        if (context.trackScores() == false || hits.length == 0 ||\n-                // scores were already computed since they are needed on the coordinated node to merge top hits\n-                context.sort() == null) {\n-            return;\n+    public FetchSubPhaseProcessor getProcessor(SearchContext context) throws IOException {\n+        if (context.trackScores() == false || context.docIdsToLoadSize() == 0 ||\n+            // scores were already computed since they are needed on the coordinated node to merge top hits\n+            context.sort() == null) {\n+            return null;\n         }\n-\n         final IndexSearcher searcher = context.searcher();\n         final Weight weight = searcher.createWeight(searcher.rewrite(context.query()), ScoreMode.COMPLETE, 1);\n-        Iterator<LeafReaderContext> leafContextIterator = searcher.getIndexReader().leaves().iterator();\n-        LeafReaderContext leafContext = null;\n-        Scorer scorer = null;\n-        for (SearchHit hit : hits) {\n-            if (leafContext == null || leafContext.docBase + leafContext.reader().maxDoc() <= hit.docId()) {\n-                do {\n-                    leafContext = leafContextIterator.next();\n-                } while (leafContext == null || leafContext.docBase + leafContext.reader().maxDoc() <= hit.docId());\n-                ScorerSupplier scorerSupplier = weight.scorerSupplier(leafContext);\n+        return new FetchSubPhaseProcessor() {\n+\n+            Scorer scorer;\n+\n+            @Override\n+            public void setNextReader(LeafReaderContext readerContext) throws IOException {\n+                ScorerSupplier scorerSupplier = weight.scorerSupplier(readerContext);\n                 if (scorerSupplier == null) {\n-                    throw new IllegalStateException(\"Can't compute score on document \" + hit + \" as it doesn't match the query\");\n+                    throw new IllegalStateException(\"Can't compute score on document as it doesn't match the query\");\n+                } else {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "218a15a4b1168d111a4d1e7a7a40e02074c886eb"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njc2MzU3OQ==", "bodyText": "It's great how these subphases become more readable.", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r476763579", "createdAt": "2020-08-25T21:41:38Z", "author": {"login": "jtibshirani"}, "path": "server/src/main/java/org/elasticsearch/search/fetch/subphase/MatchedQueriesPhase.java", "diffHunk": "@@ -41,53 +38,52 @@\n public final class MatchedQueriesPhase implements FetchSubPhase {\n \n     @Override\n-    public void hitsExecute(SearchContext context, SearchHit[] hits) {\n-        if (hits.length == 0 ||\n+    public FetchSubPhaseProcessor getProcessor(SearchContext context) throws IOException {\n+        if (context.docIdsToLoadSize() == 0 ||\n             // in case the request has only suggest, parsed query is null\n             context.parsedQuery() == null) {\n-            return;\n+            return null;\n         }\n-        @SuppressWarnings(\"unchecked\")\n-        List<String>[] matchedQueries = new List[hits.length];\n-        for (int i = 0; i < matchedQueries.length; ++i) {\n-            matchedQueries[i] = new ArrayList<>();\n-        }\n-\n         Map<String, Query> namedQueries = new HashMap<>(context.parsedQuery().namedFilters());\n         if (context.parsedPostFilter() != null) {\n             namedQueries.putAll(context.parsedPostFilter().namedFilters());\n         }\n+        if (namedQueries.isEmpty()) {\n+            return null;\n+        }\n+        Map<String, Weight> weights = new HashMap<>();\n+        for (Map.Entry<String, Query> entry : namedQueries.entrySet()) {\n+            weights.put(entry.getKey(),\n+                context.searcher().createWeight(context.searcher().rewrite(entry.getValue()), ScoreMode.COMPLETE_NO_SCORES, 1));\n+        }\n+        return new FetchSubPhaseProcessor() {\n \n-        try {\n-            for (Map.Entry<String, Query> entry : namedQueries.entrySet()) {\n-                String name = entry.getKey();\n-                Query query = entry.getValue();\n-                int readerIndex = -1;\n-                int docBase = -1;\n-                Weight weight = context.searcher().createWeight(context.searcher().rewrite(query), ScoreMode.COMPLETE_NO_SCORES, 1f);\n-                Bits matchingDocs = null;\n-                final IndexReader indexReader = context.searcher().getIndexReader();\n-                for (int i = 0; i < hits.length; ++i) {\n-                    SearchHit hit = hits[i];\n-                    int hitReaderIndex = ReaderUtil.subIndex(hit.docId(), indexReader.leaves());\n-                    if (readerIndex != hitReaderIndex) {\n-                        readerIndex = hitReaderIndex;\n-                        LeafReaderContext ctx = indexReader.leaves().get(readerIndex);\n-                        docBase = ctx.docBase;\n-                        // scorers can be costly to create, so reuse them across docs of the same segment\n-                        ScorerSupplier scorerSupplier = weight.scorerSupplier(ctx);\n-                        matchingDocs = Lucene.asSequentialAccessBits(ctx.reader().maxDoc(), scorerSupplier);\n-                    }\n-                    if (matchingDocs.get(hit.docId() - docBase)) {\n-                        matchedQueries[i].add(name);\n+            final Map<String, Bits> matchingIterators = new HashMap<>();\n+\n+            @Override\n+            public void setNextReader(LeafReaderContext readerContext) throws IOException {\n+                matchingIterators.clear();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "218a15a4b1168d111a4d1e7a7a40e02074c886eb"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njc2ODg0Mg==", "bodyText": "Maybe we could revert to the old behavior for now to be really safe and scope down the change? My impression is that the fetch code hasn't been refactored in a while and isn't extensively tested.", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r476768842", "createdAt": "2020-08-25T21:47:53Z", "author": {"login": "jtibshirani"}, "path": "server/src/main/java/org/elasticsearch/search/fetch/subphase/ExplainPhase.java", "diffHunk": "@@ -32,24 +33,27 @@\n public final class ExplainPhase implements FetchSubPhase {\n \n     @Override\n-    public void hitExecute(SearchContext context, HitContext hitContext) {\n+    public FetchSubPhaseExecutor getExecutor(SearchContext context) {\n         if (context.explain() == false || context.hasOnlySuggest()) {\n-            return;\n+            return null;\n         }\n-        try {\n-            final int topLevelDocId = hitContext.hit().docId();\n-            Explanation explanation = context.searcher().explain(context.query(), topLevelDocId);\n+        return new FetchSubPhaseExecutor() {\n+            @Override\n+            public void setNextReader(LeafReaderContext readerContext) {\n \n-            for (RescoreContext rescore : context.rescore()) {\n-                explanation = rescore.rescorer().explain(topLevelDocId, context.searcher(), rescore, explanation);\n             }\n-            // we use the top level doc id, since we work with the top level searcher\n-            hitContext.hit().explanation(explanation);\n-        } catch (IOException e) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQyMjM2OA=="}, "originalCommit": {"oid": "4f574db14f528b8287dddc95762ecf2b815267be"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njc4MDA2MA==", "bodyText": "Could we perform this check only once for the whole subphase (maybe by reworking the contextBuilders method)? That would let us avoid adding the fieldNameContainsWildcards field to FieldHighlightContext.", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r476780060", "createdAt": "2020-08-25T22:01:33Z", "author": {"login": "jtibshirani"}, "path": "server/src/main/java/org/elasticsearch/search/fetch/subphase/highlight/HighlightPhase.java", "diffHunk": "@@ -28,34 +29,83 @@\n import org.elasticsearch.index.query.QueryShardContext;\n import org.elasticsearch.search.SearchShardTarget;\n import org.elasticsearch.search.fetch.FetchSubPhase;\n+import org.elasticsearch.search.fetch.FetchSubPhaseProcessor;\n import org.elasticsearch.search.internal.SearchContext;\n \n import java.util.Collection;\n import java.util.Collections;\n import java.util.HashMap;\n+import java.util.LinkedHashMap;\n import java.util.Map;\n+import java.util.function.Function;\n \n public class HighlightPhase implements FetchSubPhase {\n+\n     private final Map<String, Highlighter> highlighters;\n \n     public HighlightPhase(Map<String, Highlighter> highlighters) {\n         this.highlighters = highlighters;\n     }\n \n     @Override\n-    public void hitExecute(SearchContext context, HitContext hitContext) {\n+    public FetchSubPhaseProcessor getProcessor(SearchContext context) {\n         if (context.highlight() == null) {\n-            return;\n+            return null;\n         }\n-        hitExecute(context.shardTarget(), context.getQueryShardContext(), context.parsedQuery().query(), context.highlight(), hitContext);\n+\n+        return getProcessor(context.getQueryShardContext(), context.shardTarget(), context.highlight(), context.parsedQuery().query());\n+    }\n+\n+    public FetchSubPhaseProcessor getProcessor(QueryShardContext qsc, SearchShardTarget target, SearchHighlightContext hc, Query query) {\n+        Map<String, Function<HitContext, FieldHighlightContext>> contextBuilders = contextBuilders(qsc, target, hc, query);\n+        return new FetchSubPhaseProcessor() {\n+            @Override\n+            public void setNextReader(LeafReaderContext readerContext) {\n+\n+            }\n+\n+            @Override\n+            public void process(HitContext hitContext) {\n+                Map<String, HighlightField> highlightFields = new HashMap<>();\n+                for (String field : contextBuilders.keySet()) {\n+                    FieldHighlightContext fieldContext = contextBuilders.get(field).apply(hitContext);\n+                    Highlighter highlighter = getHighlighter(fieldContext.field);\n+                    if ((highlighter.canHighlight(fieldContext.fieldType) == false) && fieldContext.fromWildcard) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "218a15a4b1168d111a4d1e7a7a40e02074c886eb"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njc4ODk0Mw==", "bodyText": "Small comment, we could pass this into the PercolateContext constructor to avoid always having to pass it into PercolateContext#fieldName.", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r476788943", "createdAt": "2020-08-25T22:13:01Z", "author": {"login": "jtibshirani"}, "path": "modules/percolator/src/main/java/org/elasticsearch/percolator/PercolatorMatchedSlotSubFetchPhase.java", "diffHunk": "@@ -56,62 +56,86 @@\n     static final String FIELD_NAME_PREFIX = \"_percolator_document_slot\";\n \n     @Override\n-    public void hitsExecute(SearchContext context, SearchHit[] hits) throws IOException {\n-        innerHitsExecute(context.query(), context.searcher(), hits);\n-    }\n+    public FetchSubPhaseProcessor getProcessor(SearchContext searchContext) throws IOException {\n \n-    static void innerHitsExecute(Query mainQuery,\n-                                 IndexSearcher indexSearcher,\n-                                 SearchHit[] hits) throws IOException {\n-        List<PercolateQuery> percolateQueries = locatePercolatorQuery(mainQuery);\n-        if (percolateQueries.isEmpty()) {\n-            return;\n+        List<PercolateContext> percolateContexts = new ArrayList<>();\n+        for (PercolateQuery pq : locatePercolatorQuery(searchContext.query())) {\n+            percolateContexts.add(new PercolateContext(pq));\n+        }\n+        if (percolateContexts.isEmpty()) {\n+            return null;\n         }\n+        boolean singlePercolateQuery = percolateContexts.size() == 1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "218a15a4b1168d111a4d1e7a7a40e02074c886eb"}, "originalPosition": 44}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "08c859defd935db3e4416156c7329510d563b06b", "author": {"user": {"login": "romseygeek", "name": "Alan Woodward"}}, "url": "https://github.com/elastic/elasticsearch/commit/08c859defd935db3e4416156c7329510d563b06b", "committedDate": "2020-08-26T09:25:50Z", "message": "feedback"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a76d6b07ee2679af13625c038dd1dd426aa32ce9", "author": {"user": {"login": "romseygeek", "name": "Alan Woodward"}}, "url": "https://github.com/elastic/elasticsearch/commit/a76d6b07ee2679af13625c038dd1dd426aa32ce9", "committedDate": "2020-08-26T10:13:34Z", "message": "Merge remote-tracking branch 'origin/master' into fetch/hitexecute"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ca849f8451474ea7346a4e0d1b448e61a163ff06", "author": {"user": {"login": "romseygeek", "name": "Alan Woodward"}}, "url": "https://github.com/elastic/elasticsearch/commit/ca849f8451474ea7346a4e0d1b448e61a163ff06", "committedDate": "2020-08-27T15:38:47Z", "message": "Merge remote-tracking branch 'origin/master' into fetch/hitexecute"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f880d94415df66431213f95859a5a238a17892d8", "author": {"user": {"login": "romseygeek", "name": "Alan Woodward"}}, "url": "https://github.com/elastic/elasticsearch/commit/f880d94415df66431213f95859a5a238a17892d8", "committedDate": "2020-09-01T16:01:35Z", "message": "Merge remote-tracking branch 'origin/master' into fetch/hitexecute"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b541593f98418d7130fd771500a41a6c94a94b48", "author": {"user": {"login": "elasticmachine", "name": "Elastic Machine"}}, "url": "https://github.com/elastic/elasticsearch/commit/b541593f98418d7130fd771500a41a6c94a94b48", "committedDate": "2020-09-02T16:12:11Z", "message": "Merge branch 'master' into fetch/hitexecute"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgxMzQ2MDY3", "url": "https://github.com/elastic/elasticsearch/pull/60907#pullrequestreview-481346067", "createdAt": "2020-09-02T22:16:58Z", "commit": {"oid": "b541593f98418d7130fd771500a41a6c94a94b48"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "897e78b1c42540d83fd7bb85226af46ea9660295", "author": {"user": {"login": "elasticmachine", "name": "Elastic Machine"}}, "url": "https://github.com/elastic/elasticsearch/commit/897e78b1c42540d83fd7bb85226af46ea9660295", "committedDate": "2020-09-03T08:21:11Z", "message": "Merge branch 'master' into fetch/hitexecute"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3352, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}