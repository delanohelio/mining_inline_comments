{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk4MDEyOTc4", "number": 63273, "reviewThreads": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwODozMzo0M1rOEqn39w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxNTozMzoxM1rOErPMAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMTI4OTUxOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "isResolved": true, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwODozMzo0NFrOHc7rHQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxNToxMToyOVrOHd4Rrw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA5OTg2OQ==", "bodyText": "I'm wondering why we use a margin of 1000 docs here. IIUC the index writer will only under-count the total by at most one doc per write thread?\nOTOH if there is more severe under-counting under concurrent load then is 1000 enough?", "url": "https://github.com/elastic/elasticsearch/pull/63273#discussion_r500099869", "createdAt": "2020-10-06T08:33:44Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "diffHunk": "@@ -176,6 +176,16 @@\n     private final KeyedLock<Long> noOpKeyedLock = new KeyedLock<>();\n     private final AtomicBoolean shouldPeriodicallyFlushAfterBigMerge = new AtomicBoolean(false);\n \n+    /**\n+     * If multiple writes passed {@link InternalEngine#testReserveDocs(Operation, int)} (int)} but haven't adjusted\n+     * {@link IndexWriter#getPendingNumDocs()} yet, then IndexWriter can fail with too many documents. In this case,\n+     * we have to fail the engine because we already generated sequence numbers for write operations; otherwise we\n+     * will have gaps in sequence numbers. To avoid this (best-effort), we use a lower limit when trying to reserve\n+     * documents in InternalEngine.\n+     */\n+    static final int DEFAULT_MAX_DOCS = IndexWriter.MAX_DOCS - 1000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f5e10be04004d2c735f20a5daf342ce44235cf53"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDI0MDgyNg==", "bodyText": "IIUC the index writer will only under-count the total by at most one doc per write thread?\n\nYes, but IW can under-count more than one with nested documents.\n\nOTOH if there is more severe under-counting under concurrent load then is 1000 enough?\n\nI think 1000 is enough because all writes should execute using the WRITE thread pool, which has no more threads than the number of cores. Do you have a suggestion for this?", "url": "https://github.com/elastic/elasticsearch/pull/63273#discussion_r500240826", "createdAt": "2020-10-06T12:38:25Z", "author": {"login": "dnhatn"}, "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "diffHunk": "@@ -176,6 +176,16 @@\n     private final KeyedLock<Long> noOpKeyedLock = new KeyedLock<>();\n     private final AtomicBoolean shouldPeriodicallyFlushAfterBigMerge = new AtomicBoolean(false);\n \n+    /**\n+     * If multiple writes passed {@link InternalEngine#testReserveDocs(Operation, int)} (int)} but haven't adjusted\n+     * {@link IndexWriter#getPendingNumDocs()} yet, then IndexWriter can fail with too many documents. In this case,\n+     * we have to fail the engine because we already generated sequence numbers for write operations; otherwise we\n+     * will have gaps in sequence numbers. To avoid this (best-effort), we use a lower limit when trying to reserve\n+     * documents in InternalEngine.\n+     */\n+    static final int DEFAULT_MAX_DOCS = IndexWriter.MAX_DOCS - 1000;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA5OTg2OQ=="}, "originalCommit": {"oid": "f5e10be04004d2c735f20a5daf342ce44235cf53"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDI1MDY2MQ==", "bodyText": "Ah darn it yes, nested docs strike again. In which case I don't think 1000 is enough for all users. Can we instead acquire a proper reservation for the right number of docs in testReserveDocs (e.g. using a Semaphore) and then release them once they're tracked by the IndexWriter?", "url": "https://github.com/elastic/elasticsearch/pull/63273#discussion_r500250661", "createdAt": "2020-10-06T12:53:44Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "diffHunk": "@@ -176,6 +176,16 @@\n     private final KeyedLock<Long> noOpKeyedLock = new KeyedLock<>();\n     private final AtomicBoolean shouldPeriodicallyFlushAfterBigMerge = new AtomicBoolean(false);\n \n+    /**\n+     * If multiple writes passed {@link InternalEngine#testReserveDocs(Operation, int)} (int)} but haven't adjusted\n+     * {@link IndexWriter#getPendingNumDocs()} yet, then IndexWriter can fail with too many documents. In this case,\n+     * we have to fail the engine because we already generated sequence numbers for write operations; otherwise we\n+     * will have gaps in sequence numbers. To avoid this (best-effort), we use a lower limit when trying to reserve\n+     * documents in InternalEngine.\n+     */\n+    static final int DEFAULT_MAX_DOCS = IndexWriter.MAX_DOCS - 1000;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA5OTg2OQ=="}, "originalCommit": {"oid": "f5e10be04004d2c735f20a5daf342ce44235cf53"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDM4Mzk4Nw==", "bodyText": "That would lead to double counting as adding documents will be counted twice in InternalEngine and IndexWriter. But I think that's okay if we want to make this check more watertight (than the current best-effort). I can make that change. WDYT?", "url": "https://github.com/elastic/elasticsearch/pull/63273#discussion_r500383987", "createdAt": "2020-10-06T15:21:49Z", "author": {"login": "dnhatn"}, "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "diffHunk": "@@ -176,6 +176,16 @@\n     private final KeyedLock<Long> noOpKeyedLock = new KeyedLock<>();\n     private final AtomicBoolean shouldPeriodicallyFlushAfterBigMerge = new AtomicBoolean(false);\n \n+    /**\n+     * If multiple writes passed {@link InternalEngine#testReserveDocs(Operation, int)} (int)} but haven't adjusted\n+     * {@link IndexWriter#getPendingNumDocs()} yet, then IndexWriter can fail with too many documents. In this case,\n+     * we have to fail the engine because we already generated sequence numbers for write operations; otherwise we\n+     * will have gaps in sequence numbers. To avoid this (best-effort), we use a lower limit when trying to reserve\n+     * documents in InternalEngine.\n+     */\n+    static final int DEFAULT_MAX_DOCS = IndexWriter.MAX_DOCS - 1000;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA5OTg2OQ=="}, "originalCommit": {"oid": "f5e10be04004d2c735f20a5daf342ce44235cf53"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQ1NzYxOA==", "bodyText": "Yes, it'd mean some temporary double-counting so that we potentially reject some docs when we get very close to the limit, and then accept some more docs, but I think that's ok. We have that behaviour anyway today because after a merge the doc count may decrease permitting some more docs to be indexed.", "url": "https://github.com/elastic/elasticsearch/pull/63273#discussion_r500457618", "createdAt": "2020-10-06T17:03:40Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "diffHunk": "@@ -176,6 +176,16 @@\n     private final KeyedLock<Long> noOpKeyedLock = new KeyedLock<>();\n     private final AtomicBoolean shouldPeriodicallyFlushAfterBigMerge = new AtomicBoolean(false);\n \n+    /**\n+     * If multiple writes passed {@link InternalEngine#testReserveDocs(Operation, int)} (int)} but haven't adjusted\n+     * {@link IndexWriter#getPendingNumDocs()} yet, then IndexWriter can fail with too many documents. In this case,\n+     * we have to fail the engine because we already generated sequence numbers for write operations; otherwise we\n+     * will have gaps in sequence numbers. To avoid this (best-effort), we use a lower limit when trying to reserve\n+     * documents in InternalEngine.\n+     */\n+    static final int DEFAULT_MAX_DOCS = IndexWriter.MAX_DOCS - 1000;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA5OTg2OQ=="}, "originalCommit": {"oid": "f5e10be04004d2c735f20a5daf342ce44235cf53"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTA5Mjc4Mw==", "bodyText": "Adjusted in efa8145", "url": "https://github.com/elastic/elasticsearch/pull/63273#discussion_r501092783", "createdAt": "2020-10-07T15:11:29Z", "author": {"login": "dnhatn"}, "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "diffHunk": "@@ -176,6 +176,16 @@\n     private final KeyedLock<Long> noOpKeyedLock = new KeyedLock<>();\n     private final AtomicBoolean shouldPeriodicallyFlushAfterBigMerge = new AtomicBoolean(false);\n \n+    /**\n+     * If multiple writes passed {@link InternalEngine#testReserveDocs(Operation, int)} (int)} but haven't adjusted\n+     * {@link IndexWriter#getPendingNumDocs()} yet, then IndexWriter can fail with too many documents. In this case,\n+     * we have to fail the engine because we already generated sequence numbers for write operations; otherwise we\n+     * will have gaps in sequence numbers. To avoid this (best-effort), we use a lower limit when trying to reserve\n+     * documents in InternalEngine.\n+     */\n+    static final int DEFAULT_MAX_DOCS = IndexWriter.MAX_DOCS - 1000;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA5OTg2OQ=="}, "originalCommit": {"oid": "f5e10be04004d2c735f20a5daf342ce44235cf53"}, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMTI5NDAzOnYy", "diffSide": "RIGHT", "path": "server/src/internalClusterTest/java/org/elasticsearch/index/engine/MaxDocsLimitIT.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwODozNTowMVrOHc7uBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxNToxMToyMFrOHd4RPw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDEwMDYxNA==", "bodyText": "Could we run this test (or a similar one) with concurrent indexing too, to demonstrate that we only exceed the limit by a bounded amount?", "url": "https://github.com/elastic/elasticsearch/pull/63273#discussion_r500100614", "createdAt": "2020-10-06T08:35:01Z", "author": {"login": "DaveCTurner"}, "path": "server/src/internalClusterTest/java/org/elasticsearch/index/engine/MaxDocsLimitIT.java", "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.index.engine;\n+\n+import org.apache.lucene.index.IndexWriterMaxDocsChanger;\n+import org.elasticsearch.action.index.IndexResponse;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.xcontent.XContentType;\n+import org.elasticsearch.index.IndexSettings;\n+import org.elasticsearch.index.query.MatchAllQueryBuilder;\n+import org.elasticsearch.index.translog.Translog;\n+import org.elasticsearch.plugins.EnginePlugin;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.test.ESIntegTestCase;\n+import org.elasticsearch.test.hamcrest.ElasticsearchAssertions;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Optional;\n+\n+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;\n+import static org.hamcrest.Matchers.containsString;\n+import static org.hamcrest.Matchers.equalTo;\n+\n+public class MaxDocsLimitIT extends ESIntegTestCase {\n+\n+    public static class TestEnginePlugin extends Plugin implements EnginePlugin {\n+        public static final int maxDocs = randomIntBetween(1, 20);\n+\n+        @Override\n+        public Optional<EngineFactory> getEngineFactory(IndexSettings indexSettings) {\n+            return Optional.of(config -> EngineTestCase.createEngine(config, maxDocs));\n+        }\n+    }\n+\n+    @Override\n+    protected boolean addMockInternalEngine() {\n+        return false;\n+    }\n+\n+    @Override\n+    protected Collection<Class<? extends Plugin>> nodePlugins() {\n+        List<Class<? extends Plugin>> plugins = new ArrayList<>(super.nodePlugins());\n+        plugins.add(TestEnginePlugin.class);\n+        return plugins;\n+    }\n+\n+    public void testMaxDocsLimit() throws Exception {\n+        final int maxDocs = TestEnginePlugin.maxDocs;\n+        IndexWriterMaxDocsChanger.setMaxDocs(maxDocs);\n+        try {\n+            internalCluster().ensureAtLeastNumDataNodes(1);\n+            assertAcked(client().admin().indices().prepareCreate(\"test\")\n+                .setSettings(Settings.builder().put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)\n+                    .put(IndexSettings.INDEX_TRANSLOG_DURABILITY_SETTING.getKey(), Translog.Durability.REQUEST)));\n+            int numDocs = randomIntBetween(maxDocs + 1, maxDocs * 2);\n+            for (int i = 0; i < numDocs; i++) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f5e10be04004d2c735f20a5daf342ce44235cf53"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDI0MTA2OA==", "bodyText": "++, I will add a new test.", "url": "https://github.com/elastic/elasticsearch/pull/63273#discussion_r500241068", "createdAt": "2020-10-06T12:38:46Z", "author": {"login": "dnhatn"}, "path": "server/src/internalClusterTest/java/org/elasticsearch/index/engine/MaxDocsLimitIT.java", "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.index.engine;\n+\n+import org.apache.lucene.index.IndexWriterMaxDocsChanger;\n+import org.elasticsearch.action.index.IndexResponse;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.xcontent.XContentType;\n+import org.elasticsearch.index.IndexSettings;\n+import org.elasticsearch.index.query.MatchAllQueryBuilder;\n+import org.elasticsearch.index.translog.Translog;\n+import org.elasticsearch.plugins.EnginePlugin;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.test.ESIntegTestCase;\n+import org.elasticsearch.test.hamcrest.ElasticsearchAssertions;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Optional;\n+\n+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;\n+import static org.hamcrest.Matchers.containsString;\n+import static org.hamcrest.Matchers.equalTo;\n+\n+public class MaxDocsLimitIT extends ESIntegTestCase {\n+\n+    public static class TestEnginePlugin extends Plugin implements EnginePlugin {\n+        public static final int maxDocs = randomIntBetween(1, 20);\n+\n+        @Override\n+        public Optional<EngineFactory> getEngineFactory(IndexSettings indexSettings) {\n+            return Optional.of(config -> EngineTestCase.createEngine(config, maxDocs));\n+        }\n+    }\n+\n+    @Override\n+    protected boolean addMockInternalEngine() {\n+        return false;\n+    }\n+\n+    @Override\n+    protected Collection<Class<? extends Plugin>> nodePlugins() {\n+        List<Class<? extends Plugin>> plugins = new ArrayList<>(super.nodePlugins());\n+        plugins.add(TestEnginePlugin.class);\n+        return plugins;\n+    }\n+\n+    public void testMaxDocsLimit() throws Exception {\n+        final int maxDocs = TestEnginePlugin.maxDocs;\n+        IndexWriterMaxDocsChanger.setMaxDocs(maxDocs);\n+        try {\n+            internalCluster().ensureAtLeastNumDataNodes(1);\n+            assertAcked(client().admin().indices().prepareCreate(\"test\")\n+                .setSettings(Settings.builder().put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)\n+                    .put(IndexSettings.INDEX_TRANSLOG_DURABILITY_SETTING.getKey(), Translog.Durability.REQUEST)));\n+            int numDocs = randomIntBetween(maxDocs + 1, maxDocs * 2);\n+            for (int i = 0; i < numDocs; i++) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDEwMDYxNA=="}, "originalCommit": {"oid": "f5e10be04004d2c735f20a5daf342ce44235cf53"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTA5MjY3MQ==", "bodyText": "added in efa8145.", "url": "https://github.com/elastic/elasticsearch/pull/63273#discussion_r501092671", "createdAt": "2020-10-07T15:11:20Z", "author": {"login": "dnhatn"}, "path": "server/src/internalClusterTest/java/org/elasticsearch/index/engine/MaxDocsLimitIT.java", "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.index.engine;\n+\n+import org.apache.lucene.index.IndexWriterMaxDocsChanger;\n+import org.elasticsearch.action.index.IndexResponse;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.xcontent.XContentType;\n+import org.elasticsearch.index.IndexSettings;\n+import org.elasticsearch.index.query.MatchAllQueryBuilder;\n+import org.elasticsearch.index.translog.Translog;\n+import org.elasticsearch.plugins.EnginePlugin;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.test.ESIntegTestCase;\n+import org.elasticsearch.test.hamcrest.ElasticsearchAssertions;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Optional;\n+\n+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;\n+import static org.hamcrest.Matchers.containsString;\n+import static org.hamcrest.Matchers.equalTo;\n+\n+public class MaxDocsLimitIT extends ESIntegTestCase {\n+\n+    public static class TestEnginePlugin extends Plugin implements EnginePlugin {\n+        public static final int maxDocs = randomIntBetween(1, 20);\n+\n+        @Override\n+        public Optional<EngineFactory> getEngineFactory(IndexSettings indexSettings) {\n+            return Optional.of(config -> EngineTestCase.createEngine(config, maxDocs));\n+        }\n+    }\n+\n+    @Override\n+    protected boolean addMockInternalEngine() {\n+        return false;\n+    }\n+\n+    @Override\n+    protected Collection<Class<? extends Plugin>> nodePlugins() {\n+        List<Class<? extends Plugin>> plugins = new ArrayList<>(super.nodePlugins());\n+        plugins.add(TestEnginePlugin.class);\n+        return plugins;\n+    }\n+\n+    public void testMaxDocsLimit() throws Exception {\n+        final int maxDocs = TestEnginePlugin.maxDocs;\n+        IndexWriterMaxDocsChanger.setMaxDocs(maxDocs);\n+        try {\n+            internalCluster().ensureAtLeastNumDataNodes(1);\n+            assertAcked(client().admin().indices().prepareCreate(\"test\")\n+                .setSettings(Settings.builder().put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)\n+                    .put(IndexSettings.INDEX_TRANSLOG_DURABILITY_SETTING.getKey(), Translog.Durability.REQUEST)));\n+            int numDocs = randomIntBetween(maxDocs + 1, maxDocs * 2);\n+            for (int i = 0; i < numDocs; i++) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDEwMDYxNA=="}, "originalCommit": {"oid": "f5e10be04004d2c735f20a5daf342ce44235cf53"}, "originalPosition": 78}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzNzcxMDQ0OnYy", "diffSide": "RIGHT", "path": "server/src/internalClusterTest/java/org/elasticsearch/index/engine/MaxDocsLimitIT.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxNToyODo1M1rOHd5GSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxNjoxOTozMFrOHd7VWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTEwNjI1MA==", "bodyText": "Can we make this assertion more generally too? IIRC there are some other assertions that check that things have settled down after a test (no in-flight operations, for instance) although I'm not quite sure where they are.", "url": "https://github.com/elastic/elasticsearch/pull/63273#discussion_r501106250", "createdAt": "2020-10-07T15:28:53Z", "author": {"login": "DaveCTurner"}, "path": "server/src/internalClusterTest/java/org/elasticsearch/index/engine/MaxDocsLimitIT.java", "diffHunk": "@@ -0,0 +1,212 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.index.engine;\n+\n+import org.apache.lucene.index.IndexWriterMaxDocsChanger;\n+import org.apache.lucene.store.AlreadyClosedException;\n+import org.elasticsearch.action.index.IndexResponse;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.xcontent.XContentType;\n+import org.elasticsearch.index.IndexService;\n+import org.elasticsearch.index.IndexSettings;\n+import org.elasticsearch.index.query.MatchAllQueryBuilder;\n+import org.elasticsearch.index.shard.IndexShard;\n+import org.elasticsearch.index.shard.IndexShardTestCase;\n+import org.elasticsearch.index.translog.Translog;\n+import org.elasticsearch.indices.IndicesService;\n+import org.elasticsearch.plugins.EnginePlugin;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.test.ESIntegTestCase;\n+import org.elasticsearch.test.hamcrest.ElasticsearchAssertions;\n+import org.junit.After;\n+import org.junit.Before;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.concurrent.Phaser;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;\n+import static org.hamcrest.Matchers.both;\n+import static org.hamcrest.Matchers.containsString;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThan;\n+import static org.hamcrest.Matchers.lessThanOrEqualTo;\n+\n+public class MaxDocsLimitIT extends ESIntegTestCase {\n+\n+    private static final AtomicInteger maxDocs = new AtomicInteger();\n+\n+    public static class TestEnginePlugin extends Plugin implements EnginePlugin {\n+        @Override\n+        public Optional<EngineFactory> getEngineFactory(IndexSettings indexSettings) {\n+            return Optional.of(config -> {\n+                assert maxDocs.get() > 0 : \"maxDocs is unset\";\n+                return EngineTestCase.createEngine(config, maxDocs.get());\n+            });\n+        }\n+    }\n+\n+    @Override\n+    protected boolean addMockInternalEngine() {\n+        return false;\n+    }\n+\n+    @Override\n+    protected Collection<Class<? extends Plugin>> nodePlugins() {\n+        List<Class<? extends Plugin>> plugins = new ArrayList<>(super.nodePlugins());\n+        plugins.add(TestEnginePlugin.class);\n+        return plugins;\n+    }\n+\n+    @Before\n+    public void setMaxDocs() {\n+        maxDocs.set(randomIntBetween(10, 100)); // Do not set this too low as we can fail to write the cluster state\n+        IndexWriterMaxDocsChanger.setMaxDocs(maxDocs.get());\n+    }\n+\n+    @After\n+    public void restoreMaxDocs() {\n+        IndexWriterMaxDocsChanger.restoreMaxDocs();\n+    }\n+\n+    public static void assertNoOutstandingReservingDocs() throws Exception {\n+        assertBusy(() -> {\n+            for (IndicesService indicesService : internalCluster().getDataNodeInstances(IndicesService.class)) {\n+                for (IndexService indexService : indicesService) {\n+                    for (IndexShard indexShard : indexService) {\n+                        try {\n+                            assertThat(EngineTestCase.getReservingDocs(IndexShardTestCase.getEngine(indexShard)), equalTo(0L));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "95189c54bf1269c540f16a757d7063821b13fdbe"}, "originalPosition": 101}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTE0Mjg3Mg==", "bodyText": "This assertion should be very lightweight. I added it in 290806d.", "url": "https://github.com/elastic/elasticsearch/pull/63273#discussion_r501142872", "createdAt": "2020-10-07T16:19:30Z", "author": {"login": "dnhatn"}, "path": "server/src/internalClusterTest/java/org/elasticsearch/index/engine/MaxDocsLimitIT.java", "diffHunk": "@@ -0,0 +1,212 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.index.engine;\n+\n+import org.apache.lucene.index.IndexWriterMaxDocsChanger;\n+import org.apache.lucene.store.AlreadyClosedException;\n+import org.elasticsearch.action.index.IndexResponse;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.xcontent.XContentType;\n+import org.elasticsearch.index.IndexService;\n+import org.elasticsearch.index.IndexSettings;\n+import org.elasticsearch.index.query.MatchAllQueryBuilder;\n+import org.elasticsearch.index.shard.IndexShard;\n+import org.elasticsearch.index.shard.IndexShardTestCase;\n+import org.elasticsearch.index.translog.Translog;\n+import org.elasticsearch.indices.IndicesService;\n+import org.elasticsearch.plugins.EnginePlugin;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.test.ESIntegTestCase;\n+import org.elasticsearch.test.hamcrest.ElasticsearchAssertions;\n+import org.junit.After;\n+import org.junit.Before;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.concurrent.Phaser;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;\n+import static org.hamcrest.Matchers.both;\n+import static org.hamcrest.Matchers.containsString;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThan;\n+import static org.hamcrest.Matchers.lessThanOrEqualTo;\n+\n+public class MaxDocsLimitIT extends ESIntegTestCase {\n+\n+    private static final AtomicInteger maxDocs = new AtomicInteger();\n+\n+    public static class TestEnginePlugin extends Plugin implements EnginePlugin {\n+        @Override\n+        public Optional<EngineFactory> getEngineFactory(IndexSettings indexSettings) {\n+            return Optional.of(config -> {\n+                assert maxDocs.get() > 0 : \"maxDocs is unset\";\n+                return EngineTestCase.createEngine(config, maxDocs.get());\n+            });\n+        }\n+    }\n+\n+    @Override\n+    protected boolean addMockInternalEngine() {\n+        return false;\n+    }\n+\n+    @Override\n+    protected Collection<Class<? extends Plugin>> nodePlugins() {\n+        List<Class<? extends Plugin>> plugins = new ArrayList<>(super.nodePlugins());\n+        plugins.add(TestEnginePlugin.class);\n+        return plugins;\n+    }\n+\n+    @Before\n+    public void setMaxDocs() {\n+        maxDocs.set(randomIntBetween(10, 100)); // Do not set this too low as we can fail to write the cluster state\n+        IndexWriterMaxDocsChanger.setMaxDocs(maxDocs.get());\n+    }\n+\n+    @After\n+    public void restoreMaxDocs() {\n+        IndexWriterMaxDocsChanger.restoreMaxDocs();\n+    }\n+\n+    public static void assertNoOutstandingReservingDocs() throws Exception {\n+        assertBusy(() -> {\n+            for (IndicesService indicesService : internalCluster().getDataNodeInstances(IndicesService.class)) {\n+                for (IndexService indexService : indicesService) {\n+                    for (IndexShard indexShard : indexService) {\n+                        try {\n+                            assertThat(EngineTestCase.getReservingDocs(IndexShardTestCase.getEngine(indexShard)), equalTo(0L));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTEwNjI1MA=="}, "originalCommit": {"oid": "95189c54bf1269c540f16a757d7063821b13fdbe"}, "originalPosition": 101}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzNzcxOTYxOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxNTozMDozOVrOHd5L7Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxNjoxODo0OVrOHd7Tnw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTEwNzY5Mw==", "bodyText": "Naming nit: reserved feels rather too general a term for me, how would you feel about renaming this something like inFlightDocCount instead?", "url": "https://github.com/elastic/elasticsearch/pull/63273#discussion_r501107693", "createdAt": "2020-10-07T15:30:39Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "diffHunk": "@@ -176,6 +176,18 @@\n     private final KeyedLock<Long> noOpKeyedLock = new KeyedLock<>();\n     private final AtomicBoolean shouldPeriodicallyFlushAfterBigMerge = new AtomicBoolean(false);\n \n+    /**\n+     * If multiple writes passed {@link InternalEngine#tryReserveDocs(Operation, int)} but they haven't adjusted\n+     * {@link IndexWriter#getPendingNumDocs()} yet, then IndexWriter can fail with too many documents. In this case, we have to fail\n+     * the engine because we already generated sequence numbers for write operations; otherwise we will have gaps in sequence numbers.\n+     * To avoid this, we keep track the number of documents that are being added to IndexWriter, and account it in\n+     * {@link InternalEngine#tryReserveDocs(Operation, int)}. Although we can double count some adding documents in both IW and Engine,\n+     * this shouldn't be an issue because it happens for a short window and we adjust the reservingNumDocs once an indexing is completed.\n+     */\n+    private final AtomicLong reservingNumDocs = new AtomicLong();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "95189c54bf1269c540f16a757d7063821b13fdbe"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTE0MjQzMQ==", "bodyText": "++", "url": "https://github.com/elastic/elasticsearch/pull/63273#discussion_r501142431", "createdAt": "2020-10-07T16:18:49Z", "author": {"login": "dnhatn"}, "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "diffHunk": "@@ -176,6 +176,18 @@\n     private final KeyedLock<Long> noOpKeyedLock = new KeyedLock<>();\n     private final AtomicBoolean shouldPeriodicallyFlushAfterBigMerge = new AtomicBoolean(false);\n \n+    /**\n+     * If multiple writes passed {@link InternalEngine#tryReserveDocs(Operation, int)} but they haven't adjusted\n+     * {@link IndexWriter#getPendingNumDocs()} yet, then IndexWriter can fail with too many documents. In this case, we have to fail\n+     * the engine because we already generated sequence numbers for write operations; otherwise we will have gaps in sequence numbers.\n+     * To avoid this, we keep track the number of documents that are being added to IndexWriter, and account it in\n+     * {@link InternalEngine#tryReserveDocs(Operation, int)}. Although we can double count some adding documents in both IW and Engine,\n+     * this shouldn't be an issue because it happens for a short window and we adjust the reservingNumDocs once an indexing is completed.\n+     */\n+    private final AtomicLong reservingNumDocs = new AtomicLong();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTEwNzY5Mw=="}, "originalCommit": {"oid": "95189c54bf1269c540f16a757d7063821b13fdbe"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzNzcyODY2OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxNTozMjo0NVrOHd5Rmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxNjoxODo0MlrOHd7TUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTEwOTE0Nw==", "bodyText": "Since we only ever use this to release the docs, how about renaming this to something like releaseInFlightDocs  and accepting a positive parameter instead?", "url": "https://github.com/elastic/elasticsearch/pull/63273#discussion_r501109147", "createdAt": "2020-10-07T15:32:45Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "diffHunk": "@@ -1275,11 +1308,35 @@ public DeleteResult delete(Delete delete) throws IOException {\n                 e.addSuppressed(inner);\n             }\n             throw e;\n+        } finally {\n+            adjustReservingDocs(-reservedDocs);\n         }\n         maybePruneDeletes();\n         return deleteResult;\n     }\n \n+    private Exception tryReserveDocs(Operation operation, int addingDocs) {\n+        assert operation.origin() == Operation.Origin.PRIMARY : operation;\n+        assert operation.seqNo() == SequenceNumbers.UNASSIGNED_SEQ_NO : operation;\n+        final long totalDocs = indexWriter.getPendingNumDocs() + reservingNumDocs.addAndGet(addingDocs);\n+        if (totalDocs > maxDocs) {\n+            adjustReservingDocs(-addingDocs);\n+            return new IllegalArgumentException(\"Number of documents in the index can't exceed [\" + maxDocs + \"]\");\n+        } else {\n+            return null;\n+        }\n+    }\n+\n+    private void adjustReservingDocs(int numDocs) {\n+        assert numDocs <= 0 : numDocs;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "95189c54bf1269c540f16a757d7063821b13fdbe"}, "originalPosition": 231}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTE0MjM1NQ==", "bodyText": "Good suggestion. I pushed 294fcb4.", "url": "https://github.com/elastic/elasticsearch/pull/63273#discussion_r501142355", "createdAt": "2020-10-07T16:18:42Z", "author": {"login": "dnhatn"}, "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "diffHunk": "@@ -1275,11 +1308,35 @@ public DeleteResult delete(Delete delete) throws IOException {\n                 e.addSuppressed(inner);\n             }\n             throw e;\n+        } finally {\n+            adjustReservingDocs(-reservedDocs);\n         }\n         maybePruneDeletes();\n         return deleteResult;\n     }\n \n+    private Exception tryReserveDocs(Operation operation, int addingDocs) {\n+        assert operation.origin() == Operation.Origin.PRIMARY : operation;\n+        assert operation.seqNo() == SequenceNumbers.UNASSIGNED_SEQ_NO : operation;\n+        final long totalDocs = indexWriter.getPendingNumDocs() + reservingNumDocs.addAndGet(addingDocs);\n+        if (totalDocs > maxDocs) {\n+            adjustReservingDocs(-addingDocs);\n+            return new IllegalArgumentException(\"Number of documents in the index can't exceed [\" + maxDocs + \"]\");\n+        } else {\n+            return null;\n+        }\n+    }\n+\n+    private void adjustReservingDocs(int numDocs) {\n+        assert numDocs <= 0 : numDocs;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTEwOTE0Nw=="}, "originalCommit": {"oid": "95189c54bf1269c540f16a757d7063821b13fdbe"}, "originalPosition": 231}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzNzczMDU3OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxNTozMzoxM1rOHd5S5A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxNjoxOTowMVrOHd7UHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTEwOTQ3Ng==", "bodyText": "Contrasting with releaseInFlightDocs how about tryAcquireInFlightDocs?", "url": "https://github.com/elastic/elasticsearch/pull/63273#discussion_r501109476", "createdAt": "2020-10-07T15:33:13Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "diffHunk": "@@ -1275,11 +1308,35 @@ public DeleteResult delete(Delete delete) throws IOException {\n                 e.addSuppressed(inner);\n             }\n             throw e;\n+        } finally {\n+            adjustReservingDocs(-reservedDocs);\n         }\n         maybePruneDeletes();\n         return deleteResult;\n     }\n \n+    private Exception tryReserveDocs(Operation operation, int addingDocs) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "95189c54bf1269c540f16a757d7063821b13fdbe"}, "originalPosition": 218}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTE0MjU1Ng==", "bodyText": "Ok, see 294fcb4", "url": "https://github.com/elastic/elasticsearch/pull/63273#discussion_r501142556", "createdAt": "2020-10-07T16:19:01Z", "author": {"login": "dnhatn"}, "path": "server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java", "diffHunk": "@@ -1275,11 +1308,35 @@ public DeleteResult delete(Delete delete) throws IOException {\n                 e.addSuppressed(inner);\n             }\n             throw e;\n+        } finally {\n+            adjustReservingDocs(-reservedDocs);\n         }\n         maybePruneDeletes();\n         return deleteResult;\n     }\n \n+    private Exception tryReserveDocs(Operation operation, int addingDocs) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTEwOTQ3Ng=="}, "originalCommit": {"oid": "95189c54bf1269c540f16a757d7063821b13fdbe"}, "originalPosition": 218}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3198, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}