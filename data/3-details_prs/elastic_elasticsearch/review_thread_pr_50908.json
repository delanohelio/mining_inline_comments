{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYyMDcwMzIw", "number": 50908, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xM1QxNTo1NToxNFrODXkUAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xM1QyMTowNjoyOVrODXp_Hg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MDM4Nzg1OnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/action/admin/indices/TransportAnalyzeActionTests.java", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xM1QxNTo1NToxNFrOFc7j_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xM1QxOTo0MTo1N1rOFdCYfg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTg4MDMxOA==", "bodyText": "Just a small observation: I thought this checks that the normalize method in DeprecatedTokenFilterFactory, so I tried changing it but the test didn't fail, do you know why?", "url": "https://github.com/elastic/elasticsearch/pull/50908#discussion_r365880318", "createdAt": "2020-01-13T15:55:14Z", "author": {"login": "cbuescher"}, "path": "server/src/test/java/org/elasticsearch/action/admin/indices/TransportAnalyzeActionTests.java", "diffHunk": "@@ -492,4 +512,28 @@ public void testExceedSetMaxTokenLimit() {\n         assertEquals(e.getMessage(), \"The number of tokens produced by calling _analyze has exceeded the allowed maximum of [\"\n             + idxMaxTokenCount + \"].\" + \" This limit can be set by changing the [index.analyze.max_token_count] index level setting.\");\n     }\n+\n+    public void testDeprecationWarnings() throws IOException {\n+        AnalyzeAction.Request req = new AnalyzeAction.Request();\n+        req.tokenizer(\"standard\");\n+        req.addTokenFilter(\"lowercase\");\n+        req.addTokenFilter(\"deprecated\");\n+        req.text(\"test text\");\n+\n+        AnalyzeAction.Response analyze =\n+            TransportAnalyzeAction.analyze(req, registry, mockIndexService(), maxTokenCount);\n+        assertEquals(2, analyze.getTokens().size());\n+        assertWarnings(\"Using deprecated token filter [deprecated]\");\n+\n+        // normalizer\n+        req = new AnalyzeAction.Request();\n+        req.addTokenFilter(\"lowercase\");\n+        req.addTokenFilter(\"deprecated\");\n+        req.text(\"text\");\n+\n+        analyze =\n+            TransportAnalyzeAction.analyze(req, registry, mockIndexService(), maxTokenCount);\n+        assertEquals(1, analyze.getTokens().size());\n+        assertWarnings(\"Using deprecated token filter [deprecated]\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bcdd2b0c2bc3bd833606d12d61c7a67b40910cd5"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTg4NDkwMw==", "bodyText": "Because the default implementation of normalize delegates to create, so we get the warning from there instead.", "url": "https://github.com/elastic/elasticsearch/pull/50908#discussion_r365884903", "createdAt": "2020-01-13T16:03:04Z", "author": {"login": "romseygeek"}, "path": "server/src/test/java/org/elasticsearch/action/admin/indices/TransportAnalyzeActionTests.java", "diffHunk": "@@ -492,4 +512,28 @@ public void testExceedSetMaxTokenLimit() {\n         assertEquals(e.getMessage(), \"The number of tokens produced by calling _analyze has exceeded the allowed maximum of [\"\n             + idxMaxTokenCount + \"].\" + \" This limit can be set by changing the [index.analyze.max_token_count] index level setting.\");\n     }\n+\n+    public void testDeprecationWarnings() throws IOException {\n+        AnalyzeAction.Request req = new AnalyzeAction.Request();\n+        req.tokenizer(\"standard\");\n+        req.addTokenFilter(\"lowercase\");\n+        req.addTokenFilter(\"deprecated\");\n+        req.text(\"test text\");\n+\n+        AnalyzeAction.Response analyze =\n+            TransportAnalyzeAction.analyze(req, registry, mockIndexService(), maxTokenCount);\n+        assertEquals(2, analyze.getTokens().size());\n+        assertWarnings(\"Using deprecated token filter [deprecated]\");\n+\n+        // normalizer\n+        req = new AnalyzeAction.Request();\n+        req.addTokenFilter(\"lowercase\");\n+        req.addTokenFilter(\"deprecated\");\n+        req.text(\"text\");\n+\n+        analyze =\n+            TransportAnalyzeAction.analyze(req, registry, mockIndexService(), maxTokenCount);\n+        assertEquals(1, analyze.getTokens().size());\n+        assertWarnings(\"Using deprecated token filter [deprecated]\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTg4MDMxOA=="}, "originalCommit": {"oid": "bcdd2b0c2bc3bd833606d12d61c7a67b40910cd5"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTkwMTgwMQ==", "bodyText": "So that sounds like the \"normalize()\" method isn't actualy tested here? I saw we cover that in some other test though, so fine with whatever you decide doing here, I was just curious if this could be checked here through the \"_analyze\" API as well, but no problem it its too tricky I.", "url": "https://github.com/elastic/elasticsearch/pull/50908#discussion_r365901801", "createdAt": "2020-01-13T16:33:16Z", "author": {"login": "cbuescher"}, "path": "server/src/test/java/org/elasticsearch/action/admin/indices/TransportAnalyzeActionTests.java", "diffHunk": "@@ -492,4 +512,28 @@ public void testExceedSetMaxTokenLimit() {\n         assertEquals(e.getMessage(), \"The number of tokens produced by calling _analyze has exceeded the allowed maximum of [\"\n             + idxMaxTokenCount + \"].\" + \" This limit can be set by changing the [index.analyze.max_token_count] index level setting.\");\n     }\n+\n+    public void testDeprecationWarnings() throws IOException {\n+        AnalyzeAction.Request req = new AnalyzeAction.Request();\n+        req.tokenizer(\"standard\");\n+        req.addTokenFilter(\"lowercase\");\n+        req.addTokenFilter(\"deprecated\");\n+        req.text(\"test text\");\n+\n+        AnalyzeAction.Response analyze =\n+            TransportAnalyzeAction.analyze(req, registry, mockIndexService(), maxTokenCount);\n+        assertEquals(2, analyze.getTokens().size());\n+        assertWarnings(\"Using deprecated token filter [deprecated]\");\n+\n+        // normalizer\n+        req = new AnalyzeAction.Request();\n+        req.addTokenFilter(\"lowercase\");\n+        req.addTokenFilter(\"deprecated\");\n+        req.text(\"text\");\n+\n+        analyze =\n+            TransportAnalyzeAction.analyze(req, registry, mockIndexService(), maxTokenCount);\n+        assertEquals(1, analyze.getTokens().size());\n+        assertWarnings(\"Using deprecated token filter [deprecated]\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTg4MDMxOA=="}, "originalCommit": {"oid": "bcdd2b0c2bc3bd833606d12d61c7a67b40910cd5"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTkwNjU3OQ==", "bodyText": "No, it's tested, but in order to make it fail you can't just remove the method (because that then delegates to create()), you have to have an implementation that doesn't emit a warning", "url": "https://github.com/elastic/elasticsearch/pull/50908#discussion_r365906579", "createdAt": "2020-01-13T16:41:54Z", "author": {"login": "romseygeek"}, "path": "server/src/test/java/org/elasticsearch/action/admin/indices/TransportAnalyzeActionTests.java", "diffHunk": "@@ -492,4 +512,28 @@ public void testExceedSetMaxTokenLimit() {\n         assertEquals(e.getMessage(), \"The number of tokens produced by calling _analyze has exceeded the allowed maximum of [\"\n             + idxMaxTokenCount + \"].\" + \" This limit can be set by changing the [index.analyze.max_token_count] index level setting.\");\n     }\n+\n+    public void testDeprecationWarnings() throws IOException {\n+        AnalyzeAction.Request req = new AnalyzeAction.Request();\n+        req.tokenizer(\"standard\");\n+        req.addTokenFilter(\"lowercase\");\n+        req.addTokenFilter(\"deprecated\");\n+        req.text(\"test text\");\n+\n+        AnalyzeAction.Response analyze =\n+            TransportAnalyzeAction.analyze(req, registry, mockIndexService(), maxTokenCount);\n+        assertEquals(2, analyze.getTokens().size());\n+        assertWarnings(\"Using deprecated token filter [deprecated]\");\n+\n+        // normalizer\n+        req = new AnalyzeAction.Request();\n+        req.addTokenFilter(\"lowercase\");\n+        req.addTokenFilter(\"deprecated\");\n+        req.text(\"text\");\n+\n+        analyze =\n+            TransportAnalyzeAction.analyze(req, registry, mockIndexService(), maxTokenCount);\n+        assertEquals(1, analyze.getTokens().size());\n+        assertWarnings(\"Using deprecated token filter [deprecated]\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTg4MDMxOA=="}, "originalCommit": {"oid": "bcdd2b0c2bc3bd833606d12d61c7a67b40910cd5"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTkwNzA1Mg==", "bodyText": "Oh, I've just realised that we're talking about the AnalyzeAction - this always uses create() rather than normalize(), and we should probably change that.", "url": "https://github.com/elastic/elasticsearch/pull/50908#discussion_r365907052", "createdAt": "2020-01-13T16:42:51Z", "author": {"login": "romseygeek"}, "path": "server/src/test/java/org/elasticsearch/action/admin/indices/TransportAnalyzeActionTests.java", "diffHunk": "@@ -492,4 +512,28 @@ public void testExceedSetMaxTokenLimit() {\n         assertEquals(e.getMessage(), \"The number of tokens produced by calling _analyze has exceeded the allowed maximum of [\"\n             + idxMaxTokenCount + \"].\" + \" This limit can be set by changing the [index.analyze.max_token_count] index level setting.\");\n     }\n+\n+    public void testDeprecationWarnings() throws IOException {\n+        AnalyzeAction.Request req = new AnalyzeAction.Request();\n+        req.tokenizer(\"standard\");\n+        req.addTokenFilter(\"lowercase\");\n+        req.addTokenFilter(\"deprecated\");\n+        req.text(\"test text\");\n+\n+        AnalyzeAction.Response analyze =\n+            TransportAnalyzeAction.analyze(req, registry, mockIndexService(), maxTokenCount);\n+        assertEquals(2, analyze.getTokens().size());\n+        assertWarnings(\"Using deprecated token filter [deprecated]\");\n+\n+        // normalizer\n+        req = new AnalyzeAction.Request();\n+        req.addTokenFilter(\"lowercase\");\n+        req.addTokenFilter(\"deprecated\");\n+        req.text(\"text\");\n+\n+        analyze =\n+            TransportAnalyzeAction.analyze(req, registry, mockIndexService(), maxTokenCount);\n+        assertEquals(1, analyze.getTokens().size());\n+        assertWarnings(\"Using deprecated token filter [deprecated]\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTg4MDMxOA=="}, "originalCommit": {"oid": "bcdd2b0c2bc3bd833606d12d61c7a67b40910cd5"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTk5MjA2Mg==", "bodyText": "we should probably change that\n\nThis can most likely be done in a follow up PR though, I just wanted to understand whats going on here and which of the two methods in the DeprecatedTokenFilterFactory in this test is supposed to fire the warning, currently they emit the same text so its hard to tell which code path is checked.", "url": "https://github.com/elastic/elasticsearch/pull/50908#discussion_r365992062", "createdAt": "2020-01-13T19:41:57Z", "author": {"login": "cbuescher"}, "path": "server/src/test/java/org/elasticsearch/action/admin/indices/TransportAnalyzeActionTests.java", "diffHunk": "@@ -492,4 +512,28 @@ public void testExceedSetMaxTokenLimit() {\n         assertEquals(e.getMessage(), \"The number of tokens produced by calling _analyze has exceeded the allowed maximum of [\"\n             + idxMaxTokenCount + \"].\" + \" This limit can be set by changing the [index.analyze.max_token_count] index level setting.\");\n     }\n+\n+    public void testDeprecationWarnings() throws IOException {\n+        AnalyzeAction.Request req = new AnalyzeAction.Request();\n+        req.tokenizer(\"standard\");\n+        req.addTokenFilter(\"lowercase\");\n+        req.addTokenFilter(\"deprecated\");\n+        req.text(\"test text\");\n+\n+        AnalyzeAction.Response analyze =\n+            TransportAnalyzeAction.analyze(req, registry, mockIndexService(), maxTokenCount);\n+        assertEquals(2, analyze.getTokens().size());\n+        assertWarnings(\"Using deprecated token filter [deprecated]\");\n+\n+        // normalizer\n+        req = new AnalyzeAction.Request();\n+        req.addTokenFilter(\"lowercase\");\n+        req.addTokenFilter(\"deprecated\");\n+        req.text(\"text\");\n+\n+        analyze =\n+            TransportAnalyzeAction.analyze(req, registry, mockIndexService(), maxTokenCount);\n+        assertEquals(1, analyze.getTokens().size());\n+        assertWarnings(\"Using deprecated token filter [deprecated]\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTg4MDMxOA=="}, "originalCommit": {"oid": "bcdd2b0c2bc3bd833606d12d61c7a67b40910cd5"}, "originalPosition": 69}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MTMxNTI2OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/index/analysis/AnalysisRegistry.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xM1QyMTowNTozOVrOFdEihA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xM1QyMTowNTozOVrOFdEihA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjAyNzM5Ng==", "bodyText": "We also throw exceptions in some cases so it's not only about deprecations ?", "url": "https://github.com/elastic/elasticsearch/pull/50908#discussion_r366027396", "createdAt": "2020-01-13T21:05:39Z", "author": {"login": "jimczi"}, "path": "server/src/main/java/org/elasticsearch/index/analysis/AnalysisRegistry.java", "diffHunk": "@@ -626,4 +632,17 @@ private void processNormalizerFactory(\n         NamedAnalyzer normalizer = new NamedAnalyzer(name, normalizerFactory.scope(), normalizerF);\n         normalizers.put(name, normalizer);\n     }\n+\n+    // Deprecation warnings are emitted when actual TokenStreams are built; this is usually\n+    // too late to be useful, so we build an empty tokenstream at construction time and\n+    // use it, to ensure that warnings are emitted immediately.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bcdd2b0c2bc3bd833606d12d61c7a67b40910cd5"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MTMxNzQyOnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/index/analysis/AnalysisRegistryTests.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xM1QyMTowNjoyOVrOFdEjzw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xM1QyMTowNjoyOVrOFdEjzw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjAyNzcyNw==", "bodyText": "Can you also add a test that throws an exception ?", "url": "https://github.com/elastic/elasticsearch/pull/50908#discussion_r366027727", "createdAt": "2020-01-13T21:06:29Z", "author": {"login": "jimczi"}, "path": "server/src/test/java/org/elasticsearch/index/analysis/AnalysisRegistryTests.java", "diffHunk": "@@ -264,4 +271,90 @@ public void testEnsureCloseInvocationProperlyDelegated() throws IOException {\n         registry.close();\n         verify(mock).close();\n     }\n+\n+    public void testDeprecations() throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bcdd2b0c2bc3bd833606d12d61c7a67b40910cd5"}, "originalPosition": 50}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4652, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}