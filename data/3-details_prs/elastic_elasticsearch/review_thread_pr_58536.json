{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM5OTc0NzA0", "number": 58536, "reviewThreads": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQyMTozODozNFrOEI7upQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMjoxMTo0MFrOEJHByA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3ODAyNjYxOnYy", "diffSide": "RIGHT", "path": "docs/reference/eql/eql-search-api.asciidoc", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQyMTozODozNFrOGpMugw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQyMDo0OTozMFrOGpuTSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg1MzMxNQ==", "bodyText": "@jrodewig is there a way to ignore the \"fields\" field? This data is used internally and it might be that in the future, we'll remove it from the final response (so only _source is included).", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r445853315", "createdAt": "2020-06-25T21:38:34Z", "author": {"login": "costin"}, "path": "docs/reference/eql/eql-search-api.asciidoc", "diffHunk": "@@ -534,7 +534,12 @@ in ascending order.\n         },\n         \"sort\": [\n           1607252647000\n-        ]\n+        ],\n+        \"fields\": {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "86181b9c1911f695a0ee8aff447041e4e48089f0"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE1NzYzMA==", "bodyText": "You can use the filter_path query param to exclude fields from the output.\nYou can add the query param using a //TEST comment so it's not visible to users.\nThis should fail gracefully. The request won't return an error if fields is later removed from the response.\nHere's an example with a basic query:\n[source,console]\n----\nGET /sec_logs/_eql/search\n{\n  \"query\": \"\"\"\n    process where process.name == \"cmd.exe\"\n  \"\"\"\n}\n----\n// TEST[s/search/search\\?filter_path\\=\\-\\*\\.events\\.\\*fields/]\n\nA sequence query will need to use a different filter because the response format is different.\n[source,console]\n----\nGET /my_index/_eql/search\n{\n  \"query\": \"\"\"\n    sequence by agent.id\n      [ file where file.name == \"cmd.exe\" and agent.id != \"my_user\" ]\n      [ process where stringContains(process.path, \"regsvr32\") ]\n  \"\"\"\n}\n----\n// TEST[s/search/search\\?filter_path\\=\\-\\*\\.sequences\\.events\\.\\*fields/]", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446157630", "createdAt": "2020-06-26T12:38:11Z", "author": {"login": "jrodewig"}, "path": "docs/reference/eql/eql-search-api.asciidoc", "diffHunk": "@@ -534,7 +534,12 @@ in ascending order.\n         },\n         \"sort\": [\n           1607252647000\n-        ]\n+        ],\n+        \"fields\": {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg1MzMxNQ=="}, "originalCommit": {"oid": "86181b9c1911f695a0ee8aff447041e4e48089f0"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQwMjE5Nw==", "bodyText": "For some reason this didn't seem to work consistently so I left things in a bit of a mixed state, namely the fields tag is still in there but I also added the TESTRESPONSE; the idea being that the user should not depend on whether fields (or even sort) are in the response.\nCan you please take a look at it after this PR gets merged?", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446402197", "createdAt": "2020-06-26T20:46:38Z", "author": {"login": "costin"}, "path": "docs/reference/eql/eql-search-api.asciidoc", "diffHunk": "@@ -534,7 +534,12 @@ in ascending order.\n         },\n         \"sort\": [\n           1607252647000\n-        ]\n+        ],\n+        \"fields\": {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg1MzMxNQ=="}, "originalCommit": {"oid": "86181b9c1911f695a0ee8aff447041e4e48089f0"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQwMzQwMw==", "bodyText": "Sure thing. Thanks!", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446403403", "createdAt": "2020-06-26T20:49:30Z", "author": {"login": "jrodewig"}, "path": "docs/reference/eql/eql-search-api.asciidoc", "diffHunk": "@@ -534,7 +534,12 @@ in ascending order.\n         },\n         \"sort\": [\n           1607252647000\n-        ]\n+        ],\n+        \"fields\": {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg1MzMxNQ=="}, "originalCommit": {"oid": "86181b9c1911f695a0ee8aff447041e4e48089f0"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTEyNzM1OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/assembler/Criterion.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQwNzo1MToxOVrOGpXOEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMDozMjoxOVrOGpcCvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAyNTIzNQ==", "bodyText": "Maybe name these with the plural variant, since they are arrays?", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446025235", "createdAt": "2020-06-26T07:51:19Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/assembler/Criterion.java", "diffHunk": "@@ -9,25 +9,35 @@\n import org.elasticsearch.search.SearchHit;\n import org.elasticsearch.search.builder.SearchSourceBuilder;\n import org.elasticsearch.xpack.eql.EqlIllegalArgumentException;\n+import org.elasticsearch.xpack.eql.execution.search.QueryRequest;\n import org.elasticsearch.xpack.ql.execution.search.extractor.HitExtractor;\n \n import java.util.List;\n \n-public class Criterion {\n+public class Criterion implements QueryRequest {\n \n     private final SearchSourceBuilder searchSource;\n     private final List<HitExtractor> keyExtractors;\n     private final HitExtractor timestampExtractor;\n     private final HitExtractor tiebreakerExtractor;\n \n+    // search after markers\n+    private Object[] startMarker;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwNDI1Mw==", "bodyText": "I had them as such but in case of a timestamp there's only one marker. Plus the fact that it's one or multiple fields is an implementation detail in the end.\nHence why talking a marker as an entity (which currently happens to be an array of objects) seems better.", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446104253", "createdAt": "2020-06-26T10:32:19Z", "author": {"login": "costin"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/assembler/Criterion.java", "diffHunk": "@@ -9,25 +9,35 @@\n import org.elasticsearch.search.SearchHit;\n import org.elasticsearch.search.builder.SearchSourceBuilder;\n import org.elasticsearch.xpack.eql.EqlIllegalArgumentException;\n+import org.elasticsearch.xpack.eql.execution.search.QueryRequest;\n import org.elasticsearch.xpack.ql.execution.search.extractor.HitExtractor;\n \n import java.util.List;\n \n-public class Criterion {\n+public class Criterion implements QueryRequest {\n \n     private final SearchSourceBuilder searchSource;\n     private final List<HitExtractor> keyExtractors;\n     private final HitExtractor timestampExtractor;\n     private final HitExtractor tiebreakerExtractor;\n \n+    // search after markers\n+    private Object[] startMarker;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAyNTIzNQ=="}, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTE1NTg0OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/assembler/Criterion.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQwODowMDo1NFrOGpXgIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMDozMzowMFrOGpcD3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAyOTg1OQ==", "bodyText": "Since the markers can only be a combination of timestamp and tiebreaker OR only the timestamp, maybe abstract these two variants away in a TiebreakerMarker and TimestampMarker or something around these lines?", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446029859", "createdAt": "2020-06-26T08:00:54Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/assembler/Criterion.java", "diffHunk": "@@ -64,8 +74,34 @@ public long timestamp(SearchHit hit) {\n         throw new EqlIllegalArgumentException(\"Expected tiebreaker to be Comparable but got {}\", tb);\n     }\n \n-    public void fromMarkers(Object[] markers) {\n-        // TODO: this is likely to be rewritten afterwards\n-        searchSource.searchAfter(markers);\n+    public Object[] startMarker() {\n+        return startMarker;\n+    }\n+\n+    public Object[] stopMarker() {\n+        return stopMarker;\n+    }\n+\n+    private Object[] marker(SearchHit hit) {\n+        long timestamp = timestamp(hit);\n+        Object tiebreaker = null;\n+        if (tiebreakerExtractor() != null) {\n+            tiebreaker = tiebreaker(hit);\n+        }\n+\n+        return tiebreaker != null ? new Object[] { timestamp, tiebreaker } : new Object[] { timestamp };", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwNDU0MQ==", "bodyText": "I think the whole marker bit can be encapsulated in the Criterion itself, I plan to revisit this when working on the pagination.", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446104541", "createdAt": "2020-06-26T10:33:00Z", "author": {"login": "costin"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/assembler/Criterion.java", "diffHunk": "@@ -64,8 +74,34 @@ public long timestamp(SearchHit hit) {\n         throw new EqlIllegalArgumentException(\"Expected tiebreaker to be Comparable but got {}\", tb);\n     }\n \n-    public void fromMarkers(Object[] markers) {\n-        // TODO: this is likely to be rewritten afterwards\n-        searchSource.searchAfter(markers);\n+    public Object[] startMarker() {\n+        return startMarker;\n+    }\n+\n+    public Object[] stopMarker() {\n+        return stopMarker;\n+    }\n+\n+    private Object[] marker(SearchHit hit) {\n+        long timestamp = timestamp(hit);\n+        Object tiebreaker = null;\n+        if (tiebreakerExtractor() != null) {\n+            tiebreaker = tiebreaker(hit);\n+        }\n+\n+        return tiebreaker != null ? new Object[] { timestamp, tiebreaker } : new Object[] { timestamp };", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAyOTg1OQ=="}, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 59}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTI0NjEzOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/assembler/KeyAndOrdinal.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQwODozMDozOVrOGpYZNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxODoxMzo1OVrOGpqTOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA0NDQ3MQ==", "bodyText": "If the tiebreaker is not set, why still logging the square brackets?", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446044471", "createdAt": "2020-06-26T08:30:39Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/assembler/KeyAndOrdinal.java", "diffHunk": "@@ -18,4 +20,30 @@\n         this.timestamp = timestamp;\n         this.tiebreaker = tiebreaker;\n     }\n+\n+    @Override\n+    public int hashCode() {\n+        return Objects.hash(key, timestamp, tiebreaker);\n+    }\n+    \n+    @Override\n+    public boolean equals(Object obj) {\n+        if (this == obj) {\n+            return true;\n+        }\n+        \n+        if (obj == null || getClass() != obj.getClass()) {\n+            return false;\n+        }\n+        \n+        KeyAndOrdinal other = (KeyAndOrdinal) obj;\n+        return Objects.equals(key, other.key)\n+                && Objects.equals(timestamp, other.timestamp)\n+                && Objects.equals(tiebreaker, other.tiebreaker);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return key + \"[\" + timestamp + \"][\" + (tiebreaker != null ? Objects.toString(tiebreaker) : \"\") + \"]\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwNDgwMg==", "bodyText": "To indicate there is no tiebreaker - I find the message more consistent to be [..][] vs [..]", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446104802", "createdAt": "2020-06-26T10:33:36Z", "author": {"login": "costin"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/assembler/KeyAndOrdinal.java", "diffHunk": "@@ -18,4 +20,30 @@\n         this.timestamp = timestamp;\n         this.tiebreaker = tiebreaker;\n     }\n+\n+    @Override\n+    public int hashCode() {\n+        return Objects.hash(key, timestamp, tiebreaker);\n+    }\n+    \n+    @Override\n+    public boolean equals(Object obj) {\n+        if (this == obj) {\n+            return true;\n+        }\n+        \n+        if (obj == null || getClass() != obj.getClass()) {\n+            return false;\n+        }\n+        \n+        KeyAndOrdinal other = (KeyAndOrdinal) obj;\n+        return Objects.equals(key, other.key)\n+                && Objects.equals(timestamp, other.timestamp)\n+                && Objects.equals(tiebreaker, other.tiebreaker);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return key + \"[\" + timestamp + \"][\" + (tiebreaker != null ? Objects.toString(tiebreaker) : \"\") + \"]\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA0NDQ3MQ=="}, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwNTYyMA==", "bodyText": "Myself, I wouldn't mind to have [] when there is no tiebreaker.", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446105620", "createdAt": "2020-06-26T10:35:37Z", "author": {"login": "matriv"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/assembler/KeyAndOrdinal.java", "diffHunk": "@@ -18,4 +20,30 @@\n         this.timestamp = timestamp;\n         this.tiebreaker = tiebreaker;\n     }\n+\n+    @Override\n+    public int hashCode() {\n+        return Objects.hash(key, timestamp, tiebreaker);\n+    }\n+    \n+    @Override\n+    public boolean equals(Object obj) {\n+        if (this == obj) {\n+            return true;\n+        }\n+        \n+        if (obj == null || getClass() != obj.getClass()) {\n+            return false;\n+        }\n+        \n+        KeyAndOrdinal other = (KeyAndOrdinal) obj;\n+        return Objects.equals(key, other.key)\n+                && Objects.equals(timestamp, other.timestamp)\n+                && Objects.equals(tiebreaker, other.tiebreaker);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return key + \"[\" + timestamp + \"][\" + (tiebreaker != null ? Objects.toString(tiebreaker) : \"\") + \"]\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA0NDQ3MQ=="}, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjExODUxNA==", "bodyText": "How about specifying that there is no tiebreaker? (ie [...][no tiebreaker])", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446118514", "createdAt": "2020-06-26T11:07:47Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/assembler/KeyAndOrdinal.java", "diffHunk": "@@ -18,4 +20,30 @@\n         this.timestamp = timestamp;\n         this.tiebreaker = tiebreaker;\n     }\n+\n+    @Override\n+    public int hashCode() {\n+        return Objects.hash(key, timestamp, tiebreaker);\n+    }\n+    \n+    @Override\n+    public boolean equals(Object obj) {\n+        if (this == obj) {\n+            return true;\n+        }\n+        \n+        if (obj == null || getClass() != obj.getClass()) {\n+            return false;\n+        }\n+        \n+        KeyAndOrdinal other = (KeyAndOrdinal) obj;\n+        return Objects.equals(key, other.key)\n+                && Objects.equals(timestamp, other.timestamp)\n+                && Objects.equals(tiebreaker, other.tiebreaker);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return key + \"[\" + timestamp + \"][\" + (tiebreaker != null ? Objects.toString(tiebreaker) : \"\") + \"]\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA0NDQ3MQ=="}, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjMzNzg0OQ==", "bodyText": "That's quite verbose...", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446337849", "createdAt": "2020-06-26T18:13:59Z", "author": {"login": "costin"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/assembler/KeyAndOrdinal.java", "diffHunk": "@@ -18,4 +20,30 @@\n         this.timestamp = timestamp;\n         this.tiebreaker = tiebreaker;\n     }\n+\n+    @Override\n+    public int hashCode() {\n+        return Objects.hash(key, timestamp, tiebreaker);\n+    }\n+    \n+    @Override\n+    public boolean equals(Object obj) {\n+        if (this == obj) {\n+            return true;\n+        }\n+        \n+        if (obj == null || getClass() != obj.getClass()) {\n+            return false;\n+        }\n+        \n+        KeyAndOrdinal other = (KeyAndOrdinal) obj;\n+        return Objects.equals(key, other.key)\n+                && Objects.equals(timestamp, other.timestamp)\n+                && Objects.equals(tiebreaker, other.tiebreaker);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return key + \"[\" + timestamp + \"][\" + (tiebreaker != null ? Objects.toString(tiebreaker) : \"\") + \"]\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA0NDQ3MQ=="}, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTI2NjU3OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/assembler/SequenceRuntime.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQwODozNzowNFrOGpYmUg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMDozNDoyMVrOGpcGHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA0NzgyNg==", "bodyText": "while(iterator.hasNext())?", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446047826", "createdAt": "2020-06-26T08:37:04Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/assembler/SequenceRuntime.java", "diffHunk": "@@ -26,105 +31,103 @@\n  */\n class SequenceRuntime implements Executable {\n \n+    private final Logger log = LogManager.getLogger(SequenceRuntime.class);\n+\n     private final List<Criterion> criteria;\n     // NB: just like in a list, this represents the total number of stages yet counting starts at 0\n     private final int numberOfStages;\n     private final SequenceStateMachine stateMachine;\n     private final QueryClient queryClient;\n+    private final boolean descending;\n+\n     private long startTime;\n \n-    SequenceRuntime(List<Criterion> criteria, QueryClient queryClient) {\n+    SequenceRuntime(List<Criterion> criteria, QueryClient queryClient, boolean descending, Limit limit) {\n         this.criteria = criteria;\n         this.numberOfStages = criteria.size();\n         this.queryClient = queryClient;\n         boolean hasTiebreaker = criteria.get(0).tiebreakerExtractor() != null;\n-        this.stateMachine = new SequenceStateMachine(numberOfStages, hasTiebreaker);\n+        this.stateMachine = new SequenceStateMachine(numberOfStages, hasTiebreaker, limit);\n+\n+        this.descending = descending;\n     }\n \n     @Override\n-    public void execute(ActionListener<Results> resultsListener) {\n+    public void execute(ActionListener<Payload> listener) {\n         startTime = System.currentTimeMillis();\n-        startSequencing(resultsListener);\n-    }\n-\n-    private void startSequencing(ActionListener<Results> resultsListener) {\n-        Criterion firstStage = criteria.get(0);\n-        queryClient.query(firstStage.searchSource(), wrap(payload -> {\n-\n-            // 1. execute last stage (find keys)\n-            startTracking(payload, resultsListener);\n-\n-            // 2. go descending through the rest of the stages, while adjusting the query\n-            inspectStage(1, resultsListener);\n-\n-        }, resultsListener::onFailure));\n+        log.info(\"Starting sequencing\");\n+        queryStage(0, listener);\n     }\n \n-    private void startTracking(Payload<SearchHit> payload, ActionListener<Results> resultsListener) {\n-        Criterion lastCriterion = criteria.get(0);\n-        List<SearchHit> hits = payload.values();\n-\n-        // nothing matches the first query, bail out early\n-        if (hits.isEmpty()) {\n-            resultsListener.onResponse(assembleResults());\n-            return;\n-        }\n-        \n-        long tMin = Long.MAX_VALUE;\n-        long tMax = Long.MIN_VALUE;\n-        \n-        Comparable<Object> bMin = null;\n-        // we could have extracted that in the hit loop but that if would have been evaluated\n-        // for every document\n-        if (hits.isEmpty() == false) {\n-            tMin = lastCriterion.timestamp(hits.get(0));\n-            tMax = lastCriterion.timestamp(hits.get(hits.size() - 1));\n-            \n-            if (lastCriterion.tiebreakerExtractor() != null) {\n-               bMin = lastCriterion.tiebreaker(hits.get(0));\n-            }\n-        }\n-\n-        for (SearchHit hit : hits) {\n-            KeyAndOrdinal ko = findKey(hit, lastCriterion);\n-            Sequence seq = new Sequence(ko.key, numberOfStages, ko.timestamp, ko.tiebreaker, hit);\n-            stateMachine.trackSequence(seq, tMin, tMax);\n-        }\n-        stateMachine.setTimestampMarker(0, tMin);\n-        if (bMin != null) {\n-            stateMachine.setTiebreakerMarker(0, bMin);\n-        }\n-    }\n-\n-    private void inspectStage(int stage, ActionListener<Results> resultsListener) {\n+    private void queryStage(int stage, ActionListener<Payload> listener) {\n         // sequencing is done, return results\n-        if (stage == numberOfStages) {\n-            resultsListener.onResponse(assembleResults());\n+        if (hasFinished(stage)) {\n+            listener.onResponse(sequencePayload());\n             return;\n         }\n+\n         // else continue finding matches\n         Criterion currentCriterion = criteria.get(stage);\n-        // narrow by the previous stage timestamp marker\n-        currentCriterion.fromMarkers(stateMachine.getMarkers(stage - 1));\n+        if (stage > 0) {\n+            // FIXME: revisit this during pagination since the second criterion need to be limited to the range of the first one\n+            // narrow by the previous stage timestamp marker\n+\n+            Criterion previous = criteria.get(stage - 1);\n+            // if DESC, flip the markers (the stop becomes the start due to the reverse order), otherwise keep it accordingly\n+            Object[] marker = descending && stage == 1 ? previous.stopMarker() : previous.startMarker();\n+            currentCriterion.useMarker(marker);\n+        }\n         \n-        queryClient.query(currentCriterion.searchSource(), wrap(payload -> {\n-            findMatches(stage, payload);\n-            inspectStage(stage + 1, resultsListener);\n-        }, resultsListener::onFailure));\n+        log.info(\"Querying stage {}\", stage);\n+        queryClient.query(currentCriterion, wrap(payload -> {\n+            List<SearchHit> hits = payload.values();\n+\n+            // nothing matches the query -> bail out\n+            // FIXME: needs to be changed when doing pagination\n+            if (hits.isEmpty()) {\n+                listener.onResponse(sequencePayload());\n+                return;\n+            }\n+\n+            findMatches(stage, hits);\n+            queryStage(stage + 1, listener);\n+        }, listener::onFailure));\n     }\n \n-    private void findMatches(int currentStage, Payload<SearchHit> payload) {\n-        Criterion currentCriterion = criteria.get(currentStage);\n-        List<SearchHit> hits = payload.values();\n-        \n+    // hits are guaranteed to be non-empty\n+    private void findMatches(int currentStage, List<SearchHit> hits) {\n+        // update criterion\n+        Criterion criterion = criteria.get(currentStage);\n+        criterion.startMarker(hits.get(0));\n+        criterion.stopMarker(hits.get(hits.size() - 1));\n+\n         // break the results per key\n-        for (SearchHit hit : hits) {\n-            KeyAndOrdinal ko = findKey(hit, currentCriterion);\n-            stateMachine.match(currentStage, ko.key, ko.timestamp, ko.tiebreaker, hit);\n+        // when dealing with descending order, queries outside the base are ASC (search_before)\n+        // so look at the data in reverse (that is DESC)\n+        Iterator<SearchHit> iterator = descending ? new ReversedIterator<>(hits) : hits.iterator();\n+\n+        for (; iterator.hasNext();) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 174}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwNTExNw==", "bodyText": "same thing - I favor for since it's the most generic; in fact it might make sense to move the iterator declaration inside its declaration as well.", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446105117", "createdAt": "2020-06-26T10:34:21Z", "author": {"login": "costin"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/assembler/SequenceRuntime.java", "diffHunk": "@@ -26,105 +31,103 @@\n  */\n class SequenceRuntime implements Executable {\n \n+    private final Logger log = LogManager.getLogger(SequenceRuntime.class);\n+\n     private final List<Criterion> criteria;\n     // NB: just like in a list, this represents the total number of stages yet counting starts at 0\n     private final int numberOfStages;\n     private final SequenceStateMachine stateMachine;\n     private final QueryClient queryClient;\n+    private final boolean descending;\n+\n     private long startTime;\n \n-    SequenceRuntime(List<Criterion> criteria, QueryClient queryClient) {\n+    SequenceRuntime(List<Criterion> criteria, QueryClient queryClient, boolean descending, Limit limit) {\n         this.criteria = criteria;\n         this.numberOfStages = criteria.size();\n         this.queryClient = queryClient;\n         boolean hasTiebreaker = criteria.get(0).tiebreakerExtractor() != null;\n-        this.stateMachine = new SequenceStateMachine(numberOfStages, hasTiebreaker);\n+        this.stateMachine = new SequenceStateMachine(numberOfStages, hasTiebreaker, limit);\n+\n+        this.descending = descending;\n     }\n \n     @Override\n-    public void execute(ActionListener<Results> resultsListener) {\n+    public void execute(ActionListener<Payload> listener) {\n         startTime = System.currentTimeMillis();\n-        startSequencing(resultsListener);\n-    }\n-\n-    private void startSequencing(ActionListener<Results> resultsListener) {\n-        Criterion firstStage = criteria.get(0);\n-        queryClient.query(firstStage.searchSource(), wrap(payload -> {\n-\n-            // 1. execute last stage (find keys)\n-            startTracking(payload, resultsListener);\n-\n-            // 2. go descending through the rest of the stages, while adjusting the query\n-            inspectStage(1, resultsListener);\n-\n-        }, resultsListener::onFailure));\n+        log.info(\"Starting sequencing\");\n+        queryStage(0, listener);\n     }\n \n-    private void startTracking(Payload<SearchHit> payload, ActionListener<Results> resultsListener) {\n-        Criterion lastCriterion = criteria.get(0);\n-        List<SearchHit> hits = payload.values();\n-\n-        // nothing matches the first query, bail out early\n-        if (hits.isEmpty()) {\n-            resultsListener.onResponse(assembleResults());\n-            return;\n-        }\n-        \n-        long tMin = Long.MAX_VALUE;\n-        long tMax = Long.MIN_VALUE;\n-        \n-        Comparable<Object> bMin = null;\n-        // we could have extracted that in the hit loop but that if would have been evaluated\n-        // for every document\n-        if (hits.isEmpty() == false) {\n-            tMin = lastCriterion.timestamp(hits.get(0));\n-            tMax = lastCriterion.timestamp(hits.get(hits.size() - 1));\n-            \n-            if (lastCriterion.tiebreakerExtractor() != null) {\n-               bMin = lastCriterion.tiebreaker(hits.get(0));\n-            }\n-        }\n-\n-        for (SearchHit hit : hits) {\n-            KeyAndOrdinal ko = findKey(hit, lastCriterion);\n-            Sequence seq = new Sequence(ko.key, numberOfStages, ko.timestamp, ko.tiebreaker, hit);\n-            stateMachine.trackSequence(seq, tMin, tMax);\n-        }\n-        stateMachine.setTimestampMarker(0, tMin);\n-        if (bMin != null) {\n-            stateMachine.setTiebreakerMarker(0, bMin);\n-        }\n-    }\n-\n-    private void inspectStage(int stage, ActionListener<Results> resultsListener) {\n+    private void queryStage(int stage, ActionListener<Payload> listener) {\n         // sequencing is done, return results\n-        if (stage == numberOfStages) {\n-            resultsListener.onResponse(assembleResults());\n+        if (hasFinished(stage)) {\n+            listener.onResponse(sequencePayload());\n             return;\n         }\n+\n         // else continue finding matches\n         Criterion currentCriterion = criteria.get(stage);\n-        // narrow by the previous stage timestamp marker\n-        currentCriterion.fromMarkers(stateMachine.getMarkers(stage - 1));\n+        if (stage > 0) {\n+            // FIXME: revisit this during pagination since the second criterion need to be limited to the range of the first one\n+            // narrow by the previous stage timestamp marker\n+\n+            Criterion previous = criteria.get(stage - 1);\n+            // if DESC, flip the markers (the stop becomes the start due to the reverse order), otherwise keep it accordingly\n+            Object[] marker = descending && stage == 1 ? previous.stopMarker() : previous.startMarker();\n+            currentCriterion.useMarker(marker);\n+        }\n         \n-        queryClient.query(currentCriterion.searchSource(), wrap(payload -> {\n-            findMatches(stage, payload);\n-            inspectStage(stage + 1, resultsListener);\n-        }, resultsListener::onFailure));\n+        log.info(\"Querying stage {}\", stage);\n+        queryClient.query(currentCriterion, wrap(payload -> {\n+            List<SearchHit> hits = payload.values();\n+\n+            // nothing matches the query -> bail out\n+            // FIXME: needs to be changed when doing pagination\n+            if (hits.isEmpty()) {\n+                listener.onResponse(sequencePayload());\n+                return;\n+            }\n+\n+            findMatches(stage, hits);\n+            queryStage(stage + 1, listener);\n+        }, listener::onFailure));\n     }\n \n-    private void findMatches(int currentStage, Payload<SearchHit> payload) {\n-        Criterion currentCriterion = criteria.get(currentStage);\n-        List<SearchHit> hits = payload.values();\n-        \n+    // hits are guaranteed to be non-empty\n+    private void findMatches(int currentStage, List<SearchHit> hits) {\n+        // update criterion\n+        Criterion criterion = criteria.get(currentStage);\n+        criterion.startMarker(hits.get(0));\n+        criterion.stopMarker(hits.get(hits.size() - 1));\n+\n         // break the results per key\n-        for (SearchHit hit : hits) {\n-            KeyAndOrdinal ko = findKey(hit, currentCriterion);\n-            stateMachine.match(currentStage, ko.key, ko.timestamp, ko.tiebreaker, hit);\n+        // when dealing with descending order, queries outside the base are ASC (search_before)\n+        // so look at the data in reverse (that is DESC)\n+        Iterator<SearchHit> iterator = descending ? new ReversedIterator<>(hits) : hits.iterator();\n+\n+        for (; iterator.hasNext();) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA0NzgyNg=="}, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 174}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTI3NDU0OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/assembler/SequenceRuntime.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQwODozOTo0NFrOGpYrZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMDozNzowMFrOGpcKRg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA0OTEyNA==", "bodyText": "Shouldn't this be an OR condition? Or am I missing something...", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446049124", "createdAt": "2020-06-26T08:39:44Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/assembler/SequenceRuntime.java", "diffHunk": "@@ -26,105 +31,103 @@\n  */\n class SequenceRuntime implements Executable {\n \n+    private final Logger log = LogManager.getLogger(SequenceRuntime.class);\n+\n     private final List<Criterion> criteria;\n     // NB: just like in a list, this represents the total number of stages yet counting starts at 0\n     private final int numberOfStages;\n     private final SequenceStateMachine stateMachine;\n     private final QueryClient queryClient;\n+    private final boolean descending;\n+\n     private long startTime;\n \n-    SequenceRuntime(List<Criterion> criteria, QueryClient queryClient) {\n+    SequenceRuntime(List<Criterion> criteria, QueryClient queryClient, boolean descending, Limit limit) {\n         this.criteria = criteria;\n         this.numberOfStages = criteria.size();\n         this.queryClient = queryClient;\n         boolean hasTiebreaker = criteria.get(0).tiebreakerExtractor() != null;\n-        this.stateMachine = new SequenceStateMachine(numberOfStages, hasTiebreaker);\n+        this.stateMachine = new SequenceStateMachine(numberOfStages, hasTiebreaker, limit);\n+\n+        this.descending = descending;\n     }\n \n     @Override\n-    public void execute(ActionListener<Results> resultsListener) {\n+    public void execute(ActionListener<Payload> listener) {\n         startTime = System.currentTimeMillis();\n-        startSequencing(resultsListener);\n-    }\n-\n-    private void startSequencing(ActionListener<Results> resultsListener) {\n-        Criterion firstStage = criteria.get(0);\n-        queryClient.query(firstStage.searchSource(), wrap(payload -> {\n-\n-            // 1. execute last stage (find keys)\n-            startTracking(payload, resultsListener);\n-\n-            // 2. go descending through the rest of the stages, while adjusting the query\n-            inspectStage(1, resultsListener);\n-\n-        }, resultsListener::onFailure));\n+        log.info(\"Starting sequencing\");\n+        queryStage(0, listener);\n     }\n \n-    private void startTracking(Payload<SearchHit> payload, ActionListener<Results> resultsListener) {\n-        Criterion lastCriterion = criteria.get(0);\n-        List<SearchHit> hits = payload.values();\n-\n-        // nothing matches the first query, bail out early\n-        if (hits.isEmpty()) {\n-            resultsListener.onResponse(assembleResults());\n-            return;\n-        }\n-        \n-        long tMin = Long.MAX_VALUE;\n-        long tMax = Long.MIN_VALUE;\n-        \n-        Comparable<Object> bMin = null;\n-        // we could have extracted that in the hit loop but that if would have been evaluated\n-        // for every document\n-        if (hits.isEmpty() == false) {\n-            tMin = lastCriterion.timestamp(hits.get(0));\n-            tMax = lastCriterion.timestamp(hits.get(hits.size() - 1));\n-            \n-            if (lastCriterion.tiebreakerExtractor() != null) {\n-               bMin = lastCriterion.tiebreaker(hits.get(0));\n-            }\n-        }\n-\n-        for (SearchHit hit : hits) {\n-            KeyAndOrdinal ko = findKey(hit, lastCriterion);\n-            Sequence seq = new Sequence(ko.key, numberOfStages, ko.timestamp, ko.tiebreaker, hit);\n-            stateMachine.trackSequence(seq, tMin, tMax);\n-        }\n-        stateMachine.setTimestampMarker(0, tMin);\n-        if (bMin != null) {\n-            stateMachine.setTiebreakerMarker(0, bMin);\n-        }\n-    }\n-\n-    private void inspectStage(int stage, ActionListener<Results> resultsListener) {\n+    private void queryStage(int stage, ActionListener<Payload> listener) {\n         // sequencing is done, return results\n-        if (stage == numberOfStages) {\n-            resultsListener.onResponse(assembleResults());\n+        if (hasFinished(stage)) {\n+            listener.onResponse(sequencePayload());\n             return;\n         }\n+\n         // else continue finding matches\n         Criterion currentCriterion = criteria.get(stage);\n-        // narrow by the previous stage timestamp marker\n-        currentCriterion.fromMarkers(stateMachine.getMarkers(stage - 1));\n+        if (stage > 0) {\n+            // FIXME: revisit this during pagination since the second criterion need to be limited to the range of the first one\n+            // narrow by the previous stage timestamp marker\n+\n+            Criterion previous = criteria.get(stage - 1);\n+            // if DESC, flip the markers (the stop becomes the start due to the reverse order), otherwise keep it accordingly\n+            Object[] marker = descending && stage == 1 ? previous.stopMarker() : previous.startMarker();\n+            currentCriterion.useMarker(marker);\n+        }\n         \n-        queryClient.query(currentCriterion.searchSource(), wrap(payload -> {\n-            findMatches(stage, payload);\n-            inspectStage(stage + 1, resultsListener);\n-        }, resultsListener::onFailure));\n+        log.info(\"Querying stage {}\", stage);\n+        queryClient.query(currentCriterion, wrap(payload -> {\n+            List<SearchHit> hits = payload.values();\n+\n+            // nothing matches the query -> bail out\n+            // FIXME: needs to be changed when doing pagination\n+            if (hits.isEmpty()) {\n+                listener.onResponse(sequencePayload());\n+                return;\n+            }\n+\n+            findMatches(stage, hits);\n+            queryStage(stage + 1, listener);\n+        }, listener::onFailure));\n     }\n \n-    private void findMatches(int currentStage, Payload<SearchHit> payload) {\n-        Criterion currentCriterion = criteria.get(currentStage);\n-        List<SearchHit> hits = payload.values();\n-        \n+    // hits are guaranteed to be non-empty\n+    private void findMatches(int currentStage, List<SearchHit> hits) {\n+        // update criterion\n+        Criterion criterion = criteria.get(currentStage);\n+        criterion.startMarker(hits.get(0));\n+        criterion.stopMarker(hits.get(hits.size() - 1));\n+\n         // break the results per key\n-        for (SearchHit hit : hits) {\n-            KeyAndOrdinal ko = findKey(hit, currentCriterion);\n-            stateMachine.match(currentStage, ko.key, ko.timestamp, ko.tiebreaker, hit);\n+        // when dealing with descending order, queries outside the base are ASC (search_before)\n+        // so look at the data in reverse (that is DESC)\n+        Iterator<SearchHit> iterator = descending ? new ReversedIterator<>(hits) : hits.iterator();\n+\n+        for (; iterator.hasNext();) {\n+            SearchHit hit = iterator.next();\n+\n+            // early skip in case of reaching the limit\n+            // check the last stage to avoid calling the state machine in other stages\n+            if (isLast(currentStage) && stateMachine.reachedLimit()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 179}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwNjE4Mg==", "bodyText": "I've mentioned in the comment - checking the reachedLimit all the time does make sense but at the same time it will only increase during the last stage. Hence why checking it before is not needed.\nNevertheless I can see how this can be confusing plus I've improved the stateMachine class to have a bool and avoid the check on each method call.", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446106182", "createdAt": "2020-06-26T10:37:00Z", "author": {"login": "costin"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/assembler/SequenceRuntime.java", "diffHunk": "@@ -26,105 +31,103 @@\n  */\n class SequenceRuntime implements Executable {\n \n+    private final Logger log = LogManager.getLogger(SequenceRuntime.class);\n+\n     private final List<Criterion> criteria;\n     // NB: just like in a list, this represents the total number of stages yet counting starts at 0\n     private final int numberOfStages;\n     private final SequenceStateMachine stateMachine;\n     private final QueryClient queryClient;\n+    private final boolean descending;\n+\n     private long startTime;\n \n-    SequenceRuntime(List<Criterion> criteria, QueryClient queryClient) {\n+    SequenceRuntime(List<Criterion> criteria, QueryClient queryClient, boolean descending, Limit limit) {\n         this.criteria = criteria;\n         this.numberOfStages = criteria.size();\n         this.queryClient = queryClient;\n         boolean hasTiebreaker = criteria.get(0).tiebreakerExtractor() != null;\n-        this.stateMachine = new SequenceStateMachine(numberOfStages, hasTiebreaker);\n+        this.stateMachine = new SequenceStateMachine(numberOfStages, hasTiebreaker, limit);\n+\n+        this.descending = descending;\n     }\n \n     @Override\n-    public void execute(ActionListener<Results> resultsListener) {\n+    public void execute(ActionListener<Payload> listener) {\n         startTime = System.currentTimeMillis();\n-        startSequencing(resultsListener);\n-    }\n-\n-    private void startSequencing(ActionListener<Results> resultsListener) {\n-        Criterion firstStage = criteria.get(0);\n-        queryClient.query(firstStage.searchSource(), wrap(payload -> {\n-\n-            // 1. execute last stage (find keys)\n-            startTracking(payload, resultsListener);\n-\n-            // 2. go descending through the rest of the stages, while adjusting the query\n-            inspectStage(1, resultsListener);\n-\n-        }, resultsListener::onFailure));\n+        log.info(\"Starting sequencing\");\n+        queryStage(0, listener);\n     }\n \n-    private void startTracking(Payload<SearchHit> payload, ActionListener<Results> resultsListener) {\n-        Criterion lastCriterion = criteria.get(0);\n-        List<SearchHit> hits = payload.values();\n-\n-        // nothing matches the first query, bail out early\n-        if (hits.isEmpty()) {\n-            resultsListener.onResponse(assembleResults());\n-            return;\n-        }\n-        \n-        long tMin = Long.MAX_VALUE;\n-        long tMax = Long.MIN_VALUE;\n-        \n-        Comparable<Object> bMin = null;\n-        // we could have extracted that in the hit loop but that if would have been evaluated\n-        // for every document\n-        if (hits.isEmpty() == false) {\n-            tMin = lastCriterion.timestamp(hits.get(0));\n-            tMax = lastCriterion.timestamp(hits.get(hits.size() - 1));\n-            \n-            if (lastCriterion.tiebreakerExtractor() != null) {\n-               bMin = lastCriterion.tiebreaker(hits.get(0));\n-            }\n-        }\n-\n-        for (SearchHit hit : hits) {\n-            KeyAndOrdinal ko = findKey(hit, lastCriterion);\n-            Sequence seq = new Sequence(ko.key, numberOfStages, ko.timestamp, ko.tiebreaker, hit);\n-            stateMachine.trackSequence(seq, tMin, tMax);\n-        }\n-        stateMachine.setTimestampMarker(0, tMin);\n-        if (bMin != null) {\n-            stateMachine.setTiebreakerMarker(0, bMin);\n-        }\n-    }\n-\n-    private void inspectStage(int stage, ActionListener<Results> resultsListener) {\n+    private void queryStage(int stage, ActionListener<Payload> listener) {\n         // sequencing is done, return results\n-        if (stage == numberOfStages) {\n-            resultsListener.onResponse(assembleResults());\n+        if (hasFinished(stage)) {\n+            listener.onResponse(sequencePayload());\n             return;\n         }\n+\n         // else continue finding matches\n         Criterion currentCriterion = criteria.get(stage);\n-        // narrow by the previous stage timestamp marker\n-        currentCriterion.fromMarkers(stateMachine.getMarkers(stage - 1));\n+        if (stage > 0) {\n+            // FIXME: revisit this during pagination since the second criterion need to be limited to the range of the first one\n+            // narrow by the previous stage timestamp marker\n+\n+            Criterion previous = criteria.get(stage - 1);\n+            // if DESC, flip the markers (the stop becomes the start due to the reverse order), otherwise keep it accordingly\n+            Object[] marker = descending && stage == 1 ? previous.stopMarker() : previous.startMarker();\n+            currentCriterion.useMarker(marker);\n+        }\n         \n-        queryClient.query(currentCriterion.searchSource(), wrap(payload -> {\n-            findMatches(stage, payload);\n-            inspectStage(stage + 1, resultsListener);\n-        }, resultsListener::onFailure));\n+        log.info(\"Querying stage {}\", stage);\n+        queryClient.query(currentCriterion, wrap(payload -> {\n+            List<SearchHit> hits = payload.values();\n+\n+            // nothing matches the query -> bail out\n+            // FIXME: needs to be changed when doing pagination\n+            if (hits.isEmpty()) {\n+                listener.onResponse(sequencePayload());\n+                return;\n+            }\n+\n+            findMatches(stage, hits);\n+            queryStage(stage + 1, listener);\n+        }, listener::onFailure));\n     }\n \n-    private void findMatches(int currentStage, Payload<SearchHit> payload) {\n-        Criterion currentCriterion = criteria.get(currentStage);\n-        List<SearchHit> hits = payload.values();\n-        \n+    // hits are guaranteed to be non-empty\n+    private void findMatches(int currentStage, List<SearchHit> hits) {\n+        // update criterion\n+        Criterion criterion = criteria.get(currentStage);\n+        criterion.startMarker(hits.get(0));\n+        criterion.stopMarker(hits.get(hits.size() - 1));\n+\n         // break the results per key\n-        for (SearchHit hit : hits) {\n-            KeyAndOrdinal ko = findKey(hit, currentCriterion);\n-            stateMachine.match(currentStage, ko.key, ko.timestamp, ko.tiebreaker, hit);\n+        // when dealing with descending order, queries outside the base are ASC (search_before)\n+        // so look at the data in reverse (that is DESC)\n+        Iterator<SearchHit> iterator = descending ? new ReversedIterator<>(hits) : hits.iterator();\n+\n+        for (; iterator.hasNext();) {\n+            SearchHit hit = iterator.next();\n+\n+            // early skip in case of reaching the limit\n+            // check the last stage to avoid calling the state machine in other stages\n+            if (isLast(currentStage) && stateMachine.reachedLimit()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA0OTEyNA=="}, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 179}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTI5NjgxOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/search/BasicQueryClient.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQwODo0Njo1MlrOGpY5PQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxODoyMzo0OVrOGpqkUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA1MjY2OQ==", "bodyText": "I find indexAsWildcard naming not reflecting what it actually does. Not sure where the wildcard comes from, I would name it commaDelimitedIndices or something similar.", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446052669", "createdAt": "2020-06-26T08:46:52Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/search/BasicQueryClient.java", "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.eql.execution.search;\n+\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.tasks.TaskCancelledException;\n+import org.elasticsearch.xpack.eql.session.EqlConfiguration;\n+import org.elasticsearch.xpack.eql.session.EqlSession;\n+import org.elasticsearch.xpack.eql.session.Payload;\n+import org.elasticsearch.xpack.ql.util.StringUtils;\n+\n+import static org.elasticsearch.xpack.eql.execution.search.RuntimeUtils.prepareRequest;\n+\n+public class BasicQueryClient implements QueryClient {\n+\n+    private static final Logger log = RuntimeUtils.QUERY_LOG;\n+\n+    private final EqlConfiguration cfg;\n+    private final Client client;\n+    private final String indices;\n+\n+    public BasicQueryClient(EqlSession eqlSession) {\n+        this.cfg = eqlSession.configuration();\n+        this.client = eqlSession.client();\n+        this.indices = cfg.indexAsWildcard();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwNjk3Ng==", "bodyText": "Not sure where the wildcard comes from\nFrom IndexResolver.resolveAsMergedMapping.\n\nI'll rename it.", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446106976", "createdAt": "2020-06-26T10:39:03Z", "author": {"login": "costin"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/search/BasicQueryClient.java", "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.eql.execution.search;\n+\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.tasks.TaskCancelledException;\n+import org.elasticsearch.xpack.eql.session.EqlConfiguration;\n+import org.elasticsearch.xpack.eql.session.EqlSession;\n+import org.elasticsearch.xpack.eql.session.Payload;\n+import org.elasticsearch.xpack.ql.util.StringUtils;\n+\n+import static org.elasticsearch.xpack.eql.execution.search.RuntimeUtils.prepareRequest;\n+\n+public class BasicQueryClient implements QueryClient {\n+\n+    private static final Logger log = RuntimeUtils.QUERY_LOG;\n+\n+    private final EqlConfiguration cfg;\n+    private final Client client;\n+    private final String indices;\n+\n+    public BasicQueryClient(EqlSession eqlSession) {\n+        this.cfg = eqlSession.configuration();\n+        this.client = eqlSession.client();\n+        this.indices = cfg.indexAsWildcard();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA1MjY2OQ=="}, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwOTA5NA==", "bodyText": "I'm not so sure about the rename...when given as a pattern index* the value of the index is said string. Using commaDelimitedIndices suggests to me that the pattern has been resolved to concrete indices vs indexAsWildcard which indicates that any potential pattern hasn't been computed yet.", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446109094", "createdAt": "2020-06-26T10:44:17Z", "author": {"login": "costin"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/search/BasicQueryClient.java", "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.eql.execution.search;\n+\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.tasks.TaskCancelledException;\n+import org.elasticsearch.xpack.eql.session.EqlConfiguration;\n+import org.elasticsearch.xpack.eql.session.EqlSession;\n+import org.elasticsearch.xpack.eql.session.Payload;\n+import org.elasticsearch.xpack.ql.util.StringUtils;\n+\n+import static org.elasticsearch.xpack.eql.execution.search.RuntimeUtils.prepareRequest;\n+\n+public class BasicQueryClient implements QueryClient {\n+\n+    private static final Logger log = RuntimeUtils.QUERY_LOG;\n+\n+    private final EqlConfiguration cfg;\n+    private final Client client;\n+    private final String indices;\n+\n+    public BasicQueryClient(EqlSession eqlSession) {\n+        this.cfg = eqlSession.configuration();\n+        this.client = eqlSession.client();\n+        this.indices = cfg.indexAsWildcard();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA1MjY2OQ=="}, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEyMDM2OA==", "bodyText": "How about commaDelimitedIndexPatterns?\nAgree about index*, but what about the other scenario of index1, index2, index3? There is no wildcard there. In fact, there are multiple indices even, whereas the name of the method uses the singular.", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446120368", "createdAt": "2020-06-26T11:12:09Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/search/BasicQueryClient.java", "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.eql.execution.search;\n+\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.tasks.TaskCancelledException;\n+import org.elasticsearch.xpack.eql.session.EqlConfiguration;\n+import org.elasticsearch.xpack.eql.session.EqlSession;\n+import org.elasticsearch.xpack.eql.session.Payload;\n+import org.elasticsearch.xpack.ql.util.StringUtils;\n+\n+import static org.elasticsearch.xpack.eql.execution.search.RuntimeUtils.prepareRequest;\n+\n+public class BasicQueryClient implements QueryClient {\n+\n+    private static final Logger log = RuntimeUtils.QUERY_LOG;\n+\n+    private final EqlConfiguration cfg;\n+    private final Client client;\n+    private final String indices;\n+\n+    public BasicQueryClient(EqlSession eqlSession) {\n+        this.cfg = eqlSession.configuration();\n+        this.client = eqlSession.client();\n+        this.indices = cfg.indexAsWildcard();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA1MjY2OQ=="}, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjM0MjIyNA==", "bodyText": "commaDelimitedIndexPatterns - that's a lot of chars :)\nI can rename it to indexPattern but to me that's the same as wildcard (which is pattern) but a bit longer.", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446342224", "createdAt": "2020-06-26T18:23:49Z", "author": {"login": "costin"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/execution/search/BasicQueryClient.java", "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.eql.execution.search;\n+\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.tasks.TaskCancelledException;\n+import org.elasticsearch.xpack.eql.session.EqlConfiguration;\n+import org.elasticsearch.xpack.eql.session.EqlSession;\n+import org.elasticsearch.xpack.eql.session.Payload;\n+import org.elasticsearch.xpack.ql.util.StringUtils;\n+\n+import static org.elasticsearch.xpack.eql.execution.search.RuntimeUtils.prepareRequest;\n+\n+public class BasicQueryClient implements QueryClient {\n+\n+    private static final Logger log = RuntimeUtils.QUERY_LOG;\n+\n+    private final EqlConfiguration cfg;\n+    private final Client client;\n+    private final String indices;\n+\n+    public BasicQueryClient(EqlSession eqlSession) {\n+        this.cfg = eqlSession.configuration();\n+        this.client = eqlSession.client();\n+        this.indices = cfg.indexAsWildcard();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA1MjY2OQ=="}, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTM1MDE5OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/optimizer/Optimizer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQwOTowMzoxN1rOGpZZ7Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxODoyODoxOVrOGpqr9Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA2MTAzNw==", "bodyText": "if (limit.child() instanceof LimitWithOffset == false) {\n   return limit;\n}", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446061037", "createdAt": "2020-06-26T09:03:17Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/optimizer/Optimizer.java", "diffHunk": "@@ -154,14 +174,168 @@ protected LogicalPlan rule(UnaryPlan plan) {\n             return plan;\n         }\n     }\n-    \n+\n+    static class SkipQueryOnLimitZero extends org.elasticsearch.xpack.ql.optimizer.OptimizerRules.SkipQueryOnLimitZero {\n+\n+        @Override\n+        protected LogicalPlan skipPlan(Limit limit) {\n+            return Optimizer.skipPlan(limit);\n+        }\n+    }\n+\n+    private static LogicalPlan skipPlan(UnaryPlan plan) {\n+        return new LocalRelation(plan.source(), plan.output());\n+    }\n+\n+    /**\n+     * Combine tail and head into one limit.\n+     * The rules moves up since the first limit is the one that defines whether it's the head (positive) or\n+     * the tail (negative) limit of the data and the rest simply work in this space.\n+     */\n+    static final class CombineLimits extends OptimizerRule<LimitWithOffset> {\n+\n+        CombineLimits() {\n+            super(TransformDirection.UP);\n+        }\n+\n+        @Override\n+        protected LogicalPlan rule(LimitWithOffset limit) {\n+            if (limit.child() instanceof LimitWithOffset) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjM0NDE4MQ==", "bodyText": "I've modified it since I think the gains (less formatting) are sufficient. In general our rules tend to start with if() and I like consistency.\nThat and having only one return, essentially a clear exit vs multiple return paths (which is why I haven't updated PushDownOrderBy). This is mainly a styling issue but then again, we're software writers not just engineers.", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446344181", "createdAt": "2020-06-26T18:28:19Z", "author": {"login": "costin"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/optimizer/Optimizer.java", "diffHunk": "@@ -154,14 +174,168 @@ protected LogicalPlan rule(UnaryPlan plan) {\n             return plan;\n         }\n     }\n-    \n+\n+    static class SkipQueryOnLimitZero extends org.elasticsearch.xpack.ql.optimizer.OptimizerRules.SkipQueryOnLimitZero {\n+\n+        @Override\n+        protected LogicalPlan skipPlan(Limit limit) {\n+            return Optimizer.skipPlan(limit);\n+        }\n+    }\n+\n+    private static LogicalPlan skipPlan(UnaryPlan plan) {\n+        return new LocalRelation(plan.source(), plan.output());\n+    }\n+\n+    /**\n+     * Combine tail and head into one limit.\n+     * The rules moves up since the first limit is the one that defines whether it's the head (positive) or\n+     * the tail (negative) limit of the data and the rest simply work in this space.\n+     */\n+    static final class CombineLimits extends OptimizerRule<LimitWithOffset> {\n+\n+        CombineLimits() {\n+            super(TransformDirection.UP);\n+        }\n+\n+        @Override\n+        protected LogicalPlan rule(LimitWithOffset limit) {\n+            if (limit.child() instanceof LimitWithOffset) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA2MTAzNw=="}, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 124}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTM5MDA5OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/optimizer/Optimizer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQwOToxNjoxMVrOGpZzJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQwOToxNjoxMVrOGpZzJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA2NzQ5Mw==", "bodyText": "Leftover comment?", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446067493", "createdAt": "2020-06-26T09:16:11Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/optimizer/Optimizer.java", "diffHunk": "@@ -154,14 +174,168 @@ protected LogicalPlan rule(UnaryPlan plan) {\n             return plan;\n         }\n     }\n-    \n+\n+    static class SkipQueryOnLimitZero extends org.elasticsearch.xpack.ql.optimizer.OptimizerRules.SkipQueryOnLimitZero {\n+\n+        @Override\n+        protected LogicalPlan skipPlan(Limit limit) {\n+            return Optimizer.skipPlan(limit);\n+        }\n+    }\n+\n+    private static LogicalPlan skipPlan(UnaryPlan plan) {\n+        return new LocalRelation(plan.source(), plan.output());\n+    }\n+\n+    /**\n+     * Combine tail and head into one limit.\n+     * The rules moves up since the first limit is the one that defines whether it's the head (positive) or\n+     * the tail (negative) limit of the data and the rest simply work in this space.\n+     */\n+    static final class CombineLimits extends OptimizerRule<LimitWithOffset> {\n+\n+        CombineLimits() {\n+            super(TransformDirection.UP);\n+        }\n+\n+        @Override\n+        protected LogicalPlan rule(LimitWithOffset limit) {\n+            if (limit.child() instanceof LimitWithOffset) {\n+                LimitWithOffset primary = (LimitWithOffset) limit.child();\n+\n+                int primaryLimit = (Integer) primary.limit().fold();\n+                int primaryOffset = primary.offset();\n+                // +1 means ASC, -1 descending and 0 if there are no results\n+                int sign = Integer.signum(primaryLimit);\n+\n+                int secondaryLimit = (Integer) limit.limit().fold();\n+                if (limit.offset() != 0) {\n+                    throw new EqlIllegalArgumentException(\"Limits with different offset not implemented yet\");\n+                }\n+\n+                // for the same direction\n+                if (primaryLimit > 0 && secondaryLimit > 0) {\n+                    // consider the minimum\n+                    primaryLimit = Math.min(primaryLimit, secondaryLimit);\n+                } else if (primaryLimit < 0 && secondaryLimit < 0) {\n+                    primaryLimit = Math.max(primaryLimit, secondaryLimit);\n+                } else {\n+                    // the secondary limit cannot go beyond the primary - if it does it gets ignored\n+                    if (MathUtils.abs(secondaryLimit) < MathUtils.abs(primaryLimit)) {\n+                        primaryOffset += MathUtils.abs(primaryLimit + secondaryLimit);\n+                        // preserve order\n+                        primaryLimit = MathUtils.abs(secondaryLimit) * sign;\n+                    }\n+                }\n+\n+                Literal literal = new Literal(primary.limit().source(), primaryLimit, DataTypes.INTEGER);\n+                return new LimitWithOffset(primary.source(), literal, primaryOffset, primary.child());\n+            }\n+\n+            return limit;\n+        }\n+    }\n+\n+    /**\n+     * Align the implicit order with the limit (head means ASC or tail means DESC).\n+     */\n+    static final class SortByLimit extends OptimizerRule<LimitWithOffset> {\n+\n+        @Override\n+        protected LogicalPlan rule(LimitWithOffset limit) {\n+            // only care if the limit is negative (tail)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 167}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTQwMTg2OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/parser/LogicalPlanBuilder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQwOToxOTo0MVrOGpZ6WQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQwOToxOTo0MVrOGpZ6WQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA2OTMzNw==", "bodyText": "?", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446069337", "createdAt": "2020-06-26T09:19:41Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/parser/LogicalPlanBuilder.java", "diffHunk": "@@ -262,4 +290,53 @@ public TimeValue visitSequenceParams(SequenceParamsContext ctx) {\n                     text(numberCtx));\n         }\n     }\n-}\n+\n+    private LogicalPlan pipe(PipeContext ctx, LogicalPlan plan) {\n+        String name = text(ctx.IDENTIFIER());\n+\n+        if (SUPPORTED_PIPES.contains(name) == false) {\n+            List<String> potentialMatches = StringUtils.findSimilar(name, SUPPORTED_PIPES);\n+            \n+            String msg = \"Unrecognized pipe [{}]\";\n+            if (potentialMatches.isEmpty() == false) {\n+                String matchString = potentialMatches.toString();\n+                msg += \", did you mean \" + (potentialMatches.size() == 1\n+                        ? matchString\n+                        : \"any of \" + matchString) + \"?\";\n+            }\n+            throw new ParsingException(source(ctx.IDENTIFIER()), msg, name);\n+        }\n+\n+        switch (name) {\n+            case \"head\":\n+                Expression headLimit = pipeIntArgument(source(ctx), name, ctx.booleanExpression());\n+                return new Head(source(ctx), headLimit, plan);\n+            //new LimitWithOffset(source(ctx), headLimit, 0, plan)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 179}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTQxNDExOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/parser/LogicalPlanBuilder.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQwOToyMzoyMFrOGpaB7Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxODoxODo1NlrOGpqb7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA3MTI3Nw==", "bodyText": "Where is the positive check taking place?", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446071277", "createdAt": "2020-06-26T09:23:20Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/parser/LogicalPlanBuilder.java", "diffHunk": "@@ -262,4 +290,53 @@ public TimeValue visitSequenceParams(SequenceParamsContext ctx) {\n                     text(numberCtx));\n         }\n     }\n-}\n+\n+    private LogicalPlan pipe(PipeContext ctx, LogicalPlan plan) {\n+        String name = text(ctx.IDENTIFIER());\n+\n+        if (SUPPORTED_PIPES.contains(name) == false) {\n+            List<String> potentialMatches = StringUtils.findSimilar(name, SUPPORTED_PIPES);\n+            \n+            String msg = \"Unrecognized pipe [{}]\";\n+            if (potentialMatches.isEmpty() == false) {\n+                String matchString = potentialMatches.toString();\n+                msg += \", did you mean \" + (potentialMatches.size() == 1\n+                        ? matchString\n+                        : \"any of \" + matchString) + \"?\";\n+            }\n+            throw new ParsingException(source(ctx.IDENTIFIER()), msg, name);\n+        }\n+\n+        switch (name) {\n+            case \"head\":\n+                Expression headLimit = pipeIntArgument(source(ctx), name, ctx.booleanExpression());\n+                return new Head(source(ctx), headLimit, plan);\n+            //new LimitWithOffset(source(ctx), headLimit, 0, plan)\n+\n+            case \"tail\":\n+                Expression tailLimit = pipeIntArgument(source(ctx), name, ctx.booleanExpression());\n+                // negate the limit\n+                return new Tail(source(ctx), tailLimit, plan);\n+            //return new LimitWithOffset(source(ctx), new Neg(tailLimit.source(), tailLimit), plan);\n+\n+            default:\n+                throw new ParsingException(source(ctx), \"Pipe [{}] is not supported yet\", name);\n+        }\n+    }\n+\n+    private Expression pipeIntArgument(Source source, String pipeName, List<BooleanExpressionContext> exps) {\n+        int size = CollectionUtils.isEmpty(exps) ? 0 : exps.size();\n+        if (size != 1) {\n+            throw new ParsingException(source, \"Pipe [{}] expects exactly one argument but found [{}]\", pipeName, size);\n+        }\n+        BooleanExpressionContext limitCtx = exps.get(0);\n+        Expression expression = expression(limitCtx);\n+\n+        if (expression.dataType().isInteger() == false || expression.foldable() == false) {\n+            throw new ParsingException(source(limitCtx), \"Pipe [{}] expects a positive integer but found [{}]\", pipeName, expression", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 201}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjM0MDA3Ng==", "bodyText": "There isn't any :) - the check was mainly to check the integer type. I've added one.", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446340076", "createdAt": "2020-06-26T18:18:56Z", "author": {"login": "costin"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/parser/LogicalPlanBuilder.java", "diffHunk": "@@ -262,4 +290,53 @@ public TimeValue visitSequenceParams(SequenceParamsContext ctx) {\n                     text(numberCtx));\n         }\n     }\n-}\n+\n+    private LogicalPlan pipe(PipeContext ctx, LogicalPlan plan) {\n+        String name = text(ctx.IDENTIFIER());\n+\n+        if (SUPPORTED_PIPES.contains(name) == false) {\n+            List<String> potentialMatches = StringUtils.findSimilar(name, SUPPORTED_PIPES);\n+            \n+            String msg = \"Unrecognized pipe [{}]\";\n+            if (potentialMatches.isEmpty() == false) {\n+                String matchString = potentialMatches.toString();\n+                msg += \", did you mean \" + (potentialMatches.size() == 1\n+                        ? matchString\n+                        : \"any of \" + matchString) + \"?\";\n+            }\n+            throw new ParsingException(source(ctx.IDENTIFIER()), msg, name);\n+        }\n+\n+        switch (name) {\n+            case \"head\":\n+                Expression headLimit = pipeIntArgument(source(ctx), name, ctx.booleanExpression());\n+                return new Head(source(ctx), headLimit, plan);\n+            //new LimitWithOffset(source(ctx), headLimit, 0, plan)\n+\n+            case \"tail\":\n+                Expression tailLimit = pipeIntArgument(source(ctx), name, ctx.booleanExpression());\n+                // negate the limit\n+                return new Tail(source(ctx), tailLimit, plan);\n+            //return new LimitWithOffset(source(ctx), new Neg(tailLimit.source(), tailLimit), plan);\n+\n+            default:\n+                throw new ParsingException(source(ctx), \"Pipe [{}] is not supported yet\", name);\n+        }\n+    }\n+\n+    private Expression pipeIntArgument(Source source, String pipeName, List<BooleanExpressionContext> exps) {\n+        int size = CollectionUtils.isEmpty(exps) ? 0 : exps.size();\n+        if (size != 1) {\n+            throw new ParsingException(source, \"Pipe [{}] expects exactly one argument but found [{}]\", pipeName, size);\n+        }\n+        BooleanExpressionContext limitCtx = exps.get(0);\n+        Expression expression = expression(limitCtx);\n+\n+        if (expression.dataType().isInteger() == false || expression.foldable() == false) {\n+            throw new ParsingException(source(limitCtx), \"Pipe [{}] expects a positive integer but found [{}]\", pipeName, expression", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA3MTI3Nw=="}, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 201}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTQzMDAzOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/planner/QueryFolder.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQwOToyODoxMlrOGpaLtQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxODo0MzoxOVrOGprF9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA3Mzc4MQ==", "bodyText": "Is this being used anywhere?", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446073781", "createdAt": "2020-06-26T09:28:12Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/planner/QueryFolder.java", "diffHunk": "@@ -139,4 +162,18 @@ public final PhysicalPlan apply(PhysicalPlan plan) {\n         @Override\n         protected abstract PhysicalPlan rule(SubPlan plan);\n     }\n-}\n+\n+    abstract static class QueryFoldingRule<SubPlan extends UnaryExec> extends FoldingRule<SubPlan> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjM1MDgzOQ==", "bodyText": "Thanks. Used it for the existing rules", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446350839", "createdAt": "2020-06-26T18:43:19Z", "author": {"login": "costin"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/planner/QueryFolder.java", "diffHunk": "@@ -139,4 +162,18 @@ public final PhysicalPlan apply(PhysicalPlan plan) {\n         @Override\n         protected abstract PhysicalPlan rule(SubPlan plan);\n     }\n-}\n+\n+    abstract static class QueryFoldingRule<SubPlan extends UnaryExec> extends FoldingRule<SubPlan> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA3Mzc4MQ=="}, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTQ1NzkyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/eql/src/test/java/org/elasticsearch/xpack/eql/optimizer/OptimizerTests.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQwOTozNzozMFrOGpadZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxODoyMToxNVrOGpqf8Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA3ODMwOQ==", "bodyText": "Is the offset here 5 or 4?", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446078309", "createdAt": "2020-06-26T09:37:30Z", "author": {"login": "astefan"}, "path": "x-pack/plugin/eql/src/test/java/org/elasticsearch/xpack/eql/optimizer/OptimizerTests.java", "diffHunk": "@@ -175,4 +178,51 @@ public void testWildcardEscapes() {\n         assertEquals(like.pattern().asLuceneWildcard(), \"* %bar_ * \\\\\\\\ \\n \\r \\t\");\n         assertEquals(like.pattern().asIndexNameWildcard(), \"* %bar_ * \\\\ \\n \\r \\t\");\n     }\n+\n+    public void testCombineHeadBigHeadSmall() {\n+        checkOffsetAndLimit(accept(\"process where true | head 10 | head 1\"), 0, 1);\n+    }\n+\n+    public void testCombineHeadSmallHeadBig() {\n+        checkOffsetAndLimit(accept(\"process where true | head 1 | head 12\"), 0, 1);\n+    }\n+\n+    public void testCombineTailBigTailSmall() {\n+        checkOffsetAndLimit(accept(\"process where true | tail 10 | tail 1\"), 0, -1);\n+    }\n+\n+    public void testCombineTailSmallTailBig() {\n+        checkOffsetAndLimit(accept(\"process where true | tail 1 | tail 12\"), 0, -1);\n+    }\n+\n+    public void testCombineHeadBigTailSmall() {\n+        checkOffsetAndLimit(accept(\"process where true | head 10 | tail 7\"), 3, 7);\n+    }\n+\n+    public void testCombineTailBigHeadSmall() {\n+        checkOffsetAndLimit(accept(\"process where true | tail 10 | head 7\"), 3, -7);\n+    }\n+\n+    public void testCombineTailSmallHeadBig() {\n+        checkOffsetAndLimit(accept(\"process where true | tail 7 | head 10\"), 0, -7);\n+    }\n+\n+    public void testCombineHeadBigTailBig() {\n+        checkOffsetAndLimit(accept(\"process where true | head 1 | tail 7\"), 0, 1);\n+    }\n+\n+    public void testCombineHeadTailWithHeadAndTail() {\n+        checkOffsetAndLimit(accept(\"process where true | head 10 | tail 7 | head 5 | tail 3\"), 5, 3);\n+    }\n+\n+    public void testCombineTailHeadWithTailAndHead() {\n+        checkOffsetAndLimit(accept(\"process where true | tail 10 | head 7 | tail 5 | head 3\"), 5, -3);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjM0MTEwNQ==", "bodyText": "command  | limit, offset\ntail 10 -> -10  | 0\nhead 7  -> -7   | 3\ntail 5  -> -5   | 3\nhead 3  -> -3   | 5", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446341105", "createdAt": "2020-06-26T18:21:15Z", "author": {"login": "costin"}, "path": "x-pack/plugin/eql/src/test/java/org/elasticsearch/xpack/eql/optimizer/OptimizerTests.java", "diffHunk": "@@ -175,4 +178,51 @@ public void testWildcardEscapes() {\n         assertEquals(like.pattern().asLuceneWildcard(), \"* %bar_ * \\\\\\\\ \\n \\r \\t\");\n         assertEquals(like.pattern().asIndexNameWildcard(), \"* %bar_ * \\\\ \\n \\r \\t\");\n     }\n+\n+    public void testCombineHeadBigHeadSmall() {\n+        checkOffsetAndLimit(accept(\"process where true | head 10 | head 1\"), 0, 1);\n+    }\n+\n+    public void testCombineHeadSmallHeadBig() {\n+        checkOffsetAndLimit(accept(\"process where true | head 1 | head 12\"), 0, 1);\n+    }\n+\n+    public void testCombineTailBigTailSmall() {\n+        checkOffsetAndLimit(accept(\"process where true | tail 10 | tail 1\"), 0, -1);\n+    }\n+\n+    public void testCombineTailSmallTailBig() {\n+        checkOffsetAndLimit(accept(\"process where true | tail 1 | tail 12\"), 0, -1);\n+    }\n+\n+    public void testCombineHeadBigTailSmall() {\n+        checkOffsetAndLimit(accept(\"process where true | head 10 | tail 7\"), 3, 7);\n+    }\n+\n+    public void testCombineTailBigHeadSmall() {\n+        checkOffsetAndLimit(accept(\"process where true | tail 10 | head 7\"), 3, -7);\n+    }\n+\n+    public void testCombineTailSmallHeadBig() {\n+        checkOffsetAndLimit(accept(\"process where true | tail 7 | head 10\"), 0, -7);\n+    }\n+\n+    public void testCombineHeadBigTailBig() {\n+        checkOffsetAndLimit(accept(\"process where true | head 1 | tail 7\"), 0, 1);\n+    }\n+\n+    public void testCombineHeadTailWithHeadAndTail() {\n+        checkOffsetAndLimit(accept(\"process where true | head 10 | tail 7 | head 5 | tail 3\"), 5, 3);\n+    }\n+\n+    public void testCombineTailHeadWithTailAndHead() {\n+        checkOffsetAndLimit(accept(\"process where true | tail 10 | head 7 | tail 5 | head 3\"), 5, -3);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA3ODMwOQ=="}, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 117}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTg3MDAyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/parser/LogicalPlanBuilder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMjowODo0M1rOGpeeYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMjowODo0M1rOGpeeYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0NDA5Nw==", "bodyText": "also leftover here.", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446144097", "createdAt": "2020-06-26T12:08:43Z", "author": {"login": "matriv"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/parser/LogicalPlanBuilder.java", "diffHunk": "@@ -262,4 +290,53 @@ public TimeValue visitSequenceParams(SequenceParamsContext ctx) {\n                     text(numberCtx));\n         }\n     }\n-}\n+\n+    private LogicalPlan pipe(PipeContext ctx, LogicalPlan plan) {\n+        String name = text(ctx.IDENTIFIER());\n+\n+        if (SUPPORTED_PIPES.contains(name) == false) {\n+            List<String> potentialMatches = StringUtils.findSimilar(name, SUPPORTED_PIPES);\n+            \n+            String msg = \"Unrecognized pipe [{}]\";\n+            if (potentialMatches.isEmpty() == false) {\n+                String matchString = potentialMatches.toString();\n+                msg += \", did you mean \" + (potentialMatches.size() == 1\n+                        ? matchString\n+                        : \"any of \" + matchString) + \"?\";\n+            }\n+            throw new ParsingException(source(ctx.IDENTIFIER()), msg, name);\n+        }\n+\n+        switch (name) {\n+            case \"head\":\n+                Expression headLimit = pipeIntArgument(source(ctx), name, ctx.booleanExpression());\n+                return new Head(source(ctx), headLimit, plan);\n+            //new LimitWithOffset(source(ctx), headLimit, 0, plan)\n+\n+            case \"tail\":\n+                Expression tailLimit = pipeIntArgument(source(ctx), name, ctx.booleanExpression());\n+                // negate the limit\n+                return new Tail(source(ctx), tailLimit, plan);\n+            //return new LimitWithOffset(source(ctx), new Neg(tailLimit.source(), tailLimit), plan);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 185}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTg3NTkyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/plan/physical/SequenceExec.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMjoxMDo0N1rOGpeiEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMjoxMDo0N1rOGpeiEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0NTA0MQ==", "bodyText": "Minor: code formatting for consistency:\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                    Attribute tiebreaker, OrderDirection direction) {\n          \n          \n            \n                                    Attribute tiebreaker, \n          \n          \n            \n                                    OrderDirection direction) {", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446145041", "createdAt": "2020-06-26T12:10:47Z", "author": {"login": "matriv"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/plan/physical/SequenceExec.java", "diffHunk": "@@ -29,27 +31,37 @@\n     private final List<List<Attribute>> keys;\n     private final Attribute timestamp;\n     private final Attribute tiebreaker;\n+    private final Limit limit;\n+    private final OrderDirection direction;\n \n     public SequenceExec(Source source,\n                         List<List<Attribute>> keys,\n                         List<PhysicalPlan> matches,\n                         List<Attribute> untilKeys,\n                         PhysicalPlan until,\n                         Attribute timestamp,\n-                        Attribute tiebreaker) {\n-        this(source, combine(matches, until), combine(keys, singletonList(untilKeys)), timestamp, tiebreaker);\n+                        Attribute tiebreaker, OrderDirection direction) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3OTg3Nzg0OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/querydsl/container/QueryContainer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMjoxMTo0MFrOGpejbg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMjoxMTo0MFrOGpejbg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0NTM5MA==", "bodyText": "minor: empty line", "url": "https://github.com/elastic/elasticsearch/pull/58536#discussion_r446145390", "createdAt": "2020-06-26T12:11:40Z", "author": {"login": "matriv"}, "path": "x-pack/plugin/eql/src/main/java/org/elasticsearch/xpack/eql/querydsl/container/QueryContainer.java", "diffHunk": "@@ -45,18 +46,27 @@\n     private final boolean trackHits;\n     private final boolean includeFrozen;\n \n+    private final Limit limit;\n+\n     public QueryContainer() {\n-        this(null, emptyList(), AttributeMap.emptyAttributeMap(), emptyMap(), false, false);\n+        this(null, emptyList(), AttributeMap.emptyAttributeMap(), emptyMap(), false, false, null);\n     }\n \n-    private QueryContainer(Query query, List<Tuple<FieldExtraction, String>> fields, AttributeMap<Expression> attributes,\n-                           Map<String, Sort> sort, boolean trackHits, boolean includeFrozen) {\n+    private QueryContainer(Query query,\n+                           List<Tuple<FieldExtraction, String>> fields,\n+                           AttributeMap<Expression> attributes,\n+                           Map<String, Sort> sort,\n+                           boolean trackHits,\n+                           boolean includeFrozen,\n+                           Limit limit) {\n         this.query = query;\n         this.fields = fields;\n         this.sort = sort;\n         this.attributes = attributes;\n         this.trackHits = trackHits;\n         this.includeFrozen = includeFrozen;\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "40ada655e5985a1a9bb8b32cfe42514dcc7c7259"}, "originalPosition": 34}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2304, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}