{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI2NTgyODA0", "number": 65436, "title": "Also reroute after shard snapshot size fetch failure", "bodyText": "In #61906 we added the possibility for the master node to fetch the size of a shard snapshot before allocating the shard to a data node with enough disk space to host it. When merging this change we agreed that any failure during size fetching should not prevent the shard to be allocated.\nSadly it does not work as expected: the InternalSnapshotsInfoService only triggers reroutes when fetching the size succeed but never when it fails. It means that a shard might stay unassigned until another cluster state update triggers a new allocation (as in #64372). More sadly, the test I wrote was wrong as it explicitly triggered a reroute.\nThis PR changes the InternalSnapshotsInfoService so that it also triggers a reroute when fetching the snapshot shard size failed, ensuring that the allocation can move forward by using an UNAVAILABLE_EXPECTED_SHARD_SIZE shard size. This unknown shard size is kept around in the snapshot info service until no corresponding unassigned shards need the information.\nThe previous behavior failedSnapshotShards.remove(snapshotShard); // retry the failed shard that retries to fetch the snapshot shard size again on cluster state updates has been removed to avoid looping between fetch failures and reroutes.", "createdAt": "2020-11-24T15:53:02Z", "url": "https://github.com/elastic/elasticsearch/pull/65436", "merged": true, "mergeCommit": {"oid": "fc67aaa2be5b6f18fb1cbb58ade65916e1f312ff"}, "closed": true, "closedAt": "2020-12-08T09:47:59Z", "author": {"login": "tlrx"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdfrUcSAH2gAyNTI2NTgyODA0OjlhOWYxYTUxYTRmY2E1NDk5NTJjMDI3NjI3MjQ3MTQyYzE4N2U2ZjI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdkGRJUAH2gAyNTI2NTgyODA0OmNiMTlhODM2MDM1MjQ5ZjU2OTc2ZjQ4NzQzMzIxNmRiYmVmNmIyZjU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "9a9f1a51a4fca549952c027627247142c187e6f2", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/9a9f1a51a4fca549952c027627247142c187e6f2", "committedDate": "2020-11-24T15:17:08Z", "message": "Also reroute after shard snapshot size fetch failure"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ0Mjg4NDI0", "url": "https://github.com/elastic/elasticsearch/pull/65436#pullrequestreview-544288424", "createdAt": "2020-12-03T19:07:18Z", "commit": {"oid": "9a9f1a51a4fca549952c027627247142c187e6f2"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxOTowNzoxOVrOH-sp6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxOTo1Mzo0MVrOH-u00A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTUwNTM4Ng==", "bodyText": "Should this go outside the assertBusy()?", "url": "https://github.com/elastic/elasticsearch/pull/65436#discussion_r535505386", "createdAt": "2020-12-03T19:07:19Z", "author": {"login": "henningandersen"}, "path": "x-pack/plugin/ccr/src/internalClusterTest/java/org/elasticsearch/xpack/ccr/CcrRepositoryIT.java", "diffHunk": "@@ -613,83 +602,76 @@ public void testCcrRepositoryFailsToFetchSnapshotShardSizes() throws Exception {\n                         && indicesStatsRequest.search() == false\n                         && indicesStatsRequest.fieldData() == false\n                     ) {\n-                        indicesStatsRequestsCount.incrementAndGet();\n+                        simulatedFailures.incrementAndGet();\n                         channel.sendResponse(new ElasticsearchException(\"simulated\"));\n-                        return;\n                     }\n                 }\n                 handler.messageReceived(request, channel, task);\n             });\n-            transportServices.add(mockTransportService);\n         }\n \n         final String followerIndex = \"follower\";\n         try {\n-            final String leaderCluster = CcrRepository.NAME_PREFIX + \"leader_cluster\";\n-            final RepositoriesService repositoriesService = getFollowerCluster().getCurrentMasterNodeInstance(RepositoriesService.class);\n-            final Repository repository = repositoriesService.repository(leaderCluster);\n-            assertThat(repository.getMetadata().type(), equalTo(CcrRepository.TYPE));\n-            assertThat(repository.getMetadata().name(), equalTo(leaderCluster));\n-\n-            for (int i = 0; i < numberOfShards; i++) {\n-                final Index index = indexMetadata.getIndex();\n-                final int shardId = i;\n-                ElasticsearchException exception = expectThrows(ElasticsearchException.class,\n-                    () -> repository.getShardSnapshotStatus(\n-                        new SnapshotId(CcrRepository.LATEST, CcrRepository.LATEST),\n-                        new IndexId(index.getName(), index.getUUID()),\n-                        new ShardId(index, shardId)));\n-                assertThat(exception.getMessage(), equalTo(\"simulated\"));\n-            }\n-            assertThat(indicesStatsRequestsCount.getAndSet(0), equalTo(numberOfShards));\n-\n-            final RestoreService restoreService = getFollowerCluster().getCurrentMasterNodeInstance(RestoreService.class);\n-            final ClusterService clusterService = getFollowerCluster().getCurrentMasterNodeInstance(ClusterService.class);\n+            final SnapshotsInfoService snapshotsInfoService = getFollowerCluster().getCurrentMasterNodeInstance(SnapshotsInfoService.class);\n \n-            final PlainActionFuture<IndexRoutingTable> waitForRestoreInProgress = PlainActionFuture.newFuture();\n+            final PlainActionFuture<List<Long>> waitForAllShardSnapshotSizesFailures = PlainActionFuture.newFuture();\n             final ClusterStateListener listener = event -> {\n                 RestoreInProgress restoreInProgress = event.state().custom(RestoreInProgress.TYPE, RestoreInProgress.EMPTY);\n                 if (restoreInProgress != null\n                     && restoreInProgress.isEmpty() == false\n                     && event.state().routingTable().hasIndex(followerIndex)) {\n-                    waitForRestoreInProgress.onResponse(event.state().routingTable().index(followerIndex));\n+                    try {\n+                        final IndexRoutingTable indexRoutingTable = event.state().routingTable().index(followerIndex);\n+                        assertBusy(() -> {\n+                            List<Long> sizes = indexRoutingTable.shardsWithState(ShardRoutingState.UNASSIGNED).stream()\n+                                .filter(shard -> shard.unassignedInfo().getLastAllocationStatus() == AllocationStatus.FETCHING_SHARD_DATA)\n+                                .sorted(Comparator.comparingInt(ShardRouting::getId))\n+                                .map(shard -> snapshotsInfoService.snapshotShardSizes().getShardSize(shard))\n+                                .filter(Objects::nonNull)\n+                                .collect(Collectors.toList());\n+                            assertThat(sizes, hasSize(numberOfShards));\n+                            waitForAllShardSnapshotSizesFailures.onResponse(sizes);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9f1a51a4fca549952c027627247142c187e6f2"}, "originalPosition": 136}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTUyNjA5Nw==", "bodyText": "I wonder if we could use a smaller timeout like 1 minute or so?", "url": "https://github.com/elastic/elasticsearch/pull/65436#discussion_r535526097", "createdAt": "2020-12-03T19:33:44Z", "author": {"login": "henningandersen"}, "path": "x-pack/plugin/ccr/src/internalClusterTest/java/org/elasticsearch/xpack/ccr/CcrRepositoryIT.java", "diffHunk": "@@ -613,83 +602,76 @@ public void testCcrRepositoryFailsToFetchSnapshotShardSizes() throws Exception {\n                         && indicesStatsRequest.search() == false\n                         && indicesStatsRequest.fieldData() == false\n                     ) {\n-                        indicesStatsRequestsCount.incrementAndGet();\n+                        simulatedFailures.incrementAndGet();\n                         channel.sendResponse(new ElasticsearchException(\"simulated\"));\n-                        return;\n                     }\n                 }\n                 handler.messageReceived(request, channel, task);\n             });\n-            transportServices.add(mockTransportService);\n         }\n \n         final String followerIndex = \"follower\";\n         try {\n-            final String leaderCluster = CcrRepository.NAME_PREFIX + \"leader_cluster\";\n-            final RepositoriesService repositoriesService = getFollowerCluster().getCurrentMasterNodeInstance(RepositoriesService.class);\n-            final Repository repository = repositoriesService.repository(leaderCluster);\n-            assertThat(repository.getMetadata().type(), equalTo(CcrRepository.TYPE));\n-            assertThat(repository.getMetadata().name(), equalTo(leaderCluster));\n-\n-            for (int i = 0; i < numberOfShards; i++) {\n-                final Index index = indexMetadata.getIndex();\n-                final int shardId = i;\n-                ElasticsearchException exception = expectThrows(ElasticsearchException.class,\n-                    () -> repository.getShardSnapshotStatus(\n-                        new SnapshotId(CcrRepository.LATEST, CcrRepository.LATEST),\n-                        new IndexId(index.getName(), index.getUUID()),\n-                        new ShardId(index, shardId)));\n-                assertThat(exception.getMessage(), equalTo(\"simulated\"));\n-            }\n-            assertThat(indicesStatsRequestsCount.getAndSet(0), equalTo(numberOfShards));\n-\n-            final RestoreService restoreService = getFollowerCluster().getCurrentMasterNodeInstance(RestoreService.class);\n-            final ClusterService clusterService = getFollowerCluster().getCurrentMasterNodeInstance(ClusterService.class);\n+            final SnapshotsInfoService snapshotsInfoService = getFollowerCluster().getCurrentMasterNodeInstance(SnapshotsInfoService.class);\n \n-            final PlainActionFuture<IndexRoutingTable> waitForRestoreInProgress = PlainActionFuture.newFuture();\n+            final PlainActionFuture<List<Long>> waitForAllShardSnapshotSizesFailures = PlainActionFuture.newFuture();\n             final ClusterStateListener listener = event -> {\n                 RestoreInProgress restoreInProgress = event.state().custom(RestoreInProgress.TYPE, RestoreInProgress.EMPTY);\n                 if (restoreInProgress != null\n                     && restoreInProgress.isEmpty() == false\n                     && event.state().routingTable().hasIndex(followerIndex)) {\n-                    waitForRestoreInProgress.onResponse(event.state().routingTable().index(followerIndex));\n+                    try {\n+                        final IndexRoutingTable indexRoutingTable = event.state().routingTable().index(followerIndex);\n+                        assertBusy(() -> {\n+                            List<Long> sizes = indexRoutingTable.shardsWithState(ShardRoutingState.UNASSIGNED).stream()\n+                                .filter(shard -> shard.unassignedInfo().getLastAllocationStatus() == AllocationStatus.FETCHING_SHARD_DATA)\n+                                .sorted(Comparator.comparingInt(ShardRouting::getId))\n+                                .map(shard -> snapshotsInfoService.snapshotShardSizes().getShardSize(shard))\n+                                .filter(Objects::nonNull)\n+                                .collect(Collectors.toList());\n+                            assertThat(sizes, hasSize(numberOfShards));\n+                            waitForAllShardSnapshotSizesFailures.onResponse(sizes);\n+                        });\n+                    } catch (Exception e) {\n+                        throw new AssertionError(\"Failed to retrieve all snapshot shard sizes\", e);\n+                    }\n                 }\n             };\n+\n+            final ClusterService clusterService = getFollowerCluster().getCurrentMasterNodeInstance(ClusterService.class);\n             clusterService.addListener(listener);\n \n-            final RestoreSnapshotRequest restoreRequest = new RestoreSnapshotRequest(leaderCluster, CcrRepository.LATEST)\n-                .indices(leaderIndex).indicesOptions(indicesOptions).renamePattern(\"^(.*)$\")\n-                .renameReplacement(followerIndex)\n-                .masterNodeTimeout(TimeValue.MAX_VALUE)\n-                .indexSettings(Settings.builder()\n-                    .put(IndexMetadata.SETTING_INDEX_PROVIDED_NAME, followerIndex)\n-                    .put(CcrSettings.CCR_FOLLOWING_INDEX_SETTING.getKey(), true));\n-            restoreService.restoreSnapshot(restoreRequest, PlainActionFuture.newFuture());\n+            logger.debug(\"--> creating follower index [{}]\", followerIndex);\n+            followerClient().execute(PutFollowAction.INSTANCE, putFollow(leaderIndex, followerIndex, ActiveShardCount.NONE));\n \n-            final IndexRoutingTable indexRoutingTable = waitForRestoreInProgress.get(30L, TimeUnit.SECONDS);\n+            final List<Long> allShardSnapshotSizes = waitForAllShardSnapshotSizesFailures.get(30L, TimeUnit.SECONDS);\n             clusterService.removeListener(listener);\n \n-            final SnapshotsInfoService snapshotsInfoService = getFollowerCluster().getCurrentMasterNodeInstance(SnapshotsInfoService.class);\n-            assertBusy(() -> {\n-                SnapshotShardSizeInfo snapshotShardSizeInfo = snapshotsInfoService.snapshotShardSizes();\n-                for (int shardId = 0; shardId < numberOfShards; shardId++) {\n-                    final ShardRouting primary = indexRoutingTable.shard(shardId).primaryShard();\n-                    assertThat(snapshotShardSizeInfo.getShardSize(primary), equalTo(ShardRouting.UNAVAILABLE_EXPECTED_SHARD_SIZE));\n-                    final long randomSize = randomNonNegativeLong();\n-                    assertThat(snapshotShardSizeInfo.getShardSize(primary, randomSize), equalTo(randomSize));\n-                }\n-            }, 60L, TimeUnit.SECONDS);\n-        } finally {\n-            transportServices.forEach(MockTransportService::clearAllRules);\n-        }\n+            assertTrue(allShardSnapshotSizes.stream().allMatch(size -> ShardRouting.UNAVAILABLE_EXPECTED_SHARD_SIZE == size));\n+            assertThat(simulatedFailures.get(), equalTo(numberOfShards));\n \n-        assertThat(indicesStatsRequestsCount.get(), equalTo(numberOfShards));\n-        blockCcrRestore.countDown();\n+            logger.debug(\"--> checking that SnapshotsInfoService does not know the real sizes fof snapshot shards\");\n+            final SnapshotShardSizeInfo snapshotShardSizeInfo = snapshotsInfoService.snapshotShardSizes();\n+            for (int shardId = 0; shardId < numberOfShards; shardId++) {\n+                final ShardRouting primary = clusterService.state().routingTable().index(followerIndex).shard(shardId).primaryShard();\n+                assertThat(snapshotShardSizeInfo.getShardSize(primary), equalTo(ShardRouting.UNAVAILABLE_EXPECTED_SHARD_SIZE));\n+                final long randomSize = randomNonNegativeLong();\n+                assertThat(snapshotShardSizeInfo.getShardSize(primary, randomSize), equalTo(randomSize));\n+            }\n \n-        followerClient().admin().cluster().prepareReroute().get();\n-        ensureFollowerGreen(followerIndex);\n+            if (randomBoolean()) {\n+                logger.debug(\"--> create a random index to generate more cluster state updates\");\n+                final String randomIndex = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+                assertAcked(followerClient().admin().indices().prepareCreate(randomIndex).setMasterNodeTimeout(TimeValue.MAX_VALUE));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9f1a51a4fca549952c027627247142c187e6f2"}, "originalPosition": 194}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTUyNjQ0NQ==", "bodyText": "nit:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        logger.debug(\"--> checking that SnapshotsInfoService does not know the real sizes fof snapshot shards\");\n          \n          \n            \n                        logger.debug(\"--> checking that SnapshotsInfoService does not know the real sizes of snapshot shards\");", "url": "https://github.com/elastic/elasticsearch/pull/65436#discussion_r535526445", "createdAt": "2020-12-03T19:34:07Z", "author": {"login": "henningandersen"}, "path": "x-pack/plugin/ccr/src/internalClusterTest/java/org/elasticsearch/xpack/ccr/CcrRepositoryIT.java", "diffHunk": "@@ -613,83 +602,76 @@ public void testCcrRepositoryFailsToFetchSnapshotShardSizes() throws Exception {\n                         && indicesStatsRequest.search() == false\n                         && indicesStatsRequest.fieldData() == false\n                     ) {\n-                        indicesStatsRequestsCount.incrementAndGet();\n+                        simulatedFailures.incrementAndGet();\n                         channel.sendResponse(new ElasticsearchException(\"simulated\"));\n-                        return;\n                     }\n                 }\n                 handler.messageReceived(request, channel, task);\n             });\n-            transportServices.add(mockTransportService);\n         }\n \n         final String followerIndex = \"follower\";\n         try {\n-            final String leaderCluster = CcrRepository.NAME_PREFIX + \"leader_cluster\";\n-            final RepositoriesService repositoriesService = getFollowerCluster().getCurrentMasterNodeInstance(RepositoriesService.class);\n-            final Repository repository = repositoriesService.repository(leaderCluster);\n-            assertThat(repository.getMetadata().type(), equalTo(CcrRepository.TYPE));\n-            assertThat(repository.getMetadata().name(), equalTo(leaderCluster));\n-\n-            for (int i = 0; i < numberOfShards; i++) {\n-                final Index index = indexMetadata.getIndex();\n-                final int shardId = i;\n-                ElasticsearchException exception = expectThrows(ElasticsearchException.class,\n-                    () -> repository.getShardSnapshotStatus(\n-                        new SnapshotId(CcrRepository.LATEST, CcrRepository.LATEST),\n-                        new IndexId(index.getName(), index.getUUID()),\n-                        new ShardId(index, shardId)));\n-                assertThat(exception.getMessage(), equalTo(\"simulated\"));\n-            }\n-            assertThat(indicesStatsRequestsCount.getAndSet(0), equalTo(numberOfShards));\n-\n-            final RestoreService restoreService = getFollowerCluster().getCurrentMasterNodeInstance(RestoreService.class);\n-            final ClusterService clusterService = getFollowerCluster().getCurrentMasterNodeInstance(ClusterService.class);\n+            final SnapshotsInfoService snapshotsInfoService = getFollowerCluster().getCurrentMasterNodeInstance(SnapshotsInfoService.class);\n \n-            final PlainActionFuture<IndexRoutingTable> waitForRestoreInProgress = PlainActionFuture.newFuture();\n+            final PlainActionFuture<List<Long>> waitForAllShardSnapshotSizesFailures = PlainActionFuture.newFuture();\n             final ClusterStateListener listener = event -> {\n                 RestoreInProgress restoreInProgress = event.state().custom(RestoreInProgress.TYPE, RestoreInProgress.EMPTY);\n                 if (restoreInProgress != null\n                     && restoreInProgress.isEmpty() == false\n                     && event.state().routingTable().hasIndex(followerIndex)) {\n-                    waitForRestoreInProgress.onResponse(event.state().routingTable().index(followerIndex));\n+                    try {\n+                        final IndexRoutingTable indexRoutingTable = event.state().routingTable().index(followerIndex);\n+                        assertBusy(() -> {\n+                            List<Long> sizes = indexRoutingTable.shardsWithState(ShardRoutingState.UNASSIGNED).stream()\n+                                .filter(shard -> shard.unassignedInfo().getLastAllocationStatus() == AllocationStatus.FETCHING_SHARD_DATA)\n+                                .sorted(Comparator.comparingInt(ShardRouting::getId))\n+                                .map(shard -> snapshotsInfoService.snapshotShardSizes().getShardSize(shard))\n+                                .filter(Objects::nonNull)\n+                                .collect(Collectors.toList());\n+                            assertThat(sizes, hasSize(numberOfShards));\n+                            waitForAllShardSnapshotSizesFailures.onResponse(sizes);\n+                        });\n+                    } catch (Exception e) {\n+                        throw new AssertionError(\"Failed to retrieve all snapshot shard sizes\", e);\n+                    }\n                 }\n             };\n+\n+            final ClusterService clusterService = getFollowerCluster().getCurrentMasterNodeInstance(ClusterService.class);\n             clusterService.addListener(listener);\n \n-            final RestoreSnapshotRequest restoreRequest = new RestoreSnapshotRequest(leaderCluster, CcrRepository.LATEST)\n-                .indices(leaderIndex).indicesOptions(indicesOptions).renamePattern(\"^(.*)$\")\n-                .renameReplacement(followerIndex)\n-                .masterNodeTimeout(TimeValue.MAX_VALUE)\n-                .indexSettings(Settings.builder()\n-                    .put(IndexMetadata.SETTING_INDEX_PROVIDED_NAME, followerIndex)\n-                    .put(CcrSettings.CCR_FOLLOWING_INDEX_SETTING.getKey(), true));\n-            restoreService.restoreSnapshot(restoreRequest, PlainActionFuture.newFuture());\n+            logger.debug(\"--> creating follower index [{}]\", followerIndex);\n+            followerClient().execute(PutFollowAction.INSTANCE, putFollow(leaderIndex, followerIndex, ActiveShardCount.NONE));\n \n-            final IndexRoutingTable indexRoutingTable = waitForRestoreInProgress.get(30L, TimeUnit.SECONDS);\n+            final List<Long> allShardSnapshotSizes = waitForAllShardSnapshotSizesFailures.get(30L, TimeUnit.SECONDS);\n             clusterService.removeListener(listener);\n \n-            final SnapshotsInfoService snapshotsInfoService = getFollowerCluster().getCurrentMasterNodeInstance(SnapshotsInfoService.class);\n-            assertBusy(() -> {\n-                SnapshotShardSizeInfo snapshotShardSizeInfo = snapshotsInfoService.snapshotShardSizes();\n-                for (int shardId = 0; shardId < numberOfShards; shardId++) {\n-                    final ShardRouting primary = indexRoutingTable.shard(shardId).primaryShard();\n-                    assertThat(snapshotShardSizeInfo.getShardSize(primary), equalTo(ShardRouting.UNAVAILABLE_EXPECTED_SHARD_SIZE));\n-                    final long randomSize = randomNonNegativeLong();\n-                    assertThat(snapshotShardSizeInfo.getShardSize(primary, randomSize), equalTo(randomSize));\n-                }\n-            }, 60L, TimeUnit.SECONDS);\n-        } finally {\n-            transportServices.forEach(MockTransportService::clearAllRules);\n-        }\n+            assertTrue(allShardSnapshotSizes.stream().allMatch(size -> ShardRouting.UNAVAILABLE_EXPECTED_SHARD_SIZE == size));\n+            assertThat(simulatedFailures.get(), equalTo(numberOfShards));\n \n-        assertThat(indicesStatsRequestsCount.get(), equalTo(numberOfShards));\n-        blockCcrRestore.countDown();\n+            logger.debug(\"--> checking that SnapshotsInfoService does not know the real sizes fof snapshot shards\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9f1a51a4fca549952c027627247142c187e6f2"}, "originalPosition": 180}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTUzNDE5NA==", "bodyText": "It seems a bit delicate to wait inside the cluster-listener, I think that could lead to strange failures. On the other hand, it seems quite deliberate, since the old version did the assertBusy outside the listener. I would be curious to know more details on why this needed to be like this?", "url": "https://github.com/elastic/elasticsearch/pull/65436#discussion_r535534194", "createdAt": "2020-12-03T19:42:58Z", "author": {"login": "henningandersen"}, "path": "x-pack/plugin/ccr/src/internalClusterTest/java/org/elasticsearch/xpack/ccr/CcrRepositoryIT.java", "diffHunk": "@@ -613,83 +602,76 @@ public void testCcrRepositoryFailsToFetchSnapshotShardSizes() throws Exception {\n                         && indicesStatsRequest.search() == false\n                         && indicesStatsRequest.fieldData() == false\n                     ) {\n-                        indicesStatsRequestsCount.incrementAndGet();\n+                        simulatedFailures.incrementAndGet();\n                         channel.sendResponse(new ElasticsearchException(\"simulated\"));\n-                        return;\n                     }\n                 }\n                 handler.messageReceived(request, channel, task);\n             });\n-            transportServices.add(mockTransportService);\n         }\n \n         final String followerIndex = \"follower\";\n         try {\n-            final String leaderCluster = CcrRepository.NAME_PREFIX + \"leader_cluster\";\n-            final RepositoriesService repositoriesService = getFollowerCluster().getCurrentMasterNodeInstance(RepositoriesService.class);\n-            final Repository repository = repositoriesService.repository(leaderCluster);\n-            assertThat(repository.getMetadata().type(), equalTo(CcrRepository.TYPE));\n-            assertThat(repository.getMetadata().name(), equalTo(leaderCluster));\n-\n-            for (int i = 0; i < numberOfShards; i++) {\n-                final Index index = indexMetadata.getIndex();\n-                final int shardId = i;\n-                ElasticsearchException exception = expectThrows(ElasticsearchException.class,\n-                    () -> repository.getShardSnapshotStatus(\n-                        new SnapshotId(CcrRepository.LATEST, CcrRepository.LATEST),\n-                        new IndexId(index.getName(), index.getUUID()),\n-                        new ShardId(index, shardId)));\n-                assertThat(exception.getMessage(), equalTo(\"simulated\"));\n-            }\n-            assertThat(indicesStatsRequestsCount.getAndSet(0), equalTo(numberOfShards));\n-\n-            final RestoreService restoreService = getFollowerCluster().getCurrentMasterNodeInstance(RestoreService.class);\n-            final ClusterService clusterService = getFollowerCluster().getCurrentMasterNodeInstance(ClusterService.class);\n+            final SnapshotsInfoService snapshotsInfoService = getFollowerCluster().getCurrentMasterNodeInstance(SnapshotsInfoService.class);\n \n-            final PlainActionFuture<IndexRoutingTable> waitForRestoreInProgress = PlainActionFuture.newFuture();\n+            final PlainActionFuture<List<Long>> waitForAllShardSnapshotSizesFailures = PlainActionFuture.newFuture();\n             final ClusterStateListener listener = event -> {\n                 RestoreInProgress restoreInProgress = event.state().custom(RestoreInProgress.TYPE, RestoreInProgress.EMPTY);\n                 if (restoreInProgress != null\n                     && restoreInProgress.isEmpty() == false\n                     && event.state().routingTable().hasIndex(followerIndex)) {\n-                    waitForRestoreInProgress.onResponse(event.state().routingTable().index(followerIndex));\n+                    try {\n+                        final IndexRoutingTable indexRoutingTable = event.state().routingTable().index(followerIndex);\n+                        assertBusy(() -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9f1a51a4fca549952c027627247142c187e6f2"}, "originalPosition": 128}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTU0MDk0NA==", "bodyText": "I think we could change the implementation to only have one map now, by putting the UNAVAILABLE_EXPECTED_SHARD_SIZE value into the map when fetching fails. But we can leave that to follow-ups, we may want to refine the failure handling and that could benefit from having them in separate maps.", "url": "https://github.com/elastic/elasticsearch/pull/65436#discussion_r535540944", "createdAt": "2020-12-03T19:53:41Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -120,7 +120,7 @@ private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n     @Override\n     public SnapshotShardSizeInfo snapshotShardSizes() {\n         synchronized (mutex){\n-            final ImmutableOpenMap.Builder<SnapshotShard, Long> snapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+            final ImmutableOpenMap.Builder<SnapshotShard, Long> snapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShards);\n             for (SnapshotShard snapshotShard : failedSnapshotShards) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9f1a51a4fca549952c027627247142c187e6f2"}, "originalPosition": 24}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a7494327c556aacf1d48020386af1f971bc4a7ed", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/a7494327c556aacf1d48020386af1f971bc4a7ed", "committedDate": "2020-12-04T08:29:46Z", "message": "Merge branch 'master' into reroute-after-snapshot-shard-size-failure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7c4480bcf0af405532382578f418ba634fa5da0f", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/7c4480bcf0af405532382578f418ba634fa5da0f", "committedDate": "2020-12-04T08:38:43Z", "message": "waitForAllShardSnapshotSizesFailures"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3b0ab8fa2a80e91ce4e48df03d7ea76245fb76d3", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/3b0ab8fa2a80e91ce4e48df03d7ea76245fb76d3", "committedDate": "2020-12-04T08:40:36Z", "message": "fof"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ2ODQzMTM0", "url": "https://github.com/elastic/elasticsearch/pull/65436#pullrequestreview-546843134", "createdAt": "2020-12-08T08:15:17Z", "commit": {"oid": "9a9f1a51a4fca549952c027627247142c187e6f2"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQwODoxNToxN1rOIBMjeg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQwODozMjoxNVrOIBNPDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODEyNTE3OA==", "bodyText": "That is fine, but could we then check whether failedSnapshotShards.isEmpty() and return knownSnapshotShards directly if it is? Just to not waste cpu cycles unnecessarily on the happy case.", "url": "https://github.com/elastic/elasticsearch/pull/65436#discussion_r538125178", "createdAt": "2020-12-08T08:15:17Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -120,7 +120,7 @@ private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n     @Override\n     public SnapshotShardSizeInfo snapshotShardSizes() {\n         synchronized (mutex){\n-            final ImmutableOpenMap.Builder<SnapshotShard, Long> snapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+            final ImmutableOpenMap.Builder<SnapshotShard, Long> snapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShards);\n             for (SnapshotShard snapshotShard : failedSnapshotShards) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTU0MDk0NA=="}, "originalCommit": {"oid": "9a9f1a51a4fca549952c027627247142c187e6f2"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODEzNDQ1Mw==", "bodyText": "Can we add a comment on the importance of the ordering of cluster service listeners? Something like:\n// this assertBusy completes because the listener is added after the InternalSnapshotsInfoService and ClusterService preserves the order of listeners.\nI think that such a comment can help if this breaks in the future...", "url": "https://github.com/elastic/elasticsearch/pull/65436#discussion_r538134453", "createdAt": "2020-12-08T08:29:22Z", "author": {"login": "henningandersen"}, "path": "x-pack/plugin/ccr/src/internalClusterTest/java/org/elasticsearch/xpack/ccr/CcrRepositoryIT.java", "diffHunk": "@@ -613,83 +602,76 @@ public void testCcrRepositoryFailsToFetchSnapshotShardSizes() throws Exception {\n                         && indicesStatsRequest.search() == false\n                         && indicesStatsRequest.fieldData() == false\n                     ) {\n-                        indicesStatsRequestsCount.incrementAndGet();\n+                        simulatedFailures.incrementAndGet();\n                         channel.sendResponse(new ElasticsearchException(\"simulated\"));\n-                        return;\n                     }\n                 }\n                 handler.messageReceived(request, channel, task);\n             });\n-            transportServices.add(mockTransportService);\n         }\n \n         final String followerIndex = \"follower\";\n         try {\n-            final String leaderCluster = CcrRepository.NAME_PREFIX + \"leader_cluster\";\n-            final RepositoriesService repositoriesService = getFollowerCluster().getCurrentMasterNodeInstance(RepositoriesService.class);\n-            final Repository repository = repositoriesService.repository(leaderCluster);\n-            assertThat(repository.getMetadata().type(), equalTo(CcrRepository.TYPE));\n-            assertThat(repository.getMetadata().name(), equalTo(leaderCluster));\n-\n-            for (int i = 0; i < numberOfShards; i++) {\n-                final Index index = indexMetadata.getIndex();\n-                final int shardId = i;\n-                ElasticsearchException exception = expectThrows(ElasticsearchException.class,\n-                    () -> repository.getShardSnapshotStatus(\n-                        new SnapshotId(CcrRepository.LATEST, CcrRepository.LATEST),\n-                        new IndexId(index.getName(), index.getUUID()),\n-                        new ShardId(index, shardId)));\n-                assertThat(exception.getMessage(), equalTo(\"simulated\"));\n-            }\n-            assertThat(indicesStatsRequestsCount.getAndSet(0), equalTo(numberOfShards));\n-\n-            final RestoreService restoreService = getFollowerCluster().getCurrentMasterNodeInstance(RestoreService.class);\n-            final ClusterService clusterService = getFollowerCluster().getCurrentMasterNodeInstance(ClusterService.class);\n+            final SnapshotsInfoService snapshotsInfoService = getFollowerCluster().getCurrentMasterNodeInstance(SnapshotsInfoService.class);\n \n-            final PlainActionFuture<IndexRoutingTable> waitForRestoreInProgress = PlainActionFuture.newFuture();\n+            final PlainActionFuture<List<Long>> waitForAllShardSnapshotSizesFailures = PlainActionFuture.newFuture();\n             final ClusterStateListener listener = event -> {\n                 RestoreInProgress restoreInProgress = event.state().custom(RestoreInProgress.TYPE, RestoreInProgress.EMPTY);\n                 if (restoreInProgress != null\n                     && restoreInProgress.isEmpty() == false\n                     && event.state().routingTable().hasIndex(followerIndex)) {\n-                    waitForRestoreInProgress.onResponse(event.state().routingTable().index(followerIndex));\n+                    try {\n+                        final IndexRoutingTable indexRoutingTable = event.state().routingTable().index(followerIndex);\n+                        assertBusy(() -> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTUzNDE5NA=="}, "originalCommit": {"oid": "9a9f1a51a4fca549952c027627247142c187e6f2"}, "originalPosition": 128}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODEzNjMzNA==", "bodyText": "\ud83d\udc4d thanks for the clarification.", "url": "https://github.com/elastic/elasticsearch/pull/65436#discussion_r538136334", "createdAt": "2020-12-08T08:32:15Z", "author": {"login": "henningandersen"}, "path": "x-pack/plugin/ccr/src/internalClusterTest/java/org/elasticsearch/xpack/ccr/CcrRepositoryIT.java", "diffHunk": "@@ -613,83 +602,76 @@ public void testCcrRepositoryFailsToFetchSnapshotShardSizes() throws Exception {\n                         && indicesStatsRequest.search() == false\n                         && indicesStatsRequest.fieldData() == false\n                     ) {\n-                        indicesStatsRequestsCount.incrementAndGet();\n+                        simulatedFailures.incrementAndGet();\n                         channel.sendResponse(new ElasticsearchException(\"simulated\"));\n-                        return;\n                     }\n                 }\n                 handler.messageReceived(request, channel, task);\n             });\n-            transportServices.add(mockTransportService);\n         }\n \n         final String followerIndex = \"follower\";\n         try {\n-            final String leaderCluster = CcrRepository.NAME_PREFIX + \"leader_cluster\";\n-            final RepositoriesService repositoriesService = getFollowerCluster().getCurrentMasterNodeInstance(RepositoriesService.class);\n-            final Repository repository = repositoriesService.repository(leaderCluster);\n-            assertThat(repository.getMetadata().type(), equalTo(CcrRepository.TYPE));\n-            assertThat(repository.getMetadata().name(), equalTo(leaderCluster));\n-\n-            for (int i = 0; i < numberOfShards; i++) {\n-                final Index index = indexMetadata.getIndex();\n-                final int shardId = i;\n-                ElasticsearchException exception = expectThrows(ElasticsearchException.class,\n-                    () -> repository.getShardSnapshotStatus(\n-                        new SnapshotId(CcrRepository.LATEST, CcrRepository.LATEST),\n-                        new IndexId(index.getName(), index.getUUID()),\n-                        new ShardId(index, shardId)));\n-                assertThat(exception.getMessage(), equalTo(\"simulated\"));\n-            }\n-            assertThat(indicesStatsRequestsCount.getAndSet(0), equalTo(numberOfShards));\n-\n-            final RestoreService restoreService = getFollowerCluster().getCurrentMasterNodeInstance(RestoreService.class);\n-            final ClusterService clusterService = getFollowerCluster().getCurrentMasterNodeInstance(ClusterService.class);\n+            final SnapshotsInfoService snapshotsInfoService = getFollowerCluster().getCurrentMasterNodeInstance(SnapshotsInfoService.class);\n \n-            final PlainActionFuture<IndexRoutingTable> waitForRestoreInProgress = PlainActionFuture.newFuture();\n+            final PlainActionFuture<List<Long>> waitForAllShardSnapshotSizesFailures = PlainActionFuture.newFuture();\n             final ClusterStateListener listener = event -> {\n                 RestoreInProgress restoreInProgress = event.state().custom(RestoreInProgress.TYPE, RestoreInProgress.EMPTY);\n                 if (restoreInProgress != null\n                     && restoreInProgress.isEmpty() == false\n                     && event.state().routingTable().hasIndex(followerIndex)) {\n-                    waitForRestoreInProgress.onResponse(event.state().routingTable().index(followerIndex));\n+                    try {\n+                        final IndexRoutingTable indexRoutingTable = event.state().routingTable().index(followerIndex);\n+                        assertBusy(() -> {\n+                            List<Long> sizes = indexRoutingTable.shardsWithState(ShardRoutingState.UNASSIGNED).stream()\n+                                .filter(shard -> shard.unassignedInfo().getLastAllocationStatus() == AllocationStatus.FETCHING_SHARD_DATA)\n+                                .sorted(Comparator.comparingInt(ShardRouting::getId))\n+                                .map(shard -> snapshotsInfoService.snapshotShardSizes().getShardSize(shard))\n+                                .filter(Objects::nonNull)\n+                                .collect(Collectors.toList());\n+                            assertThat(sizes, hasSize(numberOfShards));\n+                            waitForAllShardSnapshotSizesFailures.onResponse(sizes);\n+                        });\n+                    } catch (Exception e) {\n+                        throw new AssertionError(\"Failed to retrieve all snapshot shard sizes\", e);\n+                    }\n                 }\n             };\n+\n+            final ClusterService clusterService = getFollowerCluster().getCurrentMasterNodeInstance(ClusterService.class);\n             clusterService.addListener(listener);\n \n-            final RestoreSnapshotRequest restoreRequest = new RestoreSnapshotRequest(leaderCluster, CcrRepository.LATEST)\n-                .indices(leaderIndex).indicesOptions(indicesOptions).renamePattern(\"^(.*)$\")\n-                .renameReplacement(followerIndex)\n-                .masterNodeTimeout(TimeValue.MAX_VALUE)\n-                .indexSettings(Settings.builder()\n-                    .put(IndexMetadata.SETTING_INDEX_PROVIDED_NAME, followerIndex)\n-                    .put(CcrSettings.CCR_FOLLOWING_INDEX_SETTING.getKey(), true));\n-            restoreService.restoreSnapshot(restoreRequest, PlainActionFuture.newFuture());\n+            logger.debug(\"--> creating follower index [{}]\", followerIndex);\n+            followerClient().execute(PutFollowAction.INSTANCE, putFollow(leaderIndex, followerIndex, ActiveShardCount.NONE));\n \n-            final IndexRoutingTable indexRoutingTable = waitForRestoreInProgress.get(30L, TimeUnit.SECONDS);\n+            final List<Long> allShardSnapshotSizes = waitForAllShardSnapshotSizesFailures.get(30L, TimeUnit.SECONDS);\n             clusterService.removeListener(listener);\n \n-            final SnapshotsInfoService snapshotsInfoService = getFollowerCluster().getCurrentMasterNodeInstance(SnapshotsInfoService.class);\n-            assertBusy(() -> {\n-                SnapshotShardSizeInfo snapshotShardSizeInfo = snapshotsInfoService.snapshotShardSizes();\n-                for (int shardId = 0; shardId < numberOfShards; shardId++) {\n-                    final ShardRouting primary = indexRoutingTable.shard(shardId).primaryShard();\n-                    assertThat(snapshotShardSizeInfo.getShardSize(primary), equalTo(ShardRouting.UNAVAILABLE_EXPECTED_SHARD_SIZE));\n-                    final long randomSize = randomNonNegativeLong();\n-                    assertThat(snapshotShardSizeInfo.getShardSize(primary, randomSize), equalTo(randomSize));\n-                }\n-            }, 60L, TimeUnit.SECONDS);\n-        } finally {\n-            transportServices.forEach(MockTransportService::clearAllRules);\n-        }\n+            assertTrue(allShardSnapshotSizes.stream().allMatch(size -> ShardRouting.UNAVAILABLE_EXPECTED_SHARD_SIZE == size));\n+            assertThat(simulatedFailures.get(), equalTo(numberOfShards));\n \n-        assertThat(indicesStatsRequestsCount.get(), equalTo(numberOfShards));\n-        blockCcrRestore.countDown();\n+            logger.debug(\"--> checking that SnapshotsInfoService does not know the real sizes fof snapshot shards\");\n+            final SnapshotShardSizeInfo snapshotShardSizeInfo = snapshotsInfoService.snapshotShardSizes();\n+            for (int shardId = 0; shardId < numberOfShards; shardId++) {\n+                final ShardRouting primary = clusterService.state().routingTable().index(followerIndex).shard(shardId).primaryShard();\n+                assertThat(snapshotShardSizeInfo.getShardSize(primary), equalTo(ShardRouting.UNAVAILABLE_EXPECTED_SHARD_SIZE));\n+                final long randomSize = randomNonNegativeLong();\n+                assertThat(snapshotShardSizeInfo.getShardSize(primary, randomSize), equalTo(randomSize));\n+            }\n \n-        followerClient().admin().cluster().prepareReroute().get();\n-        ensureFollowerGreen(followerIndex);\n+            if (randomBoolean()) {\n+                logger.debug(\"--> create a random index to generate more cluster state updates\");\n+                final String randomIndex = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+                assertAcked(followerClient().admin().indices().prepareCreate(randomIndex).setMasterNodeTimeout(TimeValue.MAX_VALUE));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTUyNjA5Nw=="}, "originalCommit": {"oid": "9a9f1a51a4fca549952c027627247142c187e6f2"}, "originalPosition": 194}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6930102cfdc1fdd271cc6852b49d5f54bcad6074", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/6930102cfdc1fdd271cc6852b49d5f54bcad6074", "committedDate": "2020-12-08T08:39:24Z", "message": "Merge branch 'master' into reroute-after-snapshot-shard-size-failure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cb19a836035249f56976f487433216dbbef6b2f5", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/cb19a836035249f56976f487433216dbbef6b2f5", "committedDate": "2020-12-08T08:56:40Z", "message": "feedback"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4435, "cost": 1, "resetAt": "2021-10-28T19:08:13Z"}}}