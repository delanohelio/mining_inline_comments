{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzc4NDY2NTg3", "number": 52662, "reviewThreads": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxNTozNzo1MlrODiXy-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQyMTo1NjowNFrODi3crA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3MzY4MDU3OnYy", "diffSide": "RIGHT", "path": "client/rest-high-level/src/test/java/org/elasticsearch/client/analytics/AnalyticsAggsIT.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxNTozNzo1MlrOFtlIqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxNTozNzo1MlrOFtlIqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzMzODY2Ng==", "bodyText": "Nit - maybe call this testTopMetricsTwoVaules or something? or leave a comment? Double sounds to me like it's testing values of type double.", "url": "https://github.com/elastic/elasticsearch/pull/52662#discussion_r383338666", "createdAt": "2020-02-24T15:37:52Z", "author": {"login": "not-napoleon"}, "path": "client/rest-high-level/src/test/java/org/elasticsearch/client/analytics/AnalyticsAggsIT.java", "diffHunk": "@@ -61,19 +61,38 @@ public void testStringStats() throws IOException {\n         assertThat(stats.getDistribution(), hasEntry(equalTo(\"t\"), closeTo(.09, .005)));\n     }\n \n-    public void testBasic() throws IOException {\n+    public void testTopMetricsSingle() throws IOException {\n         BulkRequest bulk = new BulkRequest(\"test\").setRefreshPolicy(RefreshPolicy.IMMEDIATE);\n         bulk.add(new IndexRequest().source(XContentType.JSON, \"s\", 1, \"v\", 2));\n         bulk.add(new IndexRequest().source(XContentType.JSON, \"s\", 2, \"v\", 3));\n         highLevelClient().bulk(bulk, RequestOptions.DEFAULT);\n         SearchRequest search = new SearchRequest(\"test\");\n         search.source().aggregation(new TopMetricsAggregationBuilder(\n-                \"test\", new FieldSortBuilder(\"s\").order(SortOrder.DESC), \"v\"));\n+                \"test\", new FieldSortBuilder(\"s\").order(SortOrder.DESC), 1, \"v\"));\n         SearchResponse response = highLevelClient().search(search, RequestOptions.DEFAULT);\n         ParsedTopMetrics top = response.getAggregations().get(\"test\");\n         assertThat(top.getTopMetrics(), hasSize(1));\n         ParsedTopMetrics.TopMetrics metric = top.getTopMetrics().get(0);\n         assertThat(metric.getSort(), equalTo(singletonList(2)));\n         assertThat(metric.getMetrics(), equalTo(singletonMap(\"v\", 3.0)));\n     }\n+\n+    public void testTopMetricsDouble() throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70e48271326cd73cc1deb99c06b3e1a34f8f0528"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3NzU0NTQ3OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/index/fielddata/fieldcomparator/DoubleValuesComparatorSource.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQxNToxMzo1MFrOFuJ8zg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxNzoyODo0MlrOFu1Drw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mzk0MTgzOA==", "bodyText": "I don't think I understand the need for this change. Can you add a comment or two for why we want to do it this way, please?", "url": "https://github.com/elastic/elasticsearch/pull/52662#discussion_r383941838", "createdAt": "2020-02-25T15:13:50Z", "author": {"login": "not-napoleon"}, "path": "server/src/main/java/org/elasticsearch/index/fielddata/fieldcomparator/DoubleValuesComparatorSource.java", "diffHunk": "@@ -96,23 +96,29 @@ public void setScorer(Scorable scorer) {\n     }\n \n     @Override\n-    public BucketedSort newBucketedSort(BigArrays bigArrays, SortOrder sortOrder, DocValueFormat format) {\n-        return new BucketedSort.ForDoubles(bigArrays, sortOrder, format) {\n+    public BucketedSort newBucketedSort(BigArrays bigArrays, SortOrder sortOrder, DocValueFormat format,\n+            int bucketSize, BucketedSort.ExtraData extra) {\n+        return new BucketedSort.ForDoubles(bigArrays, sortOrder, format, bucketSize, extra) {\n             private final double dMissingValue = (Double) missingObject(missingValue, sortOrder == SortOrder.DESC);\n \n             @Override\n             public Leaf forLeaf(LeafReaderContext ctx) throws IOException {\n-                return new Leaf() {\n+                return new Leaf(ctx) {\n                     private final NumericDoubleValues values = getNumericDocValues(ctx, dMissingValue);\n+                    private double docValue;\n \n                     @Override\n                     protected boolean advanceExact(int doc) throws IOException {\n-                        return values.advanceExact(doc);\n+                        if (values.advanceExact(doc)) {\n+                            docValue = values.doubleValue();\n+                            return true;\n+                        }\n+                        return false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3eedaccf3344563a431032ced50922d6ccc157d"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDE4ODM3NA==", "bodyText": "I got it in my head that I wanted docValue be \"fast\" and the underlying Lucene iterators aren't. I don't recall why I wanted that. Let me try to suss out what past-Nik was thinking.", "url": "https://github.com/elastic/elasticsearch/pull/52662#discussion_r384188374", "createdAt": "2020-02-25T23:24:53Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/index/fielddata/fieldcomparator/DoubleValuesComparatorSource.java", "diffHunk": "@@ -96,23 +96,29 @@ public void setScorer(Scorable scorer) {\n     }\n \n     @Override\n-    public BucketedSort newBucketedSort(BigArrays bigArrays, SortOrder sortOrder, DocValueFormat format) {\n-        return new BucketedSort.ForDoubles(bigArrays, sortOrder, format) {\n+    public BucketedSort newBucketedSort(BigArrays bigArrays, SortOrder sortOrder, DocValueFormat format,\n+            int bucketSize, BucketedSort.ExtraData extra) {\n+        return new BucketedSort.ForDoubles(bigArrays, sortOrder, format, bucketSize, extra) {\n             private final double dMissingValue = (Double) missingObject(missingValue, sortOrder == SortOrder.DESC);\n \n             @Override\n             public Leaf forLeaf(LeafReaderContext ctx) throws IOException {\n-                return new Leaf() {\n+                return new Leaf(ctx) {\n                     private final NumericDoubleValues values = getNumericDocValues(ctx, dMissingValue);\n+                    private double docValue;\n \n                     @Override\n                     protected boolean advanceExact(int doc) throws IOException {\n-                        return values.advanceExact(doc);\n+                        if (values.advanceExact(doc)) {\n+                            docValue = values.doubleValue();\n+                            return true;\n+                        }\n+                        return false;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mzk0MTgzOA=="}, "originalCommit": {"oid": "d3eedaccf3344563a431032ced50922d6ccc157d"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDY0ODExMQ==", "bodyText": "OK! I've figured it out. I've also pushed javadoc explaining it, but I'll say it here too: when you are in heap mode we call docValue() twice, once to check if the doc is competitive, and once to load the value into the heap. The underlying doc values code may or may not be fast. It looks like it most cases they are indeed fast, but this is a little bit of extra paranoia.", "url": "https://github.com/elastic/elasticsearch/pull/52662#discussion_r384648111", "createdAt": "2020-02-26T17:28:42Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/index/fielddata/fieldcomparator/DoubleValuesComparatorSource.java", "diffHunk": "@@ -96,23 +96,29 @@ public void setScorer(Scorable scorer) {\n     }\n \n     @Override\n-    public BucketedSort newBucketedSort(BigArrays bigArrays, SortOrder sortOrder, DocValueFormat format) {\n-        return new BucketedSort.ForDoubles(bigArrays, sortOrder, format) {\n+    public BucketedSort newBucketedSort(BigArrays bigArrays, SortOrder sortOrder, DocValueFormat format,\n+            int bucketSize, BucketedSort.ExtraData extra) {\n+        return new BucketedSort.ForDoubles(bigArrays, sortOrder, format, bucketSize, extra) {\n             private final double dMissingValue = (Double) missingObject(missingValue, sortOrder == SortOrder.DESC);\n \n             @Override\n             public Leaf forLeaf(LeafReaderContext ctx) throws IOException {\n-                return new Leaf() {\n+                return new Leaf(ctx) {\n                     private final NumericDoubleValues values = getNumericDocValues(ctx, dMissingValue);\n+                    private double docValue;\n \n                     @Override\n                     protected boolean advanceExact(int doc) throws IOException {\n-                        return values.advanceExact(doc);\n+                        if (values.advanceExact(doc)) {\n+                            docValue = values.doubleValue();\n+                            return true;\n+                        }\n+                        return false;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mzk0MTgzOA=="}, "originalCommit": {"oid": "d3eedaccf3344563a431032ced50922d6ccc157d"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3NzU1OTM0OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/index/fielddata/fieldcomparator/DoubleValuesComparatorSource.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQxNToxNzoxM1rOFuKFmA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQxNToxNzoxM1rOFuKFmA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mzk0NDA4OA==", "bodyText": "nit: in the other two copies of this function, this variable is just called \"value\"", "url": "https://github.com/elastic/elasticsearch/pull/52662#discussion_r383944088", "createdAt": "2020-02-25T15:17:13Z", "author": {"login": "not-napoleon"}, "path": "server/src/main/java/org/elasticsearch/index/fielddata/fieldcomparator/DoubleValuesComparatorSource.java", "diffHunk": "@@ -96,23 +96,29 @@ public void setScorer(Scorable scorer) {\n     }\n \n     @Override\n-    public BucketedSort newBucketedSort(BigArrays bigArrays, SortOrder sortOrder, DocValueFormat format) {\n-        return new BucketedSort.ForDoubles(bigArrays, sortOrder, format) {\n+    public BucketedSort newBucketedSort(BigArrays bigArrays, SortOrder sortOrder, DocValueFormat format,\n+            int bucketSize, BucketedSort.ExtraData extra) {\n+        return new BucketedSort.ForDoubles(bigArrays, sortOrder, format, bucketSize, extra) {\n             private final double dMissingValue = (Double) missingObject(missingValue, sortOrder == SortOrder.DESC);\n \n             @Override\n             public Leaf forLeaf(LeafReaderContext ctx) throws IOException {\n-                return new Leaf() {\n+                return new Leaf(ctx) {\n                     private final NumericDoubleValues values = getNumericDocValues(ctx, dMissingValue);\n+                    private double docValue;\n \n                     @Override\n                     protected boolean advanceExact(int doc) throws IOException {\n-                        return values.advanceExact(doc);\n+                        if (values.advanceExact(doc)) {\n+                            docValue = values.doubleValue();\n+                            return true;\n+                        }\n+                        return false;\n                     }\n \n                     @Override\n-                    protected double docValue() throws IOException {\n-                        return values.doubleValue();\n+                    protected double docValue() {\n+                        return docValue;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3eedaccf3344563a431032ced50922d6ccc157d"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3NzU2NTY4OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/index/fielddata/fieldcomparator/LongValuesComparatorSource.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQxNToxODo1MVrOFuKJqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMTowNDowMVrOFu8IhA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mzk0NTEyOA==", "bodyText": "Probably out of scope for this PR, but it's a little weird to me that we have three copies of this logic which only differ by a type.  Seems like we could refactor this a bit.  If you agree, let's open an issue for it.", "url": "https://github.com/elastic/elasticsearch/pull/52662#discussion_r383945128", "createdAt": "2020-02-25T15:18:51Z", "author": {"login": "not-napoleon"}, "path": "server/src/main/java/org/elasticsearch/index/fielddata/fieldcomparator/LongValuesComparatorSource.java", "diffHunk": "@@ -104,23 +104,29 @@ protected NumericDocValues getNumericDocValues(LeafReaderContext context, String\n     }\n \n     @Override\n-    public BucketedSort newBucketedSort(BigArrays bigArrays, SortOrder sortOrder, DocValueFormat format) {\n-        return new BucketedSort.ForLongs(bigArrays, sortOrder, format) {\n+    public BucketedSort newBucketedSort(BigArrays bigArrays, SortOrder sortOrder, DocValueFormat format,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3eedaccf3344563a431032ced50922d6ccc157d"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDE4NTM5Mg==", "bodyText": "They differ by the primitive types they operate on. I don't think they can share very much more than they do. But I can certainly look into sharing more.", "url": "https://github.com/elastic/elasticsearch/pull/52662#discussion_r384185392", "createdAt": "2020-02-25T23:17:10Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/index/fielddata/fieldcomparator/LongValuesComparatorSource.java", "diffHunk": "@@ -104,23 +104,29 @@ protected NumericDocValues getNumericDocValues(LeafReaderContext context, String\n     }\n \n     @Override\n-    public BucketedSort newBucketedSort(BigArrays bigArrays, SortOrder sortOrder, DocValueFormat format) {\n-        return new BucketedSort.ForLongs(bigArrays, sortOrder, format) {\n+    public BucketedSort newBucketedSort(BigArrays bigArrays, SortOrder sortOrder, DocValueFormat format,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mzk0NTEyOA=="}, "originalCommit": {"oid": "d3eedaccf3344563a431032ced50922d6ccc157d"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc2NDAzNg==", "bodyText": "That's fair.  I didn't spend a lot of time thinking about it other than to see that they looked really similar.  If it's necessary, it's necessary.", "url": "https://github.com/elastic/elasticsearch/pull/52662#discussion_r384764036", "createdAt": "2020-02-26T21:04:01Z", "author": {"login": "not-napoleon"}, "path": "server/src/main/java/org/elasticsearch/index/fielddata/fieldcomparator/LongValuesComparatorSource.java", "diffHunk": "@@ -104,23 +104,29 @@ protected NumericDocValues getNumericDocValues(LeafReaderContext context, String\n     }\n \n     @Override\n-    public BucketedSort newBucketedSort(BigArrays bigArrays, SortOrder sortOrder, DocValueFormat format) {\n-        return new BucketedSort.ForLongs(bigArrays, sortOrder, format) {\n+    public BucketedSort newBucketedSort(BigArrays bigArrays, SortOrder sortOrder, DocValueFormat format,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mzk0NTEyOA=="}, "originalCommit": {"oid": "d3eedaccf3344563a431032ced50922d6ccc157d"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3NzYzMzQ3OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQxNTozNTowOFrOFuK0Hw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQxNTozNTowOFrOFuK0Hw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mzk1NTk5OQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             * he tracking valu at the root. So collecting values is {@code O(1)}.\n          \n          \n            \n             * the tracking value at the root. So collecting values is {@code O(1)}.", "url": "https://github.com/elastic/elasticsearch/pull/52662#discussion_r383955999", "createdAt": "2020-02-25T15:35:08Z", "author": {"login": "not-napoleon"}, "path": "server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java", "diffHunk": "@@ -33,20 +33,122 @@\n import org.elasticsearch.search.DocValueFormat;\n \n import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Locale;\n+\n+import static java.util.Collections.emptyList;\n \n /**\n  * Type specialized sort implementations designed for use in aggregations.\n+ * Aggregations have a couple of super interesting characteristics:\n+ * <ul>\n+ * <li>They can have many, many buckets so this implementation backs to\n+ * {@link BigArrays} so it doesn't need to allocate any objects per bucket\n+ * and the circuit breaker in {@linkplain BigArrays} will automatically\n+ * track memory usage and abort execution if it grows too large.</li>\n+ * <li>Its fairly common for a bucket to be collected but not returned so\n+ * these implementations delay as much work as possible until collection</li>\n+ * </ul>\n+ * <p>\n+ * Every bucket is in one of two states: \"gathering\" or min/max \"heap\". While\n+ * \"gathering\" the next empty slot is stored in the \"root\" offset of the\n+ * bucket and collecting a value is just adding it in the next slot bumping\n+ * he tracking valu at the root. So collecting values is {@code O(1)}.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3eedaccf3344563a431032ced50922d6ccc157d"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3NzcyMzYzOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQxNTo1NjoxNFrOFuLtLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQxNTo1NjoxNFrOFuLtLA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mzk3MDYwNA==", "bodyText": "This looks handy, thanks for including it!", "url": "https://github.com/elastic/elasticsearch/pull/52662#discussion_r383970604", "createdAt": "2020-02-25T15:56:14Z", "author": {"login": "not-napoleon"}, "path": "server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java", "diffHunk": "@@ -86,126 +233,305 @@ public final SortValue getValue(long bucket) {\n     /**\n      * The {@linkplain BigArray} backing this sort.\n      */\n-    protected abstract BigArray buckets();\n+    protected abstract BigArray values();\n \n     /**\n      * Grow the {@linkplain BigArray} backing this sort to account for new buckets.\n      * This will only be called if the array is too small.\n      */\n-    protected abstract void grow(long minSize);\n+    protected abstract void growValues(long minSize);\n+\n+    /**\n+     * Get the next index that should be \"gathered\" for a bucket rooted\n+     * at {@code rootIndex}.\n+     */\n+    protected abstract int getNextGatherOffset(long rootIndex);\n+\n+    /**\n+     * Set the next index that should be \"gathered\" for a bucket rooted\n+     * at {@code rootIndex}.\n+     */\n+    protected abstract void setNextGatherOffset(long rootIndex, int offset);\n+\n+    /**\n+     * Get the value at an index.\n+     */\n+    protected abstract SortValue getValue(long index);\n+\n+    /**\n+     * {@code true} if the entry at index {@code lhs} is \"better\" than\n+     * the entry at {@code rhs}. \"Better\" in this means \"lower\" for\n+     * {@link SortOrder#ASC} and \"higher\" for {@link SortOrder#DESC}. \n+     */\n+    protected abstract boolean betterThan(long lhs, long rhs);\n \n     /**\n-     * Get the value for a bucket. This will only be called if the bucket was collected.\n+     * Swap the data at two indices.\n      */\n-    protected abstract SortValue getValueForBucket(long bucket);\n+    protected abstract void swap(long lhs, long rhs);\n+\n+    /**\n+     * Return a fairly human readable representation of the array backing the sort.\n+     * <p>\n+     * This is intentionally not a {@link #toString()} implementation because it'll\n+     * be quite slow.\n+     * </p>\n+     */\n+    protected final String debugFormat() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3eedaccf3344563a431032ced50922d6ccc157d"}, "originalPosition": 245}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3NzczNjI4OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQxNTo1OTowMFrOFuL05g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQxNTo1OTowMFrOFuL05g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mzk3MjU4Mg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * a fairly well studied algorithm attributed to Floyd there's\n          \n          \n            \n                 * a fairly well studied algorithm attributed to Floyd. There's", "url": "https://github.com/elastic/elasticsearch/pull/52662#discussion_r383972582", "createdAt": "2020-02-25T15:59:00Z", "author": {"login": "not-napoleon"}, "path": "server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java", "diffHunk": "@@ -86,126 +233,305 @@ public final SortValue getValue(long bucket) {\n     /**\n      * The {@linkplain BigArray} backing this sort.\n      */\n-    protected abstract BigArray buckets();\n+    protected abstract BigArray values();\n \n     /**\n      * Grow the {@linkplain BigArray} backing this sort to account for new buckets.\n      * This will only be called if the array is too small.\n      */\n-    protected abstract void grow(long minSize);\n+    protected abstract void growValues(long minSize);\n+\n+    /**\n+     * Get the next index that should be \"gathered\" for a bucket rooted\n+     * at {@code rootIndex}.\n+     */\n+    protected abstract int getNextGatherOffset(long rootIndex);\n+\n+    /**\n+     * Set the next index that should be \"gathered\" for a bucket rooted\n+     * at {@code rootIndex}.\n+     */\n+    protected abstract void setNextGatherOffset(long rootIndex, int offset);\n+\n+    /**\n+     * Get the value at an index.\n+     */\n+    protected abstract SortValue getValue(long index);\n+\n+    /**\n+     * {@code true} if the entry at index {@code lhs} is \"better\" than\n+     * the entry at {@code rhs}. \"Better\" in this means \"lower\" for\n+     * {@link SortOrder#ASC} and \"higher\" for {@link SortOrder#DESC}. \n+     */\n+    protected abstract boolean betterThan(long lhs, long rhs);\n \n     /**\n-     * Get the value for a bucket. This will only be called if the bucket was collected.\n+     * Swap the data at two indices.\n      */\n-    protected abstract SortValue getValueForBucket(long bucket);\n+    protected abstract void swap(long lhs, long rhs);\n+\n+    /**\n+     * Return a fairly human readable representation of the array backing the sort.\n+     * <p>\n+     * This is intentionally not a {@link #toString()} implementation because it'll\n+     * be quite slow.\n+     * </p>\n+     */\n+    protected final String debugFormat() {\n+        StringBuilder b = new StringBuilder();\n+        for (long index = 0; index < values().size(); index++) {\n+            if (index % bucketSize == 0) {\n+                b.append('\\n').append(String.format(Locale.ROOT, \"%20d\", index / bucketSize)).append(\":  \");\n+            }\n+            b.append(String.format(Locale.ROOT, \"%20s\", getValue(index))).append(' ');\n+        }\n+        return b.toString();\n+    }\n+\n+    /**\n+     * Initialize the gather offsets after setting up values. Subclasses\n+     * should call this once, after setting up their {@link #values()}.  \n+     */\n+    protected final void initGatherOffsets() {\n+        setNextGatherOffsets(0);\n+    }\n+\n+    /**\n+     * Allocate storage for more buckets and store the \"next gather offset\"\n+     * for those new buckets.\n+     */\n+    private void grow(long minSize) {\n+        long oldMax = values().size() - 1;\n+        growValues(minSize);\n+        // Set the next gather offsets for all newly allocated buckets.\n+        setNextGatherOffsets(oldMax - (oldMax % getBucketSize()) + getBucketSize());\n+    }\n+\n+    /**\n+     * Maintain the \"next gather offsets\" for newly allocated buckets.\n+     */\n+    private void setNextGatherOffsets(long startingAt) {\n+        int nextOffset = getBucketSize() - 1;\n+        for (long bucketRoot = startingAt; bucketRoot < values().size(); bucketRoot += getBucketSize()) {\n+            setNextGatherOffset(bucketRoot, nextOffset);\n+        }\n+    }\n+\n+    /**\n+     * Heapify a bucket who's entries are in random order.\n+     * <p>\n+     * While this *looks* like it could easily be {@code O(n * log n)}, it is\n+     * a fairly well studied algorithm attributed to Floyd there's", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3eedaccf3344563a431032ced50922d6ccc157d"}, "originalPosition": 289}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3ODM3ODE5OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQxOToyMDo0M1rOFuR80Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQyMzoxODo1MlrOFuY2Ww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDA3MjkxMw==", "bodyText": "It was unclear to me on the first read that left and right referred to the child nodes of the heap, not left and right array partitions.  Maybe rename to leftChild and rightChild or something like that?", "url": "https://github.com/elastic/elasticsearch/pull/52662#discussion_r384072913", "createdAt": "2020-02-25T19:20:43Z", "author": {"login": "not-napoleon"}, "path": "server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java", "diffHunk": "@@ -86,126 +233,305 @@ public final SortValue getValue(long bucket) {\n     /**\n      * The {@linkplain BigArray} backing this sort.\n      */\n-    protected abstract BigArray buckets();\n+    protected abstract BigArray values();\n \n     /**\n      * Grow the {@linkplain BigArray} backing this sort to account for new buckets.\n      * This will only be called if the array is too small.\n      */\n-    protected abstract void grow(long minSize);\n+    protected abstract void growValues(long minSize);\n+\n+    /**\n+     * Get the next index that should be \"gathered\" for a bucket rooted\n+     * at {@code rootIndex}.\n+     */\n+    protected abstract int getNextGatherOffset(long rootIndex);\n+\n+    /**\n+     * Set the next index that should be \"gathered\" for a bucket rooted\n+     * at {@code rootIndex}.\n+     */\n+    protected abstract void setNextGatherOffset(long rootIndex, int offset);\n+\n+    /**\n+     * Get the value at an index.\n+     */\n+    protected abstract SortValue getValue(long index);\n+\n+    /**\n+     * {@code true} if the entry at index {@code lhs} is \"better\" than\n+     * the entry at {@code rhs}. \"Better\" in this means \"lower\" for\n+     * {@link SortOrder#ASC} and \"higher\" for {@link SortOrder#DESC}. \n+     */\n+    protected abstract boolean betterThan(long lhs, long rhs);\n \n     /**\n-     * Get the value for a bucket. This will only be called if the bucket was collected.\n+     * Swap the data at two indices.\n      */\n-    protected abstract SortValue getValueForBucket(long bucket);\n+    protected abstract void swap(long lhs, long rhs);\n+\n+    /**\n+     * Return a fairly human readable representation of the array backing the sort.\n+     * <p>\n+     * This is intentionally not a {@link #toString()} implementation because it'll\n+     * be quite slow.\n+     * </p>\n+     */\n+    protected final String debugFormat() {\n+        StringBuilder b = new StringBuilder();\n+        for (long index = 0; index < values().size(); index++) {\n+            if (index % bucketSize == 0) {\n+                b.append('\\n').append(String.format(Locale.ROOT, \"%20d\", index / bucketSize)).append(\":  \");\n+            }\n+            b.append(String.format(Locale.ROOT, \"%20s\", getValue(index))).append(' ');\n+        }\n+        return b.toString();\n+    }\n+\n+    /**\n+     * Initialize the gather offsets after setting up values. Subclasses\n+     * should call this once, after setting up their {@link #values()}.  \n+     */\n+    protected final void initGatherOffsets() {\n+        setNextGatherOffsets(0);\n+    }\n+\n+    /**\n+     * Allocate storage for more buckets and store the \"next gather offset\"\n+     * for those new buckets.\n+     */\n+    private void grow(long minSize) {\n+        long oldMax = values().size() - 1;\n+        growValues(minSize);\n+        // Set the next gather offsets for all newly allocated buckets.\n+        setNextGatherOffsets(oldMax - (oldMax % getBucketSize()) + getBucketSize());\n+    }\n+\n+    /**\n+     * Maintain the \"next gather offsets\" for newly allocated buckets.\n+     */\n+    private void setNextGatherOffsets(long startingAt) {\n+        int nextOffset = getBucketSize() - 1;\n+        for (long bucketRoot = startingAt; bucketRoot < values().size(); bucketRoot += getBucketSize()) {\n+            setNextGatherOffset(bucketRoot, nextOffset);\n+        }\n+    }\n+\n+    /**\n+     * Heapify a bucket who's entries are in random order.\n+     * <p>\n+     * While this *looks* like it could easily be {@code O(n * log n)}, it is\n+     * a fairly well studied algorithm attributed to Floyd there's\n+     * been a bunch of work that puts this at {@code O(n)}, close to 1.88n worst\n+     * case.\n+     * </p>\n+     * <ul>\n+     * <li>Hayward, Ryan; McDiarmid, Colin (1991).  \n+     * <a href=\"https://web.archive.org/web/20160205023201/http://www.stats.ox.ac.uk/__data/assets/pdf_file/0015/4173/heapbuildjalg.pdf\">\n+     * Average Case Analysis of Heap Building byRepeated Insertion</a> J. Algorithms.\n+     * <li>D.E. Knuth, \u201dThe Art of Computer Programming, Vol. 3, Sorting and Searching\u201d</li>\n+     * </ul>\n+     * @param rootIndex the index the start of the bucket \n+     */\n+    private void heapify(long rootIndex) {\n+        int maxParent = bucketSize / 2 - 1;\n+        for (int parent = maxParent; parent >= 0; parent--) {\n+            downHeap(rootIndex, parent);\n+        }\n+    }\n+\n+    /**\n+     * Correct the heap invariant of a parent and its children. This\n+     * runs in {@code O(log n)} time.\n+     * @param rootIndex index of the start of the bucket\n+     * @param parent Index within the bucket of the parent to check.\n+     *               For example, 0 is the \"root\". \n+     */\n+    private void downHeap(long rootIndex, int parent) {\n+        while (true) {\n+            long parentIndex = rootIndex + parent;\n+            int worst = parent;\n+            long worstIndex = parentIndex;\n+            int left = parent * 2 + 1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3eedaccf3344563a431032ced50922d6ccc157d"}, "originalPosition": 320}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDE4NTk0Nw==", "bodyText": "\ud83d\udc4d", "url": "https://github.com/elastic/elasticsearch/pull/52662#discussion_r384185947", "createdAt": "2020-02-25T23:18:52Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java", "diffHunk": "@@ -86,126 +233,305 @@ public final SortValue getValue(long bucket) {\n     /**\n      * The {@linkplain BigArray} backing this sort.\n      */\n-    protected abstract BigArray buckets();\n+    protected abstract BigArray values();\n \n     /**\n      * Grow the {@linkplain BigArray} backing this sort to account for new buckets.\n      * This will only be called if the array is too small.\n      */\n-    protected abstract void grow(long minSize);\n+    protected abstract void growValues(long minSize);\n+\n+    /**\n+     * Get the next index that should be \"gathered\" for a bucket rooted\n+     * at {@code rootIndex}.\n+     */\n+    protected abstract int getNextGatherOffset(long rootIndex);\n+\n+    /**\n+     * Set the next index that should be \"gathered\" for a bucket rooted\n+     * at {@code rootIndex}.\n+     */\n+    protected abstract void setNextGatherOffset(long rootIndex, int offset);\n+\n+    /**\n+     * Get the value at an index.\n+     */\n+    protected abstract SortValue getValue(long index);\n+\n+    /**\n+     * {@code true} if the entry at index {@code lhs} is \"better\" than\n+     * the entry at {@code rhs}. \"Better\" in this means \"lower\" for\n+     * {@link SortOrder#ASC} and \"higher\" for {@link SortOrder#DESC}. \n+     */\n+    protected abstract boolean betterThan(long lhs, long rhs);\n \n     /**\n-     * Get the value for a bucket. This will only be called if the bucket was collected.\n+     * Swap the data at two indices.\n      */\n-    protected abstract SortValue getValueForBucket(long bucket);\n+    protected abstract void swap(long lhs, long rhs);\n+\n+    /**\n+     * Return a fairly human readable representation of the array backing the sort.\n+     * <p>\n+     * This is intentionally not a {@link #toString()} implementation because it'll\n+     * be quite slow.\n+     * </p>\n+     */\n+    protected final String debugFormat() {\n+        StringBuilder b = new StringBuilder();\n+        for (long index = 0; index < values().size(); index++) {\n+            if (index % bucketSize == 0) {\n+                b.append('\\n').append(String.format(Locale.ROOT, \"%20d\", index / bucketSize)).append(\":  \");\n+            }\n+            b.append(String.format(Locale.ROOT, \"%20s\", getValue(index))).append(' ');\n+        }\n+        return b.toString();\n+    }\n+\n+    /**\n+     * Initialize the gather offsets after setting up values. Subclasses\n+     * should call this once, after setting up their {@link #values()}.  \n+     */\n+    protected final void initGatherOffsets() {\n+        setNextGatherOffsets(0);\n+    }\n+\n+    /**\n+     * Allocate storage for more buckets and store the \"next gather offset\"\n+     * for those new buckets.\n+     */\n+    private void grow(long minSize) {\n+        long oldMax = values().size() - 1;\n+        growValues(minSize);\n+        // Set the next gather offsets for all newly allocated buckets.\n+        setNextGatherOffsets(oldMax - (oldMax % getBucketSize()) + getBucketSize());\n+    }\n+\n+    /**\n+     * Maintain the \"next gather offsets\" for newly allocated buckets.\n+     */\n+    private void setNextGatherOffsets(long startingAt) {\n+        int nextOffset = getBucketSize() - 1;\n+        for (long bucketRoot = startingAt; bucketRoot < values().size(); bucketRoot += getBucketSize()) {\n+            setNextGatherOffset(bucketRoot, nextOffset);\n+        }\n+    }\n+\n+    /**\n+     * Heapify a bucket who's entries are in random order.\n+     * <p>\n+     * While this *looks* like it could easily be {@code O(n * log n)}, it is\n+     * a fairly well studied algorithm attributed to Floyd there's\n+     * been a bunch of work that puts this at {@code O(n)}, close to 1.88n worst\n+     * case.\n+     * </p>\n+     * <ul>\n+     * <li>Hayward, Ryan; McDiarmid, Colin (1991).  \n+     * <a href=\"https://web.archive.org/web/20160205023201/http://www.stats.ox.ac.uk/__data/assets/pdf_file/0015/4173/heapbuildjalg.pdf\">\n+     * Average Case Analysis of Heap Building byRepeated Insertion</a> J. Algorithms.\n+     * <li>D.E. Knuth, \u201dThe Art of Computer Programming, Vol. 3, Sorting and Searching\u201d</li>\n+     * </ul>\n+     * @param rootIndex the index the start of the bucket \n+     */\n+    private void heapify(long rootIndex) {\n+        int maxParent = bucketSize / 2 - 1;\n+        for (int parent = maxParent; parent >= 0; parent--) {\n+            downHeap(rootIndex, parent);\n+        }\n+    }\n+\n+    /**\n+     * Correct the heap invariant of a parent and its children. This\n+     * runs in {@code O(log n)} time.\n+     * @param rootIndex index of the start of the bucket\n+     * @param parent Index within the bucket of the parent to check.\n+     *               For example, 0 is the \"root\". \n+     */\n+    private void downHeap(long rootIndex, int parent) {\n+        while (true) {\n+            long parentIndex = rootIndex + parent;\n+            int worst = parent;\n+            long worstIndex = parentIndex;\n+            int left = parent * 2 + 1;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDA3MjkxMw=="}, "originalCommit": {"oid": "d3eedaccf3344563a431032ced50922d6ccc157d"}, "originalPosition": 320}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3ODQwNDAwOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQxOToyNzo1OVrOFuSMYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQyMzoxOTowNVrOFuY2mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDA3Njg5OA==", "bodyText": "I love a good paper reference as much as the next nerd, but as long as we're citing references, maybe also link to an article just on how heapify works? I found even wikipedia's short explanation of how Floyd's algorithm works helpful while reviewing: https://en.wikipedia.org/wiki/Heapsort#Floyd's_heap_construction", "url": "https://github.com/elastic/elasticsearch/pull/52662#discussion_r384076898", "createdAt": "2020-02-25T19:27:59Z", "author": {"login": "not-napoleon"}, "path": "server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java", "diffHunk": "@@ -86,126 +233,305 @@ public final SortValue getValue(long bucket) {\n     /**\n      * The {@linkplain BigArray} backing this sort.\n      */\n-    protected abstract BigArray buckets();\n+    protected abstract BigArray values();\n \n     /**\n      * Grow the {@linkplain BigArray} backing this sort to account for new buckets.\n      * This will only be called if the array is too small.\n      */\n-    protected abstract void grow(long minSize);\n+    protected abstract void growValues(long minSize);\n+\n+    /**\n+     * Get the next index that should be \"gathered\" for a bucket rooted\n+     * at {@code rootIndex}.\n+     */\n+    protected abstract int getNextGatherOffset(long rootIndex);\n+\n+    /**\n+     * Set the next index that should be \"gathered\" for a bucket rooted\n+     * at {@code rootIndex}.\n+     */\n+    protected abstract void setNextGatherOffset(long rootIndex, int offset);\n+\n+    /**\n+     * Get the value at an index.\n+     */\n+    protected abstract SortValue getValue(long index);\n+\n+    /**\n+     * {@code true} if the entry at index {@code lhs} is \"better\" than\n+     * the entry at {@code rhs}. \"Better\" in this means \"lower\" for\n+     * {@link SortOrder#ASC} and \"higher\" for {@link SortOrder#DESC}. \n+     */\n+    protected abstract boolean betterThan(long lhs, long rhs);\n \n     /**\n-     * Get the value for a bucket. This will only be called if the bucket was collected.\n+     * Swap the data at two indices.\n      */\n-    protected abstract SortValue getValueForBucket(long bucket);\n+    protected abstract void swap(long lhs, long rhs);\n+\n+    /**\n+     * Return a fairly human readable representation of the array backing the sort.\n+     * <p>\n+     * This is intentionally not a {@link #toString()} implementation because it'll\n+     * be quite slow.\n+     * </p>\n+     */\n+    protected final String debugFormat() {\n+        StringBuilder b = new StringBuilder();\n+        for (long index = 0; index < values().size(); index++) {\n+            if (index % bucketSize == 0) {\n+                b.append('\\n').append(String.format(Locale.ROOT, \"%20d\", index / bucketSize)).append(\":  \");\n+            }\n+            b.append(String.format(Locale.ROOT, \"%20s\", getValue(index))).append(' ');\n+        }\n+        return b.toString();\n+    }\n+\n+    /**\n+     * Initialize the gather offsets after setting up values. Subclasses\n+     * should call this once, after setting up their {@link #values()}.  \n+     */\n+    protected final void initGatherOffsets() {\n+        setNextGatherOffsets(0);\n+    }\n+\n+    /**\n+     * Allocate storage for more buckets and store the \"next gather offset\"\n+     * for those new buckets.\n+     */\n+    private void grow(long minSize) {\n+        long oldMax = values().size() - 1;\n+        growValues(minSize);\n+        // Set the next gather offsets for all newly allocated buckets.\n+        setNextGatherOffsets(oldMax - (oldMax % getBucketSize()) + getBucketSize());\n+    }\n+\n+    /**\n+     * Maintain the \"next gather offsets\" for newly allocated buckets.\n+     */\n+    private void setNextGatherOffsets(long startingAt) {\n+        int nextOffset = getBucketSize() - 1;\n+        for (long bucketRoot = startingAt; bucketRoot < values().size(); bucketRoot += getBucketSize()) {\n+            setNextGatherOffset(bucketRoot, nextOffset);\n+        }\n+    }\n+\n+    /**\n+     * Heapify a bucket who's entries are in random order.\n+     * <p>\n+     * While this *looks* like it could easily be {@code O(n * log n)}, it is\n+     * a fairly well studied algorithm attributed to Floyd there's\n+     * been a bunch of work that puts this at {@code O(n)}, close to 1.88n worst\n+     * case.\n+     * </p>\n+     * <ul>\n+     * <li>Hayward, Ryan; McDiarmid, Colin (1991).  \n+     * <a href=\"https://web.archive.org/web/20160205023201/http://www.stats.ox.ac.uk/__data/assets/pdf_file/0015/4173/heapbuildjalg.pdf\">", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3eedaccf3344563a431032ced50922d6ccc157d"}, "originalPosition": 295}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDE4NjAxMQ==", "bodyText": "\ud83d\udc4d", "url": "https://github.com/elastic/elasticsearch/pull/52662#discussion_r384186011", "createdAt": "2020-02-25T23:19:05Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java", "diffHunk": "@@ -86,126 +233,305 @@ public final SortValue getValue(long bucket) {\n     /**\n      * The {@linkplain BigArray} backing this sort.\n      */\n-    protected abstract BigArray buckets();\n+    protected abstract BigArray values();\n \n     /**\n      * Grow the {@linkplain BigArray} backing this sort to account for new buckets.\n      * This will only be called if the array is too small.\n      */\n-    protected abstract void grow(long minSize);\n+    protected abstract void growValues(long minSize);\n+\n+    /**\n+     * Get the next index that should be \"gathered\" for a bucket rooted\n+     * at {@code rootIndex}.\n+     */\n+    protected abstract int getNextGatherOffset(long rootIndex);\n+\n+    /**\n+     * Set the next index that should be \"gathered\" for a bucket rooted\n+     * at {@code rootIndex}.\n+     */\n+    protected abstract void setNextGatherOffset(long rootIndex, int offset);\n+\n+    /**\n+     * Get the value at an index.\n+     */\n+    protected abstract SortValue getValue(long index);\n+\n+    /**\n+     * {@code true} if the entry at index {@code lhs} is \"better\" than\n+     * the entry at {@code rhs}. \"Better\" in this means \"lower\" for\n+     * {@link SortOrder#ASC} and \"higher\" for {@link SortOrder#DESC}. \n+     */\n+    protected abstract boolean betterThan(long lhs, long rhs);\n \n     /**\n-     * Get the value for a bucket. This will only be called if the bucket was collected.\n+     * Swap the data at two indices.\n      */\n-    protected abstract SortValue getValueForBucket(long bucket);\n+    protected abstract void swap(long lhs, long rhs);\n+\n+    /**\n+     * Return a fairly human readable representation of the array backing the sort.\n+     * <p>\n+     * This is intentionally not a {@link #toString()} implementation because it'll\n+     * be quite slow.\n+     * </p>\n+     */\n+    protected final String debugFormat() {\n+        StringBuilder b = new StringBuilder();\n+        for (long index = 0; index < values().size(); index++) {\n+            if (index % bucketSize == 0) {\n+                b.append('\\n').append(String.format(Locale.ROOT, \"%20d\", index / bucketSize)).append(\":  \");\n+            }\n+            b.append(String.format(Locale.ROOT, \"%20s\", getValue(index))).append(' ');\n+        }\n+        return b.toString();\n+    }\n+\n+    /**\n+     * Initialize the gather offsets after setting up values. Subclasses\n+     * should call this once, after setting up their {@link #values()}.  \n+     */\n+    protected final void initGatherOffsets() {\n+        setNextGatherOffsets(0);\n+    }\n+\n+    /**\n+     * Allocate storage for more buckets and store the \"next gather offset\"\n+     * for those new buckets.\n+     */\n+    private void grow(long minSize) {\n+        long oldMax = values().size() - 1;\n+        growValues(minSize);\n+        // Set the next gather offsets for all newly allocated buckets.\n+        setNextGatherOffsets(oldMax - (oldMax % getBucketSize()) + getBucketSize());\n+    }\n+\n+    /**\n+     * Maintain the \"next gather offsets\" for newly allocated buckets.\n+     */\n+    private void setNextGatherOffsets(long startingAt) {\n+        int nextOffset = getBucketSize() - 1;\n+        for (long bucketRoot = startingAt; bucketRoot < values().size(); bucketRoot += getBucketSize()) {\n+            setNextGatherOffset(bucketRoot, nextOffset);\n+        }\n+    }\n+\n+    /**\n+     * Heapify a bucket who's entries are in random order.\n+     * <p>\n+     * While this *looks* like it could easily be {@code O(n * log n)}, it is\n+     * a fairly well studied algorithm attributed to Floyd there's\n+     * been a bunch of work that puts this at {@code O(n)}, close to 1.88n worst\n+     * case.\n+     * </p>\n+     * <ul>\n+     * <li>Hayward, Ryan; McDiarmid, Colin (1991).  \n+     * <a href=\"https://web.archive.org/web/20160205023201/http://www.stats.ox.ac.uk/__data/assets/pdf_file/0015/4173/heapbuildjalg.pdf\">", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDA3Njg5OA=="}, "originalCommit": {"oid": "d3eedaccf3344563a431032ced50922d6ccc157d"}, "originalPosition": 295}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3ODgzNzY4OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/AnalyticsPlugin.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQyMTo0NjozOVrOFuWZFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQyMTo0NjozOVrOFuWZFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDE0NTY4NQ==", "bodyText": "Oh, hey, I remember this conversation.  :)", "url": "https://github.com/elastic/elasticsearch/pull/52662#discussion_r384145685", "createdAt": "2020-02-25T21:46:39Z", "author": {"login": "not-napoleon"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/AnalyticsPlugin.java", "diffHunk": "@@ -88,6 +90,11 @@ public AnalyticsPlugin() { }\n             new ActionHandler<>(AnalyticsStatsAction.INSTANCE, TransportAnalyticsStatsAction.class));\n     }\n \n+    @Override\n+    public List<Setting<?>> getSettings() {\n+        return singletonList(TopMetricsAggregatorFactory.MAX_BUCKET_SIZE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4395882abf6a3779d3a92ce95464e539abd634ed"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3ODg0MzA5OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetrics.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQyMTo0ODozMlrOFuWcnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQyMzoxOTo1MFrOFuY3gA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDE0NjU4OA==", "bodyText": "Just double checking - we haven't released a version of this yet, so changing the serialization format here is safe, right?", "url": "https://github.com/elastic/elasticsearch/pull/52662#discussion_r384146588", "createdAt": "2020-02-25T21:48:32Z", "author": {"login": "not-napoleon"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetrics.java", "diffHunk": "@@ -17,52 +19,53 @@\n import org.elasticsearch.search.sort.SortValue;\n \n import java.io.IOException;\n+import java.util.ArrayList;\n import java.util.List;\n import java.util.Map;\n import java.util.Objects;\n \n+import static java.util.Collections.emptyList;\n+\n public class InternalTopMetrics extends InternalNumericMetricsAggregation.MultiValue {\n-    private final DocValueFormat sortFormat;\n     private final SortOrder sortOrder;\n-    private final SortValue sortValue;\n+    private final int size;\n     private final String metricName;\n-    private final double metricValue;\n+    private final List<TopMetric> topMetrics;\n \n-    public InternalTopMetrics(String name, DocValueFormat sortFormat, @Nullable SortOrder sortOrder, SortValue sortValue, String metricName,\n-            double metricValue, List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) {\n+    public InternalTopMetrics(String name, @Nullable SortOrder sortOrder, String metricName,\n+            int size, List<TopMetric> topMetrics, List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) {\n         super(name, pipelineAggregators, metaData);\n-        this.sortFormat = sortFormat;\n         this.sortOrder = sortOrder;\n-        this.sortValue = sortValue;\n         this.metricName = metricName;\n-        this.metricValue = metricValue;\n+        /*\n+         * topMetrics.size won't be size when the bucket doesn't have size docs!\n+         */\n+        this.size = size;\n+        this.topMetrics = topMetrics;\n     }\n \n     static InternalTopMetrics buildEmptyAggregation(String name, String metricField,\n             List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) {\n-        return new InternalTopMetrics(name, DocValueFormat.RAW, SortOrder.ASC, null, metricField, Double.NaN, pipelineAggregators,\n-                metaData);\n+        return new InternalTopMetrics(name, SortOrder.ASC, metricField, 0, emptyList(), pipelineAggregators, metaData);\n     }\n \n     /**\n      * Read from a stream.\n      */\n     public InternalTopMetrics(StreamInput in) throws IOException {\n         super(in);\n-        sortFormat = in.readNamedWriteable(DocValueFormat.class);\n         sortOrder = SortOrder.readFromStream(in);\n-        sortValue = in.readOptionalNamedWriteable(SortValue.class);\n         metricName = in.readString();\n-        metricValue = in.readDouble();\n+        size = in.readVInt();\n+        topMetrics = in.readList(TopMetric::new);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4395882abf6a3779d3a92ce95464e539abd634ed"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDE4NjI0MA==", "bodyText": "We haven't released it, yeah. So, indeed, breaking serialization is \"safe\". I have to disable BWC tests until I backport it, but other than that this should be ok.", "url": "https://github.com/elastic/elasticsearch/pull/52662#discussion_r384186240", "createdAt": "2020-02-25T23:19:50Z", "author": {"login": "nik9000"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetrics.java", "diffHunk": "@@ -17,52 +19,53 @@\n import org.elasticsearch.search.sort.SortValue;\n \n import java.io.IOException;\n+import java.util.ArrayList;\n import java.util.List;\n import java.util.Map;\n import java.util.Objects;\n \n+import static java.util.Collections.emptyList;\n+\n public class InternalTopMetrics extends InternalNumericMetricsAggregation.MultiValue {\n-    private final DocValueFormat sortFormat;\n     private final SortOrder sortOrder;\n-    private final SortValue sortValue;\n+    private final int size;\n     private final String metricName;\n-    private final double metricValue;\n+    private final List<TopMetric> topMetrics;\n \n-    public InternalTopMetrics(String name, DocValueFormat sortFormat, @Nullable SortOrder sortOrder, SortValue sortValue, String metricName,\n-            double metricValue, List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) {\n+    public InternalTopMetrics(String name, @Nullable SortOrder sortOrder, String metricName,\n+            int size, List<TopMetric> topMetrics, List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) {\n         super(name, pipelineAggregators, metaData);\n-        this.sortFormat = sortFormat;\n         this.sortOrder = sortOrder;\n-        this.sortValue = sortValue;\n         this.metricName = metricName;\n-        this.metricValue = metricValue;\n+        /*\n+         * topMetrics.size won't be size when the bucket doesn't have size docs!\n+         */\n+        this.size = size;\n+        this.topMetrics = topMetrics;\n     }\n \n     static InternalTopMetrics buildEmptyAggregation(String name, String metricField,\n             List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) {\n-        return new InternalTopMetrics(name, DocValueFormat.RAW, SortOrder.ASC, null, metricField, Double.NaN, pipelineAggregators,\n-                metaData);\n+        return new InternalTopMetrics(name, SortOrder.ASC, metricField, 0, emptyList(), pipelineAggregators, metaData);\n     }\n \n     /**\n      * Read from a stream.\n      */\n     public InternalTopMetrics(StreamInput in) throws IOException {\n         super(in);\n-        sortFormat = in.readNamedWriteable(DocValueFormat.class);\n         sortOrder = SortOrder.readFromStream(in);\n-        sortValue = in.readOptionalNamedWriteable(SortValue.class);\n         metricName = in.readString();\n-        metricValue = in.readDouble();\n+        size = in.readVInt();\n+        topMetrics = in.readList(TopMetric::new);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDE0NjU4OA=="}, "originalCommit": {"oid": "4395882abf6a3779d3a92ce95464e539abd634ed"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3ODg2NjM2OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQyMTo1NjowNFrOFuWrfg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQyMTo1NjowNFrOFuWrfg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDE1MDM5OA==", "bodyText": "nit: a DEFAULT_SIZE constant would be easier to read than a literal 1", "url": "https://github.com/elastic/elasticsearch/pull/52662#discussion_r384150398", "createdAt": "2020-02-25T21:56:04Z", "author": {"login": "not-napoleon"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java", "diffHunk": "@@ -36,29 +38,37 @@\n             false, (args, name) -> {\n                 @SuppressWarnings(\"unchecked\")\n                 List<SortBuilder<?>> sorts = (List<SortBuilder<?>>) args[0];\n-                MultiValuesSourceFieldConfig metricField = (MultiValuesSourceFieldConfig) args[1];\n-                return new TopMetricsAggregationBuilder(name, sorts, metricField);\n+                int size = args[1] == null ? 1 : (Integer) args[1];", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4395882abf6a3779d3a92ce95464e539abd634ed"}, "originalPosition": 15}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3893, "cost": 1, "resetAt": "2021-11-12T19:05:54Z"}}}