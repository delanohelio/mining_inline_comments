{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk0OTg5NzU5", "number": 63031, "title": "Add telemetry for data tiers", "bodyText": "This commit adds telemetry for our data tier formalization. This telemetry helps determine the\ntopology of the cluster with regard to the content, hot, warm, & cold tiers/roles.\nAn example of the telemetry looks like:\nGET /_xpack/usage?human\n{\n  ...\n  \"data_tiers\" : {\n    \"available\" : true,\n    \"enabled\" : true,\n    \"data_warm\" : {\n      ...\n    },\n    \"data_cold\" : {\n      ...\n    },\n    \"data_content\" : {\n      \"node_count\" : 1,\n      \"index_count\" : 6,\n      \"total_shard_count\" : 6,\n      \"primary_shard_count\" : 6,\n      \"doc_count\" : 71,\n      \"total_size\" : \"59.6kb\",\n      \"total_size_bytes\" : 61110,\n      \"primary_size\" : \"59.6kb\",\n      \"primary_size_bytes\" : 61110,\n      \"primary_shard_size_avg\" : \"9.9kb\",\n      \"primary_shard_size_avg_bytes\" : 10185,\n      \"primary_shard_size_median\" : \"8kb\",\n      \"primary_shard_size_median_bytes\" : 8254,\n      \"primary_shard_size_mad\" : \"7.2kb\",\n      \"primary_shard_size_mad_bytes\" : 7391\n    },\n    \"data_hot\" : {\n       ...\n    }\n  }\n}\n\nThe fields are as follows:\n\nnode_count :: number of nodes with this tier/role\nindex_count :: number of indices on this tier\ntotal_shard_count :: total number of shards for all nodes in this tier\nprimary_shard_count :: number of primary shards for all nodes in this tier\ndoc_count :: number of documents for all nodes in this tier\ntotal_size_bytes :: total number of bytes for all shards for all nodes in this tier\nprimary_size_bytes :: number of bytes for all primary shards on all nodes in this tier\nprimary_shard_size_avg_bytes :: average shard size for primary shard in this tier\nprimary_shard_size_median_bytes :: median shard size for primary shard in this tier\nprimary_shard_size_mad_bytes :: median absolute deviation of shard size for primary shard in this tier\n\nRelates to #60848", "createdAt": "2020-09-29T17:29:02Z", "url": "https://github.com/elastic/elasticsearch/pull/63031", "merged": true, "mergeCommit": {"oid": "5fca68a155e78077beb30a51b3c2f729e6945bf4"}, "closed": true, "closedAt": "2020-10-01T14:35:11Z", "author": {"login": "dakrone"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdNri4UAH2gAyNDk0OTg5NzU5OjA3MTgzNjE4ZDY5N2MxNGRjNzMyNTI2NDRkN2Y3Mjk4MmU1YjMzMmE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdONRJOAFqTUwMDEyNzU5Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "07183618d697c14dc73252644d7f72982e5b332a", "author": {"user": {"login": "dakrone", "name": "Lee Hinman"}}, "url": "https://github.com/elastic/elasticsearch/commit/07183618d697c14dc73252644d7f72982e5b332a", "committedDate": "2020-09-29T17:22:16Z", "message": "Add telemetry for data tiers\n\nThis commit adds telemetry for our data tier formalization. This telemetry helps determine the\ntopology of the cluster with regard to the content, data, hot, warm, & cold tiers/roles.\n\nAn example of the telemetry looks like:\n\n```\nGET /_xpack/usage?human\n{\n  ...\n  \"data_tiers\" : {\n    \"available\" : true,\n    \"enabled\" : true,\n    \"data_warm\" : {\n      ...\n    },\n    \"data\" : {\n      ...\n    },\n    \"data_cold\" : {\n      ...\n    },\n    \"data_content\" : {\n      \"node_count\" : 1,\n      \"index_count\" : 6,\n      \"total_shard_count\" : 6,\n      \"primary_shard_count\" : 6,\n      \"doc_count\" : 71,\n      \"total_size\" : \"59.6kb\",\n      \"total_size_bytes\" : 61110,\n      \"primary_size\" : \"59.6kb\",\n      \"primary_size_bytes\" : 61110,\n      \"primary_shard_size_avg\" : \"9.9kb\",\n      \"primary_shard_size_avg_bytes\" : 10185,\n      \"primary_shard_size_median_bytes\" : \"8kb\",\n      \"primary_shard_size_median_bytes\" : 8254,\n      \"primary_shard_size_mad_bytes\" : \"7.2kb\",\n      \"primary_shard_size_mad_bytes\" : 7391\n    },\n    \"data_hot\" : {\n       ...\n    }\n  }\n}\n```\n\nThe fields are as follows:\n\n- node_count :: number of nodes with this tier/role\n- index_count :: number of indices on this tier\n- total_shard_count :: total number of shards for all nodes in this tier\n- primary_shard_count :: number of primary shards for all nodes in this tier\n- doc_count :: number of documents for all nodes in this tier\n- total_size_bytes :: total number of bytes for all shards for all nodes in this tier\n- primary_size_bytes :: number of bytes for all primary shards on all nodes in this tier\n- primary_shard_size_avg_bytes :: average shard size for primary shard in this tier\n- primary_shard_size_median_bytes :: median shard size for primary shard in this tier\n- primary_shard_size_mad_bytes :: [median absolute deviation](https://en.wikipedia.org/wiki/Median_absolute_deviation) of shard size for primary shard in this tier\n\nRelates to #60848"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b1e0ab290ec58de2cb7021124fa63c3fb15c6f7a", "author": {"user": {"login": "dakrone", "name": "Lee Hinman"}}, "url": "https://github.com/elastic/elasticsearch/commit/b1e0ab290ec58de2cb7021124fa63c3fb15c6f7a", "committedDate": "2020-09-29T17:46:05Z", "message": "Fix docs tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b2e2acb2c72d0ba9595e1ea5a41529c80e1cd8c9", "author": {"user": {"login": "dakrone", "name": "Lee Hinman"}}, "url": "https://github.com/elastic/elasticsearch/commit/b2e2acb2c72d0ba9595e1ea5a41529c80e1cd8c9", "committedDate": "2020-09-29T17:46:11Z", "message": "Fix erroneous field names"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk5MTkyNjA0", "url": "https://github.com/elastic/elasticsearch/pull/63031#pullrequestreview-499192604", "createdAt": "2020-09-30T08:21:55Z", "commit": {"oid": "b2e2acb2c72d0ba9595e1ea5a41529c80e1cd8c9"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQwODoyMTo1NVrOHaSikw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQwODoyNDowNVrOHaSnow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzMyODc4Nw==", "bodyText": "As said above, I don't think we should mix the data role with the data tiers.", "url": "https://github.com/elastic/elasticsearch/pull/63031#discussion_r497328787", "createdAt": "2020-09-30T08:21:55Z", "author": {"login": "andreidan"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/DataTiersUsageTransportAction.java", "diffHunk": "@@ -0,0 +1,146 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core;\n+\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.admin.cluster.node.stats.NodeStats;\n+import org.elasticsearch.action.admin.cluster.node.stats.NodesStatsResponse;\n+import org.elasticsearch.action.admin.indices.stats.CommonStatsFlags;\n+import org.elasticsearch.action.support.ActionFilters;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.store.StoreStats;\n+import org.elasticsearch.protocol.xpack.XPackUsageRequest;\n+import org.elasticsearch.search.aggregations.metrics.TDigestState;\n+import org.elasticsearch.tasks.Task;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.transport.TransportService;\n+import org.elasticsearch.xpack.core.action.XPackUsageFeatureAction;\n+import org.elasticsearch.xpack.core.action.XPackUsageFeatureResponse;\n+import org.elasticsearch.xpack.core.action.XPackUsageFeatureTransportAction;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.stream.Collectors;\n+\n+public class DataTiersUsageTransportAction extends XPackUsageFeatureTransportAction {\n+\n+    private final Client client;\n+\n+    @Inject\n+    public DataTiersUsageTransportAction(TransportService transportService, ClusterService clusterService,\n+                                         ThreadPool threadPool, ActionFilters actionFilters,\n+                                         IndexNameExpressionResolver indexNameExpressionResolver, Client client) {\n+        super(XPackUsageFeatureAction.DATA_TIERS.name(), transportService, clusterService,\n+            threadPool, actionFilters, indexNameExpressionResolver);\n+        this.client = client;\n+    }\n+\n+    @Override\n+    protected void masterOperation(Task task, XPackUsageRequest request, ClusterState state,\n+                                   ActionListener<XPackUsageFeatureResponse> listener) {\n+        client.admin().cluster().prepareNodesStats()\n+            .all()\n+            .setIndices(CommonStatsFlags.ALL)\n+            .execute(ActionListener.wrap(nodesStatsResponse -> {\n+                final RoutingNodes routingNodes = state.getRoutingNodes();\n+\n+                // First separate the nodes into separate tiers, note that nodes *may* be duplicated\n+                Map<String, List<NodeStats>> tierSpecificNodeStats = separateTiers(nodesStatsResponse);\n+\n+                // Generate tier specific stats for the nodes\n+                Map<String, DataTiersFeatureSetUsage.TierSpecificStats> tierSpecificStats = tierSpecificNodeStats.entrySet()\n+                    .stream().collect(Collectors.toMap(Map.Entry::getKey, ns -> calculateStats(ns.getValue(), routingNodes)));\n+\n+                listener.onResponse(new XPackUsageFeatureResponse(new DataTiersFeatureSetUsage(tierSpecificStats)));\n+            }, listener::onFailure));\n+    }\n+\n+    private static Map<String, List<NodeStats>> separateTiers(NodesStatsResponse nodesStatsResponse) {\n+        Map<String, List<NodeStats>> responses = new HashMap<>();\n+        DataTier.ALL_DATA_TIERS.forEach(tier ->\n+            responses.put(tier, nodesStatsResponse.getNodes().stream()\n+                .filter(stats -> stats.getNode().getRoles().stream()\n+                    .map(DiscoveryNodeRole::roleName)\n+                    .anyMatch(rn -> rn.equals(tier)))\n+                .collect(Collectors.toList())));\n+        // Also manually add the \"data\" role so we calculate statistics for it\n+        responses.put(DiscoveryNodeRole.DATA_ROLE.roleName(), nodesStatsResponse.getNodes().stream()\n+            .filter(stats -> stats.getNode().getRoles().stream().anyMatch(rn -> rn.equals(DiscoveryNodeRole.DATA_ROLE)))\n+            .collect(Collectors.toList()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2e2acb2c72d0ba9595e1ea5a41529c80e1cd8c9"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzMyOTU5OA==", "bodyText": "I don't think we should be reporting the data role under data_tiers. Trying to do tier routing etc. on the data role will fail. I'd rather not have this here as it could be confusing.\nI can see how this could be useful to have, but maybe it should be under another \"data\" or \"data_role\" object.\nWhat do you think?", "url": "https://github.com/elastic/elasticsearch/pull/63031#discussion_r497329598", "createdAt": "2020-09-30T08:23:17Z", "author": {"login": "andreidan"}, "path": "docs/reference/rest-api/usage.asciidoc", "diffHunk": "@@ -285,6 +285,70 @@ GET /_xpack/usage\n     \"enabled\" : true,\n     \"data_streams\" : 0,\n     \"indices_count\" : 0\n+  },\n+  \"data_tiers\" : {\n+    \"available\" : true,\n+    \"enabled\" : true,\n+    \"data_warm\" : {\n+      \"node_count\" : 0,\n+      \"index_count\" : 0,\n+      \"total_shard_count\" : 0,\n+      \"primary_shard_count\" : 0,\n+      \"doc_count\" : 0,\n+      \"total_size_bytes\" : 0,\n+      \"primary_size_bytes\" : 0,\n+      \"primary_shard_size_avg_bytes\" : 0,\n+      \"primary_shard_size_median_bytes\" : 0,\n+      \"primary_shard_size_mad_bytes\" : 0\n+    },\n+    \"data\" : {\n+      \"node_count\" : 1,\n+      \"index_count\" : 0,\n+      \"total_shard_count\" : 0,\n+      \"primary_shard_count\" : 0,\n+      \"doc_count\" : 0,\n+      \"total_size_bytes\" : 0,\n+      \"primary_size_bytes\" : 0,\n+      \"primary_shard_size_avg_bytes\" : 0,\n+      \"primary_shard_size_median_bytes\" : 0,\n+      \"primary_shard_size_mad_bytes\" : 0", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2e2acb2c72d0ba9595e1ea5a41529c80e1cd8c9"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzMyOTkzNw==", "bodyText": "shall we unit test these static methods?", "url": "https://github.com/elastic/elasticsearch/pull/63031#discussion_r497329937", "createdAt": "2020-09-30T08:23:51Z", "author": {"login": "andreidan"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/DataTiersUsageTransportAction.java", "diffHunk": "@@ -0,0 +1,146 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core;\n+\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.admin.cluster.node.stats.NodeStats;\n+import org.elasticsearch.action.admin.cluster.node.stats.NodesStatsResponse;\n+import org.elasticsearch.action.admin.indices.stats.CommonStatsFlags;\n+import org.elasticsearch.action.support.ActionFilters;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.store.StoreStats;\n+import org.elasticsearch.protocol.xpack.XPackUsageRequest;\n+import org.elasticsearch.search.aggregations.metrics.TDigestState;\n+import org.elasticsearch.tasks.Task;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.transport.TransportService;\n+import org.elasticsearch.xpack.core.action.XPackUsageFeatureAction;\n+import org.elasticsearch.xpack.core.action.XPackUsageFeatureResponse;\n+import org.elasticsearch.xpack.core.action.XPackUsageFeatureTransportAction;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.stream.Collectors;\n+\n+public class DataTiersUsageTransportAction extends XPackUsageFeatureTransportAction {\n+\n+    private final Client client;\n+\n+    @Inject\n+    public DataTiersUsageTransportAction(TransportService transportService, ClusterService clusterService,\n+                                         ThreadPool threadPool, ActionFilters actionFilters,\n+                                         IndexNameExpressionResolver indexNameExpressionResolver, Client client) {\n+        super(XPackUsageFeatureAction.DATA_TIERS.name(), transportService, clusterService,\n+            threadPool, actionFilters, indexNameExpressionResolver);\n+        this.client = client;\n+    }\n+\n+    @Override\n+    protected void masterOperation(Task task, XPackUsageRequest request, ClusterState state,\n+                                   ActionListener<XPackUsageFeatureResponse> listener) {\n+        client.admin().cluster().prepareNodesStats()\n+            .all()\n+            .setIndices(CommonStatsFlags.ALL)\n+            .execute(ActionListener.wrap(nodesStatsResponse -> {\n+                final RoutingNodes routingNodes = state.getRoutingNodes();\n+\n+                // First separate the nodes into separate tiers, note that nodes *may* be duplicated\n+                Map<String, List<NodeStats>> tierSpecificNodeStats = separateTiers(nodesStatsResponse);\n+\n+                // Generate tier specific stats for the nodes\n+                Map<String, DataTiersFeatureSetUsage.TierSpecificStats> tierSpecificStats = tierSpecificNodeStats.entrySet()\n+                    .stream().collect(Collectors.toMap(Map.Entry::getKey, ns -> calculateStats(ns.getValue(), routingNodes)));\n+\n+                listener.onResponse(new XPackUsageFeatureResponse(new DataTiersFeatureSetUsage(tierSpecificStats)));\n+            }, listener::onFailure));\n+    }\n+\n+    private static Map<String, List<NodeStats>> separateTiers(NodesStatsResponse nodesStatsResponse) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2e2acb2c72d0ba9595e1ea5a41529c80e1cd8c9"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzMzMDA4Mw==", "bodyText": "can we please verify this with unit tests?", "url": "https://github.com/elastic/elasticsearch/pull/63031#discussion_r497330083", "createdAt": "2020-09-30T08:24:05Z", "author": {"login": "andreidan"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/DataTiersUsageTransportAction.java", "diffHunk": "@@ -0,0 +1,146 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core;\n+\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.admin.cluster.node.stats.NodeStats;\n+import org.elasticsearch.action.admin.cluster.node.stats.NodesStatsResponse;\n+import org.elasticsearch.action.admin.indices.stats.CommonStatsFlags;\n+import org.elasticsearch.action.support.ActionFilters;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.store.StoreStats;\n+import org.elasticsearch.protocol.xpack.XPackUsageRequest;\n+import org.elasticsearch.search.aggregations.metrics.TDigestState;\n+import org.elasticsearch.tasks.Task;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.transport.TransportService;\n+import org.elasticsearch.xpack.core.action.XPackUsageFeatureAction;\n+import org.elasticsearch.xpack.core.action.XPackUsageFeatureResponse;\n+import org.elasticsearch.xpack.core.action.XPackUsageFeatureTransportAction;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.stream.Collectors;\n+\n+public class DataTiersUsageTransportAction extends XPackUsageFeatureTransportAction {\n+\n+    private final Client client;\n+\n+    @Inject\n+    public DataTiersUsageTransportAction(TransportService transportService, ClusterService clusterService,\n+                                         ThreadPool threadPool, ActionFilters actionFilters,\n+                                         IndexNameExpressionResolver indexNameExpressionResolver, Client client) {\n+        super(XPackUsageFeatureAction.DATA_TIERS.name(), transportService, clusterService,\n+            threadPool, actionFilters, indexNameExpressionResolver);\n+        this.client = client;\n+    }\n+\n+    @Override\n+    protected void masterOperation(Task task, XPackUsageRequest request, ClusterState state,\n+                                   ActionListener<XPackUsageFeatureResponse> listener) {\n+        client.admin().cluster().prepareNodesStats()\n+            .all()\n+            .setIndices(CommonStatsFlags.ALL)\n+            .execute(ActionListener.wrap(nodesStatsResponse -> {\n+                final RoutingNodes routingNodes = state.getRoutingNodes();\n+\n+                // First separate the nodes into separate tiers, note that nodes *may* be duplicated\n+                Map<String, List<NodeStats>> tierSpecificNodeStats = separateTiers(nodesStatsResponse);\n+\n+                // Generate tier specific stats for the nodes\n+                Map<String, DataTiersFeatureSetUsage.TierSpecificStats> tierSpecificStats = tierSpecificNodeStats.entrySet()\n+                    .stream().collect(Collectors.toMap(Map.Entry::getKey, ns -> calculateStats(ns.getValue(), routingNodes)));\n+\n+                listener.onResponse(new XPackUsageFeatureResponse(new DataTiersFeatureSetUsage(tierSpecificStats)));\n+            }, listener::onFailure));\n+    }\n+\n+    private static Map<String, List<NodeStats>> separateTiers(NodesStatsResponse nodesStatsResponse) {\n+        Map<String, List<NodeStats>> responses = new HashMap<>();\n+        DataTier.ALL_DATA_TIERS.forEach(tier ->\n+            responses.put(tier, nodesStatsResponse.getNodes().stream()\n+                .filter(stats -> stats.getNode().getRoles().stream()\n+                    .map(DiscoveryNodeRole::roleName)\n+                    .anyMatch(rn -> rn.equals(tier)))\n+                .collect(Collectors.toList())));\n+        // Also manually add the \"data\" role so we calculate statistics for it\n+        responses.put(DiscoveryNodeRole.DATA_ROLE.roleName(), nodesStatsResponse.getNodes().stream()\n+            .filter(stats -> stats.getNode().getRoles().stream().anyMatch(rn -> rn.equals(DiscoveryNodeRole.DATA_ROLE)))\n+            .collect(Collectors.toList()));\n+        return responses;\n+    }\n+\n+    private DataTiersFeatureSetUsage.TierSpecificStats calculateStats(List<NodeStats> nodesStats, RoutingNodes routingNodes) {\n+        int nodeCount = 0;\n+        int indexCount = 0;\n+        int totalShardCount = 0;\n+        long totalByteCount = 0;\n+        long docCount = 0;\n+        final AtomicInteger primaryShardCount = new AtomicInteger(0);\n+        final AtomicLong primaryByteCount = new AtomicLong(0);\n+        final TDigestState valueSketch = new TDigestState(1000);\n+        for (NodeStats nodeStats : nodesStats) {\n+            nodeCount++;\n+            totalByteCount += nodeStats.getIndices().getStore().getSizeInBytes();\n+            docCount += nodeStats.getIndices().getDocs().getCount();\n+            String nodeId = nodeStats.getNode().getId();\n+            final RoutingNode node = routingNodes.node(nodeId);\n+            if (node != null) {\n+                totalShardCount += node.shardsWithState(ShardRoutingState.STARTED).size();\n+                Set<Index> indicesOnNode = node.shardsWithState(ShardRoutingState.STARTED).stream()\n+                    .map(ShardRouting::index)\n+                    .collect(Collectors.toSet());\n+                indexCount += indicesOnNode.size();\n+                indicesOnNode.forEach(index -> {\n+                    nodeStats.getIndices().getShardStats(index).stream()\n+                        .filter(shardStats -> shardStats.getPrimary().getStore() != null)\n+                        .forEach(shardStats -> {\n+                            StoreStats primaryStoreStats = shardStats.getPrimary().getStore();\n+                            // If storeStats is null, it means this is not a replica\n+                            primaryShardCount.incrementAndGet();\n+                            long primarySize = primaryStoreStats.getSizeInBytes();\n+                            primaryByteCount.addAndGet(primarySize);\n+                            valueSketch.add(primarySize);\n+                        });\n+                });\n+            }\n+        }\n+        long primaryShardSizeMedian = (long) valueSketch.quantile(0.5);\n+        long primaryShardSizeMAD = computeMedianAbsoluteDeviation(valueSketch);\n+        return new DataTiersFeatureSetUsage.TierSpecificStats(nodeCount, indexCount, totalShardCount, primaryShardCount.get(), docCount,\n+            totalByteCount, primaryByteCount.get(), primaryShardSizeMedian, primaryShardSizeMAD);\n+    }\n+\n+    private static long computeMedianAbsoluteDeviation(TDigestState valuesSketch) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2e2acb2c72d0ba9595e1ea5a41529c80e1cd8c9"}, "originalPosition": 132}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7b8de38e4c3e5c11bc483291dabba73d311dae42", "author": {"user": {"login": "dakrone", "name": "Lee Hinman"}}, "url": "https://github.com/elastic/elasticsearch/commit/7b8de38e4c3e5c11bc483291dabba73d311dae42", "committedDate": "2020-09-30T20:20:03Z", "message": "Add unit test for computeMedianAbsoluteDeviation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "94267fbe3ff3f658516afdbd2e87b982d74bf2c2", "author": {"user": {"login": "dakrone", "name": "Lee Hinman"}}, "url": "https://github.com/elastic/elasticsearch/commit/94267fbe3ff3f658516afdbd2e87b982d74bf2c2", "committedDate": "2020-09-30T20:38:15Z", "message": "Remove \"data\" from data_tiers, add unit tests for separateTiers"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ff2a6980b039850bff9f8c04a6bd0747bb37552d", "author": {"user": {"login": "dakrone", "name": "Lee Hinman"}}, "url": "https://github.com/elastic/elasticsearch/commit/ff2a6980b039850bff9f8c04a6bd0747bb37552d", "committedDate": "2020-09-30T20:43:11Z", "message": "Merge remote-tracking branch 'origin/master' into dt-add-telemetry"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAwMTI3NTk3", "url": "https://github.com/elastic/elasticsearch/pull/63031#pullrequestreview-500127597", "createdAt": "2020-10-01T08:39:40Z", "commit": {"oid": "ff2a6980b039850bff9f8c04a6bd0747bb37552d"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4532, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}