{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA1OTE1NDI2", "number": 55441, "title": "Add moving percentiles pipeline aggregation", "bodyText": "Similar to what the moving function aggregation does, except merging windows of percentiles sketches  together instead of cumulatively merging final metrics.\ncloses #49452", "createdAt": "2020-04-20T08:43:09Z", "url": "https://github.com/elastic/elasticsearch/pull/55441", "merged": true, "mergeCommit": {"oid": "4e39184c3866552fd7c8d11970689945d64153ce"}, "closed": true, "closedAt": "2020-05-12T08:30:53Z", "author": {"login": "iverase"}, "timelineItems": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcZa9lLgH2gAyNDA1OTE1NDI2OmM4MTMxYTYxNDY2YzM0OGI3YWViZDRlZWFiZWZkZTJiNjEwNzlhMzk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcgQqI5AFqTQwOTIzMzEzMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "c8131a61466c348b7aebd4eeabefde2b61079a39", "author": {"user": {"login": "iverase", "name": "Ignacio Vera"}}, "url": "https://github.com/elastic/elasticsearch/commit/c8131a61466c348b7aebd4eeabefde2b61079a39", "committedDate": "2020-04-20T08:38:59Z", "message": "Add moving_percentiles pipeline aggregation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8a0db42e7e11a5ff30aeaf4a64a0ca12f1c7d220", "author": {"user": {"login": "iverase", "name": "Ignacio Vera"}}, "url": "https://github.com/elastic/elasticsearch/commit/8a0db42e7e11a5ff30aeaf4a64a0ca12f1c7d220", "committedDate": "2020-04-20T08:56:09Z", "message": "checkStyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8a6992c5eaab960422f28aebaa72b7d77f6b7f26", "author": {"user": {"login": "iverase", "name": "Ignacio Vera"}}, "url": "https://github.com/elastic/elasticsearch/commit/8a6992c5eaab960422f28aebaa72b7d77f6b7f26", "committedDate": "2020-04-20T09:35:54Z", "message": "checkStyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "37eb537b849657111a9eeba6ee0ec00c437ed260", "author": {"user": {"login": "iverase", "name": "Ignacio Vera"}}, "url": "https://github.com/elastic/elasticsearch/commit/37eb537b849657111a9eeba6ee0ec00c437ed260", "committedDate": "2020-04-20T10:13:19Z", "message": "fix failing tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk5MjE3Mjgz", "url": "https://github.com/elastic/elasticsearch/pull/55441#pullrequestreview-399217283", "createdAt": "2020-04-23T15:29:14Z", "commit": {"oid": "37eb537b849657111a9eeba6ee0ec00c437ed260"}, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QxNToyOToxNFrOGKuRMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QxNjowMjozNlrOGKv6iw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzg5NzAxMQ==", "bodyText": "I wonder if @nik9000 has ideas how we could validate that the pipeline targets a percentiles agg up front in the builder, instead of down below during runtime?  Might not be possible yet...", "url": "https://github.com/elastic/elasticsearch/pull/55441#discussion_r413897011", "createdAt": "2020-04-23T15:29:14Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/movingPercentiles/MovingPercentilesPipelineAggregationBuilder.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.movingPercentiles;\n+\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.search.aggregations.pipeline.AbstractPipelineAggregationBuilder;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+\n+import java.io.IOException;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+public class MovingPercentilesPipelineAggregationBuilder\n+        extends AbstractPipelineAggregationBuilder<MovingPercentilesPipelineAggregationBuilder> {\n+    public static final String NAME = \"moving_percentiles\";\n+    private static final ParseField WINDOW = new ParseField(\"window\");\n+    private static final ParseField SHIFT = new ParseField(\"shift\");\n+\n+    public static final ConstructingObjectParser<MovingPercentilesPipelineAggregationBuilder, String> PARSER =\n+            new ConstructingObjectParser<>(NAME, false, (args, name) -> {\n+                return new MovingPercentilesPipelineAggregationBuilder(name, (String) args[0], (int) args[1]);\n+            });\n+    static {\n+        PARSER.declareString(constructorArg(), BUCKETS_PATH_FIELD);\n+        PARSER.declareInt(constructorArg(), WINDOW);\n+        PARSER.declareInt(MovingPercentilesPipelineAggregationBuilder::setShift, SHIFT);\n+    }\n+\n+    private final int window;\n+    private int shift;\n+\n+    public MovingPercentilesPipelineAggregationBuilder(String name, String bucketsPath, int window) {\n+        super(name, NAME, new String[] { bucketsPath });\n+        if (window <= 0) {\n+            throw new IllegalArgumentException(\"[\" + WINDOW.getPreferredName() + \"] must be a positive, non-zero integer.\");\n+        }\n+        this.window = window;\n+    }\n+\n+    /**\n+     * Read from a stream.\n+     */\n+    public MovingPercentilesPipelineAggregationBuilder(StreamInput in) throws IOException {\n+        super(in, NAME);\n+        window = in.readVInt();\n+        shift = in.readInt();\n+    }\n+\n+    @Override\n+    protected final void doWriteTo(StreamOutput out) throws IOException {\n+        out.writeVInt(window);\n+        out.writeInt(shift);\n+    }\n+\n+    /**\n+     * Returns the window size for this aggregation\n+     */\n+    public int getWindow() {\n+        return window;\n+    }\n+\n+    /**\n+     * Returns the shift for this aggregation\n+     */\n+    public int getShift() {\n+        return shift;\n+    }\n+\n+    /**\n+     * Sets the shift for this aggregation\n+     */\n+    public void setShift(int shift) {\n+        this.shift = shift;\n+    }\n+\n+    @Override\n+    protected PipelineAggregator createInternal(Map<String, Object> metaData) {\n+        return new MovingPercentilesPipelineAggregator(name, bucketsPaths, getWindow(), getShift(), metaData);\n+    }\n+\n+    @Override\n+    protected void validate(ValidationContext context) {\n+        if (bucketsPaths.length != 1) {\n+            context.addBucketPathValidationError(\"must contain a single entry for aggregation [\" + name + \"]\");\n+        }\n+        context.validateParentAggSequentiallyOrdered(NAME, name);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37eb537b849657111a9eeba6ee0ec00c437ed260"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzkwMDM0MQ==", "bodyText": "I'm assuming this means any \"gaps\" in the buckets will be skipped?\nWe should probably document that, since other pipeline aggs have a gap_policy which allows modifying how gaps are handled.  I don't really see how we can support that here (insert_zero doesn't really make sense and would totally skew gaps...).  So we probably just need to document that it always runs in gap_policy: skip mode.", "url": "https://github.com/elastic/elasticsearch/pull/55441#discussion_r413900341", "createdAt": "2020-04-23T15:33:14Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/movingPercentiles/MovingPercentilesPipelineAggregator.java", "diffHunk": "@@ -0,0 +1,276 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.movingPercentiles;\n+\n+import org.HdrHistogram.DoubleHistogram;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AggregationExecutionException;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.InternalAggregation.ReduceContext;\n+import org.elasticsearch.search.aggregations.InternalAggregations;\n+import org.elasticsearch.search.aggregations.InternalMultiBucketAggregation;\n+import org.elasticsearch.search.aggregations.bucket.MultiBucketsAggregation;\n+import org.elasticsearch.search.aggregations.bucket.MultiBucketsAggregation.Bucket;\n+import org.elasticsearch.search.aggregations.bucket.histogram.HistogramFactory;\n+import org.elasticsearch.search.aggregations.metrics.InternalHDRPercentiles;\n+import org.elasticsearch.search.aggregations.metrics.InternalTDigestPercentiles;\n+import org.elasticsearch.search.aggregations.metrics.PercentilesMethod;\n+import org.elasticsearch.search.aggregations.metrics.TDigestState;\n+import org.elasticsearch.search.aggregations.pipeline.AbstractPipelineAggregationBuilder;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.AggregationPath;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.StreamSupport;\n+\n+public class MovingPercentilesPipelineAggregator extends PipelineAggregator {\n+\n+    private final int window;\n+    private final int shift;\n+\n+    MovingPercentilesPipelineAggregator(String name, String[] bucketsPaths, int window, int shift,\n+                                        Map<String, Object> metadata) {\n+        super(name, bucketsPaths, metadata);\n+        this.window = window;\n+        this.shift = shift;\n+    }\n+\n+    @Override\n+    public InternalAggregation reduce(InternalAggregation aggregation, ReduceContext reduceContext) {\n+        InternalMultiBucketAggregation<? extends InternalMultiBucketAggregation, ? extends InternalMultiBucketAggregation.InternalBucket>\n+            histo = (InternalMultiBucketAggregation<? extends InternalMultiBucketAggregation, ? extends\n+            InternalMultiBucketAggregation.InternalBucket>) aggregation;\n+        List<? extends InternalMultiBucketAggregation.InternalBucket> buckets = histo.getBuckets();\n+        HistogramFactory factory = (HistogramFactory) histo;\n+\n+        List<Bucket> newBuckets = new ArrayList<>(buckets.size());\n+        if (buckets.size() == 0) {\n+            return factory.createAggregation(newBuckets);\n+        }\n+        PercentileConfig config = resolvePercentileConfig(histo, buckets.get(0), bucketsPaths()[0]);\n+        switch (config.method) {\n+            case TDIGEST:\n+                reduceTDigest(buckets, histo, newBuckets, factory, config);\n+                break;\n+            case HDR:\n+                reduceHDR(buckets, histo, newBuckets, factory, config);\n+                break;\n+            default:\n+                throw new AggregationExecutionException(AbstractPipelineAggregationBuilder.BUCKETS_PATH_FIELD.getPreferredName()\n+                    + \" references an unknown percentile aggregation method: [\" + config.method + \"]\");\n+        }\n+        return factory.createAggregation(newBuckets);\n+    }\n+\n+    private void reduceTDigest(List<? extends InternalMultiBucketAggregation.InternalBucket> buckets,\n+                                              MultiBucketsAggregation histo,\n+                                              List<Bucket> newBuckets,\n+                                              HistogramFactory factory,\n+                                              PercentileConfig config) {\n+\n+        List<TDigestState> values = buckets.stream()\n+            .map(b -> resolveTDigestBucketValue(histo, b, bucketsPaths()[0]))\n+            .filter(v -> v != null)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37eb537b849657111a9eeba6ee0ec00c437ed260"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzkxMzM0MQ==", "bodyText": "I think we can probably change these to just bucket.getAggregations.asList().stream()..., instead of using StreamSupport.  I'm not actually sure why pipeline aggs follow this convention, I don't think it's needed (we don't use the spliterator capability) and I think it might end up doing more work too.  Might just be a historical artifact.\nBut, not an expert with this interface so happy to hear otherwise :)", "url": "https://github.com/elastic/elasticsearch/pull/55441#discussion_r413913341", "createdAt": "2020-04-23T15:49:28Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/movingPercentiles/MovingPercentilesPipelineAggregator.java", "diffHunk": "@@ -0,0 +1,276 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.movingPercentiles;\n+\n+import org.HdrHistogram.DoubleHistogram;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AggregationExecutionException;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.InternalAggregation.ReduceContext;\n+import org.elasticsearch.search.aggregations.InternalAggregations;\n+import org.elasticsearch.search.aggregations.InternalMultiBucketAggregation;\n+import org.elasticsearch.search.aggregations.bucket.MultiBucketsAggregation;\n+import org.elasticsearch.search.aggregations.bucket.MultiBucketsAggregation.Bucket;\n+import org.elasticsearch.search.aggregations.bucket.histogram.HistogramFactory;\n+import org.elasticsearch.search.aggregations.metrics.InternalHDRPercentiles;\n+import org.elasticsearch.search.aggregations.metrics.InternalTDigestPercentiles;\n+import org.elasticsearch.search.aggregations.metrics.PercentilesMethod;\n+import org.elasticsearch.search.aggregations.metrics.TDigestState;\n+import org.elasticsearch.search.aggregations.pipeline.AbstractPipelineAggregationBuilder;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.AggregationPath;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.StreamSupport;\n+\n+public class MovingPercentilesPipelineAggregator extends PipelineAggregator {\n+\n+    private final int window;\n+    private final int shift;\n+\n+    MovingPercentilesPipelineAggregator(String name, String[] bucketsPaths, int window, int shift,\n+                                        Map<String, Object> metadata) {\n+        super(name, bucketsPaths, metadata);\n+        this.window = window;\n+        this.shift = shift;\n+    }\n+\n+    @Override\n+    public InternalAggregation reduce(InternalAggregation aggregation, ReduceContext reduceContext) {\n+        InternalMultiBucketAggregation<? extends InternalMultiBucketAggregation, ? extends InternalMultiBucketAggregation.InternalBucket>\n+            histo = (InternalMultiBucketAggregation<? extends InternalMultiBucketAggregation, ? extends\n+            InternalMultiBucketAggregation.InternalBucket>) aggregation;\n+        List<? extends InternalMultiBucketAggregation.InternalBucket> buckets = histo.getBuckets();\n+        HistogramFactory factory = (HistogramFactory) histo;\n+\n+        List<Bucket> newBuckets = new ArrayList<>(buckets.size());\n+        if (buckets.size() == 0) {\n+            return factory.createAggregation(newBuckets);\n+        }\n+        PercentileConfig config = resolvePercentileConfig(histo, buckets.get(0), bucketsPaths()[0]);\n+        switch (config.method) {\n+            case TDIGEST:\n+                reduceTDigest(buckets, histo, newBuckets, factory, config);\n+                break;\n+            case HDR:\n+                reduceHDR(buckets, histo, newBuckets, factory, config);\n+                break;\n+            default:\n+                throw new AggregationExecutionException(AbstractPipelineAggregationBuilder.BUCKETS_PATH_FIELD.getPreferredName()\n+                    + \" references an unknown percentile aggregation method: [\" + config.method + \"]\");\n+        }\n+        return factory.createAggregation(newBuckets);\n+    }\n+\n+    private void reduceTDigest(List<? extends InternalMultiBucketAggregation.InternalBucket> buckets,\n+                                              MultiBucketsAggregation histo,\n+                                              List<Bucket> newBuckets,\n+                                              HistogramFactory factory,\n+                                              PercentileConfig config) {\n+\n+        List<TDigestState> values = buckets.stream()\n+            .map(b -> resolveTDigestBucketValue(histo, b, bucketsPaths()[0]))\n+            .filter(v -> v != null)\n+            .collect(Collectors.toList());\n+\n+        int index = 0;\n+        for (InternalMultiBucketAggregation.InternalBucket bucket : buckets) {\n+\n+            // Default is to reuse existing bucket.  Simplifies the rest of the logic,\n+            // since we only change newBucket if we can add to it\n+            MultiBucketsAggregation.Bucket newBucket = bucket;\n+\n+            TDigestState state = null;\n+            int fromIndex = clamp(index - window + shift, values.size());\n+            int toIndex = clamp(index + shift, values.size());\n+            for (int i = fromIndex; i < toIndex; i++) {\n+                TDigestState bucketState = values.get(i);\n+                if (bucketState != null) {\n+                    if (state == null) {\n+                        // We have to create a new TDigest histogram because otherwise it will alter the\n+                        // existing histogram and bucket value\n+                        state = new TDigestState(bucketState.compression());\n+                    }\n+                    state.add(bucketState);\n+\n+                }\n+            }\n+\n+            if (state != null) {\n+                List<InternalAggregation> aggs = StreamSupport.stream(bucket.getAggregations().spliterator(), false)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37eb537b849657111a9eeba6ee0ec00c437ed260"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzkxNTQ4Mw==", "bodyText": "Shame there isn't a way to share this code with tdigest since it's mainly the same.  Not sure it's worth trying to figure out though, unless someone has a simple/clever solution :)", "url": "https://github.com/elastic/elasticsearch/pull/55441#discussion_r413915483", "createdAt": "2020-04-23T15:51:59Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/movingPercentiles/MovingPercentilesPipelineAggregator.java", "diffHunk": "@@ -0,0 +1,276 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.movingPercentiles;\n+\n+import org.HdrHistogram.DoubleHistogram;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AggregationExecutionException;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.InternalAggregation.ReduceContext;\n+import org.elasticsearch.search.aggregations.InternalAggregations;\n+import org.elasticsearch.search.aggregations.InternalMultiBucketAggregation;\n+import org.elasticsearch.search.aggregations.bucket.MultiBucketsAggregation;\n+import org.elasticsearch.search.aggregations.bucket.MultiBucketsAggregation.Bucket;\n+import org.elasticsearch.search.aggregations.bucket.histogram.HistogramFactory;\n+import org.elasticsearch.search.aggregations.metrics.InternalHDRPercentiles;\n+import org.elasticsearch.search.aggregations.metrics.InternalTDigestPercentiles;\n+import org.elasticsearch.search.aggregations.metrics.PercentilesMethod;\n+import org.elasticsearch.search.aggregations.metrics.TDigestState;\n+import org.elasticsearch.search.aggregations.pipeline.AbstractPipelineAggregationBuilder;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.AggregationPath;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.StreamSupport;\n+\n+public class MovingPercentilesPipelineAggregator extends PipelineAggregator {\n+\n+    private final int window;\n+    private final int shift;\n+\n+    MovingPercentilesPipelineAggregator(String name, String[] bucketsPaths, int window, int shift,\n+                                        Map<String, Object> metadata) {\n+        super(name, bucketsPaths, metadata);\n+        this.window = window;\n+        this.shift = shift;\n+    }\n+\n+    @Override\n+    public InternalAggregation reduce(InternalAggregation aggregation, ReduceContext reduceContext) {\n+        InternalMultiBucketAggregation<? extends InternalMultiBucketAggregation, ? extends InternalMultiBucketAggregation.InternalBucket>\n+            histo = (InternalMultiBucketAggregation<? extends InternalMultiBucketAggregation, ? extends\n+            InternalMultiBucketAggregation.InternalBucket>) aggregation;\n+        List<? extends InternalMultiBucketAggregation.InternalBucket> buckets = histo.getBuckets();\n+        HistogramFactory factory = (HistogramFactory) histo;\n+\n+        List<Bucket> newBuckets = new ArrayList<>(buckets.size());\n+        if (buckets.size() == 0) {\n+            return factory.createAggregation(newBuckets);\n+        }\n+        PercentileConfig config = resolvePercentileConfig(histo, buckets.get(0), bucketsPaths()[0]);\n+        switch (config.method) {\n+            case TDIGEST:\n+                reduceTDigest(buckets, histo, newBuckets, factory, config);\n+                break;\n+            case HDR:\n+                reduceHDR(buckets, histo, newBuckets, factory, config);\n+                break;\n+            default:\n+                throw new AggregationExecutionException(AbstractPipelineAggregationBuilder.BUCKETS_PATH_FIELD.getPreferredName()\n+                    + \" references an unknown percentile aggregation method: [\" + config.method + \"]\");\n+        }\n+        return factory.createAggregation(newBuckets);\n+    }\n+\n+    private void reduceTDigest(List<? extends InternalMultiBucketAggregation.InternalBucket> buckets,\n+                                              MultiBucketsAggregation histo,\n+                                              List<Bucket> newBuckets,\n+                                              HistogramFactory factory,\n+                                              PercentileConfig config) {\n+\n+        List<TDigestState> values = buckets.stream()\n+            .map(b -> resolveTDigestBucketValue(histo, b, bucketsPaths()[0]))\n+            .filter(v -> v != null)\n+            .collect(Collectors.toList());\n+\n+        int index = 0;\n+        for (InternalMultiBucketAggregation.InternalBucket bucket : buckets) {\n+\n+            // Default is to reuse existing bucket.  Simplifies the rest of the logic,\n+            // since we only change newBucket if we can add to it\n+            MultiBucketsAggregation.Bucket newBucket = bucket;\n+\n+            TDigestState state = null;\n+            int fromIndex = clamp(index - window + shift, values.size());\n+            int toIndex = clamp(index + shift, values.size());\n+            for (int i = fromIndex; i < toIndex; i++) {\n+                TDigestState bucketState = values.get(i);\n+                if (bucketState != null) {\n+                    if (state == null) {\n+                        // We have to create a new TDigest histogram because otherwise it will alter the\n+                        // existing histogram and bucket value\n+                        state = new TDigestState(bucketState.compression());\n+                    }\n+                    state.add(bucketState);\n+\n+                }\n+            }\n+\n+            if (state != null) {\n+                List<InternalAggregation> aggs = StreamSupport.stream(bucket.getAggregations().spliterator(), false)\n+                    .map((p) -> (InternalAggregation) p)\n+                    .collect(Collectors.toList());\n+                aggs.add(new InternalTDigestPercentiles(name(), config.keys, state, config.keyed, config.formatter, metadata()));\n+                newBucket = factory.createBucket(factory.getKey(bucket), bucket.getDocCount(), new InternalAggregations(aggs));\n+            }\n+            newBuckets.add(newBucket);\n+            index++;\n+        }\n+    }\n+\n+    private void reduceHDR(List<? extends InternalMultiBucketAggregation.InternalBucket> buckets,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37eb537b849657111a9eeba6ee0ec00c437ed260"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzkxOTYwNQ==", "bodyText": "Could we move this chunk of exception code into a function so all the resolve methods can use it?", "url": "https://github.com/elastic/elasticsearch/pull/55441#discussion_r413919605", "createdAt": "2020-04-23T15:57:12Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/movingPercentiles/MovingPercentilesPipelineAggregator.java", "diffHunk": "@@ -0,0 +1,276 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.movingPercentiles;\n+\n+import org.HdrHistogram.DoubleHistogram;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AggregationExecutionException;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.InternalAggregation.ReduceContext;\n+import org.elasticsearch.search.aggregations.InternalAggregations;\n+import org.elasticsearch.search.aggregations.InternalMultiBucketAggregation;\n+import org.elasticsearch.search.aggregations.bucket.MultiBucketsAggregation;\n+import org.elasticsearch.search.aggregations.bucket.MultiBucketsAggregation.Bucket;\n+import org.elasticsearch.search.aggregations.bucket.histogram.HistogramFactory;\n+import org.elasticsearch.search.aggregations.metrics.InternalHDRPercentiles;\n+import org.elasticsearch.search.aggregations.metrics.InternalTDigestPercentiles;\n+import org.elasticsearch.search.aggregations.metrics.PercentilesMethod;\n+import org.elasticsearch.search.aggregations.metrics.TDigestState;\n+import org.elasticsearch.search.aggregations.pipeline.AbstractPipelineAggregationBuilder;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.AggregationPath;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.StreamSupport;\n+\n+public class MovingPercentilesPipelineAggregator extends PipelineAggregator {\n+\n+    private final int window;\n+    private final int shift;\n+\n+    MovingPercentilesPipelineAggregator(String name, String[] bucketsPaths, int window, int shift,\n+                                        Map<String, Object> metadata) {\n+        super(name, bucketsPaths, metadata);\n+        this.window = window;\n+        this.shift = shift;\n+    }\n+\n+    @Override\n+    public InternalAggregation reduce(InternalAggregation aggregation, ReduceContext reduceContext) {\n+        InternalMultiBucketAggregation<? extends InternalMultiBucketAggregation, ? extends InternalMultiBucketAggregation.InternalBucket>\n+            histo = (InternalMultiBucketAggregation<? extends InternalMultiBucketAggregation, ? extends\n+            InternalMultiBucketAggregation.InternalBucket>) aggregation;\n+        List<? extends InternalMultiBucketAggregation.InternalBucket> buckets = histo.getBuckets();\n+        HistogramFactory factory = (HistogramFactory) histo;\n+\n+        List<Bucket> newBuckets = new ArrayList<>(buckets.size());\n+        if (buckets.size() == 0) {\n+            return factory.createAggregation(newBuckets);\n+        }\n+        PercentileConfig config = resolvePercentileConfig(histo, buckets.get(0), bucketsPaths()[0]);\n+        switch (config.method) {\n+            case TDIGEST:\n+                reduceTDigest(buckets, histo, newBuckets, factory, config);\n+                break;\n+            case HDR:\n+                reduceHDR(buckets, histo, newBuckets, factory, config);\n+                break;\n+            default:\n+                throw new AggregationExecutionException(AbstractPipelineAggregationBuilder.BUCKETS_PATH_FIELD.getPreferredName()\n+                    + \" references an unknown percentile aggregation method: [\" + config.method + \"]\");\n+        }\n+        return factory.createAggregation(newBuckets);\n+    }\n+\n+    private void reduceTDigest(List<? extends InternalMultiBucketAggregation.InternalBucket> buckets,\n+                                              MultiBucketsAggregation histo,\n+                                              List<Bucket> newBuckets,\n+                                              HistogramFactory factory,\n+                                              PercentileConfig config) {\n+\n+        List<TDigestState> values = buckets.stream()\n+            .map(b -> resolveTDigestBucketValue(histo, b, bucketsPaths()[0]))\n+            .filter(v -> v != null)\n+            .collect(Collectors.toList());\n+\n+        int index = 0;\n+        for (InternalMultiBucketAggregation.InternalBucket bucket : buckets) {\n+\n+            // Default is to reuse existing bucket.  Simplifies the rest of the logic,\n+            // since we only change newBucket if we can add to it\n+            MultiBucketsAggregation.Bucket newBucket = bucket;\n+\n+            TDigestState state = null;\n+            int fromIndex = clamp(index - window + shift, values.size());\n+            int toIndex = clamp(index + shift, values.size());\n+            for (int i = fromIndex; i < toIndex; i++) {\n+                TDigestState bucketState = values.get(i);\n+                if (bucketState != null) {\n+                    if (state == null) {\n+                        // We have to create a new TDigest histogram because otherwise it will alter the\n+                        // existing histogram and bucket value\n+                        state = new TDigestState(bucketState.compression());\n+                    }\n+                    state.add(bucketState);\n+\n+                }\n+            }\n+\n+            if (state != null) {\n+                List<InternalAggregation> aggs = StreamSupport.stream(bucket.getAggregations().spliterator(), false)\n+                    .map((p) -> (InternalAggregation) p)\n+                    .collect(Collectors.toList());\n+                aggs.add(new InternalTDigestPercentiles(name(), config.keys, state, config.keyed, config.formatter, metadata()));\n+                newBucket = factory.createBucket(factory.getKey(bucket), bucket.getDocCount(), new InternalAggregations(aggs));\n+            }\n+            newBuckets.add(newBucket);\n+            index++;\n+        }\n+    }\n+\n+    private void reduceHDR(List<? extends InternalMultiBucketAggregation.InternalBucket> buckets,\n+                               MultiBucketsAggregation histo,\n+                               List<Bucket> newBuckets,\n+                               HistogramFactory factory,\n+                               PercentileConfig config) {\n+\n+        List<DoubleHistogram> values = buckets.stream()\n+            .map(b -> resolveHDRBucketValue(histo, b, bucketsPaths()[0]))\n+            .filter(v -> v != null)\n+            .collect(Collectors.toList());\n+\n+        int index = 0;\n+        for (InternalMultiBucketAggregation.InternalBucket bucket : buckets) {\n+            DoubleHistogram state = null;\n+\n+            // Default is to reuse existing bucket.  Simplifies the rest of the logic,\n+            // since we only change newBucket if we can add to it\n+            MultiBucketsAggregation.Bucket newBucket = bucket;\n+\n+            int fromIndex = clamp(index - window + shift, values.size());\n+            int toIndex = clamp(index + shift, values.size());\n+            for (int i = fromIndex; i < toIndex; i++) {\n+                DoubleHistogram bucketState = values.get(i);\n+                if (bucketState != null) {\n+                    if (state == null) {\n+                        // We have to create a new HDR histogram because otherwise it will alter the\n+                        // existing histogram and bucket value\n+                        state = new DoubleHistogram(bucketState.getNumberOfSignificantValueDigits());\n+                    }\n+                    state.add(bucketState);\n+\n+                }\n+            }\n+\n+            if (state != null) {\n+                List<InternalAggregation> aggs = StreamSupport.stream(bucket.getAggregations().spliterator(), false)\n+                    .map((p) -> (InternalAggregation) p)\n+                    .collect(Collectors.toList());\n+                aggs.add(new InternalHDRPercentiles(name(), config.keys, state, config.keyed, config.formatter, metadata()));\n+                newBucket = factory.createBucket(factory.getKey(bucket), bucket.getDocCount(), new InternalAggregations(aggs));\n+            }\n+            newBuckets.add(newBucket);\n+            index++;\n+        }\n+    }\n+\n+    private PercentileConfig resolvePercentileConfig(MultiBucketsAggregation agg,\n+                                                 InternalMultiBucketAggregation.InternalBucket bucket,\n+                                                 String aggPath) {\n+        List<String> aggPathsList = AggregationPath.parse(aggPath).getPathElementsAsStringList();\n+        Object propertyValue = bucket.getProperty(agg.getName(), aggPathsList);\n+        if (propertyValue == null) {\n+            throw new AggregationExecutionException(AbstractPipelineAggregationBuilder.BUCKETS_PATH_FIELD.getPreferredName()\n+                + \" must reference an aggregation\");\n+        }\n+\n+        if (propertyValue instanceof InternalTDigestPercentiles) {\n+            InternalTDigestPercentiles internalTDigestPercentiles = ((InternalTDigestPercentiles) propertyValue);\n+            return new PercentileConfig(PercentilesMethod.TDIGEST,\n+                                        internalTDigestPercentiles.getKeys(),\n+                                        internalTDigestPercentiles.keyed(),\n+                                        internalTDigestPercentiles.formatter());\n+        }\n+        if (propertyValue instanceof InternalHDRPercentiles) {\n+            InternalHDRPercentiles internalHDRPercentiles = ((InternalHDRPercentiles) propertyValue);\n+            return new PercentileConfig(PercentilesMethod.HDR,\n+                                        internalHDRPercentiles.getKeys(),\n+                                        internalHDRPercentiles.keyed(),\n+                                        internalHDRPercentiles.formatter());\n+        }\n+\n+        String currentAggName;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37eb537b849657111a9eeba6ee0ec00c437ed260"}, "originalPosition": 188}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzkyMDM1Nw==", "bodyText": "Let's change this to an IllegalArgumentException, since technically it's the client's fault for pointing us at the wrong thing :)", "url": "https://github.com/elastic/elasticsearch/pull/55441#discussion_r413920357", "createdAt": "2020-04-23T15:58:06Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/movingPercentiles/MovingPercentilesPipelineAggregator.java", "diffHunk": "@@ -0,0 +1,276 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.movingPercentiles;\n+\n+import org.HdrHistogram.DoubleHistogram;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AggregationExecutionException;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.InternalAggregation.ReduceContext;\n+import org.elasticsearch.search.aggregations.InternalAggregations;\n+import org.elasticsearch.search.aggregations.InternalMultiBucketAggregation;\n+import org.elasticsearch.search.aggregations.bucket.MultiBucketsAggregation;\n+import org.elasticsearch.search.aggregations.bucket.MultiBucketsAggregation.Bucket;\n+import org.elasticsearch.search.aggregations.bucket.histogram.HistogramFactory;\n+import org.elasticsearch.search.aggregations.metrics.InternalHDRPercentiles;\n+import org.elasticsearch.search.aggregations.metrics.InternalTDigestPercentiles;\n+import org.elasticsearch.search.aggregations.metrics.PercentilesMethod;\n+import org.elasticsearch.search.aggregations.metrics.TDigestState;\n+import org.elasticsearch.search.aggregations.pipeline.AbstractPipelineAggregationBuilder;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.AggregationPath;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.StreamSupport;\n+\n+public class MovingPercentilesPipelineAggregator extends PipelineAggregator {\n+\n+    private final int window;\n+    private final int shift;\n+\n+    MovingPercentilesPipelineAggregator(String name, String[] bucketsPaths, int window, int shift,\n+                                        Map<String, Object> metadata) {\n+        super(name, bucketsPaths, metadata);\n+        this.window = window;\n+        this.shift = shift;\n+    }\n+\n+    @Override\n+    public InternalAggregation reduce(InternalAggregation aggregation, ReduceContext reduceContext) {\n+        InternalMultiBucketAggregation<? extends InternalMultiBucketAggregation, ? extends InternalMultiBucketAggregation.InternalBucket>\n+            histo = (InternalMultiBucketAggregation<? extends InternalMultiBucketAggregation, ? extends\n+            InternalMultiBucketAggregation.InternalBucket>) aggregation;\n+        List<? extends InternalMultiBucketAggregation.InternalBucket> buckets = histo.getBuckets();\n+        HistogramFactory factory = (HistogramFactory) histo;\n+\n+        List<Bucket> newBuckets = new ArrayList<>(buckets.size());\n+        if (buckets.size() == 0) {\n+            return factory.createAggregation(newBuckets);\n+        }\n+        PercentileConfig config = resolvePercentileConfig(histo, buckets.get(0), bucketsPaths()[0]);\n+        switch (config.method) {\n+            case TDIGEST:\n+                reduceTDigest(buckets, histo, newBuckets, factory, config);\n+                break;\n+            case HDR:\n+                reduceHDR(buckets, histo, newBuckets, factory, config);\n+                break;\n+            default:\n+                throw new AggregationExecutionException(AbstractPipelineAggregationBuilder.BUCKETS_PATH_FIELD.getPreferredName()\n+                    + \" references an unknown percentile aggregation method: [\" + config.method + \"]\");\n+        }\n+        return factory.createAggregation(newBuckets);\n+    }\n+\n+    private void reduceTDigest(List<? extends InternalMultiBucketAggregation.InternalBucket> buckets,\n+                                              MultiBucketsAggregation histo,\n+                                              List<Bucket> newBuckets,\n+                                              HistogramFactory factory,\n+                                              PercentileConfig config) {\n+\n+        List<TDigestState> values = buckets.stream()\n+            .map(b -> resolveTDigestBucketValue(histo, b, bucketsPaths()[0]))\n+            .filter(v -> v != null)\n+            .collect(Collectors.toList());\n+\n+        int index = 0;\n+        for (InternalMultiBucketAggregation.InternalBucket bucket : buckets) {\n+\n+            // Default is to reuse existing bucket.  Simplifies the rest of the logic,\n+            // since we only change newBucket if we can add to it\n+            MultiBucketsAggregation.Bucket newBucket = bucket;\n+\n+            TDigestState state = null;\n+            int fromIndex = clamp(index - window + shift, values.size());\n+            int toIndex = clamp(index + shift, values.size());\n+            for (int i = fromIndex; i < toIndex; i++) {\n+                TDigestState bucketState = values.get(i);\n+                if (bucketState != null) {\n+                    if (state == null) {\n+                        // We have to create a new TDigest histogram because otherwise it will alter the\n+                        // existing histogram and bucket value\n+                        state = new TDigestState(bucketState.compression());\n+                    }\n+                    state.add(bucketState);\n+\n+                }\n+            }\n+\n+            if (state != null) {\n+                List<InternalAggregation> aggs = StreamSupport.stream(bucket.getAggregations().spliterator(), false)\n+                    .map((p) -> (InternalAggregation) p)\n+                    .collect(Collectors.toList());\n+                aggs.add(new InternalTDigestPercentiles(name(), config.keys, state, config.keyed, config.formatter, metadata()));\n+                newBucket = factory.createBucket(factory.getKey(bucket), bucket.getDocCount(), new InternalAggregations(aggs));\n+            }\n+            newBuckets.add(newBucket);\n+            index++;\n+        }\n+    }\n+\n+    private void reduceHDR(List<? extends InternalMultiBucketAggregation.InternalBucket> buckets,\n+                               MultiBucketsAggregation histo,\n+                               List<Bucket> newBuckets,\n+                               HistogramFactory factory,\n+                               PercentileConfig config) {\n+\n+        List<DoubleHistogram> values = buckets.stream()\n+            .map(b -> resolveHDRBucketValue(histo, b, bucketsPaths()[0]))\n+            .filter(v -> v != null)\n+            .collect(Collectors.toList());\n+\n+        int index = 0;\n+        for (InternalMultiBucketAggregation.InternalBucket bucket : buckets) {\n+            DoubleHistogram state = null;\n+\n+            // Default is to reuse existing bucket.  Simplifies the rest of the logic,\n+            // since we only change newBucket if we can add to it\n+            MultiBucketsAggregation.Bucket newBucket = bucket;\n+\n+            int fromIndex = clamp(index - window + shift, values.size());\n+            int toIndex = clamp(index + shift, values.size());\n+            for (int i = fromIndex; i < toIndex; i++) {\n+                DoubleHistogram bucketState = values.get(i);\n+                if (bucketState != null) {\n+                    if (state == null) {\n+                        // We have to create a new HDR histogram because otherwise it will alter the\n+                        // existing histogram and bucket value\n+                        state = new DoubleHistogram(bucketState.getNumberOfSignificantValueDigits());\n+                    }\n+                    state.add(bucketState);\n+\n+                }\n+            }\n+\n+            if (state != null) {\n+                List<InternalAggregation> aggs = StreamSupport.stream(bucket.getAggregations().spliterator(), false)\n+                    .map((p) -> (InternalAggregation) p)\n+                    .collect(Collectors.toList());\n+                aggs.add(new InternalHDRPercentiles(name(), config.keys, state, config.keyed, config.formatter, metadata()));\n+                newBucket = factory.createBucket(factory.getKey(bucket), bucket.getDocCount(), new InternalAggregations(aggs));\n+            }\n+            newBuckets.add(newBucket);\n+            index++;\n+        }\n+    }\n+\n+    private PercentileConfig resolvePercentileConfig(MultiBucketsAggregation agg,\n+                                                 InternalMultiBucketAggregation.InternalBucket bucket,\n+                                                 String aggPath) {\n+        List<String> aggPathsList = AggregationPath.parse(aggPath).getPathElementsAsStringList();\n+        Object propertyValue = bucket.getProperty(agg.getName(), aggPathsList);\n+        if (propertyValue == null) {\n+            throw new AggregationExecutionException(AbstractPipelineAggregationBuilder.BUCKETS_PATH_FIELD.getPreferredName()\n+                + \" must reference an aggregation\");\n+        }\n+\n+        if (propertyValue instanceof InternalTDigestPercentiles) {\n+            InternalTDigestPercentiles internalTDigestPercentiles = ((InternalTDigestPercentiles) propertyValue);\n+            return new PercentileConfig(PercentilesMethod.TDIGEST,\n+                                        internalTDigestPercentiles.getKeys(),\n+                                        internalTDigestPercentiles.keyed(),\n+                                        internalTDigestPercentiles.formatter());\n+        }\n+        if (propertyValue instanceof InternalHDRPercentiles) {\n+            InternalHDRPercentiles internalHDRPercentiles = ((InternalHDRPercentiles) propertyValue);\n+            return new PercentileConfig(PercentilesMethod.HDR,\n+                                        internalHDRPercentiles.getKeys(),\n+                                        internalHDRPercentiles.keyed(),\n+                                        internalHDRPercentiles.formatter());\n+        }\n+\n+        String currentAggName;\n+        if (aggPathsList.isEmpty()) {\n+            currentAggName = agg.getName();\n+        } else {\n+            currentAggName = aggPathsList.get(0);\n+        }\n+\n+        throw new AggregationExecutionException(AbstractPipelineAggregationBuilder.BUCKETS_PATH_FIELD.getPreferredName()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37eb537b849657111a9eeba6ee0ec00c437ed260"}, "originalPosition": 195}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzkyMzQ2Nw==", "bodyText": "Let's add a TODO here to replace this with the PercentilesConfig that's used by the percentiles builder.  I don't think we can do that yet since the config isn't available through the Internal objects... but eventually when we refactor pipelines sufficiently they should be able to grab this from original request builder object I think.", "url": "https://github.com/elastic/elasticsearch/pull/55441#discussion_r413923467", "createdAt": "2020-04-23T16:01:55Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/movingPercentiles/MovingPercentilesPipelineAggregator.java", "diffHunk": "@@ -0,0 +1,276 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.movingPercentiles;\n+\n+import org.HdrHistogram.DoubleHistogram;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AggregationExecutionException;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.InternalAggregation.ReduceContext;\n+import org.elasticsearch.search.aggregations.InternalAggregations;\n+import org.elasticsearch.search.aggregations.InternalMultiBucketAggregation;\n+import org.elasticsearch.search.aggregations.bucket.MultiBucketsAggregation;\n+import org.elasticsearch.search.aggregations.bucket.MultiBucketsAggregation.Bucket;\n+import org.elasticsearch.search.aggregations.bucket.histogram.HistogramFactory;\n+import org.elasticsearch.search.aggregations.metrics.InternalHDRPercentiles;\n+import org.elasticsearch.search.aggregations.metrics.InternalTDigestPercentiles;\n+import org.elasticsearch.search.aggregations.metrics.PercentilesMethod;\n+import org.elasticsearch.search.aggregations.metrics.TDigestState;\n+import org.elasticsearch.search.aggregations.pipeline.AbstractPipelineAggregationBuilder;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.AggregationPath;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.StreamSupport;\n+\n+public class MovingPercentilesPipelineAggregator extends PipelineAggregator {\n+\n+    private final int window;\n+    private final int shift;\n+\n+    MovingPercentilesPipelineAggregator(String name, String[] bucketsPaths, int window, int shift,\n+                                        Map<String, Object> metadata) {\n+        super(name, bucketsPaths, metadata);\n+        this.window = window;\n+        this.shift = shift;\n+    }\n+\n+    @Override\n+    public InternalAggregation reduce(InternalAggregation aggregation, ReduceContext reduceContext) {\n+        InternalMultiBucketAggregation<? extends InternalMultiBucketAggregation, ? extends InternalMultiBucketAggregation.InternalBucket>\n+            histo = (InternalMultiBucketAggregation<? extends InternalMultiBucketAggregation, ? extends\n+            InternalMultiBucketAggregation.InternalBucket>) aggregation;\n+        List<? extends InternalMultiBucketAggregation.InternalBucket> buckets = histo.getBuckets();\n+        HistogramFactory factory = (HistogramFactory) histo;\n+\n+        List<Bucket> newBuckets = new ArrayList<>(buckets.size());\n+        if (buckets.size() == 0) {\n+            return factory.createAggregation(newBuckets);\n+        }\n+        PercentileConfig config = resolvePercentileConfig(histo, buckets.get(0), bucketsPaths()[0]);\n+        switch (config.method) {\n+            case TDIGEST:\n+                reduceTDigest(buckets, histo, newBuckets, factory, config);\n+                break;\n+            case HDR:\n+                reduceHDR(buckets, histo, newBuckets, factory, config);\n+                break;\n+            default:\n+                throw new AggregationExecutionException(AbstractPipelineAggregationBuilder.BUCKETS_PATH_FIELD.getPreferredName()\n+                    + \" references an unknown percentile aggregation method: [\" + config.method + \"]\");\n+        }\n+        return factory.createAggregation(newBuckets);\n+    }\n+\n+    private void reduceTDigest(List<? extends InternalMultiBucketAggregation.InternalBucket> buckets,\n+                                              MultiBucketsAggregation histo,\n+                                              List<Bucket> newBuckets,\n+                                              HistogramFactory factory,\n+                                              PercentileConfig config) {\n+\n+        List<TDigestState> values = buckets.stream()\n+            .map(b -> resolveTDigestBucketValue(histo, b, bucketsPaths()[0]))\n+            .filter(v -> v != null)\n+            .collect(Collectors.toList());\n+\n+        int index = 0;\n+        for (InternalMultiBucketAggregation.InternalBucket bucket : buckets) {\n+\n+            // Default is to reuse existing bucket.  Simplifies the rest of the logic,\n+            // since we only change newBucket if we can add to it\n+            MultiBucketsAggregation.Bucket newBucket = bucket;\n+\n+            TDigestState state = null;\n+            int fromIndex = clamp(index - window + shift, values.size());\n+            int toIndex = clamp(index + shift, values.size());\n+            for (int i = fromIndex; i < toIndex; i++) {\n+                TDigestState bucketState = values.get(i);\n+                if (bucketState != null) {\n+                    if (state == null) {\n+                        // We have to create a new TDigest histogram because otherwise it will alter the\n+                        // existing histogram and bucket value\n+                        state = new TDigestState(bucketState.compression());\n+                    }\n+                    state.add(bucketState);\n+\n+                }\n+            }\n+\n+            if (state != null) {\n+                List<InternalAggregation> aggs = StreamSupport.stream(bucket.getAggregations().spliterator(), false)\n+                    .map((p) -> (InternalAggregation) p)\n+                    .collect(Collectors.toList());\n+                aggs.add(new InternalTDigestPercentiles(name(), config.keys, state, config.keyed, config.formatter, metadata()));\n+                newBucket = factory.createBucket(factory.getKey(bucket), bucket.getDocCount(), new InternalAggregations(aggs));\n+            }\n+            newBuckets.add(newBucket);\n+            index++;\n+        }\n+    }\n+\n+    private void reduceHDR(List<? extends InternalMultiBucketAggregation.InternalBucket> buckets,\n+                               MultiBucketsAggregation histo,\n+                               List<Bucket> newBuckets,\n+                               HistogramFactory factory,\n+                               PercentileConfig config) {\n+\n+        List<DoubleHistogram> values = buckets.stream()\n+            .map(b -> resolveHDRBucketValue(histo, b, bucketsPaths()[0]))\n+            .filter(v -> v != null)\n+            .collect(Collectors.toList());\n+\n+        int index = 0;\n+        for (InternalMultiBucketAggregation.InternalBucket bucket : buckets) {\n+            DoubleHistogram state = null;\n+\n+            // Default is to reuse existing bucket.  Simplifies the rest of the logic,\n+            // since we only change newBucket if we can add to it\n+            MultiBucketsAggregation.Bucket newBucket = bucket;\n+\n+            int fromIndex = clamp(index - window + shift, values.size());\n+            int toIndex = clamp(index + shift, values.size());\n+            for (int i = fromIndex; i < toIndex; i++) {\n+                DoubleHistogram bucketState = values.get(i);\n+                if (bucketState != null) {\n+                    if (state == null) {\n+                        // We have to create a new HDR histogram because otherwise it will alter the\n+                        // existing histogram and bucket value\n+                        state = new DoubleHistogram(bucketState.getNumberOfSignificantValueDigits());\n+                    }\n+                    state.add(bucketState);\n+\n+                }\n+            }\n+\n+            if (state != null) {\n+                List<InternalAggregation> aggs = StreamSupport.stream(bucket.getAggregations().spliterator(), false)\n+                    .map((p) -> (InternalAggregation) p)\n+                    .collect(Collectors.toList());\n+                aggs.add(new InternalHDRPercentiles(name(), config.keys, state, config.keyed, config.formatter, metadata()));\n+                newBucket = factory.createBucket(factory.getKey(bucket), bucket.getDocCount(), new InternalAggregations(aggs));\n+            }\n+            newBuckets.add(newBucket);\n+            index++;\n+        }\n+    }\n+\n+    private PercentileConfig resolvePercentileConfig(MultiBucketsAggregation agg,\n+                                                 InternalMultiBucketAggregation.InternalBucket bucket,\n+                                                 String aggPath) {\n+        List<String> aggPathsList = AggregationPath.parse(aggPath).getPathElementsAsStringList();\n+        Object propertyValue = bucket.getProperty(agg.getName(), aggPathsList);\n+        if (propertyValue == null) {\n+            throw new AggregationExecutionException(AbstractPipelineAggregationBuilder.BUCKETS_PATH_FIELD.getPreferredName()\n+                + \" must reference an aggregation\");\n+        }\n+\n+        if (propertyValue instanceof InternalTDigestPercentiles) {\n+            InternalTDigestPercentiles internalTDigestPercentiles = ((InternalTDigestPercentiles) propertyValue);\n+            return new PercentileConfig(PercentilesMethod.TDIGEST,\n+                                        internalTDigestPercentiles.getKeys(),\n+                                        internalTDigestPercentiles.keyed(),\n+                                        internalTDigestPercentiles.formatter());\n+        }\n+        if (propertyValue instanceof InternalHDRPercentiles) {\n+            InternalHDRPercentiles internalHDRPercentiles = ((InternalHDRPercentiles) propertyValue);\n+            return new PercentileConfig(PercentilesMethod.HDR,\n+                                        internalHDRPercentiles.getKeys(),\n+                                        internalHDRPercentiles.keyed(),\n+                                        internalHDRPercentiles.formatter());\n+        }\n+\n+        String currentAggName;\n+        if (aggPathsList.isEmpty()) {\n+            currentAggName = agg.getName();\n+        } else {\n+            currentAggName = aggPathsList.get(0);\n+        }\n+\n+        throw new AggregationExecutionException(AbstractPipelineAggregationBuilder.BUCKETS_PATH_FIELD.getPreferredName()\n+            + \" must reference a percentiles aggregation, got: [\"\n+            + propertyValue.getClass().getSimpleName() + \"] at aggregation [\" + currentAggName + \"]\");\n+    }\n+\n+    private TDigestState resolveTDigestBucketValue(MultiBucketsAggregation agg,\n+                                                   InternalMultiBucketAggregation.InternalBucket bucket,\n+                                                   String aggPath) {\n+        List<String> aggPathsList = AggregationPath.parse(aggPath).getPathElementsAsStringList();\n+        Object propertyValue = bucket.getProperty(agg.getName(), aggPathsList);\n+        if (propertyValue == null) {\n+            throw new AggregationExecutionException(AbstractPipelineAggregationBuilder.BUCKETS_PATH_FIELD.getPreferredName()\n+                + \" must reference a TDigest percentile aggregation\");\n+        }\n+\n+        if (propertyValue instanceof InternalTDigestPercentiles) {\n+            return ((InternalTDigestPercentiles) propertyValue).getState();\n+        }\n+\n+        String currentAggName;\n+        if (aggPathsList.isEmpty()) {\n+            currentAggName = agg.getName();\n+        } else {\n+            currentAggName = aggPathsList.get(0);\n+        }\n+\n+        throw new AggregationExecutionException(AbstractPipelineAggregationBuilder.BUCKETS_PATH_FIELD.getPreferredName()\n+            + \" must reference a TDigest percentiles aggregation, got: [\"\n+            + propertyValue.getClass().getSimpleName() + \"] at aggregation [\" + currentAggName + \"]\");\n+    }\n+\n+    private DoubleHistogram resolveHDRBucketValue(MultiBucketsAggregation agg,\n+                                                  InternalMultiBucketAggregation.InternalBucket bucket,\n+                                                  String aggPath) {\n+        List<String> aggPathsList = AggregationPath.parse(aggPath).getPathElementsAsStringList();\n+        Object propertyValue = bucket.getProperty(agg.getName(), aggPathsList);\n+        if (propertyValue == null) {\n+            throw new AggregationExecutionException(AbstractPipelineAggregationBuilder.BUCKETS_PATH_FIELD.getPreferredName()\n+                + \" must reference a HDR percentile aggregation\");\n+        }\n+\n+        if (propertyValue instanceof InternalHDRPercentiles) {\n+            return ((InternalHDRPercentiles) propertyValue).getState();\n+        }\n+\n+        String currentAggName;\n+        if (aggPathsList.isEmpty()) {\n+            currentAggName = agg.getName();\n+        } else {\n+            currentAggName = aggPathsList.get(0);\n+        }\n+\n+        throw new AggregationExecutionException(AbstractPipelineAggregationBuilder.BUCKETS_PATH_FIELD.getPreferredName()\n+            + \" must reference a HDR percentiles aggregation, got: [\"\n+            + propertyValue.getClass().getSimpleName() + \"] at aggregation [\" + currentAggName + \"]\");\n+    }\n+\n+    private int clamp(int index, int length) {\n+        if (index < 0) {\n+            return 0;\n+        }\n+        if (index > length) {\n+            return length;\n+        }\n+        return index;\n+    }\n+\n+    /** helper class to collect the percentile's configuration */\n+    private static class PercentileConfig {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37eb537b849657111a9eeba6ee0ec00c437ed260"}, "originalPosition": 263}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzkyMzk3OQ==", "bodyText": "Leftover from debugging?", "url": "https://github.com/elastic/elasticsearch/pull/55441#discussion_r413923979", "createdAt": "2020-04-23T16:02:36Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/src/test/resources/rest-api-spec/test/analytics/moving_percentile.yml", "diffHunk": "@@ -0,0 +1,144 @@\n+setup:\n+  - skip:\n+      features: headers\n+  - do:\n+      indices.create:\n+        index: foo\n+        body:\n+          mappings:\n+            properties:\n+              timestamp:\n+                type: date\n+              histogram:\n+                type: histogram\n+\n+\n+  - do:\n+      headers:\n+        Authorization: \"Basic eF9wYWNrX3Jlc3RfdXNlcjp4LXBhY2stdGVzdC1wYXNzd29yZA==\" # run as x_pack_rest_user, i.e. the test setup superuser\n+      bulk:\n+        refresh: true\n+        body:\n+          - index:\n+              _index: \"foo\"\n+          - timestamp: \"2017-01-01T05:00:00Z\"\n+            histogram:\n+              values: [0.1, 0.5, 1, 2, 4, 10]\n+              counts: [1, 4, 5, 4, 5, 1]\n+\n+          - index:\n+              _index: \"foo\"\n+          - timestamp: \"2017-01-01T05:00:00Z\"\n+            histogram:\n+              values: [0.1, 0.5, 1, 2, 4, 10]\n+              counts: [1, 4, 5, 4, 5, 1]\n+\n+          - index:\n+              _index: \"foo\"\n+          - timestamp: \"2017-01-01T05:00:00Z\"\n+            histogram:\n+              values: [0.1, 0.5, 1, 2, 4, 10]\n+              counts: [1, 4, 5, 4, 5, 1]\n+\n+          - index:\n+              _index: \"foo\"\n+          - timestamp: \"2017-01-02T05:00:00Z\"\n+            histogram:\n+              values: [0.1, 0.5, 1, 2, 4, 10]\n+              counts: [1, 4, 5, 4, 5, 1]\n+\n+          - index:\n+              _index: \"foo\"\n+          - timestamp: \"2017-01-02T05:00:00Z\"\n+            histogram:\n+              values: [0.1, 0.5, 1, 2, 4, 10]\n+              counts: [1, 4, 5, 4, 5, 1]\n+\n+          - index:\n+              _index: \"foo\"\n+          - timestamp: \"2017-01-03T05:00:00Z\"\n+            histogram:\n+              values: [0.1, 0.5, 1, 2, 4, 10]\n+              counts: [1, 4, 5, 4, 5, 1]\n+\n+---\n+\"Basic Search TDigest\":\n+# --tests \"org.elasticsearch.xpack.test.rest.XPackRestIT.test {p0=analytics/moving_percentile/Basic Search}\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37eb537b849657111a9eeba6ee0ec00c437ed260"}, "originalPosition": 66}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b817d41c2a8c5cfa9a9f83f3f9688c25bf194575", "author": {"user": {"login": "iverase", "name": "Ignacio Vera"}}, "url": "https://github.com/elastic/elasticsearch/commit/b817d41c2a8c5cfa9a9f83f3f9688c25bf194575", "committedDate": "2020-04-24T10:35:52Z", "message": "address review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b3c314b9853254e30ff5cbd94a118b6dc2c480e7", "author": {"user": {"login": "iverase", "name": "Ignacio Vera"}}, "url": "https://github.com/elastic/elasticsearch/commit/b3c314b9853254e30ff5cbd94a118b6dc2c480e7", "committedDate": "2020-04-24T11:30:15Z", "message": "Merge branch 'master' into movingPercentiles"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "099d62101d1960a9e199e864feb958fb0a3fc5d8", "author": {"user": {"login": "iverase", "name": "Ignacio Vera"}}, "url": "https://github.com/elastic/elasticsearch/commit/099d62101d1960a9e199e864feb958fb0a3fc5d8", "committedDate": "2020-04-24T11:33:15Z", "message": "fix doc issue"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAwMDExOTM4", "url": "https://github.com/elastic/elasticsearch/pull/55441#pullrequestreview-400011938", "createdAt": "2020-04-24T14:44:53Z", "commit": {"oid": "099d62101d1960a9e199e864feb958fb0a3fc5d8"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQxNDo0NDo1M1rOGLbI1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQxNDo1MzozOFrOGLbi8g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDYzMjE1MA==", "bodyText": "Would you kindly add javadoc to these while you are here?", "url": "https://github.com/elastic/elasticsearch/pull/55441#discussion_r414632150", "createdAt": "2020-04-24T14:44:53Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/search/aggregations/metrics/AbstractInternalHDRPercentiles.java", "diffHunk": "@@ -96,10 +96,18 @@ public long getEstimatedMemoryFootprint() {\n         return state.getEstimatedFootprintInBytes();\n     }\n \n-    DoubleHistogram getState() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "099d62101d1960a9e199e864feb958fb0a3fc5d8"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDYzNTA1MA==", "bodyText": "I think it may be worth adding something near bucketCardinality that returns the type of buckets. That'd let us do this ordered assertion without instanceofs. I'd be happy to take a stab at it in a follow up because I have ideas. No need to delay this PR for it though.", "url": "https://github.com/elastic/elasticsearch/pull/55441#discussion_r414635050", "createdAt": "2020-04-24T14:48:38Z", "author": {"login": "nik9000"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/movingPercentiles/MovingPercentilesPipelineAggregationBuilder.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.movingPercentiles;\n+\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.search.aggregations.pipeline.AbstractPipelineAggregationBuilder;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+\n+import java.io.IOException;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+\n+public class MovingPercentilesPipelineAggregationBuilder\n+        extends AbstractPipelineAggregationBuilder<MovingPercentilesPipelineAggregationBuilder> {\n+    public static final String NAME = \"moving_percentiles\";\n+    private static final ParseField WINDOW = new ParseField(\"window\");\n+    private static final ParseField SHIFT = new ParseField(\"shift\");\n+\n+    public static final ConstructingObjectParser<MovingPercentilesPipelineAggregationBuilder, String> PARSER =\n+            new ConstructingObjectParser<>(NAME, false, (args, name) -> {\n+                return new MovingPercentilesPipelineAggregationBuilder(name, (String) args[0], (int) args[1]);\n+            });\n+    static {\n+        PARSER.declareString(constructorArg(), BUCKETS_PATH_FIELD);\n+        PARSER.declareInt(constructorArg(), WINDOW);\n+        PARSER.declareInt(MovingPercentilesPipelineAggregationBuilder::setShift, SHIFT);\n+    }\n+\n+    private final int window;\n+    private int shift;\n+\n+    public MovingPercentilesPipelineAggregationBuilder(String name, String bucketsPath, int window) {\n+        super(name, NAME, new String[] { bucketsPath });\n+        if (window <= 0) {\n+            throw new IllegalArgumentException(\"[\" + WINDOW.getPreferredName() + \"] must be a positive, non-zero integer.\");\n+        }\n+        this.window = window;\n+    }\n+\n+    /**\n+     * Read from a stream.\n+     */\n+    public MovingPercentilesPipelineAggregationBuilder(StreamInput in) throws IOException {\n+        super(in, NAME);\n+        window = in.readVInt();\n+        shift = in.readInt();\n+    }\n+\n+    @Override\n+    protected final void doWriteTo(StreamOutput out) throws IOException {\n+        out.writeVInt(window);\n+        out.writeInt(shift);\n+    }\n+\n+    /**\n+     * Returns the window size for this aggregation\n+     */\n+    public int getWindow() {\n+        return window;\n+    }\n+\n+    /**\n+     * Returns the shift for this aggregation\n+     */\n+    public int getShift() {\n+        return shift;\n+    }\n+\n+    /**\n+     * Sets the shift for this aggregation\n+     */\n+    public void setShift(int shift) {\n+        this.shift = shift;\n+    }\n+\n+    @Override\n+    protected PipelineAggregator createInternal(Map<String, Object> metaData) {\n+        return new MovingPercentilesPipelineAggregator(name, bucketsPaths, getWindow(), getShift(), metaData);\n+    }\n+\n+    @Override\n+    protected void validate(ValidationContext context) {\n+        if (bucketsPaths.length != 1) {\n+            context.addBucketPathValidationError(\"must contain a single entry for aggregation [\" + name + \"]\");\n+        }\n+        context.validateParentAggSequentiallyOrdered(NAME, name);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzg5NzAxMQ=="}, "originalCommit": {"oid": "37eb537b849657111a9eeba6ee0ec00c437ed260"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDYzODgzNA==", "bodyText": "I think it'd be a fairly small change to plumb the parent builder into the ctor of the pipeline aggregator. A fine thing to do in a follow up though because it'd touch a bunch of file mechanically.", "url": "https://github.com/elastic/elasticsearch/pull/55441#discussion_r414638834", "createdAt": "2020-04-24T14:53:38Z", "author": {"login": "nik9000"}, "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/movingPercentiles/MovingPercentilesPipelineAggregator.java", "diffHunk": "@@ -0,0 +1,254 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.movingPercentiles;\n+\n+import org.HdrHistogram.DoubleHistogram;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AggregationExecutionException;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.InternalAggregation.ReduceContext;\n+import org.elasticsearch.search.aggregations.InternalAggregations;\n+import org.elasticsearch.search.aggregations.InternalMultiBucketAggregation;\n+import org.elasticsearch.search.aggregations.bucket.MultiBucketsAggregation;\n+import org.elasticsearch.search.aggregations.bucket.MultiBucketsAggregation.Bucket;\n+import org.elasticsearch.search.aggregations.bucket.histogram.HistogramFactory;\n+import org.elasticsearch.search.aggregations.metrics.InternalHDRPercentiles;\n+import org.elasticsearch.search.aggregations.metrics.InternalTDigestPercentiles;\n+import org.elasticsearch.search.aggregations.metrics.PercentilesMethod;\n+import org.elasticsearch.search.aggregations.metrics.TDigestState;\n+import org.elasticsearch.search.aggregations.pipeline.AbstractPipelineAggregationBuilder;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.AggregationPath;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+public class MovingPercentilesPipelineAggregator extends PipelineAggregator {\n+\n+    private final int window;\n+    private final int shift;\n+\n+    MovingPercentilesPipelineAggregator(String name, String[] bucketsPaths, int window, int shift,\n+                                        Map<String, Object> metadata) {\n+        super(name, bucketsPaths, metadata);\n+        this.window = window;\n+        this.shift = shift;\n+    }\n+\n+    @Override\n+    public InternalAggregation reduce(InternalAggregation aggregation, ReduceContext reduceContext) {\n+        InternalMultiBucketAggregation<? extends InternalMultiBucketAggregation, ? extends InternalMultiBucketAggregation.InternalBucket>\n+            histo = (InternalMultiBucketAggregation<? extends InternalMultiBucketAggregation, ? extends\n+            InternalMultiBucketAggregation.InternalBucket>) aggregation;\n+        List<? extends InternalMultiBucketAggregation.InternalBucket> buckets = histo.getBuckets();\n+        HistogramFactory factory = (HistogramFactory) histo;\n+\n+        List<Bucket> newBuckets = new ArrayList<>(buckets.size());\n+        if (buckets.size() == 0) {\n+            return factory.createAggregation(newBuckets);\n+        }\n+        PercentileConfig config = resolvePercentileConfig(histo, buckets.get(0), bucketsPaths()[0]);\n+        switch (config.method) {\n+            case TDIGEST:\n+                reduceTDigest(buckets, histo, newBuckets, factory, config);\n+                break;\n+            case HDR:\n+                reduceHDR(buckets, histo, newBuckets, factory, config);\n+                break;\n+            default:\n+                throw new AggregationExecutionException(AbstractPipelineAggregationBuilder.BUCKETS_PATH_FIELD.getPreferredName()\n+                    + \" references an unknown percentile aggregation method: [\" + config.method + \"]\");\n+        }\n+        return factory.createAggregation(newBuckets);\n+    }\n+\n+    private void reduceTDigest(List<? extends InternalMultiBucketAggregation.InternalBucket> buckets,\n+                                              MultiBucketsAggregation histo,\n+                                              List<Bucket> newBuckets,\n+                                              HistogramFactory factory,\n+                                              PercentileConfig config) {\n+\n+        List<TDigestState> values = buckets.stream()\n+            .map(b -> resolveTDigestBucketValue(histo, b, bucketsPaths()[0]))\n+            .filter(v -> v != null)\n+            .collect(Collectors.toList());\n+\n+        int index = 0;\n+        for (InternalMultiBucketAggregation.InternalBucket bucket : buckets) {\n+\n+            // Default is to reuse existing bucket.  Simplifies the rest of the logic,\n+            // since we only change newBucket if we can add to it\n+            MultiBucketsAggregation.Bucket newBucket = bucket;\n+\n+            TDigestState state = null;\n+            int fromIndex = clamp(index - window + shift, values.size());\n+            int toIndex = clamp(index + shift, values.size());\n+            for (int i = fromIndex; i < toIndex; i++) {\n+                TDigestState bucketState = values.get(i);\n+                if (bucketState != null) {\n+                    if (state == null) {\n+                        // We have to create a new TDigest histogram because otherwise it will alter the\n+                        // existing histogram and bucket value\n+                        state = new TDigestState(bucketState.compression());\n+                    }\n+                    state.add(bucketState);\n+\n+                }\n+            }\n+\n+            if (state != null) {\n+                List<InternalAggregation> aggs = bucket.getAggregations().asList().stream()\n+                    .map((p) -> (InternalAggregation) p)\n+                    .collect(Collectors.toList());\n+                aggs.add(new InternalTDigestPercentiles(name(), config.keys, state, config.keyed, config.formatter, metadata()));\n+                newBucket = factory.createBucket(factory.getKey(bucket), bucket.getDocCount(), new InternalAggregations(aggs));\n+            }\n+            newBuckets.add(newBucket);\n+            index++;\n+        }\n+    }\n+\n+    private void reduceHDR(List<? extends InternalMultiBucketAggregation.InternalBucket> buckets,\n+                               MultiBucketsAggregation histo,\n+                               List<Bucket> newBuckets,\n+                               HistogramFactory factory,\n+                               PercentileConfig config) {\n+\n+        List<DoubleHistogram> values = buckets.stream()\n+            .map(b -> resolveHDRBucketValue(histo, b, bucketsPaths()[0]))\n+            .filter(v -> v != null)\n+            .collect(Collectors.toList());\n+\n+        int index = 0;\n+        for (InternalMultiBucketAggregation.InternalBucket bucket : buckets) {\n+            DoubleHistogram state = null;\n+\n+            // Default is to reuse existing bucket.  Simplifies the rest of the logic,\n+            // since we only change newBucket if we can add to it\n+            MultiBucketsAggregation.Bucket newBucket = bucket;\n+\n+            int fromIndex = clamp(index - window + shift, values.size());\n+            int toIndex = clamp(index + shift, values.size());\n+            for (int i = fromIndex; i < toIndex; i++) {\n+                DoubleHistogram bucketState = values.get(i);\n+                if (bucketState != null) {\n+                    if (state == null) {\n+                        // We have to create a new HDR histogram because otherwise it will alter the\n+                        // existing histogram and bucket value\n+                        state = new DoubleHistogram(bucketState.getNumberOfSignificantValueDigits());\n+                    }\n+                    state.add(bucketState);\n+\n+                }\n+            }\n+\n+            if (state != null) {\n+                List<InternalAggregation> aggs = bucket.getAggregations().asList().stream()\n+                    .map((p) -> (InternalAggregation) p)\n+                    .collect(Collectors.toList());\n+                aggs.add(new InternalHDRPercentiles(name(), config.keys, state, config.keyed, config.formatter, metadata()));\n+                newBucket = factory.createBucket(factory.getKey(bucket), bucket.getDocCount(), new InternalAggregations(aggs));\n+            }\n+            newBuckets.add(newBucket);\n+            index++;\n+        }\n+    }\n+\n+    private PercentileConfig resolvePercentileConfig(MultiBucketsAggregation agg,\n+                                                 InternalMultiBucketAggregation.InternalBucket bucket,\n+                                                 String aggPath) {\n+        List<String> aggPathsList = AggregationPath.parse(aggPath).getPathElementsAsStringList();\n+        Object propertyValue = bucket.getProperty(agg.getName(), aggPathsList);\n+        if (propertyValue == null) {\n+            throw buildResolveError(agg, aggPathsList, propertyValue, \"percentiles\");\n+        }\n+\n+        if (propertyValue instanceof InternalTDigestPercentiles) {\n+            InternalTDigestPercentiles internalTDigestPercentiles = ((InternalTDigestPercentiles) propertyValue);\n+            return new PercentileConfig(PercentilesMethod.TDIGEST,\n+                                        internalTDigestPercentiles.getKeys(),\n+                                        internalTDigestPercentiles.keyed(),\n+                                        internalTDigestPercentiles.formatter());\n+        }\n+        if (propertyValue instanceof InternalHDRPercentiles) {\n+            InternalHDRPercentiles internalHDRPercentiles = ((InternalHDRPercentiles) propertyValue);\n+            return new PercentileConfig(PercentilesMethod.HDR,\n+                                        internalHDRPercentiles.getKeys(),\n+                                        internalHDRPercentiles.keyed(),\n+                                        internalHDRPercentiles.formatter());\n+        }\n+        throw buildResolveError(agg, aggPathsList, propertyValue, \"percentiles\");\n+    }\n+\n+    private TDigestState resolveTDigestBucketValue(MultiBucketsAggregation agg,\n+                                                   InternalMultiBucketAggregation.InternalBucket bucket,\n+                                                   String aggPath) {\n+        List<String> aggPathsList = AggregationPath.parse(aggPath).getPathElementsAsStringList();\n+        Object propertyValue = bucket.getProperty(agg.getName(), aggPathsList);\n+        if (propertyValue == null || (propertyValue instanceof InternalTDigestPercentiles) == false) {\n+            throw buildResolveError(agg, aggPathsList, propertyValue, \"TDigest\");\n+        }\n+        return ((InternalTDigestPercentiles) propertyValue).getState();\n+    }\n+\n+    private DoubleHistogram resolveHDRBucketValue(MultiBucketsAggregation agg,\n+                                                  InternalMultiBucketAggregation.InternalBucket bucket,\n+                                                  String aggPath) {\n+        List<String> aggPathsList = AggregationPath.parse(aggPath).getPathElementsAsStringList();\n+        Object propertyValue = bucket.getProperty(agg.getName(), aggPathsList);\n+        if (propertyValue == null || (propertyValue instanceof InternalHDRPercentiles) == false) {\n+            throw buildResolveError(agg, aggPathsList, propertyValue, \"HDR\");\n+        }\n+        return ((InternalHDRPercentiles) propertyValue).getState();\n+    }\n+\n+    private IllegalArgumentException buildResolveError(MultiBucketsAggregation agg, List<String> aggPathsList,\n+                                                       Object propertyValue, String method) {\n+        if (propertyValue == null) {\n+            return new IllegalArgumentException(AbstractPipelineAggregationBuilder.BUCKETS_PATH_FIELD.getPreferredName()\n+                + \" must reference a \" + method + \" percentile aggregation\");\n+        } else {\n+            String currentAggName;\n+            if (aggPathsList.isEmpty()) {\n+                currentAggName = agg.getName();\n+            } else {\n+                currentAggName = aggPathsList.get(0);\n+            }\n+            return new IllegalArgumentException(AbstractPipelineAggregationBuilder.BUCKETS_PATH_FIELD.getPreferredName()\n+                + \" must reference a \" + method + \" percentiles aggregation, got: [\"\n+                + propertyValue.getClass().getSimpleName() + \"] at aggregation [\" + currentAggName + \"]\");\n+        }\n+    }\n+\n+    private int clamp(int index, int length) {\n+        if (index < 0) {\n+            return 0;\n+        }\n+        if (index > length) {\n+            return length;\n+        }\n+        return index;\n+    }\n+\n+    // TODO: replace this with the PercentilesConfig that's used by the percentiles builder.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "099d62101d1960a9e199e864feb958fb0a3fc5d8"}, "originalPosition": 238}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "17fdd0285cc7f50f0daade89d3d1049f0e28a0d4", "author": {"user": {"login": "iverase", "name": "Ignacio Vera"}}, "url": "https://github.com/elastic/elasticsearch/commit/17fdd0285cc7f50f0daade89d3d1049f0e28a0d4", "committedDate": "2020-04-29T08:27:28Z", "message": "Added some java docs for public methods"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6537358fb954a9f502b6d99b07442147838d6d53", "author": {"user": {"login": "iverase", "name": "Ignacio Vera"}}, "url": "https://github.com/elastic/elasticsearch/commit/6537358fb954a9f502b6d99b07442147838d6d53", "committedDate": "2020-04-29T08:27:54Z", "message": "Merge branch 'master' into movingPercentiles"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA5MjMzMTMy", "url": "https://github.com/elastic/elasticsearch/pull/55441#pullrequestreview-409233132", "createdAt": "2020-05-11T14:36:10Z", "commit": {"oid": "6537358fb954a9f502b6d99b07442147838d6d53"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 700, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}