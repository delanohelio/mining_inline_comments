{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY2MTAzNDAz", "number": 51338, "title": "Limit max concurrency of test cluster nodes to a function of max workers", "bodyText": "We periodically run into issues with resource contention in highly parallelized builds. This is mostly due to the resource cost of running external Elasticsearch cluster nodes during integration test execution. Some integration test suites are more costly in this regard than others, such as some of our upgrade and mixed cluster tests which spin up multiple nodes for a single test suite. Gradle task execution currently doesn't take this into account when scheduling tasks. So we could in theory be running several integration suites, each which requires multiple nodes, a total of which far exceeds the total number of CPUs. This causes a lot of variability in test execution times, and inevitably, timeouts. For local development this makes running parallel builds difficult as it can bring the system to a halt, making it unusable during the build.\nThis pull request registers a throttle which limits the total number of concurrently running test cluster nodes to max-workers / 2. This is probably a reasonable default since for any given external integration test we have at least two JVMs in play, that of the test executor, and then the external cluster node itself.\nSome other misc refactoring was done with TestClustersPlugin here as well, such as leveraging the new BuildService pattern in Gradle 6.1 for the TestClustersRegistry as well as using a root project plugin for an idempotent way of registering task execution hooks.", "createdAt": "2020-01-22T22:55:51Z", "url": "https://github.com/elastic/elasticsearch/pull/51338", "merged": true, "mergeCommit": {"oid": "9a0238c7166e70e467ca61c1353157979fd1598b"}, "closed": true, "closedAt": "2020-01-23T23:20:18Z", "author": {"login": "mark-vieira"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb893aPgH2gAyMzY2MTAzNDAzOmE0ZWUxNzhhZTczZDc0NjhkNmUwZjRiZDVkZDcyNmM5YTZjYzE5NGM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABb9PrIoAFqTM0NzU1ODIxMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "a4ee178ae73d7468d6e0f4bd5dd726c9a6cc194c", "author": {"user": {"login": "mark-vieira", "name": "Mark Vieira"}}, "url": "https://github.com/elastic/elasticsearch/commit/a4ee178ae73d7468d6e0f4bd5dd726c9a6cc194c", "committedDate": "2020-01-22T22:55:07Z", "message": "Limit max concurrency of test cluster nodes to a function of max workers\n\nSigned-off-by: Mark Vieira <portugee@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "80f33ff08883f7d8f69e270bb3004498afefe40e", "author": {"user": {"login": "mark-vieira", "name": "Mark Vieira"}}, "url": "https://github.com/elastic/elasticsearch/commit/80f33ff08883f7d8f69e270bb3004498afefe40e", "committedDate": "2020-01-22T23:05:23Z", "message": "Fix some generic type checking error\n\nSigned-off-by: Mark Vieira <portugee@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "38c8f3eff998e76daab9da45d99b28440bf56169", "author": {"user": {"login": "mark-vieira", "name": "Mark Vieira"}}, "url": "https://github.com/elastic/elasticsearch/commit/38c8f3eff998e76daab9da45d99b28440bf56169", "committedDate": "2020-01-22T23:22:26Z", "message": "Suppress unchecked cast warning\n\nSigned-off-by: Mark Vieira <portugee@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "96916aeafcc5cbc8b102e31c0baf139fb85f9989", "author": {"user": {"login": "mark-vieira", "name": "Mark Vieira"}}, "url": "https://github.com/elastic/elasticsearch/commit/96916aeafcc5cbc8b102e31c0baf139fb85f9989", "committedDate": "2020-01-22T23:27:06Z", "message": "Simplify\n\nSigned-off-by: Mark Vieira <portugee@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8d60aaa2a66cdd6e9c92231cfaa76fbf0358015a", "author": {"user": {"login": "mark-vieira", "name": "Mark Vieira"}}, "url": "https://github.com/elastic/elasticsearch/commit/8d60aaa2a66cdd6e9c92231cfaa76fbf0358015a", "committedDate": "2020-01-22T23:37:43Z", "message": "Fix checkstyle violations\n\nSigned-off-by: Mark Vieira <portugee@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ3MTAyNjkw", "url": "https://github.com/elastic/elasticsearch/pull/51338#pullrequestreview-347102690", "createdAt": "2020-01-23T07:39:30Z", "commit": {"oid": "8d60aaa2a66cdd6e9c92231cfaa76fbf0358015a"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QwNzo0NzoxMFrOFg1Hvg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QwODoxMjo0NlrOFg1neg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTk2OTA4Ng==", "bodyText": "It doesn't have many usages, but we should consider DefaultTestClustersTask too in the same way.", "url": "https://github.com/elastic/elasticsearch/pull/51338#discussion_r369969086", "createdAt": "2020-01-23T07:47:10Z", "author": {"login": "alpar-t"}, "path": "buildSrc/src/main/java/org/elasticsearch/gradle/testclusters/RestTestRunnerTask.java", "diffHunk": "@@ -47,4 +57,19 @@ public int getMaxParallelForks() {\n         return clusters;\n     }\n \n+    @Override\n+    @Internal\n+    public List<ResourceLock> getSharedResources() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8d60aaa2a66cdd6e9c92231cfaa76fbf0358015a"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTk2OTUzMQ==", "bodyText": "Maybe this is just me, but this threw me off at first, maybe this would be more straight forward:\n.map(cluster.getNodes().size()).sum()", "url": "https://github.com/elastic/elasticsearch/pull/51338#discussion_r369969531", "createdAt": "2020-01-23T07:48:39Z", "author": {"login": "alpar-t"}, "path": "buildSrc/src/main/java/org/elasticsearch/gradle/testclusters/RestTestRunnerTask.java", "diffHunk": "@@ -47,4 +57,19 @@ public int getMaxParallelForks() {\n         return clusters;\n     }\n \n+    @Override\n+    @Internal\n+    public List<ResourceLock> getSharedResources() {\n+        List<ResourceLock> locks = new ArrayList<>(super.getSharedResources());\n+        BuildServiceRegistryInternal serviceRegistry = getServices().get(BuildServiceRegistryInternal.class);\n+        Provider<TestClustersThrottle> throttleProvider = Boilerplate.getBuildService(serviceRegistry, THROTTLE_SERVICE_NAME);\n+        SharedResource resource = serviceRegistry.forService(throttleProvider);\n+\n+        int nodeCount = (int) clusters.stream().flatMap(cluster -> cluster.getNodes().stream()).count();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8d60aaa2a66cdd6e9c92231cfaa76fbf0358015a"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTk3NzIxMA==", "bodyText": "I think we set this to half the physical cores in CI, so it may end up lower than it should.\nLooking at some CPU usage graphs will make it  obvious that we are under utilizing.\nUnaffected build times are a good sign trough.\nSince we can't set number of workers in a dynamic way, I think we should keep this code as is\nand stop setting max workers explicitly, I would expect that to work well both for CI and local runs without explicit configuration and with parallel turned on by default.\nOne caveat for running locally is that we would need to add a memory check\nand error out if there isn't enough.  I have 12 threads and 32GB of ram, and can't run a --parallel check without lowering workers. I think we need ~ 3GB for the daemon and ~ an additional 4GB for each worker. The number are based on observations, and the changes in the PR should make them better.\nIn theory, worst case, each worker could be running a test  and half as many nodes may be running, each consuming tests.heap.size (512MB) by default memory so one needs at lest daemon memory + 3/4 * nr of workers GB of memory just to run this. Without taking the OS and OS caches into account.\nIf we consider that ES recommends leaving half as much memory to OS caches, it would  work out  to\ndaemon memory + number of workers GB.  We may want to add some margin there, like 16 GB for other stuff running on the machine, that won't hurt CI since we have plenty of memory there.\nOn a 12 thread CPU, that works out to 12GB or 15 GB RAM free, so in theory I should be able to run ./graldew --parallel check without setting the number of workers with this change, given that after running browsers and developer tools I still have  18GB free.\nThe check may be conditioned on the task graph being big enough so we don't annoy the people to add configuration if they are just looking to run a single test ?\nOr maybe that's all just over-complicating it ?", "url": "https://github.com/elastic/elasticsearch/pull/51338#discussion_r369977210", "createdAt": "2020-01-23T08:12:46Z", "author": {"login": "alpar-t"}, "path": "buildSrc/src/main/java/org/elasticsearch/gradle/testclusters/TestClustersPlugin.java", "diffHunk": "@@ -30,53 +31,50 @@\n import org.gradle.api.invocation.Gradle;\n import org.gradle.api.logging.Logger;\n import org.gradle.api.logging.Logging;\n+import org.gradle.api.provider.Provider;\n import org.gradle.api.tasks.TaskState;\n \n import java.io.File;\n \n public class TestClustersPlugin implements Plugin<Project> {\n \n-    private static final String LIST_TASK_NAME = \"listTestClusters\";\n     public static final String EXTENSION_NAME = \"testClusters\";\n-    private static final String REGISTRY_EXTENSION_NAME = \"testClustersRegistry\";\n+    public static final String THROTTLE_SERVICE_NAME = \"testClustersThrottle\";\n \n+    private static final String LIST_TASK_NAME = \"listTestClusters\";\n+    private static final String REGISTRY_SERVICE_NAME = \"testClustersRegistry\";\n     private static final Logger logger = Logging.getLogger(TestClustersPlugin.class);\n \n-    private ReaperService reaper;\n-\n     @Override\n     public void apply(Project project) {\n         project.getPlugins().apply(DistributionDownloadPlugin.class);\n-\n         project.getRootProject().getPluginManager().apply(ReaperPlugin.class);\n-        reaper = project.getRootProject().getExtensions().getByType(ReaperService.class);\n+\n+        ReaperService reaper = project.getRootProject().getExtensions().getByType(ReaperService.class);\n \n         // enable the DSL to describe clusters\n-        NamedDomainObjectContainer<ElasticsearchCluster> container = createTestClustersContainerExtension(project);\n+        NamedDomainObjectContainer<ElasticsearchCluster> container = createTestClustersContainerExtension(project, reaper);\n \n         // provide a task to be able to list defined clusters.\n         createListClustersTask(project, container);\n \n-        if (project.getRootProject().getExtensions().findByName(REGISTRY_EXTENSION_NAME) == null) {\n-            TestClustersRegistry registry = project.getRootProject()\n-                .getExtensions()\n-                .create(REGISTRY_EXTENSION_NAME, TestClustersRegistry.class);\n-\n-            // When we know what tasks will run, we claim the clusters of those task to differentiate between clusters\n-            // that are defined in the build script and the ones that will actually be used in this invocation of gradle\n-            // we use this information to determine when the last task that required the cluster executed so that we can\n-            // terminate the cluster right away and free up resources.\n-            configureClaimClustersHook(project.getGradle(), registry);\n+        // register cluster registry as a global build service\n+        project.getGradle().getSharedServices().registerIfAbsent(REGISTRY_SERVICE_NAME, TestClustersRegistry.class, spec -> {});\n \n-            // Before each task, we determine if a cluster needs to be started for that task.\n-            configureStartClustersHook(project.getGradle(), registry);\n+        // register throttle so we only run at most max-workers/2 nodes concurrently\n+        project.getGradle()\n+            .getSharedServices()\n+            .registerIfAbsent(\n+                THROTTLE_SERVICE_NAME,\n+                TestClustersThrottle.class,\n+                spec -> spec.getMaxParallelUsages().set(project.getGradle().getStartParameter().getMaxWorkerCount() / 2)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8d60aaa2a66cdd6e9c92231cfaa76fbf0358015a"}, "originalPosition": 67}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "adb2127da1169752f9fb6daf35d99f556a28c9d6", "author": {"user": {"login": "mark-vieira", "name": "Mark Vieira"}}, "url": "https://github.com/elastic/elasticsearch/commit/adb2127da1169752f9fb6daf35d99f556a28c9d6", "committedDate": "2020-01-23T17:16:25Z", "message": "Simplify expression\n\nSigned-off-by: Mark Vieira <portugee@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ3NTU4MjEx", "url": "https://github.com/elastic/elasticsearch/pull/51338#pullrequestreview-347558211", "createdAt": "2020-01-23T19:40:00Z", "commit": {"oid": "adb2127da1169752f9fb6daf35d99f556a28c9d6"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2877, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}