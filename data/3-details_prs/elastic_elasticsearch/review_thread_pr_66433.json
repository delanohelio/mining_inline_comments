{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQxMDI0NDUw", "number": 66433, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwOTozNjozNFrOFGGIZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxMjozNDoxMlrOFGK3Jg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxOTM2MjI4OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/action/admin/cluster/reroute/ClusterRerouteResponse.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwOTozNjozNVrOIG8LjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwOTozNjozNVrOIG8LjA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDE0ODM2NA==", "bodyText": "Just a revert of making this public yesterday now that it's not needed for tests any longer.", "url": "https://github.com/elastic/elasticsearch/pull/66433#discussion_r544148364", "createdAt": "2020-12-16T09:36:35Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/action/admin/cluster/reroute/ClusterRerouteResponse.java", "diffHunk": "@@ -44,7 +44,7 @@\n         explanations = RoutingExplanations.readFrom(in);\n     }\n \n-    public ClusterRerouteResponse(boolean acknowledged, ClusterState state, RoutingExplanations explanations) {\n+    ClusterRerouteResponse(boolean acknowledged, ClusterState state, RoutingExplanations explanations) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "52460d5840d036668d6d5bf6ffed3224f3e1f5d7"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyMDEzNzM0OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshotAllocator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxMjozNDoxMlrOIHDKIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxMzowMDoxMlrOIHEJug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDI2MjY5MQ==", "bodyText": "Can we add a test that we do not trigger any reads or reroutes when deciders say no?", "url": "https://github.com/elastic/elasticsearch/pull/66433#discussion_r544262691", "createdAt": "2020-12-16T12:34:12Z", "author": {"login": "henningandersen"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshotAllocator.java", "diffHunk": "@@ -151,20 +156,15 @@ private AllocateUnassignedDecision decideAllocation(RoutingAllocation allocation\n             return AllocateUnassignedDecision.no(UnassignedInfo.AllocationStatus.FETCHING_SHARD_DATA, null);\n         }\n \n-        final AsyncShardFetch.FetchResult<NodeCacheFilesMetadata> fetchedCacheData = fetchData(shardRouting, allocation);\n-        if (fetchedCacheData.hasData() == false) {\n-            return AllocateUnassignedDecision.no(UnassignedInfo.AllocationStatus.FETCHING_SHARD_DATA, null);\n-        }\n-\n         final boolean explain = allocation.debugDecision();\n-        final MatchingNodes matchingNodes = findMatchingNodes(shardRouting, allocation, fetchedCacheData, explain);\n-        assert explain == false || matchingNodes.nodeDecisions != null : \"in explain mode, we must have individual node decisions\";\n-\n         // pre-check if it can be allocated to any node that currently exists, so we won't list the cache sizes for it for nothing\n         // TODO: in the following logic, we do not account for existing cache size when handling disk space checks, should and can we\n         // reliably do this in a world of concurrent cache evictions or are we ok with the cache size just being a best effort hint\n         // here?\n-        Tuple<Decision, Map<String, NodeAllocationResult>> result = canBeAllocatedToAtLeastOneNode(shardRouting, allocation);\n+        Tuple<Decision, Map<String, NodeAllocationResult>> result = ReplicaShardAllocator.canBeAllocatedToAtLeastOneNode(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "52460d5840d036668d6d5bf6ffed3224f3e1f5d7"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDI3ODk3MA==", "bodyText": "Sure thing, I pushed 0cb0017 :)", "url": "https://github.com/elastic/elasticsearch/pull/66433#discussion_r544278970", "createdAt": "2020-12-16T13:00:12Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshotAllocator.java", "diffHunk": "@@ -151,20 +156,15 @@ private AllocateUnassignedDecision decideAllocation(RoutingAllocation allocation\n             return AllocateUnassignedDecision.no(UnassignedInfo.AllocationStatus.FETCHING_SHARD_DATA, null);\n         }\n \n-        final AsyncShardFetch.FetchResult<NodeCacheFilesMetadata> fetchedCacheData = fetchData(shardRouting, allocation);\n-        if (fetchedCacheData.hasData() == false) {\n-            return AllocateUnassignedDecision.no(UnassignedInfo.AllocationStatus.FETCHING_SHARD_DATA, null);\n-        }\n-\n         final boolean explain = allocation.debugDecision();\n-        final MatchingNodes matchingNodes = findMatchingNodes(shardRouting, allocation, fetchedCacheData, explain);\n-        assert explain == false || matchingNodes.nodeDecisions != null : \"in explain mode, we must have individual node decisions\";\n-\n         // pre-check if it can be allocated to any node that currently exists, so we won't list the cache sizes for it for nothing\n         // TODO: in the following logic, we do not account for existing cache size when handling disk space checks, should and can we\n         // reliably do this in a world of concurrent cache evictions or are we ok with the cache size just being a best effort hint\n         // here?\n-        Tuple<Decision, Map<String, NodeAllocationResult>> result = canBeAllocatedToAtLeastOneNode(shardRouting, allocation);\n+        Tuple<Decision, Map<String, NodeAllocationResult>> result = ReplicaShardAllocator.canBeAllocatedToAtLeastOneNode(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDI2MjY5MQ=="}, "originalCommit": {"oid": "52460d5840d036668d6d5bf6ffed3224f3e1f5d7"}, "originalPosition": 77}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4513, "cost": 1, "resetAt": "2021-11-12T19:05:54Z"}}}