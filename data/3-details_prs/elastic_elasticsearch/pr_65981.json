{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTMzOTM3Nzc2", "number": 65981, "title": "Remove BigArrays from SearchContext", "bodyText": "We've been trying to shrink the big, mutable SearchContext. I'm doing\nmy part by removing BigArrays from it. Doing that required reworking\nhow we test Aggregators to not need SearchContext. So I did that\ntoo. Mostly. top_hits still needs a SubSearchContext which we can\nstill build, but it is now quite contained.", "createdAt": "2020-12-07T20:45:25Z", "url": "https://github.com/elastic/elasticsearch/pull/65981", "merged": true, "mergeCommit": {"oid": "3e45318d87958118be7688f316234b1afb28765b"}, "closed": true, "closedAt": "2020-12-08T15:22:35Z", "author": {"login": "nik9000"}, "timelineItems": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdj71jugH2gAyNTMzOTM3Nzc2OmUyOTI5MGIxNGE4ZWZhYzhhOWVhOTA2NmYwNTc1MjQwOTA1ZjYwM2Y=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdkLr00AFqTU0NzMzMjI5Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "e29290b14a8efac8a9ea9066f0575240905f603f", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/e29290b14a8efac8a9ea9066f0575240905f603f", "committedDate": "2020-12-07T20:47:29Z", "message": "Remove BigArrays from SearchContext\n\nWe've been trying to shrink the big, mutable `SearchContext`. I'm doing\nmy part by removing `BigArrays` from it. Doing that required reworking\nhow we test `Aggregator`s to not need `SearchContext`. So I did that\ntoo. Mostly. `top_hits` still needs a `SubSearchContext` which we can\nstill build, but it is now quite contained."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ2NTIxODY0", "url": "https://github.com/elastic/elasticsearch/pull/65981#pullrequestreview-546521864", "createdAt": "2020-12-07T20:46:06Z", "commit": {"oid": "e29290b14a8efac8a9ea9066f0575240905f603f"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QyMDo0NjowNlrOIA58vQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QyMDo1MTowNVrOIA6IiQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzgyMDM0OQ==", "bodyText": "clusterService was unused so I removed it while I was clearing bigArrays.", "url": "https://github.com/elastic/elasticsearch/pull/65981#discussion_r537820349", "createdAt": "2020-12-07T20:46:06Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/search/SearchService.java", "diffHunk": "@@ -768,8 +768,8 @@ private DefaultSearchContext createSearchContext(ReaderContext reader, ShardSear\n         try {\n             SearchShardTarget shardTarget = new SearchShardTarget(clusterService.localNode().getId(),\n                 reader.indexShard().shardId(), request.getClusterAlias(), OriginalIndices.NONE);\n-            searchContext = new DefaultSearchContext(reader, request, shardTarget, clusterService,\n-                bigArrays, threadPool::relativeTimeInMillis, timeout, fetchPhase, lowLevelCancellation);\n+            searchContext = new DefaultSearchContext(reader, request, shardTarget,\n+                threadPool::relativeTimeInMillis, timeout, fetchPhase, lowLevelCancellation);\n             // we clone the query shard context here just for rewriting otherwise we", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e29290b14a8efac8a9ea9066f0575240905f603f"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzgyMDQ3MA==", "bodyText": "This didn't do anything....", "url": "https://github.com/elastic/elasticsearch/pull/65981#discussion_r537820470", "createdAt": "2020-12-07T20:46:19Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/TermsAggregationBuilder.java", "diffHunk": "@@ -401,11 +400,6 @@ public String getType() {\n         return NAME;\n     }\n \n-    @Override\n-    protected AggregationBuilder doRewrite(QueryRewriteContext queryShardContext) throws IOException {\n-        return super.doRewrite(queryShardContext);\n-    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e29290b14a8efac8a9ea9066f0575240905f603f"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzgyMDgwMA==", "bodyText": "These are required by tests. I could avoid adding it with some terrible casting stuff in tests but I think it is better to be up front about it.", "url": "https://github.com/elastic/elasticsearch/pull/65981#discussion_r537820800", "createdAt": "2020-12-07T20:46:49Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/search/aggregations/support/AggregationContext.java", "diffHunk": "@@ -230,6 +230,12 @@ public final AggregationUsageService getUsageService() {\n      */\n     public abstract Analyzer getIndexAnalyzer(Function<String, NamedAnalyzer> unindexedFieldAnalyzer);\n \n+    /**\n+     * Is this request cacheable? Requests that have\n+     * non-deterministic queries or scripts aren't cachable.\n+     */\n+    public abstract boolean isCacheable();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e29290b14a8efac8a9ea9066f0575240905f603f"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzgyMTQ0NQ==", "bodyText": "Had to move with withCircuitBreaking from SearchContext.", "url": "https://github.com/elastic/elasticsearch/pull/65981#discussion_r537821445", "createdAt": "2020-12-07T20:47:48Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/search/aggregations/support/AggregationContext.java", "diffHunk": "@@ -277,6 +284,7 @@ public ProductionAggregationContext(\n             Supplier<Boolean> isCancelled\n         ) {\n             this.context = context;\n+            this.bigArrays = context.bigArrays().withCircuitBreaking();  // We can break in searches.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e29290b14a8efac8a9ea9066f0575240905f603f"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzgyMjA1MQ==", "bodyText": "I'd love to use a specialized testing subclass but this change is large enough as it is without me changing it.", "url": "https://github.com/elastic/elasticsearch/pull/65981#discussion_r537822051", "createdAt": "2020-12-07T20:48:48Z", "author": {"login": "nik9000"}, "path": "test/framework/src/main/java/org/elasticsearch/search/aggregations/AggregatorTestCase.java", "diffHunk": "@@ -297,25 +291,64 @@ public boolean shouldCache(Query query) {\n             return null;\n         });\n \n-        NestedDocuments nestedDocuments = new NestedDocuments(mapperService, searchContext.bitsetFilterCache()::getBitSetProducer);\n-        when(searchContext.getNestedDocuments())\n-            .thenReturn(nestedDocuments);\n+        MultiBucketConsumer consumer = new MultiBucketConsumer(maxBucket, breakerService.getBreaker(CircuitBreaker.REQUEST));\n+        BitsetFilterCache bitsetFilterCache = new BitsetFilterCache(indexSettings, mock(Listener.class));\n+        return new ProductionAggregationContext(\n+            queryShardContext,\n+            query,\n+            null,\n+            consumer,\n+            () -> buildSubSearchContext(mapperService, queryShardContext, bitsetFilterCache),\n+            releasables::add,\n+            bitsetFilterCache,\n+            randomInt(),\n+            () -> 0L,\n+            () -> false\n+        );", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e29290b14a8efac8a9ea9066f0575240905f603f"}, "originalPosition": 217}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzgyMzM2OQ==", "bodyText": "Now all of this is contained to only be called for top_hits.", "url": "https://github.com/elastic/elasticsearch/pull/65981#discussion_r537823369", "createdAt": "2020-12-07T20:51:05Z", "author": {"login": "nik9000"}, "path": "test/framework/src/main/java/org/elasticsearch/search/aggregations/AggregatorTestCase.java", "diffHunk": "@@ -297,25 +291,64 @@ public boolean shouldCache(Query query) {\n             return null;\n         });\n \n-        NestedDocuments nestedDocuments = new NestedDocuments(mapperService, searchContext.bitsetFilterCache()::getBitSetProducer);\n-        when(searchContext.getNestedDocuments())\n-            .thenReturn(nestedDocuments);\n+        MultiBucketConsumer consumer = new MultiBucketConsumer(maxBucket, breakerService.getBreaker(CircuitBreaker.REQUEST));\n+        BitsetFilterCache bitsetFilterCache = new BitsetFilterCache(indexSettings, mock(Listener.class));\n+        return new ProductionAggregationContext(\n+            queryShardContext,\n+            query,\n+            null,\n+            consumer,\n+            () -> buildSubSearchContext(mapperService, queryShardContext, bitsetFilterCache),\n+            releasables::add,\n+            bitsetFilterCache,\n+            randomInt(),\n+            () -> 0L,\n+            () -> false\n+        );\n+    }\n \n-        Map<String, MappedFieldType> fieldNameToType = new HashMap<>();\n-        fieldNameToType.putAll(Arrays.stream(fieldTypes)\n-            .filter(Objects::nonNull)\n-            .collect(Collectors.toMap(MappedFieldType::name, Function.identity())));\n-        fieldNameToType.putAll(getFieldAliases(fieldTypes));\n+    /**\n+     * Build a {@link SubSearchContext}s to power {@code top_hits}.\n+     */\n+    private SubSearchContext buildSubSearchContext(\n+        MapperService mapperService,\n+        QueryShardContext queryShardContext,\n+        BitsetFilterCache bitsetFilterCache\n+    ) {\n+        SearchContext ctx = mock(SearchContext.class);\n+        QueryCache queryCache = new DisabledQueryCache(mapperService.getIndexSettings());\n+        QueryCachingPolicy queryCachingPolicy = new QueryCachingPolicy() {\n+            @Override\n+            public void onUse(Query query) {\n+            }\n \n-        registerFieldTypes(searchContext, mapperService,\n-            fieldNameToType);\n-        doAnswer(invocation -> {\n-            /* Store the release-ables so we can release them at the end of the test case. This is important because aggregations don't\n-             * close their sub-aggregations. This is fairly similar to what the production code does. */\n-            releasables.add((Releasable) invocation.getArguments()[0]);\n-            return null;\n-        }).when(searchContext).addReleasable(anyObject());\n-        return searchContext;\n+            @Override\n+            public boolean shouldCache(Query query) {\n+                // never cache a query\n+                return false;\n+            }\n+        };\n+        try {\n+            when(ctx.searcher()).thenReturn(\n+                new ContextIndexSearcher(\n+                    queryShardContext.searcher().getIndexReader(),\n+                    queryShardContext.searcher().getSimilarity(),\n+                    queryCache,\n+                    queryCachingPolicy,\n+                    false\n+                )\n+            );\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+        when(ctx.fetchPhase()).thenReturn(new FetchPhase(Arrays.asList(new FetchSourcePhase(), new FetchDocValuesPhase())));\n+        when(ctx.getQueryShardContext()).thenReturn(queryShardContext);\n+        NestedDocuments nestedDocuments = new NestedDocuments(mapperService, bitsetFilterCache::getBitSetProducer);\n+        when(ctx.getNestedDocuments()).thenReturn(nestedDocuments);\n+        IndexShard indexShard = mock(IndexShard.class);\n+        when(indexShard.shardId()).thenReturn(new ShardId(\"test\", \"test\", 0));\n+        when(ctx.indexShard()).thenReturn(indexShard);\n+        return new SubSearchContext(ctx);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e29290b14a8efac8a9ea9066f0575240905f603f"}, "originalPosition": 275}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "68af24f6f129a9c121ada8f4250d8afdcdeff6a0", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/68af24f6f129a9c121ada8f4250d8afdcdeff6a0", "committedDate": "2020-12-07T20:53:06Z", "message": "Move mocking"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "152e014f8ed7d3cfad35778a2644b6c3dc04a87f", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/152e014f8ed7d3cfad35778a2644b6c3dc04a87f", "committedDate": "2020-12-07T21:13:34Z", "message": "Oh checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9ed67c6e11d24a057adb044a491a37f1dd1c0c6b", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/9ed67c6e11d24a057adb044a491a37f1dd1c0c6b", "committedDate": "2020-12-08T13:41:05Z", "message": "Fixup test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ3MzMyMjky", "url": "https://github.com/elastic/elasticsearch/pull/65981#pullrequestreview-547332292", "createdAt": "2020-12-08T15:15:20Z", "commit": {"oid": "9ed67c6e11d24a057adb044a491a37f1dd1c0c6b"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4089, "cost": 1, "resetAt": "2021-10-28T19:08:13Z"}}}