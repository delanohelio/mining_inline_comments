{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ3NjY4NDEz", "number": 59366, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMlQxOToyODoyNVrOENoEjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNjozMToxNFrOEPmXmQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgyNzIzNDY5OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/BucketsAggregator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMlQxOToyODoyNVrOGwWiPw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMlQxOToyODoyNVrOGwWiPw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzM1NDA0Nw==", "bodyText": "I think you could write this:\nmergeBuckets(newNumbBuckets, buck -> mergeMap[Math.toIntExact(bucket)]);", "url": "https://github.com/elastic/elasticsearch/pull/59366#discussion_r453354047", "createdAt": "2020-07-12T19:28:25Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/BucketsAggregator.java", "diffHunk": "@@ -107,15 +108,33 @@ public final void collectExistingBucket(LeafBucketCollector subCollector, int do\n      * Refer to that method for documentation about the merge map.\n      */\n     public final void mergeBuckets(long[] mergeMap, long newNumBuckets) {\n+        UnaryOperator<Long> mergeMapOperator = new UnaryOperator<Long>() {\n+            @Override\n+            public Long apply(Long bucket) {\n+                return mergeMap[Math.toIntExact(bucket)];\n+            }\n+        };\n+\n+        mergeBuckets(mergeMapOperator, newNumBuckets);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c706833645f769e8a432708c37d24a96717b5a3"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgyNzIzNjY4OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/BucketsAggregator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMlQxOTozMDo1MFrOGwWjMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMlQxOTozMDo1MFrOGwWjMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzM1NDI4OA==", "bodyText": "Two things, only one is important though:\n\nCould you replace UnaryOperator<Long> with LongUnaryOperator? That'll prevent auto-boxing of the parameter.\nCould you switch the order of the arguments? I think the call sites are a little prettier when the \"function\" argument is last, if possible.", "url": "https://github.com/elastic/elasticsearch/pull/59366#discussion_r453354288", "createdAt": "2020-07-12T19:30:50Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/BucketsAggregator.java", "diffHunk": "@@ -107,15 +108,33 @@ public final void collectExistingBucket(LeafBucketCollector subCollector, int do\n      * Refer to that method for documentation about the merge map.\n      */\n     public final void mergeBuckets(long[] mergeMap, long newNumBuckets) {\n+        UnaryOperator<Long> mergeMapOperator = new UnaryOperator<Long>() {\n+            @Override\n+            public Long apply(Long bucket) {\n+                return mergeMap[Math.toIntExact(bucket)];\n+            }\n+        };\n+\n+        mergeBuckets(mergeMapOperator, newNumBuckets);\n+    }\n+\n+    /**\n+     * This only tidies up doc counts. Call {@link MergingBucketsDeferringCollector#mergeBuckets(UnaryOperator)} to\n+     * merge the actual ordinals and doc ID deltas.\n+     */\n+    public final void mergeBuckets(UnaryOperator<Long> mergeMap, long newNumBuckets){", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c706833645f769e8a432708c37d24a96717b5a3"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgyNzIzNjk0OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/BucketsAggregator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMlQxOTozMTowMlrOGwWjTw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMlQxOTozMTowMlrOGwWjTw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzM1NDMxOQ==", "bodyText": "Could you swap to long i?", "url": "https://github.com/elastic/elasticsearch/pull/59366#discussion_r453354319", "createdAt": "2020-07-12T19:31:02Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/BucketsAggregator.java", "diffHunk": "@@ -107,15 +108,33 @@ public final void collectExistingBucket(LeafBucketCollector subCollector, int do\n      * Refer to that method for documentation about the merge map.\n      */\n     public final void mergeBuckets(long[] mergeMap, long newNumBuckets) {\n+        UnaryOperator<Long> mergeMapOperator = new UnaryOperator<Long>() {\n+            @Override\n+            public Long apply(Long bucket) {\n+                return mergeMap[Math.toIntExact(bucket)];\n+            }\n+        };\n+\n+        mergeBuckets(mergeMapOperator, newNumBuckets);\n+    }\n+\n+    /**\n+     * This only tidies up doc counts. Call {@link MergingBucketsDeferringCollector#mergeBuckets(UnaryOperator)} to\n+     * merge the actual ordinals and doc ID deltas.\n+     */\n+    public final void mergeBuckets(UnaryOperator<Long> mergeMap, long newNumBuckets){\n         try (IntArray oldDocCounts = docCounts) {\n             docCounts = bigArrays.newIntArray(newNumBuckets, true);\n             docCounts.fill(0, newNumBuckets, 0);\n             for (int i = 0; i < oldDocCounts.size(); i++) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c706833645f769e8a432708c37d24a96717b5a3"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgyNzIzNzc5OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/BucketsAggregator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMlQxOTozMjoyNVrOGwWjuw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMlQxOTozMjoyNVrOGwWjuw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzM1NDQyNw==", "bodyText": "I think it is worth saying what the unary operator does here, that -1 means throw away and otherwise it is the destination index.", "url": "https://github.com/elastic/elasticsearch/pull/59366#discussion_r453354427", "createdAt": "2020-07-12T19:32:25Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/BucketsAggregator.java", "diffHunk": "@@ -107,15 +108,33 @@ public final void collectExistingBucket(LeafBucketCollector subCollector, int do\n      * Refer to that method for documentation about the merge map.\n      */\n     public final void mergeBuckets(long[] mergeMap, long newNumBuckets) {\n+        UnaryOperator<Long> mergeMapOperator = new UnaryOperator<Long>() {\n+            @Override\n+            public Long apply(Long bucket) {\n+                return mergeMap[Math.toIntExact(bucket)];\n+            }\n+        };\n+\n+        mergeBuckets(mergeMapOperator, newNumBuckets);\n+    }\n+\n+    /**\n+     * This only tidies up doc counts. Call {@link MergingBucketsDeferringCollector#mergeBuckets(UnaryOperator)} to", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c706833645f769e8a432708c37d24a96717b5a3"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgyNzI0MDg3OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/VariableWidthHistogramAggregator.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMlQxOTozNjoxM1rOGwWlQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwMDowMzowOVrOGzA1RQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzM1NDgxOA==", "bodyText": "I'd have tried to write this:\nmergeBuckets(numClusters, bucket -> {\n  if (i < index) {\n    // The clusters in range {0 ... idx - 1} don't move\n    return 1;\n  }\n  if (i == numClusters - 1) {\n    // The new cluster moves to index\n    return i;\n  }\n  // The clusters in range {index ... numClusters - 1} shift forward\n  return i = 1;\n});\n\nI like the \"inline function declaration\" form of this because it makes it super obvious that it doesn't escape.\nI also like early return instead of else if, but that is totally up to you. Its a matter of style and we don't have a standard.", "url": "https://github.com/elastic/elasticsearch/pull/59366#discussion_r453354818", "createdAt": "2020-07-12T19:36:13Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/VariableWidthHistogramAggregator.java", "diffHunk": "@@ -354,21 +355,22 @@ private void moveLastCluster(int index){\n                 clusterSizes.set(index, holdSize);\n \n                 // Move the underlying buckets\n-                long[] mergeMap = new long[numClusters];\n-                for (int i = 0; i < index; i++) {\n-                    // The clusters in range {0 ... idx - 1} don't move\n-                    mergeMap[i] = i;\n-                }\n-                for (int i = index; i < numClusters - 1; i++) {\n-                    // The clusters in range {index ... numClusters - 1} shift up\n-                    mergeMap[i] = i + 1;\n-                }\n-                // Finally, the new cluster moves to index\n-                mergeMap[numClusters - 1] = index;\n+                UnaryOperator<Long> mergeMap = new UnaryOperator<Long>() {\n+                    @Override\n+                    public Long apply(Long i) {\n+                       if(i < index) {\n+                           // The clusters in range {0 ... idx - 1} don't move\n+                           return i;\n+                       } else if(i == numClusters - 1) {\n+                           // The new cluster moves to index\n+                           return (long)index;\n+                       } else {\n+                           // The clusters in range {index ... numClusters - 1} shift forward\n+                           return i + 1;\n+                       }\n+                    }\n+                };", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c706833645f769e8a432708c37d24a96717b5a3"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTkzMDY2NA==", "bodyText": "I'm not sure if this would work, since this same function is used in the calls to bothBucketsAggregator::mergeBuckets and MergingBucketsDeferringCollector::mergeBuckets.", "url": "https://github.com/elastic/elasticsearch/pull/59366#discussion_r455930664", "createdAt": "2020-07-16T16:52:45Z", "author": {"login": "jamesdorfman"}, "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/VariableWidthHistogramAggregator.java", "diffHunk": "@@ -354,21 +355,22 @@ private void moveLastCluster(int index){\n                 clusterSizes.set(index, holdSize);\n \n                 // Move the underlying buckets\n-                long[] mergeMap = new long[numClusters];\n-                for (int i = 0; i < index; i++) {\n-                    // The clusters in range {0 ... idx - 1} don't move\n-                    mergeMap[i] = i;\n-                }\n-                for (int i = index; i < numClusters - 1; i++) {\n-                    // The clusters in range {index ... numClusters - 1} shift up\n-                    mergeMap[i] = i + 1;\n-                }\n-                // Finally, the new cluster moves to index\n-                mergeMap[numClusters - 1] = index;\n+                UnaryOperator<Long> mergeMap = new UnaryOperator<Long>() {\n+                    @Override\n+                    public Long apply(Long i) {\n+                       if(i < index) {\n+                           // The clusters in range {0 ... idx - 1} don't move\n+                           return i;\n+                       } else if(i == numClusters - 1) {\n+                           // The new cluster moves to index\n+                           return (long)index;\n+                       } else {\n+                           // The clusters in range {index ... numClusters - 1} shift forward\n+                           return i + 1;\n+                       }\n+                    }\n+                };", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzM1NDgxOA=="}, "originalCommit": {"oid": "4c706833645f769e8a432708c37d24a96717b5a3"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE0NDE5Nw==", "bodyText": "Ah! Well, what you have is just fine too.", "url": "https://github.com/elastic/elasticsearch/pull/59366#discussion_r456144197", "createdAt": "2020-07-17T00:03:09Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/VariableWidthHistogramAggregator.java", "diffHunk": "@@ -354,21 +355,22 @@ private void moveLastCluster(int index){\n                 clusterSizes.set(index, holdSize);\n \n                 // Move the underlying buckets\n-                long[] mergeMap = new long[numClusters];\n-                for (int i = 0; i < index; i++) {\n-                    // The clusters in range {0 ... idx - 1} don't move\n-                    mergeMap[i] = i;\n-                }\n-                for (int i = index; i < numClusters - 1; i++) {\n-                    // The clusters in range {index ... numClusters - 1} shift up\n-                    mergeMap[i] = i + 1;\n-                }\n-                // Finally, the new cluster moves to index\n-                mergeMap[numClusters - 1] = index;\n+                UnaryOperator<Long> mergeMap = new UnaryOperator<Long>() {\n+                    @Override\n+                    public Long apply(Long i) {\n+                       if(i < index) {\n+                           // The clusters in range {0 ... idx - 1} don't move\n+                           return i;\n+                       } else if(i == numClusters - 1) {\n+                           // The new cluster moves to index\n+                           return (long)index;\n+                       } else {\n+                           // The clusters in range {index ... numClusters - 1} shift forward\n+                           return i + 1;\n+                       }\n+                    }\n+                };", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzM1NDgxOA=="}, "originalCommit": {"oid": "4c706833645f769e8a432708c37d24a96717b5a3"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzMDUwMjI4OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/BucketsAggregator.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxODoyNzo1OVrOGw0mVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwMDowMjoxNFrOGzA0Rw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg0NjYxNA==", "bodyText": "Could you deprecate this method? I think all callers would be better off with the other method.", "url": "https://github.com/elastic/elasticsearch/pull/59366#discussion_r453846614", "createdAt": "2020-07-13T18:27:59Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/BucketsAggregator.java", "diffHunk": "@@ -107,15 +108,33 @@ public final void collectExistingBucket(LeafBucketCollector subCollector, int do\n      * Refer to that method for documentation about the merge map.\n      */\n     public final void mergeBuckets(long[] mergeMap, long newNumBuckets) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c706833645f769e8a432708c37d24a96717b5a3"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTkyOTY2NQ==", "bodyText": "Done! I just marked it as deprecated. Should I also update all other usages of this method?", "url": "https://github.com/elastic/elasticsearch/pull/59366#discussion_r455929665", "createdAt": "2020-07-16T16:51:07Z", "author": {"login": "jamesdorfman"}, "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/BucketsAggregator.java", "diffHunk": "@@ -107,15 +108,33 @@ public final void collectExistingBucket(LeafBucketCollector subCollector, int do\n      * Refer to that method for documentation about the merge map.\n      */\n     public final void mergeBuckets(long[] mergeMap, long newNumBuckets) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg0NjYxNA=="}, "originalCommit": {"oid": "4c706833645f769e8a432708c37d24a96717b5a3"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE0Mzk0Mw==", "bodyText": "Marking it as deprecated is plenty for this or!", "url": "https://github.com/elastic/elasticsearch/pull/59366#discussion_r456143943", "createdAt": "2020-07-17T00:02:14Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/BucketsAggregator.java", "diffHunk": "@@ -107,15 +108,33 @@ public final void collectExistingBucket(LeafBucketCollector subCollector, int do\n      * Refer to that method for documentation about the merge map.\n      */\n     public final void mergeBuckets(long[] mergeMap, long newNumBuckets) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg0NjYxNA=="}, "originalCommit": {"oid": "4c706833645f769e8a432708c37d24a96717b5a3"}, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NzkyNzI5OnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/search/aggregations/bucket/MergingBucketsDeferringCollectorTests.java", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNjozMToxNVrOGzZhGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxMjo0NjozNlrOG2I2vQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU0ODYzMg==", "bodyText": "I think it'd be a little cleaner to do this by wrapping the collector that you pass to indexSearcher.search and just us MatchAllDocsQuery instead.", "url": "https://github.com/elastic/elasticsearch/pull/59366#discussion_r456548632", "createdAt": "2020-07-17T16:31:15Z", "author": {"login": "nik9000"}, "path": "server/src/test/java/org/elasticsearch/search/aggregations/bucket/MergingBucketsDeferringCollectorTests.java", "diffHunk": "@@ -0,0 +1,269 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.elasticsearch.search.aggregations.bucket;\n+\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.apache.lucene.document.Document;\n+import org.apache.lucene.document.NumericDocValuesField;\n+import org.apache.lucene.index.DirectoryReader;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.IndexWriter;\n+import org.apache.lucene.index.IndexWriterConfig;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.BulkScorer;\n+import org.apache.lucene.search.ConstantScoreScorer;\n+import org.apache.lucene.search.ConstantScoreWeight;\n+import org.apache.lucene.search.DocIdSetIterator;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.LeafCollector;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.QueryVisitor;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.search.Scorer;\n+import org.apache.lucene.search.Weight;\n+import org.apache.lucene.store.Directory;\n+import org.apache.lucene.util.Bits;\n+import org.elasticsearch.search.aggregations.AggregatorTestCase;\n+import org.elasticsearch.search.aggregations.BucketCollector;\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.elasticsearch.search.aggregations.bucket.MergingBucketsDeferringCollector;\n+import org.elasticsearch.search.internal.SearchContext;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import static org.apache.lucene.util.LuceneTestCase.newDirectory;\n+import static org.mockito.Mockito.when;\n+\n+public class MergingBucketsDeferringCollectorTests extends AggregatorTestCase {\n+\n+    /**\n+     * Usually all documents get collected into ordinal 0 unless they are part of a sub aggregation\n+     * @return a query that collects the i'th document into bucket ordinal i\n+     */\n+    private Query getQueryToCollectIntoDifferentOrdinals() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71b1797e2bd827bad5bf30c91c8d994a57a3c62b"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjY1NTk4NQ==", "bodyText": "Fixed! I overrode one of the methods in MergingBucketsDeferringCollector and now it is a lot cleaner. Is this what you had in mind?\nI'm not sure if wrapping the bucket collector directly would work, since the deferring collector stores the bucket ordinal before it calls the bucket collector's collect method.", "url": "https://github.com/elastic/elasticsearch/pull/59366#discussion_r456655985", "createdAt": "2020-07-17T20:20:07Z", "author": {"login": "jamesdorfman"}, "path": "server/src/test/java/org/elasticsearch/search/aggregations/bucket/MergingBucketsDeferringCollectorTests.java", "diffHunk": "@@ -0,0 +1,269 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.elasticsearch.search.aggregations.bucket;\n+\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.apache.lucene.document.Document;\n+import org.apache.lucene.document.NumericDocValuesField;\n+import org.apache.lucene.index.DirectoryReader;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.IndexWriter;\n+import org.apache.lucene.index.IndexWriterConfig;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.BulkScorer;\n+import org.apache.lucene.search.ConstantScoreScorer;\n+import org.apache.lucene.search.ConstantScoreWeight;\n+import org.apache.lucene.search.DocIdSetIterator;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.LeafCollector;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.QueryVisitor;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.search.Scorer;\n+import org.apache.lucene.search.Weight;\n+import org.apache.lucene.store.Directory;\n+import org.apache.lucene.util.Bits;\n+import org.elasticsearch.search.aggregations.AggregatorTestCase;\n+import org.elasticsearch.search.aggregations.BucketCollector;\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.elasticsearch.search.aggregations.bucket.MergingBucketsDeferringCollector;\n+import org.elasticsearch.search.internal.SearchContext;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import static org.apache.lucene.util.LuceneTestCase.newDirectory;\n+import static org.mockito.Mockito.when;\n+\n+public class MergingBucketsDeferringCollectorTests extends AggregatorTestCase {\n+\n+    /**\n+     * Usually all documents get collected into ordinal 0 unless they are part of a sub aggregation\n+     * @return a query that collects the i'th document into bucket ordinal i\n+     */\n+    private Query getQueryToCollectIntoDifferentOrdinals() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU0ODYzMg=="}, "originalCommit": {"oid": "71b1797e2bd827bad5bf30c91c8d994a57a3c62b"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjY5MTE4Mw==", "bodyText": "That isn't quite what I was thinking. I think part of the problem is that I'm sort of stuck in a \"do it like aggs do\" mindset. In that mindset there are two collectors and the MergingBucketsDeferringCollector. One collector emulates the outer aggregator and calls to the MergingBucketsDeferringCollector's collect method, calling merge in some funny shape. And the other bucket emulates the inner aggregation and is just called by the aggregator.\nI've got half of a patch on my laptop that does this but I'm probably going to stop for the day. I'll try and post it this weekend.", "url": "https://github.com/elastic/elasticsearch/pull/59366#discussion_r456691183", "createdAt": "2020-07-17T21:57:32Z", "author": {"login": "nik9000"}, "path": "server/src/test/java/org/elasticsearch/search/aggregations/bucket/MergingBucketsDeferringCollectorTests.java", "diffHunk": "@@ -0,0 +1,269 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.elasticsearch.search.aggregations.bucket;\n+\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.apache.lucene.document.Document;\n+import org.apache.lucene.document.NumericDocValuesField;\n+import org.apache.lucene.index.DirectoryReader;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.IndexWriter;\n+import org.apache.lucene.index.IndexWriterConfig;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.BulkScorer;\n+import org.apache.lucene.search.ConstantScoreScorer;\n+import org.apache.lucene.search.ConstantScoreWeight;\n+import org.apache.lucene.search.DocIdSetIterator;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.LeafCollector;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.QueryVisitor;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.search.Scorer;\n+import org.apache.lucene.search.Weight;\n+import org.apache.lucene.store.Directory;\n+import org.apache.lucene.util.Bits;\n+import org.elasticsearch.search.aggregations.AggregatorTestCase;\n+import org.elasticsearch.search.aggregations.BucketCollector;\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.elasticsearch.search.aggregations.bucket.MergingBucketsDeferringCollector;\n+import org.elasticsearch.search.internal.SearchContext;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import static org.apache.lucene.util.LuceneTestCase.newDirectory;\n+import static org.mockito.Mockito.when;\n+\n+public class MergingBucketsDeferringCollectorTests extends AggregatorTestCase {\n+\n+    /**\n+     * Usually all documents get collected into ordinal 0 unless they are part of a sub aggregation\n+     * @return a query that collects the i'th document into bucket ordinal i\n+     */\n+    private Query getQueryToCollectIntoDifferentOrdinals() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU0ODYzMg=="}, "originalCommit": {"oid": "71b1797e2bd827bad5bf30c91c8d994a57a3c62b"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjgxNzg1Nw==", "bodyText": "I was thinking something like this. There is a collector that just counts and a collector the distributes bucket ords and merges. And the MergingBucketsDeferringCollector sits between them.\nTwo neat things:\n\nI think I found a bug! I don't think it actually comes up in production because you have to throw away buckets using the merge method while collecting buckets and I think we only do that in the rare_terms aggregators and they only merge after all the collections are done.\nMy test only really covers the variable-width histogram style of merging, not the rare_terms style. But I think that is pretty ok. Its is the harder style.", "url": "https://github.com/elastic/elasticsearch/pull/59366#discussion_r456817857", "createdAt": "2020-07-18T18:56:43Z", "author": {"login": "nik9000"}, "path": "server/src/test/java/org/elasticsearch/search/aggregations/bucket/MergingBucketsDeferringCollectorTests.java", "diffHunk": "@@ -0,0 +1,269 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.elasticsearch.search.aggregations.bucket;\n+\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.apache.lucene.document.Document;\n+import org.apache.lucene.document.NumericDocValuesField;\n+import org.apache.lucene.index.DirectoryReader;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.IndexWriter;\n+import org.apache.lucene.index.IndexWriterConfig;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.BulkScorer;\n+import org.apache.lucene.search.ConstantScoreScorer;\n+import org.apache.lucene.search.ConstantScoreWeight;\n+import org.apache.lucene.search.DocIdSetIterator;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.LeafCollector;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.QueryVisitor;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.search.Scorer;\n+import org.apache.lucene.search.Weight;\n+import org.apache.lucene.store.Directory;\n+import org.apache.lucene.util.Bits;\n+import org.elasticsearch.search.aggregations.AggregatorTestCase;\n+import org.elasticsearch.search.aggregations.BucketCollector;\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.elasticsearch.search.aggregations.bucket.MergingBucketsDeferringCollector;\n+import org.elasticsearch.search.internal.SearchContext;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import static org.apache.lucene.util.LuceneTestCase.newDirectory;\n+import static org.mockito.Mockito.when;\n+\n+public class MergingBucketsDeferringCollectorTests extends AggregatorTestCase {\n+\n+    /**\n+     * Usually all documents get collected into ordinal 0 unless they are part of a sub aggregation\n+     * @return a query that collects the i'th document into bucket ordinal i\n+     */\n+    private Query getQueryToCollectIntoDifferentOrdinals() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU0ODYzMg=="}, "originalCommit": {"oid": "71b1797e2bd827bad5bf30c91c8d994a57a3c62b"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk1ODAxNw==", "bodyText": "Sorry for my delayed response, I had a very hectic start of week!\nVery cool, that is definitely a lot cleaner, thanks for the patch! I've added it and filed a corresponding bug.\nThat's a strange bug by the way...", "url": "https://github.com/elastic/elasticsearch/pull/59366#discussion_r458958017", "createdAt": "2020-07-22T17:22:40Z", "author": {"login": "jamesdorfman"}, "path": "server/src/test/java/org/elasticsearch/search/aggregations/bucket/MergingBucketsDeferringCollectorTests.java", "diffHunk": "@@ -0,0 +1,269 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.elasticsearch.search.aggregations.bucket;\n+\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.apache.lucene.document.Document;\n+import org.apache.lucene.document.NumericDocValuesField;\n+import org.apache.lucene.index.DirectoryReader;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.IndexWriter;\n+import org.apache.lucene.index.IndexWriterConfig;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.BulkScorer;\n+import org.apache.lucene.search.ConstantScoreScorer;\n+import org.apache.lucene.search.ConstantScoreWeight;\n+import org.apache.lucene.search.DocIdSetIterator;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.LeafCollector;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.QueryVisitor;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.search.Scorer;\n+import org.apache.lucene.search.Weight;\n+import org.apache.lucene.store.Directory;\n+import org.apache.lucene.util.Bits;\n+import org.elasticsearch.search.aggregations.AggregatorTestCase;\n+import org.elasticsearch.search.aggregations.BucketCollector;\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.elasticsearch.search.aggregations.bucket.MergingBucketsDeferringCollector;\n+import org.elasticsearch.search.internal.SearchContext;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import static org.apache.lucene.util.LuceneTestCase.newDirectory;\n+import static org.mockito.Mockito.when;\n+\n+public class MergingBucketsDeferringCollectorTests extends AggregatorTestCase {\n+\n+    /**\n+     * Usually all documents get collected into ordinal 0 unless they are part of a sub aggregation\n+     * @return a query that collects the i'th document into bucket ordinal i\n+     */\n+    private Query getQueryToCollectIntoDifferentOrdinals() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU0ODYzMg=="}, "originalCommit": {"oid": "71b1797e2bd827bad5bf30c91c8d994a57a3c62b"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTQyMTM3Mw==", "bodyText": "Sorry for my delayed response, I had a very hectic start of week!\n\nIts cool! Thanks for getting back to me!\n\nThat's a strange bug by the way...\n\nIt's sneaky! I'm hoping we really don't actually hit it. But it is the kind of thing that happens without unit tests, I think.", "url": "https://github.com/elastic/elasticsearch/pull/59366#discussion_r459421373", "createdAt": "2020-07-23T12:46:36Z", "author": {"login": "nik9000"}, "path": "server/src/test/java/org/elasticsearch/search/aggregations/bucket/MergingBucketsDeferringCollectorTests.java", "diffHunk": "@@ -0,0 +1,269 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.elasticsearch.search.aggregations.bucket;\n+\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.apache.lucene.document.Document;\n+import org.apache.lucene.document.NumericDocValuesField;\n+import org.apache.lucene.index.DirectoryReader;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.IndexWriter;\n+import org.apache.lucene.index.IndexWriterConfig;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.BulkScorer;\n+import org.apache.lucene.search.ConstantScoreScorer;\n+import org.apache.lucene.search.ConstantScoreWeight;\n+import org.apache.lucene.search.DocIdSetIterator;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.LeafCollector;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.QueryVisitor;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.search.Scorer;\n+import org.apache.lucene.search.Weight;\n+import org.apache.lucene.store.Directory;\n+import org.apache.lucene.util.Bits;\n+import org.elasticsearch.search.aggregations.AggregatorTestCase;\n+import org.elasticsearch.search.aggregations.BucketCollector;\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.elasticsearch.search.aggregations.bucket.MergingBucketsDeferringCollector;\n+import org.elasticsearch.search.internal.SearchContext;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import static org.apache.lucene.util.LuceneTestCase.newDirectory;\n+import static org.mockito.Mockito.when;\n+\n+public class MergingBucketsDeferringCollectorTests extends AggregatorTestCase {\n+\n+    /**\n+     * Usually all documents get collected into ordinal 0 unless they are part of a sub aggregation\n+     * @return a query that collects the i'th document into bucket ordinal i\n+     */\n+    private Query getQueryToCollectIntoDifferentOrdinals() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU0ODYzMg=="}, "originalCommit": {"oid": "71b1797e2bd827bad5bf30c91c8d994a57a3c62b"}, "originalPosition": 61}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1965, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}