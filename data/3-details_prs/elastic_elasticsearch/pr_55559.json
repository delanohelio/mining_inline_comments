{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA2OTQxMTE2", "number": 55559, "title": "Optimize date_histograms across daylight savings time", "bodyText": "Rounding dates on a shard that contains a daylight savings time transition\nis currently something like 1400% slower than when a shard contains dates\nonly on one side of the DST transition. And it makes a ton of short lived\ngarbage. This replaces that implementation with one that benchmarks to\nhaving around 30% overhead instead of the 1400%. And it doesn't generate\nany garbage per search hit.\nSome background:\nThere are two ways to round in ES:\n\nRound to the nearest time unit (Day/Hour/Week/Month/etc)\nRound to the nearest time interval (3 days/2 weeks/etc)\n\nI'm only optimizing the first one in this change and plan to do the second\nin a follow up. It turns out that rounding to the nearest unit really is\ntwo problems: when the unit rounds to midnight (day/week/month/year) and\nwhen it doesn't (hour/minute/second). Rounding to midnight is consistently\nabout 25% faster and rounding to individual hour or minutes.\nThis optimization relies on being able to usually figure out what the\nminimum and maximum dates are on the shard. This is similar to an existing\noptimization where we rewrite time zones that aren't fixed\n(think America/New_York and its daylight savings time transitions) into\nfixed time zones so long as there isn't a daylight savings time transition\non the shard (UTC-5 or UTC-4 for America/New_York). Once I implement\ntime interval rounding the time zone rewriting optimization should no\nlonger be needed.\nThis optimization doesn't come into play for composite or\nauto_date_histogram aggs because neither have been migrated to the new\nDATE ValuesSourceType which is where that range lookup happens. When\nthey are they will be able to pick up the optimization without much work.\nI expect this to be substantial for auto_date_histogram but less so for\ncomposite because it deals with fewer values.\nNote: My 30% overhead figure comes from small numbers of daylight savings\ntime transitions. That overhead gets higher when there are more\ntransitions in logarithmic fashion. When there are two thousand years\nworth of transitions my algorithm ends up being 250% slower than rounding\nwithout a time zone, but java time is 47000% slower at that point,\nallocating memory as fast as it possibly can.", "createdAt": "2020-04-21T22:28:26Z", "url": "https://github.com/elastic/elasticsearch/pull/55559", "merged": true, "mergeCommit": {"oid": "0097a86d5389d990387005d64a908777dcf61ff6"}, "closed": true, "closedAt": "2020-05-07T11:22:33Z", "author": {"login": "nik9000"}, "timelineItems": {"totalCount": 53, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcYoX8MgH2gAyNDA2OTQxMTE2OmMyMzBjZjg5ZWZkZDk2N2FhOGRjMWNkMDcyZmFiOGFjMDZjMzAzZjE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcevYFHgH2gAyNDA2OTQxMTE2OjgzZTcyZWRhNmFiNjE1YWVlYjkxYzQwNjcwMWQwNzkwYzg5M2Y0M2U=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "c230cf89efdd967aa8dc1cd072fab8ac06c303f1", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/c230cf89efdd967aa8dc1cd072fab8ac06c303f1", "committedDate": "2020-04-17T21:42:37Z", "message": "Take that Rounding!"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "971b473c59aeb22ba3bf478e421ab2314e9b4aac", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/971b473c59aeb22ba3bf478e421ab2314e9b4aac", "committedDate": "2020-04-18T18:13:32Z", "message": "This time for sure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "41a7699790f37ede26cd9b7c65f8adc8039d3f8e", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/41a7699790f37ede26cd9b7c65f8adc8039d3f8e", "committedDate": "2020-04-18T19:00:18Z", "message": "Fix quarter of year"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "308a4589ce86c3bf40c6de2c2e45ceb3dbba02c5", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/308a4589ce86c3bf40c6de2c2e45ceb3dbba02c5", "committedDate": "2020-04-18T20:39:19Z", "message": "Benchmark"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b33d546c83d492a77e12e335f2c6fbb451b2a76e", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/b33d546c83d492a77e12e335f2c6fbb451b2a76e", "committedDate": "2020-04-19T15:07:23Z", "message": "Try"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bd18c2a8deaf51480733b51fb0a641e867fc5543", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/bd18c2a8deaf51480733b51fb0a641e867fc5543", "committedDate": "2020-04-20T17:11:03Z", "message": "WIP"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "35c6ef4dd20421d9376187d6d5724be9a0218a81", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/35c6ef4dd20421d9376187d6d5724be9a0218a81", "committedDate": "2020-04-20T18:21:27Z", "message": "Moar"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bb01ea90ede493b1e9a66c7da04870a4000b8409", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/bb01ea90ede493b1e9a66c7da04870a4000b8409", "committedDate": "2020-04-20T18:38:04Z", "message": "All"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "acf1971a7c194cd4299fd69d61aabe7b0added56", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/acf1971a7c194cd4299fd69d61aabe7b0added56", "committedDate": "2020-04-20T19:33:30Z", "message": "Check this"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e242a3da04fda35aeba1ac54e6c7894110341dcc", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/e242a3da04fda35aeba1ac54e6c7894110341dcc", "committedDate": "2020-04-20T20:36:29Z", "message": "UTC?"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8ef7fb727a4b42f12611d3ed6ff5225bd780d460", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/8ef7fb727a4b42f12611d3ed6ff5225bd780d460", "committedDate": "2020-04-21T12:59:37Z", "message": "WIP"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d65b447506cd6d32bc034f2c114bc5a3e4e6257f", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/d65b447506cd6d32bc034f2c114bc5a3e4e6257f", "committedDate": "2020-04-21T14:36:34Z", "message": "WIP"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b8eefdab2ebb8237bcf204883ebe6381be6974cd", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/b8eefdab2ebb8237bcf204883ebe6381be6974cd", "committedDate": "2020-04-21T14:53:29Z", "message": "Spotless"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "27089f025a3c30ea69b35e3a9bbc997f2c571d11", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/27089f025a3c30ea69b35e3a9bbc997f2c571d11", "committedDate": "2020-04-21T19:35:02Z", "message": "Better!"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0951db5d749769cf0cced6293d36e84050c670d4", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/0951db5d749769cf0cced6293d36e84050c670d4", "committedDate": "2020-04-21T20:12:25Z", "message": "Words"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2a2440445337a9247b67b57d6ebfabcbbdd61a48", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/2a2440445337a9247b67b57d6ebfabcbbdd61a48", "committedDate": "2020-04-21T20:17:22Z", "message": "JMH"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c99ea8973dfc4c19d626555e1e84e3c5f7f03683", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/c99ea8973dfc4c19d626555e1e84e3c5f7f03683", "committedDate": "2020-04-21T21:47:51Z", "message": "JMH2"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cf5c5e9e31ce1e7f1c654174e60e3523fb2cfa22", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/cf5c5e9e31ce1e7f1c654174e60e3523fb2cfa22", "committedDate": "2020-04-21T22:26:30Z", "message": "Words"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6be2d0681aabd102170b78a1a70d5336b7d485e9", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/6be2d0681aabd102170b78a1a70d5336b7d485e9", "committedDate": "2020-04-21T22:30:11Z", "message": "Merge branch 'master' into tz_round"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "49a60e5d9311b240e422179621c20d118f6add39", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/49a60e5d9311b240e422179621c20d118f6add39", "committedDate": "2020-04-21T22:32:12Z", "message": "Revert extra"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk3NzIwNjk0", "url": "https://github.com/elastic/elasticsearch/pull/55559#pullrequestreview-397720694", "createdAt": "2020-04-21T22:29:05Z", "commit": {"oid": "cf5c5e9e31ce1e7f1c654174e60e3523fb2cfa22"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQyMjoyOTowNVrOGJbJJA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQyMjozNTozNlrOGJbUZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjUzNTA3Ng==", "bodyText": "@danielmitterdorfer , these are for you!", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412535076", "createdAt": "2020-04-21T22:29:05Z", "author": {"login": "nik9000"}, "path": "benchmarks/README.md", "diffHunk": "@@ -53,9 +53,9 @@ To get realistic results, you should exercise care when running benchmarks. Here\n   `performance` CPU governor.\n * Vary the problem input size with `@Param`.\n * Use the integrated profilers in JMH to dig deeper if benchmark results to not match your hypotheses:\n-    * Run the generated uberjar directly and use `-prof gc` to check whether the garbage collector runs during a microbenchmarks and skews\n+    * Add `-prof gc` to the options to check whether the garbage collector runs during a microbenchmarks and skews\n    your results. If so, try to force a GC between runs (`-gc true`) but watch out for the caveats.\n-    * Use `-prof perf` or `-prof perfasm` (both only available on Linux) to see hotspots.\n+    * Add `-prof perf` or `-prof perfasm` (both only available on Linux) to see hotspots.\n * Have your benchmarks peer-reviewed.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cf5c5e9e31ce1e7f1c654174e60e3523fb2cfa22"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjUzNTU0OQ==", "bodyText": "@DaveCTurner this bit is for you!", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412535549", "createdAt": "2020-04-21T22:30:14Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/common/LocalTimeOffset.java", "diffHunk": "@@ -0,0 +1,661 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.common;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.ZoneId;\n+import java.time.ZoneOffset;\n+import java.time.zone.ZoneOffsetTransition;\n+import java.time.zone.ZoneOffsetTransitionRule;\n+import java.time.zone.ZoneRules;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Locale;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cf5c5e9e31ce1e7f1c654174e60e3523fb2cfa22"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjUzNzEzNw==", "bodyText": "@not-napoleon this bit is for you!", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412537137", "createdAt": "2020-04-21T22:33:38Z", "author": {"login": "nik9000"}, "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregationSupplier.java", "diffHunk": "@@ -19,6 +19,7 @@\n \n package org.elasticsearch.search.aggregations.bucket.histogram;\n \n+import org.apache.lucene.index.IndexReader;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6be2d0681aabd102170b78a1a70d5336b7d485e9"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjUzNzk1Nw==", "bodyText": "Now that I look at the search index to run the agg I index the dates as well as make doc values for them. This makes this field not really useful any more.", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412537957", "createdAt": "2020-04-21T22:35:36Z", "author": {"login": "nik9000"}, "path": "server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java", "diffHunk": "@@ -50,7 +50,6 @@\n public class DateHistogramAggregatorTests extends AggregatorTestCase {\n \n     private static final String DATE_FIELD = \"date\";\n-    private static final String INSTANT_FIELD = \"instant\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6be2d0681aabd102170b78a1a70d5336b7d485e9"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "706007e9c48c8a98b06f61b258cfd2eee8701263", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/706007e9c48c8a98b06f61b258cfd2eee8701263", "committedDate": "2020-04-21T22:47:59Z", "message": "Words"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1185b465c7e5c52818349b7bb515b3361ea2dd24", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/1185b465c7e5c52818349b7bb515b3361ea2dd24", "committedDate": "2020-04-21T22:51:30Z", "message": "Unused import"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3a6b46ec88bde6c3f1f2bcbb96d849281e864cd5", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/3a6b46ec88bde6c3f1f2bcbb96d849281e864cd5", "committedDate": "2020-04-21T23:21:35Z", "message": "Explain"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9ccecd72a01ffbae05cc0db601da8105184e9f3e", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/9ccecd72a01ffbae05cc0db601da8105184e9f3e", "committedDate": "2020-04-21T23:28:14Z", "message": "Checkstyle"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk3OTI4ODkz", "url": "https://github.com/elastic/elasticsearch/pull/55559#pullrequestreview-397928893", "createdAt": "2020-04-22T07:49:06Z", "commit": {"oid": "9ccecd72a01ffbae05cc0db601da8105184e9f3e"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQwNzo0OTowNlrOGJoZTA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQwODowMTowNVrOGJo6MA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc1MjIwNA==", "bodyText": "nanoseconds don't seem handy for the output and I wonder whether it makes sense to switch to microseconds here? Especially when count is set to 1000000 the score is quite high.", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412752204", "createdAt": "2020-04-22T07:49:06Z", "author": {"login": "danielmitterdorfer"}, "path": "benchmarks/src/main/java/org/elasticsearch/common/RoundingBenchmark.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.common;\n+\n+import org.elasticsearch.common.time.DateFormatter;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.Warmup;\n+\n+import java.time.ZoneId;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+@Fork(1)\n+@Warmup(iterations = 5)\n+@Measurement(iterations = 3)\n+@BenchmarkMode(Mode.AverageTime)\n+@OutputTimeUnit(TimeUnit.NANOSECONDS)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9ccecd72a01ffbae05cc0db601da8105184e9f3e"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc1MjM5Mw==", "bodyText": "These changes make sense to me!", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412752393", "createdAt": "2020-04-22T07:49:21Z", "author": {"login": "danielmitterdorfer"}, "path": "benchmarks/README.md", "diffHunk": "@@ -53,9 +53,9 @@ To get realistic results, you should exercise care when running benchmarks. Here\n   `performance` CPU governor.\n * Vary the problem input size with `@Param`.\n * Use the integrated profilers in JMH to dig deeper if benchmark results to not match your hypotheses:\n-    * Run the generated uberjar directly and use `-prof gc` to check whether the garbage collector runs during a microbenchmarks and skews\n+    * Add `-prof gc` to the options to check whether the garbage collector runs during a microbenchmarks and skews\n    your results. If so, try to force a GC between runs (`-gc true`) but watch out for the caveats.\n-    * Use `-prof perf` or `-prof perfasm` (both only available on Linux) to see hotspots.\n+    * Add `-prof perf` or `-prof perfasm` (both only available on Linux) to see hotspots.\n * Have your benchmarks peer-reviewed.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjUzNTA3Ng=="}, "originalCommit": {"oid": "cf5c5e9e31ce1e7f1c654174e60e3523fb2cfa22"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc1NDE4MQ==", "bodyText": "All these numbers seem pretty low? I suggest at least two forks, 10 iterations for warmup and 5 for measurement. Here is an example from a benchmark run that I did where you can see that the score varies quite a bit after warmup:\n# Run progress: 91.41% complete, ETA 00:02:17\n# Fork: 1 of 1\n# Warmup Iteration   1: 14309725.186 ns/op\n# Warmup Iteration   2: 9710448.427 ns/op\n# Warmup Iteration   3: 9633859.654 ns/op\n# Warmup Iteration   4: 9712434.864 ns/op\n# Warmup Iteration   5: 9721697.184 ns/op\nIteration   1: 9706033.942 ns/op4m 34s]\n                 \u00b7gc.alloc.rate:      1.154 MB/sec\n                 \u00b7gc.alloc.rate.norm: 17564.231 B/op\n                 \u00b7gc.count:           \u2248 0 counts\n\nIteration   2: 9776863.388 ns/op4m 36s]\n                 \u00b7gc.alloc.rate:      1.144 MB/sec\n                 \u00b7gc.alloc.rate.norm: 17564.272 B/op\n                 \u00b7gc.count:           \u2248 0 counts\n\nIteration   3: 9703990.712 ns/op\n                 \u00b7gc.alloc.rate:      1.154 MB/sec\n                 \u00b7gc.alloc.rate.norm: 17564.231 B/op\n                 \u00b7gc.count:           \u2248 0 counts", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412754181", "createdAt": "2020-04-22T07:51:47Z", "author": {"login": "danielmitterdorfer"}, "path": "benchmarks/src/main/java/org/elasticsearch/common/RoundingBenchmark.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.common;\n+\n+import org.elasticsearch.common.time.DateFormatter;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.Warmup;\n+\n+import java.time.ZoneId;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+@Fork(1)\n+@Warmup(iterations = 5)\n+@Measurement(iterations = 3)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9ccecd72a01ffbae05cc0db601da8105184e9f3e"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc2MDU1NA==", "bodyText": "It's safer here to sink it into a blackhole instead to reduce the potential for compiler tricks.", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412760554", "createdAt": "2020-04-22T08:01:01Z", "author": {"login": "danielmitterdorfer"}, "path": "benchmarks/src/main/java/org/elasticsearch/common/RoundingBenchmark.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.common;\n+\n+import org.elasticsearch.common.time.DateFormatter;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.Warmup;\n+\n+import java.time.ZoneId;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+@Fork(1)\n+@Warmup(iterations = 5)\n+@Measurement(iterations = 3)\n+@BenchmarkMode(Mode.AverageTime)\n+@OutputTimeUnit(TimeUnit.NANOSECONDS)\n+@State(Scope.Benchmark)\n+public class RoundingBenchmark {\n+    private static final DateFormatter FORMATTER = DateFormatter.forPattern(\"date_optional_time\");\n+\n+    @Param({\n+        \"2000-01-01 to 2020-01-01\", // A super long range\n+        \"2000-10-01 to 2000-11-01\", // A whole month which is pretty believable\n+        \"2000-10-29 to 2000-10-30\", // A date right around daylight savings time.\n+        \"2000-06-01 to 2000-06-02\"  // A date fully in one time zone. Should be much faster than above.\n+    })\n+    public String range;\n+\n+    @Param({ \"java time\", \"es\" })\n+    public String rounder;\n+\n+    @Param({ \"UTC\", \"America/New_York\" })\n+    public String zone;\n+\n+    @Param({ \"MONTH_OF_YEAR\", \"HOUR_OF_DAY\" })\n+    public String timeUnit;\n+\n+    @Param({ \"1\", \"1000000\" })\n+    public int count;\n+\n+    private long min;\n+    private long max;\n+    private long[] dates;\n+    private Supplier<Rounding.Prepared> rounderBuilder;\n+\n+    @Setup\n+    public void buildDates() {\n+        String[] r = range.split(\" to \");\n+        min = FORMATTER.parseMillis(r[0]);\n+        max = FORMATTER.parseMillis(r[1]);\n+        dates = new long[count];\n+        long date = min;\n+        long diff = (max - min) / dates.length;\n+        for (int i = 0; i < dates.length; i++) {\n+            if (date >= max) {\n+                throw new IllegalStateException(\"made a bad date [\" + date + \"]\");\n+            }\n+            dates[i] = date;\n+            date += diff;\n+        }\n+        Rounding rounding = Rounding.builder(Rounding.DateTimeUnit.valueOf(timeUnit)).timeZone(ZoneId.of(zone)).build();\n+        switch (rounder) {\n+            case \"java time\":\n+                rounderBuilder = rounding::prepareJavaTime;\n+                break;\n+            case \"es\":\n+                rounderBuilder = () -> rounding.prepare(min, max);\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Expectd rounder to be [java time] or [es]\");\n+        }\n+    }\n+\n+    @Benchmark\n+    public long round() {\n+        long sum = 0;\n+        Rounding.Prepared rounder = rounderBuilder.get();\n+        for (int i = 0; i < dates.length; i++) {\n+            sum += rounder.round(dates[i]);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9ccecd72a01ffbae05cc0db601da8105184e9f3e"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc2MDYyNA==", "bodyText": "It's safer here to sink it into a blackhole instead to reduce the potential for compiler tricks.", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412760624", "createdAt": "2020-04-22T08:01:05Z", "author": {"login": "danielmitterdorfer"}, "path": "benchmarks/src/main/java/org/elasticsearch/common/RoundingBenchmark.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.common;\n+\n+import org.elasticsearch.common.time.DateFormatter;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.Warmup;\n+\n+import java.time.ZoneId;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+@Fork(1)\n+@Warmup(iterations = 5)\n+@Measurement(iterations = 3)\n+@BenchmarkMode(Mode.AverageTime)\n+@OutputTimeUnit(TimeUnit.NANOSECONDS)\n+@State(Scope.Benchmark)\n+public class RoundingBenchmark {\n+    private static final DateFormatter FORMATTER = DateFormatter.forPattern(\"date_optional_time\");\n+\n+    @Param({\n+        \"2000-01-01 to 2020-01-01\", // A super long range\n+        \"2000-10-01 to 2000-11-01\", // A whole month which is pretty believable\n+        \"2000-10-29 to 2000-10-30\", // A date right around daylight savings time.\n+        \"2000-06-01 to 2000-06-02\"  // A date fully in one time zone. Should be much faster than above.\n+    })\n+    public String range;\n+\n+    @Param({ \"java time\", \"es\" })\n+    public String rounder;\n+\n+    @Param({ \"UTC\", \"America/New_York\" })\n+    public String zone;\n+\n+    @Param({ \"MONTH_OF_YEAR\", \"HOUR_OF_DAY\" })\n+    public String timeUnit;\n+\n+    @Param({ \"1\", \"1000000\" })\n+    public int count;\n+\n+    private long min;\n+    private long max;\n+    private long[] dates;\n+    private Supplier<Rounding.Prepared> rounderBuilder;\n+\n+    @Setup\n+    public void buildDates() {\n+        String[] r = range.split(\" to \");\n+        min = FORMATTER.parseMillis(r[0]);\n+        max = FORMATTER.parseMillis(r[1]);\n+        dates = new long[count];\n+        long date = min;\n+        long diff = (max - min) / dates.length;\n+        for (int i = 0; i < dates.length; i++) {\n+            if (date >= max) {\n+                throw new IllegalStateException(\"made a bad date [\" + date + \"]\");\n+            }\n+            dates[i] = date;\n+            date += diff;\n+        }\n+        Rounding rounding = Rounding.builder(Rounding.DateTimeUnit.valueOf(timeUnit)).timeZone(ZoneId.of(zone)).build();\n+        switch (rounder) {\n+            case \"java time\":\n+                rounderBuilder = rounding::prepareJavaTime;\n+                break;\n+            case \"es\":\n+                rounderBuilder = () -> rounding.prepare(min, max);\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Expectd rounder to be [java time] or [es]\");\n+        }\n+    }\n+\n+    @Benchmark\n+    public long round() {\n+        long sum = 0;\n+        Rounding.Prepared rounder = rounderBuilder.get();\n+        for (int i = 0; i < dates.length; i++) {\n+            sum += rounder.round(dates[i]);\n+        }\n+        return sum;\n+    }\n+\n+    @Benchmark\n+    public long nextRoundingValue() {\n+        long sum = 0;\n+        Rounding.Prepared rounder = rounderBuilder.get();\n+        for (int i = 0; i < dates.length; i++) {\n+            sum += rounder.nextRoundingValue(dates[i]);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9ccecd72a01ffbae05cc0db601da8105184e9f3e"}, "originalPosition": 116}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk4MDI0OTk4", "url": "https://github.com/elastic/elasticsearch/pull/55559#pullrequestreview-398024998", "createdAt": "2020-04-22T09:48:55Z", "commit": {"oid": "9ccecd72a01ffbae05cc0db601da8105184e9f3e"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxMDowNjo0NFrOGJuVyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxMDozMjowNlrOGJvV1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg0OTYwOQ==", "bodyText": "It's also likely completely invalid; surely we'll have abolished DST at some point in the next 2500 years? \ud83d\ude01\nHow well are we testing the case where we hit this limit?", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412849609", "createdAt": "2020-04-22T10:06:44Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/common/LocalTimeOffset.java", "diffHunk": "@@ -0,0 +1,679 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.common;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.ZoneId;\n+import java.time.zone.ZoneOffsetTransition;\n+import java.time.zone.ZoneOffsetTransitionRule;\n+import java.time.zone.ZoneRules;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Locale;\n+\n+/**\n+ * Converts utc into local time and back again.\n+ * <p>\n+ * \"Local time\" is defined by some time zone, specifically and {@link ZoneId}.\n+ * At any point in time a particular time zone is at some offset from from\n+ * utc. So converting from utc is as simple as adding the offset.\n+ * <p>\n+ * Getting from local time back to utc is harder. Most local times happen once.\n+ * But some local times happen twice. And some don't happen at all. Take, for\n+ * example, the time in my house. Most days I don't touch my clocks and I'm a\n+ * constant offset from UTC. But once in the fall at 2am I roll my clock back.\n+ * So at 5am utc my clocks say 1am. Then at 6am utc my clocks say 1am AGAIN.\n+ * I do similarly terrifying things again in the spring when I skip my clocks\n+ * straight from 1:59am to 3am.\n+ * <p>\n+ * So there are three methods to convert from local time back to utc,\n+ * {@link #localToUtc(long, Strategy)}, {@link #localToSensibleUtc(long)} and\n+ * {@link #localToUtcInThisOffset(long)}. They are all unique and frightening.\n+ */\n+public abstract class LocalTimeOffset {\n+    /**\n+     * Lookup offsets for a provided zone. This <strong>can</strong> fail if\n+     * there are many transitions and the provided lookup would be very large.\n+     *\n+     * @return a {@linkplain Lookup} or {@code null} if none could be built \n+     */\n+    public static Lookup lookup(ZoneId zone, long minUtcMillis, long maxUtcMillis) {\n+        if (minUtcMillis > maxUtcMillis) {\n+            throw new IllegalArgumentException(\"[\" + minUtcMillis + \"] must be <= [\" + maxUtcMillis + \"]\");\n+        }\n+        ZoneRules rules = zone.getRules();\n+        {\n+            LocalTimeOffset fixed = checkForFixedZone(zone, rules);\n+            if (fixed != null) {\n+                return new FixedLookup(zone, fixed);\n+            }\n+        }\n+        List<ZoneOffsetTransition> transitions = collectTransitions(zone, rules, minUtcMillis, maxUtcMillis);\n+        if (transitions == null) {\n+            // The range is too large for us to pre-build all the offsets\n+            return null;\n+        }\n+        if (transitions.size() < 3) {\n+            /*\n+             * Its actually quite common that there are *very* few transitions.\n+             * This case where there are only two transitions covers an entire\n+             * year of data! In any case, it is slightly faster to do the\n+             * \"simpler\" thing and compare the start times instead of perform\n+             * a binary search when there are so few offsets to look at.\n+             */\n+            return new LinkedListLookup(zone, minUtcMillis, maxUtcMillis, transitions);\n+        }\n+        return new TransitionArrayLookup(zone, minUtcMillis, maxUtcMillis, transitions);\n+    }\n+\n+    /**\n+     * Lookup offsets without any known min or max time. This will generally\n+     * fail if the provided zone isn't fixed.\n+     *\n+     * @return a lookup function of {@code null} if none could be built \n+     */\n+    public static LocalTimeOffset lookupFixedOffset(ZoneId zone) {\n+        return checkForFixedZone(zone, zone.getRules());\n+    }\n+\n+    private final long millis;\n+\n+    private LocalTimeOffset(long millis) {\n+        this.millis = millis;\n+    }\n+\n+    /**\n+     * Convert a time in utc into a the local time at this offset.\n+     */\n+    public final long utcToLocalTime(long utcMillis) {\n+        return utcMillis + millis;\n+    }\n+\n+    /**\n+     * Convert a time in local millis to utc millis using <strong>this</strong> offset.\n+     * <p>\n+     * <strong>Important:</strong> Callers will rarely want to <strong>force</strong>\n+     * using this offset and are instead instead interested in picking an appropriate\n+     * offset for some local time that they have rounded down. In that case use\n+     * {@link #localToSensibleUtc(long)} or {@link #localToUtc(long, Strategy)}.\n+     */\n+    public final long localToUtcInThisOffset(long localMillis) {\n+        return localMillis - millis;\n+    }\n+\n+    /**\n+     * Convert a local time that occurs during this offset or a previous\n+     * offset to utc, providing a strategy for how to resolve \"funny\" cases.\n+     * You can use this if you've converted from utc to local, rounded down,\n+     * and then want to convert back to utc and you need fine control over\n+     * how to handle the \"funny\" edges.\n+     * <p>\n+     * This will not help you if you must convert a local time that you've\n+     * rounded <strong>up</strong>. For that you are on your own. May God\n+     * have mercy on your soul.\n+     */\n+    public abstract long localToUtc(long localMillis, Strategy strat);\n+    public interface Strategy {\n+        /**\n+         * Handle a local time that never actually happened because a \"gap\"\n+         * jumped over it. This happens in many time zones when folks wind\n+         * their clocks forwards in the spring.\n+         *\n+         * @return the time in utc representing the local time\n+         */\n+        long inGap(long localMillis, Gap gap);\n+        /**\n+         * Handle a local time that happened before the start of a gap.\n+         *\n+         * @return the time in utc representing the local time\n+         */\n+        long beforeGap(long localMillis, Gap gap);\n+        /**\n+         * Handle a local time that happened twice because an \"overlap\"\n+         * jumped behind it. This happens in many time zones when folks wind\n+         * their clocks back in the fall.\n+         *\n+         * @return the time in utc representing the local time\n+         */\n+        long inOverlap(long localMillis, Overlap overlap);\n+        /**\n+         * Handle a local time that happened before the start of an overlap.\n+         *\n+         * @return the time in utc representing the local time\n+         */\n+        long beforeOverlap(long localMillis, Overlap overlap);\n+    }\n+\n+    /**\n+     * Map a local time that occurs during this offset or a previous offset\n+     * to a utc time . You can use this if you've converted from utc to local,\n+     * rounded down, and then want to convert back to utc but you don't really\n+     * care about how to resolve \"funny\" edge cases. This resolves them\n+     * <em>fairly</em> sanely.\n+     * <p>\n+     * If a local time occurred twice then returns the time in utc that the\n+     * clocks first showed that time. If a local time never occurred then\n+     * returns the utc time where the clock jumped over that time. If a local\n+     * time occurs before a gap or overlap then uses the offset to convert it.\n+     * This is all sensible but it may not be right for you.\n+     */\n+    public final long localToSensibleUtc(long localMillis) {\n+        return localToUtc(localMillis, SENSIBLE_STRAT);\n+    }\n+    private static final Strategy SENSIBLE_STRAT = new Strategy() {\n+        @Override\n+        public long inGap(long localMillis, Gap gap) {\n+            return gap.startUtcMillis();\n+        }\n+\n+        public long beforeGap(long localMillis, Gap gap) {\n+            return gap.previous().localToUtc(localMillis, SENSIBLE_STRAT);\n+        };\n+\n+        @Override\n+        public long inOverlap(long localMillis, Overlap overlap) {\n+            return overlap.previous().localToUtc(localMillis, SENSIBLE_STRAT);\n+        }\n+\n+        public long beforeOverlap(long localMillis, Overlap overlap) {\n+            return overlap.previous().localToUtc(localMillis, SENSIBLE_STRAT);\n+        };\n+    };\n+\n+    /**\n+     * Does this offset contain the provided time?\n+     */\n+    protected abstract boolean containsUtcMillis(long utcMillis);\n+\n+    /**\n+     * Find the offset containing the provided time, first checking this\n+     * offset, then its previous offset, the than one's previous offset, etc.\n+     */\n+    protected abstract LocalTimeOffset offsetContaining(long utcMillis);\n+\n+    @Override\n+    public String toString() {\n+        return toString(millis);\n+    }\n+    protected abstract String toString(long millis);\n+\n+    /**\n+     * How to get instances of {@link LocalTimeOffset}.\n+     */\n+    public abstract static class Lookup {\n+        /**\n+         * Lookup the offset at the provided millis in utc.\n+         */\n+        public abstract LocalTimeOffset lookup(long utcMillis);\n+\n+        /**\n+         * If the offset for a range is constant then return it, otherwise\n+         * return {@code null}.\n+         */\n+        public abstract LocalTimeOffset fixedInRange(long minUtcMillis, long maxUtcMillis);\n+\n+        /**\n+         * The number of offsets in the lookup. Package private for testing.\n+         */\n+        abstract int size();\n+    }\n+\n+    private static class NoPrevious extends LocalTimeOffset {\n+        NoPrevious(long millis) {\n+            super(millis);\n+        }\n+\n+        @Override\n+        public long localToUtc(long localMillis, Strategy strat) {\n+            return localToUtcInThisOffset(localMillis);\n+        }\n+\n+        @Override\n+        protected boolean containsUtcMillis(long utcMillis) {\n+            return true;\n+        }\n+\n+        @Override\n+        protected LocalTimeOffset offsetContaining(long utcMillis) {\n+            /*\n+             * Since there isn't a previous offset this offset *must* contain\n+             * the provided time.\n+             */\n+            return this;\n+        }\n+\n+        @Override\n+        protected String toString(long millis) {\n+            return Long.toString(millis);\n+        }\n+    }\n+\n+    public abstract static class Transition extends LocalTimeOffset {\n+        private final LocalTimeOffset previous;\n+        private final long startUtcMillis;\n+\n+        private Transition(long millis, LocalTimeOffset previous, long startUtcMillis) {\n+            super(millis);\n+            this.previous = previous;\n+            this.startUtcMillis = startUtcMillis;\n+        }\n+\n+        /**\n+         * The offset before the this one.\n+         */\n+        public LocalTimeOffset previous() {\n+            return previous;\n+        }\n+\n+        @Override\n+        protected final boolean containsUtcMillis(long utcMillis) {\n+            return utcMillis >= startUtcMillis;\n+        }\n+\n+        @Override\n+        protected final LocalTimeOffset offsetContaining(long utcMillis) {\n+            if (containsUtcMillis(utcMillis)) {\n+                return this;\n+            }\n+            return previous.offsetContaining(utcMillis);\n+        }\n+\n+        /**\n+         * The time that this offset started in milliseconds since epoch.\n+         */\n+        public long startUtcMillis() {\n+            return startUtcMillis;\n+        }\n+    }\n+\n+    public static class Gap extends Transition {\n+        private final long firstMissingLocalTime;\n+        private final long firstLocalTimeAfterGap;\n+\n+        private Gap(long millis, LocalTimeOffset previous, long startUtcMillis, long firstMissingLocalTime, long firstLocalTimeAfterGap) {\n+            super(millis, previous, startUtcMillis);\n+            this.firstMissingLocalTime = firstMissingLocalTime;\n+            this.firstLocalTimeAfterGap = firstLocalTimeAfterGap;\n+            assert firstMissingLocalTime < firstLocalTimeAfterGap;\n+        }\n+\n+        @Override\n+        public long localToUtc(long localMillis, Strategy strat) {\n+            if (localMillis >= firstLocalTimeAfterGap) {\n+                return localToUtcInThisOffset(localMillis);\n+            }\n+            if (localMillis >= firstMissingLocalTime) {\n+                return strat.inGap(localMillis, this);\n+            }\n+            return strat.beforeGap(localMillis, this);\n+        }\n+\n+        /**\n+         * The first time that is missing from the local time because of this gap.\n+         */\n+        public long firstMissingLocalTime() {\n+            return firstMissingLocalTime;\n+        }\n+\n+        @Override\n+        protected String toString(long millis) {\n+            return \"Gap of \" + millis + \"@\" + Instant.ofEpochMilli(startUtcMillis());\n+        }\n+    }\n+\n+    public static class Overlap extends Transition {\n+        private final long firstOverlappingLocalTime;\n+        private final long firstNonOverlappingLocalTime;\n+\n+        private Overlap(long millis, LocalTimeOffset previous, long startUtcMillis,\n+                long firstOverlappingLocalTime, long firstNonOverlappingLocalTime) {\n+            super(millis, previous, startUtcMillis);\n+            this.firstOverlappingLocalTime = firstOverlappingLocalTime;\n+            this.firstNonOverlappingLocalTime = firstNonOverlappingLocalTime;\n+            assert firstOverlappingLocalTime < firstNonOverlappingLocalTime;\n+        }\n+\n+        @Override\n+        public long localToUtc(long localMillis, Strategy strat) {\n+            if (localMillis >= firstNonOverlappingLocalTime) {\n+                return localToUtcInThisOffset(localMillis);\n+            }\n+            if (localMillis >= firstOverlappingLocalTime) {\n+                return strat.inOverlap(localMillis, this);\n+            }\n+            return strat.beforeOverlap(localMillis, this);\n+        }\n+\n+        /**\n+         * The first local time after the overlap stops.\n+         */\n+        public long firstNonOverlappingLocalTime() {\n+            return firstNonOverlappingLocalTime;\n+        }\n+\n+        /**\n+         * The first local time to be appear twice.\n+         */\n+        public long firstOverlappingLocalTime() {\n+            return firstOverlappingLocalTime;\n+        }\n+\n+        @Override\n+        protected String toString(long millis) {\n+            return \"Overlap of \" + millis + \"@\" + Instant.ofEpochMilli(startUtcMillis());\n+        }\n+    }\n+\n+    private static class FixedLookup extends Lookup {\n+        private final ZoneId zone;\n+        private final LocalTimeOffset fixed;\n+\n+        private FixedLookup(ZoneId zone, LocalTimeOffset fixed) {\n+            this.zone = zone;\n+            this.fixed = fixed;\n+        }\n+\n+        @Override\n+        public LocalTimeOffset lookup(long utcMillis) {\n+            return fixed;\n+        }\n+\n+        @Override\n+        public LocalTimeOffset fixedInRange(long minUtcMillis, long maxUtcMillis) {\n+            return fixed;\n+        }\n+\n+        @Override\n+        int size() {\n+            return 1;\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return String.format(Locale.ROOT, \"FixedLookup[for %s at %s]\", zone, fixed);\n+        }\n+    }\n+\n+    /**\n+     * Looks up transitions by checking whether the date is after the start\n+     * of each transition. Simple so fast for small numbers of transitions.\n+     */\n+    private static class LinkedListLookup extends AbstractManyTransitionsLookup {\n+        private final LocalTimeOffset lastOffset;\n+        private final int size;\n+\n+        LinkedListLookup(ZoneId zone, long minUtcMillis, long maxUtcMillis, List<ZoneOffsetTransition> transitions) {\n+            super(zone, minUtcMillis, maxUtcMillis);\n+            int size = 1;\n+            LocalTimeOffset last = buildNoPrevious(transitions.get(0));\n+            for (ZoneOffsetTransition t : transitions) {\n+                last = buildTransition(t, last);\n+                size++;\n+            }\n+            this.lastOffset = last;\n+            this.size = size;\n+        }\n+\n+        @Override\n+        public LocalTimeOffset innerLookup(long utcMillis) {\n+            return lastOffset.offsetContaining(utcMillis);\n+        }\n+\n+        @Override\n+        int size() {\n+            return size;\n+        }\n+    }\n+\n+    /**\n+     * Builds an array that can be {@link Arrays#binarySearch(long[], long)}ed\n+     * for the daylight savings time transitions.\n+     */\n+    private static class TransitionArrayLookup extends AbstractManyTransitionsLookup {\n+        private final LocalTimeOffset[] offsets;\n+        private final long[] transitionOutUtcMillis;\n+\n+        private TransitionArrayLookup(ZoneId zone, long minUtcMillis, long maxUtcMillis, List<ZoneOffsetTransition> transitions) {\n+            super(zone, minUtcMillis, maxUtcMillis);\n+            this.offsets = new LocalTimeOffset[transitions.size() + 1];\n+            this.transitionOutUtcMillis = new long[transitions.size()];\n+            this.offsets[0] = buildNoPrevious(transitions.get(0));\n+            int i = 0;\n+            for (ZoneOffsetTransition t : transitions) {\n+                Transition transition = buildTransition(t, this.offsets[i]);\n+                transitionOutUtcMillis[i] = transition.startUtcMillis();\n+                i++;\n+                this.offsets[i] = transition;\n+            }\n+        }\n+\n+        @Override\n+        protected LocalTimeOffset innerLookup(long utcMillis) {\n+            int index = Arrays.binarySearch(transitionOutUtcMillis, utcMillis);\n+            if (index < 0) {\n+                /*\n+                 * We're mostly not going to find the exact offset. Instead we'll\n+                 * end up at the \"insertion point\" for the utcMillis. We have no\n+                 * plans to insert utcMillis in the array, but the offset that\n+                 * contains utcMillis happens to be \"insertion point\" - 1.\n+                 */\n+                index = -index - 1;\n+            } else {\n+                index++;\n+            }\n+            assert index < offsets.length : \"binarySearch did something weird\";\n+            return offsets[index];\n+        }\n+\n+        @Override\n+        int size() {\n+            return offsets.length;\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return String.format(Locale.ROOT, \"TransitionArrayLookup[for %s between %s and %s]\",\n+                    zone, Instant.ofEpochMilli(minUtcMillis), Instant.ofEpochMilli(maxUtcMillis));\n+        }\n+    }\n+\n+    private abstract static class AbstractManyTransitionsLookup extends Lookup {\n+        protected final ZoneId zone;\n+        protected final long minUtcMillis;\n+        protected final long maxUtcMillis;\n+\n+        AbstractManyTransitionsLookup(ZoneId zone, long minUtcMillis, long maxUtcMillis) {\n+            this.zone = zone;\n+            this.minUtcMillis = minUtcMillis;\n+            this.maxUtcMillis = maxUtcMillis;\n+        }\n+\n+        @Override\n+        public final LocalTimeOffset lookup(long utcMillis) {\n+            assert utcMillis >= minUtcMillis;\n+            assert utcMillis <= maxUtcMillis;\n+            return innerLookup(utcMillis);\n+        }\n+\n+        protected abstract LocalTimeOffset innerLookup(long utcMillis);\n+\n+        @Override\n+        public final LocalTimeOffset fixedInRange(long minUtcMillis, long maxUtcMillis) {\n+            LocalTimeOffset offset = lookup(maxUtcMillis);\n+            return offset.containsUtcMillis(minUtcMillis) ? offset : null;\n+        }\n+\n+        protected static NoPrevious buildNoPrevious(ZoneOffsetTransition transition) {\n+            return new NoPrevious(transition.getOffsetBefore().getTotalSeconds() * 1000);\n+        }\n+\n+        protected static Transition buildTransition(ZoneOffsetTransition transition, LocalTimeOffset previous) {\n+            long utcStart = transition.toEpochSecond() * 1000;\n+            long offsetBeforeMillis = transition.getOffsetBefore().getTotalSeconds() * 1000;\n+            long offsetAfterMillis = transition.getOffsetAfter().getTotalSeconds() * 1000;\n+            if (transition.isGap()) {\n+                long firstMissingLocalTime = utcStart + offsetBeforeMillis;\n+                long firstLocalTimeAfterGap = utcStart + offsetAfterMillis;\n+                return new Gap(offsetAfterMillis, previous, utcStart, firstMissingLocalTime, firstLocalTimeAfterGap);\n+            }\n+            long firstOverlappingLocalTime = utcStart + offsetAfterMillis;\n+            long firstNonOverlappingLocalTime = utcStart + offsetBeforeMillis;\n+            return new Overlap(offsetAfterMillis, previous, utcStart, firstOverlappingLocalTime, firstNonOverlappingLocalTime);\n+        }\n+    }\n+\n+    private static LocalTimeOffset checkForFixedZone(ZoneId zone, ZoneRules rules) {\n+        if (false == rules.isFixedOffset()) {\n+            return null;\n+        }\n+        LocalTimeOffset fixedTransition = new NoPrevious(rules.getOffset(Instant.EPOCH).getTotalSeconds() * 1000);\n+        return fixedTransition;\n+    }\n+\n+    /**\n+     * The maximum number of {@link ZoneOffsetTransition} to collect before\n+     * giving up because the date range will be \"too big\". I picked this number\n+     * fairly arbitrarily with the following goals:\n+     * <ol>\n+     * <li>Don't let {@code lookup(Long.MIN_VALUE, Long.MAX_VALUE)} consume all\n+     *     the memory in the JVM.\n+     * <li>It should be much larger than the number of offsets I'm bound to\n+     *     collect.\n+     * </ol>\n+     * {@code 5_000} collects about 2_500 years worth offsets which feels like\n+     * quite a few!", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9ccecd72a01ffbae05cc0db601da8105184e9f3e"}, "originalPosition": 564}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg1Mzg0Nw==", "bodyText": "It'd be cute to use TimeValue.timeValueDays(7).millis() instead of the comment, and similarly below.", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412853847", "createdAt": "2020-04-22T10:13:00Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/common/Rounding.java", "diffHunk": "@@ -46,58 +48,94 @@\n import java.util.Objects;\n \n /**\n- * A strategy for rounding date/time based values.\n- *\n+ * A strategy for rounding milliseconds since epoch.\n+ * <p>\n  * There are two implementations for rounding.\n- * The first one requires a date time unit and rounds to the supplied date time unit (i.e. quarter of year, day of month)\n- * The second one allows you to specify an interval to round to\n+ * The first one requires a date time unit and rounds to the supplied date time unit (i.e. quarter of year, day of month).\n+ * The second one allows you to specify an interval to round to.\n+ * <p>\n+ * See <a href=\"https://davecturner.github.io/2019/04/14/timezone-rounding.html\">this</a>\n+ * blog for some background reading. Its super interesting and the links are\n+ * a comedy gold mine. If you like time zones. Or hate them.\n  */\n public abstract class Rounding implements Writeable {\n-\n     public enum DateTimeUnit {\n         WEEK_OF_WEEKYEAR((byte) 1, IsoFields.WEEK_OF_WEEK_BASED_YEAR) {\n             long roundFloor(long utcMillis) {\n                 return DateUtils.roundWeekOfWeekYear(utcMillis);\n             }\n+\n+            @Override\n+            long extraLocalOffsetLookup() {\n+                return 604800000L; // 7 days worth of a milliseconds ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9ccecd72a01ffbae05cc0db601da8105184e9f3e"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg2MjE4Nw==", "bodyText": "\"sensible\" feels like the wrong word for timezone code. Suggest inlining this, it's only called once, and moving SENSIBLE_STRAT to a field of ToMidnightRounding, maybe renaming to MIDNIGHT_STRATEGY or similar.", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412862187", "createdAt": "2020-04-22T10:26:10Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/common/LocalTimeOffset.java", "diffHunk": "@@ -0,0 +1,679 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.common;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.ZoneId;\n+import java.time.zone.ZoneOffsetTransition;\n+import java.time.zone.ZoneOffsetTransitionRule;\n+import java.time.zone.ZoneRules;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Locale;\n+\n+/**\n+ * Converts utc into local time and back again.\n+ * <p>\n+ * \"Local time\" is defined by some time zone, specifically and {@link ZoneId}.\n+ * At any point in time a particular time zone is at some offset from from\n+ * utc. So converting from utc is as simple as adding the offset.\n+ * <p>\n+ * Getting from local time back to utc is harder. Most local times happen once.\n+ * But some local times happen twice. And some don't happen at all. Take, for\n+ * example, the time in my house. Most days I don't touch my clocks and I'm a\n+ * constant offset from UTC. But once in the fall at 2am I roll my clock back.\n+ * So at 5am utc my clocks say 1am. Then at 6am utc my clocks say 1am AGAIN.\n+ * I do similarly terrifying things again in the spring when I skip my clocks\n+ * straight from 1:59am to 3am.\n+ * <p>\n+ * So there are three methods to convert from local time back to utc,\n+ * {@link #localToUtc(long, Strategy)}, {@link #localToSensibleUtc(long)} and\n+ * {@link #localToUtcInThisOffset(long)}. They are all unique and frightening.\n+ */\n+public abstract class LocalTimeOffset {\n+    /**\n+     * Lookup offsets for a provided zone. This <strong>can</strong> fail if\n+     * there are many transitions and the provided lookup would be very large.\n+     *\n+     * @return a {@linkplain Lookup} or {@code null} if none could be built \n+     */\n+    public static Lookup lookup(ZoneId zone, long minUtcMillis, long maxUtcMillis) {\n+        if (minUtcMillis > maxUtcMillis) {\n+            throw new IllegalArgumentException(\"[\" + minUtcMillis + \"] must be <= [\" + maxUtcMillis + \"]\");\n+        }\n+        ZoneRules rules = zone.getRules();\n+        {\n+            LocalTimeOffset fixed = checkForFixedZone(zone, rules);\n+            if (fixed != null) {\n+                return new FixedLookup(zone, fixed);\n+            }\n+        }\n+        List<ZoneOffsetTransition> transitions = collectTransitions(zone, rules, minUtcMillis, maxUtcMillis);\n+        if (transitions == null) {\n+            // The range is too large for us to pre-build all the offsets\n+            return null;\n+        }\n+        if (transitions.size() < 3) {\n+            /*\n+             * Its actually quite common that there are *very* few transitions.\n+             * This case where there are only two transitions covers an entire\n+             * year of data! In any case, it is slightly faster to do the\n+             * \"simpler\" thing and compare the start times instead of perform\n+             * a binary search when there are so few offsets to look at.\n+             */\n+            return new LinkedListLookup(zone, minUtcMillis, maxUtcMillis, transitions);\n+        }\n+        return new TransitionArrayLookup(zone, minUtcMillis, maxUtcMillis, transitions);\n+    }\n+\n+    /**\n+     * Lookup offsets without any known min or max time. This will generally\n+     * fail if the provided zone isn't fixed.\n+     *\n+     * @return a lookup function of {@code null} if none could be built \n+     */\n+    public static LocalTimeOffset lookupFixedOffset(ZoneId zone) {\n+        return checkForFixedZone(zone, zone.getRules());\n+    }\n+\n+    private final long millis;\n+\n+    private LocalTimeOffset(long millis) {\n+        this.millis = millis;\n+    }\n+\n+    /**\n+     * Convert a time in utc into a the local time at this offset.\n+     */\n+    public final long utcToLocalTime(long utcMillis) {\n+        return utcMillis + millis;\n+    }\n+\n+    /**\n+     * Convert a time in local millis to utc millis using <strong>this</strong> offset.\n+     * <p>\n+     * <strong>Important:</strong> Callers will rarely want to <strong>force</strong>\n+     * using this offset and are instead instead interested in picking an appropriate\n+     * offset for some local time that they have rounded down. In that case use\n+     * {@link #localToSensibleUtc(long)} or {@link #localToUtc(long, Strategy)}.\n+     */\n+    public final long localToUtcInThisOffset(long localMillis) {\n+        return localMillis - millis;\n+    }\n+\n+    /**\n+     * Convert a local time that occurs during this offset or a previous\n+     * offset to utc, providing a strategy for how to resolve \"funny\" cases.\n+     * You can use this if you've converted from utc to local, rounded down,\n+     * and then want to convert back to utc and you need fine control over\n+     * how to handle the \"funny\" edges.\n+     * <p>\n+     * This will not help you if you must convert a local time that you've\n+     * rounded <strong>up</strong>. For that you are on your own. May God\n+     * have mercy on your soul.\n+     */\n+    public abstract long localToUtc(long localMillis, Strategy strat);\n+    public interface Strategy {\n+        /**\n+         * Handle a local time that never actually happened because a \"gap\"\n+         * jumped over it. This happens in many time zones when folks wind\n+         * their clocks forwards in the spring.\n+         *\n+         * @return the time in utc representing the local time\n+         */\n+        long inGap(long localMillis, Gap gap);\n+        /**\n+         * Handle a local time that happened before the start of a gap.\n+         *\n+         * @return the time in utc representing the local time\n+         */\n+        long beforeGap(long localMillis, Gap gap);\n+        /**\n+         * Handle a local time that happened twice because an \"overlap\"\n+         * jumped behind it. This happens in many time zones when folks wind\n+         * their clocks back in the fall.\n+         *\n+         * @return the time in utc representing the local time\n+         */\n+        long inOverlap(long localMillis, Overlap overlap);\n+        /**\n+         * Handle a local time that happened before the start of an overlap.\n+         *\n+         * @return the time in utc representing the local time\n+         */\n+        long beforeOverlap(long localMillis, Overlap overlap);\n+    }\n+\n+    /**\n+     * Map a local time that occurs during this offset or a previous offset\n+     * to a utc time . You can use this if you've converted from utc to local,\n+     * rounded down, and then want to convert back to utc but you don't really\n+     * care about how to resolve \"funny\" edge cases. This resolves them\n+     * <em>fairly</em> sanely.\n+     * <p>\n+     * If a local time occurred twice then returns the time in utc that the\n+     * clocks first showed that time. If a local time never occurred then\n+     * returns the utc time where the clock jumped over that time. If a local\n+     * time occurs before a gap or overlap then uses the offset to convert it.\n+     * This is all sensible but it may not be right for you.\n+     */\n+    public final long localToSensibleUtc(long localMillis) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9ccecd72a01ffbae05cc0db601da8105184e9f3e"}, "originalPosition": 180}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg2NjAwNw==", "bodyText": "Do you need to special-case this here? We handle the more general case that the zone is fixed in the given range in the caller.", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412866007", "createdAt": "2020-04-22T10:32:06Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/common/LocalTimeOffset.java", "diffHunk": "@@ -0,0 +1,679 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.common;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.ZoneId;\n+import java.time.zone.ZoneOffsetTransition;\n+import java.time.zone.ZoneOffsetTransitionRule;\n+import java.time.zone.ZoneRules;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Locale;\n+\n+/**\n+ * Converts utc into local time and back again.\n+ * <p>\n+ * \"Local time\" is defined by some time zone, specifically and {@link ZoneId}.\n+ * At any point in time a particular time zone is at some offset from from\n+ * utc. So converting from utc is as simple as adding the offset.\n+ * <p>\n+ * Getting from local time back to utc is harder. Most local times happen once.\n+ * But some local times happen twice. And some don't happen at all. Take, for\n+ * example, the time in my house. Most days I don't touch my clocks and I'm a\n+ * constant offset from UTC. But once in the fall at 2am I roll my clock back.\n+ * So at 5am utc my clocks say 1am. Then at 6am utc my clocks say 1am AGAIN.\n+ * I do similarly terrifying things again in the spring when I skip my clocks\n+ * straight from 1:59am to 3am.\n+ * <p>\n+ * So there are three methods to convert from local time back to utc,\n+ * {@link #localToUtc(long, Strategy)}, {@link #localToSensibleUtc(long)} and\n+ * {@link #localToUtcInThisOffset(long)}. They are all unique and frightening.\n+ */\n+public abstract class LocalTimeOffset {\n+    /**\n+     * Lookup offsets for a provided zone. This <strong>can</strong> fail if\n+     * there are many transitions and the provided lookup would be very large.\n+     *\n+     * @return a {@linkplain Lookup} or {@code null} if none could be built \n+     */\n+    public static Lookup lookup(ZoneId zone, long minUtcMillis, long maxUtcMillis) {\n+        if (minUtcMillis > maxUtcMillis) {\n+            throw new IllegalArgumentException(\"[\" + minUtcMillis + \"] must be <= [\" + maxUtcMillis + \"]\");\n+        }\n+        ZoneRules rules = zone.getRules();\n+        {\n+            LocalTimeOffset fixed = checkForFixedZone(zone, rules);\n+            if (fixed != null) {\n+                return new FixedLookup(zone, fixed);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9ccecd72a01ffbae05cc0db601da8105184e9f3e"}, "originalPosition": 68}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "587605da6d74b8b776dd83f8d988399ff88dede2", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/587605da6d74b8b776dd83f8d988399ff88dede2", "committedDate": "2020-04-22T13:22:24Z", "message": "Default forks?"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk4MjA3OTcz", "url": "https://github.com/elastic/elasticsearch/pull/55559#pullrequestreview-398207973", "createdAt": "2020-04-22T13:46:51Z", "commit": {"oid": "9ccecd72a01ffbae05cc0db601da8105184e9f3e"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxMzo0Njo1MlrOGJ3Wow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxNDowMTozNVrOGJ4HOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjk5NzI4Mw==", "bodyText": "Nit: can this be private?", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412997283", "createdAt": "2020-04-22T13:46:52Z", "author": {"login": "not-napoleon"}, "path": "server/src/main/java/org/elasticsearch/search/aggregations/support/CoreValuesSourceType.java", "diffHunk": "@@ -232,7 +239,45 @@ public ValuesSource getScript(AggregationScript.LeafFactory script, ValueType sc\n \n         @Override\n         public ValuesSource getField(FieldContext fieldContext, AggregationScript.LeafFactory script) {\n-            return NUMERIC.getField(fieldContext, script);\n+            ValuesSource.Numeric dataSource = fieldData(fieldContext);\n+            if (script != null) {\n+                // Value script case\n+                return new ValuesSource.Numeric.WithScript(dataSource, script);\n+            }\n+            return dataSource;\n+        }\n+\n+        ValuesSource.Numeric fieldData(FieldContext fieldContext) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9ccecd72a01ffbae05cc0db601da8105184e9f3e"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjk5OTY2Nw==", "bodyText": "Maybe a comment here that about what conditions are required to apply the optimziation?", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412999667", "createdAt": "2020-04-22T13:49:37Z", "author": {"login": "not-napoleon"}, "path": "server/src/main/java/org/elasticsearch/search/aggregations/support/CoreValuesSourceType.java", "diffHunk": "@@ -232,7 +239,45 @@ public ValuesSource getScript(AggregationScript.LeafFactory script, ValueType sc\n \n         @Override\n         public ValuesSource getField(FieldContext fieldContext, AggregationScript.LeafFactory script) {\n-            return NUMERIC.getField(fieldContext, script);\n+            ValuesSource.Numeric dataSource = fieldData(fieldContext);\n+            if (script != null) {\n+                // Value script case\n+                return new ValuesSource.Numeric.WithScript(dataSource, script);\n+            }\n+            return dataSource;\n+        }\n+\n+        ValuesSource.Numeric fieldData(FieldContext fieldContext) {\n+            if ((fieldContext.indexFieldData() instanceof IndexNumericFieldData) == false) {\n+                throw new IllegalArgumentException(\"Expected numeric type on field [\" + fieldContext.field() +\n+                    \"], but got [\" + fieldContext.fieldType().typeName() + \"]\");\n+            }\n+            if (fieldContext.fieldType().indexOptions() == IndexOptions.NONE", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9ccecd72a01ffbae05cc0db601da8105184e9f3e"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzAwNTE4OQ==", "bodyText": "I think the anonymous class is fine for now, but adds to my growing belief that. dates should have their own ValuesSource.  IDK, need to think about it more.", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r413005189", "createdAt": "2020-04-22T13:56:13Z", "author": {"login": "not-napoleon"}, "path": "server/src/main/java/org/elasticsearch/search/aggregations/support/CoreValuesSourceType.java", "diffHunk": "@@ -232,7 +239,45 @@ public ValuesSource getScript(AggregationScript.LeafFactory script, ValueType sc\n \n         @Override\n         public ValuesSource getField(FieldContext fieldContext, AggregationScript.LeafFactory script) {\n-            return NUMERIC.getField(fieldContext, script);\n+            ValuesSource.Numeric dataSource = fieldData(fieldContext);\n+            if (script != null) {\n+                // Value script case\n+                return new ValuesSource.Numeric.WithScript(dataSource, script);\n+            }\n+            return dataSource;\n+        }\n+\n+        ValuesSource.Numeric fieldData(FieldContext fieldContext) {\n+            if ((fieldContext.indexFieldData() instanceof IndexNumericFieldData) == false) {\n+                throw new IllegalArgumentException(\"Expected numeric type on field [\" + fieldContext.field() +\n+                    \"], but got [\" + fieldContext.fieldType().typeName() + \"]\");\n+            }\n+            if (fieldContext.fieldType().indexOptions() == IndexOptions.NONE\n+                    || fieldContext.fieldType() instanceof DateFieldType == false) {\n+                return new ValuesSource.Numeric.FieldData((IndexNumericFieldData) fieldContext.indexFieldData());\n+            }\n+            return new ValuesSource.Numeric.FieldData((IndexNumericFieldData) fieldContext.indexFieldData()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9ccecd72a01ffbae05cc0db601da8105184e9f3e"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzAwNjY0Mg==", "bodyText": "Do we still have tests that demonstrate correctness when only using doc values?", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r413006642", "createdAt": "2020-04-22T13:57:58Z", "author": {"login": "not-napoleon"}, "path": "server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java", "diffHunk": "@@ -50,7 +50,6 @@\n public class DateHistogramAggregatorTests extends AggregatorTestCase {\n \n     private static final String DATE_FIELD = \"date\";\n-    private static final String INSTANT_FIELD = \"instant\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjUzNzk1Nw=="}, "originalCommit": {"oid": "6be2d0681aabd102170b78a1a70d5336b7d485e9"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzAwOTcyMg==", "bodyText": "Maybe I just haven't had enough coffee, but it's not clear to me why we can't just pass in the already prepared rounding, instead of passing in the reader and doing the prepare call here.  We have a roundingPreparer method on the base ValuesSource class, so we shouldn't need to cast before calling.", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r413009722", "createdAt": "2020-04-22T14:01:35Z", "author": {"login": "not-napoleon"}, "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregator.java", "diffHunk": "@@ -63,22 +67,22 @@\n \n     private final LongHash bucketOrds;\n \n-    DateHistogramAggregator(String name, AggregatorFactories factories, Rounding rounding, Rounding shardRounding,\n+    DateHistogramAggregator(String name, AggregatorFactories factories, Rounding rounding, Rounding shardRounding, IndexReader reader,\n             BucketOrder order, boolean keyed,\n-            long minDocCount, @Nullable ExtendedBounds extendedBounds, @Nullable ValuesSource.Numeric valuesSource,\n+            long minDocCount, @Nullable ExtendedBounds extendedBounds, @Nullable ValuesSource valuesSource,\n             DocValueFormat formatter, SearchContext aggregationContext,\n             Aggregator parent, Map<String, Object> metadata) throws IOException {\n \n         super(name, factories, aggregationContext, parent, metadata);\n         this.rounding = rounding;\n-        this.shardRounding = shardRounding;\n         this.order = order;\n         order.validate(this);\n         this.keyed = keyed;\n         this.minDocCount = minDocCount;\n         this.extendedBounds = extendedBounds;\n-        this.valuesSource = valuesSource;\n+        this.valuesSource = (ValuesSource.Numeric) valuesSource;\n         this.formatter = formatter;\n+        this.preparedRounding = reader == null ? null : this.valuesSource.roundingPreparer(reader).apply(shardRounding);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9ccecd72a01ffbae05cc0db601da8105184e9f3e"}, "originalPosition": 43}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8fbeb0b298f301038ee2a2ce1b3e1dfd30890960", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/8fbeb0b298f301038ee2a2ce1b3e1dfd30890960", "committedDate": "2020-04-22T14:39:34Z", "message": "More clear"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dcc3b5b3a68d1ea63b6901ae671c6a4c9f088e7a", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/dcc3b5b3a68d1ea63b6901ae671c6a4c9f088e7a", "committedDate": "2020-04-22T14:39:41Z", "message": "Preserve test without searchable field"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f646f233ee24070007945cb599e0fe97a41a10c5", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/f646f233ee24070007945cb599e0fe97a41a10c5", "committedDate": "2020-04-22T14:45:23Z", "message": "Prepare rounding in factory"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "587a6cdcb0f202a17799d4d62caefd693ed17c34", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/587a6cdcb0f202a17799d4d62caefd693ed17c34", "committedDate": "2020-04-22T14:49:29Z", "message": "Comment on why optimization can't work here"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "22239668ebedcbc2b08012e4fdcc9bff70c242d2", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/22239668ebedcbc2b08012e4fdcc9bff70c242d2", "committedDate": "2020-04-22T14:50:27Z", "message": "line length"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c07350143d4b705c85381ee2e3c35bebda0025ed", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/c07350143d4b705c85381ee2e3c35bebda0025ed", "committedDate": "2020-04-22T15:03:46Z", "message": "Different counts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b53b59dce418b3c6acb741974a9b1f9ab4929f63", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/b53b59dce418b3c6acb741974a9b1f9ab4929f63", "committedDate": "2020-04-22T15:18:22Z", "message": "Private!"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5ba5dc7da64e74d80c1084384e3efc793ed65f98", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/5ba5dc7da64e74d80c1084384e3efc793ed65f98", "committedDate": "2020-04-22T15:30:04Z", "message": "Tests in the future!"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dd0d16e482b6e91c6fef4919c0e5a01912c387e1", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/dd0d16e482b6e91c6fef4919c0e5a01912c387e1", "committedDate": "2020-04-22T15:44:39Z", "message": "Nothing is sensible"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c8fcdd010cf0b1f453e653537930943c76385998", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/c8fcdd010cf0b1f453e653537930943c76385998", "committedDate": "2020-04-22T16:22:07Z", "message": "Merge branch 'master' into tz_round"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk5MTUwNTY5", "url": "https://github.com/elastic/elasticsearch/pull/55559#pullrequestreview-399150569", "createdAt": "2020-04-23T14:24:18Z", "commit": {"oid": "c8fcdd010cf0b1f453e653537930943c76385998"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QxNDoyNDoxOFrOGKq0pA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QxNDoyNDoxOFrOGKq0pA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzg0MDU0OA==", "bodyText": "After sleeping on it, I've come to think that having the default here is wrong.  I think we should either make this abstract and require each specific ValuesSource to specify if they round or not, or at a minimum make the default to throw and let ValuesSources that support rounding override it.  Otherwise, people writing new ValuesSources need to know that if they aren't going to support rounding, they need to have an override, which is counter intuitive IMHO.", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r413840548", "createdAt": "2020-04-23T14:24:18Z", "author": {"login": "not-napoleon"}, "path": "server/src/main/java/org/elasticsearch/search/aggregations/support/ValuesSource.java", "diffHunk": "@@ -74,6 +77,16 @@ public boolean needsScores() {\n         return false;\n     }\n \n+    /**\n+     * Build a function prepares rounding values to be called many times.\n+     * <p>\n+     * This returns a {@linkplain Function} because auto date histogram will\n+     * need to call it many times over the course of running the aggregation.\n+     */\n+    public Function<Rounding, Rounding.Prepared> roundingPreparer(IndexReader reader) throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c8fcdd010cf0b1f453e653537930943c76385998"}, "originalPosition": 43}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b3538a146bbbba57b4cdb705d403bf13e900a0f1", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/b3538a146bbbba57b4cdb705d403bf13e900a0f1", "committedDate": "2020-04-23T15:56:50Z", "message": "Merge branch 'master' into tz_round"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "675fc07e51687fa7bcbb9714149e978c3c455a95", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/675fc07e51687fa7bcbb9714149e978c3c455a95", "committedDate": "2020-04-23T16:15:29Z", "message": "abstract"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "28a10abe1b826141db1e9c7d0e529c98694496db", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/28a10abe1b826141db1e9c7d0e529c98694496db", "committedDate": "2020-04-24T14:11:46Z", "message": "tMerge branch 'master' into tz_round"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ede9cbc8e1b748c0ed1b563b887ff70b555020b7", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/ede9cbc8e1b748c0ed1b563b887ff70b555020b7", "committedDate": "2020-04-28T14:18:06Z", "message": "Merge branch 'master' into tz_round"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8e52138b68ce17f25044645fbdf5eb4d526921cf", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/8e52138b68ce17f25044645fbdf5eb4d526921cf", "committedDate": "2020-04-28T18:34:22Z", "message": "Merge branch 'master' into tz_round"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "44424ea98300fef5eb9b863f7577572cc8a1fef2", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/44424ea98300fef5eb9b863f7577572cc8a1fef2", "committedDate": "2020-04-28T22:06:45Z", "message": "Fix merge mistake"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "83e9ecc5a615f5e36a44138175bc81cb004fd026", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/83e9ecc5a615f5e36a44138175bc81cb004fd026", "committedDate": "2020-04-29T14:52:59Z", "message": "Merge branch 'master' into tz_round"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7551cbc93a90fbdfc1b8a85f7a3bc407ece13707", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/7551cbc93a90fbdfc1b8a85f7a3bc407ece13707", "committedDate": "2020-04-29T15:23:43Z", "message": "Merge branch 'master' into tz_round"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAyOTUyNTE4", "url": "https://github.com/elastic/elasticsearch/pull/55559#pullrequestreview-402952518", "createdAt": "2020-04-29T18:59:43Z", "commit": {"oid": "7551cbc93a90fbdfc1b8a85f7a3bc407ece13707"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxODo1OTo0M1rOGOMwqQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxODo1OTo0M1rOGOMwqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzU0MjMxMw==", "bodyText": "I merged #55687 to wire AutoDateHistogram up to the ValuesSourceRegistry.", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r417542313", "createdAt": "2020-04-29T18:59:43Z", "author": {"login": "not-napoleon"}, "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/AutoDateHistogramAggregatorFactory.java", "diffHunk": "@@ -76,15 +77,16 @@ protected Aggregator doCreateInternal(ValuesSource valuesSource,\n             throw new AggregationExecutionException(\"Registry miss-match - expected AutoDateHistogramAggregationSupplier, found [\" +\n                 aggregatorSupplier.getClass().toString() + \"]\");\n         }\n-        return ((AutoDateHistogramAggregatorSupplier) aggregatorSupplier).build(name, factories, numBuckets, roundingInfos, valuesSource,\n-            config.format(), searchContext, parent, metadata);\n+        return ((AutoDateHistogramAggregatorSupplier) aggregatorSupplier).build(name, factories, numBuckets, roundingInfos,\n+            // TODO once auto date histo is plugged into the ValuesSource refactoring use the date values source", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7551cbc93a90fbdfc1b8a85f7a3bc407ece13707"}, "originalPosition": 15}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA2NDEyNzQ1", "url": "https://github.com/elastic/elasticsearch/pull/55559#pullrequestreview-406412745", "createdAt": "2020-05-06T08:45:40Z", "commit": {"oid": "7551cbc93a90fbdfc1b8a85f7a3bc407ece13707"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNlQwODo0NTo0MVrOGRJeCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNlQwODo0NTo0MVrOGRJeCA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDYzNDEyMA==", "bodyText": "I ran the microbenchmarks again once with your implementation and once with a cheaper version of Blackhole (calling a method that is not inlined) and there are cases where the score is vastly different, e.g.:\nsum (your approach):\nBenchmark                                                               (count)                   (range)  (rounder)     (timeUnit)            (zone)  Mode  Cnt            Score            Error   Units\nRoundingBenchmark.round                                               100000000  2000-06-01 to 2000-06-02  java time    HOUR_OF_DAY               UTC  avgt   10   5468296772.000 \u00b1   13822182.335   ns/op\nRoundingBenchmark.round                                               100000000  2000-06-01 to 2000-06-02         es    HOUR_OF_DAY               UTC  avgt   10    949419080.100 \u00b1    2728670.015   ns/op\nRoundingBenchmark.round                                               100000000  2000-06-01 to 2000-06-02  java time    HOUR_OF_DAY  America/New_York  avgt   10  13193144584.600 \u00b1   86152570.014   ns/op\nRoundingBenchmark.round                                               100000000  2000-06-01 to 2000-06-02         es    HOUR_OF_DAY  America/New_York  avgt   10    947821052.350 \u00b1    6119635.225   ns/op\n\ndon't inline:\nBenchmark                                                               (count)                   (range)  (rounder)     (timeUnit)            (zone)  Mode  Cnt            Score            Error   Units\nRoundingBenchmark.round                                               100000000  2000-06-01 to 2000-06-02  java time    HOUR_OF_DAY               UTC  avgt   10   5559418450.700 \u00b1    3268596.659   ns/op\nRoundingBenchmark.round                                               100000000  2000-06-01 to 2000-06-02         es    HOUR_OF_DAY               UTC  avgt   10   1363302403.000 \u00b1   16780559.912   ns/op\nRoundingBenchmark.round                                               100000000  2000-06-01 to 2000-06-02  java time    HOUR_OF_DAY  America/New_York  avgt   10  13554514668.900 \u00b1   25928733.412   ns/op\nRoundingBenchmark.round                                               100000000  2000-06-01 to 2000-06-02         es    HOUR_OF_DAY  America/New_York  avgt   10   1354972403.700 \u00b1   15574272.765   ns/op\n\nThis means that in some cases your microbenchmark implementation shows numbers that are e.g. in the last case in the table above ~ 1.4 times faster than they are if we don't inline which is more likely in production code. We do see a significant speedup compared to the original implementation in both microbenchmark approaches anyway so I think the actual change makes sense. It's just that the change is probably slightly less pronounced in practice than the microbenchmarks indicate.", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r420634120", "createdAt": "2020-05-06T08:45:41Z", "author": {"login": "danielmitterdorfer"}, "path": "benchmarks/src/main/java/org/elasticsearch/common/RoundingBenchmark.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.common;\n+\n+import org.elasticsearch.common.time.DateFormatter;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.Warmup;\n+\n+import java.time.ZoneId;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+@Fork(1)\n+@Warmup(iterations = 5)\n+@Measurement(iterations = 3)\n+@BenchmarkMode(Mode.AverageTime)\n+@OutputTimeUnit(TimeUnit.NANOSECONDS)\n+@State(Scope.Benchmark)\n+public class RoundingBenchmark {\n+    private static final DateFormatter FORMATTER = DateFormatter.forPattern(\"date_optional_time\");\n+\n+    @Param({\n+        \"2000-01-01 to 2020-01-01\", // A super long range\n+        \"2000-10-01 to 2000-11-01\", // A whole month which is pretty believable\n+        \"2000-10-29 to 2000-10-30\", // A date right around daylight savings time.\n+        \"2000-06-01 to 2000-06-02\"  // A date fully in one time zone. Should be much faster than above.\n+    })\n+    public String range;\n+\n+    @Param({ \"java time\", \"es\" })\n+    public String rounder;\n+\n+    @Param({ \"UTC\", \"America/New_York\" })\n+    public String zone;\n+\n+    @Param({ \"MONTH_OF_YEAR\", \"HOUR_OF_DAY\" })\n+    public String timeUnit;\n+\n+    @Param({ \"1\", \"1000000\" })\n+    public int count;\n+\n+    private long min;\n+    private long max;\n+    private long[] dates;\n+    private Supplier<Rounding.Prepared> rounderBuilder;\n+\n+    @Setup\n+    public void buildDates() {\n+        String[] r = range.split(\" to \");\n+        min = FORMATTER.parseMillis(r[0]);\n+        max = FORMATTER.parseMillis(r[1]);\n+        dates = new long[count];\n+        long date = min;\n+        long diff = (max - min) / dates.length;\n+        for (int i = 0; i < dates.length; i++) {\n+            if (date >= max) {\n+                throw new IllegalStateException(\"made a bad date [\" + date + \"]\");\n+            }\n+            dates[i] = date;\n+            date += diff;\n+        }\n+        Rounding rounding = Rounding.builder(Rounding.DateTimeUnit.valueOf(timeUnit)).timeZone(ZoneId.of(zone)).build();\n+        switch (rounder) {\n+            case \"java time\":\n+                rounderBuilder = rounding::prepareJavaTime;\n+                break;\n+            case \"es\":\n+                rounderBuilder = () -> rounding.prepare(min, max);\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Expectd rounder to be [java time] or [es]\");\n+        }\n+    }\n+\n+    @Benchmark\n+    public long round() {\n+        long sum = 0;\n+        Rounding.Prepared rounder = rounderBuilder.get();\n+        for (int i = 0; i < dates.length; i++) {\n+            sum += rounder.round(dates[i]);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc2MDU1NA=="}, "originalCommit": {"oid": "9ccecd72a01ffbae05cc0db601da8105184e9f3e"}, "originalPosition": 106}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "986afab9e090c8e5ac3a9a1e4933239742e570ec", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/986afab9e090c8e5ac3a9a1e4933239742e570ec", "committedDate": "2020-05-06T12:24:42Z", "message": "Merge branch 'master' into tz_round"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9d5c1c510bc3764d0a80116695bcbe3af7c424b8", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/9d5c1c510bc3764d0a80116695bcbe3af7c424b8", "committedDate": "2020-05-06T12:32:18Z", "message": "Blackhole"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "83e72eda6ab615aeeb91c406701d0790c893f43e", "author": {"user": {"login": "nik9000", "name": "Nik Everett"}}, "url": "https://github.com/elastic/elasticsearch/commit/83e72eda6ab615aeeb91c406701d0790c893f43e", "committedDate": "2020-05-06T21:15:39Z", "message": "Merge branch 'master' into tz_round"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 655, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}