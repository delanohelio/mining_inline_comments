{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMxNzU5Nzg3", "number": 57875, "title": "Use Search After job iterators", "bodyText": "The changes made in #57337 have a few shortcomings:\n\nUsing scrolled searches is not safe if processing the search results takes a long time as the scroll context will expire.\n\nIn the case of deleting expired data, if there are > 10,000 jobs then processing those will almost certainly time out the scroll context (5 minutes). The first part of this change is to add a class SearchAfterDocumentsIterator similar in function to the BatchedDocumentsIterator but uses search after instead of scroll.\n\nA bad job Id in the delete expired data request will not return a 404 if the job does not exist.  This is a leniency we always try to avoid.\n\nThe problem is that the check that a job is present can only take place for a single search response not for multiple responses, this is how JobConfigProvider works.\nTheoretically for the job id expression bar-*,foo if there are more than 10,000 bar-* jobs then foo would come in the second page but the ExpandedIdsMatcher would throw because foo is not in the results. This is a known limitation.\nIn order to get the behaviour that a bad job Id should throw a ResourceNotFoundException I've used the JobConfigProvider if the request uses a job Id that is not *, _all or null/empty. When all jobs are requested the SearchAfterJobsIterator is used.", "createdAt": "2020-06-09T12:33:09Z", "url": "https://github.com/elastic/elasticsearch/pull/57875", "merged": true, "mergeCommit": {"oid": "96a6de22d9003763202e56b7fe324e2aae70f215"}, "closed": true, "closedAt": "2020-06-10T08:53:23Z", "author": {"login": "davidkyle"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcplbvhAFqTQyNzE2ODE1OQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcprhQOgFqTQyNzU0MDg1Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI3MTY4MTU5", "url": "https://github.com/elastic/elasticsearch/pull/57875#pullrequestreview-427168159", "createdAt": "2020-06-09T13:47:56Z", "commit": {"oid": "83313a84ef11c2d9becc25848d5ed669d090605c"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQxMzo0Nzo1N1rOGhKyfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQxMzo1MTowM1rOGhK_ZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzQzMjk1OQ==", "bodyText": "We only need total hits for the first query. Would be good to have this be false once we have the total hits recorded.", "url": "https://github.com/elastic/elasticsearch/pull/57875#discussion_r437432959", "createdAt": "2020-06-09T13:47:57Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/utils/persistence/SearchAfterDocumentsIterator.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.utils.persistence;\n+\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.client.OriginSettingClient;\n+import org.elasticsearch.index.query.QueryBuilder;\n+import org.elasticsearch.search.SearchHit;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.xpack.ml.utils.MlIndicesUtils;\n+\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import java.util.NoSuchElementException;\n+import java.util.Objects;\n+\n+/**\n+ * An iterator useful to fetch a large number of documents of type T\n+ * and iterate through them in batches of 10,000.\n+ *\n+ * In terms of functionality this is very similar to {@link BatchedDocumentsIterator}\n+ * the difference being that this uses search after rather than scroll.\n+ *\n+ * Search after has the advantage that the scroll context does not have to be kept\n+ * alive so if processing each batch takes a long time search after should be\n+ * preferred to scroll.\n+ */\n+public abstract class SearchAfterDocumentsIterator<T> implements BatchedIterator<T> {\n+\n+    private static final int BATCH_SIZE = 10_000;\n+\n+    private final OriginSettingClient client;\n+    private final String index;\n+    private volatile long count;\n+    private volatile long totalHits;\n+\n+    protected SearchAfterDocumentsIterator(OriginSettingClient client, String index) {\n+        this.client = Objects.requireNonNull(client);\n+        this.index = Objects.requireNonNull(index);\n+        this.totalHits = -1;\n+        this.count = 0;\n+    }\n+\n+    /**\n+     * Returns {@code true} if the iteration has more elements or\n+     * no searches have been been run and it is unknown if there is a next.\n+     *\n+     * @return {@code true} if the iteration has more elements or the first\n+     * search has not been run\n+     */\n+    @Override\n+    public boolean hasNext() {\n+        return count != totalHits;\n+    }\n+\n+    /**\n+     * The first time next() is called, the search will be performed and the first\n+     * batch will be returned. Any subsequent call will return the following batches.\n+     * <p>\n+     * Note that in some implementations it is possible that when there are no\n+     * results at all, the first time this method is called an empty {@code Deque} is returned.\n+     *\n+     * @return a {@code Deque} with the next batch of documents\n+     * @throws NoSuchElementException if the iteration has no more elements\n+     */\n+    @Override\n+    public Deque<T> next() {\n+        if (!hasNext()) {\n+            throw new NoSuchElementException();\n+        }\n+\n+        SearchResponse searchResponse;\n+        if (totalHits == -1) {\n+            searchResponse = initSearch();\n+        } else {\n+            searchResponse = doSearch(searchAfterFields());\n+        }\n+        return mapHits(searchResponse);\n+    }\n+\n+    private SearchResponse initSearch() {\n+        SearchResponse searchResponse = doSearch(null);\n+        totalHits = searchResponse.getHits().getTotalHits().value;\n+        return searchResponse;\n+    }\n+\n+    private SearchResponse doSearch(Object [] searchAfterValues) {\n+        SearchRequest searchRequest = new SearchRequest(index);\n+        searchRequest.indicesOptions(MlIndicesUtils.addIgnoreUnavailable(SearchRequest.DEFAULT_INDICES_OPTIONS));\n+        SearchSourceBuilder sourceBuilder = (new SearchSourceBuilder()\n+            .size(BATCH_SIZE)\n+            .query(getQuery())\n+            .fetchSource(shouldFetchSource())\n+            .trackTotalHits(true)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "83313a84ef11c2d9becc25848d5ed669d090605c"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzQzNjI2MQ==", "bodyText": "Does search after protect us from new docs being added?\nIt seems to me that there is a possibility of count > totalHits if new documents are added + the index is refreshed.\nIt might be good to have this as count <= totalHits as adjust the initial values + initialization of values accordingly.", "url": "https://github.com/elastic/elasticsearch/pull/57875#discussion_r437436261", "createdAt": "2020-06-09T13:51:03Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/utils/persistence/SearchAfterDocumentsIterator.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.utils.persistence;\n+\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.client.OriginSettingClient;\n+import org.elasticsearch.index.query.QueryBuilder;\n+import org.elasticsearch.search.SearchHit;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.xpack.ml.utils.MlIndicesUtils;\n+\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import java.util.NoSuchElementException;\n+import java.util.Objects;\n+\n+/**\n+ * An iterator useful to fetch a large number of documents of type T\n+ * and iterate through them in batches of 10,000.\n+ *\n+ * In terms of functionality this is very similar to {@link BatchedDocumentsIterator}\n+ * the difference being that this uses search after rather than scroll.\n+ *\n+ * Search after has the advantage that the scroll context does not have to be kept\n+ * alive so if processing each batch takes a long time search after should be\n+ * preferred to scroll.\n+ */\n+public abstract class SearchAfterDocumentsIterator<T> implements BatchedIterator<T> {\n+\n+    private static final int BATCH_SIZE = 10_000;\n+\n+    private final OriginSettingClient client;\n+    private final String index;\n+    private volatile long count;\n+    private volatile long totalHits;\n+\n+    protected SearchAfterDocumentsIterator(OriginSettingClient client, String index) {\n+        this.client = Objects.requireNonNull(client);\n+        this.index = Objects.requireNonNull(index);\n+        this.totalHits = -1;\n+        this.count = 0;\n+    }\n+\n+    /**\n+     * Returns {@code true} if the iteration has more elements or\n+     * no searches have been been run and it is unknown if there is a next.\n+     *\n+     * @return {@code true} if the iteration has more elements or the first\n+     * search has not been run\n+     */\n+    @Override\n+    public boolean hasNext() {\n+        return count != totalHits;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "83313a84ef11c2d9becc25848d5ed669d090605c"}, "originalPosition": 59}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d16bc5c141f73c840ded9c6cf842d5f1892673fe", "author": {"user": {"login": "davidkyle", "name": "David Kyle"}}, "url": "https://github.com/elastic/elasticsearch/commit/d16bc5c141f73c840ded9c6cf842d5f1892673fe", "committedDate": "2020-06-09T17:02:40Z", "message": "WIP"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3cc6d16c65c651a969ff33bebb89123ccec051dd", "author": {"user": {"login": "davidkyle", "name": "David Kyle"}}, "url": "https://github.com/elastic/elasticsearch/commit/3cc6d16c65c651a969ff33bebb89123ccec051dd", "committedDate": "2020-06-09T17:02:40Z", "message": "Add SearchAfterDocumentsIterator"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c95ca06e8c631034617c0e33bd3e155e3eba849c", "author": {"user": {"login": "davidkyle", "name": "David Kyle"}}, "url": "https://github.com/elastic/elasticsearch/commit/c95ca06e8c631034617c0e33bd3e155e3eba849c", "committedDate": "2020-06-09T17:02:40Z", "message": "Use search after iterator in expired data removers"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e4b995c8cdb4aa861da753a0a8e7230bc9df752e", "author": {"user": {"login": "davidkyle", "name": "David Kyle"}}, "url": "https://github.com/elastic/elasticsearch/commit/e4b995c8cdb4aa861da753a0a8e7230bc9df752e", "committedDate": "2020-06-09T17:02:40Z", "message": "Expand jobs with config porovider"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "24fde634aeddb34daca0141a5b45d0493c45d193", "author": {"user": {"login": "davidkyle", "name": "David Kyle"}}, "url": "https://github.com/elastic/elasticsearch/commit/24fde634aeddb34daca0141a5b45d0493c45d193", "committedDate": "2020-06-09T17:02:40Z", "message": "Remove unused class"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "22b320c5c933c9f50234a302d867983fbeaa3b9a", "author": {"user": {"login": "davidkyle", "name": "David Kyle"}}, "url": "https://github.com/elastic/elasticsearch/commit/22b320c5c933c9f50234a302d867983fbeaa3b9a", "committedDate": "2020-06-09T17:02:40Z", "message": "Fix yml test match"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "87d25f17cfcd69634b48321dbc833b0adb30a283", "author": {"user": {"login": "davidkyle", "name": "David Kyle"}}, "url": "https://github.com/elastic/elasticsearch/commit/87d25f17cfcd69634b48321dbc833b0adb30a283", "committedDate": "2020-06-09T19:25:20Z", "message": "Use number of search results to determine hasNext"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "83313a84ef11c2d9becc25848d5ed669d090605c", "author": {"user": {"login": "davidkyle", "name": "David Kyle"}}, "url": "https://github.com/elastic/elasticsearch/commit/83313a84ef11c2d9becc25848d5ed669d090605c", "committedDate": "2020-06-09T12:32:07Z", "message": "Fix yml test match"}, "afterCommit": {"oid": "87d25f17cfcd69634b48321dbc833b0adb30a283", "author": {"user": {"login": "davidkyle", "name": "David Kyle"}}, "url": "https://github.com/elastic/elasticsearch/commit/87d25f17cfcd69634b48321dbc833b0adb30a283", "committedDate": "2020-06-09T19:25:20Z", "message": "Use number of search results to determine hasNext"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI3NTQwODUy", "url": "https://github.com/elastic/elasticsearch/pull/57875#pullrequestreview-427540852", "createdAt": "2020-06-09T20:59:13Z", "commit": {"oid": "87d25f17cfcd69634b48321dbc833b0adb30a283"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 821, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}