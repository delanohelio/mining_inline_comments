{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzczNzMzNzQy", "number": 52218, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QxNDoxMjo0M1rODfj2HQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QxNDo1NTo1M1rODfk5pg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM0NDE5NzQxOnYy", "diffSide": "RIGHT", "path": "docs/reference/ingest/processors/inference.asciidoc", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QxNDoxMjo0M1rOFpVPVw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QxNDoxMjo0M1rOFpVPVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODg4MzkyNw==", "bodyText": "You might be able to use the macro from https://github.com/elastic/elasticsearch/pull/52283/files#diff-876579125ed69329aeee2dff00706206R909 to avoid duplicating this text.", "url": "https://github.com/elastic/elasticsearch/pull/52218#discussion_r378883927", "createdAt": "2020-02-13T14:12:43Z", "author": {"login": "droberts195"}, "path": "docs/reference/ingest/processors/inference.asciidoc", "diffHunk": "@@ -44,6 +44,12 @@ include::common-options.asciidoc[]\n Specifies the field to which the inference prediction is written. Defaults to \n `predicted_value`.\n \n+`num_top_feature_importance_values`::\n+(Optional, integer)\n+If set, feature importance for the top\n+most important features will be computed. Importance is calculated\n+using the SHAP (SHapley Additive exPlanations) method as described in", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7ca4875d52c5c4f8f196907dbf8fde8af289a81b"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM0NDM3MDMwOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/tree/Tree.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QxNDo1NTo1M1rOFpW6Ug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QxNzo0Nzo0MVrOFpdgKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODkxMTMxNA==", "bodyText": "If it is possible that this can be called from two different threads around the same time then there is a bigger problem that making this synchronized will not solve.  In the private featureImportance(List<Double>, Map<String, String> featureDecoder) method above it would be possible for a simultaneous call to calculateNodeEstimatesIfNeeded() has changed maxDepth but not nodeEstimates at the time when these members are being read in featureImportance().\nIf multithreaded access to Tree objects is possible then the featureImportance(List<Double>, Map<String, String> featureDecoder) method needs to be synchronized and this method needs a comment saying it must only be called from featureImportance(List<Double>, Map<String, String> featureDecoder).  Then nodeEstimates and maxDepth wouldn't need to be volatile.", "url": "https://github.com/elastic/elasticsearch/pull/52218#discussion_r378911314", "createdAt": "2020-02-13T14:55:53Z", "author": {"login": "droberts195"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/tree/Tree.java", "diffHunk": "@@ -261,12 +267,146 @@ public void validate() {\n         detectCycle();\n     }\n \n+    @Override\n+    public Map<String, Double> featureImportance(Map<String, Object> fields, Map<String, String> featureDecoder) {\n+        if (nodes.stream().allMatch(n -> n.getNumberSamples() == 0)) {\n+            throw ExceptionsHelper.badRequestException(\"[tree_structure.number_samples] must be greater than zero for feature importance\");\n+        }\n+        List<Double> features = featureNames.stream()\n+            .map(f -> InferenceHelpers.toDouble(MapHelper.dig(f, fields)))\n+            .collect(Collectors.toList());\n+        return featureImportance(features, featureDecoder);\n+    }\n+\n+    private Map<String, Double> featureImportance(List<Double> fieldValues, Map<String, String> featureDecoder) {\n+        calculateNodeEstimatesIfNeeded();\n+        double[] featureImportance = new double[fieldValues.size()];\n+        ShapPath initialPath = new ShapPath(this.maxDepth + 1);\n+        shapRecursive(fieldValues, this.nodeEstimates, initialPath, 0, 1.0, 1.0, -1, featureImportance);\n+        return InferenceHelpers.decodeFeatureImportances(featureDecoder,\n+            IntStream.range(0, featureImportance.length)\n+                .boxed()\n+                .collect(Collectors.toMap(featureNames::get, i -> featureImportance[i])));\n+    }\n+\n+    //TODO synchronized?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7ca4875d52c5c4f8f196907dbf8fde8af289a81b"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTAxOTMwNg==", "bodyText": "@droberts195 I do think this will be accessible via multiple threads. Multiple docs can come into different pipelines on the same node referencing the same model. So, they would all hit the same instance in cache.\nI am going to get this synchronized, and also add a node to the classes saying that they must be MT safe.", "url": "https://github.com/elastic/elasticsearch/pull/52218#discussion_r379019306", "createdAt": "2020-02-13T17:47:41Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/trainedmodel/tree/Tree.java", "diffHunk": "@@ -261,12 +267,146 @@ public void validate() {\n         detectCycle();\n     }\n \n+    @Override\n+    public Map<String, Double> featureImportance(Map<String, Object> fields, Map<String, String> featureDecoder) {\n+        if (nodes.stream().allMatch(n -> n.getNumberSamples() == 0)) {\n+            throw ExceptionsHelper.badRequestException(\"[tree_structure.number_samples] must be greater than zero for feature importance\");\n+        }\n+        List<Double> features = featureNames.stream()\n+            .map(f -> InferenceHelpers.toDouble(MapHelper.dig(f, fields)))\n+            .collect(Collectors.toList());\n+        return featureImportance(features, featureDecoder);\n+    }\n+\n+    private Map<String, Double> featureImportance(List<Double> fieldValues, Map<String, String> featureDecoder) {\n+        calculateNodeEstimatesIfNeeded();\n+        double[] featureImportance = new double[fieldValues.size()];\n+        ShapPath initialPath = new ShapPath(this.maxDepth + 1);\n+        shapRecursive(fieldValues, this.nodeEstimates, initialPath, 0, 1.0, 1.0, -1, featureImportance);\n+        return InferenceHelpers.decodeFeatureImportances(featureDecoder,\n+            IntStream.range(0, featureImportance.length)\n+                .boxed()\n+                .collect(Collectors.toMap(featureNames::get, i -> featureImportance[i])));\n+    }\n+\n+    //TODO synchronized?", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODkxMTMxNA=="}, "originalCommit": {"oid": "7ca4875d52c5c4f8f196907dbf8fde8af289a81b"}, "originalPosition": 110}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4761, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}