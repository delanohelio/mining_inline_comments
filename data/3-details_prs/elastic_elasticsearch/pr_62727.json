{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDkwNTA1NzIz", "number": 62727, "title": "Cleanup Blobstore Repository Metadata Serialization", "bodyText": "Follow up to #62684 making use of shorter utility for corruption checks.", "createdAt": "2020-09-21T19:16:59Z", "url": "https://github.com/elastic/elasticsearch/pull/62727", "merged": true, "mergeCommit": {"oid": "e02555ce822ec7ba7e89a21a5415d187b9377d33"}, "closed": true, "closedAt": "2020-09-22T09:07:03Z", "author": {"login": "original-brownbear"}, "timelineItems": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdLIV6xgH2gAyNDkwNTA1NzIzOjE4MjRmYjM4NGRiZGRlMTczMDExZDRhMjI2MmVhNTM4ZGZmMGMxZWM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdLTlhdgH2gAyNDkwNTA1NzIzOmQ2ZTc4NjYyZWYxMjkyMjE5NDU1MGVmZWFhNzQ0ODcyNDM3YTMzNTU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "1824fb384dbdde173011d4a2262ea538dff0c1ec", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/1824fb384dbdde173011d4a2262ea538dff0c1ec", "committedDate": "2020-09-21T19:13:35Z", "message": "Cleanup Blobstore Repository Metadata Serialization\n\nFollow ups to #62684 making use of shorter utility for corruption checks."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkzMjAwNTA2", "url": "https://github.com/elastic/elasticsearch/pull/62727#pullrequestreview-493200506", "createdAt": "2020-09-22T07:46:02Z", "commit": {"oid": "1824fb384dbdde173011d4a2262ea538dff0c1ec"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMlQwNzo0NjowMlrOHVt6PA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMlQwNzo0NjozN1rOHVt7eA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjUzNDMzMg==", "bodyText": "I'd prefer this to be final", "url": "https://github.com/elastic/elasticsearch/pull/62727#discussion_r492534332", "createdAt": "2020-09-22T07:46:02Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardSnapshot.java", "diffHunk": "@@ -507,39 +508,36 @@ public static BlobStoreIndexShardSnapshot fromXContent(XContentParser parser) th\n         XContentParser.Token token = parser.currentToken();\n         if (token == XContentParser.Token.START_OBJECT) {\n             while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {\n-                if (token == XContentParser.Token.FIELD_NAME) {\n-                    String currentFieldName = parser.currentName();\n-                    token = parser.nextToken();\n-                    if (token.isValue()) {\n-                        if (PARSE_NAME.match(currentFieldName, parser.getDeprecationHandler())) {\n-                            snapshot = parser.text();\n-                        } else if (PARSE_INDEX_VERSION.match(currentFieldName, parser.getDeprecationHandler())) {\n-                            // The index-version is needed for backward compatibility with v 1.0\n-                            indexVersion = parser.longValue();\n-                        } else if (PARSE_START_TIME.match(currentFieldName, parser.getDeprecationHandler())) {\n-                            startTime = parser.longValue();\n-                        } else if (PARSE_TIME.match(currentFieldName, parser.getDeprecationHandler())) {\n-                            time = parser.longValue();\n-                        } else if (PARSE_INCREMENTAL_FILE_COUNT.match(currentFieldName, parser.getDeprecationHandler())) {\n-                            incrementalFileCount = parser.intValue();\n-                        } else if (PARSE_INCREMENTAL_SIZE.match(currentFieldName, parser.getDeprecationHandler())) {\n-                            incrementalSize = parser.longValue();\n-                        } else {\n-                            throw new ElasticsearchParseException(\"unknown parameter [{}]\", currentFieldName);\n-                        }\n-                    } else if (token == XContentParser.Token.START_ARRAY) {\n-                        if (PARSE_FILES.match(currentFieldName, parser.getDeprecationHandler())) {\n-                            while ((parser.nextToken()) != XContentParser.Token.END_ARRAY) {\n-                                indexFiles.add(FileInfo.fromXContent(parser));\n-                            }\n-                        } else {\n-                            throw new ElasticsearchParseException(\"unknown parameter [{}]\", currentFieldName);\n+                XContentParserUtils.ensureExpectedToken(XContentParser.Token.FIELD_NAME, token, parser);\n+                String currentFieldName = parser.currentName();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1824fb384dbdde173011d4a2262ea538dff0c1ec"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjUzNDY0OA==", "bodyText": "Do you really prefer with an extra space? :)", "url": "https://github.com/elastic/elasticsearch/pull/62727#discussion_r492534648", "createdAt": "2020-09-22T07:46:37Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardSnapshot.java", "diffHunk": "@@ -507,39 +508,36 @@ public static BlobStoreIndexShardSnapshot fromXContent(XContentParser parser) th\n         XContentParser.Token token = parser.currentToken();\n         if (token == XContentParser.Token.START_OBJECT) {\n             while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {\n-                if (token == XContentParser.Token.FIELD_NAME) {\n-                    String currentFieldName = parser.currentName();\n-                    token = parser.nextToken();\n-                    if (token.isValue()) {\n-                        if (PARSE_NAME.match(currentFieldName, parser.getDeprecationHandler())) {\n-                            snapshot = parser.text();\n-                        } else if (PARSE_INDEX_VERSION.match(currentFieldName, parser.getDeprecationHandler())) {\n-                            // The index-version is needed for backward compatibility with v 1.0\n-                            indexVersion = parser.longValue();\n-                        } else if (PARSE_START_TIME.match(currentFieldName, parser.getDeprecationHandler())) {\n-                            startTime = parser.longValue();\n-                        } else if (PARSE_TIME.match(currentFieldName, parser.getDeprecationHandler())) {\n-                            time = parser.longValue();\n-                        } else if (PARSE_INCREMENTAL_FILE_COUNT.match(currentFieldName, parser.getDeprecationHandler())) {\n-                            incrementalFileCount = parser.intValue();\n-                        } else if (PARSE_INCREMENTAL_SIZE.match(currentFieldName, parser.getDeprecationHandler())) {\n-                            incrementalSize = parser.longValue();\n-                        } else {\n-                            throw new ElasticsearchParseException(\"unknown parameter [{}]\", currentFieldName);\n-                        }\n-                    } else if (token == XContentParser.Token.START_ARRAY) {\n-                        if (PARSE_FILES.match(currentFieldName, parser.getDeprecationHandler())) {\n-                            while ((parser.nextToken()) != XContentParser.Token.END_ARRAY) {\n-                                indexFiles.add(FileInfo.fromXContent(parser));\n-                            }\n-                        } else {\n-                            throw new ElasticsearchParseException(\"unknown parameter [{}]\", currentFieldName);\n+                XContentParserUtils.ensureExpectedToken(XContentParser.Token.FIELD_NAME, token, parser);\n+                String currentFieldName = parser.currentName();\n+                token = parser.nextToken();\n+                if (token.isValue()) {\n+                    if (PARSE_NAME.match(currentFieldName, parser.getDeprecationHandler())) {\n+                        snapshot = parser.text();\n+                    } else if (PARSE_INDEX_VERSION.match(currentFieldName, parser.getDeprecationHandler())) {\n+                        // The index-version is needed for backward compatibility with v 1.0\n+                        indexVersion = parser.longValue();\n+                    } else if (PARSE_START_TIME.match(currentFieldName, parser.getDeprecationHandler())) {\n+                        startTime = parser.longValue();\n+                    } else if (PARSE_TIME.match(currentFieldName, parser.getDeprecationHandler())) {\n+                        time = parser.longValue();\n+                    } else if (PARSE_INCREMENTAL_FILE_COUNT.match(currentFieldName, parser.getDeprecationHandler())) {\n+                        incrementalFileCount = parser.intValue();\n+                    } else if (PARSE_INCREMENTAL_SIZE.match(currentFieldName, parser.getDeprecationHandler())) {\n+                        incrementalSize = parser.longValue();\n+                    } else {\n+                        throw new ElasticsearchParseException(\"unknown parameter [{}]\", currentFieldName);\n+                    }\n+                } else if (token == XContentParser.Token.START_ARRAY) {\n+                    if (PARSE_FILES.match(currentFieldName, parser.getDeprecationHandler())) {\n+                        while ((parser.nextToken()) != XContentParser.Token.END_ARRAY) {\n+                            indexFiles.add(FileInfo.fromXContent(parser));\n                         }\n                     } else {\n-                        throw new ElasticsearchParseException(\"unexpected token  [{}]\", token);\n+                        throw new ElasticsearchParseException(\"unknown parameter [{}]\", currentFieldName);\n                     }\n                 } else {\n-                    throw new ElasticsearchParseException(\"unexpected token [{}]\", token);\n+                    throw new ElasticsearchParseException(\"unexpected token  [{}]\", token);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1824fb384dbdde173011d4a2262ea538dff0c1ec"}, "originalPosition": 70}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9b253fd8437eeab2d6d5c734b1cdf3f592a12db9", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/9b253fd8437eeab2d6d5c734b1cdf3f592a12db9", "committedDate": "2020-09-22T08:15:57Z", "message": "Merge remote-tracking branch 'elastic/master' into cleanup-repo-data-serialization"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "83431aea32aa2c03ecf521f313557cb88d14758e", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/83431aea32aa2c03ecf521f313557cb88d14758e", "committedDate": "2020-09-22T08:16:45Z", "message": "remove weird extra space"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d6e78662ef12922194550efeaa744872437a3355", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/d6e78662ef12922194550efeaa744872437a3355", "committedDate": "2020-09-22T08:19:35Z", "message": "final"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4684, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}