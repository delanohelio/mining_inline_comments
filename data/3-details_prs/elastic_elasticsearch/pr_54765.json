{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk4NjMzNjUx", "number": 54765, "title": "Make Snapshot Deletes Less Racy", "bodyText": "Snapshot deletes should first check the cluster state for an in-progress snapshot\nand try to abort it before checking the repository contents. This allows for atomically\nchecking and aborting a snapshot in the same cluster state update, removing all possible\nraces where a snapshot that is in-progress could not be found if it finishes between\nchecking the repository contents and the cluster state.\nAlso removes confusing races, where checking the cluster state off of the cluster state thread\nfinds an in-progress snapshot that is then not found in the cluster state update to abort it.\nFinally, the logic to use the repository generation of the in-progress snapshot + 1 was error\nprone because it would always fail the delete when the repository had a pending generation different from its safe generation when a snapshot started (leading to the snapshot finalizing at a\nhigher generation).\nThese issues (particularly that last point) can easily be reproduced by running SLMSnapshotBlockingIntegTests in a loop with current master (see #54766).\nThe snapshot resiliency test for concurrent snapshot creation and deletion was made to more\naggressively start the delete operation so that the above races would become visible.\nPreviously, the fact that deletes would never coincide with initializing snapshots resulted\nin a number of the above races not reproducing.\nThis PR is the most consistent I could get snapshot deletes without changes to the state machine. The fact that aborted deletes will not put the delete operation in the cluster state before waiting for the snapshot to abort still allows for some possible (though practically very unlikely) races. These will be fixed by a state-machine change in upcoming work in #54705 (which will have a much simpler and clearer diff after this change).\nCloses #54766", "createdAt": "2020-04-04T16:15:03Z", "url": "https://github.com/elastic/elasticsearch/pull/54765", "merged": true, "mergeCommit": {"oid": "373da6a8a883558dd24296a2da4d2846655c9210"}, "closed": true, "closedAt": "2020-04-06T10:26:56Z", "author": {"login": "original-brownbear"}, "timelineItems": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcUXsmdAH2gAyMzk4NjMzNjUxOjc1ODBlZGU2YTAzMzQ2ZjkwNmQ1N2JiYWExMjhlMTA0YmYyMzFiMGI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcU7d_8AH2gAyMzk4NjMzNjUxOmM3OGVjOWEzOTA5NTBiMzJiOGE2MDYzOGE3ZWYyODJhYjU5ZDUxNjQ=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "7580ede6a03346f906d57bbaa128e104bf231b0b", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/7580ede6a03346f906d57bbaa128e104bf231b0b", "committedDate": "2020-04-04T16:01:06Z", "message": "Make Snapshot Deletes Less Racy\n\nSnapshot deletes should first check the cluster state for an in-progress snapshot\nand try to abort it before checking the repository contents. This allows for atomically\nchecking and aborting a snapshot in the same cluster state update, removing all possible\nraces where a snapshot that is in-progress could not be found if it finishes between\nchecking the repository contents and the cluster state.\nAlso removes confusing races, where checking the cluster state off of the cluster state thread\nfinds an in-progress snapshot that is then not found in the cluster state update to abort it.\nFinally, the logic to use the repository generation of the in-progress snapshot + 1 was error\nprone because it would always fail the delete when the repository had a pending generation different\nfrom its safe generation when a snapshot started (leading to the snapshot finalizing at a\nhigher generation).\n\nThese issues (particularly that last point) were shaken out by removing workarounds from\nSLM tests that would retry snapshot delete operations on repository exceptions as thrown\nwhen hitting the unexpected generation issue.\n\nThe snapshot resiliency test for concurrent snapshot creation and deletion was made to more\naggressively start the delete operation so that the above races would become visible.\nPreviously, the fact that deletes would never coincide with initializing snapshots resulted\nin a number of the above races not reproducing."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6fea237b49b2cbbaced50c63f78b7a61522642ab", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/6fea237b49b2cbbaced50c63f78b7a61522642ab", "committedDate": "2020-04-04T16:21:14Z", "message": "revert unrelated changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "37660835c7f6bd9af645a711aedb65776ca9aecd", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/37660835c7f6bd9af645a711aedb65776ca9aecd", "committedDate": "2020-04-05T13:31:15Z", "message": "Merge remote-tracking branch 'elastic/master' into cleanup-slm-tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a0cdd17a1869f684b169a427ee5686dd21652f6b", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/a0cdd17a1869f684b169a427ee5686dd21652f6b", "committedDate": "2020-04-05T13:43:36Z", "message": "fix deadlock"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg3ODIwNTQ3", "url": "https://github.com/elastic/elasticsearch/pull/54765#pullrequestreview-387820547", "createdAt": "2020-04-05T13:44:30Z", "commit": {"oid": "a0cdd17a1869f684b169a427ee5686dd21652f6b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNVQxMzo0NDozMFrOGBAIbA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNVQxMzo0NDozMFrOGBAIbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMzkxNg==", "bodyText": "No need to fork to the generic pool here any more, we instantly move to the cluster state thread now in the snapshots service. We'll use the generic pool there once we have to inspect the repository data", "url": "https://github.com/elastic/elasticsearch/pull/54765#discussion_r403703916", "createdAt": "2020-04-05T13:44:30Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/delete/TransportDeleteSnapshotAction.java", "diffHunk": "@@ -54,7 +54,7 @@ public TransportDeleteSnapshotAction(TransportService transportService, ClusterS\n \n     @Override\n     protected String executor() {\n-        return ThreadPool.Names.GENERIC;\n+        return ThreadPool.Names.SAME;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0cdd17a1869f684b169a427ee5686dd21652f6b"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg3OTgyMjM1", "url": "https://github.com/elastic/elasticsearch/pull/54765#pullrequestreview-387982235", "createdAt": "2020-04-06T07:09:41Z", "commit": {"oid": "a0cdd17a1869f684b169a427ee5686dd21652f6b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQwNzowOTo0MVrOGBKYqw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQwNzowOTo0MVrOGBKYqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg3MTkxNQ==", "bodyText": "We would incorrectly get a -1 (empty repo gen) here when we deleted/aborted an initializing snapshot (because the repo gen is at -2 during the snapshot INIT stage). This wouldn't have caused any corruption and only made deletes fail but still, this assertion would've avoided not catching this race for so long :)", "url": "https://github.com/elastic/elasticsearch/pull/54765#discussion_r403871915", "createdAt": "2020-04-06T07:09:41Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/cluster/SnapshotDeletionsInProgress.java", "diffHunk": "@@ -174,6 +175,8 @@ public Entry(Snapshot snapshot, long startTime, long repositoryStateId) {\n             this.snapshot = snapshot;\n             this.startTime = startTime;\n             this.repositoryStateId = repositoryStateId;\n+            assert repositoryStateId > RepositoryData.EMPTY_REPO_GEN :", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0cdd17a1869f684b169a427ee5686dd21652f6b"}, "originalPosition": 12}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg3OTgwOTIy", "url": "https://github.com/elastic/elasticsearch/pull/54765#pullrequestreview-387980922", "createdAt": "2020-04-06T07:07:28Z", "commit": {"oid": "a0cdd17a1869f684b169a427ee5686dd21652f6b"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQwNzowNzoyOFrOGBKUpw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQwNzoyMzowOFrOGBKxUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg3MDg4Nw==", "bodyText": "should we also log an info-level message once we have successfully completed the deletion?", "url": "https://github.com/elastic/elasticsearch/pull/54765#discussion_r403870887", "createdAt": "2020-04-06T07:07:28Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java", "diffHunk": "@@ -970,61 +970,168 @@ private void failSnapshotCompletionListeners(Snapshot snapshot, Exception e) {\n     }\n \n     /**\n-     * Deletes a snapshot from the repository, looking up the {@link Snapshot} reference before deleting.\n-     * If the snapshot is still running cancels the snapshot first and then deletes it from the repository.\n+     * Deletes a snapshot from the repository or aborts a running snapshot.\n+     * First checks if the snapshot is still running and if so cancels the snapshot and then deletes it from the repository.\n+     * If the snapshot is not running, moves to trying to find a matching {@link Snapshot} for the given name in the repository and if\n+     * one is found deletes it by invoking {@link #deleteCompletedSnapshot}.\n      *\n      * @param repositoryName  repositoryName\n      * @param snapshotName    snapshotName\n      * @param listener        listener\n      */\n-    public void deleteSnapshot(final String repositoryName, final String snapshotName, final ActionListener<Void> listener,\n-                               final boolean immediatePriority) {\n-        // First, look for the snapshot in the repository\n-        final Repository repository = repositoriesService.repository(repositoryName);\n-        repository.getRepositoryData(ActionListener.wrap(repositoryData -> {\n-            Optional<SnapshotId> matchedEntry = repositoryData.getSnapshotIds()\n-                .stream()\n-                .filter(s -> s.getName().equals(snapshotName))\n-                .findFirst();\n-            // if nothing found by the same name, then look in the cluster state for current in progress snapshots\n-            long repoGenId = repositoryData.getGenId();\n-            if (matchedEntry.isPresent() == false) {\n-                Optional<SnapshotsInProgress.Entry> matchedInProgress = currentSnapshots(\n-                    clusterService.state().custom(SnapshotsInProgress.TYPE), repositoryName, Collections.emptyList()).stream()\n-                    .filter(s -> s.snapshot().getSnapshotId().getName().equals(snapshotName)).findFirst();\n-                if (matchedInProgress.isPresent()) {\n-                    matchedEntry = matchedInProgress.map(s -> s.snapshot().getSnapshotId());\n-                    // Derive repository generation if a snapshot is in progress because it will increment the generation when it finishes\n-                    repoGenId = matchedInProgress.get().repositoryStateId() + 1L;\n+    public void deleteSnapshot(final String repositoryName, final String snapshotName, final ActionListener<Void> listener) {\n+        logger.info(\"deleting snapshot [{}] from repository [{}]\", snapshotName, repositoryName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0cdd17a1869f684b169a427ee5686dd21652f6b"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg3MjczNA==", "bodyText": "maybe add this a helper method to SnapshotsInProgress similar to public Entry snapshot(final Snapshot snapshot)", "url": "https://github.com/elastic/elasticsearch/pull/54765#discussion_r403872734", "createdAt": "2020-04-06T07:11:37Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java", "diffHunk": "@@ -970,61 +970,168 @@ private void failSnapshotCompletionListeners(Snapshot snapshot, Exception e) {\n     }\n \n     /**\n-     * Deletes a snapshot from the repository, looking up the {@link Snapshot} reference before deleting.\n-     * If the snapshot is still running cancels the snapshot first and then deletes it from the repository.\n+     * Deletes a snapshot from the repository or aborts a running snapshot.\n+     * First checks if the snapshot is still running and if so cancels the snapshot and then deletes it from the repository.\n+     * If the snapshot is not running, moves to trying to find a matching {@link Snapshot} for the given name in the repository and if\n+     * one is found deletes it by invoking {@link #deleteCompletedSnapshot}.\n      *\n      * @param repositoryName  repositoryName\n      * @param snapshotName    snapshotName\n      * @param listener        listener\n      */\n-    public void deleteSnapshot(final String repositoryName, final String snapshotName, final ActionListener<Void> listener,\n-                               final boolean immediatePriority) {\n-        // First, look for the snapshot in the repository\n-        final Repository repository = repositoriesService.repository(repositoryName);\n-        repository.getRepositoryData(ActionListener.wrap(repositoryData -> {\n-            Optional<SnapshotId> matchedEntry = repositoryData.getSnapshotIds()\n-                .stream()\n-                .filter(s -> s.getName().equals(snapshotName))\n-                .findFirst();\n-            // if nothing found by the same name, then look in the cluster state for current in progress snapshots\n-            long repoGenId = repositoryData.getGenId();\n-            if (matchedEntry.isPresent() == false) {\n-                Optional<SnapshotsInProgress.Entry> matchedInProgress = currentSnapshots(\n-                    clusterService.state().custom(SnapshotsInProgress.TYPE), repositoryName, Collections.emptyList()).stream()\n-                    .filter(s -> s.snapshot().getSnapshotId().getName().equals(snapshotName)).findFirst();\n-                if (matchedInProgress.isPresent()) {\n-                    matchedEntry = matchedInProgress.map(s -> s.snapshot().getSnapshotId());\n-                    // Derive repository generation if a snapshot is in progress because it will increment the generation when it finishes\n-                    repoGenId = matchedInProgress.get().repositoryStateId() + 1L;\n+    public void deleteSnapshot(final String repositoryName, final String snapshotName, final ActionListener<Void> listener) {\n+        logger.info(\"deleting snapshot [{}] from repository [{}]\", snapshotName, repositoryName);\n+\n+        clusterService.submitStateUpdateTask(\"delete snapshot\", new ClusterStateUpdateTask(Priority.NORMAL) {\n+\n+            Snapshot runningSnapshot;\n+\n+            boolean abortedDuringInit = false;\n+\n+            @Override\n+            public ClusterState execute(ClusterState currentState) {\n+                SnapshotsInProgress snapshots = currentState.custom(SnapshotsInProgress.TYPE);\n+                SnapshotsInProgress.Entry snapshotEntry = null;\n+                if (snapshots != null) {\n+                    for (SnapshotsInProgress.Entry entry : snapshots.entries()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0cdd17a1869f684b169a427ee5686dd21652f6b"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg3NDYxMw==", "bodyText": "I know that this was already the case before, but if we were to allow concurrent snapshots, this line here would be silently removing other snapshots. Let's make sure to preserve other snapshots so that we don't get nasty surprises in the future.", "url": "https://github.com/elastic/elasticsearch/pull/54765#discussion_r403874613", "createdAt": "2020-04-06T07:15:38Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java", "diffHunk": "@@ -970,61 +970,168 @@ private void failSnapshotCompletionListeners(Snapshot snapshot, Exception e) {\n     }\n \n     /**\n-     * Deletes a snapshot from the repository, looking up the {@link Snapshot} reference before deleting.\n-     * If the snapshot is still running cancels the snapshot first and then deletes it from the repository.\n+     * Deletes a snapshot from the repository or aborts a running snapshot.\n+     * First checks if the snapshot is still running and if so cancels the snapshot and then deletes it from the repository.\n+     * If the snapshot is not running, moves to trying to find a matching {@link Snapshot} for the given name in the repository and if\n+     * one is found deletes it by invoking {@link #deleteCompletedSnapshot}.\n      *\n      * @param repositoryName  repositoryName\n      * @param snapshotName    snapshotName\n      * @param listener        listener\n      */\n-    public void deleteSnapshot(final String repositoryName, final String snapshotName, final ActionListener<Void> listener,\n-                               final boolean immediatePriority) {\n-        // First, look for the snapshot in the repository\n-        final Repository repository = repositoriesService.repository(repositoryName);\n-        repository.getRepositoryData(ActionListener.wrap(repositoryData -> {\n-            Optional<SnapshotId> matchedEntry = repositoryData.getSnapshotIds()\n-                .stream()\n-                .filter(s -> s.getName().equals(snapshotName))\n-                .findFirst();\n-            // if nothing found by the same name, then look in the cluster state for current in progress snapshots\n-            long repoGenId = repositoryData.getGenId();\n-            if (matchedEntry.isPresent() == false) {\n-                Optional<SnapshotsInProgress.Entry> matchedInProgress = currentSnapshots(\n-                    clusterService.state().custom(SnapshotsInProgress.TYPE), repositoryName, Collections.emptyList()).stream()\n-                    .filter(s -> s.snapshot().getSnapshotId().getName().equals(snapshotName)).findFirst();\n-                if (matchedInProgress.isPresent()) {\n-                    matchedEntry = matchedInProgress.map(s -> s.snapshot().getSnapshotId());\n-                    // Derive repository generation if a snapshot is in progress because it will increment the generation when it finishes\n-                    repoGenId = matchedInProgress.get().repositoryStateId() + 1L;\n+    public void deleteSnapshot(final String repositoryName, final String snapshotName, final ActionListener<Void> listener) {\n+        logger.info(\"deleting snapshot [{}] from repository [{}]\", snapshotName, repositoryName);\n+\n+        clusterService.submitStateUpdateTask(\"delete snapshot\", new ClusterStateUpdateTask(Priority.NORMAL) {\n+\n+            Snapshot runningSnapshot;\n+\n+            boolean abortedDuringInit = false;\n+\n+            @Override\n+            public ClusterState execute(ClusterState currentState) {\n+                SnapshotsInProgress snapshots = currentState.custom(SnapshotsInProgress.TYPE);\n+                SnapshotsInProgress.Entry snapshotEntry = null;\n+                if (snapshots != null) {\n+                    for (SnapshotsInProgress.Entry entry : snapshots.entries()) {\n+                        if (entry.repository().equals(repositoryName)\n+                            && entry.snapshot().getSnapshotId().getName().equals(snapshotName)) {\n+                            snapshotEntry = entry;\n+                            break;\n+                        }\n+                    }\n+                }\n+                if (snapshotEntry == null) {\n+                    return currentState;\n                 }\n+                runningSnapshot = snapshotEntry.snapshot();\n+                final ImmutableOpenMap<ShardId, ShardSnapshotStatus> shards;\n+\n+                final State state = snapshotEntry.state();\n+                final String failure;\n+                if (state == State.INIT) {\n+                    // snapshot is still initializing, mark it as aborted\n+                    shards = snapshotEntry.shards();\n+                    assert shards.isEmpty();\n+                    failure = \"Snapshot was aborted during initialization\";\n+                    abortedDuringInit = true;\n+                } else if (state == State.STARTED) {\n+                    // snapshot is started - mark every non completed shard as aborted\n+                    final ImmutableOpenMap.Builder<ShardId, ShardSnapshotStatus> shardsBuilder = ImmutableOpenMap.builder();\n+                    for (ObjectObjectCursor<ShardId, ShardSnapshotStatus> shardEntry : snapshotEntry.shards()) {\n+                        ShardSnapshotStatus status = shardEntry.value;\n+                        if (status.state().completed() == false) {\n+                            status = new ShardSnapshotStatus(\n+                                status.nodeId(), ShardState.ABORTED, \"aborted by snapshot deletion\", status.generation());\n+                        }\n+                        shardsBuilder.put(shardEntry.key, status);\n+                    }\n+                    shards = shardsBuilder.build();\n+                    failure = \"Snapshot was aborted by deletion\";\n+                } else {\n+                    boolean hasUncompletedShards = false;\n+                    // Cleanup in case a node gone missing and snapshot wasn't updated for some reason\n+                    for (ObjectCursor<ShardSnapshotStatus> shardStatus : snapshotEntry.shards().values()) {\n+                        // Check if we still have shard running on existing nodes\n+                        if (shardStatus.value.state().completed() == false && shardStatus.value.nodeId() != null\n+                            && currentState.nodes().get(shardStatus.value.nodeId()) != null) {\n+                            hasUncompletedShards = true;\n+                            break;\n+                        }\n+                    }\n+                    if (hasUncompletedShards) {\n+                        // snapshot is being finalized - wait for shards to complete finalization process\n+                        logger.debug(\"trying to delete completed snapshot - should wait for shards to finalize on all nodes\");\n+                        return currentState;\n+                    } else {\n+                        // no shards to wait for but a node is gone - this is the only case\n+                        // where we force to finish the snapshot\n+                        logger.debug(\"trying to delete completed snapshot with no finalizing shards - can delete immediately\");\n+                        shards = snapshotEntry.shards();\n+                    }\n+                    failure = snapshotEntry.failure();\n+                }\n+                return ClusterState.builder(currentState).putCustom(SnapshotsInProgress.TYPE,\n+                    new SnapshotsInProgress(new SnapshotsInProgress.Entry(snapshotEntry, State.ABORTED, shards, failure))).build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0cdd17a1869f684b169a427ee5686dd21652f6b"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg3NTY0Mw==", "bodyText": "why is method defined at the previous cluster state update task level? I think I would prefer explicitly passing in the listener, and moving it up", "url": "https://github.com/elastic/elasticsearch/pull/54765#discussion_r403875643", "createdAt": "2020-04-06T07:17:52Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java", "diffHunk": "@@ -970,61 +970,168 @@ private void failSnapshotCompletionListeners(Snapshot snapshot, Exception e) {\n     }\n \n     /**\n-     * Deletes a snapshot from the repository, looking up the {@link Snapshot} reference before deleting.\n-     * If the snapshot is still running cancels the snapshot first and then deletes it from the repository.\n+     * Deletes a snapshot from the repository or aborts a running snapshot.\n+     * First checks if the snapshot is still running and if so cancels the snapshot and then deletes it from the repository.\n+     * If the snapshot is not running, moves to trying to find a matching {@link Snapshot} for the given name in the repository and if\n+     * one is found deletes it by invoking {@link #deleteCompletedSnapshot}.\n      *\n      * @param repositoryName  repositoryName\n      * @param snapshotName    snapshotName\n      * @param listener        listener\n      */\n-    public void deleteSnapshot(final String repositoryName, final String snapshotName, final ActionListener<Void> listener,\n-                               final boolean immediatePriority) {\n-        // First, look for the snapshot in the repository\n-        final Repository repository = repositoriesService.repository(repositoryName);\n-        repository.getRepositoryData(ActionListener.wrap(repositoryData -> {\n-            Optional<SnapshotId> matchedEntry = repositoryData.getSnapshotIds()\n-                .stream()\n-                .filter(s -> s.getName().equals(snapshotName))\n-                .findFirst();\n-            // if nothing found by the same name, then look in the cluster state for current in progress snapshots\n-            long repoGenId = repositoryData.getGenId();\n-            if (matchedEntry.isPresent() == false) {\n-                Optional<SnapshotsInProgress.Entry> matchedInProgress = currentSnapshots(\n-                    clusterService.state().custom(SnapshotsInProgress.TYPE), repositoryName, Collections.emptyList()).stream()\n-                    .filter(s -> s.snapshot().getSnapshotId().getName().equals(snapshotName)).findFirst();\n-                if (matchedInProgress.isPresent()) {\n-                    matchedEntry = matchedInProgress.map(s -> s.snapshot().getSnapshotId());\n-                    // Derive repository generation if a snapshot is in progress because it will increment the generation when it finishes\n-                    repoGenId = matchedInProgress.get().repositoryStateId() + 1L;\n+    public void deleteSnapshot(final String repositoryName, final String snapshotName, final ActionListener<Void> listener) {\n+        logger.info(\"deleting snapshot [{}] from repository [{}]\", snapshotName, repositoryName);\n+\n+        clusterService.submitStateUpdateTask(\"delete snapshot\", new ClusterStateUpdateTask(Priority.NORMAL) {\n+\n+            Snapshot runningSnapshot;\n+\n+            boolean abortedDuringInit = false;\n+\n+            @Override\n+            public ClusterState execute(ClusterState currentState) {\n+                SnapshotsInProgress snapshots = currentState.custom(SnapshotsInProgress.TYPE);\n+                SnapshotsInProgress.Entry snapshotEntry = null;\n+                if (snapshots != null) {\n+                    for (SnapshotsInProgress.Entry entry : snapshots.entries()) {\n+                        if (entry.repository().equals(repositoryName)\n+                            && entry.snapshot().getSnapshotId().getName().equals(snapshotName)) {\n+                            snapshotEntry = entry;\n+                            break;\n+                        }\n+                    }\n+                }\n+                if (snapshotEntry == null) {\n+                    return currentState;\n                 }\n+                runningSnapshot = snapshotEntry.snapshot();\n+                final ImmutableOpenMap<ShardId, ShardSnapshotStatus> shards;\n+\n+                final State state = snapshotEntry.state();\n+                final String failure;\n+                if (state == State.INIT) {\n+                    // snapshot is still initializing, mark it as aborted\n+                    shards = snapshotEntry.shards();\n+                    assert shards.isEmpty();\n+                    failure = \"Snapshot was aborted during initialization\";\n+                    abortedDuringInit = true;\n+                } else if (state == State.STARTED) {\n+                    // snapshot is started - mark every non completed shard as aborted\n+                    final ImmutableOpenMap.Builder<ShardId, ShardSnapshotStatus> shardsBuilder = ImmutableOpenMap.builder();\n+                    for (ObjectObjectCursor<ShardId, ShardSnapshotStatus> shardEntry : snapshotEntry.shards()) {\n+                        ShardSnapshotStatus status = shardEntry.value;\n+                        if (status.state().completed() == false) {\n+                            status = new ShardSnapshotStatus(\n+                                status.nodeId(), ShardState.ABORTED, \"aborted by snapshot deletion\", status.generation());\n+                        }\n+                        shardsBuilder.put(shardEntry.key, status);\n+                    }\n+                    shards = shardsBuilder.build();\n+                    failure = \"Snapshot was aborted by deletion\";\n+                } else {\n+                    boolean hasUncompletedShards = false;\n+                    // Cleanup in case a node gone missing and snapshot wasn't updated for some reason\n+                    for (ObjectCursor<ShardSnapshotStatus> shardStatus : snapshotEntry.shards().values()) {\n+                        // Check if we still have shard running on existing nodes\n+                        if (shardStatus.value.state().completed() == false && shardStatus.value.nodeId() != null\n+                            && currentState.nodes().get(shardStatus.value.nodeId()) != null) {\n+                            hasUncompletedShards = true;\n+                            break;\n+                        }\n+                    }\n+                    if (hasUncompletedShards) {\n+                        // snapshot is being finalized - wait for shards to complete finalization process\n+                        logger.debug(\"trying to delete completed snapshot - should wait for shards to finalize on all nodes\");\n+                        return currentState;\n+                    } else {\n+                        // no shards to wait for but a node is gone - this is the only case\n+                        // where we force to finish the snapshot\n+                        logger.debug(\"trying to delete completed snapshot with no finalizing shards - can delete immediately\");\n+                        shards = snapshotEntry.shards();\n+                    }\n+                    failure = snapshotEntry.failure();\n+                }\n+                return ClusterState.builder(currentState).putCustom(SnapshotsInProgress.TYPE,\n+                    new SnapshotsInProgress(new SnapshotsInProgress.Entry(snapshotEntry, State.ABORTED, shards, failure))).build();\n+            }\n+\n+            @Override\n+            public void onFailure(String source, Exception e) {\n+                listener.onFailure(e);\n             }\n-            if (matchedEntry.isPresent() == false) {\n-                throw new SnapshotMissingException(repositoryName, snapshotName);\n+\n+            @Override\n+            public void clusterStateProcessed(String source, ClusterState oldState, ClusterState newState) {\n+                if (runningSnapshot == null) {\n+                    tryDeleteExisting(Priority.NORMAL);\n+                    return;\n+                }\n+                logger.trace(\"adding snapshot completion listener to wait for deleted snapshot to finish\");\n+                addListener(runningSnapshot, ActionListener.wrap(\n+                    snapshotInfo -> {\n+                        logger.debug(\"deleted snapshot completed - deleting files\");\n+                        tryDeleteExisting(Priority.IMMEDIATE);\n+                    },\n+                    e -> {\n+                        if (abortedDuringInit) {\n+                            logger.debug(() -> new ParameterizedMessage(\"Snapshot [{}] was aborted during INIT\", runningSnapshot), e);\n+                            listener.onResponse(null);\n+                        } else {\n+                            if (ExceptionsHelper.unwrap(e, NotMasterException.class, FailedToCommitClusterStateException.class)\n+                                != null) {\n+                                logger.warn(\"master failover before deleted snapshot could complete\", e);\n+                                // Just pass the exception to the transport handler as is so it is retried on the new master\n+                                listener.onFailure(e);\n+                            } else {\n+                                logger.warn(\"deleted snapshot failed\", e);\n+                                listener.onFailure(\n+                                    new SnapshotMissingException(runningSnapshot.getRepository(), runningSnapshot.getSnapshotId(), e));\n+                            }\n+                        }\n+                    }\n+                ));\n             }\n-            deleteSnapshot(new Snapshot(repositoryName, matchedEntry.get()), listener, repoGenId, immediatePriority);\n-        }, listener::onFailure));\n+\n+            private void tryDeleteExisting(Priority priority) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0cdd17a1869f684b169a427ee5686dd21652f6b"}, "originalPosition": 151}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg3ODIyNA==", "bodyText": "same here as before, let's preserve other deletions", "url": "https://github.com/elastic/elasticsearch/pull/54765#discussion_r403878224", "createdAt": "2020-04-06T07:23:08Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java", "diffHunk": "@@ -1050,81 +1157,15 @@ public ClusterState execute(ClusterState currentState) {\n                         }\n                     }\n                 }\n-                ClusterState.Builder clusterStateBuilder = ClusterState.builder(currentState);\n                 SnapshotsInProgress snapshots = currentState.custom(SnapshotsInProgress.TYPE);\n-                SnapshotsInProgress.Entry snapshotEntry = snapshots != null ? snapshots.snapshot(snapshot) : null;\n-                if (snapshotEntry == null) {\n-                    // This snapshot is not running - delete\n-                    if (snapshots != null && !snapshots.entries().isEmpty()) {\n-                        // However other snapshots are running - cannot continue\n-                        throw new ConcurrentSnapshotExecutionException(snapshot, \"another snapshot is currently running cannot delete\");\n-                    }\n-                    // add the snapshot deletion to the cluster state\n-                    SnapshotDeletionsInProgress.Entry entry = new SnapshotDeletionsInProgress.Entry(\n-                        snapshot,\n-                        threadPool.absoluteTimeInMillis(),\n-                        repositoryStateId\n-                    );\n-                    if (deletionsInProgress != null) {\n-                        deletionsInProgress = deletionsInProgress.withAddedEntry(entry);\n-                    } else {\n-                        deletionsInProgress = SnapshotDeletionsInProgress.newInstance(entry);\n-                    }\n-                    clusterStateBuilder.putCustom(SnapshotDeletionsInProgress.TYPE, deletionsInProgress);\n-                } else {\n-                    // This snapshot is currently running - stopping shards first\n-                    waitForSnapshot = true;\n-\n-                    final ImmutableOpenMap<ShardId, ShardSnapshotStatus> shards;\n-\n-                    final State state = snapshotEntry.state();\n-                    final String failure;\n-                    if (state == State.INIT) {\n-                        // snapshot is still initializing, mark it as aborted\n-                        shards = snapshotEntry.shards();\n-                        assert shards.isEmpty();\n-                        failure = \"Snapshot was aborted during initialization\";\n-                        abortedDuringInit = true;\n-                    } else if (state == State.STARTED) {\n-                        // snapshot is started - mark every non completed shard as aborted\n-                        final ImmutableOpenMap.Builder<ShardId, ShardSnapshotStatus> shardsBuilder = ImmutableOpenMap.builder();\n-                        for (ObjectObjectCursor<ShardId, ShardSnapshotStatus> shardEntry : snapshotEntry.shards()) {\n-                            ShardSnapshotStatus status = shardEntry.value;\n-                            if (status.state().completed() == false) {\n-                                status = new ShardSnapshotStatus(\n-                                    status.nodeId(), ShardState.ABORTED, \"aborted by snapshot deletion\", status.generation());\n-                            }\n-                            shardsBuilder.put(shardEntry.key, status);\n-                        }\n-                        shards = shardsBuilder.build();\n-                        failure = \"Snapshot was aborted by deletion\";\n-                    } else {\n-                        boolean hasUncompletedShards = false;\n-                        // Cleanup in case a node gone missing and snapshot wasn't updated for some reason\n-                        for (ObjectCursor<ShardSnapshotStatus> shardStatus : snapshotEntry.shards().values()) {\n-                            // Check if we still have shard running on existing nodes\n-                            if (shardStatus.value.state().completed() == false && shardStatus.value.nodeId() != null\n-                                    && currentState.nodes().get(shardStatus.value.nodeId()) != null) {\n-                                hasUncompletedShards = true;\n-                                break;\n-                            }\n-                        }\n-                        if (hasUncompletedShards) {\n-                            // snapshot is being finalized - wait for shards to complete finalization process\n-                            logger.debug(\"trying to delete completed snapshot - should wait for shards to finalize on all nodes\");\n-                            return currentState;\n-                        } else {\n-                            // no shards to wait for but a node is gone - this is the only case\n-                            // where we force to finish the snapshot\n-                            logger.debug(\"trying to delete completed snapshot with no finalizing shards - can delete immediately\");\n-                            shards = snapshotEntry.shards();\n-                        }\n-                        failure = snapshotEntry.failure();\n-                    }\n-                    SnapshotsInProgress.Entry newSnapshot = new SnapshotsInProgress.Entry(snapshotEntry, State.ABORTED, shards, failure);\n-                    clusterStateBuilder.putCustom(SnapshotsInProgress.TYPE, new SnapshotsInProgress(newSnapshot));\n+                if (snapshots != null && snapshots.entries().isEmpty() == false) {\n+                    // However other snapshots are running - cannot continue\n+                    throw new ConcurrentSnapshotExecutionException(snapshot, \"another snapshot is currently running cannot delete\");\n                 }\n-                return clusterStateBuilder.build();\n+                // add the snapshot deletion to the cluster state\n+                return ClusterState.builder(currentState).putCustom(SnapshotDeletionsInProgress.TYPE,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0cdd17a1869f684b169a427ee5686dd21652f6b"}, "originalPosition": 293}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "36aa15da20c72d41877b795d471c380ca13c71eb", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/36aa15da20c72d41877b795d471c380ca13c71eb", "committedDate": "2020-04-06T08:01:13Z", "message": "Merge remote-tracking branch 'elastic/master' into cleanup-slm-tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7f4deafd2171b610f6c379760db44af3b8d5ef41", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/7f4deafd2171b610f6c379760db44af3b8d5ef41", "committedDate": "2020-04-06T08:05:45Z", "message": "CR: add after delete log messages"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "157c938191600e6bc4be51b028f7325f1dc1c634", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/157c938191600e6bc4be51b028f7325f1dc1c634", "committedDate": "2020-04-06T08:09:32Z", "message": "CR: extract helper for in progrss snapshot search"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ecd90a56cd099a6427d038b1a7d9ebd0d2180b60", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/ecd90a56cd099a6427d038b1a7d9ebd0d2180b60", "committedDate": "2020-04-06T08:24:58Z", "message": "CR: update snapshot list safer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7c3a24e7b34d26e4940376dbf92adba33da0933f", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/7c3a24e7b34d26e4940376dbf92adba33da0933f", "committedDate": "2020-04-06T08:29:50Z", "message": "CR: preserve other deletes"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg4MDc4NTAz", "url": "https://github.com/elastic/elasticsearch/pull/54765#pullrequestreview-388078503", "createdAt": "2020-04-06T09:29:06Z", "commit": {"oid": "ecd90a56cd099a6427d038b1a7d9ebd0d2180b60"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQwOToyOTowNlrOGBPQMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQwOToyOTowNlrOGBPQMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzk1MTY2Nw==", "bodyText": "there is also a list construcutor, so no need for the array conversion.", "url": "https://github.com/elastic/elasticsearch/pull/54765#discussion_r403951667", "createdAt": "2020-04-06T09:29:06Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java", "diffHunk": "@@ -1042,7 +1043,12 @@ public ClusterState execute(ClusterState currentState) {\n                     failure = snapshotEntry.failure();\n                 }\n                 return ClusterState.builder(currentState).putCustom(SnapshotsInProgress.TYPE,\n-                    new SnapshotsInProgress(new SnapshotsInProgress.Entry(snapshotEntry, State.ABORTED, shards, failure))).build();\n+                    new SnapshotsInProgress(snapshots.entries().stream().map(existing -> {\n+                        if (existing.equals(snapshotEntry)) {\n+                            return new SnapshotsInProgress.Entry(snapshotEntry, State.ABORTED, shards, failure);\n+                        }\n+                        return existing;\n+                    }).toArray(SnapshotsInProgress.Entry[]::new))).build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ecd90a56cd099a6427d038b1a7d9ebd0d2180b60"}, "originalPosition": 20}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6cd5631075543ecd73d0293e9223de9760cb714a", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/6cd5631075543ecd73d0293e9223de9760cb714a", "committedDate": "2020-04-06T09:37:22Z", "message": "Merge remote-tracking branch 'elastic/master' into cleanup-slm-tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c78ec9a390950b32b8a60638a7ef282ab59d5164", "author": {"user": {"login": "original-brownbear", "name": "Armin Braun"}}, "url": "https://github.com/elastic/elasticsearch/commit/c78ec9a390950b32b8a60638a7ef282ab59d5164", "committedDate": "2020-04-06T09:41:44Z", "message": "CR: list it is"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3838, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}