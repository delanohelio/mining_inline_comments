{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg5NTM0NDA0", "number": 62666, "title": "Split up large HTTP responses in outbound pipeline", "bodyText": "Currently Netty will batch compression an entire HTTP response\nregardless of its content size. It allocates a byte array at least of\nthe same size as the uncompressed content. This causes issues with our\nattempts to remove humungous G1GC allocations. This commit resolves the\nissue by split responses into 128KB chunks.\nThis has the side-effect of making large outbound HTTP responses that\nare compressed be send as chunked transfer-encoding.", "createdAt": "2020-09-18T20:49:39Z", "url": "https://github.com/elastic/elasticsearch/pull/62666", "merged": true, "mergeCommit": {"oid": "19c19f28cb7b82f0c9b480e7f07289ab6bfeeb60"}, "closed": true, "closedAt": "2020-09-24T20:20:13Z", "author": {"login": "tbrooks8"}, "timelineItems": {"totalCount": 26, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdKL2zzAH2gAyNDg5NTM0NDA0OjVmZTBhY2I1MmQ4Mzk0MWY1MzkxZjg4NzYzMjE3ZDFhMzI1Y2I3ZDI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdMGXLAAH2gAyNDg5NTM0NDA0OjJhMTRjNGNjMmY1MThlMGRhMTI3ZjAzZTI3YzUwNzNjODIxMzAwM2M=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "5fe0acb52d83941f5391f88763217d1a325cb7d2", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/5fe0acb52d83941f5391f88763217d1a325cb7d2", "committedDate": "2020-09-18T20:45:18Z", "message": "Split up large HTTP responses in outbound pipeline\n\nCurrently Netty will batch compression an entire HTTP response\nregardless of its content size. It allocates a byte array at least of\nthe same size as the uncompressed content. This causes issues with our\nattempts to remove humungous G1GC allocations. This commit resolves the\nissue by split responses into 128KB chunks.\n\nThis has the side-effect of making large outbound HTTP responses that\nare compressed be send as chunked transfer-encoding."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkxNzc0Njky", "url": "https://github.com/elastic/elasticsearch/pull/62666#pullrequestreview-491774692", "createdAt": "2020-09-18T20:52:58Z", "commit": {"oid": "5fe0acb52d83941f5391f88763217d1a325cb7d2"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQyMDo1Mjo1OFrOHUblSw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQyMDo1Mjo1OFrOHUblSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTE4NTQ4Mw==", "bodyText": "Netty uses static direct byte buffers to chunked transfer encoded line breaks. So we have to handle them.", "url": "https://github.com/elastic/elasticsearch/pull/62666#discussion_r491185483", "createdAt": "2020-09-18T20:52:58Z", "author": {"login": "tbrooks8"}, "path": "modules/transport-netty4/src/main/java/org/elasticsearch/transport/CopyBytesSocketChannel.java", "diffHunk": "@@ -162,9 +162,17 @@ private void adjustMaxBytesPerGatheringWrite(int attempted, int written, int old\n     private static void copyBytes(ByteBuffer[] source, int nioBufferCnt, ByteBuffer destination) {\n         for (int i = 0; i < nioBufferCnt && destination.hasRemaining(); i++) {\n             ByteBuffer buffer = source[i];\n-            assert buffer.hasArray() : \"Buffer must have heap array\";\n             int nBytesToCopy = Math.min(destination.remaining(), buffer.remaining());\n-            destination.put(buffer.array(), buffer.arrayOffset() + buffer.position(), nBytesToCopy);\n+            if (buffer.hasArray()) {\n+                destination.put(buffer.array(), buffer.arrayOffset() + buffer.position(), nBytesToCopy);\n+            } else {\n+                int initialLimit = buffer.limit();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5fe0acb52d83941f5391f88763217d1a325cb7d2"}, "originalPosition": 10}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2b3f541885d67e37994fe2ca69685733bd23ad8f", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/2b3f541885d67e37994fe2ca69685733bd23ad8f", "committedDate": "2020-09-18T20:53:21Z", "message": "Merge remote-tracking branch 'upstream/master' into remove_batch_http_compression"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkyMjA4MDI3", "url": "https://github.com/elastic/elasticsearch/pull/62666#pullrequestreview-492208027", "createdAt": "2020-09-20T17:03:54Z", "commit": {"oid": "2b3f541885d67e37994fe2ca69685733bd23ad8f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMFQxNzowMzo1NVrOHU7qzw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMFQxNzowMzo1NVrOHU7qzw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTcxMTE4Mw==", "bodyText": "Should we only add this when handlingSettings.isCompression() == true?", "url": "https://github.com/elastic/elasticsearch/pull/62666#discussion_r491711183", "createdAt": "2020-09-20T17:03:55Z", "author": {"login": "original-brownbear"}, "path": "modules/transport-netty4/src/main/java/org/elasticsearch/http/netty4/Netty4HttpServerTransport.java", "diffHunk": "@@ -313,6 +315,7 @@ protected void initChannel(Channel ch) throws Exception {\n                 ch.pipeline().addLast(\"encoder_compress\", new HttpContentCompressor(handlingSettings.getCompressionLevel()));\n             }\n             ch.pipeline().addLast(\"request_creator\", requestCreator);\n+            ch.pipeline().addLast(\"response_creator\", responseCreator);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b3f541885d67e37994fe2ca69685733bd23ad8f"}, "originalPosition": 20}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkyNDA3ODI0", "url": "https://github.com/elastic/elasticsearch/pull/62666#pullrequestreview-492407824", "createdAt": "2020-09-21T09:13:19Z", "commit": {"oid": "2b3f541885d67e37994fe2ca69685733bd23ad8f"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQwOToxMzoxOVrOHVG4OA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQxMDoxMToyNVrOHVI_VQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTg5NDg0MA==", "bodyText": "Is this necessary/correct? It looks like other byte buffers position are fowarded during write.", "url": "https://github.com/elastic/elasticsearch/pull/62666#discussion_r491894840", "createdAt": "2020-09-21T09:13:19Z", "author": {"login": "henningandersen"}, "path": "modules/transport-netty4/src/main/java/org/elasticsearch/transport/CopyBytesSocketChannel.java", "diffHunk": "@@ -162,9 +162,17 @@ private void adjustMaxBytesPerGatheringWrite(int attempted, int written, int old\n     private static void copyBytes(ByteBuffer[] source, int nioBufferCnt, ByteBuffer destination) {\n         for (int i = 0; i < nioBufferCnt && destination.hasRemaining(); i++) {\n             ByteBuffer buffer = source[i];\n-            assert buffer.hasArray() : \"Buffer must have heap array\";\n             int nBytesToCopy = Math.min(destination.remaining(), buffer.remaining());\n-            destination.put(buffer.array(), buffer.arrayOffset() + buffer.position(), nBytesToCopy);\n+            if (buffer.hasArray()) {\n+                destination.put(buffer.array(), buffer.arrayOffset() + buffer.position(), nBytesToCopy);\n+            } else {\n+                int initialLimit = buffer.limit();\n+                int initialPosition = buffer.position();\n+                buffer.limit(buffer.position() + nBytesToCopy);\n+                destination.put(buffer);\n+                buffer.position(initialPosition);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b3f541885d67e37994fe2ca69685733bd23ad8f"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTkxNDQzOA==", "bodyText": "Is there an easy way to assert that we did not do a big unpooled allocation?\nIf not, we could consider adding an assert here that the encoding is chunked (if possible)?", "url": "https://github.com/elastic/elasticsearch/pull/62666#discussion_r491914438", "createdAt": "2020-09-21T09:46:03Z", "author": {"login": "henningandersen"}, "path": "modules/transport-netty4/src/test/java/org/elasticsearch/http/netty4/Netty4HttpServerTransportTests.java", "diffHunk": "@@ -282,6 +282,52 @@ public void dispatchBadRequest(final RestChannel channel, final ThreadContext th\n         assertThat(causeReference.get(), instanceOf(TooLongFrameException.class));\n     }\n \n+    public void testLargeCompressedResponse() throws InterruptedException {\n+        final String responseString = randomAlphaOfLength(4 * 1024 * 1024);\n+        final String url = \"/thing\";\n+        final HttpServerTransport.Dispatcher dispatcher = new HttpServerTransport.Dispatcher() {\n+\n+            @Override\n+            public void dispatchRequest(final RestRequest request, final RestChannel channel, final ThreadContext threadContext) {\n+                if (url.equals(request.uri())) {\n+                    channel.sendResponse(new BytesRestResponse(OK, responseString));\n+                } else {\n+                    logger.error(\"--> Unexpected successful uri [{}]\", request.uri());\n+                    throw new AssertionError();\n+                }\n+            }\n+\n+            @Override\n+            public void dispatchBadRequest(final RestChannel channel, final ThreadContext threadContext, final Throwable cause) {\n+                logger.error(new ParameterizedMessage(\"--> Unexpected bad request [{}]\",\n+                    FakeRestRequest.requestToString(channel.request())), cause);\n+                throw new AssertionError();\n+            }\n+\n+        };\n+\n+        try (Netty4HttpServerTransport transport = new Netty4HttpServerTransport(\n+            Settings.EMPTY, networkService, bigArrays, threadPool, xContentRegistry(), dispatcher, clusterSettings,\n+            new SharedGroupFactory(Settings.EMPTY))) {\n+            transport.start();\n+            final TransportAddress remoteAddress = randomFrom(transport.boundAddress().boundAddresses());\n+\n+            try (Netty4HttpClient client = new Netty4HttpClient()) {\n+                DefaultFullHttpRequest request = new DefaultFullHttpRequest(HttpVersion.HTTP_1_1, HttpMethod.GET, url);\n+                request.headers().add(HttpHeaderNames.ACCEPT_ENCODING, randomFrom(\"deflate\", \"gzip\"));\n+                final FullHttpResponse response = client.send(remoteAddress.address(), request);\n+                try {\n+                    assertThat(response.status(), equalTo(HttpResponseStatus.OK));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b3f541885d67e37994fe2ca69685733bd23ad8f"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTkxNTIyNw==", "bodyText": "Do we need something similar for nio http or does that not have that behavior anyway?", "url": "https://github.com/elastic/elasticsearch/pull/62666#discussion_r491915227", "createdAt": "2020-09-21T09:46:58Z", "author": {"login": "henningandersen"}, "path": "modules/transport-netty4/src/main/java/org/elasticsearch/http/netty4/Netty4HttpServerTransport.java", "diffHunk": "@@ -313,6 +315,7 @@ protected void initChannel(Channel ch) throws Exception {\n                 ch.pipeline().addLast(\"encoder_compress\", new HttpContentCompressor(handlingSettings.getCompressionLevel()));\n             }\n             ch.pipeline().addLast(\"request_creator\", requestCreator);\n+            ch.pipeline().addLast(\"response_creator\", responseCreator);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b3f541885d67e37994fe2ca69685733bd23ad8f"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTkyODMwNA==", "bodyText": "Will this not always result in chunked response? I would imagine we should check the size first and then pass the original message unmodified if below 128KB?", "url": "https://github.com/elastic/elasticsearch/pull/62666#discussion_r491928304", "createdAt": "2020-09-21T10:09:20Z", "author": {"login": "henningandersen"}, "path": "modules/transport-netty4/src/main/java/org/elasticsearch/http/netty4/Netty4HttpResponseCreator.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.http.netty4;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.channel.ChannelHandler;\n+import io.netty.channel.ChannelHandlerContext;\n+import io.netty.handler.codec.MessageToMessageEncoder;\n+import io.netty.handler.codec.http.DefaultHttpContent;\n+import io.netty.handler.codec.http.DefaultHttpResponse;\n+import io.netty.handler.codec.http.DefaultLastHttpContent;\n+import io.netty.handler.codec.http.HttpResponse;\n+\n+import java.util.List;\n+\n+@ChannelHandler.Sharable\n+class Netty4HttpResponseCreator extends MessageToMessageEncoder<Netty4HttpResponse> {\n+\n+    public static final int ONE_TWENTY_EIGHT_KB = 128 * 1024;\n+\n+    @Override\n+    protected void encode(ChannelHandlerContext ctx, Netty4HttpResponse msg, List<Object> out) {\n+        HttpResponse response = new DefaultHttpResponse(msg.protocolVersion(), msg.status(), msg.headers());\n+        out.add(response);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b3f541885d67e37994fe2ca69685733bd23ad8f"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTkyOTQyOQ==", "bodyText": "I wonder if we should make this a system property? Mainly to be able to set it very high in case the additional chunked transfer causes performance issues somewhere. Not intending to document or anything, just a safe-guard.\nnit: should be private.", "url": "https://github.com/elastic/elasticsearch/pull/62666#discussion_r491929429", "createdAt": "2020-09-21T10:11:25Z", "author": {"login": "henningandersen"}, "path": "modules/transport-netty4/src/main/java/org/elasticsearch/http/netty4/Netty4HttpResponseCreator.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.http.netty4;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.channel.ChannelHandler;\n+import io.netty.channel.ChannelHandlerContext;\n+import io.netty.handler.codec.MessageToMessageEncoder;\n+import io.netty.handler.codec.http.DefaultHttpContent;\n+import io.netty.handler.codec.http.DefaultHttpResponse;\n+import io.netty.handler.codec.http.DefaultLastHttpContent;\n+import io.netty.handler.codec.http.HttpResponse;\n+\n+import java.util.List;\n+\n+@ChannelHandler.Sharable\n+class Netty4HttpResponseCreator extends MessageToMessageEncoder<Netty4HttpResponse> {\n+\n+    public static final int ONE_TWENTY_EIGHT_KB = 128 * 1024;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b3f541885d67e37994fe2ca69685733bd23ad8f"}, "originalPosition": 36}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkyNTE5NzEx", "url": "https://github.com/elastic/elasticsearch/pull/62666#pullrequestreview-492519711", "createdAt": "2020-09-21T11:52:01Z", "commit": {"oid": "2b3f541885d67e37994fe2ca69685733bd23ad8f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQxMTo1MjowMVrOHVMO5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQxMTo1MjowMVrOHVMO5g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTk4MjU2Ng==", "bodyText": "I wonder if can do better here. If we just slice to 128k here, we'll still see massive amounts of 128k byte[] allocations for large responses. Couldn't we just copy to new ByteBuf allocated by Netty's allocator and pre-sized to 128k here and assume those will mostly be backed by a single byte[] (not sure if we can assume that I must admit but maybe there's some things we could do to make it so at least) and thus not incur the allocation in the compressor because ?\nOr asked the other way around, maybe we could just use a chunk size here that we know the Netty allocator would use single byte[] backed buffers for and use that?", "url": "https://github.com/elastic/elasticsearch/pull/62666#discussion_r491982566", "createdAt": "2020-09-21T11:52:01Z", "author": {"login": "original-brownbear"}, "path": "modules/transport-netty4/src/main/java/org/elasticsearch/http/netty4/Netty4HttpResponseCreator.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.http.netty4;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.channel.ChannelHandler;\n+import io.netty.channel.ChannelHandlerContext;\n+import io.netty.handler.codec.MessageToMessageEncoder;\n+import io.netty.handler.codec.http.DefaultHttpContent;\n+import io.netty.handler.codec.http.DefaultHttpResponse;\n+import io.netty.handler.codec.http.DefaultLastHttpContent;\n+import io.netty.handler.codec.http.HttpResponse;\n+\n+import java.util.List;\n+\n+@ChannelHandler.Sharable\n+class Netty4HttpResponseCreator extends MessageToMessageEncoder<Netty4HttpResponse> {\n+\n+    public static final int ONE_TWENTY_EIGHT_KB = 128 * 1024;\n+\n+    @Override\n+    protected void encode(ChannelHandlerContext ctx, Netty4HttpResponse msg, List<Object> out) {\n+        HttpResponse response = new DefaultHttpResponse(msg.protocolVersion(), msg.status(), msg.headers());\n+        out.add(response);\n+        ByteBuf content = msg.content();\n+        while (content.readableBytes() > ONE_TWENTY_EIGHT_KB) {\n+            out.add(new DefaultHttpContent(content.readRetainedSlice(ONE_TWENTY_EIGHT_KB)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b3f541885d67e37994fe2ca69685733bd23ad8f"}, "originalPosition": 44}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3c62705cbc9f0c6696e8fa027dac10a71878218e", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/3c62705cbc9f0c6696e8fa027dac10a71878218e", "committedDate": "2020-09-21T16:47:37Z", "message": "Merge remote-tracking branch 'upstream/master' into remove_batch_http_compression"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b582f2fdc40b2ca1d54d003a3cb4bfef96574a66", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/b582f2fdc40b2ca1d54d003a3cb4bfef96574a66", "committedDate": "2020-09-21T18:59:48Z", "message": "Changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a18f42f2b78ef5a1707cf4803c150de3c8ab0a57", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/a18f42f2b78ef5a1707cf4803c150de3c8ab0a57", "committedDate": "2020-09-21T19:50:43Z", "message": "WIP"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c5241bb853567cbe4c50d0366b39468b3c805764", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/c5241bb853567cbe4c50d0366b39468b3c805764", "committedDate": "2020-09-21T19:50:51Z", "message": "Merge remote-tracking branch 'upstream/master' into remove_batch_http_compression"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "769148b2156aaabc6272280fd3b60bfcbe6d487b", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/769148b2156aaabc6272280fd3b60bfcbe6d487b", "committedDate": "2020-09-21T20:44:33Z", "message": "Changes"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkyOTg0OTgx", "url": "https://github.com/elastic/elasticsearch/pull/62666#pullrequestreview-492984981", "createdAt": "2020-09-21T21:14:14Z", "commit": {"oid": "769148b2156aaabc6272280fd3b60bfcbe6d487b"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQyMToxNDoxNFrOHVipag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQyMToxNDozNlrOHVip_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjM0OTgwMg==", "bodyText": "Don't we by default have compression off with tls enabled?", "url": "https://github.com/elastic/elasticsearch/pull/62666#discussion_r492349802", "createdAt": "2020-09-21T21:14:14Z", "author": {"login": "original-brownbear"}, "path": "modules/transport-netty4/src/main/java/org/elasticsearch/http/netty4/Netty4HttpServerTransport.java", "diffHunk": "@@ -313,6 +315,7 @@ protected void initChannel(Channel ch) throws Exception {\n                 ch.pipeline().addLast(\"encoder_compress\", new HttpContentCompressor(handlingSettings.getCompressionLevel()));\n             }\n             ch.pipeline().addLast(\"request_creator\", requestCreator);\n+            ch.pipeline().addLast(\"response_creator\", responseCreator);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTcxMTE4Mw=="}, "originalCommit": {"oid": "2b3f541885d67e37994fe2ca69685733bd23ad8f"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjM0OTk1MA==", "bodyText": "Maybe add some short Javadoc here to explain why this is needed?", "url": "https://github.com/elastic/elasticsearch/pull/62666#discussion_r492349950", "createdAt": "2020-09-21T21:14:36Z", "author": {"login": "original-brownbear"}, "path": "modules/transport-netty4/src/main/java/org/elasticsearch/http/netty4/Netty4HttpResponseCreator.java", "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.http.netty4;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.channel.ChannelHandler;\n+import io.netty.channel.ChannelHandlerContext;\n+import io.netty.handler.codec.MessageToMessageEncoder;\n+import io.netty.handler.codec.http.DefaultHttpContent;\n+import io.netty.handler.codec.http.DefaultHttpResponse;\n+import io.netty.handler.codec.http.DefaultLastHttpContent;\n+import io.netty.handler.codec.http.HttpResponse;\n+import org.elasticsearch.common.Booleans;\n+import org.elasticsearch.transport.NettyAllocator;\n+\n+import java.util.List;\n+\n+@ChannelHandler.Sharable\n+class Netty4HttpResponseCreator extends MessageToMessageEncoder<Netty4HttpResponse> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "769148b2156aaabc6272280fd3b60bfcbe6d487b"}, "originalPosition": 36}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4dad3e675362026f7c850e8210c684108c6f9762", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/4dad3e675362026f7c850e8210c684108c6f9762", "committedDate": "2020-09-21T22:29:30Z", "message": "nio and javadoc"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkzMTg2ODQ3", "url": "https://github.com/elastic/elasticsearch/pull/62666#pullrequestreview-493186847", "createdAt": "2020-09-22T07:25:32Z", "commit": {"oid": "4dad3e675362026f7c850e8210c684108c6f9762"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMlQwNzoyNTozMlrOHVtRig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMlQwNzoyOTowOFrOHVtY-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjUyMzkxNA==", "bodyText": "I don't think this will show in benchmarks it's a small thing relative to the general noise in them for sure, but to me it seems strange to add general overhead for a workaround that's very specific to a concrete issue with the Netty compression implementation? (not too important to me, but still seems like it would also make it clearer why we're doing this).", "url": "https://github.com/elastic/elasticsearch/pull/62666#discussion_r492523914", "createdAt": "2020-09-22T07:25:32Z", "author": {"login": "original-brownbear"}, "path": "modules/transport-netty4/src/main/java/org/elasticsearch/http/netty4/Netty4HttpServerTransport.java", "diffHunk": "@@ -313,6 +315,7 @@ protected void initChannel(Channel ch) throws Exception {\n                 ch.pipeline().addLast(\"encoder_compress\", new HttpContentCompressor(handlingSettings.getCompressionLevel()));\n             }\n             ch.pipeline().addLast(\"request_creator\", requestCreator);\n+            ch.pipeline().addLast(\"response_creator\", responseCreator);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTcxMTE4Mw=="}, "originalCommit": {"oid": "2b3f541885d67e37994fe2ca69685733bd23ad8f"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjUyNTgxOA==", "bodyText": "Can't we just clearly link to Netty's JdkZlibEncoder here since that is the only actual reason we're splitting responses as of today? If we say \"or other CPU intensive operations\" posterity will have a hard time figuring out if it's safe to remove this or not? :)", "url": "https://github.com/elastic/elasticsearch/pull/62666#discussion_r492525818", "createdAt": "2020-09-22T07:29:08Z", "author": {"login": "original-brownbear"}, "path": "modules/transport-netty4/src/main/java/org/elasticsearch/http/netty4/Netty4HttpResponseCreator.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.http.netty4;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.channel.ChannelHandler;\n+import io.netty.channel.ChannelHandlerContext;\n+import io.netty.handler.codec.MessageToMessageEncoder;\n+import io.netty.handler.codec.http.DefaultHttpContent;\n+import io.netty.handler.codec.http.DefaultHttpResponse;\n+import io.netty.handler.codec.http.DefaultLastHttpContent;\n+import io.netty.handler.codec.http.HttpResponse;\n+import org.elasticsearch.common.Booleans;\n+import org.elasticsearch.transport.NettyAllocator;\n+\n+import java.util.List;\n+\n+/**\n+ * Split up large responses to prevent batch compression or other CPU intensive operations down the pipeline.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4dad3e675362026f7c850e8210c684108c6f9762"}, "originalPosition": 36}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkzMjMxMDE0", "url": "https://github.com/elastic/elasticsearch/pull/62666#pullrequestreview-493231014", "createdAt": "2020-09-22T08:27:11Z", "commit": {"oid": "4dad3e675362026f7c850e8210c684108c6f9762"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMlQwODoyNzoxMVrOHVvX9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMlQwODoyNzoxMVrOHVvX9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjU1ODMyNw==", "bodyText": "I think the last part sounds reasonable to do. I am curious about:\n\nused by both the testing and production code so it will be brittle to a concurrent failure where test code does a huge allocation\n\nIf we check the number of huge allocations before and after doing the http request I am not sure how anything concurrent can happen too in this test?", "url": "https://github.com/elastic/elasticsearch/pull/62666#discussion_r492558327", "createdAt": "2020-09-22T08:27:11Z", "author": {"login": "henningandersen"}, "path": "modules/transport-netty4/src/test/java/org/elasticsearch/http/netty4/Netty4HttpServerTransportTests.java", "diffHunk": "@@ -282,6 +282,52 @@ public void dispatchBadRequest(final RestChannel channel, final ThreadContext th\n         assertThat(causeReference.get(), instanceOf(TooLongFrameException.class));\n     }\n \n+    public void testLargeCompressedResponse() throws InterruptedException {\n+        final String responseString = randomAlphaOfLength(4 * 1024 * 1024);\n+        final String url = \"/thing\";\n+        final HttpServerTransport.Dispatcher dispatcher = new HttpServerTransport.Dispatcher() {\n+\n+            @Override\n+            public void dispatchRequest(final RestRequest request, final RestChannel channel, final ThreadContext threadContext) {\n+                if (url.equals(request.uri())) {\n+                    channel.sendResponse(new BytesRestResponse(OK, responseString));\n+                } else {\n+                    logger.error(\"--> Unexpected successful uri [{}]\", request.uri());\n+                    throw new AssertionError();\n+                }\n+            }\n+\n+            @Override\n+            public void dispatchBadRequest(final RestChannel channel, final ThreadContext threadContext, final Throwable cause) {\n+                logger.error(new ParameterizedMessage(\"--> Unexpected bad request [{}]\",\n+                    FakeRestRequest.requestToString(channel.request())), cause);\n+                throw new AssertionError();\n+            }\n+\n+        };\n+\n+        try (Netty4HttpServerTransport transport = new Netty4HttpServerTransport(\n+            Settings.EMPTY, networkService, bigArrays, threadPool, xContentRegistry(), dispatcher, clusterSettings,\n+            new SharedGroupFactory(Settings.EMPTY))) {\n+            transport.start();\n+            final TransportAddress remoteAddress = randomFrom(transport.boundAddress().boundAddresses());\n+\n+            try (Netty4HttpClient client = new Netty4HttpClient()) {\n+                DefaultFullHttpRequest request = new DefaultFullHttpRequest(HttpVersion.HTTP_1_1, HttpMethod.GET, url);\n+                request.headers().add(HttpHeaderNames.ACCEPT_ENCODING, randomFrom(\"deflate\", \"gzip\"));\n+                final FullHttpResponse response = client.send(remoteAddress.address(), request);\n+                try {\n+                    assertThat(response.status(), equalTo(HttpResponseStatus.OK));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTkxNDQzOA=="}, "originalCommit": {"oid": "2b3f541885d67e37994fe2ca69685733bd23ad8f"}, "originalPosition": 64}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "05bb7e0edd566d006f3127b9f98c2c55e097baca", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/05bb7e0edd566d006f3127b9f98c2c55e097baca", "committedDate": "2020-09-22T15:10:40Z", "message": "Merge remote-tracking branch 'upstream/master' into remove_batch_http_compression"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ddeb152cd12edcfcdda2eae1b1de0f2545470872", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/ddeb152cd12edcfcdda2eae1b1de0f2545470872", "committedDate": "2020-09-22T15:24:16Z", "message": "Changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "89cada52f65cb6118500b07e3d26e93a6ddedc2d", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/89cada52f65cb6118500b07e3d26e93a6ddedc2d", "committedDate": "2020-09-22T15:49:24Z", "message": "Fix test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "223f90160ca1a4615b842bbfee5620eaf22ae51f", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/223f90160ca1a4615b842bbfee5620eaf22ae51f", "committedDate": "2020-09-22T15:54:26Z", "message": "Add comment"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "28f342d4a711a94ead8405c687a715ed31a85363", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/28f342d4a711a94ead8405c687a715ed31a85363", "committedDate": "2020-09-22T16:44:08Z", "message": "log raw"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3b497f7f8dc1a7b0aecd0c397630d07bd41f4082", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/3b497f7f8dc1a7b0aecd0c397630d07bd41f4082", "committedDate": "2020-09-22T16:44:22Z", "message": "Merge remote-tracking branch 'upstream/master' into remove_batch_http_compression"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2b5fcdb2b0dee6e3fe8e0526b979106388289e24", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/2b5fcdb2b0dee6e3fe8e0526b979106388289e24", "committedDate": "2020-09-22T18:08:08Z", "message": "Merge remote-tracking branch 'upstream/master' into remove_batch_http_compression"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk1NDYwODY3", "url": "https://github.com/elastic/elasticsearch/pull/62666#pullrequestreview-495460867", "createdAt": "2020-09-24T11:13:50Z", "commit": {"oid": "2b5fcdb2b0dee6e3fe8e0526b979106388289e24"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk1ODIzNTcw", "url": "https://github.com/elastic/elasticsearch/pull/62666#pullrequestreview-495823570", "createdAt": "2020-09-24T18:05:53Z", "commit": {"oid": "2b5fcdb2b0dee6e3fe8e0526b979106388289e24"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQxODowNTo1M1rOHXml1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQxOToxMzo0NVrOHXpGiQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDUxMTU3Mg==", "bodyText": "nit: rename to numOfHugeAllocations", "url": "https://github.com/elastic/elasticsearch/pull/62666#discussion_r494511572", "createdAt": "2020-09-24T18:05:53Z", "author": {"login": "henningandersen"}, "path": "modules/transport-netty4/src/test/java/org/elasticsearch/http/netty4/Netty4HttpServerTransportTests.java", "diffHunk": "@@ -282,6 +286,68 @@ public void dispatchBadRequest(final RestChannel channel, final ThreadContext th\n         assertThat(causeReference.get(), instanceOf(TooLongFrameException.class));\n     }\n \n+    public void testLargeCompressedResponse() throws InterruptedException {\n+        final String responseString = randomAlphaOfLength(4 * 1024 * 1024);\n+        final String url = \"/thing\";\n+        final HttpServerTransport.Dispatcher dispatcher = new HttpServerTransport.Dispatcher() {\n+\n+            @Override\n+            public void dispatchRequest(final RestRequest request, final RestChannel channel, final ThreadContext threadContext) {\n+                if (url.equals(request.uri())) {\n+                    channel.sendResponse(new BytesRestResponse(OK, responseString));\n+                } else {\n+                    logger.error(\"--> Unexpected successful uri [{}]\", request.uri());\n+                    throw new AssertionError();\n+                }\n+            }\n+\n+            @Override\n+            public void dispatchBadRequest(final RestChannel channel, final ThreadContext threadContext, final Throwable cause) {\n+                logger.error(new ParameterizedMessage(\"--> Unexpected bad request [{}]\",\n+                    FakeRestRequest.requestToString(channel.request())), cause);\n+                throw new AssertionError();\n+            }\n+\n+        };\n+\n+        try (Netty4HttpServerTransport transport = new Netty4HttpServerTransport(\n+            Settings.EMPTY, networkService, bigArrays, threadPool, xContentRegistry(), dispatcher, clusterSettings,\n+            new SharedGroupFactory(Settings.EMPTY))) {\n+            transport.start();\n+            final TransportAddress remoteAddress = randomFrom(transport.boundAddress().boundAddresses());\n+\n+            try (Netty4HttpClient client = new Netty4HttpClient()) {\n+                DefaultFullHttpRequest request = new DefaultFullHttpRequest(HttpVersion.HTTP_1_1, HttpMethod.GET, url);\n+                request.headers().add(HttpHeaderNames.ACCEPT_ENCODING, randomFrom(\"deflate\", \"gzip\"));\n+                long numOfHugAllocations = getHugeAllocationCount();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b5fcdb2b0dee6e3fe8e0526b979106388289e24"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDU1MjcxMw==", "bodyText": "I think this is always true in tests? If so, I would prefer an assert to help ensure we do get a huge allocation count out.", "url": "https://github.com/elastic/elasticsearch/pull/62666#discussion_r494552713", "createdAt": "2020-09-24T19:13:45Z", "author": {"login": "henningandersen"}, "path": "modules/transport-netty4/src/test/java/org/elasticsearch/http/netty4/Netty4HttpServerTransportTests.java", "diffHunk": "@@ -282,6 +286,68 @@ public void dispatchBadRequest(final RestChannel channel, final ThreadContext th\n         assertThat(causeReference.get(), instanceOf(TooLongFrameException.class));\n     }\n \n+    public void testLargeCompressedResponse() throws InterruptedException {\n+        final String responseString = randomAlphaOfLength(4 * 1024 * 1024);\n+        final String url = \"/thing\";\n+        final HttpServerTransport.Dispatcher dispatcher = new HttpServerTransport.Dispatcher() {\n+\n+            @Override\n+            public void dispatchRequest(final RestRequest request, final RestChannel channel, final ThreadContext threadContext) {\n+                if (url.equals(request.uri())) {\n+                    channel.sendResponse(new BytesRestResponse(OK, responseString));\n+                } else {\n+                    logger.error(\"--> Unexpected successful uri [{}]\", request.uri());\n+                    throw new AssertionError();\n+                }\n+            }\n+\n+            @Override\n+            public void dispatchBadRequest(final RestChannel channel, final ThreadContext threadContext, final Throwable cause) {\n+                logger.error(new ParameterizedMessage(\"--> Unexpected bad request [{}]\",\n+                    FakeRestRequest.requestToString(channel.request())), cause);\n+                throw new AssertionError();\n+            }\n+\n+        };\n+\n+        try (Netty4HttpServerTransport transport = new Netty4HttpServerTransport(\n+            Settings.EMPTY, networkService, bigArrays, threadPool, xContentRegistry(), dispatcher, clusterSettings,\n+            new SharedGroupFactory(Settings.EMPTY))) {\n+            transport.start();\n+            final TransportAddress remoteAddress = randomFrom(transport.boundAddress().boundAddresses());\n+\n+            try (Netty4HttpClient client = new Netty4HttpClient()) {\n+                DefaultFullHttpRequest request = new DefaultFullHttpRequest(HttpVersion.HTTP_1_1, HttpMethod.GET, url);\n+                request.headers().add(HttpHeaderNames.ACCEPT_ENCODING, randomFrom(\"deflate\", \"gzip\"));\n+                long numOfHugAllocations = getHugeAllocationCount();\n+                final FullHttpResponse response = client.send(remoteAddress.address(), request);\n+                try {\n+                    assertThat(getHugeAllocationCount(), equalTo(numOfHugAllocations));\n+                    assertThat(response.status(), equalTo(HttpResponseStatus.OK));\n+                    byte[] bytes = new byte[response.content().readableBytes()];\n+                    response.content().readBytes(bytes);\n+                    assertThat(new String(bytes, StandardCharsets.UTF_8), equalTo(responseString));\n+                } finally {\n+                    response.release();\n+                }\n+            }\n+        }\n+    }\n+\n+    private long getHugeAllocationCount() {\n+        long numOfHugAllocations = 0;\n+        ByteBufAllocator allocator = NettyAllocator.getAllocator();\n+        if (allocator instanceof NettyAllocator.NoDirectBuffers) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b5fcdb2b0dee6e3fe8e0526b979106388289e24"}, "originalPosition": 92}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bd857887a0f5e1e214199a843883bb80160d166b", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/bd857887a0f5e1e214199a843883bb80160d166b", "committedDate": "2020-09-24T19:28:43Z", "message": "Review changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2a14c4cc2f518e0da127f03e27c5073c8213003c", "author": {"user": {"login": "tbrooks8", "name": "Tim Brooks"}}, "url": "https://github.com/elastic/elasticsearch/commit/2a14c4cc2f518e0da127f03e27c5073c8213003c", "committedDate": "2020-09-24T19:29:04Z", "message": "Merge remote-tracking branch 'upstream/master' into remove_batch_http_compression"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3581, "cost": 1, "resetAt": "2021-10-28T19:08:13Z"}}}