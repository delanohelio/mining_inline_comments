{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDUxMTE2MDA0", "number": 59773, "reviewThreads": {"totalCount": 45, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxMzo0MTo1NVrOESZGSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMzozNTo0MlrOEk-Q1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3NzIxMDMzOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxMzo0MTo1NVrOG3i-Xg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxMzo0MTo1NVrOG3i-Xg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDg5Nzg4Ng==", "bodyText": "What's the need of  extra TypeParsers.parseMultiField on line 169 if TypeParsers.parseField on line 155 already takes care of multi-field?   Should we choose one of these 2 options?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r460897886", "createdAt": "2020-07-27T13:41:55Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,550 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.support.XContentMapValues;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+        private boolean storeMalformed = false;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        Builder storeMalformed(boolean storeMalformed) {\n+            this.storeMalformed = storeMalformed;\n+            return builder;\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            boolean validateVersion = storeMalformed == false;\n+            return new VersionStringFieldType(buildFullName(context), indexed, validateVersion, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                storeMalformed,\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                } else if (propName.equals(\"store_malformed\")) {\n+                    builder.storeMalformed(XContentMapValues.nodeBooleanValue(propNode, name + \".store_malformed\"));\n+                    iterator.remove();\n+                } else if (TypeParsers.parseMultiField(builder::addMultiField, name, parserContext, propName, propNode)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 169}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3NzQ5MTQwOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxNDo0MTo0MVrOG3lo-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxNDo0MTo0MVrOG3lo-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk0MTU2Mw==", "bodyText": "Should we override and disallow indexOptions in Builder, similarly how NumberFieldMapper#Builder does it?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r460941563", "createdAt": "2020-07-27T14:41:41Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,550 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.support.XContentMapValues;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+        private boolean storeMalformed = false;\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 103}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3NzU0OTI5OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxNDo1Mzo1MlrOG3mMlw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxMDozMzo1OVrOHHGF5g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk1MDY3OQ==", "bodyText": "Do we want to assign nullValue here as as well in cases where a string is empty or null?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r460950679", "createdAt": "2020-07-27T14:53:52Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,550 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.support.XContentMapValues;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+        private boolean storeMalformed = false;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        Builder storeMalformed(boolean storeMalformed) {\n+            this.storeMalformed = storeMalformed;\n+            return builder;\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            boolean validateVersion = storeMalformed == false;\n+            return new VersionStringFieldType(buildFullName(context), indexed, validateVersion, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                storeMalformed,\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                } else if (propName.equals(\"store_malformed\")) {\n+                    builder.storeMalformed(XContentMapValues.nodeBooleanValue(propNode, name + \".store_malformed\"));\n+                    iterator.remove();\n+                } else if (TypeParsers.parseMultiField(builder::addMultiField, name, parserContext, propName, propNode)) {\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        // if true, we want to throw errors on illegal versions at index and query time\n+        private boolean validateVersion = false;\n+\n+        public VersionStringFieldType(\n+            String name,\n+            boolean isSearchable,\n+            boolean validateVersion,\n+            Map<String, String> meta,\n+            float boost,\n+            FieldType fieldType\n+        ) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+            this.validateVersion = validateVersion;\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            EncodedVersion encodedVersion = encodeVersion(valueAsString);\n+            if (encodedVersion.isLegal == false && validateVersion) {\n+                throw new IllegalArgumentException(\"Illegal version string: \" + valueAsString);\n+            }\n+            return encodedVersion.bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private boolean storeMalformed;\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        boolean storeMalformed,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.storeMalformed = storeMalformed;\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 460}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE4MjY0OQ==", "bodyText": "I actually wonder if this type should support null_value at all. I can't think of an example where it'd be useful to supply a default value for a version. And what could the default value even be?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461182649", "createdAt": "2020-07-27T21:32:14Z", "author": {"login": "jtibshirani"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,550 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.support.XContentMapValues;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+        private boolean storeMalformed = false;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        Builder storeMalformed(boolean storeMalformed) {\n+            this.storeMalformed = storeMalformed;\n+            return builder;\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            boolean validateVersion = storeMalformed == false;\n+            return new VersionStringFieldType(buildFullName(context), indexed, validateVersion, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                storeMalformed,\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                } else if (propName.equals(\"store_malformed\")) {\n+                    builder.storeMalformed(XContentMapValues.nodeBooleanValue(propNode, name + \".store_malformed\"));\n+                    iterator.remove();\n+                } else if (TypeParsers.parseMultiField(builder::addMultiField, name, parserContext, propName, propNode)) {\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        // if true, we want to throw errors on illegal versions at index and query time\n+        private boolean validateVersion = false;\n+\n+        public VersionStringFieldType(\n+            String name,\n+            boolean isSearchable,\n+            boolean validateVersion,\n+            Map<String, String> meta,\n+            float boost,\n+            FieldType fieldType\n+        ) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+            this.validateVersion = validateVersion;\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            EncodedVersion encodedVersion = encodeVersion(valueAsString);\n+            if (encodedVersion.isLegal == false && validateVersion) {\n+                throw new IllegalArgumentException(\"Illegal version string: \" + valueAsString);\n+            }\n+            return encodedVersion.bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private boolean storeMalformed;\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        boolean storeMalformed,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.storeMalformed = storeMalformed;\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk1MDY3OQ=="}, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 460}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTcwMzQxOA==", "bodyText": "I agree that default values are probably not that meaningful here, but e.g. 0.0.0 might be something users might want to index in case this value is null. I think I added this for versions so they behave as close to \"keyword\" fields as possible, also on the indexing side, but I'm open to discuss and remove this if you think its not required.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461703418", "createdAt": "2020-07-28T16:12:41Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,550 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.support.XContentMapValues;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+        private boolean storeMalformed = false;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        Builder storeMalformed(boolean storeMalformed) {\n+            this.storeMalformed = storeMalformed;\n+            return builder;\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            boolean validateVersion = storeMalformed == false;\n+            return new VersionStringFieldType(buildFullName(context), indexed, validateVersion, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                storeMalformed,\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                } else if (propName.equals(\"store_malformed\")) {\n+                    builder.storeMalformed(XContentMapValues.nodeBooleanValue(propNode, name + \".store_malformed\"));\n+                    iterator.remove();\n+                } else if (TypeParsers.parseMultiField(builder::addMultiField, name, parserContext, propName, propNode)) {\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        // if true, we want to throw errors on illegal versions at index and query time\n+        private boolean validateVersion = false;\n+\n+        public VersionStringFieldType(\n+            String name,\n+            boolean isSearchable,\n+            boolean validateVersion,\n+            Map<String, String> meta,\n+            float boost,\n+            FieldType fieldType\n+        ) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+            this.validateVersion = validateVersion;\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            EncodedVersion encodedVersion = encodeVersion(valueAsString);\n+            if (encodedVersion.isLegal == false && validateVersion) {\n+                throw new IllegalArgumentException(\"Illegal version string: \" + valueAsString);\n+            }\n+            return encodedVersion.bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private boolean storeMalformed;\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        boolean storeMalformed,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.storeMalformed = storeMalformed;\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk1MDY3OQ=="}, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 460}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ4ODE5Ng==", "bodyText": "It would be great to discuss (maybe through a different channel?), I've been wondering in general about whether most field types should support null_value.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462488196", "createdAt": "2020-07-29T18:04:51Z", "author": {"login": "jtibshirani"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,550 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.support.XContentMapValues;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+        private boolean storeMalformed = false;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        Builder storeMalformed(boolean storeMalformed) {\n+            this.storeMalformed = storeMalformed;\n+            return builder;\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            boolean validateVersion = storeMalformed == false;\n+            return new VersionStringFieldType(buildFullName(context), indexed, validateVersion, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                storeMalformed,\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                } else if (propName.equals(\"store_malformed\")) {\n+                    builder.storeMalformed(XContentMapValues.nodeBooleanValue(propNode, name + \".store_malformed\"));\n+                    iterator.remove();\n+                } else if (TypeParsers.parseMultiField(builder::addMultiField, name, parserContext, propName, propNode)) {\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        // if true, we want to throw errors on illegal versions at index and query time\n+        private boolean validateVersion = false;\n+\n+        public VersionStringFieldType(\n+            String name,\n+            boolean isSearchable,\n+            boolean validateVersion,\n+            Map<String, String> meta,\n+            float boost,\n+            FieldType fieldType\n+        ) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+            this.validateVersion = validateVersion;\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            EncodedVersion encodedVersion = encodeVersion(valueAsString);\n+            if (encodedVersion.isLegal == false && validateVersion) {\n+                throw new IllegalArgumentException(\"Illegal version string: \" + valueAsString);\n+            }\n+            return encodedVersion.bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private boolean storeMalformed;\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        boolean storeMalformed,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.storeMalformed = storeMalformed;\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk1MDY3OQ=="}, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 460}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzIwMTg5NA==", "bodyText": "I changed this PR to not allow setting null_value, however we accept null as a field value in the input json in which case we don't index any value into the field.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r477201894", "createdAt": "2020-08-26T10:33:59Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,550 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.support.XContentMapValues;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+        private boolean storeMalformed = false;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        Builder storeMalformed(boolean storeMalformed) {\n+            this.storeMalformed = storeMalformed;\n+            return builder;\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            boolean validateVersion = storeMalformed == false;\n+            return new VersionStringFieldType(buildFullName(context), indexed, validateVersion, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                storeMalformed,\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                } else if (propName.equals(\"store_malformed\")) {\n+                    builder.storeMalformed(XContentMapValues.nodeBooleanValue(propNode, name + \".store_malformed\"));\n+                    iterator.remove();\n+                } else if (TypeParsers.parseMultiField(builder::addMultiField, name, parserContext, propName, propNode)) {\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        // if true, we want to throw errors on illegal versions at index and query time\n+        private boolean validateVersion = false;\n+\n+        public VersionStringFieldType(\n+            String name,\n+            boolean isSearchable,\n+            boolean validateVersion,\n+            Map<String, String> meta,\n+            float boost,\n+            FieldType fieldType\n+        ) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+            this.validateVersion = validateVersion;\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            EncodedVersion encodedVersion = encodeVersion(valueAsString);\n+            if (encodedVersion.isLegal == false && validateVersion) {\n+                throw new IllegalArgumentException(\"Illegal version string: \" + valueAsString);\n+            }\n+            return encodedVersion.bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private boolean storeMalformed;\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        boolean storeMalformed,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.storeMalformed = storeMalformed;\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk1MDY3OQ=="}, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 460}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3ODYwMzgwOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxOToyNDowM1rOG3wS1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxOToyNDowM1rOG3wS1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTExNjExNg==", "bodyText": "RELESE -> RELEASE (and same issue below)", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461116116", "createdAt": "2020-07-27T19:24:03Z", "author": {"login": "jtibshirani"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantiv Versioning (https://semver.org/)\n+ *\n+ * Version strings are considered to consist of three parts:\n+ * <ul>\n+ *  <li> a numeric major.minor.patch part starting the version string (e.g. 1.2.3)\n+ *  <li> an optional \"pre-release\" part that starts with a `-` character and can consist of several alpha-numerical sections\n+ *  separated by dots (e.g. \"-alpha.2.3\")\n+ *  <li> an optional \"build\" part that starts with a `+` character. This will simply be treated as a prefix with no guaranteed ordering,\n+ *  (although the ordering should be alphabetical in most cases).\n+ * </ul>\n+ *\n+ * The version string is encoded such that the ordering works like the following:\n+ * <ul>\n+ *  <li> Major, minor, and patch versions are always compared numerically\n+ *  <li> pre-release version have lower precedence than a normal version. (e.g 1.0.0-alpha &lt; 1.0.0)\n+ *  <li> the precedence for pre-release versions with same main version is calculated comparing each dot separated identifier from\n+ *  left to right. Identifiers consisting of only digits are compared numerically and identifiers with letters or hyphens are compared\n+ *  lexically in ASCII sort order. Numeric identifiers always have lower precedence than non-numeric identifiers.\n+ * </ul>\n+ */\n+class VersionEncoder {\n+\n+    public static final byte NUMERIC_MARKER_BYTE = (byte) 0x01;\n+    public static final byte PRERELESE_SEPARATOR_BYTE = (byte) 0x02;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3ODYwNDgxOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxOToyNDoyM1rOG3wTfA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxOToyNDoyM1rOG3wTfA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTExNjI4NA==", "bodyText": "Semantiv -> Semantic", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461116284", "createdAt": "2020-07-27T19:24:23Z", "author": {"login": "jtibshirani"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantiv Versioning (https://semver.org/)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3ODYxMzMyOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxOToyNjo1NlrOG3wYvA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxNTo1Nzo0M1rOG4Tg4g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTExNzYyOA==", "bodyText": "This will simply be treated as a prefix with no guaranteed ordering, (although the ordering should be alphabetical in most cases).\n\nI'm not sure what this part means, could you clarify the behavior?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461117628", "createdAt": "2020-07-27T19:26:56Z", "author": {"login": "jtibshirani"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantiv Versioning (https://semver.org/)\n+ *\n+ * Version strings are considered to consist of three parts:\n+ * <ul>\n+ *  <li> a numeric major.minor.patch part starting the version string (e.g. 1.2.3)\n+ *  <li> an optional \"pre-release\" part that starts with a `-` character and can consist of several alpha-numerical sections\n+ *  separated by dots (e.g. \"-alpha.2.3\")\n+ *  <li> an optional \"build\" part that starts with a `+` character. This will simply be treated as a prefix with no guaranteed ordering,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY5MzE1NA==", "bodyText": "Sorry for the confusion, it should be \"suffix\" and I changed the description to a hopefully less confusing \"ascii order\"", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461693154", "createdAt": "2020-07-28T15:57:43Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantiv Versioning (https://semver.org/)\n+ *\n+ * Version strings are considered to consist of three parts:\n+ * <ul>\n+ *  <li> a numeric major.minor.patch part starting the version string (e.g. 1.2.3)\n+ *  <li> an optional \"pre-release\" part that starts with a `-` character and can consist of several alpha-numerical sections\n+ *  separated by dots (e.g. \"-alpha.2.3\")\n+ *  <li> an optional \"build\" part that starts with a `+` character. This will simply be treated as a prefix with no guaranteed ordering,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTExNzYyOA=="}, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3ODkzMTA2OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionFieldPlugin.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QyMTowMTowN1rOG3zaqw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QyMTowMTowN1rOG3zaqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE2NzI3NQ==", "bodyText": "Super small comment, you could just return Map.of(VersionStringFieldMapper.CONTENT_TYPE, new VersionStringFieldMapper.TypeParser())?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461167275", "createdAt": "2020-07-27T21:01:07Z", "author": {"login": "jtibshirani"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionFieldPlugin.java", "diffHunk": "@@ -0,0 +1,28 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.plugins.MapperPlugin;\n+import org.elasticsearch.plugins.Plugin;\n+\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+public class VersionFieldPlugin extends Plugin implements MapperPlugin {\n+\n+    public VersionFieldPlugin(Settings settings) {}\n+\n+    @Override\n+    public Map<String, Mapper.TypeParser> getMappers() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3ODkzOTExOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/test/java/org/elasticsearch/xpack/versionfield/VersionEncoderTests.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QyMTowMzozN1rOG3zflw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QyMTowMzozN1rOG3zflw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE2ODUzNQ==", "bodyText": "Great unit test coverage!", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461168535", "createdAt": "2020-07-27T21:03:37Z", "author": {"login": "jtibshirani"}, "path": "x-pack/plugin/versionfield/src/test/java/org/elasticsearch/xpack/versionfield/VersionEncoderTests.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.util.Arrays;\n+\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.decodeVersion;\n+\n+public class VersionEncoderTests extends ESTestCase {\n+\n+    public void testEncodingOrderingSemver() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3OTA2NDQzOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QyMTo0Mzo0OVrOG30sBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxODowNzowNlrOG5EHTQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE4ODEwMg==", "bodyText": "Small comment, maybe we could have a constructor (or static factory method) to create illegal versions, like EncodedVersion.createIllegalVersion(versionString) ? This would avoid exposing the option to create an illegal version plus parsed components.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461188102", "createdAt": "2020-07-27T21:43:49Z", "author": {"login": "jtibshirani"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantiv Versioning (https://semver.org/)\n+ *\n+ * Version strings are considered to consist of three parts:\n+ * <ul>\n+ *  <li> a numeric major.minor.patch part starting the version string (e.g. 1.2.3)\n+ *  <li> an optional \"pre-release\" part that starts with a `-` character and can consist of several alpha-numerical sections\n+ *  separated by dots (e.g. \"-alpha.2.3\")\n+ *  <li> an optional \"build\" part that starts with a `+` character. This will simply be treated as a prefix with no guaranteed ordering,\n+ *  (although the ordering should be alphabetical in most cases).\n+ * </ul>\n+ *\n+ * The version string is encoded such that the ordering works like the following:\n+ * <ul>\n+ *  <li> Major, minor, and patch versions are always compared numerically\n+ *  <li> pre-release version have lower precedence than a normal version. (e.g 1.0.0-alpha &lt; 1.0.0)\n+ *  <li> the precedence for pre-release versions with same main version is calculated comparing each dot separated identifier from\n+ *  left to right. Identifiers consisting of only digits are compared numerically and identifiers with letters or hyphens are compared\n+ *  lexically in ASCII sort order. Numeric identifiers always have lower precedence than non-numeric identifiers.\n+ * </ul>\n+ */\n+class VersionEncoder {\n+\n+    public static final byte NUMERIC_MARKER_BYTE = (byte) 0x01;\n+    public static final byte PRERELESE_SEPARATOR_BYTE = (byte) 0x02;\n+    public static final byte NO_PRERELESE_SEPARATOR_BYTE = (byte) 0x03;\n+\n+    private static final char PRERELESE_SEPARATOR = '-';\n+    private static final char DOT_SEPARATOR = '.';\n+    private static final char BUILD_SEPARATOR = '+';\n+\n+    // Regex to test relaxed Semver Main Version validity. Allows for more or less than three main version parts\n+    private static Pattern LEGAL_MAIN_VERSION_SEMVER = Pattern.compile(\"(0|[1-9]\\\\d*)(\\\\.(0|[1-9]\\\\d*))*\");\n+\n+    private static Pattern LEGAL_PRERELEASE_VERSION_SEMVER = Pattern.compile(\n+        \"(?:-((?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\\\\.(?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*))*))\"\n+    );\n+\n+    private static Pattern LEGAL_BUILDSUFFIX_SEMVER = Pattern.compile(\"(?:\\\\+([0-9a-zA-Z-]+(?:\\\\.[0-9a-zA-Z-]+)*))?\");\n+\n+    /**\n+     * Encodes a version string.\n+     */\n+    public static EncodedVersion encodeVersion(String versionString) {\n+        VersionParts versionParts = VersionParts.ofVersion(versionString);\n+\n+        // don't treat non-legal versions further, just mark them as illegal and return\n+        if (legalVersionString(versionParts) == false) {\n+            return new EncodedVersion(new BytesRef(versionString), false, true, 0, 0, 0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY3NTAwNw==", "bodyText": "I made the class package private and the ctor private, hope that fits your suggestion.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461675007", "createdAt": "2020-07-28T15:32:04Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantiv Versioning (https://semver.org/)\n+ *\n+ * Version strings are considered to consist of three parts:\n+ * <ul>\n+ *  <li> a numeric major.minor.patch part starting the version string (e.g. 1.2.3)\n+ *  <li> an optional \"pre-release\" part that starts with a `-` character and can consist of several alpha-numerical sections\n+ *  separated by dots (e.g. \"-alpha.2.3\")\n+ *  <li> an optional \"build\" part that starts with a `+` character. This will simply be treated as a prefix with no guaranteed ordering,\n+ *  (although the ordering should be alphabetical in most cases).\n+ * </ul>\n+ *\n+ * The version string is encoded such that the ordering works like the following:\n+ * <ul>\n+ *  <li> Major, minor, and patch versions are always compared numerically\n+ *  <li> pre-release version have lower precedence than a normal version. (e.g 1.0.0-alpha &lt; 1.0.0)\n+ *  <li> the precedence for pre-release versions with same main version is calculated comparing each dot separated identifier from\n+ *  left to right. Identifiers consisting of only digits are compared numerically and identifiers with letters or hyphens are compared\n+ *  lexically in ASCII sort order. Numeric identifiers always have lower precedence than non-numeric identifiers.\n+ * </ul>\n+ */\n+class VersionEncoder {\n+\n+    public static final byte NUMERIC_MARKER_BYTE = (byte) 0x01;\n+    public static final byte PRERELESE_SEPARATOR_BYTE = (byte) 0x02;\n+    public static final byte NO_PRERELESE_SEPARATOR_BYTE = (byte) 0x03;\n+\n+    private static final char PRERELESE_SEPARATOR = '-';\n+    private static final char DOT_SEPARATOR = '.';\n+    private static final char BUILD_SEPARATOR = '+';\n+\n+    // Regex to test relaxed Semver Main Version validity. Allows for more or less than three main version parts\n+    private static Pattern LEGAL_MAIN_VERSION_SEMVER = Pattern.compile(\"(0|[1-9]\\\\d*)(\\\\.(0|[1-9]\\\\d*))*\");\n+\n+    private static Pattern LEGAL_PRERELEASE_VERSION_SEMVER = Pattern.compile(\n+        \"(?:-((?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\\\\.(?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*))*))\"\n+    );\n+\n+    private static Pattern LEGAL_BUILDSUFFIX_SEMVER = Pattern.compile(\"(?:\\\\+([0-9a-zA-Z-]+(?:\\\\.[0-9a-zA-Z-]+)*))?\");\n+\n+    /**\n+     * Encodes a version string.\n+     */\n+    public static EncodedVersion encodeVersion(String versionString) {\n+        VersionParts versionParts = VersionParts.ofVersion(versionString);\n+\n+        // don't treat non-legal versions further, just mark them as illegal and return\n+        if (legalVersionString(versionParts) == false) {\n+            return new EncodedVersion(new BytesRef(versionString), false, true, 0, 0, 0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE4ODEwMg=="}, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ4OTQyMQ==", "bodyText": "\ud83d\udc4d  this helps address the concern.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462489421", "createdAt": "2020-07-29T18:07:06Z", "author": {"login": "jtibshirani"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantiv Versioning (https://semver.org/)\n+ *\n+ * Version strings are considered to consist of three parts:\n+ * <ul>\n+ *  <li> a numeric major.minor.patch part starting the version string (e.g. 1.2.3)\n+ *  <li> an optional \"pre-release\" part that starts with a `-` character and can consist of several alpha-numerical sections\n+ *  separated by dots (e.g. \"-alpha.2.3\")\n+ *  <li> an optional \"build\" part that starts with a `+` character. This will simply be treated as a prefix with no guaranteed ordering,\n+ *  (although the ordering should be alphabetical in most cases).\n+ * </ul>\n+ *\n+ * The version string is encoded such that the ordering works like the following:\n+ * <ul>\n+ *  <li> Major, minor, and patch versions are always compared numerically\n+ *  <li> pre-release version have lower precedence than a normal version. (e.g 1.0.0-alpha &lt; 1.0.0)\n+ *  <li> the precedence for pre-release versions with same main version is calculated comparing each dot separated identifier from\n+ *  left to right. Identifiers consisting of only digits are compared numerically and identifiers with letters or hyphens are compared\n+ *  lexically in ASCII sort order. Numeric identifiers always have lower precedence than non-numeric identifiers.\n+ * </ul>\n+ */\n+class VersionEncoder {\n+\n+    public static final byte NUMERIC_MARKER_BYTE = (byte) 0x01;\n+    public static final byte PRERELESE_SEPARATOR_BYTE = (byte) 0x02;\n+    public static final byte NO_PRERELESE_SEPARATOR_BYTE = (byte) 0x03;\n+\n+    private static final char PRERELESE_SEPARATOR = '-';\n+    private static final char DOT_SEPARATOR = '.';\n+    private static final char BUILD_SEPARATOR = '+';\n+\n+    // Regex to test relaxed Semver Main Version validity. Allows for more or less than three main version parts\n+    private static Pattern LEGAL_MAIN_VERSION_SEMVER = Pattern.compile(\"(0|[1-9]\\\\d*)(\\\\.(0|[1-9]\\\\d*))*\");\n+\n+    private static Pattern LEGAL_PRERELEASE_VERSION_SEMVER = Pattern.compile(\n+        \"(?:-((?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\\\\.(?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*))*))\"\n+    );\n+\n+    private static Pattern LEGAL_BUILDSUFFIX_SEMVER = Pattern.compile(\"(?:\\\\+([0-9a-zA-Z-]+(?:\\\\.[0-9a-zA-Z-]+)*))?\");\n+\n+    /**\n+     * Encodes a version string.\n+     */\n+    public static EncodedVersion encodeVersion(String versionString) {\n+        VersionParts versionParts = VersionParts.ofVersion(versionString);\n+\n+        // don't treat non-legal versions further, just mark them as illegal and return\n+        if (legalVersionString(versionParts) == false) {\n+            return new EncodedVersion(new BytesRef(versionString), false, true, 0, 0, 0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE4ODEwMg=="}, "originalCommit": {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4MTY0NDQ2OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxMzozNzowMFrOG4M7VA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxNjowNToxOVrOG4T1Vg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTU4NTIzNg==", "bodyText": "may be worth separating this function into 2 functions: one that just prefix digit group with length and another one extracts main versions?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461585236", "createdAt": "2020-07-28T13:37:00Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantiv Versioning (https://semver.org/)\n+ *\n+ * Version strings are considered to consist of three parts:\n+ * <ul>\n+ *  <li> a numeric major.minor.patch part starting the version string (e.g. 1.2.3)\n+ *  <li> an optional \"pre-release\" part that starts with a `-` character and can consist of several alpha-numerical sections\n+ *  separated by dots (e.g. \"-alpha.2.3\")\n+ *  <li> an optional \"build\" part that starts with a `+` character. This will simply be treated as a prefix with no guaranteed ordering,\n+ *  (although the ordering should be alphabetical in most cases).\n+ * </ul>\n+ *\n+ * The version string is encoded such that the ordering works like the following:\n+ * <ul>\n+ *  <li> Major, minor, and patch versions are always compared numerically\n+ *  <li> pre-release version have lower precedence than a normal version. (e.g 1.0.0-alpha &lt; 1.0.0)\n+ *  <li> the precedence for pre-release versions with same main version is calculated comparing each dot separated identifier from\n+ *  left to right. Identifiers consisting of only digits are compared numerically and identifiers with letters or hyphens are compared\n+ *  lexically in ASCII sort order. Numeric identifiers always have lower precedence than non-numeric identifiers.\n+ * </ul>\n+ */\n+class VersionEncoder {\n+\n+    public static final byte NUMERIC_MARKER_BYTE = (byte) 0x01;\n+    public static final byte PRERELESE_SEPARATOR_BYTE = (byte) 0x02;\n+    public static final byte NO_PRERELESE_SEPARATOR_BYTE = (byte) 0x03;\n+\n+    private static final char PRERELESE_SEPARATOR = '-';\n+    private static final char DOT_SEPARATOR = '.';\n+    private static final char BUILD_SEPARATOR = '+';\n+\n+    // Regex to test relaxed Semver Main Version validity. Allows for more or less than three main version parts\n+    private static Pattern LEGAL_MAIN_VERSION_SEMVER = Pattern.compile(\"(0|[1-9]\\\\d*)(\\\\.(0|[1-9]\\\\d*))*\");\n+\n+    private static Pattern LEGAL_PRERELEASE_VERSION_SEMVER = Pattern.compile(\n+        \"(?:-((?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\\\\.(?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*))*))\"\n+    );\n+\n+    private static Pattern LEGAL_BUILDSUFFIX_SEMVER = Pattern.compile(\"(?:\\\\+([0-9a-zA-Z-]+(?:\\\\.[0-9a-zA-Z-]+)*))?\");\n+\n+    /**\n+     * Encodes a version string.\n+     */\n+    public static EncodedVersion encodeVersion(String versionString) {\n+        VersionParts versionParts = VersionParts.ofVersion(versionString);\n+\n+        // don't treat non-legal versions further, just mark them as illegal and return\n+        if (legalVersionString(versionParts) == false) {\n+            return new EncodedVersion(new BytesRef(versionString), false, true, 0, 0, 0);\n+        }\n+\n+        BytesRefBuilder encodedBytes = new BytesRefBuilder();\n+        Integer[] mainVersionParts = prefixDigitGroupsWithLength(versionParts.mainVersion, encodedBytes);\n+\n+        if (versionParts.preRelease != null) {\n+            encodedBytes.append(PRERELESE_SEPARATOR_BYTE);  // versions with pre-release part sort before ones without\n+            encodedBytes.append((byte) PRERELESE_SEPARATOR);\n+            String[] preReleaseParts = versionParts.preRelease.substring(1).split(\"\\\\.\");\n+            boolean first = true;\n+            for (String preReleasePart : preReleaseParts) {\n+                if (first == false) {\n+                    encodedBytes.append((byte) DOT_SEPARATOR);\n+                }\n+                boolean isNumeric = preReleasePart.chars().allMatch(x -> Character.isDigit(x));\n+                if (isNumeric) {\n+                    prefixDigitGroupsWithLength(preReleasePart, encodedBytes);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6d71b52424efa5423f9d4603a00706cb34561639"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY5ODM5MA==", "bodyText": "I couldn't find a simple way to split this methodf that wouldn't involve running through the input string at least twice. This way we avoid two passes, but I'm happy for any suggestions how to change this if you have an idea...", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461698390", "createdAt": "2020-07-28T16:05:19Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantiv Versioning (https://semver.org/)\n+ *\n+ * Version strings are considered to consist of three parts:\n+ * <ul>\n+ *  <li> a numeric major.minor.patch part starting the version string (e.g. 1.2.3)\n+ *  <li> an optional \"pre-release\" part that starts with a `-` character and can consist of several alpha-numerical sections\n+ *  separated by dots (e.g. \"-alpha.2.3\")\n+ *  <li> an optional \"build\" part that starts with a `+` character. This will simply be treated as a prefix with no guaranteed ordering,\n+ *  (although the ordering should be alphabetical in most cases).\n+ * </ul>\n+ *\n+ * The version string is encoded such that the ordering works like the following:\n+ * <ul>\n+ *  <li> Major, minor, and patch versions are always compared numerically\n+ *  <li> pre-release version have lower precedence than a normal version. (e.g 1.0.0-alpha &lt; 1.0.0)\n+ *  <li> the precedence for pre-release versions with same main version is calculated comparing each dot separated identifier from\n+ *  left to right. Identifiers consisting of only digits are compared numerically and identifiers with letters or hyphens are compared\n+ *  lexically in ASCII sort order. Numeric identifiers always have lower precedence than non-numeric identifiers.\n+ * </ul>\n+ */\n+class VersionEncoder {\n+\n+    public static final byte NUMERIC_MARKER_BYTE = (byte) 0x01;\n+    public static final byte PRERELESE_SEPARATOR_BYTE = (byte) 0x02;\n+    public static final byte NO_PRERELESE_SEPARATOR_BYTE = (byte) 0x03;\n+\n+    private static final char PRERELESE_SEPARATOR = '-';\n+    private static final char DOT_SEPARATOR = '.';\n+    private static final char BUILD_SEPARATOR = '+';\n+\n+    // Regex to test relaxed Semver Main Version validity. Allows for more or less than three main version parts\n+    private static Pattern LEGAL_MAIN_VERSION_SEMVER = Pattern.compile(\"(0|[1-9]\\\\d*)(\\\\.(0|[1-9]\\\\d*))*\");\n+\n+    private static Pattern LEGAL_PRERELEASE_VERSION_SEMVER = Pattern.compile(\n+        \"(?:-((?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\\\\.(?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*))*))\"\n+    );\n+\n+    private static Pattern LEGAL_BUILDSUFFIX_SEMVER = Pattern.compile(\"(?:\\\\+([0-9a-zA-Z-]+(?:\\\\.[0-9a-zA-Z-]+)*))?\");\n+\n+    /**\n+     * Encodes a version string.\n+     */\n+    public static EncodedVersion encodeVersion(String versionString) {\n+        VersionParts versionParts = VersionParts.ofVersion(versionString);\n+\n+        // don't treat non-legal versions further, just mark them as illegal and return\n+        if (legalVersionString(versionParts) == false) {\n+            return new EncodedVersion(new BytesRef(versionString), false, true, 0, 0, 0);\n+        }\n+\n+        BytesRefBuilder encodedBytes = new BytesRefBuilder();\n+        Integer[] mainVersionParts = prefixDigitGroupsWithLength(versionParts.mainVersion, encodedBytes);\n+\n+        if (versionParts.preRelease != null) {\n+            encodedBytes.append(PRERELESE_SEPARATOR_BYTE);  // versions with pre-release part sort before ones without\n+            encodedBytes.append((byte) PRERELESE_SEPARATOR);\n+            String[] preReleaseParts = versionParts.preRelease.substring(1).split(\"\\\\.\");\n+            boolean first = true;\n+            for (String preReleasePart : preReleaseParts) {\n+                if (first == false) {\n+                    encodedBytes.append((byte) DOT_SEPARATOR);\n+                }\n+                boolean isNumeric = preReleasePart.chars().allMatch(x -> Character.isDigit(x));\n+                if (isNumeric) {\n+                    prefixDigitGroupsWithLength(preReleasePart, encodedBytes);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTU4NTIzNg=="}, "originalCommit": {"oid": "6d71b52424efa5423f9d4603a00706cb34561639"}, "originalPosition": 81}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4MjIyMTE2OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxNTozMzoyNFrOG4Sdmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMzo0NjoyNFrOG45NDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY3NTkzMQ==", "bodyText": "That's quite a clever encoding! Nice work! What I like about it is that it allows the decoding to the original values.\nAnother way to do encoding I was thinking of is to standardize main versions to 3 bytes (1 byte of each component), but standardization would not allow the decoding to the original values.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461675931", "createdAt": "2020-07-28T15:33:24Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantiv Versioning (https://semver.org/)\n+ *\n+ * Version strings are considered to consist of three parts:\n+ * <ul>\n+ *  <li> a numeric major.minor.patch part starting the version string (e.g. 1.2.3)\n+ *  <li> an optional \"pre-release\" part that starts with a `-` character and can consist of several alpha-numerical sections\n+ *  separated by dots (e.g. \"-alpha.2.3\")\n+ *  <li> an optional \"build\" part that starts with a `+` character. This will simply be treated as a prefix with no guaranteed ordering,\n+ *  (although the ordering should be alphabetical in most cases).\n+ * </ul>\n+ *\n+ * The version string is encoded such that the ordering works like the following:\n+ * <ul>\n+ *  <li> Major, minor, and patch versions are always compared numerically\n+ *  <li> pre-release version have lower precedence than a normal version. (e.g 1.0.0-alpha &lt; 1.0.0)\n+ *  <li> the precedence for pre-release versions with same main version is calculated comparing each dot separated identifier from\n+ *  left to right. Identifiers consisting of only digits are compared numerically and identifiers with letters or hyphens are compared\n+ *  lexically in ASCII sort order. Numeric identifiers always have lower precedence than non-numeric identifiers.\n+ * </ul>\n+ */\n+class VersionEncoder {\n+\n+    public static final byte NUMERIC_MARKER_BYTE = (byte) 0x01;\n+    public static final byte PRERELESE_SEPARATOR_BYTE = (byte) 0x02;\n+    public static final byte NO_PRERELESE_SEPARATOR_BYTE = (byte) 0x03;\n+\n+    private static final char PRERELESE_SEPARATOR = '-';\n+    private static final char DOT_SEPARATOR = '.';\n+    private static final char BUILD_SEPARATOR = '+';\n+\n+    // Regex to test relaxed Semver Main Version validity. Allows for more or less than three main version parts\n+    private static Pattern LEGAL_MAIN_VERSION_SEMVER = Pattern.compile(\"(0|[1-9]\\\\d*)(\\\\.(0|[1-9]\\\\d*))*\");\n+\n+    private static Pattern LEGAL_PRERELEASE_VERSION_SEMVER = Pattern.compile(\n+        \"(?:-((?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\\\\.(?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*))*))\"\n+    );\n+\n+    private static Pattern LEGAL_BUILDSUFFIX_SEMVER = Pattern.compile(\"(?:\\\\+([0-9a-zA-Z-]+(?:\\\\.[0-9a-zA-Z-]+)*))?\");\n+\n+    /**\n+     * Encodes a version string.\n+     */\n+    public static EncodedVersion encodeVersion(String versionString) {\n+        VersionParts versionParts = VersionParts.ofVersion(versionString);\n+\n+        // don't treat non-legal versions further, just mark them as illegal and return\n+        if (legalVersionString(versionParts) == false) {\n+            return new EncodedVersion(new BytesRef(versionString), false, true, 0, 0, 0);\n+        }\n+\n+        BytesRefBuilder encodedBytes = new BytesRefBuilder();\n+        Integer[] mainVersionParts = prefixDigitGroupsWithLength(versionParts.mainVersion, encodedBytes);\n+\n+        if (versionParts.preRelease != null) {\n+            encodedBytes.append(PRERELESE_SEPARATOR_BYTE);  // versions with pre-release part sort before ones without\n+            encodedBytes.append((byte) PRERELESE_SEPARATOR);\n+            String[] preReleaseParts = versionParts.preRelease.substring(1).split(\"\\\\.\");\n+            boolean first = true;\n+            for (String preReleasePart : preReleaseParts) {\n+                if (first == false) {\n+                    encodedBytes.append((byte) DOT_SEPARATOR);\n+                }\n+                boolean isNumeric = preReleasePart.chars().allMatch(x -> Character.isDigit(x));\n+                if (isNumeric) {\n+                    prefixDigitGroupsWithLength(preReleasePart, encodedBytes);\n+                } else {\n+                    encodedBytes.append(new BytesRef(preReleasePart));\n+                }\n+                first = false;\n+            }\n+        } else {\n+            encodedBytes.append(NO_PRERELESE_SEPARATOR_BYTE);\n+        }\n+\n+        if (versionParts.buildSuffix != null) {\n+            encodedBytes.append(new BytesRef(versionParts.buildSuffix));\n+        }\n+        return new EncodedVersion(\n+            encodedBytes.toBytesRef(),\n+            true,\n+            versionParts.preRelease != null,\n+            mainVersionParts[0],\n+            mainVersionParts[1],\n+            mainVersionParts[2]\n+        );\n+    }\n+\n+    private static Integer[] prefixDigitGroupsWithLength(String input, BytesRefBuilder result) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6d71b52424efa5423f9d4603a00706cb34561639"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjMxMDY3MQ==", "bodyText": "Yes, being able to get back the original values is quite important here, e.g. we need that when needing to display encoded docvalues (e.g. keys for terms aggs where I first encountered that problem). I tried several approaches with encoding main verison parts as bytes (several widths) but they all failed either because bein too restrictive (we also want to allow less or more than 3 main digits, as an extension to strict semver, e.g. \"1.0.14.20201027\") and the range of verison numbers is in theory unlimited. Thats why in the end I prefer this simpler apporoach which can also be used for numeric parts in the pre-release part of the version string.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462310671", "createdAt": "2020-07-29T13:46:24Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantiv Versioning (https://semver.org/)\n+ *\n+ * Version strings are considered to consist of three parts:\n+ * <ul>\n+ *  <li> a numeric major.minor.patch part starting the version string (e.g. 1.2.3)\n+ *  <li> an optional \"pre-release\" part that starts with a `-` character and can consist of several alpha-numerical sections\n+ *  separated by dots (e.g. \"-alpha.2.3\")\n+ *  <li> an optional \"build\" part that starts with a `+` character. This will simply be treated as a prefix with no guaranteed ordering,\n+ *  (although the ordering should be alphabetical in most cases).\n+ * </ul>\n+ *\n+ * The version string is encoded such that the ordering works like the following:\n+ * <ul>\n+ *  <li> Major, minor, and patch versions are always compared numerically\n+ *  <li> pre-release version have lower precedence than a normal version. (e.g 1.0.0-alpha &lt; 1.0.0)\n+ *  <li> the precedence for pre-release versions with same main version is calculated comparing each dot separated identifier from\n+ *  left to right. Identifiers consisting of only digits are compared numerically and identifiers with letters or hyphens are compared\n+ *  lexically in ASCII sort order. Numeric identifiers always have lower precedence than non-numeric identifiers.\n+ * </ul>\n+ */\n+class VersionEncoder {\n+\n+    public static final byte NUMERIC_MARKER_BYTE = (byte) 0x01;\n+    public static final byte PRERELESE_SEPARATOR_BYTE = (byte) 0x02;\n+    public static final byte NO_PRERELESE_SEPARATOR_BYTE = (byte) 0x03;\n+\n+    private static final char PRERELESE_SEPARATOR = '-';\n+    private static final char DOT_SEPARATOR = '.';\n+    private static final char BUILD_SEPARATOR = '+';\n+\n+    // Regex to test relaxed Semver Main Version validity. Allows for more or less than three main version parts\n+    private static Pattern LEGAL_MAIN_VERSION_SEMVER = Pattern.compile(\"(0|[1-9]\\\\d*)(\\\\.(0|[1-9]\\\\d*))*\");\n+\n+    private static Pattern LEGAL_PRERELEASE_VERSION_SEMVER = Pattern.compile(\n+        \"(?:-((?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\\\\.(?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*))*))\"\n+    );\n+\n+    private static Pattern LEGAL_BUILDSUFFIX_SEMVER = Pattern.compile(\"(?:\\\\+([0-9a-zA-Z-]+(?:\\\\.[0-9a-zA-Z-]+)*))?\");\n+\n+    /**\n+     * Encodes a version string.\n+     */\n+    public static EncodedVersion encodeVersion(String versionString) {\n+        VersionParts versionParts = VersionParts.ofVersion(versionString);\n+\n+        // don't treat non-legal versions further, just mark them as illegal and return\n+        if (legalVersionString(versionParts) == false) {\n+            return new EncodedVersion(new BytesRef(versionString), false, true, 0, 0, 0);\n+        }\n+\n+        BytesRefBuilder encodedBytes = new BytesRefBuilder();\n+        Integer[] mainVersionParts = prefixDigitGroupsWithLength(versionParts.mainVersion, encodedBytes);\n+\n+        if (versionParts.preRelease != null) {\n+            encodedBytes.append(PRERELESE_SEPARATOR_BYTE);  // versions with pre-release part sort before ones without\n+            encodedBytes.append((byte) PRERELESE_SEPARATOR);\n+            String[] preReleaseParts = versionParts.preRelease.substring(1).split(\"\\\\.\");\n+            boolean first = true;\n+            for (String preReleasePart : preReleaseParts) {\n+                if (first == false) {\n+                    encodedBytes.append((byte) DOT_SEPARATOR);\n+                }\n+                boolean isNumeric = preReleasePart.chars().allMatch(x -> Character.isDigit(x));\n+                if (isNumeric) {\n+                    prefixDigitGroupsWithLength(preReleasePart, encodedBytes);\n+                } else {\n+                    encodedBytes.append(new BytesRef(preReleasePart));\n+                }\n+                first = false;\n+            }\n+        } else {\n+            encodedBytes.append(NO_PRERELESE_SEPARATOR_BYTE);\n+        }\n+\n+        if (versionParts.buildSuffix != null) {\n+            encodedBytes.append(new BytesRef(versionParts.buildSuffix));\n+        }\n+        return new EncodedVersion(\n+            encodedBytes.toBytesRef(),\n+            true,\n+            versionParts.preRelease != null,\n+            mainVersionParts[0],\n+            mainVersionParts[1],\n+            mainVersionParts[2]\n+        );\n+    }\n+\n+    private static Integer[] prefixDigitGroupsWithLength(String input, BytesRefBuilder result) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY3NTkzMQ=="}, "originalCommit": {"oid": "6d71b52424efa5423f9d4603a00706cb34561639"}, "originalPosition": 104}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5MDEwMDg4OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxMDoyNjo0MFrOG5dSfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxMDoyNjo0MFrOG5dSfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkwMTg4Nw==", "bodyText": "Should we index BinaryPoint only when indexOptions() != IndexOptions.NONE (because currently this field will be indexed even when IndexOptions.NONE and stored=true) ?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462901887", "createdAt": "2020-07-30T10:26:40Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);\n+            context.doc().add(field);\n+            // encode the first 16 bytes as points for efficient range query\n+            byte[] first16bytes = Arrays.copyOfRange(encodedVersion.bytes, encodedVersion.offset, 16);\n+            context.doc().add(new BinaryPoint(fieldType().name(), first16bytes));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 448}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5MDEwOTgxOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxMDoyOToyMVrOG5dX5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxMDozNToxNlrOHHGIdg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkwMzI2OQ==", "bodyText": "Should we create this field only when hasDocValues() == true?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462903269", "createdAt": "2020-07-30T10:29:21Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);\n+            context.doc().add(field);\n+            // encode the first 16 bytes as points for efficient range query\n+            byte[] first16bytes = Arrays.copyOfRange(encodedVersion.bytes, encodedVersion.offset, 16);\n+            context.doc().add(new BinaryPoint(fieldType().name(), first16bytes));\n+        }\n+        context.doc().add(new SortedSetDocValuesField(fieldType().name(), encodedVersion));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 450}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkzMDUyNA==", "bodyText": "Sure. I was also thinking about always setting \"docValue == true\" for this field regardless of the users settings. I think @jpountz suggested this at some point during reviewing the draft, maybe he can restate this opinion here?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462930524", "createdAt": "2020-07-30T11:26:54Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);\n+            context.doc().add(field);\n+            // encode the first 16 bytes as points for efficient range query\n+            byte[] first16bytes = Arrays.copyOfRange(encodedVersion.bytes, encodedVersion.offset, 16);\n+            context.doc().add(new BinaryPoint(fieldType().name(), first16bytes));\n+        }\n+        context.doc().add(new SortedSetDocValuesField(fieldType().name(), encodedVersion));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkwMzI2OQ=="}, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 450}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzIwMjU1MA==", "bodyText": "I updated the PR so we now don't allow disabling doc_values for this specialized field, so it will always be true.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r477202550", "createdAt": "2020-08-26T10:35:16Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);\n+            context.doc().add(field);\n+            // encode the first 16 bytes as points for efficient range query\n+            byte[] first16bytes = Arrays.copyOfRange(encodedVersion.bytes, encodedVersion.offset, 16);\n+            context.doc().add(new BinaryPoint(fieldType().name(), first16bytes));\n+        }\n+        context.doc().add(new SortedSetDocValuesField(fieldType().name(), encodedVersion));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkwMzI2OQ=="}, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 450}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5MDExMjgwOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxMDozMDoxNVrOG5dZzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxMDozNTo1MlrOHHGJpA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkwMzc1Nw==", "bodyText": "Should we create all the fields below only when indexOptions() != IndexOptions.NONE  and SortedNumericDocValuesField when hasDocValues() == true?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462903757", "createdAt": "2020-07-30T10:30:15Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);\n+            context.doc().add(field);\n+            // encode the first 16 bytes as points for efficient range query\n+            byte[] first16bytes = Arrays.copyOfRange(encodedVersion.bytes, encodedVersion.offset, 16);\n+            context.doc().add(new BinaryPoint(fieldType().name(), first16bytes));\n+        }\n+        context.doc().add(new SortedSetDocValuesField(fieldType().name(), encodedVersion));\n+\n+        // add additional information extracted from version string", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 452}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzIwMjg1Mg==", "bodyText": "I updated the PR so we now don't allow disabling doc_values or setting specific index options for this specialized field.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r477202852", "createdAt": "2020-08-26T10:35:52Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);\n+            context.doc().add(field);\n+            // encode the first 16 bytes as points for efficient range query\n+            byte[] first16bytes = Arrays.copyOfRange(encodedVersion.bytes, encodedVersion.offset, 16);\n+            context.doc().add(new BinaryPoint(fieldType().name(), first16bytes));\n+        }\n+        context.doc().add(new SortedSetDocValuesField(fieldType().name(), encodedVersion));\n+\n+        // add additional information extracted from version string", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkwMzc1Nw=="}, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 452}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5MDE0NTM1OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxMDo0MTowOFrOG5dubw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxMToyNToxOFrOG5e_bQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkwOTAzOQ==", "bodyText": "I am wondering if this query still should be considering expensive if with  a binaryPoint query we can efficiently narrow down terms?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462909039", "createdAt": "2020-07-30T10:41:08Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 352}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkxMzgxOA==", "bodyText": "I was also wondering since lowerTerm and upperTerm represent valid versions can we extract major, minor, patch fields  and use them for querying to further narrow down terms?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462913818", "createdAt": "2020-07-30T10:51:30Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkwOTAzOQ=="}, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 352}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkyOTc3Mw==", "bodyText": "lower and upper don't necessarily represent valid versions, we'd also be able to use non-semver versions that then sort above the valid ones. Major/Minor/Patch might be not available for them.  As for the expensive part, I'm happy to change, I'm not familiar enough with the cost of binaryPoint so I'd follow your judgement or if anyone else has an opinion on this.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462929773", "createdAt": "2020-07-30T11:25:18Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkwOTAzOQ=="}, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 352}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5MDIzOTc2OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxMToxMjoyNlrOG5en_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMzozNDo0N1rOHUNY_A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkyMzc3Mg==", "bodyText": "I don't think we should apply this setting here. It's a specialized type so we should make this query fast and/or harmless if it's useful ?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462923772", "createdAt": "2020-07-30T11:12:26Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 188}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDk1Mjk1Ng==", "bodyText": "Can you remove the check please", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490952956", "createdAt": "2020-09-18T13:34:47Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkyMzc3Mg=="}, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 188}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5MDMyNjg2OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxMTo0MTowN1rOG5fcsQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxMDozNzo0OVrOHHGNWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkzNzI2NQ==", "bodyText": "For specialized type we're trying to limit the number of options. It's perfectly ok to have a new field with no option at all so I think we should start with a clean state and discuss any addition.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462937265", "createdAt": "2020-07-30T11:41:07Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 151}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzAxMjc5MA==", "bodyText": "Would that include common options like \"meta\" or \"boost\"? It would certainly simplify things if we would had fixed 'index_options' or 'doc_values'  settings. My impression was that people would like to use this like a keyword field and expect certain basic options.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r463012790", "createdAt": "2020-07-30T13:53:56Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkzNzI2NQ=="}, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 151}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzIwMzgwMQ==", "bodyText": "I updated the PR so the mapper now extends ParametrizedFieldMapper, which limits the number of options. I only added parsing for \"meta\" field for now since we seem to want to support this for all fields.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r477203801", "createdAt": "2020-08-26T10:37:49Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkzNzI2NQ=="}, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 151}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5MDMzNjU1OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxMTo0NDozNVrOG5fivw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxMDozODoyNFrOHHGOcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkzODgxNQ==", "bodyText": "I'd assume that we are in control and that the index_options are fixed. These options are not relevant in this context imo.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462938815", "createdAt": "2020-07-30T11:44:35Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 443}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzAxMzcwNQ==", "bodyText": "Happy to not allow configurable ' index_options' and e.g. also assume 'doc_values'  are always turned on (if we decide thats where to store the full encoded version)", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r463013705", "createdAt": "2020-07-30T13:55:09Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkzODgxNQ=="}, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 443}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzIwNDA4MA==", "bodyText": "index_options are now fixed with a recent update", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r477204080", "createdAt": "2020-08-26T10:38:24Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkzODgxNQ=="}, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 443}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5MDM1NjY1OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxMTo1MToyOFrOG5fu4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxMzowNjo0MFrOG6H2kw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk0MTkyMw==", "bodyText": "I don't see any use of these fields in queries. Is it for future optimizations ? That seems premature, the primary heuristic should be quite fast already.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462941923", "createdAt": "2020-07-30T11:51:28Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);\n+            context.doc().add(field);\n+            // encode the first 16 bytes as points for efficient range query\n+            byte[] first16bytes = Arrays.copyOfRange(encodedVersion.bytes, encodedVersion.offset, 16);\n+            context.doc().add(new BinaryPoint(fieldType().name(), first16bytes));\n+        }\n+        context.doc().add(new SortedSetDocValuesField(fieldType().name(), encodedVersion));\n+\n+        // add additional information extracted from version string\n+        context.doc().add(new Field(prereleaseSubField.name(), encoding.isPreRelease ? \"T\" : \"F\", BooleanFieldMapper.Defaults.FIELD_TYPE));\n+        context.doc().add(new SortedNumericDocValuesField(prereleaseSubField.name(), encoding.isPreRelease ? 1 : 0));\n+\n+        addVersionPartSubfield(context, majorVersionSubField.name(), encoding.major);\n+        addVersionPartSubfield(context, minorVersionSubField.name(), encoding.minor);\n+        addVersionPartSubfield(context, patchVersionSubField.name(), encoding.patch);\n+    }\n+\n+    private void addVersionPartSubfield(ParseContext context, String fieldName, Integer versionPart) {\n+        if (versionPart != null) {\n+            context.doc().addAll(NumberType.INTEGER.createFields(fieldName, versionPart, true, true, false));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 463}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk0MjM1NQ==", "bodyText": "There's also the cost of indexing three more points so I'd lean towards limiting the number of indexed/points fields.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462942355", "createdAt": "2020-07-30T11:52:19Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);\n+            context.doc().add(field);\n+            // encode the first 16 bytes as points for efficient range query\n+            byte[] first16bytes = Arrays.copyOfRange(encodedVersion.bytes, encodedVersion.offset, 16);\n+            context.doc().add(new BinaryPoint(fieldType().name(), first16bytes));\n+        }\n+        context.doc().add(new SortedSetDocValuesField(fieldType().name(), encodedVersion));\n+\n+        // add additional information extracted from version string\n+        context.doc().add(new Field(prereleaseSubField.name(), encoding.isPreRelease ? \"T\" : \"F\", BooleanFieldMapper.Defaults.FIELD_TYPE));\n+        context.doc().add(new SortedNumericDocValuesField(prereleaseSubField.name(), encoding.isPreRelease ? 1 : 0));\n+\n+        addVersionPartSubfield(context, majorVersionSubField.name(), encoding.major);\n+        addVersionPartSubfield(context, minorVersionSubField.name(), encoding.minor);\n+        addVersionPartSubfield(context, patchVersionSubField.name(), encoding.patch);\n+    }\n+\n+    private void addVersionPartSubfield(ParseContext context, String fieldName, Integer versionPart) {\n+        if (versionPart != null) {\n+            context.doc().addAll(NumberType.INTEGER.createFields(fieldName, versionPart, true, true, false));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk0MTkyMw=="}, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 463}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzAxMDM0MA==", "bodyText": "This is not aimed at making the range queries faster like in indexing the 16 byte prefix as point. I added these fields because the telemetry team have the use case that they want to filter and aggregate on mayor / minor version (maybe patch), e.g. with histograms or terms aggregations. Think along the lines of \"give me a breakdown of all mayor/minor/patch\" versions running in my cluster. That information would otherwise have to be parsed out again on aggregations e.g. by scripts, so adding these field will make these kind of aggregations faster. I was considering having to switch these additional subfields on with a type parameter so its not done by default.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r463010340", "createdAt": "2020-07-30T13:50:25Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);\n+            context.doc().add(field);\n+            // encode the first 16 bytes as points for efficient range query\n+            byte[] first16bytes = Arrays.copyOfRange(encodedVersion.bytes, encodedVersion.offset, 16);\n+            context.doc().add(new BinaryPoint(fieldType().name(), first16bytes));\n+        }\n+        context.doc().add(new SortedSetDocValuesField(fieldType().name(), encodedVersion));\n+\n+        // add additional information extracted from version string\n+        context.doc().add(new Field(prereleaseSubField.name(), encoding.isPreRelease ? \"T\" : \"F\", BooleanFieldMapper.Defaults.FIELD_TYPE));\n+        context.doc().add(new SortedNumericDocValuesField(prereleaseSubField.name(), encoding.isPreRelease ? 1 : 0));\n+\n+        addVersionPartSubfield(context, majorVersionSubField.name(), encoding.major);\n+        addVersionPartSubfield(context, minorVersionSubField.name(), encoding.minor);\n+        addVersionPartSubfield(context, patchVersionSubField.name(), encoding.patch);\n+    }\n+\n+    private void addVersionPartSubfield(ParseContext context, String fieldName, Integer versionPart) {\n+        if (versionPart != null) {\n+            context.doc().addAll(NumberType.INTEGER.createFields(fieldName, versionPart, true, true, false));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk0MTkyMw=="}, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 463}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzU5OTI1MQ==", "bodyText": "Ok thanks for explaining. Although I think we should discuss more alternatives to handle these requirements. Extracting the major/minor/patch shouldn't be considered costly in aggregations for instance. We also have plenty of ways to make the decoding faster if needed.\nQuerying all 0 minor should also  be possible with the full version so I'd prefer to find an alternative that doesn't require 3 additional fields.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r463599251", "createdAt": "2020-07-31T13:06:40Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);\n+            context.doc().add(field);\n+            // encode the first 16 bytes as points for efficient range query\n+            byte[] first16bytes = Arrays.copyOfRange(encodedVersion.bytes, encodedVersion.offset, 16);\n+            context.doc().add(new BinaryPoint(fieldType().name(), first16bytes));\n+        }\n+        context.doc().add(new SortedSetDocValuesField(fieldType().name(), encodedVersion));\n+\n+        // add additional information extracted from version string\n+        context.doc().add(new Field(prereleaseSubField.name(), encoding.isPreRelease ? \"T\" : \"F\", BooleanFieldMapper.Defaults.FIELD_TYPE));\n+        context.doc().add(new SortedNumericDocValuesField(prereleaseSubField.name(), encoding.isPreRelease ? 1 : 0));\n+\n+        addVersionPartSubfield(context, majorVersionSubField.name(), encoding.major);\n+        addVersionPartSubfield(context, minorVersionSubField.name(), encoding.minor);\n+        addVersionPartSubfield(context, patchVersionSubField.name(), encoding.patch);\n+    }\n+\n+    private void addVersionPartSubfield(ParseContext context, String fieldName, Integer versionPart) {\n+        if (versionPart != null) {\n+            context.doc().addAll(NumberType.INTEGER.createFields(fieldName, versionPart, true, true, false));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk0MTkyMw=="}, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 463}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5MDQwNDQ0OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxMjowNzozOFrOG5gLig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxMjowNzozOFrOG5gLig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk0OTI1OA==", "bodyText": "That seems redundant. If I understand correctly, the encoded version is stored in three structures:\n\n\nFully encoded version in Postings\n\n\nThe first 16 bytes of the encoded version in Points\n\n\nFully encoded version in SortedSetDocValues\n\n\nThe main benefit of indexing Points is that you don't need the postings. We can use them as an approximation and rely on the doc values to validate matches in a range query. Prefix, wildcard, regex are more tricky to handle with Points so I guess that is why you also create an indexed Field. However, I think we should only pick one strategy. The current approach is too costly imo, we should control the indexing cost more carefully.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462949258", "createdAt": "2020-07-30T12:07:38Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 444}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5MDQ0NDM2OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxMjoxOTo0M1rOG5gj2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxMDoyOTowN1rOHHF8QQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk1NTQ4MQ==", "bodyText": "The two queries that you mixed are totally independent so the resulting boolean query is just more costly than a plain TermRangeQuery.\nThe idea behind using a prefix query on Points is that you can use the doc values to validate the matches. You can check how the wildcard field does  since it's very similar. The AutomatonQueryOnBinaryDv leverages the TwoPhaseIterator to only validate documents found by other filter (the point range query approximation).\nAs I said in previous comments, I think we need to make a choice. Relying on Points or Postings is ok but not both.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462955481", "createdAt": "2020-07-30T12:19:43Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 378}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY0MjYxMg==", "bodyText": "Thanks, I looked into this and hope I understood things right. I pushed cfe2dba which follows a simiar approach as AutomatonQueryOnBinaryDv but works on SortedSet doc values.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r463642612", "createdAt": "2020-07-31T14:25:26Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk1NTQ4MQ=="}, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 378}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzE5OTQyNQ==", "bodyText": "After talking again about this I changed the range validation query again in eaa1ef8. Since we also talked about not using Points at all I will use this version when comparing to a solution that doesn't use Points at all (a simple TermRangeQuery)", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r477199425", "createdAt": "2020-08-26T10:29:07Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk1NTQ4MQ=="}, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 378}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5MTgxMzA2OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxNzo1NTozNVrOG5tyYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxOTozODo1MFrOG6T6TQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzE3MjE5NA==", "bodyText": "Do you need to register this format in NamedWriteableRegistry like we register other format in SearchModule#registerValueFormats?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r463172194", "createdAt": "2020-07-30T17:55:35Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);\n+            context.doc().add(field);\n+            // encode the first 16 bytes as points for efficient range query\n+            byte[] first16bytes = Arrays.copyOfRange(encodedVersion.bytes, encodedVersion.offset, 16);\n+            context.doc().add(new BinaryPoint(fieldType().name(), first16bytes));\n+        }\n+        context.doc().add(new SortedSetDocValuesField(fieldType().name(), encodedVersion));\n+\n+        // add additional information extracted from version string\n+        context.doc().add(new Field(prereleaseSubField.name(), encoding.isPreRelease ? \"T\" : \"F\", BooleanFieldMapper.Defaults.FIELD_TYPE));\n+        context.doc().add(new SortedNumericDocValuesField(prereleaseSubField.name(), encoding.isPreRelease ? 1 : 0));\n+\n+        addVersionPartSubfield(context, majorVersionSubField.name(), encoding.major);\n+        addVersionPartSubfield(context, minorVersionSubField.name(), encoding.minor);\n+        addVersionPartSubfield(context, patchVersionSubField.name(), encoding.patch);\n+    }\n+\n+    private void addVersionPartSubfield(ParseContext context, String fieldName, Integer versionPart) {\n+        if (versionPart != null) {\n+            context.doc().addAll(NumberType.INTEGER.createFields(fieldName, versionPart, true, true, false));\n+        }\n+    }\n+\n+    @Override\n+    protected void mergeOptions(FieldMapper other, List<String> conflicts) {\n+        VersionStringFieldMapper mergeWith = (VersionStringFieldMapper) other;\n+        this.nullValue = mergeWith.nullValue;\n+    }\n+\n+    @Override\n+    protected void doXContentBody(XContentBuilder builder, boolean includeDefaults, Params params) throws IOException {\n+        super.doXContentBody(builder, includeDefaults, params);\n+        if (nullValue != null) {\n+            builder.field(\"null_value\", nullValue);\n+        }\n+    }\n+\n+    @Override\n+    public Iterator<Mapper> iterator() {\n+        List<Mapper> subIterators = new ArrayList<>();\n+        subIterators.add(prereleaseSubField);\n+        subIterators.add(majorVersionSubField);\n+        subIterators.add(minorVersionSubField);\n+        subIterators.add(patchVersionSubField);\n+        @SuppressWarnings(\"unchecked\")\n+        Iterator<Mapper> concat = Iterators.concat(super.iterator(), subIterators.iterator());\n+        return concat;\n+    }\n+\n+    @Override\n+    protected Object parseSourceValue(Object value, String format) {\n+        if (format != null) {\n+            throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] doesn't support formats.\");\n+        }\n+        return value.toString();\n+    }\n+\n+    private static DocValueFormat VERSION_DOCVALUE = new DocValueFormat() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 501}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY1Mzc0NA==", "bodyText": "Good point, I guess this hasn't shown up in tests yet because they are mostly single node. I'll see if this would e.g. fail a yaml aggs test. I can probably register this in the plugin.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r463653744", "createdAt": "2020-07-31T14:44:44Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);\n+            context.doc().add(field);\n+            // encode the first 16 bytes as points for efficient range query\n+            byte[] first16bytes = Arrays.copyOfRange(encodedVersion.bytes, encodedVersion.offset, 16);\n+            context.doc().add(new BinaryPoint(fieldType().name(), first16bytes));\n+        }\n+        context.doc().add(new SortedSetDocValuesField(fieldType().name(), encodedVersion));\n+\n+        // add additional information extracted from version string\n+        context.doc().add(new Field(prereleaseSubField.name(), encoding.isPreRelease ? \"T\" : \"F\", BooleanFieldMapper.Defaults.FIELD_TYPE));\n+        context.doc().add(new SortedNumericDocValuesField(prereleaseSubField.name(), encoding.isPreRelease ? 1 : 0));\n+\n+        addVersionPartSubfield(context, majorVersionSubField.name(), encoding.major);\n+        addVersionPartSubfield(context, minorVersionSubField.name(), encoding.minor);\n+        addVersionPartSubfield(context, patchVersionSubField.name(), encoding.patch);\n+    }\n+\n+    private void addVersionPartSubfield(ParseContext context, String fieldName, Integer versionPart) {\n+        if (versionPart != null) {\n+            context.doc().addAll(NumberType.INTEGER.createFields(fieldName, versionPart, true, true, false));\n+        }\n+    }\n+\n+    @Override\n+    protected void mergeOptions(FieldMapper other, List<String> conflicts) {\n+        VersionStringFieldMapper mergeWith = (VersionStringFieldMapper) other;\n+        this.nullValue = mergeWith.nullValue;\n+    }\n+\n+    @Override\n+    protected void doXContentBody(XContentBuilder builder, boolean includeDefaults, Params params) throws IOException {\n+        super.doXContentBody(builder, includeDefaults, params);\n+        if (nullValue != null) {\n+            builder.field(\"null_value\", nullValue);\n+        }\n+    }\n+\n+    @Override\n+    public Iterator<Mapper> iterator() {\n+        List<Mapper> subIterators = new ArrayList<>();\n+        subIterators.add(prereleaseSubField);\n+        subIterators.add(majorVersionSubField);\n+        subIterators.add(minorVersionSubField);\n+        subIterators.add(patchVersionSubField);\n+        @SuppressWarnings(\"unchecked\")\n+        Iterator<Mapper> concat = Iterators.concat(super.iterator(), subIterators.iterator());\n+        return concat;\n+    }\n+\n+    @Override\n+    protected Object parseSourceValue(Object value, String format) {\n+        if (format != null) {\n+            throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] doesn't support formats.\");\n+        }\n+        return value.toString();\n+    }\n+\n+    private static DocValueFormat VERSION_DOCVALUE = new DocValueFormat() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzE3MjE5NA=="}, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 501}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc5NjgxMw==", "bodyText": "I added c70e7c1 to register the format and an IT test that would have caught this when serializing aggregations across nodes. Thanks for catching this!", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r463796813", "createdAt": "2020-07-31T19:38:50Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);\n+            context.doc().add(field);\n+            // encode the first 16 bytes as points for efficient range query\n+            byte[] first16bytes = Arrays.copyOfRange(encodedVersion.bytes, encodedVersion.offset, 16);\n+            context.doc().add(new BinaryPoint(fieldType().name(), first16bytes));\n+        }\n+        context.doc().add(new SortedSetDocValuesField(fieldType().name(), encodedVersion));\n+\n+        // add additional information extracted from version string\n+        context.doc().add(new Field(prereleaseSubField.name(), encoding.isPreRelease ? \"T\" : \"F\", BooleanFieldMapper.Defaults.FIELD_TYPE));\n+        context.doc().add(new SortedNumericDocValuesField(prereleaseSubField.name(), encoding.isPreRelease ? 1 : 0));\n+\n+        addVersionPartSubfield(context, majorVersionSubField.name(), encoding.major);\n+        addVersionPartSubfield(context, minorVersionSubField.name(), encoding.minor);\n+        addVersionPartSubfield(context, patchVersionSubField.name(), encoding.patch);\n+    }\n+\n+    private void addVersionPartSubfield(ParseContext context, String fieldName, Integer versionPart) {\n+        if (versionPart != null) {\n+            context.doc().addAll(NumberType.INTEGER.createFields(fieldName, versionPart, true, true, false));\n+        }\n+    }\n+\n+    @Override\n+    protected void mergeOptions(FieldMapper other, List<String> conflicts) {\n+        VersionStringFieldMapper mergeWith = (VersionStringFieldMapper) other;\n+        this.nullValue = mergeWith.nullValue;\n+    }\n+\n+    @Override\n+    protected void doXContentBody(XContentBuilder builder, boolean includeDefaults, Params params) throws IOException {\n+        super.doXContentBody(builder, includeDefaults, params);\n+        if (nullValue != null) {\n+            builder.field(\"null_value\", nullValue);\n+        }\n+    }\n+\n+    @Override\n+    public Iterator<Mapper> iterator() {\n+        List<Mapper> subIterators = new ArrayList<>();\n+        subIterators.add(prereleaseSubField);\n+        subIterators.add(majorVersionSubField);\n+        subIterators.add(minorVersionSubField);\n+        subIterators.add(patchVersionSubField);\n+        @SuppressWarnings(\"unchecked\")\n+        Iterator<Mapper> concat = Iterators.concat(super.iterator(), subIterators.iterator());\n+        return concat;\n+    }\n+\n+    @Override\n+    protected Object parseSourceValue(Object value, String format) {\n+        if (format != null) {\n+            throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] doesn't support formats.\");\n+        }\n+        return value.toString();\n+    }\n+\n+    private static DocValueFormat VERSION_DOCVALUE = new DocValueFormat() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzE3MjE5NA=="}, "originalCommit": {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c"}, "originalPosition": 501}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAwMTUyOTQzOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQxMDoyNTozNFrOHJy_-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQxNDowNDo1M1rOHJ6PCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDAzNDgxMQ==", "bodyText": "You don't need to add the validation query if the lower and upper values have less than 17 bytes ?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r480034811", "createdAt": "2020-08-31T10:25:34Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,483 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.ConstantScoreQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery87;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type, false, false);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type, false, false);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type, false, false);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build(),\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int syntaxFlags,\n+            int matchFlags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery87 query = new RegexpQuery87(new Term(name(), new BytesRef(value)), syntaxFlags, matchFlags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query validationQuery = SortedSetDocValuesField.newSlowRangeQuery(name(), lower, upper, includeLower, includeUpper);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eaa1ef8dd3ba0a8f4cd7ec646bf3ebecd726c801"}, "originalPosition": 338}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDAzNTU1MA==", "bodyText": "The validation can also be avoided on values that have less than 17 bytes so you'll maybe need a custom validation query ?\nThe slow range query uses ordinals so it's probably not needed ^^", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r480035550", "createdAt": "2020-08-31T10:27:21Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,483 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.ConstantScoreQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery87;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type, false, false);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type, false, false);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type, false, false);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build(),\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int syntaxFlags,\n+            int matchFlags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery87 query = new RegexpQuery87(new Term(name(), new BytesRef(value)), syntaxFlags, matchFlags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query validationQuery = SortedSetDocValuesField.newSlowRangeQuery(name(), lower, upper, includeLower, includeUpper);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDAzNDgxMQ=="}, "originalCommit": {"oid": "eaa1ef8dd3ba0a8f4cd7ec646bf3ebecd726c801"}, "originalPosition": 338}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDE1MzM1Mw==", "bodyText": "Good point, I probably still want to use it if includeLower or includeUpper is false since the points query will always contain the edges as far as I've seen from previous tests. I will push an update on this before I continue with testing vs. TermRangeQuery using only postings.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r480153353", "createdAt": "2020-08-31T14:04:53Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,483 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.ConstantScoreQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery87;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type, false, false);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type, false, false);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type, false, false);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build(),\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int syntaxFlags,\n+            int matchFlags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery87 query = new RegexpQuery87(new Term(name(), new BytesRef(value)), syntaxFlags, matchFlags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query validationQuery = SortedSetDocValuesField.newSlowRangeQuery(name(), lower, upper, includeLower, includeUpper);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDAzNDgxMQ=="}, "originalCommit": {"oid": "eaa1ef8dd3ba0a8f4cd7ec646bf3ebecd726c801"}, "originalPosition": 338}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0MzkyODI2OnYy", "diffSide": "RIGHT", "path": "docs/reference/mapping/types/keyword.asciidoc", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMTowNDoyMFrOHQFsMg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxODoxMTo0NFrOHTvThA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjYzMjQ5OA==", "bodyText": "@cbuescher  I am curious why you considered version to be a part of keyword family?\nI would rather say that it should be a part of structured or other category?\nAlso curious what @jtibshirani  thinks as she worked on this organization.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r486632498", "createdAt": "2020-09-10T21:04:20Z", "author": {"login": "mayya-sharipova"}, "path": "docs/reference/mapping/types/keyword.asciidoc", "diffHunk": "@@ -129,3 +129,5 @@ The following parameters are accepted by `keyword` fields:\n include::constant-keyword.asciidoc[]\n \n include::wildcard.asciidoc[]\n+\n+include::version.asciidoc[]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg3MDE0Ng==", "bodyText": "I put the docs here because we discussed the desired compatibility with the keyword field for the new field type a lot since users currently mostly seem to use keyword to indec these version constants. The version field should more or less behave like a keyword field, just with specialized semantics and ordering. I'm happy to move the docs anywhere else if there is another option that finds consensus.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487870146", "createdAt": "2020-09-14T12:24:51Z", "author": {"login": "cbuescher"}, "path": "docs/reference/mapping/types/keyword.asciidoc", "diffHunk": "@@ -129,3 +129,5 @@ The following parameters are accepted by `keyword` fields:\n include::constant-keyword.asciidoc[]\n \n include::wildcard.asciidoc[]\n+\n+include::version.asciidoc[]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjYzMjQ5OA=="}, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODY1MDkzMg==", "bodyText": "thanks for the explanation, let's see what @jtibshirani thinks of this categorization", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r488650932", "createdAt": "2020-09-15T13:06:42Z", "author": {"login": "mayya-sharipova"}, "path": "docs/reference/mapping/types/keyword.asciidoc", "diffHunk": "@@ -129,3 +129,5 @@ The following parameters are accepted by `keyword` fields:\n include::constant-keyword.asciidoc[]\n \n include::wildcard.asciidoc[]\n+\n+include::version.asciidoc[]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjYzMjQ5OA=="}, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDQyMzU1Ng==", "bodyText": "Thanks for looping me in, I was also imagining it would be listed under 'Structured'.\nWe recently added the concept of a 'field type family', which is a group of field types that have identical search behavior, but present different trade-offs (for example in terms of query speed). They all come back as the family type in field caps. The version field doesn't fit this description -- it has different search behavior (on purpose), and shouldn't present itself as a keyword in field caps.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490423556", "createdAt": "2020-09-17T17:09:23Z", "author": {"login": "jtibshirani"}, "path": "docs/reference/mapping/types/keyword.asciidoc", "diffHunk": "@@ -129,3 +129,5 @@ The following parameters are accepted by `keyword` fields:\n include::constant-keyword.asciidoc[]\n \n include::wildcard.asciidoc[]\n+\n+include::version.asciidoc[]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjYzMjQ5OA=="}, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDQ2MDAzNg==", "bodyText": "Thanks @jtibshirani I moved the docs in ccebd6f", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490460036", "createdAt": "2020-09-17T18:11:44Z", "author": {"login": "cbuescher"}, "path": "docs/reference/mapping/types/keyword.asciidoc", "diffHunk": "@@ -129,3 +129,5 @@ The following parameters are accepted by `keyword` fields:\n include::constant-keyword.asciidoc[]\n \n include::wildcard.asciidoc[]\n+\n+include::version.asciidoc[]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjYzMjQ5OA=="}, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0MzkzODU2OnYy", "diffSide": "RIGHT", "path": "docs/reference/mapping/types/version.asciidoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMTowNzozOVrOHQFyjw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMTowNzozOVrOHQFyjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjYzNDEyNw==", "bodyText": "\"Not that\" => \"Note that\"?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r486634127", "createdAt": "2020-09-10T21:07:39Z", "author": {"login": "mayya-sharipova"}, "path": "docs/reference/mapping/types/version.asciidoc", "diffHunk": "@@ -0,0 +1,125 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[discrete]\n+[[version-field-type]]\n+=== Version field type\n+\n+The `version` field type is a specialization of the `keyword` field for\n+handling software version values and to support specialized precedence\n+rules for them. Precedence is defined following the rules outlined by\n+https://semver.org/[Semantic Versioning], which for example means that\n+major, minor and patch version parts are sorted numerically (i.e. \n+\"2.1.0\" < \"2.4.1\" < \"2.11.2\") and pre-release versions are sorted before\n+release versiond (i.e. \"1.0.0-alpha\" < \"1.0.0\").\n+\n+You index a `version` field as follows\n+\n+[source,console]\n+--------------------------------------------------\n+PUT my-index-000001\n+{\n+  \"mappings\": {\n+    \"properties\": {\n+      \"my_version\": {\n+        \"type\": \"version\"\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+\n+The field offers the same search capabilities as a regular keyword field. It \n+can e.g. be searched for exact matches using `match` or `term` queries and\n+supports prefix and wildcard searches. The main benefit is that `range` queries\n+will honour Semver ordering, so a `range` query between \"1.0.0\" and \"1.5.0\"\n+will include versions of \"1.2.3\" but not \"1.11.2\" for example. Not that this", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0Mzk0NTQ2OnYy", "diffSide": "RIGHT", "path": "docs/reference/mapping/types/version.asciidoc", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMTowOTo1NFrOHQF2ow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxMzoxMDowNVrOHSBBmA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjYzNTE3MQ==", "bodyText": "\"with regular alphabetical ordering\" =>  I am not quite sure what it means?  Are we sorting versions by an alphabetical ordering?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r486635171", "createdAt": "2020-09-10T21:09:54Z", "author": {"login": "mayya-sharipova"}, "path": "docs/reference/mapping/types/version.asciidoc", "diffHunk": "@@ -0,0 +1,125 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[discrete]\n+[[version-field-type]]\n+=== Version field type\n+\n+The `version` field type is a specialization of the `keyword` field for\n+handling software version values and to support specialized precedence\n+rules for them. Precedence is defined following the rules outlined by\n+https://semver.org/[Semantic Versioning], which for example means that\n+major, minor and patch version parts are sorted numerically (i.e. \n+\"2.1.0\" < \"2.4.1\" < \"2.11.2\") and pre-release versions are sorted before\n+release versiond (i.e. \"1.0.0-alpha\" < \"1.0.0\").\n+\n+You index a `version` field as follows\n+\n+[source,console]\n+--------------------------------------------------\n+PUT my-index-000001\n+{\n+  \"mappings\": {\n+    \"properties\": {\n+      \"my_version\": {\n+        \"type\": \"version\"\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+\n+The field offers the same search capabilities as a regular keyword field. It \n+can e.g. be searched for exact matches using `match` or `term` queries and\n+supports prefix and wildcard searches. The main benefit is that `range` queries\n+will honour Semver ordering, so a `range` query between \"1.0.0\" and \"1.5.0\"\n+will include versions of \"1.2.3\" but not \"1.11.2\" for example. Not that this\n+would be different when using a regular `keyword` field for indexing where ordering\n+is alphabetical.\n+\n+Software versions are expected to follow the\n+https://semver.org/[Semantic Versioning rules] schema and precedence rules with\n+the notable exception that more or less than three main version identifiers are\n+allowed (i.e. \"1.2\" or \"1.2.3.4\" qualify as valid versions while they wouldn't under\n+strict Semver rules). Version strings that are not valid under the Semver definition\n+(e.g. \"1.2.alpha.4\") can still be indexed and retrieved as exact matches, however they\n+will all appear _after_ any valid version with regular alphabetical ordering. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg3Mzc4MA==", "bodyText": "Valid Semver versions like \"1.2.3\" are sorted numerically according to major, minor, patch, i.e. \"1.2.1\" < \"1.11.1\". There was a requirement to also be able to store and retrieve invalid versions like \"1.a.123\" for compatibility with existing solutions using \"keyword\", however we sort those after all valid versions and use the \"default\" keyword sorting which is alphabetical. Do the docs makes sense with this respect or do you think I can improve something?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487873780", "createdAt": "2020-09-14T12:30:44Z", "author": {"login": "cbuescher"}, "path": "docs/reference/mapping/types/version.asciidoc", "diffHunk": "@@ -0,0 +1,125 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[discrete]\n+[[version-field-type]]\n+=== Version field type\n+\n+The `version` field type is a specialization of the `keyword` field for\n+handling software version values and to support specialized precedence\n+rules for them. Precedence is defined following the rules outlined by\n+https://semver.org/[Semantic Versioning], which for example means that\n+major, minor and patch version parts are sorted numerically (i.e. \n+\"2.1.0\" < \"2.4.1\" < \"2.11.2\") and pre-release versions are sorted before\n+release versiond (i.e. \"1.0.0-alpha\" < \"1.0.0\").\n+\n+You index a `version` field as follows\n+\n+[source,console]\n+--------------------------------------------------\n+PUT my-index-000001\n+{\n+  \"mappings\": {\n+    \"properties\": {\n+      \"my_version\": {\n+        \"type\": \"version\"\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+\n+The field offers the same search capabilities as a regular keyword field. It \n+can e.g. be searched for exact matches using `match` or `term` queries and\n+supports prefix and wildcard searches. The main benefit is that `range` queries\n+will honour Semver ordering, so a `range` query between \"1.0.0\" and \"1.5.0\"\n+will include versions of \"1.2.3\" but not \"1.11.2\" for example. Not that this\n+would be different when using a regular `keyword` field for indexing where ordering\n+is alphabetical.\n+\n+Software versions are expected to follow the\n+https://semver.org/[Semantic Versioning rules] schema and precedence rules with\n+the notable exception that more or less than three main version identifiers are\n+allowed (i.e. \"1.2\" or \"1.2.3.4\" qualify as valid versions while they wouldn't under\n+strict Semver rules). Version strings that are not valid under the Semver definition\n+(e.g. \"1.2.alpha.4\") can still be indexed and retrieved as exact matches, however they\n+will all appear _after_ any valid version with regular alphabetical ordering. ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjYzNTE3MQ=="}, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODY1MzIwOA==", "bodyText": "@cbuescher Thanks for explanation, with it, the docs completely make sense,  I somehow assumed that \"alphabetical ordering\" applied to valid versions.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r488653208", "createdAt": "2020-09-15T13:10:05Z", "author": {"login": "mayya-sharipova"}, "path": "docs/reference/mapping/types/version.asciidoc", "diffHunk": "@@ -0,0 +1,125 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[discrete]\n+[[version-field-type]]\n+=== Version field type\n+\n+The `version` field type is a specialization of the `keyword` field for\n+handling software version values and to support specialized precedence\n+rules for them. Precedence is defined following the rules outlined by\n+https://semver.org/[Semantic Versioning], which for example means that\n+major, minor and patch version parts are sorted numerically (i.e. \n+\"2.1.0\" < \"2.4.1\" < \"2.11.2\") and pre-release versions are sorted before\n+release versiond (i.e. \"1.0.0-alpha\" < \"1.0.0\").\n+\n+You index a `version` field as follows\n+\n+[source,console]\n+--------------------------------------------------\n+PUT my-index-000001\n+{\n+  \"mappings\": {\n+    \"properties\": {\n+      \"my_version\": {\n+        \"type\": \"version\"\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+\n+The field offers the same search capabilities as a regular keyword field. It \n+can e.g. be searched for exact matches using `match` or `term` queries and\n+supports prefix and wildcard searches. The main benefit is that `range` queries\n+will honour Semver ordering, so a `range` query between \"1.0.0\" and \"1.5.0\"\n+will include versions of \"1.2.3\" but not \"1.11.2\" for example. Not that this\n+would be different when using a regular `keyword` field for indexing where ordering\n+is alphabetical.\n+\n+Software versions are expected to follow the\n+https://semver.org/[Semantic Versioning rules] schema and precedence rules with\n+the notable exception that more or less than three main version identifiers are\n+allowed (i.e. \"1.2\" or \"1.2.3.4\" qualify as valid versions while they wouldn't under\n+strict Semver rules). Version strings that are not valid under the Semver definition\n+(e.g. \"1.2.alpha.4\") can still be indexed and retrieved as exact matches, however they\n+will all appear _after_ any valid version with regular alphabetical ordering. ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjYzNTE3MQ=="}, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0Mzk1MTYxOnYy", "diffSide": "RIGHT", "path": "docs/reference/mapping/types/version.asciidoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMToxMTo0MlrOHQF6EQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMToxMTo0MlrOHQF6EQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjYzNjA0OQ==", "bodyText": "wildcard fields => version fields?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r486636049", "createdAt": "2020-09-10T21:11:42Z", "author": {"login": "mayya-sharipova"}, "path": "docs/reference/mapping/types/version.asciidoc", "diffHunk": "@@ -0,0 +1,125 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[discrete]\n+[[version-field-type]]\n+=== Version field type\n+\n+The `version` field type is a specialization of the `keyword` field for\n+handling software version values and to support specialized precedence\n+rules for them. Precedence is defined following the rules outlined by\n+https://semver.org/[Semantic Versioning], which for example means that\n+major, minor and patch version parts are sorted numerically (i.e. \n+\"2.1.0\" < \"2.4.1\" < \"2.11.2\") and pre-release versions are sorted before\n+release versiond (i.e. \"1.0.0-alpha\" < \"1.0.0\").\n+\n+You index a `version` field as follows\n+\n+[source,console]\n+--------------------------------------------------\n+PUT my-index-000001\n+{\n+  \"mappings\": {\n+    \"properties\": {\n+      \"my_version\": {\n+        \"type\": \"version\"\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+\n+The field offers the same search capabilities as a regular keyword field. It \n+can e.g. be searched for exact matches using `match` or `term` queries and\n+supports prefix and wildcard searches. The main benefit is that `range` queries\n+will honour Semver ordering, so a `range` query between \"1.0.0\" and \"1.5.0\"\n+will include versions of \"1.2.3\" but not \"1.11.2\" for example. Not that this\n+would be different when using a regular `keyword` field for indexing where ordering\n+is alphabetical.\n+\n+Software versions are expected to follow the\n+https://semver.org/[Semantic Versioning rules] schema and precedence rules with\n+the notable exception that more or less than three main version identifiers are\n+allowed (i.e. \"1.2\" or \"1.2.3.4\" qualify as valid versions while they wouldn't under\n+strict Semver rules). Version strings that are not valid under the Semver definition\n+(e.g. \"1.2.alpha.4\") can still be indexed and retrieved as exact matches, however they\n+will all appear _after_ any valid version with regular alphabetical ordering. \n+\n+[discrete]\n+[[version-params]]\n+==== Parameters for wildcard fields", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MTk4OTQ0OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionFieldPlugin.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMDoyMzo1MFrOHRNa6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMDoyMzo1MFrOHRNa6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzgwNzcyMg==", "bodyText": "Does this plugin need to implement ActionPlugin? It doesn't look like it provides new actions.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487807722", "createdAt": "2020-09-14T10:23:50Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionFieldPlugin.java", "diffHunk": "@@ -0,0 +1,39 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.elasticsearch.common.io.stream.NamedWriteableRegistry;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.plugins.ActionPlugin;\n+import org.elasticsearch.plugins.MapperPlugin;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.search.DocValueFormat;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+public class VersionFieldPlugin extends Plugin implements ActionPlugin, MapperPlugin {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MjA4NDE5OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMDo1MTo0N1rOHROTyw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjo0NToyN1rOHRR_9Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzgyMjI4Mw==", "bodyText": "I am wondering  if we should also have  a doc_values parameter?\nSince our range query doesn't depend on doc_values anymore, I am thinking may be a user can opt out of indexing doc_values if they don't need sorting, aggregation of this field, and script queries on pre-release, major, minor and patch", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487822283", "createdAt": "2020-09-14T10:51:47Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg4Mjc0MQ==", "bodyText": "I'm on the fence with this suggestion. I think the specialized sorting is one of the main features for using this field type, so I would assume most users wouldn't want to turn doc_values of. Maybe we can start without this option and add it if this is a really frequent ask (to save on storage spave while willing to pay the loss of functionality here)?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487882741", "createdAt": "2020-09-14T12:45:27Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzgyMjI4Mw=="}, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 93}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MjMzMDk0OnYy", "diffSide": "RIGHT", "path": "docs/reference/mapping/types/version.asciidoc", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjowNjozN1rOHRQnHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjo1MDo0NFrOHRSNgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg1OTk5OQ==", "bodyText": "may be also add a note about empty strings, where they will be in sorted order?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487859999", "createdAt": "2020-09-14T12:06:37Z", "author": {"login": "mayya-sharipova"}, "path": "docs/reference/mapping/types/version.asciidoc", "diffHunk": "@@ -0,0 +1,125 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[discrete]\n+[[version-field-type]]\n+=== Version field type\n+\n+The `version` field type is a specialization of the `keyword` field for\n+handling software version values and to support specialized precedence\n+rules for them. Precedence is defined following the rules outlined by\n+https://semver.org/[Semantic Versioning], which for example means that\n+major, minor and patch version parts are sorted numerically (i.e. \n+\"2.1.0\" < \"2.4.1\" < \"2.11.2\") and pre-release versions are sorted before\n+release versiond (i.e. \"1.0.0-alpha\" < \"1.0.0\").\n+\n+You index a `version` field as follows\n+\n+[source,console]\n+--------------------------------------------------\n+PUT my-index-000001\n+{\n+  \"mappings\": {\n+    \"properties\": {\n+      \"my_version\": {\n+        \"type\": \"version\"\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+\n+The field offers the same search capabilities as a regular keyword field. It \n+can e.g. be searched for exact matches using `match` or `term` queries and\n+supports prefix and wildcard searches. The main benefit is that `range` queries\n+will honour Semver ordering, so a `range` query between \"1.0.0\" and \"1.5.0\"\n+will include versions of \"1.2.3\" but not \"1.11.2\" for example. Not that this\n+would be different when using a regular `keyword` field for indexing where ordering\n+is alphabetical.\n+\n+Software versions are expected to follow the\n+https://semver.org/[Semantic Versioning rules] schema and precedence rules with\n+the notable exception that more or less than three main version identifiers are\n+allowed (i.e. \"1.2\" or \"1.2.3.4\" qualify as valid versions while they wouldn't under\n+strict Semver rules). Version strings that are not valid under the Semver definition\n+(e.g. \"1.2.alpha.4\") can still be indexed and retrieved as exact matches, however they", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg4NjIxMA==", "bodyText": "I can do that. Empty strings are considered as \"invalid\" version strings and are sorted after the valid ones, but before all other invalid versions.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487886210", "createdAt": "2020-09-14T12:50:44Z", "author": {"login": "cbuescher"}, "path": "docs/reference/mapping/types/version.asciidoc", "diffHunk": "@@ -0,0 +1,125 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[discrete]\n+[[version-field-type]]\n+=== Version field type\n+\n+The `version` field type is a specialization of the `keyword` field for\n+handling software version values and to support specialized precedence\n+rules for them. Precedence is defined following the rules outlined by\n+https://semver.org/[Semantic Versioning], which for example means that\n+major, minor and patch version parts are sorted numerically (i.e. \n+\"2.1.0\" < \"2.4.1\" < \"2.11.2\") and pre-release versions are sorted before\n+release versiond (i.e. \"1.0.0-alpha\" < \"1.0.0\").\n+\n+You index a `version` field as follows\n+\n+[source,console]\n+--------------------------------------------------\n+PUT my-index-000001\n+{\n+  \"mappings\": {\n+    \"properties\": {\n+      \"my_version\": {\n+        \"type\": \"version\"\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+\n+The field offers the same search capabilities as a regular keyword field. It \n+can e.g. be searched for exact matches using `match` or `term` queries and\n+supports prefix and wildcard searches. The main benefit is that `range` queries\n+will honour Semver ordering, so a `range` query between \"1.0.0\" and \"1.5.0\"\n+will include versions of \"1.2.3\" but not \"1.11.2\" for example. Not that this\n+would be different when using a regular `keyword` field for indexing where ordering\n+is alphabetical.\n+\n+Software versions are expected to follow the\n+https://semver.org/[Semantic Versioning rules] schema and precedence rules with\n+the notable exception that more or less than three main version identifiers are\n+allowed (i.e. \"1.2\" or \"1.2.3.4\" qualify as valid versions while they wouldn't under\n+strict Semver rules). Version strings that are not valid under the Semver definition\n+(e.g. \"1.2.alpha.4\") can still be indexed and retrieved as exact matches, however they", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg1OTk5OQ=="}, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MjM0NjY3OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjoxMDo1MFrOHRQwSA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjoxMDo1MFrOHRQwSA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg2MjM0NA==", "bodyText": "if we decide to always index a field with doc values, this failIfNoDocValues() check seems unnecessary.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487862344", "createdAt": "2020-09-14T12:10:50Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build()\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int syntaxFlags,\n+            int matchFlags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), syntaxFlags, matchFlags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName, Supplier<SearchLookup> searchLookup) {\n+            failIfNoDocValues();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 280}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MjM1OTMwOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjoxNDoyN1rOHRQ3_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNToxOTo1OFrOHTn0EA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg2NDMxOA==", "bodyText": "from your last benchmarking tests, rangeQuery doesn't seem to be expensive, so this check to allow expensive queries looks unnecessary to me. WDYT?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487864318", "createdAt": "2020-09-14T12:14:27Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build()\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int syntaxFlags,\n+            int matchFlags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), syntaxFlags, matchFlags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName, Supplier<SearchLookup> searchLookup) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 307}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzkwODI3OQ==", "bodyText": "While I'm happy removing this check, the same check exists for keyword fields via StringFieldType#rangeQuery() which is also using TermRangeQuery under the hood. While we expect the dictionary size for version fields to be lower, we cannot be sure users are not (by accident) misusing this field to store hundreds of thousands of version strings, in which case performance should be similar to keyword field performance which we currently guard for by checking \"allowExpensiveQueries()\". Wdyt?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487908279", "createdAt": "2020-09-14T13:23:38Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build()\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int syntaxFlags,\n+            int matchFlags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), syntaxFlags, matchFlags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName, Supplier<SearchLookup> searchLookup) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg2NDMxOA=="}, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 307}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODY1NjAyMg==", "bodyText": "Thanks, I am also ok to have this check for consistency with StringFieldType.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r488656022", "createdAt": "2020-09-15T13:14:01Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build()\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int syntaxFlags,\n+            int matchFlags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), syntaxFlags, matchFlags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName, Supplier<SearchLookup> searchLookup) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg2NDMxOA=="}, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 307}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDMzNzI5Ng==", "bodyText": "Unlike keyword, range queries are the most important part of this field so I'd prefer that we ignore the allowExpensiveQueries in this field.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490337296", "createdAt": "2020-09-17T15:19:58Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build()\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int syntaxFlags,\n+            int matchFlags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), syntaxFlags, matchFlags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName, Supplier<SearchLookup> searchLookup) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg2NDMxOA=="}, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 307}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MjM2NDQ3OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjoxNTo1NlrOHRQ7Fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjoxNTo1NlrOHRQ7Fw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg2NTExMQ==", "bodyText": "Doesn't seem that a user has an option not to index a field. So this check looks unnecessary", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487865111", "createdAt": "2020-09-14T12:15:56Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build()\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int syntaxFlags,\n+            int matchFlags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), syntaxFlags, matchFlags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName, Supplier<SearchLookup> searchLookup) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 314}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MjM5NDk4OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjoyNDoyMVrOHRRNbw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjoyNDoyMVrOHRRNbw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg2OTgwNw==", "bodyText": "nit: \"rexexp\"  -> \"regexp\"", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487869807", "createdAt": "2020-09-14T12:24:21Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build()\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 159}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MjQ1NjI1OnYy", "diffSide": "RIGHT", "path": "docs/reference/mapping/types/version.asciidoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjozODo1MVrOHRRwAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjozODo1MVrOHRRwAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg3ODY1Nw==", "bodyText": "For getMajor, getMinor, and getPatch functions should we provide more details, e.g \"returns Integer ... if a version is valid, or null otherwise..`", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487878657", "createdAt": "2020-09-14T12:38:51Z", "author": {"login": "mayya-sharipova"}, "path": "docs/reference/mapping/types/version.asciidoc", "diffHunk": "@@ -0,0 +1,125 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[discrete]\n+[[version-field-type]]\n+=== Version field type\n+\n+The `version` field type is a specialization of the `keyword` field for\n+handling software version values and to support specialized precedence\n+rules for them. Precedence is defined following the rules outlined by\n+https://semver.org/[Semantic Versioning], which for example means that\n+major, minor and patch version parts are sorted numerically (i.e. \n+\"2.1.0\" < \"2.4.1\" < \"2.11.2\") and pre-release versions are sorted before\n+release versiond (i.e. \"1.0.0-alpha\" < \"1.0.0\").\n+\n+You index a `version` field as follows\n+\n+[source,console]\n+--------------------------------------------------\n+PUT my-index-000001\n+{\n+  \"mappings\": {\n+    \"properties\": {\n+      \"my_version\": {\n+        \"type\": \"version\"\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+\n+The field offers the same search capabilities as a regular keyword field. It \n+can e.g. be searched for exact matches using `match` or `term` queries and\n+supports prefix and wildcard searches. The main benefit is that `range` queries\n+will honour Semver ordering, so a `range` query between \"1.0.0\" and \"1.5.0\"\n+will include versions of \"1.2.3\" but not \"1.11.2\" for example. Not that this\n+would be different when using a regular `keyword` field for indexing where ordering\n+is alphabetical.\n+\n+Software versions are expected to follow the\n+https://semver.org/[Semantic Versioning rules] schema and precedence rules with\n+the notable exception that more or less than three main version identifiers are\n+allowed (i.e. \"1.2\" or \"1.2.3.4\" qualify as valid versions while they wouldn't under\n+strict Semver rules). Version strings that are not valid under the Semver definition\n+(e.g. \"1.2.alpha.4\") can still be indexed and retrieved as exact matches, however they\n+will all appear _after_ any valid version with regular alphabetical ordering. \n+\n+[discrete]\n+[[version-params]]\n+==== Parameters for wildcard fields\n+\n+The following parameters are accepted by `version` fields:\n+\n+[horizontal]\n+\n+<<mapping-field-meta,`meta`>>::\n+\n+    Metadata about the field.\n+\n+[discrete]\n+==== Limitations\n+\n+This field type isn't optimized for heavy wildcard, regex or fuzzy searches. While those\n+type of queries work in this field, you should consider using a regular `keyword` field if\n+you strongly rely on these kind of queries.\n+\n+==== Script support\n+\n+TBD: The `version` fields offers some specialized access to detailed information derived from\n+valid version strings like the Major, Minor or Patch release number, whether the version value\n+is valid according to Semver or if it is a pre-release version. This can be helpful when e.g.\n+filtering for only released versions or running aggregations on parts of the version.\n+The following query, for example, filters for released versions and groups them by Major version\n+using a `terms` aggregation:\n+\n+[source,console]\n+--------------------------------------------------\n+POST my-index-000001/_search\n+{\n+  \"query\": {\n+    \"bool\": {\n+      \"filter\": [\n+        {\n+          \"script\": {\n+            \"script\": {\n+              \"source\": \"doc['my_version'].isPreRelease() == false\"\n+            }\n+          }\n+        }\n+      ]\n+    }\n+  },\n+  \"aggs\": {\n+    \"group_major\": {\n+      \"terms\": {\n+        \"script\": { \"source\": \"doc['my_version'].getMajor()\"},\n+        \"order\": {\n+          \"_key\": \"asc\"\n+        }\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+// TEST[continued]\n+\n+Functions available on via doc values in scripting are:\n+\n+[horizontal]\n+\n+isValid()::\n+    Returns `true` if the field contains a version thats legal according to the Semantic Versioning rules\n+\n+isPreRelease()::\n+    Returns `true` if the field contains a pre-release version\n+    \n+getMajor()::\n+    Returns the Major version for valid versions.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 119}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MjQ2MDM1OnYy", "diffSide": "RIGHT", "path": "docs/reference/mapping/types/version.asciidoc", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjozOTo1NlrOHRRycg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxMzoxODowNlrOHSBYVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg3OTI4Mg==", "bodyText": "should we also add that false is returned if a version is invalid? Or may be these functions should fail if the version is invalid than it will be up to a user to guard agains this?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487879282", "createdAt": "2020-09-14T12:39:56Z", "author": {"login": "mayya-sharipova"}, "path": "docs/reference/mapping/types/version.asciidoc", "diffHunk": "@@ -0,0 +1,125 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[discrete]\n+[[version-field-type]]\n+=== Version field type\n+\n+The `version` field type is a specialization of the `keyword` field for\n+handling software version values and to support specialized precedence\n+rules for them. Precedence is defined following the rules outlined by\n+https://semver.org/[Semantic Versioning], which for example means that\n+major, minor and patch version parts are sorted numerically (i.e. \n+\"2.1.0\" < \"2.4.1\" < \"2.11.2\") and pre-release versions are sorted before\n+release versiond (i.e. \"1.0.0-alpha\" < \"1.0.0\").\n+\n+You index a `version` field as follows\n+\n+[source,console]\n+--------------------------------------------------\n+PUT my-index-000001\n+{\n+  \"mappings\": {\n+    \"properties\": {\n+      \"my_version\": {\n+        \"type\": \"version\"\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+\n+The field offers the same search capabilities as a regular keyword field. It \n+can e.g. be searched for exact matches using `match` or `term` queries and\n+supports prefix and wildcard searches. The main benefit is that `range` queries\n+will honour Semver ordering, so a `range` query between \"1.0.0\" and \"1.5.0\"\n+will include versions of \"1.2.3\" but not \"1.11.2\" for example. Not that this\n+would be different when using a regular `keyword` field for indexing where ordering\n+is alphabetical.\n+\n+Software versions are expected to follow the\n+https://semver.org/[Semantic Versioning rules] schema and precedence rules with\n+the notable exception that more or less than three main version identifiers are\n+allowed (i.e. \"1.2\" or \"1.2.3.4\" qualify as valid versions while they wouldn't under\n+strict Semver rules). Version strings that are not valid under the Semver definition\n+(e.g. \"1.2.alpha.4\") can still be indexed and retrieved as exact matches, however they\n+will all appear _after_ any valid version with regular alphabetical ordering. \n+\n+[discrete]\n+[[version-params]]\n+==== Parameters for wildcard fields\n+\n+The following parameters are accepted by `version` fields:\n+\n+[horizontal]\n+\n+<<mapping-field-meta,`meta`>>::\n+\n+    Metadata about the field.\n+\n+[discrete]\n+==== Limitations\n+\n+This field type isn't optimized for heavy wildcard, regex or fuzzy searches. While those\n+type of queries work in this field, you should consider using a regular `keyword` field if\n+you strongly rely on these kind of queries.\n+\n+==== Script support\n+\n+TBD: The `version` fields offers some specialized access to detailed information derived from\n+valid version strings like the Major, Minor or Patch release number, whether the version value\n+is valid according to Semver or if it is a pre-release version. This can be helpful when e.g.\n+filtering for only released versions or running aggregations on parts of the version.\n+The following query, for example, filters for released versions and groups them by Major version\n+using a `terms` aggregation:\n+\n+[source,console]\n+--------------------------------------------------\n+POST my-index-000001/_search\n+{\n+  \"query\": {\n+    \"bool\": {\n+      \"filter\": [\n+        {\n+          \"script\": {\n+            \"script\": {\n+              \"source\": \"doc['my_version'].isPreRelease() == false\"\n+            }\n+          }\n+        }\n+      ]\n+    }\n+  },\n+  \"aggs\": {\n+    \"group_major\": {\n+      \"terms\": {\n+        \"script\": { \"source\": \"doc['my_version'].getMajor()\"},\n+        \"order\": {\n+          \"_key\": \"asc\"\n+        }\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+// TEST[continued]\n+\n+Functions available on via doc values in scripting are:\n+\n+[horizontal]\n+\n+isValid()::\n+    Returns `true` if the field contains a version thats legal according to the Semantic Versioning rules\n+\n+isPreRelease()::\n+    Returns `true` if the field contains a pre-release version", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg5MDg4NQ==", "bodyText": "I'm thinking about switching the semantics here to isRelease() because that is more likely what users will filter for (e.g. show me all errors in released versions between 1.2.3 and 2.3.4). isRelease() then could be false for invalid versions and if you are interesed in the distinction you can always use isValid() with it. Would that make more sense to you?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487890885", "createdAt": "2020-09-14T12:57:38Z", "author": {"login": "cbuescher"}, "path": "docs/reference/mapping/types/version.asciidoc", "diffHunk": "@@ -0,0 +1,125 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[discrete]\n+[[version-field-type]]\n+=== Version field type\n+\n+The `version` field type is a specialization of the `keyword` field for\n+handling software version values and to support specialized precedence\n+rules for them. Precedence is defined following the rules outlined by\n+https://semver.org/[Semantic Versioning], which for example means that\n+major, minor and patch version parts are sorted numerically (i.e. \n+\"2.1.0\" < \"2.4.1\" < \"2.11.2\") and pre-release versions are sorted before\n+release versiond (i.e. \"1.0.0-alpha\" < \"1.0.0\").\n+\n+You index a `version` field as follows\n+\n+[source,console]\n+--------------------------------------------------\n+PUT my-index-000001\n+{\n+  \"mappings\": {\n+    \"properties\": {\n+      \"my_version\": {\n+        \"type\": \"version\"\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+\n+The field offers the same search capabilities as a regular keyword field. It \n+can e.g. be searched for exact matches using `match` or `term` queries and\n+supports prefix and wildcard searches. The main benefit is that `range` queries\n+will honour Semver ordering, so a `range` query between \"1.0.0\" and \"1.5.0\"\n+will include versions of \"1.2.3\" but not \"1.11.2\" for example. Not that this\n+would be different when using a regular `keyword` field for indexing where ordering\n+is alphabetical.\n+\n+Software versions are expected to follow the\n+https://semver.org/[Semantic Versioning rules] schema and precedence rules with\n+the notable exception that more or less than three main version identifiers are\n+allowed (i.e. \"1.2\" or \"1.2.3.4\" qualify as valid versions while they wouldn't under\n+strict Semver rules). Version strings that are not valid under the Semver definition\n+(e.g. \"1.2.alpha.4\") can still be indexed and retrieved as exact matches, however they\n+will all appear _after_ any valid version with regular alphabetical ordering. \n+\n+[discrete]\n+[[version-params]]\n+==== Parameters for wildcard fields\n+\n+The following parameters are accepted by `version` fields:\n+\n+[horizontal]\n+\n+<<mapping-field-meta,`meta`>>::\n+\n+    Metadata about the field.\n+\n+[discrete]\n+==== Limitations\n+\n+This field type isn't optimized for heavy wildcard, regex or fuzzy searches. While those\n+type of queries work in this field, you should consider using a regular `keyword` field if\n+you strongly rely on these kind of queries.\n+\n+==== Script support\n+\n+TBD: The `version` fields offers some specialized access to detailed information derived from\n+valid version strings like the Major, Minor or Patch release number, whether the version value\n+is valid according to Semver or if it is a pre-release version. This can be helpful when e.g.\n+filtering for only released versions or running aggregations on parts of the version.\n+The following query, for example, filters for released versions and groups them by Major version\n+using a `terms` aggregation:\n+\n+[source,console]\n+--------------------------------------------------\n+POST my-index-000001/_search\n+{\n+  \"query\": {\n+    \"bool\": {\n+      \"filter\": [\n+        {\n+          \"script\": {\n+            \"script\": {\n+              \"source\": \"doc['my_version'].isPreRelease() == false\"\n+            }\n+          }\n+        }\n+      ]\n+    }\n+  },\n+  \"aggs\": {\n+    \"group_major\": {\n+      \"terms\": {\n+        \"script\": { \"source\": \"doc['my_version'].getMajor()\"},\n+        \"order\": {\n+          \"_key\": \"asc\"\n+        }\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+// TEST[continued]\n+\n+Functions available on via doc values in scripting are:\n+\n+[horizontal]\n+\n+isValid()::\n+    Returns `true` if the field contains a version thats legal according to the Semantic Versioning rules\n+\n+isPreRelease()::\n+    Returns `true` if the field contains a pre-release version", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg3OTI4Mg=="}, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODU5NDI1OA==", "bodyText": "I changed this in\n94def20, let me know if you think this is better or if I should revert.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r488594258", "createdAt": "2020-09-15T11:33:53Z", "author": {"login": "cbuescher"}, "path": "docs/reference/mapping/types/version.asciidoc", "diffHunk": "@@ -0,0 +1,125 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[discrete]\n+[[version-field-type]]\n+=== Version field type\n+\n+The `version` field type is a specialization of the `keyword` field for\n+handling software version values and to support specialized precedence\n+rules for them. Precedence is defined following the rules outlined by\n+https://semver.org/[Semantic Versioning], which for example means that\n+major, minor and patch version parts are sorted numerically (i.e. \n+\"2.1.0\" < \"2.4.1\" < \"2.11.2\") and pre-release versions are sorted before\n+release versiond (i.e. \"1.0.0-alpha\" < \"1.0.0\").\n+\n+You index a `version` field as follows\n+\n+[source,console]\n+--------------------------------------------------\n+PUT my-index-000001\n+{\n+  \"mappings\": {\n+    \"properties\": {\n+      \"my_version\": {\n+        \"type\": \"version\"\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+\n+The field offers the same search capabilities as a regular keyword field. It \n+can e.g. be searched for exact matches using `match` or `term` queries and\n+supports prefix and wildcard searches. The main benefit is that `range` queries\n+will honour Semver ordering, so a `range` query between \"1.0.0\" and \"1.5.0\"\n+will include versions of \"1.2.3\" but not \"1.11.2\" for example. Not that this\n+would be different when using a regular `keyword` field for indexing where ordering\n+is alphabetical.\n+\n+Software versions are expected to follow the\n+https://semver.org/[Semantic Versioning rules] schema and precedence rules with\n+the notable exception that more or less than three main version identifiers are\n+allowed (i.e. \"1.2\" or \"1.2.3.4\" qualify as valid versions while they wouldn't under\n+strict Semver rules). Version strings that are not valid under the Semver definition\n+(e.g. \"1.2.alpha.4\") can still be indexed and retrieved as exact matches, however they\n+will all appear _after_ any valid version with regular alphabetical ordering. \n+\n+[discrete]\n+[[version-params]]\n+==== Parameters for wildcard fields\n+\n+The following parameters are accepted by `version` fields:\n+\n+[horizontal]\n+\n+<<mapping-field-meta,`meta`>>::\n+\n+    Metadata about the field.\n+\n+[discrete]\n+==== Limitations\n+\n+This field type isn't optimized for heavy wildcard, regex or fuzzy searches. While those\n+type of queries work in this field, you should consider using a regular `keyword` field if\n+you strongly rely on these kind of queries.\n+\n+==== Script support\n+\n+TBD: The `version` fields offers some specialized access to detailed information derived from\n+valid version strings like the Major, Minor or Patch release number, whether the version value\n+is valid according to Semver or if it is a pre-release version. This can be helpful when e.g.\n+filtering for only released versions or running aggregations on parts of the version.\n+The following query, for example, filters for released versions and groups them by Major version\n+using a `terms` aggregation:\n+\n+[source,console]\n+--------------------------------------------------\n+POST my-index-000001/_search\n+{\n+  \"query\": {\n+    \"bool\": {\n+      \"filter\": [\n+        {\n+          \"script\": {\n+            \"script\": {\n+              \"source\": \"doc['my_version'].isPreRelease() == false\"\n+            }\n+          }\n+        }\n+      ]\n+    }\n+  },\n+  \"aggs\": {\n+    \"group_major\": {\n+      \"terms\": {\n+        \"script\": { \"source\": \"doc['my_version'].getMajor()\"},\n+        \"order\": {\n+          \"_key\": \"asc\"\n+        }\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+// TEST[continued]\n+\n+Functions available on via doc values in scripting are:\n+\n+[horizontal]\n+\n+isValid()::\n+    Returns `true` if the field contains a version thats legal according to the Semantic Versioning rules\n+\n+isPreRelease()::\n+    Returns `true` if the field contains a pre-release version", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg3OTI4Mg=="}, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODY1OTAzMQ==", "bodyText": "Thanks, having isRelease() function with semantics you defined looks very good to me.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r488659031", "createdAt": "2020-09-15T13:18:06Z", "author": {"login": "mayya-sharipova"}, "path": "docs/reference/mapping/types/version.asciidoc", "diffHunk": "@@ -0,0 +1,125 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[discrete]\n+[[version-field-type]]\n+=== Version field type\n+\n+The `version` field type is a specialization of the `keyword` field for\n+handling software version values and to support specialized precedence\n+rules for them. Precedence is defined following the rules outlined by\n+https://semver.org/[Semantic Versioning], which for example means that\n+major, minor and patch version parts are sorted numerically (i.e. \n+\"2.1.0\" < \"2.4.1\" < \"2.11.2\") and pre-release versions are sorted before\n+release versiond (i.e. \"1.0.0-alpha\" < \"1.0.0\").\n+\n+You index a `version` field as follows\n+\n+[source,console]\n+--------------------------------------------------\n+PUT my-index-000001\n+{\n+  \"mappings\": {\n+    \"properties\": {\n+      \"my_version\": {\n+        \"type\": \"version\"\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+\n+The field offers the same search capabilities as a regular keyword field. It \n+can e.g. be searched for exact matches using `match` or `term` queries and\n+supports prefix and wildcard searches. The main benefit is that `range` queries\n+will honour Semver ordering, so a `range` query between \"1.0.0\" and \"1.5.0\"\n+will include versions of \"1.2.3\" but not \"1.11.2\" for example. Not that this\n+would be different when using a regular `keyword` field for indexing where ordering\n+is alphabetical.\n+\n+Software versions are expected to follow the\n+https://semver.org/[Semantic Versioning rules] schema and precedence rules with\n+the notable exception that more or less than three main version identifiers are\n+allowed (i.e. \"1.2\" or \"1.2.3.4\" qualify as valid versions while they wouldn't under\n+strict Semver rules). Version strings that are not valid under the Semver definition\n+(e.g. \"1.2.alpha.4\") can still be indexed and retrieved as exact matches, however they\n+will all appear _after_ any valid version with regular alphabetical ordering. \n+\n+[discrete]\n+[[version-params]]\n+==== Parameters for wildcard fields\n+\n+The following parameters are accepted by `version` fields:\n+\n+[horizontal]\n+\n+<<mapping-field-meta,`meta`>>::\n+\n+    Metadata about the field.\n+\n+[discrete]\n+==== Limitations\n+\n+This field type isn't optimized for heavy wildcard, regex or fuzzy searches. While those\n+type of queries work in this field, you should consider using a regular `keyword` field if\n+you strongly rely on these kind of queries.\n+\n+==== Script support\n+\n+TBD: The `version` fields offers some specialized access to detailed information derived from\n+valid version strings like the Major, Minor or Patch release number, whether the version value\n+is valid according to Semver or if it is a pre-release version. This can be helpful when e.g.\n+filtering for only released versions or running aggregations on parts of the version.\n+The following query, for example, filters for released versions and groups them by Major version\n+using a `terms` aggregation:\n+\n+[source,console]\n+--------------------------------------------------\n+POST my-index-000001/_search\n+{\n+  \"query\": {\n+    \"bool\": {\n+      \"filter\": [\n+        {\n+          \"script\": {\n+            \"script\": {\n+              \"source\": \"doc['my_version'].isPreRelease() == false\"\n+            }\n+          }\n+        }\n+      ]\n+    }\n+  },\n+  \"aggs\": {\n+    \"group_major\": {\n+      \"terms\": {\n+        \"script\": { \"source\": \"doc['my_version'].getMajor()\"},\n+        \"order\": {\n+          \"_key\": \"asc\"\n+        }\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+// TEST[continued]\n+\n+Functions available on via doc values in scripting are:\n+\n+[horizontal]\n+\n+isValid()::\n+    Returns `true` if the field contains a version thats legal according to the Semantic Versioning rules\n+\n+isPreRelease()::\n+    Returns `true` if the field contains a pre-release version", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg3OTI4Mg=="}, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 116}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MjQ3MzE3OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionScriptDocValues.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMjo0MzowOFrOHRR6BQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMzowNzoxMFrOHRS3zA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg4MTIyMQ==", "bodyText": "For other script doc values, if a document doesn't have a value, we raise an error. I was wondering if we should do the same here, or keyword based fields behave differently?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487881221", "createdAt": "2020-09-14T12:43:08Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionScriptDocValues.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.index.SortedSetDocValues;\n+import org.apache.lucene.util.ArrayUtil;\n+import org.elasticsearch.index.fielddata.ScriptDocValues;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.VersionParts;\n+\n+import java.io.IOException;\n+\n+public final class VersionScriptDocValues extends ScriptDocValues<String> {\n+\n+    private final SortedSetDocValues in;\n+    private long[] ords = new long[0];\n+    private int count;\n+\n+    public VersionScriptDocValues(SortedSetDocValues in) {\n+        this.in = in;\n+    }\n+\n+    @Override\n+    public void setNextDocId(int docId) throws IOException {\n+        count = 0;\n+        if (in.advanceExact(docId)) {\n+            for (long ord = in.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = in.nextOrd()) {\n+                ords = ArrayUtil.grow(ords, count + 1);\n+                ords[count++] = ord;\n+            }\n+        }\n+    }\n+\n+    public String getValue() {\n+        if (count == 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg5NzAzNg==", "bodyText": "Yes, this seems to be the behaviour for doc values on keyword field, so I'm going to switch to raising that error.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487897036", "createdAt": "2020-09-14T13:07:10Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionScriptDocValues.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.index.SortedSetDocValues;\n+import org.apache.lucene.util.ArrayUtil;\n+import org.elasticsearch.index.fielddata.ScriptDocValues;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.VersionParts;\n+\n+import java.io.IOException;\n+\n+public final class VersionScriptDocValues extends ScriptDocValues<String> {\n+\n+    private final SortedSetDocValues in;\n+    private long[] ords = new long[0];\n+    private int count;\n+\n+    public VersionScriptDocValues(SortedSetDocValues in) {\n+        this.in = in;\n+    }\n+\n+    @Override\n+    public void setNextDocId(int docId) throws IOException {\n+        count = 0;\n+        if (in.advanceExact(docId)) {\n+            for (long ord = in.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = in.nextOrd()) {\n+                ords = ArrayUtil.grow(ords, count + 1);\n+                ords[count++] = ord;\n+            }\n+        }\n+    }\n+\n+    public String getValue() {\n+        if (count == 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg4MTIyMQ=="}, "originalCommit": {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1NzY4NjU4OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxMzo1MjoyNlrOHSC_GQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxMzo1MzoyM1rOHSDCCA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODY4NTMzNw==", "bodyText": "new String(new String( -> should there be only a single new String?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r488685337", "createdAt": "2020-09-15T13:52:26Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,226 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.commons.codec.Charsets;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantic Versioning (https://semver.org/)\n+ *\n+ * Version strings are considered to consist of three parts:\n+ * <ul>\n+ *  <li> a numeric major.minor.patch part starting the version string (e.g. 1.2.3)\n+ *  <li> an optional \"pre-release\" part that starts with a `-` character and can consist of several alphanumerical sections\n+ *  separated by dots (e.g. \"-alpha.2.3\")\n+ *  <li> an optional \"build\" part that starts with a `+` character. This will simply be treated as a suffix with ASCII sort order.\n+ * </ul>\n+ *\n+ * The version string is encoded such that the ordering works like the following:\n+ * <ul>\n+ *  <li> Major, minor, and patch versions are always compared numerically\n+ *  <li> pre-release version have lower precedence than a normal version. (e.g 1.0.0-alpha &lt; 1.0.0)\n+ *  <li> the precedence for pre-release versions with same main version is calculated comparing each dot separated identifier from\n+ *  left to right. Identifiers consisting of only digits are compared numerically and identifiers with letters or hyphens are compared\n+ *  lexically in ASCII sort order. Numeric identifiers always have lower precedence than non-numeric identifiers.\n+ * </ul>\n+ */\n+class VersionEncoder {\n+\n+    public static final byte NUMERIC_MARKER_BYTE = (byte) 0x01;\n+    public static final byte PRERELEASE_SEPARATOR_BYTE = (byte) 0x02;\n+    public static final byte NO_PRERELEASE_SEPARATOR_BYTE = (byte) 0x03;\n+\n+    private static final char PRERELEASE_SEPARATOR = '-';\n+    private static final char DOT_SEPARATOR = '.';\n+    private static final char BUILD_SEPARATOR = '+';\n+    private static final String ENCODED_EMPTY_STRING = new String(new String(new byte[] { NO_PRERELEASE_SEPARATOR_BYTE }, Charsets.UTF_8));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67df1d387a55c795eaecacb8e49640d3a42d24b1"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODY4NjA4OA==", "bodyText": "Heck yes!", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r488686088", "createdAt": "2020-09-15T13:53:23Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,226 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.commons.codec.Charsets;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantic Versioning (https://semver.org/)\n+ *\n+ * Version strings are considered to consist of three parts:\n+ * <ul>\n+ *  <li> a numeric major.minor.patch part starting the version string (e.g. 1.2.3)\n+ *  <li> an optional \"pre-release\" part that starts with a `-` character and can consist of several alphanumerical sections\n+ *  separated by dots (e.g. \"-alpha.2.3\")\n+ *  <li> an optional \"build\" part that starts with a `+` character. This will simply be treated as a suffix with ASCII sort order.\n+ * </ul>\n+ *\n+ * The version string is encoded such that the ordering works like the following:\n+ * <ul>\n+ *  <li> Major, minor, and patch versions are always compared numerically\n+ *  <li> pre-release version have lower precedence than a normal version. (e.g 1.0.0-alpha &lt; 1.0.0)\n+ *  <li> the precedence for pre-release versions with same main version is calculated comparing each dot separated identifier from\n+ *  left to right. Identifiers consisting of only digits are compared numerically and identifiers with letters or hyphens are compared\n+ *  lexically in ASCII sort order. Numeric identifiers always have lower precedence than non-numeric identifiers.\n+ * </ul>\n+ */\n+class VersionEncoder {\n+\n+    public static final byte NUMERIC_MARKER_BYTE = (byte) 0x01;\n+    public static final byte PRERELEASE_SEPARATOR_BYTE = (byte) 0x02;\n+    public static final byte NO_PRERELEASE_SEPARATOR_BYTE = (byte) 0x03;\n+\n+    private static final char PRERELEASE_SEPARATOR = '-';\n+    private static final char DOT_SEPARATOR = '.';\n+    private static final char BUILD_SEPARATOR = '+';\n+    private static final String ENCODED_EMPTY_STRING = new String(new String(new byte[] { NO_PRERELEASE_SEPARATOR_BYTE }, Charsets.UTF_8));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODY4NTMzNw=="}, "originalCommit": {"oid": "67df1d387a55c795eaecacb8e49640d3a42d24b1"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1ODY5Nzg5OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/test/java/org/elasticsearch/xpack/versionfield/VersionStringFieldTests.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNzozODowMVrOHSM9HA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxNTowODo0NVrOHS1iGA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODg0ODY2OA==", "bodyText": "Do you think we need to add some illegal versions and test that sort ASC will put them at the end?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r488848668", "createdAt": "2020-09-15T17:38:01Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/test/java/org/elasticsearch/xpack/versionfield/VersionStringFieldTests.java", "diffHunk": "@@ -0,0 +1,498 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.search.SearchHit;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.bucket.terms.Terms;\n+import org.elasticsearch.search.aggregations.bucket.terms.Terms.Bucket;\n+import org.elasticsearch.search.aggregations.metrics.Cardinality;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.test.ESSingleNodeTestCase;\n+import org.elasticsearch.xpack.analytics.AnalyticsAggregationBuilders;\n+import org.elasticsearch.xpack.analytics.AnalyticsPlugin;\n+import org.elasticsearch.xpack.analytics.stringstats.InternalStringStats;\n+import org.elasticsearch.xpack.core.LocalStateCompositeXPackPlugin;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class VersionStringFieldTests extends ESSingleNodeTestCase {\n+\n+    @Override\n+    protected Collection<Class<? extends Plugin>> getPlugins() {\n+        return pluginList(VersionFieldPlugin.class, LocalStateCompositeXPackPlugin.class, AnalyticsPlugin.class);\n+    }\n+\n+    public String setUpIndex(String indexName) throws IOException {\n+        createIndex(indexName, Settings.builder().put(\"index.number_of_shards\", 1).build(), \"_doc\", \"version\", \"type=version\");\n+        ensureGreen(indexName);\n+\n+        client().prepareIndex(indexName).setId(\"1\").setSource(jsonBuilder().startObject().field(\"version\", \"11.1.0\").endObject()).get();\n+        client().prepareIndex(indexName).setId(\"2\").setSource(jsonBuilder().startObject().field(\"version\", \"1.0.0\").endObject()).get();\n+        client().prepareIndex(indexName)\n+            .setId(\"3\")\n+            .setSource(jsonBuilder().startObject().field(\"version\", \"1.3.0+build.1234567\").endObject())\n+            .get();\n+        client().prepareIndex(indexName)\n+            .setId(\"4\")\n+            .setSource(jsonBuilder().startObject().field(\"version\", \"2.1.0-alpha.beta\").endObject())\n+            .get();\n+        client().prepareIndex(indexName).setId(\"5\").setSource(jsonBuilder().startObject().field(\"version\", \"2.1.0\").endObject()).get();\n+        client().prepareIndex(indexName).setId(\"6\").setSource(jsonBuilder().startObject().field(\"version\", \"21.11.0\").endObject()).get();\n+        client().admin().indices().prepareRefresh(indexName).get();\n+        return indexName;\n+    }\n+\n+    public void testExactQueries() throws Exception {\n+        String indexName = \"test\";\n+        setUpIndex(indexName);\n+\n+        // match\n+        SearchResponse response = client().prepareSearch(indexName).setQuery(QueryBuilders.matchQuery(\"version\", (\"1.0.0\"))).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.matchQuery(\"version\", \"1.4.0\")).get();\n+        assertEquals(0, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.matchQuery(\"version\", \"1.3.0\")).get();\n+        assertEquals(0, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.matchQuery(\"version\", \"1.3.0+build.1234567\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        // term\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.termQuery(\"version\", \"1.0.0\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.termQuery(\"version\", \"1.4.0\")).get();\n+        assertEquals(0, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.termQuery(\"version\", \"1.3.0\")).get();\n+        assertEquals(0, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.termQuery(\"version\", \"1.3.0+build.1234567\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        // terms\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.termsQuery(\"version\", \"1.0.0\", \"1.3.0\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.termsQuery(\"version\", \"1.4.0\", \"1.3.0+build.1234567\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        // phrase query (just for keyword compatibility)\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.matchPhraseQuery(\"version\", \"2.1.0-alpha.beta\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+    }\n+\n+    public void testRangeQueries() throws Exception {\n+        String indexName = setUpIndex(\"test\");\n+        SearchResponse response = client().prepareSearch(indexName)\n+            .setQuery(QueryBuilders.rangeQuery(\"version\").from(\"1.0.0\").to(\"3.0.0\"))\n+            .get();\n+        assertEquals(4, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").from(\"1.1.0\").to(\"3.0.0\")).get();\n+        assertEquals(3, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName)\n+            .setQuery(QueryBuilders.rangeQuery(\"version\").from(\"0.1.0\").to(\"2.1.0-alpha.beta\"))\n+            .get();\n+        assertEquals(3, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").from(\"2.1.0\").to(\"3.0.0\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").from(\"3.0.0\").to(\"4.0.0\")).get();\n+        assertEquals(0, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName)\n+            .setQuery(QueryBuilders.rangeQuery(\"version\").from(\"1.3.0+build.1234569\").to(\"3.0.0\"))\n+            .get();\n+        assertEquals(2, response.getHits().getTotalHits().value);\n+\n+        // ranges excluding edges\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").from(\"1.0.0\", false).to(\"3.0.0\")).get();\n+        assertEquals(3, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").from(\"1.0.0\").to(\"2.1.0\", false)).get();\n+        assertEquals(3, response.getHits().getTotalHits().value);\n+\n+        // open ranges\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").from(\"1.4.0\")).get();\n+        assertEquals(4, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").to(\"1.4.0\")).get();\n+        assertEquals(2, response.getHits().getTotalHits().value);\n+    }\n+\n+    public void testPrefixQuery() throws IOException {\n+        String indexName = setUpIndex(\"test\");\n+        // prefix\n+        SearchResponse response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"1\")).get();\n+        assertEquals(3, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"2.1\")).get();\n+        assertEquals(2, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"2.1.0-\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"1.3.0+b\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"2\")).get();\n+        assertEquals(3, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"21\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"21.\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"21.1\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"21.11\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+    }\n+\n+    public void testSort() throws IOException {\n+        String indexName = setUpIndex(\"test\");\n+\n+        // sort based on version field\n+        SearchResponse response = client().prepareSearch(indexName)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67df1d387a55c795eaecacb8e49640d3a42d24b1"}, "originalPosition": 163}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTUxMzQ5Ng==", "bodyText": "Sure can do.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r489513496", "createdAt": "2020-09-16T15:08:45Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/test/java/org/elasticsearch/xpack/versionfield/VersionStringFieldTests.java", "diffHunk": "@@ -0,0 +1,498 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.search.SearchHit;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.bucket.terms.Terms;\n+import org.elasticsearch.search.aggregations.bucket.terms.Terms.Bucket;\n+import org.elasticsearch.search.aggregations.metrics.Cardinality;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.test.ESSingleNodeTestCase;\n+import org.elasticsearch.xpack.analytics.AnalyticsAggregationBuilders;\n+import org.elasticsearch.xpack.analytics.AnalyticsPlugin;\n+import org.elasticsearch.xpack.analytics.stringstats.InternalStringStats;\n+import org.elasticsearch.xpack.core.LocalStateCompositeXPackPlugin;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class VersionStringFieldTests extends ESSingleNodeTestCase {\n+\n+    @Override\n+    protected Collection<Class<? extends Plugin>> getPlugins() {\n+        return pluginList(VersionFieldPlugin.class, LocalStateCompositeXPackPlugin.class, AnalyticsPlugin.class);\n+    }\n+\n+    public String setUpIndex(String indexName) throws IOException {\n+        createIndex(indexName, Settings.builder().put(\"index.number_of_shards\", 1).build(), \"_doc\", \"version\", \"type=version\");\n+        ensureGreen(indexName);\n+\n+        client().prepareIndex(indexName).setId(\"1\").setSource(jsonBuilder().startObject().field(\"version\", \"11.1.0\").endObject()).get();\n+        client().prepareIndex(indexName).setId(\"2\").setSource(jsonBuilder().startObject().field(\"version\", \"1.0.0\").endObject()).get();\n+        client().prepareIndex(indexName)\n+            .setId(\"3\")\n+            .setSource(jsonBuilder().startObject().field(\"version\", \"1.3.0+build.1234567\").endObject())\n+            .get();\n+        client().prepareIndex(indexName)\n+            .setId(\"4\")\n+            .setSource(jsonBuilder().startObject().field(\"version\", \"2.1.0-alpha.beta\").endObject())\n+            .get();\n+        client().prepareIndex(indexName).setId(\"5\").setSource(jsonBuilder().startObject().field(\"version\", \"2.1.0\").endObject()).get();\n+        client().prepareIndex(indexName).setId(\"6\").setSource(jsonBuilder().startObject().field(\"version\", \"21.11.0\").endObject()).get();\n+        client().admin().indices().prepareRefresh(indexName).get();\n+        return indexName;\n+    }\n+\n+    public void testExactQueries() throws Exception {\n+        String indexName = \"test\";\n+        setUpIndex(indexName);\n+\n+        // match\n+        SearchResponse response = client().prepareSearch(indexName).setQuery(QueryBuilders.matchQuery(\"version\", (\"1.0.0\"))).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.matchQuery(\"version\", \"1.4.0\")).get();\n+        assertEquals(0, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.matchQuery(\"version\", \"1.3.0\")).get();\n+        assertEquals(0, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.matchQuery(\"version\", \"1.3.0+build.1234567\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        // term\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.termQuery(\"version\", \"1.0.0\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.termQuery(\"version\", \"1.4.0\")).get();\n+        assertEquals(0, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.termQuery(\"version\", \"1.3.0\")).get();\n+        assertEquals(0, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.termQuery(\"version\", \"1.3.0+build.1234567\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        // terms\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.termsQuery(\"version\", \"1.0.0\", \"1.3.0\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.termsQuery(\"version\", \"1.4.0\", \"1.3.0+build.1234567\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        // phrase query (just for keyword compatibility)\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.matchPhraseQuery(\"version\", \"2.1.0-alpha.beta\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+    }\n+\n+    public void testRangeQueries() throws Exception {\n+        String indexName = setUpIndex(\"test\");\n+        SearchResponse response = client().prepareSearch(indexName)\n+            .setQuery(QueryBuilders.rangeQuery(\"version\").from(\"1.0.0\").to(\"3.0.0\"))\n+            .get();\n+        assertEquals(4, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").from(\"1.1.0\").to(\"3.0.0\")).get();\n+        assertEquals(3, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName)\n+            .setQuery(QueryBuilders.rangeQuery(\"version\").from(\"0.1.0\").to(\"2.1.0-alpha.beta\"))\n+            .get();\n+        assertEquals(3, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").from(\"2.1.0\").to(\"3.0.0\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").from(\"3.0.0\").to(\"4.0.0\")).get();\n+        assertEquals(0, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName)\n+            .setQuery(QueryBuilders.rangeQuery(\"version\").from(\"1.3.0+build.1234569\").to(\"3.0.0\"))\n+            .get();\n+        assertEquals(2, response.getHits().getTotalHits().value);\n+\n+        // ranges excluding edges\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").from(\"1.0.0\", false).to(\"3.0.0\")).get();\n+        assertEquals(3, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").from(\"1.0.0\").to(\"2.1.0\", false)).get();\n+        assertEquals(3, response.getHits().getTotalHits().value);\n+\n+        // open ranges\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").from(\"1.4.0\")).get();\n+        assertEquals(4, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").to(\"1.4.0\")).get();\n+        assertEquals(2, response.getHits().getTotalHits().value);\n+    }\n+\n+    public void testPrefixQuery() throws IOException {\n+        String indexName = setUpIndex(\"test\");\n+        // prefix\n+        SearchResponse response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"1\")).get();\n+        assertEquals(3, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"2.1\")).get();\n+        assertEquals(2, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"2.1.0-\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"1.3.0+b\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"2\")).get();\n+        assertEquals(3, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"21\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"21.\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"21.1\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"21.11\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+    }\n+\n+    public void testSort() throws IOException {\n+        String indexName = setUpIndex(\"test\");\n+\n+        // sort based on version field\n+        SearchResponse response = client().prepareSearch(indexName)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODg0ODY2OA=="}, "originalCommit": {"oid": "67df1d387a55c795eaecacb8e49640d3a42d24b1"}, "originalPosition": 163}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1OTM0NjEzOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionFieldWildcardQuery.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQyMDoyNDo0M1rOHSTO3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxNjoyMzowOVrOHS4s9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODk1MTUxOQ==", "bodyText": "@cbuescher This is a quite clever way to organize wildcard query!!! Good job here!!!\nFor this particular case of ? case, I think we need to add additional optional automata of PRERELEASE_SEPARATOR_BYTE and NO_PRERELEASE_SEPARATOR_BYTE.\nOtherwise,  a query \"1.2.3??\" can't match  a version like \"1.2.3+b\" or a version like \"1.2.3-a\"", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r488951519", "createdAt": "2020-09-15T20:24:43Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionFieldWildcardQuery.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.search.AutomatonQuery;\n+import org.apache.lucene.search.WildcardQuery;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.Automata;\n+import org.apache.lucene.util.automaton.Automaton;\n+import org.apache.lucene.util.automaton.Operations;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * A variation of the {@link WildcardQuery} than skips over meta characters introduced using {@link VersionEncoder}.\n+ */\n+class VersionFieldWildcardQuery extends AutomatonQuery {\n+\n+    private static final byte WILDCARD_STRING = '*';\n+\n+    private static final byte WILDCARD_CHAR = '?';\n+\n+    VersionFieldWildcardQuery(Term term) {\n+        super(term, toAutomaton(term), Integer.MAX_VALUE, true);\n+    }\n+\n+    private static Automaton toAutomaton(Term wildcardquery) {\n+        List<Automaton> automata = new ArrayList<>();\n+\n+        BytesRef wildcardText = wildcardquery.bytes();\n+        boolean containsPreReleaseSeparator = false;\n+\n+        for (int i = 0; i < wildcardText.length;) {\n+            final byte c = wildcardText.bytes[wildcardText.offset + i];\n+            int length = Character.charCount(c);\n+\n+            switch (c) {\n+                case WILDCARD_STRING:\n+                    automata.add(Automata.makeAnyString());\n+                    break;\n+                case WILDCARD_CHAR:\n+                    // this should also match leading digits, which have optional leading numeric marker and length bytes\n+                    automata.add(optionalNumericCharPrefix());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67df1d387a55c795eaecacb8e49640d3a42d24b1"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTU2NTQzMQ==", "bodyText": "Great catch, I'll add a test for this and will work on it", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r489565431", "createdAt": "2020-09-16T16:23:09Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionFieldWildcardQuery.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.search.AutomatonQuery;\n+import org.apache.lucene.search.WildcardQuery;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.Automata;\n+import org.apache.lucene.util.automaton.Automaton;\n+import org.apache.lucene.util.automaton.Operations;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * A variation of the {@link WildcardQuery} than skips over meta characters introduced using {@link VersionEncoder}.\n+ */\n+class VersionFieldWildcardQuery extends AutomatonQuery {\n+\n+    private static final byte WILDCARD_STRING = '*';\n+\n+    private static final byte WILDCARD_CHAR = '?';\n+\n+    VersionFieldWildcardQuery(Term term) {\n+        super(term, toAutomaton(term), Integer.MAX_VALUE, true);\n+    }\n+\n+    private static Automaton toAutomaton(Term wildcardquery) {\n+        List<Automaton> automata = new ArrayList<>();\n+\n+        BytesRef wildcardText = wildcardquery.bytes();\n+        boolean containsPreReleaseSeparator = false;\n+\n+        for (int i = 0; i < wildcardText.length;) {\n+            final byte c = wildcardText.bytes[wildcardText.offset + i];\n+            int length = Character.charCount(c);\n+\n+            switch (c) {\n+                case WILDCARD_STRING:\n+                    automata.add(Automata.makeAnyString());\n+                    break;\n+                case WILDCARD_CHAR:\n+                    // this should also match leading digits, which have optional leading numeric marker and length bytes\n+                    automata.add(optionalNumericCharPrefix());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODk1MTUxOQ=="}, "originalCommit": {"oid": "67df1d387a55c795eaecacb8e49640d3a42d24b1"}, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2Nzg1MzU2OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionScriptDocValues.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNDo0Mzo0OVrOHTl6Og==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNDo0Mzo0OVrOHTl6Og==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDMwNjEwNg==", "bodyText": "Small comment: I think this check should be put in get(int index) function, as we can call get(int index) function without calling getValue.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490306106", "createdAt": "2020-09-17T14:43:49Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionScriptDocValues.java", "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.index.SortedSetDocValues;\n+import org.apache.lucene.util.ArrayUtil;\n+import org.elasticsearch.index.fielddata.ScriptDocValues;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.VersionParts;\n+\n+import java.io.IOException;\n+\n+public final class VersionScriptDocValues extends ScriptDocValues<String> {\n+\n+    private final SortedSetDocValues in;\n+    private long[] ords = new long[0];\n+    private int count;\n+\n+    public VersionScriptDocValues(SortedSetDocValues in) {\n+        this.in = in;\n+    }\n+\n+    @Override\n+    public void setNextDocId(int docId) throws IOException {\n+        count = 0;\n+        if (in.advanceExact(docId)) {\n+            for (long ord = in.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = in.nextOrd()) {\n+                ords = ArrayUtil.grow(ords, count + 1);\n+                ords[count++] = ord;\n+            }\n+        }\n+    }\n+\n+    public String getValue() {\n+        if (count == 0) {\n+            throw new IllegalStateException(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce5148478d965fc4f3e4a85585301417348b2f26"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2Nzk0MTM5OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNDo1NzoxM1rOHTmxcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNDo1NzoxM1rOHTmxcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDMyMDI0MA==", "bodyText": "this check for null for lowerTerm and upperTerm look unnecessary as it is already done above", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490320240", "createdAt": "2020-09-17T14:57:13Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,419 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build()\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"regexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int syntaxFlags,\n+            int matchFlags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), syntaxFlags, matchFlags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName, Supplier<SearchLookup> searchLookup) {\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+\n+            return new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce5148478d965fc4f3e4a85585301417348b2f26"}, "originalPosition": 307}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2Nzk2OTAzOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNTowMjozMVrOHTnCCw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQwOTowNToyN1rOHUEidA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDMyNDQ5MQ==", "bodyText": "May be we can add to do for subsequent PRs to optimize these queries", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490324491", "createdAt": "2020-09-17T15:02:31Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,419 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build()\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"regexp\" queries on this field rare enough to brute-force this", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce5148478d965fc4f3e4a85585301417348b2f26"}, "originalPosition": 158}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDM2OTU4Mg==", "bodyText": "I'm not a bit fan of tracking backlog like this in TODOs in code, I'd rather open an issue to investigate improvements when time allows and track it with any other issue we have. Would that be okay for you?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490369582", "createdAt": "2020-09-17T16:04:53Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,419 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build()\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"regexp\" queries on this field rare enough to brute-force this", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDMyNDQ5MQ=="}, "originalCommit": {"oid": "ce5148478d965fc4f3e4a85585301417348b2f26"}, "originalPosition": 158}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDQ2ODQ2Mg==", "bodyText": "@cbuescher Thanks, that would be fine.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490468462", "createdAt": "2020-09-17T18:26:48Z", "author": {"login": "mayya-sharipova"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,419 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build()\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"regexp\" queries on this field rare enough to brute-force this", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDMyNDQ5MQ=="}, "originalCommit": {"oid": "ce5148478d965fc4f3e4a85585301417348b2f26"}, "originalPosition": 158}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDgwNzkyNA==", "bodyText": "I opened #62608 for tracking", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490807924", "createdAt": "2020-09-18T09:05:27Z", "author": {"login": "cbuescher"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,419 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build()\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"regexp\" queries on this field rare enough to brute-force this", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDMyNDQ5MQ=="}, "originalCommit": {"oid": "ce5148478d965fc4f3e4a85585301417348b2f26"}, "originalPosition": 158}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3MjAxOTQ1OnYy", "diffSide": "RIGHT", "path": "docs/reference/mapping/types/version.asciidoc", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMzoyOTozNlrOHUNMVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxNDozMToyMlrOHUPshw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDk0OTcxNg==", "bodyText": "I understand how useful these functions can be but I'd prefer that we handle this in a follow up. It's unclear to me if these functions could be useful for other types as well (runtime or keyword field ?) so I think we should discuss this feature separately.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490949716", "createdAt": "2020-09-18T13:29:36Z", "author": {"login": "jimczi"}, "path": "docs/reference/mapping/types/version.asciidoc", "diffHunk": "@@ -0,0 +1,129 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[[version]]\n+=== Version field type\n+++++\n+<titleabbrev>Version</titleabbrev>\n+++++\n+\n+The `version` field type is a specialization of the `keyword` field for\n+handling software version values and to support specialized precedence\n+rules for them. Precedence is defined following the rules outlined by\n+https://semver.org/[Semantic Versioning], which for example means that\n+major, minor and patch version parts are sorted numerically (i.e. \n+\"2.1.0\" < \"2.4.1\" < \"2.11.2\") and pre-release versions are sorted before\n+release versiond (i.e. \"1.0.0-alpha\" < \"1.0.0\").\n+\n+You index a `version` field as follows\n+\n+[source,console]\n+--------------------------------------------------\n+PUT my-index-000001\n+{\n+  \"mappings\": {\n+    \"properties\": {\n+      \"my_version\": {\n+        \"type\": \"version\"\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+\n+The field offers the same search capabilities as a regular keyword field. It \n+can e.g. be searched for exact matches using `match` or `term` queries and\n+supports prefix and wildcard searches. The main benefit is that `range` queries\n+will honour Semver ordering, so a `range` query between \"1.0.0\" and \"1.5.0\"\n+will include versions of \"1.2.3\" but not \"1.11.2\" for example. Note that this\n+would be different when using a regular `keyword` field for indexing where ordering\n+is alphabetical.\n+\n+Software versions are expected to follow the\n+https://semver.org/[Semantic Versioning rules] schema and precedence rules with\n+the notable exception that more or less than three main version identifiers are\n+allowed (i.e. \"1.2\" or \"1.2.3.4\" qualify as valid versions while they wouldn't under\n+strict Semver rules). Version strings that are not valid under the Semver definition\n+(e.g. \"1.2.alpha.4\") can still be indexed and retrieved as exact matches, however they\n+will all appear _after_ any valid version with regular alphabetical ordering. The empty\n+String \"\" is considered invalid and sorted after all valid versions, but before other\n+invalid ones.\n+\n+[discrete]\n+[[version-params]]\n+==== Parameters for version fields\n+\n+The following parameters are accepted by `version` fields:\n+\n+[horizontal]\n+\n+<<mapping-field-meta,`meta`>>::\n+\n+    Metadata about the field.\n+\n+[discrete]\n+==== Limitations\n+\n+This field type isn't optimized for heavy wildcard, regex or fuzzy searches. While those\n+type of queries work in this field, you should consider using a regular `keyword` field if\n+you strongly rely on these kind of queries.\n+\n+==== Script support\n+\n+The `version` fields offers some specialized access to detailed information derived from\n+valid version strings like the Major, Minor or Patch release number, whether the version value\n+is valid according to Semver or if it is a pre-release version. This can be helpful when e.g.\n+filtering for only released versions or running aggregations on parts of the version.\n+The following query, for example, filters for released versions and groups them by Major version\n+using a `terms` aggregation:\n+\n+[source,console]\n+--------------------------------------------------\n+POST my-index-000001/_search\n+{\n+  \"query\": {\n+    \"bool\": {\n+      \"filter\": [\n+        {\n+          \"script\": {\n+            \"script\": {\n+              \"source\": \"doc['my_version'].isRelease() == true\"\n+            }\n+          }\n+        }\n+      ]\n+    }\n+  },\n+  \"aggs\": {\n+    \"group_major\": {\n+      \"terms\": {\n+        \"script\": { \"source\": \"doc['my_version'].getMajor()\"},\n+        \"order\": {\n+          \"_key\": \"asc\"\n+        }\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+// TEST[continued]\n+\n+Functions available on via doc values in scripting are:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ccebd6f470c99c824a84211ed122ba10f1f9629c"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDk5MDcyNw==", "bodyText": "I'll factor these out into a follow up issue/PR.", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490990727", "createdAt": "2020-09-18T14:31:22Z", "author": {"login": "cbuescher"}, "path": "docs/reference/mapping/types/version.asciidoc", "diffHunk": "@@ -0,0 +1,129 @@\n+[role=\"xpack\"]\n+[testenv=\"basic\"]\n+[[version]]\n+=== Version field type\n+++++\n+<titleabbrev>Version</titleabbrev>\n+++++\n+\n+The `version` field type is a specialization of the `keyword` field for\n+handling software version values and to support specialized precedence\n+rules for them. Precedence is defined following the rules outlined by\n+https://semver.org/[Semantic Versioning], which for example means that\n+major, minor and patch version parts are sorted numerically (i.e. \n+\"2.1.0\" < \"2.4.1\" < \"2.11.2\") and pre-release versions are sorted before\n+release versiond (i.e. \"1.0.0-alpha\" < \"1.0.0\").\n+\n+You index a `version` field as follows\n+\n+[source,console]\n+--------------------------------------------------\n+PUT my-index-000001\n+{\n+  \"mappings\": {\n+    \"properties\": {\n+      \"my_version\": {\n+        \"type\": \"version\"\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+\n+The field offers the same search capabilities as a regular keyword field. It \n+can e.g. be searched for exact matches using `match` or `term` queries and\n+supports prefix and wildcard searches. The main benefit is that `range` queries\n+will honour Semver ordering, so a `range` query between \"1.0.0\" and \"1.5.0\"\n+will include versions of \"1.2.3\" but not \"1.11.2\" for example. Note that this\n+would be different when using a regular `keyword` field for indexing where ordering\n+is alphabetical.\n+\n+Software versions are expected to follow the\n+https://semver.org/[Semantic Versioning rules] schema and precedence rules with\n+the notable exception that more or less than three main version identifiers are\n+allowed (i.e. \"1.2\" or \"1.2.3.4\" qualify as valid versions while they wouldn't under\n+strict Semver rules). Version strings that are not valid under the Semver definition\n+(e.g. \"1.2.alpha.4\") can still be indexed and retrieved as exact matches, however they\n+will all appear _after_ any valid version with regular alphabetical ordering. The empty\n+String \"\" is considered invalid and sorted after all valid versions, but before other\n+invalid ones.\n+\n+[discrete]\n+[[version-params]]\n+==== Parameters for version fields\n+\n+The following parameters are accepted by `version` fields:\n+\n+[horizontal]\n+\n+<<mapping-field-meta,`meta`>>::\n+\n+    Metadata about the field.\n+\n+[discrete]\n+==== Limitations\n+\n+This field type isn't optimized for heavy wildcard, regex or fuzzy searches. While those\n+type of queries work in this field, you should consider using a regular `keyword` field if\n+you strongly rely on these kind of queries.\n+\n+==== Script support\n+\n+The `version` fields offers some specialized access to detailed information derived from\n+valid version strings like the Major, Minor or Patch release number, whether the version value\n+is valid according to Semver or if it is a pre-release version. This can be helpful when e.g.\n+filtering for only released versions or running aggregations on parts of the version.\n+The following query, for example, filters for released versions and groups them by Major version\n+using a `terms` aggregation:\n+\n+[source,console]\n+--------------------------------------------------\n+POST my-index-000001/_search\n+{\n+  \"query\": {\n+    \"bool\": {\n+      \"filter\": [\n+        {\n+          \"script\": {\n+            \"script\": {\n+              \"source\": \"doc['my_version'].isRelease() == true\"\n+            }\n+          }\n+        }\n+      ]\n+    }\n+  },\n+  \"aggs\": {\n+    \"group_major\": {\n+      \"terms\": {\n+        \"script\": { \"source\": \"doc['my_version'].getMajor()\"},\n+        \"order\": {\n+          \"_key\": \"asc\"\n+        }\n+      }\n+    }\n+  }\n+}\n+\n+--------------------------------------------------\n+// TEST[continued]\n+\n+Functions available on via doc values in scripting are:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDk0OTcxNg=="}, "originalCommit": {"oid": "ccebd6f470c99c824a84211ed122ba10f1f9629c"}, "originalPosition": 112}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3MjA0MzA4OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/ValidationOnSortedDv.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMzozNTo0MlrOHUNbYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMzozNTo0MlrOHUNbYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDk1MzU2OQ==", "bodyText": "This class is not needed anymore ?", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490953569", "createdAt": "2020-09-18T13:35:42Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/ValidationOnSortedDv.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.index.DocValues;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.SortedSetDocValues;\n+import org.apache.lucene.search.ConstantScoreScorer;\n+import org.apache.lucene.search.ConstantScoreWeight;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.search.Scorer;\n+import org.apache.lucene.search.TwoPhaseIterator;\n+import org.apache.lucene.search.Weight;\n+import org.apache.lucene.util.BytesRef;\n+\n+import java.io.IOException;\n+import java.util.Objects;\n+\n+/**\n+ * Query that runs a validation for version ranges across sorted doc values.\n+ * Used in conjunction with more selective query clauses.\n+ */\n+class ValidationOnSortedDv extends Query {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ccebd6f470c99c824a84211ed122ba10f1f9629c"}, "originalPosition": 29}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2293, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}