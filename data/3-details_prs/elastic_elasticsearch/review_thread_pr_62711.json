{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDkwMzg0MDQx", "number": 62711, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQxNToyOToyN1rOEluP-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQxNzoyOTo1OFrOElxK0w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3OTkwNTIxOnYy", "diffSide": "RIGHT", "path": "test/framework/src/main/java/org/elasticsearch/snapshots/mockstore/MockRepository.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQxNToyOToyN1rOHVWpvQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQxNToyOToyN1rOHVWpvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjE1MzI3Nw==", "bodyText": "We didn't throw here before but then again we only got here when all the threads were already interrupted -> I figured throwing here keeps things nice and deterministic.", "url": "https://github.com/elastic/elasticsearch/pull/62711#discussion_r492153277", "createdAt": "2020-09-21T15:29:27Z", "author": {"login": "original-brownbear"}, "path": "test/framework/src/main/java/org/elasticsearch/snapshots/mockstore/MockRepository.java", "diffHunk": "@@ -322,9 +322,13 @@ private void maybeIOExceptionOrBlock(String blobName) throws IOException {\n                 }\n             }\n \n-            private void blockExecutionAndMaybeWait(final String blobName) {\n+            private void blockExecutionAndMaybeWait(final String blobName) throws IOException {\n                 logger.info(\"[{}] blocking I/O operation for file [{}] at path [{}]\", metadata.name(), blobName, path());\n-                if (blockExecution() && waitAfterUnblock > 0) {\n+                final boolean wasBlocked = blockExecution();\n+                if (wasBlocked && lifecycle.stoppedOrClosed()) {\n+                    throw new IOException(\"already closed\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a01b184af15f4983fe5caded8b029a0c293a272b"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA4MDM4MzU1OnYy", "diffSide": "RIGHT", "path": "server/src/internalClusterTest/java/org/elasticsearch/repositories/blobstore/BlobStoreRepositoryCleanupIT.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQxNzoyOTo1OFrOHVbS6A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMlQwNzo1NjoxMFrOHVuRWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjIyOTM1Mg==", "bodyText": "We need to actually wait here for the cluster change to be fully registerd, otherwise we just randomly pick a node that hasn't yet seen the cleanup in progress in the CS and fail on the leaked running cleanup.\nObviously, there's a bit of a risk with this change in general and it might lead to more failures that need a check like this added now because they implicitly relied on the 10s wait when closing a blocked node but IMO it's worth it given the almost 10s per affected test (and it's quite a few) savings.", "url": "https://github.com/elastic/elasticsearch/pull/62711#discussion_r492229352", "createdAt": "2020-09-21T17:29:58Z", "author": {"login": "original-brownbear"}, "path": "server/src/internalClusterTest/java/org/elasticsearch/repositories/blobstore/BlobStoreRepositoryCleanupIT.java", "diffHunk": "@@ -42,9 +42,12 @@\n     public void testMasterFailoverDuringCleanup() throws Exception {\n         startBlockedCleanup(\"test-repo\");\n \n+        final int nodeCount = internalCluster().numDataAndMasterNodes();\n         logger.info(\"-->  stopping master node\");\n         internalCluster().stopCurrentMasterNode();\n \n+        ensureStableCluster(nodeCount - 1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "79578acec2faddd007aaf87f7356330dbdadb389"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjUzMDI4Mg==", "bodyText": "We can maybe run this PR on CI multiple times before merging, just to catch the most failing tests if any. But I agree with you, it's better to not have test relying on the implicit 10s.", "url": "https://github.com/elastic/elasticsearch/pull/62711#discussion_r492530282", "createdAt": "2020-09-22T07:37:56Z", "author": {"login": "tlrx"}, "path": "server/src/internalClusterTest/java/org/elasticsearch/repositories/blobstore/BlobStoreRepositoryCleanupIT.java", "diffHunk": "@@ -42,9 +42,12 @@\n     public void testMasterFailoverDuringCleanup() throws Exception {\n         startBlockedCleanup(\"test-repo\");\n \n+        final int nodeCount = internalCluster().numDataAndMasterNodes();\n         logger.info(\"-->  stopping master node\");\n         internalCluster().stopCurrentMasterNode();\n \n+        ensureStableCluster(nodeCount - 1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjIyOTM1Mg=="}, "originalCommit": {"oid": "79578acec2faddd007aaf87f7356330dbdadb389"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjU0MDI1MA==", "bodyText": "We can maybe run this PR on CI multiple times before merging, just to catch the most failing tests if any\n\nRan it all night on my local CI :D only shook out an endless series of #62713 for now :) I'm more worried about some low-frequency timing issues (from request retries) but now that we're aware of it, it should be easy to track those down if they actually occur :)", "url": "https://github.com/elastic/elasticsearch/pull/62711#discussion_r492540250", "createdAt": "2020-09-22T07:56:10Z", "author": {"login": "original-brownbear"}, "path": "server/src/internalClusterTest/java/org/elasticsearch/repositories/blobstore/BlobStoreRepositoryCleanupIT.java", "diffHunk": "@@ -42,9 +42,12 @@\n     public void testMasterFailoverDuringCleanup() throws Exception {\n         startBlockedCleanup(\"test-repo\");\n \n+        final int nodeCount = internalCluster().numDataAndMasterNodes();\n         logger.info(\"-->  stopping master node\");\n         internalCluster().stopCurrentMasterNode();\n \n+        ensureStableCluster(nodeCount - 1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjIyOTM1Mg=="}, "originalCommit": {"oid": "79578acec2faddd007aaf87f7356330dbdadb389"}, "originalPosition": 8}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3388, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}