{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTM1OTcwNDgw", "number": 66172, "title": "Add `match_only_text`, a space-efficient variant of `text`.", "bodyText": "This adds a new match_only_text field, which indexes the same data as a text\nfield that has index_options: docs and norms: false and uses the _source\nfor positional queries like match_phrase.\nUnlike text, this field doesn't support scoring and span queries.\nThis new field is part of the text family, so it is returned as a text field in the\n_field_caps output.\nCloses #64467", "createdAt": "2020-12-10T14:19:48Z", "url": "https://github.com/elastic/elasticsearch/pull/66172", "merged": true, "mergeCommit": {"oid": "83113ec8d362cc4b8e755aef452f09759153bfb5"}, "closed": true, "closedAt": "2021-04-22T06:41:47Z", "author": {"login": "jpountz"}, "timelineItems": {"totalCount": 36, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdk0DpEgH2gAyNTM1OTcwNDgwOjBiZmQzODc3YzllODg3YzEwOGMzMjg2ZjI0YmEyMWExYTlhMGQ0NDM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABePTAI4AH2gAyNTM1OTcwNDgwOmVkYWE1YjBkOWYzODIwYmI2MTQ3MjQ3NjBmN2U0N2JhMjIyZmJlODg=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "0bfd3877c9e887c108c3286f24ba21a1a9a0d443", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/0bfd3877c9e887c108c3286f24ba21a1a9a0d443", "committedDate": "2020-12-10T14:17:33Z", "message": "Add `match_only_text`, a space-efficient variant of `text`.\n\nThis adds a new `match_only_text` field, which indexes the same data as a `text`\nfield that has `index_options: docs` and `norms: false` and uses the `_source`\nfor positional queries like `match_phrase`. Unlike `text`, this field doesn't\nsupport scoring.\n\nAn alternative to this new field could have been to make the `text` field still\nable to run positional queries when positions are not indexed, but I like this\nnew field better because it avoids questions around how scoring should perform."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ5MjQ5ODQ1", "url": "https://github.com/elastic/elasticsearch/pull/66172#pullrequestreview-549249845", "createdAt": "2020-12-10T14:28:23Z", "commit": {"oid": "0bfd3877c9e887c108c3286f24ba21a1a9a0d443"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQxNDoyODoyM1rOIDL7aQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQxNDo0NjozNVrOIDMzeg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIxMjA3Mw==", "bodyText": "I don't think you need to copy this bit, because there will be no BWC issue with a new mapper", "url": "https://github.com/elastic/elasticsearch/pull/66172#discussion_r540212073", "createdAt": "2020-12-10T14:28:23Z", "author": {"login": "romseygeek"}, "path": "x-pack/plugin/mapper-match-only-text/src/main/java/org/elasticsearch/xpack/matchonlytext/mapper/MatchOnlyTextFieldMapper.java", "diffHunk": "@@ -0,0 +1,302 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.matchonlytext.mapper;\n+\n+import org.apache.lucene.analysis.Analyzer;\n+import org.apache.lucene.analysis.TokenStream;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.ConstantScoreQuery;\n+import org.apache.lucene.search.Query;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.common.CheckedIntFunction;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.index.analysis.IndexAnalyzers;\n+import org.elasticsearch.index.analysis.NamedAnalyzer;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.mapper.ContentPath;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.StringFieldType;\n+import org.elasticsearch.index.mapper.TextFieldMapper;\n+import org.elasticsearch.index.mapper.TextFieldMapper.TextFieldType;\n+import org.elasticsearch.index.mapper.TextParams;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.search.lookup.SourceLookup;\n+import org.elasticsearch.xpack.matchonlytext.query.SourceConfirmedTextQuery;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+/**\n+ * A {@link FieldMapper} for full-text fields that only indexes\n+ * {@link IndexOptions#DOCS} and runs positional queries by looking at the\n+ * _source.\n+ */\n+public class MatchOnlyTextFieldMapper extends FieldMapper {\n+\n+    public static final String CONTENT_TYPE = \"match_only_text\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(true);\n+            FIELD_TYPE.setStored(false);\n+            FIELD_TYPE.setStoreTermVectors(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+    }\n+\n+    private static Builder builder(FieldMapper in) {\n+        return ((MatchOnlyTextFieldMapper) in).builder;\n+    }\n+\n+    public static class Builder extends FieldMapper.Builder {\n+\n+        private final Version indexCreatedVersion;\n+\n+        private final Parameter<Boolean> store = Parameter.storeParam(m -> builder(m).store.getValue(), false);\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        private final TextParams.Analyzers analyzers;\n+\n+        public Builder(String name, IndexAnalyzers indexAnalyzers) {\n+            this(name, Version.CURRENT, indexAnalyzers);\n+        }\n+\n+        public Builder(String name, Version indexCreatedVersion, IndexAnalyzers indexAnalyzers) {\n+            super(name);\n+            this.indexCreatedVersion = indexCreatedVersion;\n+            this.analyzers = new TextParams.Analyzers(indexAnalyzers, m -> builder(m).analyzers);\n+        }\n+\n+        public Builder store(boolean store) {\n+            this.store.setValue(store);\n+            return this;\n+        }\n+\n+        public Builder addMultiField(FieldMapper.Builder builder) {\n+            this.multiFieldsBuilder.add(builder);\n+            return this;\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return Arrays.asList(store, analyzers.indexAnalyzer, analyzers.searchAnalyzer, analyzers.searchQuoteAnalyzer, meta);\n+        }\n+\n+        private MatchOnlyTextFieldType buildFieldType(FieldType fieldType, ContentPath contentPath) {\n+            NamedAnalyzer searchAnalyzer = analyzers.getSearchAnalyzer();\n+            NamedAnalyzer searchQuoteAnalyzer = analyzers.getSearchQuoteAnalyzer();\n+            NamedAnalyzer indexAnalyzer = analyzers.getIndexAnalyzer();\n+            TextSearchInfo tsi = new TextSearchInfo(fieldType, null, searchAnalyzer, searchQuoteAnalyzer);\n+            MatchOnlyTextFieldType ft = new MatchOnlyTextFieldType(\n+                buildFullName(contentPath),\n+                store.getValue(),\n+                tsi,\n+                indexAnalyzer,\n+                meta.getValue()\n+            );\n+            return ft;\n+        }\n+\n+        @Override\n+        public MatchOnlyTextFieldMapper build(ContentPath contentPath) {\n+            FieldType fieldType = new FieldType(Defaults.FIELD_TYPE);\n+            fieldType.setStored(store.get());\n+            MatchOnlyTextFieldType tft = buildFieldType(fieldType, contentPath);\n+            MultiFields multiFields = multiFieldsBuilder.build(this, contentPath);\n+            return new MatchOnlyTextFieldMapper(name, fieldType, tft, analyzers.getIndexAnalyzer(), multiFields, copyTo.build(), this);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n, c.indexVersionCreated(), c.getIndexAnalyzers()));\n+\n+    public static class MatchOnlyTextFieldType extends StringFieldType {\n+\n+        private final Analyzer indexAnalyzer;\n+        private final TextFieldType textFieldType;\n+\n+        public MatchOnlyTextFieldType(String name, boolean stored, TextSearchInfo tsi, Analyzer indexAnalyzer, Map<String, String> meta) {\n+            super(name, true, stored, false, tsi, meta);\n+            this.indexAnalyzer = Objects.requireNonNull(indexAnalyzer);\n+            this.textFieldType = new TextFieldType(name);\n+        }\n+\n+        public MatchOnlyTextFieldType(String name, boolean stored, Map<String, String> meta) {\n+            super(\n+                name,\n+                true,\n+                stored,\n+                false,\n+                new TextSearchInfo(Defaults.FIELD_TYPE, null, Lucene.STANDARD_ANALYZER, Lucene.STANDARD_ANALYZER),\n+                meta\n+            );\n+            this.indexAnalyzer = Lucene.STANDARD_ANALYZER;\n+            this.textFieldType = new TextFieldType(name);\n+        }\n+\n+        public MatchOnlyTextFieldType(String name) {\n+            this(\n+                name,\n+                false,\n+                new TextSearchInfo(Defaults.FIELD_TYPE, null, Lucene.STANDARD_ANALYZER, Lucene.STANDARD_ANALYZER),\n+                Lucene.STANDARD_ANALYZER,\n+                Collections.emptyMap()\n+            );\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public String familyTypeName() {\n+            return TextFieldMapper.CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public ValueFetcher valueFetcher(QueryShardContext context, String format) {\n+            return SourceValueFetcher.toString(name(), context, format);\n+        }\n+\n+        private Query toQuery(Query query, QueryShardContext queryShardContext) {\n+            Function<LeafReaderContext, CheckedIntFunction<List<Object>, IOException>> valueFetcherProvider = context -> {\n+                SourceLookup sourceLookup = new SourceLookup();\n+                ValueFetcher valueFetcher = valueFetcher(queryShardContext, null);\n+                valueFetcher.setNextReader(context);\n+                return docID -> {\n+                    try {\n+                        sourceLookup.setSegmentAndDocument(context, docID);\n+                        return valueFetcher.fetchValues(sourceLookup);\n+                    } catch (IOException e) {\n+                        throw new UncheckedIOException(e);\n+                    }\n+                };\n+            };\n+            return new ConstantScoreQuery(new SourceConfirmedTextQuery(query, valueFetcherProvider, indexAnalyzer));\n+        }\n+\n+        @Override\n+        public Query termQuery(Object value, QueryShardContext context) {\n+            // Disable scoring\n+            return new ConstantScoreQuery(super.termQuery(value, context));\n+        }\n+\n+        @Override\n+        public Query phraseQuery(TokenStream stream, int slop, boolean enablePosIncrements, QueryShardContext queryShardContext)\n+            throws IOException {\n+            final Query query = textFieldType.phraseQuery(stream, slop, enablePosIncrements, queryShardContext);\n+            return toQuery(query, queryShardContext);\n+        }\n+\n+        @Override\n+        public Query multiPhraseQuery(TokenStream stream, int slop, boolean enablePositionIncrements, QueryShardContext queryShardContext)\n+            throws IOException {\n+            final Query query = textFieldType.multiPhraseQuery(stream, slop, enablePositionIncrements, queryShardContext);\n+            return toQuery(query, queryShardContext);\n+        }\n+\n+        @Override\n+        public Query phrasePrefixQuery(TokenStream stream, int slop, int maxExpansions, QueryShardContext queryShardContext)\n+            throws IOException {\n+            final Query query = textFieldType.phrasePrefixQuery(stream, slop, maxExpansions, queryShardContext);\n+            return toQuery(query, queryShardContext);\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName, Supplier<SearchLookup> searchLookup) {\n+            throw new IllegalArgumentException(CONTENT_TYPE + \" fields do not support sorting and aggregations\");\n+        }\n+\n+    }\n+\n+    private final Builder builder;\n+    private final FieldType fieldType;\n+\n+    private MatchOnlyTextFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MatchOnlyTextFieldType mappedFieldType,\n+        NamedAnalyzer indexAnalyzer,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        Builder builder\n+    ) {\n+        super(simpleName, mappedFieldType, indexAnalyzer, multiFields, copyTo);\n+        assert mappedFieldType.getTextSearchInfo().isTokenized();\n+        assert mappedFieldType.hasDocValues() == false;\n+        this.fieldType = fieldType;\n+        this.builder = builder;\n+    }\n+\n+    @Override\n+    public FieldMapper.Builder getMergeBuilder() {\n+        return new Builder(simpleName(), builder.indexCreatedVersion, builder.analyzers.indexAnalyzers).init(this);\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        final String value;\n+        if (context.externalValueSet()) {\n+            value = context.externalValue().toString();\n+        } else {\n+            value = context.parser().textOrNull();\n+        }\n+\n+        if (value == null) {\n+            return;\n+        }\n+\n+        Field field = new Field(fieldType().name(), value, fieldType);\n+        context.doc().add(field);\n+        createFieldNamesField(context);\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    public MatchOnlyTextFieldType fieldType() {\n+        return (MatchOnlyTextFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected void doXContentBody(XContentBuilder builder, boolean includeDefaults, Params params) throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bfd3877c9e887c108c3286f24ba21a1a9a0d443"}, "originalPosition": 291}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIyMjA4Mw==", "bodyText": "Sneaky, I like it.  MemoryIndex always runs with ScoreMode.COMPLETE so it might be possible to speed things up a bit by calling createIndexSearcher and running against that with ScoreMode.COMPLETE_NO_SCORES.  Another trick that highlighters use when re-analyzing source is to add a FilteringTokenFilter to the MemoryIndex's analyzer that drops all tokens not included in the query - you need to be careful to catch Automata-based queries but QueryVisitor makes it not too difficult to implement.", "url": "https://github.com/elastic/elasticsearch/pull/66172#discussion_r540222083", "createdAt": "2020-12-10T14:41:10Z", "author": {"login": "romseygeek"}, "path": "x-pack/plugin/mapper-match-only-text/src/main/java/org/elasticsearch/xpack/matchonlytext/query/SourceConfirmedTextQuery.java", "diffHunk": "@@ -0,0 +1,345 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.matchonlytext.query;\n+\n+import org.apache.lucene.analysis.Analyzer;\n+import org.apache.lucene.index.FieldInvertState;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.TermStates;\n+import org.apache.lucene.index.memory.MemoryIndex;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.BoostQuery;\n+import org.apache.lucene.search.CollectionStatistics;\n+import org.apache.lucene.search.ConstantScoreQuery;\n+import org.apache.lucene.search.DocIdSetIterator;\n+import org.apache.lucene.search.Explanation;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.LeafSimScorer;\n+import org.apache.lucene.search.MatchAllDocsQuery;\n+import org.apache.lucene.search.MatchNoDocsQuery;\n+import org.apache.lucene.search.MultiPhraseQuery;\n+import org.apache.lucene.search.PhraseQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.QueryVisitor;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.search.Scorer;\n+import org.apache.lucene.search.TermQuery;\n+import org.apache.lucene.search.TermStatistics;\n+import org.apache.lucene.search.TwoPhaseIterator;\n+import org.apache.lucene.search.Weight;\n+import org.apache.lucene.search.similarities.Similarity;\n+import org.apache.lucene.search.similarities.Similarity.SimScorer;\n+import org.elasticsearch.common.CheckedIntFunction;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+/**\n+ * A variant of {@link TermQuery}, {@link PhraseQuery}, {@link MultiPhraseQuery}\n+ * and span queries that uses postings for its approximation, but falls back to\n+ * stored fields or _source whenever term frequencies or positions are needed.\n+ * This query matches and scores the same way as the wrapped query.\n+ */\n+public final class SourceConfirmedTextQuery extends Query {\n+\n+    /**\n+     * Create an approximation for the given query. The returned approximation\n+     * should match a superset of the matches of the provided query.\n+     */\n+    public static Query approximate(Query query) {\n+        if (query instanceof TermQuery) {\n+            return query;\n+        } else if (query instanceof PhraseQuery) {\n+            return approximate((PhraseQuery) query);\n+        } else if (query instanceof MultiPhraseQuery) {\n+            return approximate((MultiPhraseQuery) query);\n+        } else {\n+            // TODO: spans and intervals\n+            return new MatchAllDocsQuery();\n+        }\n+    }\n+\n+    private static Query approximate(PhraseQuery query) {\n+        BooleanQuery.Builder approximation = new BooleanQuery.Builder();\n+        for (Term term : query.getTerms()) {\n+            approximation.add(new TermQuery(term), Occur.FILTER);\n+        }\n+        return approximation.build();\n+    }\n+\n+    private static Query approximate(MultiPhraseQuery query) {\n+        BooleanQuery.Builder approximation = new BooleanQuery.Builder();\n+        for (Term[] termArray : query.getTermArrays()) {\n+            BooleanQuery.Builder approximationClause = new BooleanQuery.Builder();\n+            for (Term term : termArray) {\n+                approximationClause.add(new TermQuery(term), Occur.SHOULD);\n+            }\n+            approximation.add(approximationClause.build(), Occur.FILTER);\n+        }\n+        return approximation.build();\n+    }\n+\n+    /**\n+     * Similarity that produces the frequency as a score.\n+     */\n+    private static final Similarity FREQ_SIMILARITY = new Similarity() {\n+\n+        @Override\n+        public long computeNorm(FieldInvertState state) {\n+            return 1L;\n+        }\n+\n+        public SimScorer scorer(float boost, CollectionStatistics collectionStats, TermStatistics... termStats) {\n+            return new SimScorer() {\n+                @Override\n+                public float score(float freq, long norm) {\n+                    return freq;\n+                }\n+            };\n+        }\n+    };\n+\n+    private final Query in;\n+    private final Function<LeafReaderContext, CheckedIntFunction<List<Object>, IOException>> valueFetcherProvider;\n+    private final Analyzer indexAnalyzer;\n+\n+    public SourceConfirmedTextQuery(\n+        Query in,\n+        Function<LeafReaderContext, CheckedIntFunction<List<Object>, IOException>> valueFetcherProvider,\n+        Analyzer indexAnalyzer\n+    ) {\n+        this.in = in;\n+        this.valueFetcherProvider = valueFetcherProvider;\n+        this.indexAnalyzer = indexAnalyzer;\n+    }\n+\n+    @Override\n+    public String toString(String field) {\n+        return in.toString(field);\n+    }\n+\n+    @Override\n+    public boolean equals(Object obj) {\n+        if (obj == null || obj.getClass() != getClass()) {\n+            return false;\n+        }\n+        SourceConfirmedTextQuery that = (SourceConfirmedTextQuery) obj;\n+        return Objects.equals(in, that.in)\n+            && Objects.equals(valueFetcherProvider, that.valueFetcherProvider)\n+            && Objects.equals(indexAnalyzer, that.indexAnalyzer);\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return 31 * Objects.hash(in, valueFetcherProvider, indexAnalyzer) + classHash();\n+    }\n+\n+    @Override\n+    public Query rewrite(IndexReader reader) throws IOException {\n+        Query inRewritten = in.rewrite(reader);\n+        if (inRewritten != in) {\n+            return new SourceConfirmedTextQuery(inRewritten, valueFetcherProvider, indexAnalyzer);\n+        } else if (in instanceof ConstantScoreQuery) {\n+            Query sub = ((ConstantScoreQuery) in).getQuery();\n+            return new ConstantScoreQuery(new SourceConfirmedTextQuery(sub, valueFetcherProvider, indexAnalyzer));\n+        } else if (in instanceof BoostQuery) {\n+            Query sub = ((BoostQuery) in).getQuery();\n+            float boost = ((BoostQuery) in).getBoost();\n+            return new BoostQuery(new SourceConfirmedTextQuery(sub, valueFetcherProvider, indexAnalyzer), boost);\n+        } else if (in instanceof MatchNoDocsQuery) {\n+            return in; // e.g. empty phrase query\n+        }\n+        return super.rewrite(reader);\n+    }\n+\n+    @Override\n+    public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n+        if (scoreMode.needsScores() == false && in instanceof TermQuery) {\n+            // No need to ever look at the _source for non-scoring term queries\n+            return in.createWeight(searcher, scoreMode, boost);\n+        }\n+\n+        final Set<Term> terms = new HashSet<>();\n+        in.visit(QueryVisitor.termCollector(terms));\n+        if (terms.isEmpty()) {\n+            throw new IllegalStateException(\"Query \" + in + \" doesn't have any term\");\n+        }\n+        final String field = terms.iterator().next().field();\n+        final Map<Term, TermStates> termStates = new HashMap<>();\n+        final List<TermStatistics> termStats = new ArrayList<>();\n+        for (Term term : terms) {\n+            TermStates ts = termStates.computeIfAbsent(term, t -> {\n+                try {\n+                    return TermStates.build(searcher.getTopReaderContext(), t, scoreMode.needsScores());\n+                } catch (IOException e) {\n+                    throw new UncheckedIOException(e);\n+                }\n+            });\n+            if (scoreMode.needsScores()) {\n+                if (ts.docFreq() > 0) {\n+                    termStats.add(searcher.termStatistics(term, ts.docFreq(), ts.totalTermFreq()));\n+                }\n+            } else {\n+                termStats.add(new TermStatistics(term.bytes(), 1, 1L));\n+            }\n+        }\n+        final SimScorer simScorer = searcher.getSimilarity()\n+            .scorer(boost, searcher.collectionStatistics(field), termStats.toArray(TermStatistics[]::new));\n+        final Weight approximationWeight = searcher.createWeight(approximate(in), ScoreMode.COMPLETE_NO_SCORES, 1f);\n+\n+        return new Weight(this) {\n+\n+            @Override\n+            public boolean isCacheable(LeafReaderContext ctx) {\n+                // Don't cache queries that may perform linear scans\n+                return false;\n+            }\n+\n+            @Override\n+            public void extractTerms(Set<Term> termSet) {\n+                termSet.addAll(terms);\n+            }\n+\n+            @Override\n+            public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n+                RuntimePhraseScorer scorer = scorer(context);\n+                if (scorer == null) {\n+                    return Explanation.noMatch(\"No matching phrase\");\n+                }\n+                final TwoPhaseIterator twoPhase = scorer.twoPhaseIterator();\n+                if (twoPhase.approximation().advance(doc) != doc || scorer.twoPhaseIterator().matches() == false) {\n+                    return Explanation.noMatch(\"No matching phrase\");\n+                }\n+                float phraseFreq = scorer.freq();\n+                Explanation freqExplanation = Explanation.match(phraseFreq, \"phraseFreq=\" + phraseFreq);\n+                final LeafSimScorer leafSimScorer = new LeafSimScorer(simScorer, context.reader(), field, scoreMode.needsScores());\n+                Explanation scoreExplanation = leafSimScorer.explain(doc, freqExplanation);\n+                return Explanation.match(\n+                    scoreExplanation.getValue(),\n+                    \"weight(\" + getQuery() + \" in \" + doc + \") [\" + searcher.getSimilarity().getClass().getSimpleName() + \"], result of:\",\n+                    scoreExplanation\n+                );\n+            }\n+\n+            @Override\n+            public RuntimePhraseScorer scorer(LeafReaderContext context) throws IOException {\n+                final Scorer approximationScorer = approximationWeight.scorer(context);\n+                if (approximationScorer == null) {\n+                    return null;\n+                }\n+                final DocIdSetIterator approximation = approximationScorer.iterator();\n+                final LeafSimScorer leafSimScorer = new LeafSimScorer(simScorer, context.reader(), field, scoreMode.needsScores());\n+                final CheckedIntFunction<List<Object>, IOException> valueFetcher = valueFetcherProvider.apply(context);\n+                return new RuntimePhraseScorer(this, approximation, leafSimScorer, valueFetcher, field, in);\n+            }\n+\n+        };\n+    }\n+\n+    private class RuntimePhraseScorer extends Scorer {\n+\n+        private final LeafSimScorer scorer;\n+        private final CheckedIntFunction<List<Object>, IOException> valueFetcher;\n+        private final String field;\n+        private final Query query;\n+        private final TwoPhaseIterator twoPhase;\n+\n+        private int doc = -1;\n+        private float freq;\n+\n+        private RuntimePhraseScorer(\n+            Weight weight,\n+            DocIdSetIterator approximation,\n+            LeafSimScorer scorer,\n+            CheckedIntFunction<List<Object>, IOException> valueFetcher,\n+            String field,\n+            Query query\n+        ) {\n+            super(weight);\n+            this.scorer = scorer;\n+            this.valueFetcher = valueFetcher;\n+            this.field = field;\n+            this.query = query;\n+            twoPhase = new TwoPhaseIterator(approximation) {\n+\n+                @Override\n+                public boolean matches() throws IOException {\n+                    return freq() > 0;\n+                }\n+\n+                @Override\n+                public float matchCost() {\n+                    // TODO what is a right value?\n+                    // Defaults to a high-ish value so that it likely runs last.\n+                    return 10_000f;\n+                }\n+\n+            };\n+        }\n+\n+        @Override\n+        public DocIdSetIterator iterator() {\n+            return TwoPhaseIterator.asDocIdSetIterator(twoPhaseIterator());\n+        }\n+\n+        @Override\n+        public TwoPhaseIterator twoPhaseIterator() {\n+            return twoPhase;\n+        }\n+\n+        @Override\n+        public float getMaxScore(int upTo) throws IOException {\n+            return scorer.getSimScorer().score(Float.MAX_VALUE, 1L);\n+        }\n+\n+        @Override\n+        public float score() throws IOException {\n+            return scorer.score(docID(), freq());\n+        }\n+\n+        @Override\n+        public int docID() {\n+            return twoPhase.approximation().docID();\n+        }\n+\n+        private float freq() throws IOException {\n+            if (doc != docID()) {\n+                doc = docID();\n+                freq = computeFreq();\n+            }\n+            return freq;\n+        }\n+\n+        private float computeFreq() throws IOException {\n+            MemoryIndex index = new MemoryIndex();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bfd3877c9e887c108c3286f24ba21a1a9a0d443"}, "originalPosition": 329}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIyMzUyNg==", "bodyText": "Does this work, given the TODO in SourceConfirmedTextQuery implementation above?", "url": "https://github.com/elastic/elasticsearch/pull/66172#discussion_r540223526", "createdAt": "2020-12-10T14:42:56Z", "author": {"login": "romseygeek"}, "path": "x-pack/plugin/mapper-match-only-text/src/test/java/org/elasticsearch/xpack/matchonlytext/query/SourceConfirmedTextQueryTests.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.matchonlytext.query;\n+\n+import org.apache.lucene.document.Document;\n+import org.apache.lucene.document.Field.Store;\n+import org.apache.lucene.document.TextField;\n+import org.apache.lucene.index.DirectoryReader;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.IndexWriter;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.CheckHits;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.MultiPhraseQuery;\n+import org.apache.lucene.search.PhraseQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.ScoreDoc;\n+import org.apache.lucene.search.TermQuery;\n+import org.apache.lucene.search.spans.SpanNearQuery;\n+import org.apache.lucene.search.spans.SpanQuery;\n+import org.apache.lucene.search.spans.SpanTermQuery;\n+import org.apache.lucene.store.Directory;\n+import org.elasticsearch.common.CheckedIntFunction;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.test.ESTestCase;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.function.Function;\n+\n+public class SourceConfirmedTextQueryTests extends ESTestCase {\n+\n+    private static final Function<LeafReaderContext, CheckedIntFunction<List<Object>, IOException>> SOURCE_FETCHER_PROVIDER = context -> {\n+        return docID -> Collections.<Object>singletonList(context.reader().document(docID).get(\"body\"));\n+    };\n+\n+    public void testTerm() throws Exception {\n+        try (Directory dir = newDirectory(); IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(Lucene.STANDARD_ANALYZER))) {\n+\n+            Document doc = new Document();\n+            doc.add(new TextField(\"body\", \"a b c b a b c\", Store.YES));\n+            w.addDocument(doc);\n+\n+            doc = new Document();\n+            doc.add(new TextField(\"body\", \"b d\", Store.YES));\n+            w.addDocument(doc);\n+\n+            doc = new Document();\n+            doc.add(new TextField(\"body\", \"b c d\", Store.YES));\n+            w.addDocument(doc);\n+\n+            try (IndexReader reader = DirectoryReader.open(w)) {\n+                IndexSearcher searcher = new IndexSearcher(reader);\n+\n+                TermQuery query = new TermQuery(new Term(\"body\", \"c\"));\n+                Query sourceConfirmedPhraseQuery = new SourceConfirmedTextQuery(query, SOURCE_FETCHER_PROVIDER, Lucene.STANDARD_ANALYZER);\n+\n+                assertEquals(searcher.count(query), searcher.count(sourceConfirmedPhraseQuery));\n+                ScoreDoc[] phraseHits = searcher.search(query, 10).scoreDocs;\n+                assertEquals(2, phraseHits.length);\n+                ScoreDoc[] sourceConfirmedHits = searcher.search(sourceConfirmedPhraseQuery, 10).scoreDocs;\n+                CheckHits.checkEqual(query, phraseHits, sourceConfirmedHits);\n+                CheckHits.checkExplanations(sourceConfirmedPhraseQuery, \"body\", searcher);\n+\n+                // Term query with missing term\n+                query = new TermQuery(new Term(\"body\", \"e\"));\n+                sourceConfirmedPhraseQuery = new SourceConfirmedTextQuery(query, SOURCE_FETCHER_PROVIDER, Lucene.STANDARD_ANALYZER);\n+                assertEquals(searcher.count(query), searcher.count(sourceConfirmedPhraseQuery));\n+                assertArrayEquals(new ScoreDoc[0], searcher.search(sourceConfirmedPhraseQuery, 10).scoreDocs);\n+            }\n+        }\n+    }\n+\n+    public void testPhrase() throws Exception {\n+        try (Directory dir = newDirectory(); IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(Lucene.STANDARD_ANALYZER))) {\n+\n+            Document doc = new Document();\n+            doc.add(new TextField(\"body\", \"a b c b a b c\", Store.YES));\n+            w.addDocument(doc);\n+\n+            doc = new Document();\n+            doc.add(new TextField(\"body\", \"b d\", Store.YES));\n+            w.addDocument(doc);\n+\n+            doc = new Document();\n+            doc.add(new TextField(\"body\", \"b c d\", Store.YES));\n+            w.addDocument(doc);\n+\n+            try (IndexReader reader = DirectoryReader.open(w)) {\n+                IndexSearcher searcher = new IndexSearcher(reader);\n+\n+                PhraseQuery query = new PhraseQuery(\"body\", \"b\", \"c\");\n+                Query sourceConfirmedPhraseQuery = new SourceConfirmedTextQuery(query, SOURCE_FETCHER_PROVIDER, Lucene.STANDARD_ANALYZER);\n+\n+                assertEquals(searcher.count(query), searcher.count(sourceConfirmedPhraseQuery));\n+                ScoreDoc[] phraseHits = searcher.search(query, 10).scoreDocs;\n+                assertEquals(2, phraseHits.length);\n+                ScoreDoc[] sourceConfirmedHits = searcher.search(sourceConfirmedPhraseQuery, 10).scoreDocs;\n+                CheckHits.checkEqual(query, phraseHits, sourceConfirmedHits);\n+                CheckHits.checkExplanations(sourceConfirmedPhraseQuery, \"body\", searcher);\n+\n+                // Sloppy phrase query\n+                query = new PhraseQuery(1, \"body\", \"b\", \"d\");\n+                sourceConfirmedPhraseQuery = new SourceConfirmedTextQuery(query, SOURCE_FETCHER_PROVIDER, Lucene.STANDARD_ANALYZER);\n+                assertEquals(searcher.count(query), searcher.count(sourceConfirmedPhraseQuery));\n+                phraseHits = searcher.search(query, 10).scoreDocs;\n+                assertEquals(2, phraseHits.length);\n+                sourceConfirmedHits = searcher.search(sourceConfirmedPhraseQuery, 10).scoreDocs;\n+                CheckHits.checkEqual(query, phraseHits, sourceConfirmedHits);\n+                CheckHits.checkExplanations(sourceConfirmedPhraseQuery, \"body\", searcher);\n+\n+                // Phrase query with no matches\n+                query = new PhraseQuery(\"body\", \"d\", \"c\");\n+                sourceConfirmedPhraseQuery = new SourceConfirmedTextQuery(query, SOURCE_FETCHER_PROVIDER, Lucene.STANDARD_ANALYZER);\n+                assertEquals(searcher.count(query), searcher.count(sourceConfirmedPhraseQuery));\n+                assertArrayEquals(new ScoreDoc[0], searcher.search(sourceConfirmedPhraseQuery, 10).scoreDocs);\n+\n+                // Phrase query with one missing term\n+                query = new PhraseQuery(\"body\", \"b\", \"e\");\n+                sourceConfirmedPhraseQuery = new SourceConfirmedTextQuery(query, SOURCE_FETCHER_PROVIDER, Lucene.STANDARD_ANALYZER);\n+                assertEquals(searcher.count(query), searcher.count(sourceConfirmedPhraseQuery));\n+                assertArrayEquals(new ScoreDoc[0], searcher.search(sourceConfirmedPhraseQuery, 10).scoreDocs);\n+            }\n+        }\n+    }\n+\n+    public void testMultiPhrase() throws Exception {\n+        try (Directory dir = newDirectory(); IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(Lucene.STANDARD_ANALYZER))) {\n+\n+            Document doc = new Document();\n+            doc.add(new TextField(\"body\", \"a b c b a b c\", Store.YES));\n+            w.addDocument(doc);\n+\n+            doc = new Document();\n+            doc.add(new TextField(\"body\", \"b d\", Store.YES));\n+            w.addDocument(doc);\n+\n+            doc = new Document();\n+            doc.add(new TextField(\"body\", \"b c d\", Store.YES));\n+            w.addDocument(doc);\n+\n+            try (IndexReader reader = DirectoryReader.open(w)) {\n+                IndexSearcher searcher = new IndexSearcher(reader);\n+\n+                MultiPhraseQuery query = new MultiPhraseQuery.Builder().add(new Term[] { new Term(\"body\", \"a\"), new Term(\"body\", \"b\") }, 0)\n+                    .add(new Term[] { new Term(\"body\", \"c\") }, 1)\n+                    .build();\n+\n+                Query sourceConfirmedPhraseQuery = new SourceConfirmedTextQuery(query, SOURCE_FETCHER_PROVIDER, Lucene.STANDARD_ANALYZER);\n+\n+                assertEquals(searcher.count(query), searcher.count(sourceConfirmedPhraseQuery));\n+\n+                ScoreDoc[] phraseHits = searcher.search(query, 10).scoreDocs;\n+                assertEquals(2, phraseHits.length);\n+                ScoreDoc[] sourceConfirmedHits = searcher.search(sourceConfirmedPhraseQuery, 10).scoreDocs;\n+                CheckHits.checkEqual(query, phraseHits, sourceConfirmedHits);\n+                CheckHits.checkExplanations(sourceConfirmedPhraseQuery, \"body\", searcher);\n+\n+                // Sloppy multi phrase query\n+                query = new MultiPhraseQuery.Builder().add(new Term[] { new Term(\"body\", \"a\"), new Term(\"body\", \"b\") }, 0)\n+                    .add(new Term[] { new Term(\"body\", \"d\") }, 1)\n+                    .setSlop(1)\n+                    .build();\n+                sourceConfirmedPhraseQuery = new SourceConfirmedTextQuery(query, SOURCE_FETCHER_PROVIDER, Lucene.STANDARD_ANALYZER);\n+                assertEquals(searcher.count(query), searcher.count(sourceConfirmedPhraseQuery));\n+                phraseHits = searcher.search(query, 10).scoreDocs;\n+                assertEquals(2, phraseHits.length);\n+                sourceConfirmedHits = searcher.search(sourceConfirmedPhraseQuery, 10).scoreDocs;\n+                CheckHits.checkEqual(query, phraseHits, sourceConfirmedHits);\n+                CheckHits.checkExplanations(sourceConfirmedPhraseQuery, \"body\", searcher);\n+\n+                // Multi phrase query with no matches\n+                query = new MultiPhraseQuery.Builder().add(new Term[] { new Term(\"body\", \"d\"), new Term(\"body\", \"c\") }, 0)\n+                    .add(new Term[] { new Term(\"body\", \"a\") }, 1)\n+                    .build();\n+                sourceConfirmedPhraseQuery = new SourceConfirmedTextQuery(query, SOURCE_FETCHER_PROVIDER, Lucene.STANDARD_ANALYZER);\n+                assertEquals(searcher.count(query), searcher.count(sourceConfirmedPhraseQuery));\n+                assertArrayEquals(new ScoreDoc[0], searcher.search(sourceConfirmedPhraseQuery, 10).scoreDocs);\n+\n+                // Multi phrase query with one missing term\n+                query = new MultiPhraseQuery.Builder().add(new Term[] { new Term(\"body\", \"d\"), new Term(\"body\", \"c\") }, 0)\n+                    .add(new Term[] { new Term(\"body\", \"e\") }, 1)\n+                    .build();\n+                sourceConfirmedPhraseQuery = new SourceConfirmedTextQuery(query, SOURCE_FETCHER_PROVIDER, Lucene.STANDARD_ANALYZER);\n+                assertEquals(searcher.count(query), searcher.count(sourceConfirmedPhraseQuery));\n+                assertArrayEquals(new ScoreDoc[0], searcher.search(sourceConfirmedPhraseQuery, 10).scoreDocs);\n+            }\n+        }\n+    }\n+\n+    public void testSpanNear() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bfd3877c9e887c108c3286f24ba21a1a9a0d443"}, "originalPosition": 199}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIyNTc1OQ==", "bodyText": "maybe assert that this is a cached tokenstream?", "url": "https://github.com/elastic/elasticsearch/pull/66172#discussion_r540225759", "createdAt": "2020-12-10T14:45:43Z", "author": {"login": "romseygeek"}, "path": "server/src/main/java/org/elasticsearch/index/mapper/TextFieldMapper.java", "diffHunk": "@@ -741,8 +750,21 @@ public Query multiPhraseQuery(TokenStream stream, int slop, boolean enablePositi\n             return createPhraseQuery(stream, field, slop, enablePositionIncrements);\n         }\n \n+        private int countTokens(TokenStream ts) throws IOException {\n+            ts.reset();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bfd3877c9e887c108c3286f24ba21a1a9a0d443"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIyNjQyNg==", "bodyText": "I think you can avoid changing this, the concerns about BWC only apply to existing mappings and won't be a problem for entirely new field mappers.", "url": "https://github.com/elastic/elasticsearch/pull/66172#discussion_r540226426", "createdAt": "2020-12-10T14:46:35Z", "author": {"login": "romseygeek"}, "path": "server/src/main/java/org/elasticsearch/index/mapper/FieldMapper.java", "diffHunk": "@@ -670,7 +670,7 @@ private void merge(FieldMapper toMerge, Conflicts conflicts) {\n             }\n         }\n \n-        protected void toXContent(XContentBuilder builder, boolean includeDefaults) throws IOException {\n+        public void toXContent(XContentBuilder builder, boolean includeDefaults) throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bfd3877c9e887c108c3286f24ba21a1a9a0d443"}, "originalPosition": 5}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6b0cb2107d2518b7af18ee5993240253657dc844", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/6b0cb2107d2518b7af18ee5993240253657dc844", "committedDate": "2020-12-10T15:17:29Z", "message": "iter"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUyNjQxNDUy", "url": "https://github.com/elastic/elasticsearch/pull/66172#pullrequestreview-552641452", "createdAt": "2020-12-15T16:29:30Z", "commit": {"oid": "6b0cb2107d2518b7af18ee5993240253657dc844"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUyNzQ0NTI2", "url": "https://github.com/elastic/elasticsearch/pull/66172#pullrequestreview-552744526", "createdAt": "2020-12-15T18:24:10Z", "commit": {"oid": "6b0cb2107d2518b7af18ee5993240253657dc844"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQxODoyNDoxMVrOIGZk3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQxODoyNDoxMVrOIGZk3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzU4MTQwNA==", "bodyText": "Should we use the SourceLookup from QueryShardContext? I guess the _source unlikely to be shared but we've been working on consolidating all document access through QueryShardContext#searchLookup (#66256).", "url": "https://github.com/elastic/elasticsearch/pull/66172#discussion_r543581404", "createdAt": "2020-12-15T18:24:11Z", "author": {"login": "jtibshirani"}, "path": "x-pack/plugin/mapper-match-only-text/src/main/java/org/elasticsearch/xpack/matchonlytext/mapper/MatchOnlyTextFieldMapper.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.matchonlytext.mapper;\n+\n+import org.apache.lucene.analysis.Analyzer;\n+import org.apache.lucene.analysis.TokenStream;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.ConstantScoreQuery;\n+import org.apache.lucene.search.Query;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.common.CheckedIntFunction;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.index.analysis.IndexAnalyzers;\n+import org.elasticsearch.index.analysis.NamedAnalyzer;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.mapper.ContentPath;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.StringFieldType;\n+import org.elasticsearch.index.mapper.TextFieldMapper;\n+import org.elasticsearch.index.mapper.TextFieldMapper.TextFieldType;\n+import org.elasticsearch.index.mapper.TextParams;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.search.lookup.SourceLookup;\n+import org.elasticsearch.xpack.matchonlytext.query.SourceConfirmedTextQuery;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+/**\n+ * A {@link FieldMapper} for full-text fields that only indexes\n+ * {@link IndexOptions#DOCS} and runs positional queries by looking at the\n+ * _source.\n+ */\n+public class MatchOnlyTextFieldMapper extends FieldMapper {\n+\n+    public static final String CONTENT_TYPE = \"match_only_text\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(true);\n+            FIELD_TYPE.setStored(false);\n+            FIELD_TYPE.setStoreTermVectors(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+    }\n+\n+    private static Builder builder(FieldMapper in) {\n+        return ((MatchOnlyTextFieldMapper) in).builder;\n+    }\n+\n+    public static class Builder extends FieldMapper.Builder {\n+\n+        private final Version indexCreatedVersion;\n+\n+        private final Parameter<Boolean> store = Parameter.storeParam(m -> builder(m).store.getValue(), false);\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        private final TextParams.Analyzers analyzers;\n+\n+        public Builder(String name, IndexAnalyzers indexAnalyzers) {\n+            this(name, Version.CURRENT, indexAnalyzers);\n+        }\n+\n+        public Builder(String name, Version indexCreatedVersion, IndexAnalyzers indexAnalyzers) {\n+            super(name);\n+            this.indexCreatedVersion = indexCreatedVersion;\n+            this.analyzers = new TextParams.Analyzers(indexAnalyzers, m -> builder(m).analyzers);\n+        }\n+\n+        public Builder store(boolean store) {\n+            this.store.setValue(store);\n+            return this;\n+        }\n+\n+        public Builder addMultiField(FieldMapper.Builder builder) {\n+            this.multiFieldsBuilder.add(builder);\n+            return this;\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return Arrays.asList(store, analyzers.indexAnalyzer, analyzers.searchAnalyzer, analyzers.searchQuoteAnalyzer, meta);\n+        }\n+\n+        private MatchOnlyTextFieldType buildFieldType(FieldType fieldType, ContentPath contentPath) {\n+            NamedAnalyzer searchAnalyzer = analyzers.getSearchAnalyzer();\n+            NamedAnalyzer searchQuoteAnalyzer = analyzers.getSearchQuoteAnalyzer();\n+            NamedAnalyzer indexAnalyzer = analyzers.getIndexAnalyzer();\n+            TextSearchInfo tsi = new TextSearchInfo(fieldType, null, searchAnalyzer, searchQuoteAnalyzer);\n+            MatchOnlyTextFieldType ft = new MatchOnlyTextFieldType(\n+                buildFullName(contentPath),\n+                store.getValue(),\n+                tsi,\n+                indexAnalyzer,\n+                meta.getValue()\n+            );\n+            return ft;\n+        }\n+\n+        @Override\n+        public MatchOnlyTextFieldMapper build(ContentPath contentPath) {\n+            FieldType fieldType = new FieldType(Defaults.FIELD_TYPE);\n+            fieldType.setStored(store.get());\n+            MatchOnlyTextFieldType tft = buildFieldType(fieldType, contentPath);\n+            MultiFields multiFields = multiFieldsBuilder.build(this, contentPath);\n+            return new MatchOnlyTextFieldMapper(name, fieldType, tft, analyzers.getIndexAnalyzer(), multiFields, copyTo.build(), this);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n, c.indexVersionCreated(), c.getIndexAnalyzers()));\n+\n+    public static class MatchOnlyTextFieldType extends StringFieldType {\n+\n+        private final Analyzer indexAnalyzer;\n+        private final TextFieldType textFieldType;\n+\n+        public MatchOnlyTextFieldType(String name, boolean stored, TextSearchInfo tsi, Analyzer indexAnalyzer, Map<String, String> meta) {\n+            super(name, true, stored, false, tsi, meta);\n+            this.indexAnalyzer = Objects.requireNonNull(indexAnalyzer);\n+            this.textFieldType = new TextFieldType(name);\n+        }\n+\n+        public MatchOnlyTextFieldType(String name, boolean stored, Map<String, String> meta) {\n+            super(\n+                name,\n+                true,\n+                stored,\n+                false,\n+                new TextSearchInfo(Defaults.FIELD_TYPE, null, Lucene.STANDARD_ANALYZER, Lucene.STANDARD_ANALYZER),\n+                meta\n+            );\n+            this.indexAnalyzer = Lucene.STANDARD_ANALYZER;\n+            this.textFieldType = new TextFieldType(name);\n+        }\n+\n+        public MatchOnlyTextFieldType(String name) {\n+            this(\n+                name,\n+                false,\n+                new TextSearchInfo(Defaults.FIELD_TYPE, null, Lucene.STANDARD_ANALYZER, Lucene.STANDARD_ANALYZER),\n+                Lucene.STANDARD_ANALYZER,\n+                Collections.emptyMap()\n+            );\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public String familyTypeName() {\n+            return TextFieldMapper.CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public ValueFetcher valueFetcher(QueryShardContext context, String format) {\n+            return SourceValueFetcher.toString(name(), context, format);\n+        }\n+\n+        private Query toQuery(Query query, QueryShardContext queryShardContext) {\n+            Function<LeafReaderContext, CheckedIntFunction<List<Object>, IOException>> valueFetcherProvider = context -> {\n+                SourceLookup sourceLookup = new SourceLookup();\n+                ValueFetcher valueFetcher = valueFetcher(queryShardContext, null);\n+                valueFetcher.setNextReader(context);\n+                return docID -> {\n+                    try {\n+                        sourceLookup.setSegmentAndDocument(context, docID);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0cb2107d2518b7af18ee5993240253657dc844"}, "originalPosition": 193}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUzMzA1MTY0", "url": "https://github.com/elastic/elasticsearch/pull/66172#pullrequestreview-553305164", "createdAt": "2020-12-16T02:13:07Z", "commit": {"oid": "6b0cb2107d2518b7af18ee5993240253657dc844"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMjoxMzowOFrOIGoubw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMjoxMzowOFrOIGoubw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzgyOTYxNQ==", "bodyText": "We decided to make a single page for the keyword type family, so that users could easily compare the trade-offs between each type.  It'd be nice to do the same for the new 'text' family'.", "url": "https://github.com/elastic/elasticsearch/pull/66172#discussion_r543829615", "createdAt": "2020-12-16T02:13:08Z", "author": {"login": "jtibshirani"}, "path": "docs/reference/mapping/types.asciidoc", "diffHunk": "@@ -69,6 +69,7 @@ values.\n ==== Text search types\n \n <<text,`text`>>:: Analyzed, unstructured text.\n+<<match-only-text,`match_only_text`>>:: A more space-efficient variant of `text`.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0cb2107d2518b7af18ee5993240253657dc844"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7525e4f5ae712c18afc6c67171cf7fbe100f2b7a", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/7525e4f5ae712c18afc6c67171cf7fbe100f2b7a", "committedDate": "2020-12-16T09:34:34Z", "message": "Merge branch 'master' into feature/source_phrase_queries"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e57699ef719d5797c87590e2887604dbb59f15da", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/e57699ef719d5797c87590e2887604dbb59f15da", "committedDate": "2020-12-16T09:36:30Z", "message": "Use source lookup from the shard context."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9ec31c686df6bfd50284fe166f9e9e6397d4d950", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/9ec31c686df6bfd50284fe166f9e9e6397d4d950", "committedDate": "2020-12-16T09:37:12Z", "message": "Update release version."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7a03a0f974470b7c37038156dd10ef1c59c12f8e", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/7a03a0f974470b7c37038156dd10ef1c59c12f8e", "committedDate": "2020-12-16T11:54:14Z", "message": "Consolidate docs with `text`."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU0MDcyNjYy", "url": "https://github.com/elastic/elasticsearch/pull/66172#pullrequestreview-554072662", "createdAt": "2020-12-16T20:50:04Z", "commit": {"oid": "7a03a0f974470b7c37038156dd10ef1c59c12f8e"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQyMDo1MDowNVrOIHYkXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQyMDo1NToyM1rOIHYwUQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDYxMzQ3MQ==", "bodyText": "If a user disables _source on the field, we still accept positional queries but will just return no results. Maybe we should throw an error instead, as we do when positions are disabled. We could at least just check QueryShardContext#isSourceEnabled to catch cases where source is turned off entirely.", "url": "https://github.com/elastic/elasticsearch/pull/66172#discussion_r544613471", "createdAt": "2020-12-16T20:50:05Z", "author": {"login": "jtibshirani"}, "path": "x-pack/plugin/mapper-match-only-text/src/main/java/org/elasticsearch/xpack/matchonlytext/mapper/MatchOnlyTextFieldMapper.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.matchonlytext.mapper;\n+\n+import org.apache.lucene.analysis.Analyzer;\n+import org.apache.lucene.analysis.TokenStream;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.ConstantScoreQuery;\n+import org.apache.lucene.search.Query;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.common.CheckedIntFunction;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.index.analysis.IndexAnalyzers;\n+import org.elasticsearch.index.analysis.NamedAnalyzer;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.mapper.ContentPath;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.StringFieldType;\n+import org.elasticsearch.index.mapper.TextFieldMapper;\n+import org.elasticsearch.index.mapper.TextFieldMapper.TextFieldType;\n+import org.elasticsearch.index.mapper.TextParams;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.search.lookup.SourceLookup;\n+import org.elasticsearch.xpack.matchonlytext.query.SourceConfirmedTextQuery;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+/**\n+ * A {@link FieldMapper} for full-text fields that only indexes\n+ * {@link IndexOptions#DOCS} and runs positional queries by looking at the\n+ * _source.\n+ */\n+public class MatchOnlyTextFieldMapper extends FieldMapper {\n+\n+    public static final String CONTENT_TYPE = \"match_only_text\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(true);\n+            FIELD_TYPE.setStored(false);\n+            FIELD_TYPE.setStoreTermVectors(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+    }\n+\n+    private static Builder builder(FieldMapper in) {\n+        return ((MatchOnlyTextFieldMapper) in).builder;\n+    }\n+\n+    public static class Builder extends FieldMapper.Builder {\n+\n+        private final Version indexCreatedVersion;\n+\n+        private final Parameter<Boolean> store = Parameter.storeParam(m -> builder(m).store.getValue(), false);\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        private final TextParams.Analyzers analyzers;\n+\n+        public Builder(String name, IndexAnalyzers indexAnalyzers) {\n+            this(name, Version.CURRENT, indexAnalyzers);\n+        }\n+\n+        public Builder(String name, Version indexCreatedVersion, IndexAnalyzers indexAnalyzers) {\n+            super(name);\n+            this.indexCreatedVersion = indexCreatedVersion;\n+            this.analyzers = new TextParams.Analyzers(indexAnalyzers, m -> builder(m).analyzers);\n+        }\n+\n+        public Builder store(boolean store) {\n+            this.store.setValue(store);\n+            return this;\n+        }\n+\n+        public Builder addMultiField(FieldMapper.Builder builder) {\n+            this.multiFieldsBuilder.add(builder);\n+            return this;\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return Arrays.asList(store, analyzers.indexAnalyzer, analyzers.searchAnalyzer, analyzers.searchQuoteAnalyzer, meta);\n+        }\n+\n+        private MatchOnlyTextFieldType buildFieldType(FieldType fieldType, ContentPath contentPath) {\n+            NamedAnalyzer searchAnalyzer = analyzers.getSearchAnalyzer();\n+            NamedAnalyzer searchQuoteAnalyzer = analyzers.getSearchQuoteAnalyzer();\n+            NamedAnalyzer indexAnalyzer = analyzers.getIndexAnalyzer();\n+            TextSearchInfo tsi = new TextSearchInfo(fieldType, null, searchAnalyzer, searchQuoteAnalyzer);\n+            MatchOnlyTextFieldType ft = new MatchOnlyTextFieldType(\n+                buildFullName(contentPath),\n+                store.getValue(),\n+                tsi,\n+                indexAnalyzer,\n+                meta.getValue()\n+            );\n+            return ft;\n+        }\n+\n+        @Override\n+        public MatchOnlyTextFieldMapper build(ContentPath contentPath) {\n+            FieldType fieldType = new FieldType(Defaults.FIELD_TYPE);\n+            fieldType.setStored(store.get());\n+            MatchOnlyTextFieldType tft = buildFieldType(fieldType, contentPath);\n+            MultiFields multiFields = multiFieldsBuilder.build(this, contentPath);\n+            return new MatchOnlyTextFieldMapper(name, fieldType, tft, analyzers.getIndexAnalyzer(), multiFields, copyTo.build(), this);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n, c.indexVersionCreated(), c.getIndexAnalyzers()));\n+\n+    public static class MatchOnlyTextFieldType extends StringFieldType {\n+\n+        private final Analyzer indexAnalyzer;\n+        private final TextFieldType textFieldType;\n+\n+        public MatchOnlyTextFieldType(String name, boolean stored, TextSearchInfo tsi, Analyzer indexAnalyzer, Map<String, String> meta) {\n+            super(name, true, stored, false, tsi, meta);\n+            this.indexAnalyzer = Objects.requireNonNull(indexAnalyzer);\n+            this.textFieldType = new TextFieldType(name);\n+        }\n+\n+        public MatchOnlyTextFieldType(String name, boolean stored, Map<String, String> meta) {\n+            super(\n+                name,\n+                true,\n+                stored,\n+                false,\n+                new TextSearchInfo(Defaults.FIELD_TYPE, null, Lucene.STANDARD_ANALYZER, Lucene.STANDARD_ANALYZER),\n+                meta\n+            );\n+            this.indexAnalyzer = Lucene.STANDARD_ANALYZER;\n+            this.textFieldType = new TextFieldType(name);\n+        }\n+\n+        public MatchOnlyTextFieldType(String name) {\n+            this(\n+                name,\n+                false,\n+                new TextSearchInfo(Defaults.FIELD_TYPE, null, Lucene.STANDARD_ANALYZER, Lucene.STANDARD_ANALYZER),\n+                Lucene.STANDARD_ANALYZER,\n+                Collections.emptyMap()\n+            );\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public String familyTypeName() {\n+            return TextFieldMapper.CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public ValueFetcher valueFetcher(QueryShardContext context, String format) {\n+            return SourceValueFetcher.toString(name(), context, format);\n+        }\n+\n+        private Query toQuery(Query query, QueryShardContext queryShardContext) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7a03a0f974470b7c37038156dd10ef1c59c12f8e"}, "originalPosition": 186}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDYxNjUyOQ==", "bodyText": "Should we file an issue to track this? We just try not to have field types/ queries that scan all documents (unless they're runtime fields of course :))", "url": "https://github.com/elastic/elasticsearch/pull/66172#discussion_r544616529", "createdAt": "2020-12-16T20:55:23Z", "author": {"login": "jtibshirani"}, "path": "x-pack/plugin/mapper-match-only-text/src/main/java/org/elasticsearch/xpack/matchonlytext/query/SourceConfirmedTextQuery.java", "diffHunk": "@@ -0,0 +1,345 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.matchonlytext.query;\n+\n+import org.apache.lucene.analysis.Analyzer;\n+import org.apache.lucene.index.FieldInvertState;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.TermStates;\n+import org.apache.lucene.index.memory.MemoryIndex;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.BoostQuery;\n+import org.apache.lucene.search.CollectionStatistics;\n+import org.apache.lucene.search.ConstantScoreQuery;\n+import org.apache.lucene.search.DocIdSetIterator;\n+import org.apache.lucene.search.Explanation;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.LeafSimScorer;\n+import org.apache.lucene.search.MatchAllDocsQuery;\n+import org.apache.lucene.search.MatchNoDocsQuery;\n+import org.apache.lucene.search.MultiPhraseQuery;\n+import org.apache.lucene.search.PhraseQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.QueryVisitor;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.search.Scorer;\n+import org.apache.lucene.search.TermQuery;\n+import org.apache.lucene.search.TermStatistics;\n+import org.apache.lucene.search.TwoPhaseIterator;\n+import org.apache.lucene.search.Weight;\n+import org.apache.lucene.search.similarities.Similarity;\n+import org.apache.lucene.search.similarities.Similarity.SimScorer;\n+import org.elasticsearch.common.CheckedIntFunction;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+/**\n+ * A variant of {@link TermQuery}, {@link PhraseQuery}, {@link MultiPhraseQuery}\n+ * and span queries that uses postings for its approximation, but falls back to\n+ * stored fields or _source whenever term frequencies or positions are needed.\n+ * This query matches and scores the same way as the wrapped query.\n+ */\n+public final class SourceConfirmedTextQuery extends Query {\n+\n+    /**\n+     * Create an approximation for the given query. The returned approximation\n+     * should match a superset of the matches of the provided query.\n+     */\n+    public static Query approximate(Query query) {\n+        if (query instanceof TermQuery) {\n+            return query;\n+        } else if (query instanceof PhraseQuery) {\n+            return approximate((PhraseQuery) query);\n+        } else if (query instanceof MultiPhraseQuery) {\n+            return approximate((MultiPhraseQuery) query);\n+        } else {\n+            // TODO: spans and intervals", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7a03a0f974470b7c37038156dd10ef1c59c12f8e"}, "originalPosition": 72}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5774bc9fb375feb6a019bbe0ff7d5101a43fc7c3", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/5774bc9fb375feb6a019bbe0ff7d5101a43fc7c3", "committedDate": "2020-12-17T12:48:01Z", "message": "Fail phrase queries when _source is disabled."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c0be502abefa800b63194d4f81c4bd060d816e32", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/c0be502abefa800b63194d4f81c4bd060d816e32", "committedDate": "2020-12-17T12:54:09Z", "message": "Remove support for `store`."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "feaf2f8d8780dbed491e2ef507e17932afeb5192", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/feaf2f8d8780dbed491e2ef507e17932afeb5192", "committedDate": "2020-12-17T13:08:32Z", "message": "Add tests for span and intervals queries."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d51db6c08454c3b13f4ba622fc6e56f47c56c166", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/d51db6c08454c3b13f4ba622fc6e56f47c56c166", "committedDate": "2020-12-17T13:19:32Z", "message": "Test for fuzzy query."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "71adb75c68d8711941363d321b2badcce5e4ea38", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/71adb75c68d8711941363d321b2badcce5e4ea38", "committedDate": "2020-12-17T15:02:57Z", "message": "More tests."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MTE4OTg0", "url": "https://github.com/elastic/elasticsearch/pull/66172#pullrequestreview-555118984", "createdAt": "2020-12-18T01:48:40Z", "commit": {"oid": "71adb75c68d8711941363d321b2badcce5e4ea38"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4f33106b96a637a136f655619cec294d843585c8", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/4f33106b96a637a136f655619cec294d843585c8", "committedDate": "2021-02-01T09:22:40Z", "message": "Merge branch 'master' into feature/source_phrase_queries"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "24b345e149ffed4d706ef207bb3dd488873fa505", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/24b345e149ffed4d706ef207bb3dd488873fa505", "committedDate": "2021-02-01T11:14:37Z", "message": "Fix compilation."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "34743ef00d8f53c875f974e3156ffe32e0aee199", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/34743ef00d8f53c875f974e3156ffe32e0aee199", "committedDate": "2021-02-09T15:08:12Z", "message": "iter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "efdb3ba3c45b94b9c204938fbbb929523295d44b", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/efdb3ba3c45b94b9c204938fbbb929523295d44b", "committedDate": "2021-03-30T16:16:24Z", "message": "Merge branch 'master' into feature/source_phrase_queries"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7114fdc89e69d1bbc7a7b4e335ce1e58aafd1857", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/7114fdc89e69d1bbc7a7b4e335ce1e58aafd1857", "committedDate": "2021-03-30T16:54:37Z", "message": "iter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2030545187f5c8562cc95a6387be8deb4fc7fe0f", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/2030545187f5c8562cc95a6387be8deb4fc7fe0f", "committedDate": "2021-04-01T08:35:23Z", "message": "iter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "96f668bd1b1eb01983d359f3ff3837cce431c9e2", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/96f668bd1b1eb01983d359f3ff3837cce431c9e2", "committedDate": "2021-04-01T08:36:04Z", "message": "Merge branch 'master' into feature/source_phrase_queries"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3a85af4e67de873a3954f330c5a010da6b557b5b", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/3a85af4e67de873a3954f330c5a010da6b557b5b", "committedDate": "2021-04-01T08:58:48Z", "message": "iter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "448eb28bcb2fa6e840a1aaee9f5d50f8fbda1ad7", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/448eb28bcb2fa6e840a1aaee9f5d50f8fbda1ad7", "committedDate": "2021-04-01T09:10:12Z", "message": "iter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f3e77f8a61076edc55ba75aad86235ff5728c380", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/f3e77f8a61076edc55ba75aad86235ff5728c380", "committedDate": "2021-04-01T14:02:09Z", "message": "Fix compilation."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjI2NTI3MTE5", "url": "https://github.com/elastic/elasticsearch/pull/66172#pullrequestreview-626527119", "createdAt": "2021-04-01T18:10:03Z", "commit": {"oid": "f3e77f8a61076edc55ba75aad86235ff5728c380"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNC0wMVQxODoxMDowNFrOJBySGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNC0wMVQxODoxMDowNFrOJBySGA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwNTg1MjE4NA==", "bodyText": "One thought I had since reviewing: if this is just targeted at log lines, would it make sense to cut down on analysis config options? For example, not allowing for a different search analyzer or search quote analyzers. Or even removing the option configuring the analyzer, just using a default that targets log lines. This could make it simpler to maintain long BWC for the field type. (This is a rough idea, and I am not sure it makes sense... maybe many users in fact tweak analyzers for log lines.)", "url": "https://github.com/elastic/elasticsearch/pull/66172#discussion_r605852184", "createdAt": "2021-04-01T18:10:04Z", "author": {"login": "jtibshirani"}, "path": "docs/reference/mapping/types/match-only-text.asciidoc", "diffHunk": "@@ -0,0 +1,73 @@\n+[discrete]\n+[[match-only-text-field-type]]\n+=== Match-only text field type\n+\n+A variant of <<text-field-type,`text`>> that trades scoring and efficiency of\n+positional queries for space efficiency. This field effectively stores data the\n+same way as a `text` field that only indexes documents (`index_options: docs`)\n+and disables norms (`norms: false`). Term queries perform as fast if not faster\n+as on `text` fields, however queries that need positions such as the\n+<<query-dsl-match-query-phrase,`match_phrase` query>> perform slower as they\n+need to look at the `_source` document to verify whether a phrase matches. All\n+queries return constant scores that are equal to 1.0.\n+\n+<<span-queries,span queries>>, as well as `wildcard` and `fuzzy` rules of\n+<<query-dsl-intervals-query,interval queries>> are not supported by this field.\n+Use the <<text-field-type,`text`>> field type if you need them.\n+\n+Other than that, `match_only_text` supports the same queries as `text`. And\n+like `text`, it doesn't support sorting or aggregating.\n+\n+[source,console]\n+--------------------------------\n+PUT logs\n+{\n+  \"mappings\": {\n+    \"properties\": {\n+      \"@timestamp\": {\n+        \"type\": \"date\"\n+      },\n+      \"message\": {\n+        \"type\": \"match_only_text\"\n+      }\n+    }\n+  }\n+}\n+--------------------------------\n+\n+[discrete]\n+[[match-only-text-params]]\n+==== Parameters for match-only text fields\n+\n+The following mapping parameters are accepted:\n+\n+[horizontal]\n+\n+<<analyzer,`analyzer`>>::", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f3e77f8a61076edc55ba75aad86235ff5728c380"}, "originalPosition": 46}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c5f4f041b85751968767b51a8c04a50e0ff18347", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/c5f4f041b85751968767b51a8c04a50e0ff18347", "committedDate": "2021-04-02T12:34:52Z", "message": "Analysis is no longer configurable."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjI5MDgwNTQx", "url": "https://github.com/elastic/elasticsearch/pull/66172#pullrequestreview-629080541", "createdAt": "2021-04-06T15:00:36Z", "commit": {"oid": "c5f4f041b85751968767b51a8c04a50e0ff18347"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNC0wNlQxNTowMDozNlrOJDxIyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNC0wNlQxNTowMjoxM1rOJDxOFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwNzkzMDU2OQ==", "bodyText": "I think this can throw IOException?", "url": "https://github.com/elastic/elasticsearch/pull/66172#discussion_r607930569", "createdAt": "2021-04-06T15:00:36Z", "author": {"login": "romseygeek"}, "path": "modules/mapper-extras/src/main/java/org/elasticsearch/index/query/SourceIntervalsSource.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License\n+ * 2.0 and the Server Side Public License, v 1; you may not use this file except\n+ * in compliance with, at your election, the Elastic License 2.0 or the Server\n+ * Side Public License, v 1.\n+ */\n+\n+package org.elasticsearch.index.query;\n+\n+import org.apache.lucene.analysis.Analyzer;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.memory.MemoryIndex;\n+import org.apache.lucene.queries.intervals.IntervalIterator;\n+import org.apache.lucene.queries.intervals.IntervalMatchesIterator;\n+import org.apache.lucene.queries.intervals.IntervalsSource;\n+import org.apache.lucene.search.DocIdSetIterator;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.QueryVisitor;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.search.Scorer;\n+import org.apache.lucene.search.Weight;\n+import org.elasticsearch.common.CheckedIntFunction;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.function.Function;\n+\n+/**\n+ * A wrapper of {@link IntervalsSource} for the case when positions are not indexed.\n+ */\n+public final class SourceIntervalsSource extends IntervalsSource {\n+\n+    private final IntervalsSource in;\n+    private final Query approximation;\n+    private final Function<LeafReaderContext, CheckedIntFunction<List<Object>, IOException>> valueFetcherProvider;\n+    private final Analyzer indexAnalyzer;\n+\n+    public SourceIntervalsSource(IntervalsSource in,\n+            Query approximation,\n+            Function<LeafReaderContext, CheckedIntFunction<List<Object>, IOException>> valueFetcherProvider,\n+            Analyzer indexAnalyzer) {\n+        this.in = Objects.requireNonNull(in);\n+        this.approximation = Objects.requireNonNull(approximation);\n+        this.valueFetcherProvider = Objects.requireNonNull(valueFetcherProvider);\n+        this.indexAnalyzer = Objects.requireNonNull(indexAnalyzer);\n+    }\n+\n+    private LeafReaderContext createSingleDocLeafReaderContext(String field, List<Object> values) {\n+        MemoryIndex index = new MemoryIndex();\n+        for (Object value : values) {\n+            if (value == null) {\n+                continue;\n+            }\n+            index.addField(field, value.toString(), indexAnalyzer);\n+        }\n+        index.freeze();\n+        return index.createSearcher().getIndexReader().leaves().get(0);\n+    }\n+\n+    @Override\n+    public IntervalIterator intervals(String field, LeafReaderContext ctx) throws IOException {\n+        final IndexSearcher searcher = new IndexSearcher(ctx.reader());\n+        final Weight weight = searcher.createWeight(searcher.rewrite(approximation), ScoreMode.COMPLETE_NO_SCORES, 1f);\n+        final Scorer scorer = weight.scorer(ctx.reader().getContext());\n+        if (scorer == null) {\n+            return null;\n+        }\n+        final DocIdSetIterator approximation = scorer.iterator();\n+\n+        final CheckedIntFunction<List<Object>, IOException> valueFetcher = valueFetcherProvider.apply(ctx);\n+        return new IntervalIterator() {\n+\n+            private IntervalIterator in;\n+\n+            @Override\n+            public int docID() {\n+                return approximation.docID();\n+            }\n+\n+            @Override\n+            public long cost() {\n+                return approximation.cost();\n+            }\n+\n+            @Override\n+            public int nextDoc() throws IOException {\n+                return doNext(approximation.nextDoc());\n+            }\n+\n+            @Override\n+            public int advance(int target) throws IOException {\n+                return doNext(approximation.advance(target));\n+            }\n+\n+            private int doNext(int doc) throws IOException {\n+                while (doc != NO_MORE_DOCS && setIterator(doc) == false) {\n+                    doc = approximation.nextDoc();\n+                }\n+                return doc;\n+            }\n+\n+            private boolean setIterator(int doc) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c5f4f041b85751968767b51a8c04a50e0ff18347"}, "originalPosition": 108}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwNzkzMTkyNw==", "bodyText": "The index analyzer should be immutable for an open index, I think? So I'm not sure that it needs to be included here or in equals.", "url": "https://github.com/elastic/elasticsearch/pull/66172#discussion_r607931927", "createdAt": "2021-04-06T15:02:13Z", "author": {"login": "romseygeek"}, "path": "modules/mapper-extras/src/main/java/org/elasticsearch/index/query/SourceIntervalsSource.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License\n+ * 2.0 and the Server Side Public License, v 1; you may not use this file except\n+ * in compliance with, at your election, the Elastic License 2.0 or the Server\n+ * Side Public License, v 1.\n+ */\n+\n+package org.elasticsearch.index.query;\n+\n+import org.apache.lucene.analysis.Analyzer;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.memory.MemoryIndex;\n+import org.apache.lucene.queries.intervals.IntervalIterator;\n+import org.apache.lucene.queries.intervals.IntervalMatchesIterator;\n+import org.apache.lucene.queries.intervals.IntervalsSource;\n+import org.apache.lucene.search.DocIdSetIterator;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.QueryVisitor;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.search.Scorer;\n+import org.apache.lucene.search.Weight;\n+import org.elasticsearch.common.CheckedIntFunction;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.function.Function;\n+\n+/**\n+ * A wrapper of {@link IntervalsSource} for the case when positions are not indexed.\n+ */\n+public final class SourceIntervalsSource extends IntervalsSource {\n+\n+    private final IntervalsSource in;\n+    private final Query approximation;\n+    private final Function<LeafReaderContext, CheckedIntFunction<List<Object>, IOException>> valueFetcherProvider;\n+    private final Analyzer indexAnalyzer;\n+\n+    public SourceIntervalsSource(IntervalsSource in,\n+            Query approximation,\n+            Function<LeafReaderContext, CheckedIntFunction<List<Object>, IOException>> valueFetcherProvider,\n+            Analyzer indexAnalyzer) {\n+        this.in = Objects.requireNonNull(in);\n+        this.approximation = Objects.requireNonNull(approximation);\n+        this.valueFetcherProvider = Objects.requireNonNull(valueFetcherProvider);\n+        this.indexAnalyzer = Objects.requireNonNull(indexAnalyzer);\n+    }\n+\n+    private LeafReaderContext createSingleDocLeafReaderContext(String field, List<Object> values) {\n+        MemoryIndex index = new MemoryIndex();\n+        for (Object value : values) {\n+            if (value == null) {\n+                continue;\n+            }\n+            index.addField(field, value.toString(), indexAnalyzer);\n+        }\n+        index.freeze();\n+        return index.createSearcher().getIndexReader().leaves().get(0);\n+    }\n+\n+    @Override\n+    public IntervalIterator intervals(String field, LeafReaderContext ctx) throws IOException {\n+        final IndexSearcher searcher = new IndexSearcher(ctx.reader());\n+        final Weight weight = searcher.createWeight(searcher.rewrite(approximation), ScoreMode.COMPLETE_NO_SCORES, 1f);\n+        final Scorer scorer = weight.scorer(ctx.reader().getContext());\n+        if (scorer == null) {\n+            return null;\n+        }\n+        final DocIdSetIterator approximation = scorer.iterator();\n+\n+        final CheckedIntFunction<List<Object>, IOException> valueFetcher = valueFetcherProvider.apply(ctx);\n+        return new IntervalIterator() {\n+\n+            private IntervalIterator in;\n+\n+            @Override\n+            public int docID() {\n+                return approximation.docID();\n+            }\n+\n+            @Override\n+            public long cost() {\n+                return approximation.cost();\n+            }\n+\n+            @Override\n+            public int nextDoc() throws IOException {\n+                return doNext(approximation.nextDoc());\n+            }\n+\n+            @Override\n+            public int advance(int target) throws IOException {\n+                return doNext(approximation.advance(target));\n+            }\n+\n+            private int doNext(int doc) throws IOException {\n+                while (doc != NO_MORE_DOCS && setIterator(doc) == false) {\n+                    doc = approximation.nextDoc();\n+                }\n+                return doc;\n+            }\n+\n+            private boolean setIterator(int doc) {\n+                try {\n+                    final List<Object> values = valueFetcher.apply(doc);\n+                    final LeafReaderContext singleDocContext = createSingleDocLeafReaderContext(field, values);\n+                    in = SourceIntervalsSource.this.in.intervals(field, singleDocContext);\n+                    final boolean isSet = in != null && in.nextDoc() != NO_MORE_DOCS;\n+                    assert isSet == false || in.docID() == 0;\n+                    return isSet;\n+                } catch (IOException e) {\n+                    throw new UncheckedIOException(e);\n+                }\n+            }\n+\n+            @Override\n+            public int start() {\n+                return in.start();\n+            }\n+\n+            @Override\n+            public int end() {\n+                return in.end();\n+            }\n+\n+            @Override\n+            public int gaps() {\n+                return in.gaps();\n+            }\n+\n+            @Override\n+            public int nextInterval() throws IOException {\n+                return in.nextInterval();\n+            }\n+\n+            @Override\n+            public float matchCost() {\n+                // a high number since we need to parse the _source\n+                return 10_000;\n+            }\n+\n+        };\n+    }\n+\n+    @Override\n+    public IntervalMatchesIterator matches(String field, LeafReaderContext ctx, int doc) throws IOException {\n+        final CheckedIntFunction<List<Object>, IOException> valueFetcher = valueFetcherProvider.apply(ctx);\n+        final List<Object> values = valueFetcher.apply(doc);\n+        final LeafReaderContext singleDocContext = createSingleDocLeafReaderContext(field, values);\n+        return in.matches(field, singleDocContext, 0);\n+    }\n+\n+    @Override\n+    public void visit(String field, QueryVisitor visitor) {\n+        in.visit(field, visitor);\n+    }\n+\n+    @Override\n+    public int minExtent() {\n+        return in.minExtent();\n+    }\n+\n+    @Override\n+    public Collection<IntervalsSource> pullUpDisjunctions() {\n+        return Collections.singleton(this);\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        // Not using matchesProvider and valueFetcherProvider, which don't identify this source but are only used to avoid scanning linearly\n+        // through all documents\n+        return Objects.hash(in, indexAnalyzer);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c5f4f041b85751968767b51a8c04a50e0ff18347"}, "originalPosition": 177}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4818edc46dd97b80fc20e4487c969fefde811cac", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/4818edc46dd97b80fc20e4487c969fefde811cac", "committedDate": "2021-04-07T13:21:27Z", "message": "iter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "339c8dcf8f44af390aab329c36c90eefcfab0760", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/339c8dcf8f44af390aab329c36c90eefcfab0760", "committedDate": "2021-04-21T07:04:05Z", "message": "Merge branch 'master' into feature/source_phrase_queries"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e652aa40995aee83e6b21074291ac67bdf653644", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/e652aa40995aee83e6b21074291ac67bdf653644", "committedDate": "2021-04-21T11:33:47Z", "message": "Intervals unit tests."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "31a5bbad4b40a3f137a302e180e65dcf02c71b1c", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/31a5bbad4b40a3f137a302e180e65dcf02c71b1c", "committedDate": "2021-04-21T11:36:19Z", "message": "Fix docs now that `match_only_text` supports all interval queries."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3783f18defe8e1f614242674fea7368a183ea846", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/3783f18defe8e1f614242674fea7368a183ea846", "committedDate": "2021-04-21T11:53:19Z", "message": "Undo testing hack."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "edaa5b0d9f3820bb614724760f7e47ba222fbe88", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/elastic/elasticsearch/commit/edaa5b0d9f3820bb614724760f7e47ba222fbe88", "committedDate": "2021-04-21T14:05:36Z", "message": "Merge branch 'master' into feature/source_phrase_queries"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4719, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}