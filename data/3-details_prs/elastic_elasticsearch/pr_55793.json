{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA5MzgxMDgx", "number": 55793, "title": "Use workers to warm cache parts", "bodyText": "Today the cache prewarming introduced in #55322 works by enqueuing altogether the files parts to warm in the searchable_snapshots thread pool. In order to make this fairer among concurrent warmings, this pull request starts workers that concurrently polls file parts to warm from a queue, warms the part and then immediately schedule another warming execution. This should leave more room for concurrent shard warming to sneak in and be executed.\nRelates #55322 (comment)", "createdAt": "2020-04-27T09:46:05Z", "url": "https://github.com/elastic/elasticsearch/pull/55793", "merged": true, "mergeCommit": {"oid": "6dd05256f4996913983f0166da08f99017c9a96f"}, "closed": true, "closedAt": "2020-05-05T08:55:21Z", "author": {"login": "tlrx"}, "timelineItems": {"totalCount": 25, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcbrCFfAH2gAyNDA5MzgxMDgxOjk3NDM4MDZhZDVhMzk2ZDg4MDc5YmU4OTBlZjQzYjg0YjI4MTVjYTA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABceP2GugFqTQwNTU4ODAwOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "9743806ad5a396d88079be890ef43b84b2815ca0", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/9743806ad5a396d88079be890ef43b84b2815ca0", "committedDate": "2020-04-27T08:30:14Z", "message": "Use workers to warm cache parts"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAwNzk5MTk1", "url": "https://github.com/elastic/elasticsearch/pull/55793#pullrequestreview-400799195", "createdAt": "2020-04-27T09:55:05Z", "commit": {"oid": "9743806ad5a396d88079be890ef43b84b2815ca0"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QwOTo1NTowNVrOGMawBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QxMDowMjoyNFrOGMbDrQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTY3NDM3NQ==", "bodyText": "Why wrap this in a SizeBlockingQueue?", "url": "https://github.com/elastic/elasticsearch/pull/55793#discussion_r415674375", "createdAt": "2020-04-27T09:55:05Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -361,68 +367,95 @@ private void prewarmCache() {\n             final Executor executor = threadPool.executor(SEARCHABLE_SNAPSHOTS_THREAD_POOL_NAME);\n             logger.debug(\"{} warming shard cache for [{}] files\", shardId, cacheFiles.size());\n \n+            final BlockingQueue<CheckedRunnable<Exception>> queue = new SizeBlockingQueue<>(new LinkedBlockingQueue<>(), Integer.MAX_VALUE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9743806ad5a396d88079be890ef43b84b2815ca0"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTY3NTg4OA==", "bodyText": "should this not always be true? Why should this queue ever overflow?", "url": "https://github.com/elastic/elasticsearch/pull/55793#discussion_r415675888", "createdAt": "2020-04-27T09:57:18Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -361,68 +367,95 @@ private void prewarmCache() {\n             final Executor executor = threadPool.executor(SEARCHABLE_SNAPSHOTS_THREAD_POOL_NAME);\n             logger.debug(\"{} warming shard cache for [{}] files\", shardId, cacheFiles.size());\n \n+            final BlockingQueue<CheckedRunnable<Exception>> queue = new SizeBlockingQueue<>(new LinkedBlockingQueue<>(), Integer.MAX_VALUE);\n             for (BlobStoreIndexShardSnapshot.FileInfo cacheFile : cacheFiles) {\n                 final String fileName = cacheFile.physicalName();\n                 try {\n                     final IndexInput input = openInput(fileName, CachedBlobContainerIndexInput.CACHE_WARMING_CONTEXT);\n                     assert input instanceof CachedBlobContainerIndexInput : \"expected cached index input but got \" + input.getClass();\n \n                     final long numberOfParts = cacheFile.numberOfParts();\n-                    final CountDown countDown = new CountDown(Math.toIntExact(numberOfParts));\n-                    for (long p = 0; p < numberOfParts; p++) {\n-                        final int part = Math.toIntExact(p);\n-                        // TODO use multiple workers to warm each part instead of filling the thread pool\n-                        executor.execute(new AbstractRunnable() {\n-                            @Override\n-                            protected void doRun() throws Exception {\n-                                ensureOpen();\n-\n-                                logger.trace(\"warming cache for [{}] part [{}/{}]\", fileName, part, numberOfParts);\n-                                final long startTimeInNanos = statsCurrentTimeNanosSupplier.getAsLong();\n-\n-                                final CachedBlobContainerIndexInput cachedIndexInput = (CachedBlobContainerIndexInput) input.clone();\n-                                final int bytesRead = cachedIndexInput.prefetchPart(part); // TODO does not include any rate limitation\n-                                assert bytesRead == cacheFile.partBytes(part);\n-\n-                                logger.trace(\n-                                    () -> new ParameterizedMessage(\n-                                        \"part [{}/{}] of [{}] warmed in [{}] ms\",\n-                                        part,\n-                                        numberOfParts,\n-                                        fileName,\n-                                        TimeValue.timeValueNanos(statsCurrentTimeNanosSupplier.getAsLong() - startTimeInNanos).millis()\n-                                    )\n-                                );\n-                            }\n-\n-                            @Override\n-                            public void onFailure(Exception e) {\n-                                logger.trace(\n-                                    () -> new ParameterizedMessage(\n-                                        \"failed to warm cache for [{}] part [{}/{}]\",\n-                                        fileName,\n-                                        part,\n-                                        numberOfParts\n-                                    ),\n-                                    e\n-                                );\n-                            }\n-\n-                            @Override\n-                            public void onAfter() {\n-                                if (countDown.countDown()) {\n-                                    IOUtils.closeWhileHandlingException(input);\n+                    if (queue.remainingCapacity() >= numberOfParts) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9743806ad5a396d88079be890ef43b84b2815ca0"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTY3Nzc1MQ==", "bodyText": "do we need to drain the queue and close input here?", "url": "https://github.com/elastic/elasticsearch/pull/55793#discussion_r415677751", "createdAt": "2020-04-27T10:00:00Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -361,68 +367,95 @@ private void prewarmCache() {\n             final Executor executor = threadPool.executor(SEARCHABLE_SNAPSHOTS_THREAD_POOL_NAME);\n             logger.debug(\"{} warming shard cache for [{}] files\", shardId, cacheFiles.size());\n \n+            final BlockingQueue<CheckedRunnable<Exception>> queue = new SizeBlockingQueue<>(new LinkedBlockingQueue<>(), Integer.MAX_VALUE);\n             for (BlobStoreIndexShardSnapshot.FileInfo cacheFile : cacheFiles) {\n                 final String fileName = cacheFile.physicalName();\n                 try {\n                     final IndexInput input = openInput(fileName, CachedBlobContainerIndexInput.CACHE_WARMING_CONTEXT);\n                     assert input instanceof CachedBlobContainerIndexInput : \"expected cached index input but got \" + input.getClass();\n \n                     final long numberOfParts = cacheFile.numberOfParts();\n-                    final CountDown countDown = new CountDown(Math.toIntExact(numberOfParts));\n-                    for (long p = 0; p < numberOfParts; p++) {\n-                        final int part = Math.toIntExact(p);\n-                        // TODO use multiple workers to warm each part instead of filling the thread pool\n-                        executor.execute(new AbstractRunnable() {\n-                            @Override\n-                            protected void doRun() throws Exception {\n-                                ensureOpen();\n-\n-                                logger.trace(\"warming cache for [{}] part [{}/{}]\", fileName, part, numberOfParts);\n-                                final long startTimeInNanos = statsCurrentTimeNanosSupplier.getAsLong();\n-\n-                                final CachedBlobContainerIndexInput cachedIndexInput = (CachedBlobContainerIndexInput) input.clone();\n-                                final int bytesRead = cachedIndexInput.prefetchPart(part); // TODO does not include any rate limitation\n-                                assert bytesRead == cacheFile.partBytes(part);\n-\n-                                logger.trace(\n-                                    () -> new ParameterizedMessage(\n-                                        \"part [{}/{}] of [{}] warmed in [{}] ms\",\n-                                        part,\n-                                        numberOfParts,\n-                                        fileName,\n-                                        TimeValue.timeValueNanos(statsCurrentTimeNanosSupplier.getAsLong() - startTimeInNanos).millis()\n-                                    )\n-                                );\n-                            }\n-\n-                            @Override\n-                            public void onFailure(Exception e) {\n-                                logger.trace(\n-                                    () -> new ParameterizedMessage(\n-                                        \"failed to warm cache for [{}] part [{}/{}]\",\n-                                        fileName,\n-                                        part,\n-                                        numberOfParts\n-                                    ),\n-                                    e\n-                                );\n-                            }\n-\n-                            @Override\n-                            public void onAfter() {\n-                                if (countDown.countDown()) {\n-                                    IOUtils.closeWhileHandlingException(input);\n+                    if (queue.remainingCapacity() >= numberOfParts) {\n+                        final CountDown countDown = new CountDown(Math.toIntExact(numberOfParts));\n+                        for (long p = 0; p < numberOfParts; p++) {\n+                            final int part = Math.toIntExact(p);\n+                            queue.add(() -> {\n+                                try {\n+                                    ensureOpen();\n+\n+                                    logger.trace(\"warming cache for [{}] part [{}/{}]\", fileName, part, numberOfParts);\n+                                    final long startTimeInNanos = statsCurrentTimeNanosSupplier.getAsLong();\n+\n+                                    final CachedBlobContainerIndexInput cachedIndexInput = (CachedBlobContainerIndexInput) input.clone();\n+                                    final int bytesRead = cachedIndexInput.prefetchPart(part); // TODO does not include any rate limitation\n+                                    assert bytesRead == cacheFile.partBytes(part);\n+\n+                                    logger.trace(\n+                                        () -> new ParameterizedMessage(\n+                                            \"part [{}/{}] of [{}] warmed in [{}] ms\",\n+                                            part,\n+                                            numberOfParts,\n+                                            fileName,\n+                                            TimeValue.timeValueNanos(statsCurrentTimeNanosSupplier.getAsLong() - startTimeInNanos).millis()\n+                                        )\n+                                    );\n+                                } catch (Exception e) {\n+                                    logger.trace(\n+                                        () -> new ParameterizedMessage(\n+                                            \"failed to warm cache for [{}] part [{}/{}]\",\n+                                            fileName,\n+                                            part,\n+                                            numberOfParts\n+                                        ),\n+                                        e\n+                                    );\n+                                    if (e instanceof AlreadyClosedException\n+                                        || (e.getCause() != null && e.getCause() instanceof AlreadyClosedException)) {\n+                                        return; // don't rethrow in case of cache eviction or directory closing\n+                                    }\n+                                    throw e;\n+                                } finally {\n+                                    if (countDown.countDown()) {\n+                                        IOUtils.closeWhileHandlingException(input);\n+                                    }\n                                 }\n-                            }\n-                        });\n+                            });\n+                        }\n                     }\n                 } catch (IOException e) {\n-                    logger.trace(() -> new ParameterizedMessage(\"failed to warm cache for [{}]\", fileName), e);\n+                    logger.trace(() -> new ParameterizedMessage(\"unable to schedule cache prewarming for [{}]\", fileName), e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9743806ad5a396d88079be890ef43b84b2815ca0"}, "originalPosition": 142}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTY3OTQwNQ==", "bodyText": "If scheduling fails here, how do we guarantee that IndexInput is closed?", "url": "https://github.com/elastic/elasticsearch/pull/55793#discussion_r415679405", "createdAt": "2020-04-27T10:02:24Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -361,68 +367,95 @@ private void prewarmCache() {\n             final Executor executor = threadPool.executor(SEARCHABLE_SNAPSHOTS_THREAD_POOL_NAME);\n             logger.debug(\"{} warming shard cache for [{}] files\", shardId, cacheFiles.size());\n \n+            final BlockingQueue<CheckedRunnable<Exception>> queue = new SizeBlockingQueue<>(new LinkedBlockingQueue<>(), Integer.MAX_VALUE);\n             for (BlobStoreIndexShardSnapshot.FileInfo cacheFile : cacheFiles) {\n                 final String fileName = cacheFile.physicalName();\n                 try {\n                     final IndexInput input = openInput(fileName, CachedBlobContainerIndexInput.CACHE_WARMING_CONTEXT);\n                     assert input instanceof CachedBlobContainerIndexInput : \"expected cached index input but got \" + input.getClass();\n \n                     final long numberOfParts = cacheFile.numberOfParts();\n-                    final CountDown countDown = new CountDown(Math.toIntExact(numberOfParts));\n-                    for (long p = 0; p < numberOfParts; p++) {\n-                        final int part = Math.toIntExact(p);\n-                        // TODO use multiple workers to warm each part instead of filling the thread pool\n-                        executor.execute(new AbstractRunnable() {\n-                            @Override\n-                            protected void doRun() throws Exception {\n-                                ensureOpen();\n-\n-                                logger.trace(\"warming cache for [{}] part [{}/{}]\", fileName, part, numberOfParts);\n-                                final long startTimeInNanos = statsCurrentTimeNanosSupplier.getAsLong();\n-\n-                                final CachedBlobContainerIndexInput cachedIndexInput = (CachedBlobContainerIndexInput) input.clone();\n-                                final int bytesRead = cachedIndexInput.prefetchPart(part); // TODO does not include any rate limitation\n-                                assert bytesRead == cacheFile.partBytes(part);\n-\n-                                logger.trace(\n-                                    () -> new ParameterizedMessage(\n-                                        \"part [{}/{}] of [{}] warmed in [{}] ms\",\n-                                        part,\n-                                        numberOfParts,\n-                                        fileName,\n-                                        TimeValue.timeValueNanos(statsCurrentTimeNanosSupplier.getAsLong() - startTimeInNanos).millis()\n-                                    )\n-                                );\n-                            }\n-\n-                            @Override\n-                            public void onFailure(Exception e) {\n-                                logger.trace(\n-                                    () -> new ParameterizedMessage(\n-                                        \"failed to warm cache for [{}] part [{}/{}]\",\n-                                        fileName,\n-                                        part,\n-                                        numberOfParts\n-                                    ),\n-                                    e\n-                                );\n-                            }\n-\n-                            @Override\n-                            public void onAfter() {\n-                                if (countDown.countDown()) {\n-                                    IOUtils.closeWhileHandlingException(input);\n+                    if (queue.remainingCapacity() >= numberOfParts) {\n+                        final CountDown countDown = new CountDown(Math.toIntExact(numberOfParts));\n+                        for (long p = 0; p < numberOfParts; p++) {\n+                            final int part = Math.toIntExact(p);\n+                            queue.add(() -> {\n+                                try {\n+                                    ensureOpen();\n+\n+                                    logger.trace(\"warming cache for [{}] part [{}/{}]\", fileName, part, numberOfParts);\n+                                    final long startTimeInNanos = statsCurrentTimeNanosSupplier.getAsLong();\n+\n+                                    final CachedBlobContainerIndexInput cachedIndexInput = (CachedBlobContainerIndexInput) input.clone();\n+                                    final int bytesRead = cachedIndexInput.prefetchPart(part); // TODO does not include any rate limitation\n+                                    assert bytesRead == cacheFile.partBytes(part);\n+\n+                                    logger.trace(\n+                                        () -> new ParameterizedMessage(\n+                                            \"part [{}/{}] of [{}] warmed in [{}] ms\",\n+                                            part,\n+                                            numberOfParts,\n+                                            fileName,\n+                                            TimeValue.timeValueNanos(statsCurrentTimeNanosSupplier.getAsLong() - startTimeInNanos).millis()\n+                                        )\n+                                    );\n+                                } catch (Exception e) {\n+                                    logger.trace(\n+                                        () -> new ParameterizedMessage(\n+                                            \"failed to warm cache for [{}] part [{}/{}]\",\n+                                            fileName,\n+                                            part,\n+                                            numberOfParts\n+                                        ),\n+                                        e\n+                                    );\n+                                    if (e instanceof AlreadyClosedException\n+                                        || (e.getCause() != null && e.getCause() instanceof AlreadyClosedException)) {\n+                                        return; // don't rethrow in case of cache eviction or directory closing\n+                                    }\n+                                    throw e;\n+                                } finally {\n+                                    if (countDown.countDown()) {\n+                                        IOUtils.closeWhileHandlingException(input);\n+                                    }\n                                 }\n-                            }\n-                        });\n+                            });\n+                        }\n                     }\n                 } catch (IOException e) {\n-                    logger.trace(() -> new ParameterizedMessage(\"failed to warm cache for [{}]\", fileName), e);\n+                    logger.trace(() -> new ParameterizedMessage(\"unable to schedule cache prewarming for [{}]\", fileName), e);\n                 }\n             }\n+\n+            // Start as many workers as fit into the searchable snapshot pool at once at the most\n+            final int workers = Math.min(threadPool.info(SEARCHABLE_SNAPSHOTS_THREAD_POOL_NAME).getMax(), queue.size());\n+            for (int i = 0; i < workers; ++i) {\n+                executeNextWarmer(executor, queue);\n+            }\n         }\n     }\n \n+    private void executeNextWarmer(final Executor executor, final BlockingQueue<CheckedRunnable<Exception>> queue) {\n+        executor.execute(new AbstractRunnable() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9743806ad5a396d88079be890ef43b84b2815ca0"}, "originalPosition": 155}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "01ca9f711d4c3297890a601f93b7aadc2701e2d3", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/01ca9f711d4c3297890a601f93b7aadc2701e2d3", "committedDate": "2020-04-27T13:09:45Z", "message": "apply feedback"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAwOTU5NTg4", "url": "https://github.com/elastic/elasticsearch/pull/55793#pullrequestreview-400959588", "createdAt": "2020-04-27T13:38:26Z", "commit": {"oid": "01ca9f711d4c3297890a601f93b7aadc2701e2d3"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QxMzozODoyNlrOGMjoQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QxMzo1MTo0MlrOGMkR1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTgxOTg0MQ==", "bodyText": "Call warmer.onFailure here?", "url": "https://github.com/elastic/elasticsearch/pull/55793#discussion_r415819841", "createdAt": "2020-04-27T13:38:26Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -393,33 +403,64 @@ protected void doRun() throws Exception {\n                                         TimeValue.timeValueNanos(statsCurrentTimeNanosSupplier.getAsLong() - startTimeInNanos).millis()\n                                     )\n                                 );\n+                            }));\n+                        }\n+                        enqueued = true;\n+                    }\n+                } catch (Exception e) {\n+                    logger.warn(\n+                        () -> new ParameterizedMessage(\"unable to open file [{}], cancelling prewarming for shard [{}]\", fileName, shardId),\n+                        e\n+                    );\n+                    if (queue.size() > 0) {\n+                        try {\n+                            ActionRunnable<Void> warmer;\n+                            while ((warmer = queue.poll(0L, TimeUnit.MILLISECONDS)) != null) {\n+                                warmer.onFailure(new IOException(\"Shard cache prewarming cancelled\"));\n                             }\n+                        } catch (InterruptedException ie) {\n+                            Thread.currentThread().interrupt();\n+                        }\n+                    }\n+                } finally {\n+                    if (enqueued == false) {\n+                        IOUtils.closeWhileHandlingException(input);\n+                    }\n+                }\n+            }\n \n-                            @Override\n-                            public void onFailure(Exception e) {\n-                                logger.trace(\n-                                    () -> new ParameterizedMessage(\n-                                        \"failed to warm cache for [{}] part [{}/{}]\",\n-                                        fileName,\n-                                        part,\n-                                        numberOfParts\n-                                    ),\n-                                    e\n-                                );\n-                            }\n+            // Start as many workers as fit into the searchable snapshot pool at once at the most\n+            final int workers = Math.min(threadPool.info(SEARCHABLE_SNAPSHOTS_THREAD_POOL_NAME).getMax(), queue.size());\n+            for (int i = 0; i < workers; ++i) {\n+                executeNextWarmer(executor, queue);\n+            }\n+        }\n+    }\n \n-                            @Override\n-                            public void onAfter() {\n-                                if (countDown.countDown()) {\n-                                    IOUtils.closeWhileHandlingException(input);\n-                                }\n-                            }\n-                        });\n+    private void executeNextWarmer(final Executor executor, final BlockingQueue<ActionRunnable<Void>> queue) {\n+        try {\n+            final ActionRunnable<?> warmer = queue.poll(0L, TimeUnit.MILLISECONDS);\n+            if (warmer != null) {\n+                executor.execute(new AbstractRunnable() {\n+                    @Override\n+                    protected void doRun() {\n+                        warmer.run();\n+                        executeNextWarmer(executor, queue);\n                     }\n-                } catch (IOException e) {\n-                    logger.trace(() -> new ParameterizedMessage(\"failed to warm cache for [{}]\", fileName), e);\n-                }\n+\n+                    @Override\n+                    public void onRejection(Exception e) {\n+                        warmer.onRejection(e);\n+                    }\n+\n+                    @Override\n+                    public void onFailure(Exception e) {\n+                        logger.warn(\"failed to schedule next file part to prewarm in cache\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "01ca9f711d4c3297890a601f93b7aadc2701e2d3"}, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTgyMTgwNA==", "bodyText": "This never rethrows the exception?", "url": "https://github.com/elastic/elasticsearch/pull/55793#discussion_r415821804", "createdAt": "2020-04-27T13:40:52Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -393,33 +403,64 @@ protected void doRun() throws Exception {\n                                         TimeValue.timeValueNanos(statsCurrentTimeNanosSupplier.getAsLong() - startTimeInNanos).millis()\n                                     )\n                                 );\n+                            }));\n+                        }\n+                        enqueued = true;\n+                    }\n+                } catch (Exception e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "01ca9f711d4c3297890a601f93b7aadc2701e2d3"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTgyMTk4NQ==", "bodyText": "This just swallows the exception?", "url": "https://github.com/elastic/elasticsearch/pull/55793#discussion_r415821985", "createdAt": "2020-04-27T13:41:06Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -393,33 +403,64 @@ protected void doRun() throws Exception {\n                                         TimeValue.timeValueNanos(statsCurrentTimeNanosSupplier.getAsLong() - startTimeInNanos).millis()\n                                     )\n                                 );\n+                            }));\n+                        }\n+                        enqueued = true;\n+                    }\n+                } catch (Exception e) {\n+                    logger.warn(\n+                        () -> new ParameterizedMessage(\"unable to open file [{}], cancelling prewarming for shard [{}]\", fileName, shardId),\n+                        e\n+                    );\n+                    if (queue.size() > 0) {\n+                        try {\n+                            ActionRunnable<Void> warmer;\n+                            while ((warmer = queue.poll(0L, TimeUnit.MILLISECONDS)) != null) {\n+                                warmer.onFailure(new IOException(\"Shard cache prewarming cancelled\"));\n                             }\n+                        } catch (InterruptedException ie) {\n+                            Thread.currentThread().interrupt();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "01ca9f711d4c3297890a601f93b7aadc2701e2d3"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTgyMjEwMA==", "bodyText": "This just swallows the exception?", "url": "https://github.com/elastic/elasticsearch/pull/55793#discussion_r415822100", "createdAt": "2020-04-27T13:41:15Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -393,33 +403,64 @@ protected void doRun() throws Exception {\n                                         TimeValue.timeValueNanos(statsCurrentTimeNanosSupplier.getAsLong() - startTimeInNanos).millis()\n                                     )\n                                 );\n+                            }));\n+                        }\n+                        enqueued = true;\n+                    }\n+                } catch (Exception e) {\n+                    logger.warn(\n+                        () -> new ParameterizedMessage(\"unable to open file [{}], cancelling prewarming for shard [{}]\", fileName, shardId),\n+                        e\n+                    );\n+                    if (queue.size() > 0) {\n+                        try {\n+                            ActionRunnable<Void> warmer;\n+                            while ((warmer = queue.poll(0L, TimeUnit.MILLISECONDS)) != null) {\n+                                warmer.onFailure(new IOException(\"Shard cache prewarming cancelled\"));\n                             }\n+                        } catch (InterruptedException ie) {\n+                            Thread.currentThread().interrupt();\n+                        }\n+                    }\n+                } finally {\n+                    if (enqueued == false) {\n+                        IOUtils.closeWhileHandlingException(input);\n+                    }\n+                }\n+            }\n \n-                            @Override\n-                            public void onFailure(Exception e) {\n-                                logger.trace(\n-                                    () -> new ParameterizedMessage(\n-                                        \"failed to warm cache for [{}] part [{}/{}]\",\n-                                        fileName,\n-                                        part,\n-                                        numberOfParts\n-                                    ),\n-                                    e\n-                                );\n-                            }\n+            // Start as many workers as fit into the searchable snapshot pool at once at the most\n+            final int workers = Math.min(threadPool.info(SEARCHABLE_SNAPSHOTS_THREAD_POOL_NAME).getMax(), queue.size());\n+            for (int i = 0; i < workers; ++i) {\n+                executeNextWarmer(executor, queue);\n+            }\n+        }\n+    }\n \n-                            @Override\n-                            public void onAfter() {\n-                                if (countDown.countDown()) {\n-                                    IOUtils.closeWhileHandlingException(input);\n-                                }\n-                            }\n-                        });\n+    private void executeNextWarmer(final Executor executor, final BlockingQueue<ActionRunnable<Void>> queue) {\n+        try {\n+            final ActionRunnable<?> warmer = queue.poll(0L, TimeUnit.MILLISECONDS);\n+            if (warmer != null) {\n+                executor.execute(new AbstractRunnable() {\n+                    @Override\n+                    protected void doRun() {\n+                        warmer.run();\n+                        executeNextWarmer(executor, queue);\n                     }\n-                } catch (IOException e) {\n-                    logger.trace(() -> new ParameterizedMessage(\"failed to warm cache for [{}]\", fileName), e);\n-                }\n+\n+                    @Override\n+                    public void onRejection(Exception e) {\n+                        warmer.onRejection(e);\n+                    }\n+\n+                    @Override\n+                    public void onFailure(Exception e) {\n+                        logger.warn(\"failed to schedule next file part to prewarm in cache\", e);\n+                    }\n+                });\n             }\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "01ca9f711d4c3297890a601f93b7aadc2701e2d3"}, "originalPosition": 155}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTgyNjc0NA==", "bodyText": "Do we just silently ignore if we have more than Integer.MAX_VALUE items? Should we log a big fat warning at that point instead?", "url": "https://github.com/elastic/elasticsearch/pull/55793#discussion_r415826744", "createdAt": "2020-04-27T13:46:59Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -361,68 +367,95 @@ private void prewarmCache() {\n             final Executor executor = threadPool.executor(SEARCHABLE_SNAPSHOTS_THREAD_POOL_NAME);\n             logger.debug(\"{} warming shard cache for [{}] files\", shardId, cacheFiles.size());\n \n+            final BlockingQueue<CheckedRunnable<Exception>> queue = new SizeBlockingQueue<>(new LinkedBlockingQueue<>(), Integer.MAX_VALUE);\n             for (BlobStoreIndexShardSnapshot.FileInfo cacheFile : cacheFiles) {\n                 final String fileName = cacheFile.physicalName();\n                 try {\n                     final IndexInput input = openInput(fileName, CachedBlobContainerIndexInput.CACHE_WARMING_CONTEXT);\n                     assert input instanceof CachedBlobContainerIndexInput : \"expected cached index input but got \" + input.getClass();\n \n                     final long numberOfParts = cacheFile.numberOfParts();\n-                    final CountDown countDown = new CountDown(Math.toIntExact(numberOfParts));\n-                    for (long p = 0; p < numberOfParts; p++) {\n-                        final int part = Math.toIntExact(p);\n-                        // TODO use multiple workers to warm each part instead of filling the thread pool\n-                        executor.execute(new AbstractRunnable() {\n-                            @Override\n-                            protected void doRun() throws Exception {\n-                                ensureOpen();\n-\n-                                logger.trace(\"warming cache for [{}] part [{}/{}]\", fileName, part, numberOfParts);\n-                                final long startTimeInNanos = statsCurrentTimeNanosSupplier.getAsLong();\n-\n-                                final CachedBlobContainerIndexInput cachedIndexInput = (CachedBlobContainerIndexInput) input.clone();\n-                                final int bytesRead = cachedIndexInput.prefetchPart(part); // TODO does not include any rate limitation\n-                                assert bytesRead == cacheFile.partBytes(part);\n-\n-                                logger.trace(\n-                                    () -> new ParameterizedMessage(\n-                                        \"part [{}/{}] of [{}] warmed in [{}] ms\",\n-                                        part,\n-                                        numberOfParts,\n-                                        fileName,\n-                                        TimeValue.timeValueNanos(statsCurrentTimeNanosSupplier.getAsLong() - startTimeInNanos).millis()\n-                                    )\n-                                );\n-                            }\n-\n-                            @Override\n-                            public void onFailure(Exception e) {\n-                                logger.trace(\n-                                    () -> new ParameterizedMessage(\n-                                        \"failed to warm cache for [{}] part [{}/{}]\",\n-                                        fileName,\n-                                        part,\n-                                        numberOfParts\n-                                    ),\n-                                    e\n-                                );\n-                            }\n-\n-                            @Override\n-                            public void onAfter() {\n-                                if (countDown.countDown()) {\n-                                    IOUtils.closeWhileHandlingException(input);\n+                    if (queue.remainingCapacity() >= numberOfParts) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTY3NTg4OA=="}, "originalCommit": {"oid": "9743806ad5a396d88079be890ef43b84b2815ca0"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTgzMDQ4NA==", "bodyText": "why not pass the original exception here?", "url": "https://github.com/elastic/elasticsearch/pull/55793#discussion_r415830484", "createdAt": "2020-04-27T13:51:42Z", "author": {"login": "ywelsch"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -393,33 +403,64 @@ protected void doRun() throws Exception {\n                                         TimeValue.timeValueNanos(statsCurrentTimeNanosSupplier.getAsLong() - startTimeInNanos).millis()\n                                     )\n                                 );\n+                            }));\n+                        }\n+                        enqueued = true;\n+                    }\n+                } catch (Exception e) {\n+                    logger.warn(\n+                        () -> new ParameterizedMessage(\"unable to open file [{}], cancelling prewarming for shard [{}]\", fileName, shardId),\n+                        e\n+                    );\n+                    if (queue.size() > 0) {\n+                        try {\n+                            ActionRunnable<Void> warmer;\n+                            while ((warmer = queue.poll(0L, TimeUnit.MILLISECONDS)) != null) {\n+                                warmer.onFailure(new IOException(\"Shard cache prewarming cancelled\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "01ca9f711d4c3297890a601f93b7aadc2701e2d3"}, "originalPosition": 89}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b6b90c4e6c630972a8888dbadbc8222cf2ecc9bc", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/b6b90c4e6c630972a8888dbadbc8222cf2ecc9bc", "committedDate": "2020-04-27T14:14:39Z", "message": "log warn interrupts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e0f8874eb43086609aa52ba6e06414b33d34ecfb", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/e0f8874eb43086609aa52ba6e06414b33d34ecfb", "committedDate": "2020-04-27T14:16:58Z", "message": "pass original exception"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "717c98f05fa34271fc071fc899165bd114cb1674", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/717c98f05fa34271fc071fc899165bd114cb1674", "committedDate": "2020-04-27T14:21:08Z", "message": "log a warning when too many files to warm"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "92bcbcb85f3a1ca4a2ad7081dd0c012712f06df0", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/92bcbcb85f3a1ca4a2ad7081dd0c012712f06df0", "committedDate": "2020-04-27T14:33:41Z", "message": "rethrow non closed exceptions"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a42716d5c52cb2d2797ba2cd29cc5b2420809272", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/a42716d5c52cb2d2797ba2cd29cc5b2420809272", "committedDate": "2020-04-28T09:36:13Z", "message": "make spotless happy"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d22c34ace60a052294000abc1d9d400f404d66a8", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/d22c34ace60a052294000abc1d9d400f404d66a8", "committedDate": "2020-04-28T09:49:45Z", "message": "Merge branch 'master' into use-worker-to-warm-cache"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAzNDIxMDQ1", "url": "https://github.com/elastic/elasticsearch/pull/55793#pullrequestreview-403421045", "createdAt": "2020-04-30T11:10:19Z", "commit": {"oid": "d22c34ace60a052294000abc1d9d400f404d66a8"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQxMToxMDoxOVrOGOkmmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQxMTozNDozNFrOGOlT6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzkzMjk1NQ==", "bodyText": "++ the fact that org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardSnapshot.FileInfo#numberOfParts is a long is weird to begin with here. But practically speaking there's no way we could ever exceed the queue size here (before we get here, writing/reading the necessary metadata would have OOMed already). I'd just remove this check and assume that if the queue ever throws IllegalStateException there's some other bug at play.", "url": "https://github.com/elastic/elasticsearch/pull/55793#discussion_r417932955", "createdAt": "2020-04-30T11:10:19Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -361,68 +367,95 @@ private void prewarmCache() {\n             final Executor executor = threadPool.executor(SEARCHABLE_SNAPSHOTS_THREAD_POOL_NAME);\n             logger.debug(\"{} warming shard cache for [{}] files\", shardId, cacheFiles.size());\n \n+            final BlockingQueue<CheckedRunnable<Exception>> queue = new SizeBlockingQueue<>(new LinkedBlockingQueue<>(), Integer.MAX_VALUE);\n             for (BlobStoreIndexShardSnapshot.FileInfo cacheFile : cacheFiles) {\n                 final String fileName = cacheFile.physicalName();\n                 try {\n                     final IndexInput input = openInput(fileName, CachedBlobContainerIndexInput.CACHE_WARMING_CONTEXT);\n                     assert input instanceof CachedBlobContainerIndexInput : \"expected cached index input but got \" + input.getClass();\n \n                     final long numberOfParts = cacheFile.numberOfParts();\n-                    final CountDown countDown = new CountDown(Math.toIntExact(numberOfParts));\n-                    for (long p = 0; p < numberOfParts; p++) {\n-                        final int part = Math.toIntExact(p);\n-                        // TODO use multiple workers to warm each part instead of filling the thread pool\n-                        executor.execute(new AbstractRunnable() {\n-                            @Override\n-                            protected void doRun() throws Exception {\n-                                ensureOpen();\n-\n-                                logger.trace(\"warming cache for [{}] part [{}/{}]\", fileName, part, numberOfParts);\n-                                final long startTimeInNanos = statsCurrentTimeNanosSupplier.getAsLong();\n-\n-                                final CachedBlobContainerIndexInput cachedIndexInput = (CachedBlobContainerIndexInput) input.clone();\n-                                final int bytesRead = cachedIndexInput.prefetchPart(part); // TODO does not include any rate limitation\n-                                assert bytesRead == cacheFile.partBytes(part);\n-\n-                                logger.trace(\n-                                    () -> new ParameterizedMessage(\n-                                        \"part [{}/{}] of [{}] warmed in [{}] ms\",\n-                                        part,\n-                                        numberOfParts,\n-                                        fileName,\n-                                        TimeValue.timeValueNanos(statsCurrentTimeNanosSupplier.getAsLong() - startTimeInNanos).millis()\n-                                    )\n-                                );\n-                            }\n-\n-                            @Override\n-                            public void onFailure(Exception e) {\n-                                logger.trace(\n-                                    () -> new ParameterizedMessage(\n-                                        \"failed to warm cache for [{}] part [{}/{}]\",\n-                                        fileName,\n-                                        part,\n-                                        numberOfParts\n-                                    ),\n-                                    e\n-                                );\n-                            }\n-\n-                            @Override\n-                            public void onAfter() {\n-                                if (countDown.countDown()) {\n-                                    IOUtils.closeWhileHandlingException(input);\n+                    if (queue.remainingCapacity() >= numberOfParts) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTY3NTg4OA=="}, "originalCommit": {"oid": "9743806ad5a396d88079be890ef43b84b2815ca0"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzkzOTEzMQ==", "bodyText": "Do we actually need this? If my understanding is correct, we are only ever opening any resources on the worker threads (which haven't yet started here), so why do we need to fail the runnables here here?", "url": "https://github.com/elastic/elasticsearch/pull/55793#discussion_r417939131", "createdAt": "2020-04-30T11:23:36Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -392,33 +404,73 @@ protected void doRun() throws Exception {\n                                         TimeValue.timeValueNanos(statsCurrentTimeNanosSupplier.getAsLong() - startTimeInNanos).millis()\n                                     )\n                                 );\n+                            }));\n+                        }\n+                        enqueued = true;\n+                    } else {\n+                        logger.warn(\"{} too many files ({}) to warm in cache, skipping file [{}]\", shardId, queue.size(), fileName);\n+                    }\n+                } catch (Exception e) {\n+                    logger.warn(\n+                        () -> new ParameterizedMessage(\"unable to open file [{}], cancelling prewarming for shard [{}]\", fileName, shardId),\n+                        e\n+                    );\n+                    if (queue.size() > 0) {\n+                        try {\n+                            ActionRunnable<Void> warmer;\n+                            while ((warmer = queue.poll(0L, TimeUnit.MILLISECONDS)) != null) {\n+                                warmer.onFailure(e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d22c34ace60a052294000abc1d9d400f404d66a8"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzk0NDU1NA==", "bodyText": "Why do our own queuing here? Can't we just push all the tasks in queue onto the executor and let it poll tasks from its internal queue when we're using the full pool anyway?", "url": "https://github.com/elastic/elasticsearch/pull/55793#discussion_r417944554", "createdAt": "2020-04-30T11:34:34Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -392,33 +404,73 @@ protected void doRun() throws Exception {\n                                         TimeValue.timeValueNanos(statsCurrentTimeNanosSupplier.getAsLong() - startTimeInNanos).millis()\n                                     )\n                                 );\n+                            }));\n+                        }\n+                        enqueued = true;\n+                    } else {\n+                        logger.warn(\"{} too many files ({}) to warm in cache, skipping file [{}]\", shardId, queue.size(), fileName);\n+                    }\n+                } catch (Exception e) {\n+                    logger.warn(\n+                        () -> new ParameterizedMessage(\"unable to open file [{}], cancelling prewarming for shard [{}]\", fileName, shardId),\n+                        e\n+                    );\n+                    if (queue.size() > 0) {\n+                        try {\n+                            ActionRunnable<Void> warmer;\n+                            while ((warmer = queue.poll(0L, TimeUnit.MILLISECONDS)) != null) {\n+                                warmer.onFailure(e);\n                             }\n+                        } catch (InterruptedException ie) {\n+                            Thread.currentThread().interrupt();\n+                            logger.warn(() -> new ParameterizedMessage(\"{} shard cache warming has been interrupted\", shardId), ie);\n+                        }\n+                    }\n+                    if (e instanceof AlreadyClosedException || (e.getCause() != null && e.getCause() instanceof AlreadyClosedException)) {\n+                        break;\n+                    } else {\n+                        throw new ElasticsearchException(\"Exception when warming cache for shard \" + shardId, e);\n+                    }\n+                } finally {\n+                    if (enqueued == false) {\n+                        IOUtils.closeWhileHandlingException(input);\n+                    }\n+                }\n+            }\n \n-                            @Override\n-                            public void onFailure(Exception e) {\n-                                logger.trace(\n-                                    () -> new ParameterizedMessage(\n-                                        \"failed to warm cache for [{}] part [{}/{}]\",\n-                                        fileName,\n-                                        part,\n-                                        numberOfParts\n-                                    ),\n-                                    e\n-                                );\n-                            }\n+            // Start as many workers as fit into the searchable snapshot pool at once at the most\n+            final int workers = Math.min(threadPool.info(SEARCHABLE_SNAPSHOTS_THREAD_POOL_NAME).getMax(), queue.size());\n+            for (int i = 0; i < workers; ++i) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d22c34ace60a052294000abc1d9d400f404d66a8"}, "originalPosition": 133}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "66197fce8b8bec02e88731aef1976d369b5d5ae6", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/66197fce8b8bec02e88731aef1976d369b5d5ae6", "committedDate": "2020-05-04T08:48:14Z", "message": "remove size blocking queue"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0d9d5b6ac8894771b0b6a1de023960c9bd03d3b8", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/0d9d5b6ac8894771b0b6a1de023960c9bd03d3b8", "committedDate": "2020-05-04T10:52:12Z", "message": "apply armin feedback"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA0ODkwMTcz", "url": "https://github.com/elastic/elasticsearch/pull/55793#pullrequestreview-404890173", "createdAt": "2020-05-04T11:05:51Z", "commit": {"oid": "0d9d5b6ac8894771b0b6a1de023960c9bd03d3b8"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMTowNTo1MVrOGP7sKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMToxMDo0OVrOGP70Yg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM1OTc4NA==", "bodyText": "NIT:\nI guess technically we could\nfinal BlobStoreIndexShardSnapshot.FileInfo file = queue.poll(0L, TimeUnit.MILLISECONDS);\nif (file == null) {\n    return;\n}\nbefore branching off to the executor at the beginning of this method. That way we save at least one pointless task on the scheduler for each shard (and an indent level in the abstract runnable :)).", "url": "https://github.com/elastic/elasticsearch/pull/55793#discussion_r419359784", "createdAt": "2020-05-04T11:05:51Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -352,74 +357,71 @@ public String toString() {\n \n     private void prewarmCache() {\n         if (prewarmCache) {\n-            final List<BlobStoreIndexShardSnapshot.FileInfo> cacheFiles = snapshot().indexFiles()\n+            final BlockingQueue<BlobStoreIndexShardSnapshot.FileInfo> queue = snapshot().indexFiles()\n                 .stream()\n                 .filter(file -> file.metadata().hashEqualsContents() == false)\n                 .filter(file -> isExcludedFromCache(file.physicalName()) == false)\n-                .collect(Collectors.toList());\n+                .collect(Collectors.toCollection(LinkedBlockingQueue::new));\n \n             final Executor executor = threadPool.executor(SEARCHABLE_SNAPSHOTS_THREAD_POOL_NAME);\n-            logger.debug(\"{} warming shard cache for [{}] files\", shardId, cacheFiles.size());\n+            logger.debug(\"{} warming shard cache for [{}] files\", shardId, queue.size());\n \n-            for (BlobStoreIndexShardSnapshot.FileInfo cacheFile : cacheFiles) {\n-                final String fileName = cacheFile.physicalName();\n-                try {\n-                    final IndexInput input = openInput(fileName, CachedBlobContainerIndexInput.CACHE_WARMING_CONTEXT);\n+            // Start as many workers as fit into the searchable snapshot pool at once at the most\n+            final int workers = Math.min(threadPool.info(SEARCHABLE_SNAPSHOTS_THREAD_POOL_NAME).getMax(), queue.size());\n+            for (int i = 0; i < workers; ++i) {\n+                prewarmNextFile(executor, queue);\n+            }\n+        }\n+    }\n+\n+    private void prewarmNextFile(final Executor executor, final BlockingQueue<BlobStoreIndexShardSnapshot.FileInfo> queue) {\n+        executor.execute(new AbstractRunnable() {\n+            @Override\n+            protected void doRun() throws Exception {\n+                final BlobStoreIndexShardSnapshot.FileInfo file = queue.poll(0L, TimeUnit.MILLISECONDS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d9d5b6ac8894771b0b6a1de023960c9bd03d3b8"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM2MTg5MA==", "bodyText": "I'm wondering if we should just special case numberOfParts == 1 here? It's the by far most common case and we could simply run it straight on the current thread instead of creating another task. Currently, we're creating twice as many tasks on the pool as necessary with this change.\nNo need for a lot of code here even, could just keep it short and use the direct executor service if numberOfParts == 1 and be happy with it?", "url": "https://github.com/elastic/elasticsearch/pull/55793#discussion_r419361890", "createdAt": "2020-05-04T11:10:49Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -352,74 +357,71 @@ public String toString() {\n \n     private void prewarmCache() {\n         if (prewarmCache) {\n-            final List<BlobStoreIndexShardSnapshot.FileInfo> cacheFiles = snapshot().indexFiles()\n+            final BlockingQueue<BlobStoreIndexShardSnapshot.FileInfo> queue = snapshot().indexFiles()\n                 .stream()\n                 .filter(file -> file.metadata().hashEqualsContents() == false)\n                 .filter(file -> isExcludedFromCache(file.physicalName()) == false)\n-                .collect(Collectors.toList());\n+                .collect(Collectors.toCollection(LinkedBlockingQueue::new));\n \n             final Executor executor = threadPool.executor(SEARCHABLE_SNAPSHOTS_THREAD_POOL_NAME);\n-            logger.debug(\"{} warming shard cache for [{}] files\", shardId, cacheFiles.size());\n+            logger.debug(\"{} warming shard cache for [{}] files\", shardId, queue.size());\n \n-            for (BlobStoreIndexShardSnapshot.FileInfo cacheFile : cacheFiles) {\n-                final String fileName = cacheFile.physicalName();\n-                try {\n-                    final IndexInput input = openInput(fileName, CachedBlobContainerIndexInput.CACHE_WARMING_CONTEXT);\n+            // Start as many workers as fit into the searchable snapshot pool at once at the most\n+            final int workers = Math.min(threadPool.info(SEARCHABLE_SNAPSHOTS_THREAD_POOL_NAME).getMax(), queue.size());\n+            for (int i = 0; i < workers; ++i) {\n+                prewarmNextFile(executor, queue);\n+            }\n+        }\n+    }\n+\n+    private void prewarmNextFile(final Executor executor, final BlockingQueue<BlobStoreIndexShardSnapshot.FileInfo> queue) {\n+        executor.execute(new AbstractRunnable() {\n+            @Override\n+            protected void doRun() throws Exception {\n+                final BlobStoreIndexShardSnapshot.FileInfo file = queue.poll(0L, TimeUnit.MILLISECONDS);\n+                if (file != null) {\n+                    final IndexInput input = openInput(file.physicalName(), CachedBlobContainerIndexInput.CACHE_WARMING_CONTEXT);\n                     assert input instanceof CachedBlobContainerIndexInput : \"expected cached index input but got \" + input.getClass();\n \n-                    final long numberOfParts = cacheFile.numberOfParts();\n-                    final CountDown countDown = new CountDown(Math.toIntExact(numberOfParts));\n-                    for (long p = 0; p < numberOfParts; p++) {\n-                        final int part = Math.toIntExact(p);\n-                        // TODO use multiple workers to warm each part instead of filling the thread pool\n-                        executor.execute(new AbstractRunnable() {\n-                            @Override\n-                            protected void doRun() throws Exception {\n-                                ensureOpen();\n-\n-                                logger.trace(\"warming cache for [{}] part [{}/{}]\", fileName, part, numberOfParts);\n-                                final long startTimeInNanos = statsCurrentTimeNanosSupplier.getAsLong();\n-\n-                                final CachedBlobContainerIndexInput cachedIndexInput = (CachedBlobContainerIndexInput) input.clone();\n-                                cachedIndexInput.prefetchPart(part); // TODO does not include any rate limitation\n-\n-                                logger.trace(\n-                                    () -> new ParameterizedMessage(\n-                                        \"part [{}/{}] of [{}] warmed in [{}] ms\",\n-                                        part,\n-                                        numberOfParts,\n-                                        fileName,\n-                                        TimeValue.timeValueNanos(statsCurrentTimeNanosSupplier.getAsLong() - startTimeInNanos).millis()\n-                                    )\n-                                );\n-                            }\n-\n-                            @Override\n-                            public void onFailure(Exception e) {\n-                                logger.trace(\n-                                    () -> new ParameterizedMessage(\n-                                        \"failed to warm cache for [{}] part [{}/{}]\",\n-                                        fileName,\n-                                        part,\n-                                        numberOfParts\n-                                    ),\n-                                    e\n-                                );\n-                            }\n-\n-                            @Override\n-                            public void onAfter() {\n-                                if (countDown.countDown()) {\n-                                    IOUtils.closeWhileHandlingException(input);\n-                                }\n-                            }\n-                        });\n+                    final int numberOfParts = Math.toIntExact(file.numberOfParts());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d9d5b6ac8894771b0b6a1de023960c9bd03d3b8"}, "originalPosition": 113}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dc6d484930a61310a64020fb44dbe912c65d72fc", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/dc6d484930a61310a64020fb44dbe912c65d72fc", "committedDate": "2020-05-04T11:13:05Z", "message": "branch early"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "47b2f0e5e175111adc1937d0884b2246579f3727", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/47b2f0e5e175111adc1937d0884b2246579f3727", "committedDate": "2020-05-04T11:24:13Z", "message": "case 1"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fffc4cf388fbe10dc184b5a823bedf76144bd371", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/fffc4cf388fbe10dc184b5a823bedf76144bd371", "committedDate": "2020-05-04T12:10:12Z", "message": "Merge branch 'master' into use-worker-to-warm-cache"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA0OTgyNTYz", "url": "https://github.com/elastic/elasticsearch/pull/55793#pullrequestreview-404982563", "createdAt": "2020-05-04T13:24:36Z", "commit": {"oid": "fffc4cf388fbe10dc184b5a823bedf76144bd371"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMzoyNDozNlrOGQAH7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMzozOTowOFrOGQAwZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQzMjQzMQ==", "bodyText": "Not sure it's a big deal but I guess we could always use the current thread for one part:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                warmExecutor.execute(ActionRunnable.run(listener, () -> {\n          \n          \n            \n                                 final Executor warmExecutor = (p < numberOfParts - 1) ? executor : EsExecutors.newDirectExecutorService();\n          \n          \n            \n                                warmExecutor.execute(ActionRunnable.run(listener, () -> {", "url": "https://github.com/elastic/elasticsearch/pull/55793#discussion_r419432431", "createdAt": "2020-05-04T13:24:36Z", "author": {"login": "DaveCTurner"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -352,76 +358,78 @@ public String toString() {\n \n     private void prewarmCache() {\n         if (prewarmCache) {\n-            final List<BlobStoreIndexShardSnapshot.FileInfo> cacheFiles = snapshot().indexFiles()\n+            final BlockingQueue<BlobStoreIndexShardSnapshot.FileInfo> queue = snapshot().indexFiles()\n                 .stream()\n                 .filter(file -> file.metadata().hashEqualsContents() == false)\n                 .filter(file -> isExcludedFromCache(file.physicalName()) == false)\n-                .collect(Collectors.toList());\n+                .collect(Collectors.toCollection(LinkedBlockingQueue::new));\n \n             final Executor executor = threadPool.executor(SEARCHABLE_SNAPSHOTS_THREAD_POOL_NAME);\n-            logger.debug(\"{} warming shard cache for [{}] files\", shardId, cacheFiles.size());\n-\n-            for (BlobStoreIndexShardSnapshot.FileInfo cacheFile : cacheFiles) {\n-                final String fileName = cacheFile.physicalName();\n-                try {\n-                    final IndexInput input = openInput(fileName, CachedBlobContainerIndexInput.CACHE_WARMING_CONTEXT);\n-                    assert input instanceof CachedBlobContainerIndexInput : \"expected cached index input but got \" + input.getClass();\n-\n-                    final long numberOfParts = cacheFile.numberOfParts();\n-                    final CountDown countDown = new CountDown(Math.toIntExact(numberOfParts));\n-                    for (long p = 0; p < numberOfParts; p++) {\n-                        final int part = Math.toIntExact(p);\n-                        // TODO use multiple workers to warm each part instead of filling the thread pool\n-                        executor.execute(new AbstractRunnable() {\n-                            @Override\n-                            protected void doRun() throws Exception {\n-                                ensureOpen();\n-\n-                                logger.trace(\"warming cache for [{}] part [{}/{}]\", fileName, part, numberOfParts);\n-                                final long startTimeInNanos = statsCurrentTimeNanosSupplier.getAsLong();\n-\n-                                final CachedBlobContainerIndexInput cachedIndexInput = (CachedBlobContainerIndexInput) input.clone();\n-                                cachedIndexInput.prefetchPart(part); // TODO does not include any rate limitation\n-\n-                                logger.trace(\n-                                    () -> new ParameterizedMessage(\n-                                        \"part [{}/{}] of [{}] warmed in [{}] ms\",\n-                                        part,\n-                                        numberOfParts,\n-                                        fileName,\n-                                        TimeValue.timeValueNanos(statsCurrentTimeNanosSupplier.getAsLong() - startTimeInNanos).millis()\n-                                    )\n-                                );\n-                            }\n-\n-                            @Override\n-                            public void onFailure(Exception e) {\n-                                logger.trace(\n-                                    () -> new ParameterizedMessage(\n-                                        \"failed to warm cache for [{}] part [{}/{}]\",\n-                                        fileName,\n-                                        part,\n-                                        numberOfParts\n-                                    ),\n-                                    e\n-                                );\n-                            }\n-\n-                            @Override\n-                            public void onAfter() {\n-                                if (countDown.countDown()) {\n-                                    IOUtils.closeWhileHandlingException(input);\n-                                }\n-                            }\n-                        });\n-                    }\n-                } catch (IOException e) {\n-                    logger.trace(() -> new ParameterizedMessage(\"failed to warm cache for [{}]\", fileName), e);\n-                }\n+            logger.debug(\"{} warming shard cache for [{}] files\", shardId, queue.size());\n+\n+            // Start as many workers as fit into the searchable snapshot pool at once at the most\n+            final int workers = Math.min(threadPool.info(SEARCHABLE_SNAPSHOTS_THREAD_POOL_NAME).getMax(), queue.size());\n+            for (int i = 0; i < workers; ++i) {\n+                prewarmNextFile(executor, queue);\n             }\n         }\n     }\n \n+    private void prewarmNextFile(final Executor executor, final BlockingQueue<BlobStoreIndexShardSnapshot.FileInfo> queue) {\n+        executor.execute(new AbstractRunnable() {\n+            @Override\n+            protected void doRun() throws Exception {\n+                final BlobStoreIndexShardSnapshot.FileInfo file = queue.poll(0L, TimeUnit.MILLISECONDS);\n+                if (file == null) {\n+                    return;\n+                }\n+\n+                final IndexInput input = openInput(file.physicalName(), CachedBlobContainerIndexInput.CACHE_WARMING_CONTEXT);\n+                assert input instanceof CachedBlobContainerIndexInput : \"expected cached index input but got \" + input.getClass();\n+\n+                final int numberOfParts = Math.toIntExact(file.numberOfParts());\n+                final GroupedActionListener<Void> listener = new GroupedActionListener<>(\n+                    ActionListener.runAfter(\n+                        ActionListener.wrap(() -> IOUtils.closeWhileHandlingException(input)),\n+                        () -> prewarmNextFile(executor, queue)\n+                    ),\n+                    numberOfParts\n+                );\n+\n+                // if the file to prewarm is composed of a single part then it is prewarmed using the current thread\n+                final Executor warmExecutor = (numberOfParts > 1) ? executor : EsExecutors.newDirectExecutorService();\n+\n+                for (int p = 0; p < numberOfParts; p++) {\n+                    final int part = p;\n+                    warmExecutor.execute(ActionRunnable.run(listener, () -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fffc4cf388fbe10dc184b5a823bedf76144bd371"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQzNzQwNg==", "bodyText": "I think this means we use IOUtils.closeWhileHandlingException even when not handling an exception, which sounds wrong to me.", "url": "https://github.com/elastic/elasticsearch/pull/55793#discussion_r419437406", "createdAt": "2020-05-04T13:31:22Z", "author": {"login": "DaveCTurner"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -352,76 +358,78 @@ public String toString() {\n \n     private void prewarmCache() {\n         if (prewarmCache) {\n-            final List<BlobStoreIndexShardSnapshot.FileInfo> cacheFiles = snapshot().indexFiles()\n+            final BlockingQueue<BlobStoreIndexShardSnapshot.FileInfo> queue = snapshot().indexFiles()\n                 .stream()\n                 .filter(file -> file.metadata().hashEqualsContents() == false)\n                 .filter(file -> isExcludedFromCache(file.physicalName()) == false)\n-                .collect(Collectors.toList());\n+                .collect(Collectors.toCollection(LinkedBlockingQueue::new));\n \n             final Executor executor = threadPool.executor(SEARCHABLE_SNAPSHOTS_THREAD_POOL_NAME);\n-            logger.debug(\"{} warming shard cache for [{}] files\", shardId, cacheFiles.size());\n-\n-            for (BlobStoreIndexShardSnapshot.FileInfo cacheFile : cacheFiles) {\n-                final String fileName = cacheFile.physicalName();\n-                try {\n-                    final IndexInput input = openInput(fileName, CachedBlobContainerIndexInput.CACHE_WARMING_CONTEXT);\n-                    assert input instanceof CachedBlobContainerIndexInput : \"expected cached index input but got \" + input.getClass();\n-\n-                    final long numberOfParts = cacheFile.numberOfParts();\n-                    final CountDown countDown = new CountDown(Math.toIntExact(numberOfParts));\n-                    for (long p = 0; p < numberOfParts; p++) {\n-                        final int part = Math.toIntExact(p);\n-                        // TODO use multiple workers to warm each part instead of filling the thread pool\n-                        executor.execute(new AbstractRunnable() {\n-                            @Override\n-                            protected void doRun() throws Exception {\n-                                ensureOpen();\n-\n-                                logger.trace(\"warming cache for [{}] part [{}/{}]\", fileName, part, numberOfParts);\n-                                final long startTimeInNanos = statsCurrentTimeNanosSupplier.getAsLong();\n-\n-                                final CachedBlobContainerIndexInput cachedIndexInput = (CachedBlobContainerIndexInput) input.clone();\n-                                cachedIndexInput.prefetchPart(part); // TODO does not include any rate limitation\n-\n-                                logger.trace(\n-                                    () -> new ParameterizedMessage(\n-                                        \"part [{}/{}] of [{}] warmed in [{}] ms\",\n-                                        part,\n-                                        numberOfParts,\n-                                        fileName,\n-                                        TimeValue.timeValueNanos(statsCurrentTimeNanosSupplier.getAsLong() - startTimeInNanos).millis()\n-                                    )\n-                                );\n-                            }\n-\n-                            @Override\n-                            public void onFailure(Exception e) {\n-                                logger.trace(\n-                                    () -> new ParameterizedMessage(\n-                                        \"failed to warm cache for [{}] part [{}/{}]\",\n-                                        fileName,\n-                                        part,\n-                                        numberOfParts\n-                                    ),\n-                                    e\n-                                );\n-                            }\n-\n-                            @Override\n-                            public void onAfter() {\n-                                if (countDown.countDown()) {\n-                                    IOUtils.closeWhileHandlingException(input);\n-                                }\n-                            }\n-                        });\n-                    }\n-                } catch (IOException e) {\n-                    logger.trace(() -> new ParameterizedMessage(\"failed to warm cache for [{}]\", fileName), e);\n-                }\n+            logger.debug(\"{} warming shard cache for [{}] files\", shardId, queue.size());\n+\n+            // Start as many workers as fit into the searchable snapshot pool at once at the most\n+            final int workers = Math.min(threadPool.info(SEARCHABLE_SNAPSHOTS_THREAD_POOL_NAME).getMax(), queue.size());\n+            for (int i = 0; i < workers; ++i) {\n+                prewarmNextFile(executor, queue);\n             }\n         }\n     }\n \n+    private void prewarmNextFile(final Executor executor, final BlockingQueue<BlobStoreIndexShardSnapshot.FileInfo> queue) {\n+        executor.execute(new AbstractRunnable() {\n+            @Override\n+            protected void doRun() throws Exception {\n+                final BlobStoreIndexShardSnapshot.FileInfo file = queue.poll(0L, TimeUnit.MILLISECONDS);\n+                if (file == null) {\n+                    return;\n+                }\n+\n+                final IndexInput input = openInput(file.physicalName(), CachedBlobContainerIndexInput.CACHE_WARMING_CONTEXT);\n+                assert input instanceof CachedBlobContainerIndexInput : \"expected cached index input but got \" + input.getClass();\n+\n+                final int numberOfParts = Math.toIntExact(file.numberOfParts());\n+                final GroupedActionListener<Void> listener = new GroupedActionListener<>(\n+                    ActionListener.runAfter(\n+                        ActionListener.wrap(() -> IOUtils.closeWhileHandlingException(input)),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fffc4cf388fbe10dc184b5a823bedf76144bd371"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ0Mjc4OQ==", "bodyText": "IIUC this means we wait for all parts of this file to be warmed before starting on the next file, which sounds like it might under-utilise the available threads. Could we use something cleverer than a Queue<FileInfo> to track the progress of the work in terms of parts that keeps all the threads busy until the very end?", "url": "https://github.com/elastic/elasticsearch/pull/55793#discussion_r419442789", "createdAt": "2020-05-04T13:39:08Z", "author": {"login": "DaveCTurner"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -352,76 +358,78 @@ public String toString() {\n \n     private void prewarmCache() {\n         if (prewarmCache) {\n-            final List<BlobStoreIndexShardSnapshot.FileInfo> cacheFiles = snapshot().indexFiles()\n+            final BlockingQueue<BlobStoreIndexShardSnapshot.FileInfo> queue = snapshot().indexFiles()\n                 .stream()\n                 .filter(file -> file.metadata().hashEqualsContents() == false)\n                 .filter(file -> isExcludedFromCache(file.physicalName()) == false)\n-                .collect(Collectors.toList());\n+                .collect(Collectors.toCollection(LinkedBlockingQueue::new));\n \n             final Executor executor = threadPool.executor(SEARCHABLE_SNAPSHOTS_THREAD_POOL_NAME);\n-            logger.debug(\"{} warming shard cache for [{}] files\", shardId, cacheFiles.size());\n-\n-            for (BlobStoreIndexShardSnapshot.FileInfo cacheFile : cacheFiles) {\n-                final String fileName = cacheFile.physicalName();\n-                try {\n-                    final IndexInput input = openInput(fileName, CachedBlobContainerIndexInput.CACHE_WARMING_CONTEXT);\n-                    assert input instanceof CachedBlobContainerIndexInput : \"expected cached index input but got \" + input.getClass();\n-\n-                    final long numberOfParts = cacheFile.numberOfParts();\n-                    final CountDown countDown = new CountDown(Math.toIntExact(numberOfParts));\n-                    for (long p = 0; p < numberOfParts; p++) {\n-                        final int part = Math.toIntExact(p);\n-                        // TODO use multiple workers to warm each part instead of filling the thread pool\n-                        executor.execute(new AbstractRunnable() {\n-                            @Override\n-                            protected void doRun() throws Exception {\n-                                ensureOpen();\n-\n-                                logger.trace(\"warming cache for [{}] part [{}/{}]\", fileName, part, numberOfParts);\n-                                final long startTimeInNanos = statsCurrentTimeNanosSupplier.getAsLong();\n-\n-                                final CachedBlobContainerIndexInput cachedIndexInput = (CachedBlobContainerIndexInput) input.clone();\n-                                cachedIndexInput.prefetchPart(part); // TODO does not include any rate limitation\n-\n-                                logger.trace(\n-                                    () -> new ParameterizedMessage(\n-                                        \"part [{}/{}] of [{}] warmed in [{}] ms\",\n-                                        part,\n-                                        numberOfParts,\n-                                        fileName,\n-                                        TimeValue.timeValueNanos(statsCurrentTimeNanosSupplier.getAsLong() - startTimeInNanos).millis()\n-                                    )\n-                                );\n-                            }\n-\n-                            @Override\n-                            public void onFailure(Exception e) {\n-                                logger.trace(\n-                                    () -> new ParameterizedMessage(\n-                                        \"failed to warm cache for [{}] part [{}/{}]\",\n-                                        fileName,\n-                                        part,\n-                                        numberOfParts\n-                                    ),\n-                                    e\n-                                );\n-                            }\n-\n-                            @Override\n-                            public void onAfter() {\n-                                if (countDown.countDown()) {\n-                                    IOUtils.closeWhileHandlingException(input);\n-                                }\n-                            }\n-                        });\n-                    }\n-                } catch (IOException e) {\n-                    logger.trace(() -> new ParameterizedMessage(\"failed to warm cache for [{}]\", fileName), e);\n-                }\n+            logger.debug(\"{} warming shard cache for [{}] files\", shardId, queue.size());\n+\n+            // Start as many workers as fit into the searchable snapshot pool at once at the most\n+            final int workers = Math.min(threadPool.info(SEARCHABLE_SNAPSHOTS_THREAD_POOL_NAME).getMax(), queue.size());\n+            for (int i = 0; i < workers; ++i) {\n+                prewarmNextFile(executor, queue);\n             }\n         }\n     }\n \n+    private void prewarmNextFile(final Executor executor, final BlockingQueue<BlobStoreIndexShardSnapshot.FileInfo> queue) {\n+        executor.execute(new AbstractRunnable() {\n+            @Override\n+            protected void doRun() throws Exception {\n+                final BlobStoreIndexShardSnapshot.FileInfo file = queue.poll(0L, TimeUnit.MILLISECONDS);\n+                if (file == null) {\n+                    return;\n+                }\n+\n+                final IndexInput input = openInput(file.physicalName(), CachedBlobContainerIndexInput.CACHE_WARMING_CONTEXT);\n+                assert input instanceof CachedBlobContainerIndexInput : \"expected cached index input but got \" + input.getClass();\n+\n+                final int numberOfParts = Math.toIntExact(file.numberOfParts());\n+                final GroupedActionListener<Void> listener = new GroupedActionListener<>(\n+                    ActionListener.runAfter(\n+                        ActionListener.wrap(() -> IOUtils.closeWhileHandlingException(input)),\n+                        () -> prewarmNextFile(executor, queue)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fffc4cf388fbe10dc184b5a823bedf76144bd371"}, "originalPosition": 128}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1bffb66766ad3dc53548c6c759c854ce4ffcee17", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/1bffb66766ad3dc53548c6c759c854ce4ffcee17", "committedDate": "2020-05-04T13:42:14Z", "message": "yuuup"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA1MDAxMzcy", "url": "https://github.com/elastic/elasticsearch/pull/55793#pullrequestreview-405001372", "createdAt": "2020-05-04T13:45:49Z", "commit": {"oid": "1bffb66766ad3dc53548c6c759c854ce4ffcee17"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8a1045ee44fe3db2ab3fcc7e548da79a811ea907", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/8a1045ee44fe3db2ab3fcc7e548da79a811ea907", "committedDate": "2020-05-04T13:58:09Z", "message": "use direct exec also for last part"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e89213eef5621d776539bfa7391a4ddb8027a887", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/e89213eef5621d776539bfa7391a4ddb8027a887", "committedDate": "2020-05-04T14:02:49Z", "message": "wrap differently"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1aea98042c48781b63edd56be0e4b17ceeca07f8", "author": {"user": {"login": "tlrx", "name": "Tanguy Leroux"}}, "url": "https://github.com/elastic/elasticsearch/commit/1aea98042c48781b63edd56be0e4b17ceeca07f8", "committedDate": "2020-05-04T15:11:44Z", "message": "David's feedback"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA1MTExNTQy", "url": "https://github.com/elastic/elasticsearch/pull/55793#pullrequestreview-405111542", "createdAt": "2020-05-04T15:44:23Z", "commit": {"oid": "1aea98042c48781b63edd56be0e4b17ceeca07f8"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA1NTg4MDA5", "url": "https://github.com/elastic/elasticsearch/pull/55793#pullrequestreview-405588009", "createdAt": "2020-05-05T08:31:29Z", "commit": {"oid": "1aea98042c48781b63edd56be0e4b17ceeca07f8"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 426, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}