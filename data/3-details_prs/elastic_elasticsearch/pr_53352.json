{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg2MjgyNDg4", "number": 53352, "title": "Encrypted blob store reuse DEK", "bodyText": "EDITED 20.03.20 the repository secret is a textual password not a binary AES key\nFollows the approach described in #50846 (comment)\nThis builds upon the data encryption streams from #49896 to create an encrypted snapshot repository.\nThe repository encryption works with the following existing repository types: FS, Azure, S3, GCS (possibly works with HDFS and URL, but these are not tested).\nThe encrypted repository is protected by a 256-bit AES key password stored on every node's keystore. The repository keys (KEK - key encryption key) are generated from the password using the PBKDF2 function, and are used to encrypt (using the AES Wrap algorithm) other symmetric keys (referred to as DEK - data encryption keys) which are themselves used to encrypt the blobs of the regular snapshot.\nThe platinum license is required to snapshot to the encrypted repository, but no license is required to list or restore already encrypted snapshots.\nExample of how to use the Encrypted FS Repository:\n\npull down this branch and assemble the jar (./gradlew :distribution:archives:no-jdk-darwin-tar:assemble)\nsimilarly to the un-encrypted FS repository, specify the mount point of the shared FS in the elasticsearch.yml conf file (on all the cluster nodes), eg: path.repo: [\"/tmp/repo\"]\nmake sure the cluster runs under a trial license (simplest configuration is to put xpack.security.license.self_generated.type: true in the elasticsearch.yml file\ngenerate the master 256-bit repository key (KEK)\n\n#openssl rand 32 > repository_keyfile.key\n\n\nstore the key password inside the elasticsearch.keystore, on every cluster's node, eg for the test_enc_key test_enc_pass repository key password name:\n\n#./bin/elasticsearch-keystore add-file repository.encrypted.test_enc_key.key repository_keyfile.key\n./bin/elasticsearch-keystore add repository.encrypted.test_enc_pass.password\n\n\nstart-up the cluster, and create the new encrypted repository, eg:\n\ncurl -X PUT \"localhost:9200/_snapshot/test_enc?pretty\" -H 'Content-Type: application/json' -d'\n{\n  \"type\": \"encrypted\",\n  \"settings\": {\n    \"location\": \"/tmp/repo/enc\",\n    \"delegate_type\": \"fs\",\n    \"password_name\": \"test_enc_pass\"\n  }\n}\n'\n\nRelates #49896\nRelates #41910\nObsoletes #50846 #48221", "createdAt": "2020-03-10T17:58:58Z", "url": "https://github.com/elastic/elasticsearch/pull/53352", "merged": true, "mergeCommit": {"oid": "3249cc36be708c771b4b6b6c3b6aae1abc22a6f7"}, "closed": true, "closedAt": "2020-12-02T14:08:56Z", "author": {"login": "albertzaharovits"}, "timelineItems": {"totalCount": 28, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcPhhb2AFqTM3ODQyNzMzOQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdiOWmagH2gAyMzg2MjgyNDg4OmMxNTg1MzI3Y2Q4ODVkMjEwMGU2MGE4NWYyY2M5YTgxMGFkZjE0NzY=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc4NDI3MzM5", "url": "https://github.com/elastic/elasticsearch/pull/53352#pullrequestreview-378427339", "createdAt": "2020-03-20T12:07:09Z", "commit": {"oid": "097393b25d57aae0527eb87de4e0abefec891218"}, "state": "COMMENTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMjowNzowOVrOF5RIUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMzoyNDo1NVrOF5ThGw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU5MzgwOA==", "bodyText": "Not important, but do we need the random base path here?", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r395593808", "createdAt": "2020-03-20T12:07:09Z", "author": {"login": "original-brownbear"}, "path": "plugins/repository-azure/src/test/java/org/elasticsearch/repositories/azure/AzureBlobStoreRepositoryTests.java", "diffHunk": "@@ -50,11 +50,14 @@ protected String repositoryType() {\n \n     @Override\n     protected Settings repositorySettings() {\n-        return Settings.builder()\n+        Settings.Builder settingsBuilder = Settings.builder()\n             .put(super.repositorySettings())\n             .put(AzureRepository.Repository.CONTAINER_SETTING.getKey(), \"container\")\n-            .put(AzureStorageSettings.ACCOUNT_SETTING.getKey(), \"test\")\n-            .build();\n+            .put(AzureStorageSettings.ACCOUNT_SETTING.getKey(), \"test\");\n+        if (randomBoolean()) {\n+            settingsBuilder.put(AzureRepository.Repository.BASE_PATH_SETTING.getKey(), randomFrom(\"test\", \"test/1\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "097393b25d57aae0527eb87de4e0abefec891218"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU5NTU5OQ==", "bodyText": "Why do we want to randomly turn off verification in the general case? It seems that takes away from our chances to catch some IO issues here and there? Maybe we should make this always verify and selective turn off verification where we really need it?", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r395595599", "createdAt": "2020-03-20T12:10:54Z", "author": {"login": "original-brownbear"}, "path": "test/framework/src/main/java/org/elasticsearch/repositories/blobstore/ESBlobStoreRepositoryIntegTestCase.java", "diffHunk": "@@ -81,13 +83,15 @@ protected Settings repositorySettings() {\n         return Settings.builder().put(\"compress\", randomBoolean()).build();\n     }\n \n-    protected final String createRepository(final String name) {\n-        return createRepository(name, repositorySettings());\n+    protected Settings repositorySettings(String repositoryName) {\n+        return Settings.EMPTY;\n     }\n \n-    protected final String createRepository(final String name, final Settings settings) {\n-        final boolean verify = randomBoolean();\n+    protected final String createRepository(final String name) {\n+        return createRepository(name, Settings.builder().put(repositorySettings()).put(repositorySettings(name)).build(), randomBoolean());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "097393b25d57aae0527eb87de4e0abefec891218"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYwMTg2OQ==", "bodyText": "NIT: Maybe call this additionalRepositorySettings? Or better yet + in the sense of simplicity, maybe just add the repositoryName parameter to the existing repositorySettings() method? That way we don't have to complicate the repo creation code.", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r395601869", "createdAt": "2020-03-20T12:24:55Z", "author": {"login": "original-brownbear"}, "path": "test/framework/src/main/java/org/elasticsearch/repositories/blobstore/ESBlobStoreRepositoryIntegTestCase.java", "diffHunk": "@@ -81,13 +83,15 @@ protected Settings repositorySettings() {\n         return Settings.builder().put(\"compress\", randomBoolean()).build();\n     }\n \n-    protected final String createRepository(final String name) {\n-        return createRepository(name, repositorySettings());\n+    protected Settings repositorySettings(String repositoryName) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "097393b25d57aae0527eb87de4e0abefec891218"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYwNDkxMQ==", "bodyText": "I think you can just assert on e.repository() here and delete the \"missing\" assertion, that part really is implied by the exception type :)\nOr you could just not assert on the message at all IMO.", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r395604911", "createdAt": "2020-03-20T12:31:18Z", "author": {"login": "original-brownbear"}, "path": "test/framework/src/main/java/org/elasticsearch/repositories/blobstore/ESBlobStoreRepositoryIntegTestCase.java", "diffHunk": "@@ -97,14 +101,27 @@ protected final String createRepository(final String name, final Settings settin\n         internalCluster().getDataOrMasterNodeInstances(RepositoriesService.class).forEach(repositories -> {\n             assertThat(repositories.repository(name), notNullValue());\n             assertThat(repositories.repository(name), instanceOf(BlobStoreRepository.class));\n-            assertThat(repositories.repository(name).isReadOnly(), is(false));\n+            assertThat(repositories.repository(name).isReadOnly(), is(settings.getAsBoolean(\"readonly\", false)));\n             BlobStore blobStore = ((BlobStoreRepository) repositories.repository(name)).getBlobStore();\n             assertThat(\"blob store has to be lazy initialized\", blobStore, verify ? is(notNullValue()) : is(nullValue()));\n         });\n \n         return name;\n     }\n \n+    protected final String deleteRepository(final String name) {\n+        logger.debug(\"-->  deleting repository [name: {}]\", name);\n+        assertAcked(client().admin().cluster().prepareDeleteRepository(name));\n+\n+        internalCluster().getDataOrMasterNodeInstances(RepositoriesService.class).forEach(repositories -> {\n+            RepositoryMissingException e = expectThrows(RepositoryMissingException.class, () -> repositories.repository(name));\n+            assertThat(e.getMessage(), containsString(\"missing\"));\n+            assertThat(e.getMessage(), containsString(name));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "097393b25d57aae0527eb87de4e0abefec891218"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYwNTMwMQ==", "bodyText": "You never use the return here and it seems pointless since it's just the method input?", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r395605301", "createdAt": "2020-03-20T12:32:03Z", "author": {"login": "original-brownbear"}, "path": "test/framework/src/main/java/org/elasticsearch/repositories/blobstore/ESBlobStoreRepositoryIntegTestCase.java", "diffHunk": "@@ -97,14 +101,27 @@ protected final String createRepository(final String name, final Settings settin\n         internalCluster().getDataOrMasterNodeInstances(RepositoriesService.class).forEach(repositories -> {\n             assertThat(repositories.repository(name), notNullValue());\n             assertThat(repositories.repository(name), instanceOf(BlobStoreRepository.class));\n-            assertThat(repositories.repository(name).isReadOnly(), is(false));\n+            assertThat(repositories.repository(name).isReadOnly(), is(settings.getAsBoolean(\"readonly\", false)));\n             BlobStore blobStore = ((BlobStoreRepository) repositories.repository(name)).getBlobStore();\n             assertThat(\"blob store has to be lazy initialized\", blobStore, verify ? is(notNullValue()) : is(nullValue()));\n         });\n \n         return name;\n     }\n \n+    protected final String deleteRepository(final String name) {\n+        logger.debug(\"-->  deleting repository [name: {}]\", name);\n+        assertAcked(client().admin().cluster().prepareDeleteRepository(name));\n+\n+        internalCluster().getDataOrMasterNodeInstances(RepositoriesService.class).forEach(repositories -> {\n+            RepositoryMissingException e = expectThrows(RepositoryMissingException.class, () -> repositories.repository(name));\n+            assertThat(e.getMessage(), containsString(\"missing\"));\n+            assertThat(e.getMessage(), containsString(name));\n+        });\n+\n+        return name;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "097393b25d57aae0527eb87de4e0abefec891218"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYwODM5NQ==", "bodyText": "NIT: Maybe it's easier to follow this logic if you just add a method:\nassertBlobSize(BlobMeta meta, long contentLength)\n\nand then use it here and override in the encrypted tests? (I think it saves a little complication and it's what we do for a bunch of other repo related assertions)", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r395608395", "createdAt": "2020-03-20T12:38:19Z", "author": {"login": "original-brownbear"}, "path": "test/framework/src/main/java/org/elasticsearch/repositories/blobstore/ESBlobStoreRepositoryIntegTestCase.java", "diffHunk": "@@ -175,7 +192,7 @@ public void testList() throws IOException {\n                 BlobMetaData blobMetaData = blobs.get(generated.getKey());\n                 assertThat(generated.getKey(), blobMetaData, CoreMatchers.notNullValue());\n                 assertThat(blobMetaData.name(), CoreMatchers.equalTo(generated.getKey()));\n-                assertThat(blobMetaData.length(), CoreMatchers.equalTo(generated.getValue()));\n+                assertThat(blobMetaData.length(), CoreMatchers.equalTo(blobLengthFromContentLength(generated.getValue())));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "097393b25d57aae0527eb87de4e0abefec891218"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYwODkxMw==", "bodyText": "Revert formatting changes here?", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r395608913", "createdAt": "2020-03-20T12:39:24Z", "author": {"login": "original-brownbear"}, "path": "test/framework/src/main/java/org/elasticsearch/repositories/blobstore/ESBlobStoreRepositoryIntegTestCase.java", "diffHunk": "@@ -262,15 +279,21 @@ protected static void writeBlob(BlobContainer container, String blobName, BytesA\n     }\n \n     protected BlobStore newBlobStore() {\n-        final String repository = createRepository(randomName());\n+        final String repository = createRepository(randomRepositoryName());\n+        return newBlobStore(repository);\n+    }\n+\n+    protected BlobStore newBlobStore(String repository) {\n         final BlobStoreRepository blobStoreRepository =\n-            (BlobStoreRepository) internalCluster().getMasterNodeInstance(RepositoriesService.class).repository(repository);\n+                (BlobStoreRepository) internalCluster().getMasterNodeInstance(RepositoriesService.class).repository(repository);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "097393b25d57aae0527eb87de4e0abefec891218"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYxMDc4MA==", "bodyText": "NIT: maybe rename to something like assertEmptyRepo or so that has assert in the name?", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r395610780", "createdAt": "2020-03-20T12:43:11Z", "author": {"login": "original-brownbear"}, "path": "test/framework/src/main/java/org/elasticsearch/repositories/blobstore/ESMockAPIBasedRepositoryIntegTestCase.java", "diffHunk": "@@ -107,14 +107,17 @@ public void tearDownHttpServer() {\n             for(Map.Entry<String, HttpHandler> handler : handlers.entrySet()) {\n                 httpServer.removeContext(handler.getKey());\n                 if (handler.getValue() instanceof BlobStoreHttpHandler) {\n-                    List<String> blobs = ((BlobStoreHttpHandler) handler.getValue()).blobs().keySet().stream()\n-                        .filter(blob -> blob.contains(\"index\") == false).collect(Collectors.toList());\n-                    assertThat(\"Only index blobs should remain in repository but found \" + blobs, blobs, hasSize(0));\n+                    blobsOnTearDown(((BlobStoreHttpHandler) handler.getValue()).blobs());\n                 }\n             }\n         }\n     }\n \n+    protected void blobsOnTearDown(Map<String, BytesReference> blobsMap) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "097393b25d57aae0527eb87de4e0abefec891218"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYxMzU3MQ==", "bodyText": "NIT: just call randomName here?", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r395613571", "createdAt": "2020-03-20T12:48:59Z", "author": {"login": "original-brownbear"}, "path": "test/framework/src/main/java/org/elasticsearch/repositories/blobstore/ESBlobStoreRepositoryIntegTestCase.java", "diffHunk": "@@ -493,7 +521,15 @@ private static void assertSuccessfulRestore(RestoreSnapshotResponse response) {\n         assertThat(response.getRestoreInfo().successfulShards(), equalTo(response.getRestoreInfo().totalShards()));\n     }\n \n-    protected static String randomName() {\n+    protected String randomName() {\n         return randomAlphaOfLength(randomIntBetween(1, 10)).toLowerCase(Locale.ROOT);\n     }\n+\n+    protected String randomRepositoryName() {\n+        return randomAlphaOfLength(randomIntBetween(1, 10)).toLowerCase(Locale.ROOT);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "097393b25d57aae0527eb87de4e0abefec891218"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYzMjkyMw==", "bodyText": "Hmm I'm not a big fan of this kind of unwrapping. We're losing part of the stacktrace here and it may be painful to understand (test-)failures because of it?", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r395632923", "createdAt": "2020-03-20T13:24:55Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepository.java", "diffHunk": "@@ -6,11 +6,562 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n-public class EncryptedRepository {\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.lucene.index.IndexCommit;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.metadata.MetaData;\n+import org.elasticsearch.cluster.metadata.RepositoryMetaData;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.CheckedFunction;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.blobstore.BlobContainer;\n+import org.elasticsearch.common.blobstore.BlobMetaData;\n+import org.elasticsearch.common.blobstore.BlobPath;\n+import org.elasticsearch.common.blobstore.BlobStore;\n+import org.elasticsearch.common.blobstore.DeleteResult;\n+import org.elasticsearch.common.blobstore.support.AbstractBlobContainer;\n+import org.elasticsearch.common.cache.Cache;\n+import org.elasticsearch.common.cache.CacheBuilder;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.index.store.Store;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoryException;\n+import org.elasticsearch.repositories.ShardGenerations;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.SnapshotInfo;\n+import org.elasticsearch.snapshots.SnapshotShardFailure;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.SecretKey;\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.NoSuchFileException;\n+import java.security.GeneralSecurityException;\n+import java.security.SecureRandom;\n+import java.util.Base64;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+public final class EncryptedRepository extends BlobStoreRepository {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepository.class);\n+    // the following constants are fixed by definition\n     static final int GCM_TAG_LENGTH_IN_BYTES = 16;\n     static final int GCM_IV_LENGTH_IN_BYTES = 12;\n-    static final int AES_BLOCK_SIZE_IN_BYTES = 128;\n-    static final String GCM_ENCRYPTION_SCHEME = \"AES/GCM/NoPadding\";\n+    static final int AES_BLOCK_LENGTH_IN_BYTES = 128;\n+    // the following constants require careful thought before changing because they will break backwards compatibility\n+    static final String DATA_ENCRYPTION_SCHEME = \"AES/GCM/NoPadding\";\n     static final long PACKET_START_COUNTER = Long.MIN_VALUE;\n-    static final int MAX_PACKET_LENGTH_IN_BYTES = 1 << 30;\n+    static final int MAX_PACKET_LENGTH_IN_BYTES = 8 << 20; // 8MB\n+    // this should be smaller than {@code #MAX_PACKET_LENGTH_IN_BYTES} and it's what {@code EncryptionPacketsInputStream} uses\n+    // during encryption and what {@code DecryptionPacketsInputStream} expects during decryption (it is not configurable)\n+    static final int PACKET_LENGTH_IN_BYTES = 64 * (1 << 10); // 64KB\n+    // the path of the blob container holding all the DEKs\n+    // this is relative to the root base path holding the encrypted blobs (i.e. the repository root base path)\n+    static final String DEK_ROOT_CONTAINER = \".encryption-metadata\"; // package private for tests\n+    static final int DEK_ID_LENGTH_IN_BYTES = 16; // {@code org.elasticsearch.common.UUIDS} length\n+    private static final int DEK_ID_LENGTH_IN_CHARS = 22; // Base64 encoding without padding\n+\n+    // the following constants can be changed freely\n+    private static final String RAND_ALGO = \"SHA1PRNG\";\n+    // each snapshot metadata contains an unforgeable identifier of the repository password of the master node that started the snapshot\n+    // this hash is then verified on each data node before the actual shard files snapshot, as well as on the\n+    // master node that finalizes the snapshot (could be a different master node, if a master failover occurred during the snapshot)\n+    private static final String PASSWORD_ID_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordId\";\n+    private static final String PASSWORD_ID_SALT_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordIdSalt\";\n+    private static final int DEK_CACHE_WEIGHT = 2048;\n+\n+    // this is the repository instance to which all blob reads and writes are forwarded to (it stores both the encrypted blobs, as well\n+    // as the associated encrypted DEKs)\n+    private final BlobStoreRepository delegatedRepository;\n+    // every data blob is encrypted with its randomly generated AES key (DEK)\n+    private final Supplier<Tuple<SecretKey, String>> DEKGenerator;\n+    // license is checked before every snapshot operations; protected non-final for tests\n+    protected Supplier<XPackLicenseState> licenseStateSupplier;\n+    private final char[] repositoryPassword;\n+    private final String localRepositoryPasswordId;\n+    private final String localRepositoryPasswordIdSalt;\n+    private final AtomicReference<String> validatedRepositoryPasswordId;\n+    private final Cache<String, SecretKey> DEKCache;\n+\n+    /**\n+     * Returns the byte length (i.e. the storage size) of an encrypted blob, given the length of the blob's plaintext contents.\n+     *\n+     * @see EncryptionPacketsInputStream#getEncryptionLength(long, int)\n+     */\n+    public static long getEncryptedBlobByteLength(long plaintextBlobByteLength) {\n+        return (long) DEK_ID_LENGTH_IN_BYTES /* UUID byte length */\n+                + EncryptionPacketsInputStream.getEncryptionLength(plaintextBlobByteLength, PACKET_LENGTH_IN_BYTES);\n+    }\n+\n+    protected EncryptedRepository(RepositoryMetaData metadata, NamedXContentRegistry namedXContentRegistry, ClusterService clusterService,\n+                                  BlobStoreRepository delegatedRepository, Supplier<XPackLicenseState> licenseStateSupplier,\n+                                  char[] repositoryPassword) throws GeneralSecurityException {\n+        super(metadata, namedXContentRegistry, clusterService, BlobPath.cleanPath() /* the encrypted repository uses a hardcoded empty\n+        base blob path but the base path setting is honored for the delegated repository */);\n+        this.delegatedRepository = delegatedRepository;\n+        this.DEKGenerator = createDEKGenerator();\n+        this.licenseStateSupplier = licenseStateSupplier;\n+        this.repositoryPassword = repositoryPassword;\n+        this.localRepositoryPasswordIdSalt = UUIDs.randomBase64UUID();\n+        this.localRepositoryPasswordId = AESKeyUtils.computeId(AESKeyUtils.generatePasswordBasedKey(repositoryPassword,\n+                Base64.getUrlDecoder().decode(this.localRepositoryPasswordIdSalt.getBytes(StandardCharsets.UTF_8))));\n+        this.validatedRepositoryPasswordId = new AtomicReference<>(this.localRepositoryPasswordId);\n+        // stores decrypted DEKs; DEKs are reused to encrypt/decrypt multiple independent blobs\n+        this.DEKCache = CacheBuilder.<String, SecretKey>builder().setMaximumWeight(DEK_CACHE_WEIGHT).build();\n+        if (isReadOnly() != delegatedRepository.isReadOnly()) {\n+            throw new IllegalStateException(\"The encrypted repository must be read-only iff the delegate repository is read-only\");\n+        }\n+    }\n+\n+    /**\n+     * The repository hook method which populates the snapshot metadata with the salted password hash of the repository on the (master)\n+     * node that starts of the snapshot operation. All the other actions associated with the same snapshot operation will first verify\n+     * that the local repository password checks with the hash from the snapshot metadata.\n+     * <p>\n+     * In addition, if the installed license does not comply with encrypted snapshots, this throws an exception, which aborts the snapshot\n+     * operation.\n+     *\n+     * See {@link org.elasticsearch.repositories.Repository#adaptUserMetadata(Map)}.\n+     *\n+     * @param userMetadata the snapshot metadata as received from the calling user\n+     * @return the snapshot metadata containing the salted password hash of the node initializing the snapshot\n+     */\n+    @Override\n+    public Map<String, Object> adaptUserMetadata(Map<String, Object> userMetadata) {\n+        // because populating the snapshot metadata must be done before the actual snapshot is first initialized,\n+        // we take the opportunity to validate the license and abort if non-compliant\n+        if (false == licenseStateSupplier.get().isEncryptedSnapshotAllowed()) {\n+            throw LicenseUtils.newComplianceException(\"encrypted snapshots\");\n+        }\n+        Map<String, Object> snapshotUserMetadata = new HashMap<>();\n+        if (userMetadata != null) {\n+            snapshotUserMetadata.putAll(userMetadata);\n+        }\n+        // set out the ID of the repository secret\n+        // this is then checked before every snapshot operation (i.e. {@link #snapshotShard} and {@link #finalizeSnapshot})\n+        // to assure that all participating nodes in the snapshot operation are using the same repository secret\n+        snapshotUserMetadata.put(PASSWORD_ID_SALT_USER_METADATA_KEY, localRepositoryPasswordIdSalt);\n+        snapshotUserMetadata.put(PASSWORD_ID_USER_METADATA_KEY, localRepositoryPasswordId);\n+        return snapshotUserMetadata;\n+    }\n+\n+    @Override\n+    public void finalizeSnapshot(SnapshotId snapshotId, ShardGenerations shardGenerations, long startTime, String failure,\n+                                 int totalShards, List<SnapshotShardFailure> shardFailures, long repositoryStateId,\n+                                 boolean includeGlobalState, MetaData clusterMetaData, Map<String, Object> userMetadata,\n+                                 Version repositoryMetaVersion, ActionListener<SnapshotInfo> listener) {\n+        try {\n+            validateLocalRepositorySecret(userMetadata);\n+            // remove the repository key id from the snapshot metadata so that the id is not displayed in the API response to the user\n+            userMetadata = new HashMap<>(userMetadata);\n+            userMetadata.remove(PASSWORD_ID_USER_METADATA_KEY);\n+        } catch (RepositoryException KEKValidationException) {\n+            listener.onFailure(KEKValidationException);\n+            return;\n+        }\n+        super.finalizeSnapshot(snapshotId, shardGenerations, startTime, failure, totalShards, shardFailures, repositoryStateId,\n+                includeGlobalState, clusterMetaData, userMetadata, repositoryMetaVersion, listener);\n+    }\n+\n+    @Override\n+    public void snapshotShard(Store store, MapperService mapperService, SnapshotId snapshotId, IndexId indexId,\n+                              IndexCommit snapshotIndexCommit, IndexShardSnapshotStatus snapshotStatus, Version repositoryMetaVersion,\n+                              Map<String, Object> userMetadata, ActionListener<String> listener) {\n+        try {\n+            validateLocalRepositorySecret(userMetadata);\n+        } catch (RepositoryException KEKValidationException) {\n+            listener.onFailure(KEKValidationException);\n+            return;\n+        }\n+        super.snapshotShard(store, mapperService, snapshotId, indexId, snapshotIndexCommit, snapshotStatus, repositoryMetaVersion,\n+                userMetadata, listener);\n+    }\n+\n+    @Override\n+    protected BlobStore createBlobStore() {\n+        final Supplier<Tuple<SecretKey, String>> DEKGenerator;\n+        if (isReadOnly()) {\n+            // make sure that a read-only repository can't encrypt anything\n+            DEKGenerator = () -> {\n+                throw new IllegalStateException(\"DEKs are required for encryption but this is a read-only repository\");\n+            };\n+        } else {\n+            DEKGenerator = this.DEKGenerator;\n+        }\n+        return new EncryptedBlobStore(delegatedRepository.blobStore(), delegatedRepository.basePath(), repositoryPassword, DEKGenerator,\n+                DEKCache);\n+    }\n+\n+    @Override\n+    protected void doStart() {\n+        this.delegatedRepository.start();\n+        super.doStart();\n+    }\n+\n+    @Override\n+    protected void doStop() {\n+        super.doStop();\n+        this.delegatedRepository.stop();\n+    }\n+\n+    @Override\n+    protected void doClose() {\n+        super.doClose();\n+        this.delegatedRepository.close();\n+    }\n+\n+    private static Supplier<Tuple<SecretKey, String>> createDEKGenerator() throws GeneralSecurityException {\n+        // DEK and DEK Ids are generated randomly\n+        final SecureRandom DEKSecureRandom = SecureRandom.getInstance(RAND_ALGO);\n+        final SecureRandom DEKIdSecureRandom = SecureRandom.getInstance(RAND_ALGO);\n+        final KeyGenerator dataEncryptionKeyGenerator = KeyGenerator.getInstance(DATA_ENCRYPTION_SCHEME.split(\"/\")[0]);\n+        dataEncryptionKeyGenerator.init(AESKeyUtils.KEY_LENGTH_IN_BYTES * Byte.SIZE, DEKSecureRandom);\n+        return () -> new Tuple<>(dataEncryptionKeyGenerator.generateKey(), UUIDs.randomBase64UUID(DEKIdSecureRandom));\n+    }\n+\n+    static class EncryptedBlobStore implements BlobStore {\n+        private final BlobStore delegatedBlobStore;\n+        private final BlobPath delegatedBasePath;\n+        private final Function<String, Tuple<String, SecretKey>> getKEKforDEK;\n+        private final CheckedSupplier<SingleUseDEK, IOException> singleUseDEKSupplier;\n+        private final CheckedFunction<String, SecretKey, IOException> getDEKById;\n+\n+        EncryptedBlobStore(BlobStore delegatedBlobStore,\n+                           BlobPath delegatedBasePath,\n+                           char[] repositoryPassword,\n+                           Supplier<Tuple<SecretKey, String>> DEKGenerator,\n+                           Cache<String, SecretKey> DEKCache) {\n+            this.delegatedBlobStore = delegatedBlobStore;\n+            this.delegatedBasePath = delegatedBasePath;\n+            this.getKEKforDEK = DEKId -> {\n+                try {\n+                    SecretKey KEK = AESKeyUtils.generatePasswordBasedKey(repositoryPassword,\n+                            Base64.getUrlDecoder().decode(DEKId.getBytes(StandardCharsets.UTF_8)));\n+                    String KEKId = AESKeyUtils.computeId(KEK);\n+                    return new Tuple<>(KEKId, KEK);\n+                } catch (GeneralSecurityException e) {\n+                    throw new ElasticsearchException(\"Failure to generate KEK to wrap the DEK [\" + DEKId + \"]\", e);\n+                }\n+            };\n+            this.singleUseDEKSupplier = SingleUseDEK.createSingleUseDEKSupplier(() -> {\n+                Tuple<SecretKey, String> newDEK = DEKGenerator.get();\n+                // store newly generated DEK before making it available\n+                storeDEK(newDEK.v2(), newDEK.v1());\n+                return newDEK;\n+            });\n+            this.getDEKById = DEKId -> {\n+                try {\n+                    return DEKCache.computeIfAbsent(DEKId, ignored -> loadDEK(DEKId));\n+                } catch (ExecutionException e) {\n+                    // some exception types are to be expected\n+                    if (e.getCause() instanceof IOException) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "097393b25d57aae0527eb87de4e0abefec891218"}, "originalPosition": 274}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MTU4NTkz", "url": "https://github.com/elastic/elasticsearch/pull/53352#pullrequestreview-386158593", "createdAt": "2020-04-02T07:11:51Z", "commit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "state": "COMMENTED", "comments": {"totalCount": 27, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzoxMTo1MVrOF_eD3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwODo1ODo0MVrOF_hvdA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA5NzExOQ==", "bodyText": "I would suggest we just move these utility methods to EncryptedRepository since they are only used there (and we can replicate them as utility methods without changing BlobPath code as far as I can see).\nThese methods are pretty specific to how the encrypted repo works and do things we don't do elsewhere with the paths.", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402097119", "createdAt": "2020-04-02T07:11:51Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/common/blobstore/BlobPath.java", "diffHunk": "@@ -62,6 +63,12 @@ public BlobPath add(String path) {\n         return new BlobPath(Collections.unmodifiableList(paths));\n     }\n \n+    public BlobPath append(BlobPath otherPath) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA5ODM4Mg==", "bodyText": "NIT: paths is never null, I think you can just do a normal paths.equals(other.paths)", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402098382", "createdAt": "2020-04-02T07:14:37Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/common/blobstore/BlobPath.java", "diffHunk": "@@ -92,4 +112,17 @@ public String toString() {\n         }\n         return sb.toString();\n     }\n+\n+    @Override\n+    public boolean equals(Object o) {\n+        if (this == o) return true;\n+        if (o == null || getClass() != o.getClass()) return false;\n+        BlobPath other = (BlobPath) o;\n+        return Objects.equals(paths, other.paths);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEwMjI3OA==", "bodyText": "NIT: I think I hate this on second thought (sorry), it's really confusing to extend a concrete test class here.\nI think it would be a lot less confusing if we kept repositoryType abstract and by that kept FsBlobStoreRepositoryBaseIntegTestCase abstract. This way it's much clearer why we need this construct IMO :)", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402102278", "createdAt": "2020-04-02T07:22:44Z", "author": {"login": "original-brownbear"}, "path": "server/src/test/java/org/elasticsearch/repositories/fs/FsBlobStoreRepositoryIntegTests.java", "diffHunk": "@@ -0,0 +1,22 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.elasticsearch.repositories.fs;\n+\n+public final class FsBlobStoreRepositoryIntegTests extends FsBlobStoreRepositoryBaseIntegTestCase {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEwMjc0MQ==", "bodyText": "No need for these changes anymore right?", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402102741", "createdAt": "2020-04-02T07:23:40Z", "author": {"login": "original-brownbear"}, "path": "test/framework/src/main/java/org/elasticsearch/common/settings/MockSecureSettings.java", "diffHunk": "@@ -36,10 +37,10 @@\n  */\n public class MockSecureSettings implements SecureSettings {\n \n-    private Map<String, String> secureStrings = new HashMap<>();\n-    private Map<String, byte[]> files = new HashMap<>();\n-    private Map<String, byte[]> sha256Digests = new HashMap<>();\n-    private Set<String> settingNames = new HashSet<>();\n+    private Map<String, String> secureStrings = Collections.synchronizedMap(new HashMap<>());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEwMzAwNA==", "bodyText": "Revert random format change?", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402103004", "createdAt": "2020-04-02T07:24:13Z", "author": {"login": "original-brownbear"}, "path": "test/framework/src/main/java/org/elasticsearch/repositories/blobstore/ESBlobStoreRepositoryIntegTestCase.java", "diffHunk": "@@ -262,15 +275,21 @@ protected static void writeBlob(BlobContainer container, String blobName, BytesA\n     }\n \n     protected BlobStore newBlobStore() {\n-        final String repository = createRepository(randomName());\n+        final String repository = createRepository(randomRepositoryName());\n+        return newBlobStore(repository);\n+    }\n+\n+    protected BlobStore newBlobStore(String repository) {\n         final BlobStoreRepository blobStoreRepository =\n             (BlobStoreRepository) internalCluster().getMasterNodeInstance(RepositoriesService.class).repository(repository);\n         return PlainActionFuture.get(\n-            f -> blobStoreRepository.threadPool().generic().execute(ActionRunnable.supply(f, blobStoreRepository::blobStore)));\n+                f -> blobStoreRepository.threadPool().generic().execute(ActionRunnable.supply(f, blobStoreRepository::blobStore)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEwODEwMA==", "bodyText": "No need to get held up on this now, but let's add a TODO: to break tests out into separate modules.\nExcluding guava now and using a conflicting version with Azure may work today but it's really brittle going forward I think. Especially when we're looking into upgrading to a very different version of the Azure SDK mid-term.", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402108100", "createdAt": "2020-04-02T07:34:12Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/repository-encrypted/build.gradle", "diffHunk": "@@ -8,4 +8,23 @@ esplugin {\n     extendedPlugins = ['x-pack-core']\n }\n \n+dependencies {\n+    // necessary for the license check\n+    compileOnly project(path: xpackModule('core'), configuration: 'default')\n+    testCompile project(path: xpackModule('core'), configuration: 'testArtifacts')\n+    testCompile project(\":test:framework\")\n+    // required for tests of encrypted cloud repositories\n+    testCompile project(path: ':plugins:repository-gcs', configuration: 'testArtifacts')\n+    testCompile(project(path: ':plugins:repository-azure', configuration: 'testArtifacts'), {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEwODU3OA==", "bodyText": "NIT: weird formatting isn't it? :) Keep the exceptions on a single line?", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402108578", "createdAt": "2020-04-02T07:35:11Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/AESKeyUtils.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.repositories.encrypted;\n+\n+import javax.crypto.Cipher;\n+import javax.crypto.IllegalBlockSizeException;\n+import javax.crypto.NoSuchPaddingException;\n+import javax.crypto.SecretKey;\n+import javax.crypto.SecretKeyFactory;\n+import javax.crypto.spec.PBEKeySpec;\n+import javax.crypto.spec.SecretKeySpec;\n+import java.nio.charset.StandardCharsets;\n+import java.security.InvalidKeyException;\n+import java.security.Key;\n+import java.security.NoSuchAlgorithmException;\n+import java.security.spec.InvalidKeySpecException;\n+import java.util.Base64;\n+\n+public final class AESKeyUtils {\n+    public static final int KEY_LENGTH_IN_BYTES = 32; // 256-bit AES key\n+    public static final int WRAPPED_KEY_LENGTH_IN_BYTES = KEY_LENGTH_IN_BYTES + 8; // https://www.ietf.org/rfc/rfc3394.txt section 2.2\n+    // parameter for the KDF function, it's a funny and unusual iter count larger than 60k\n+    private static final int KDF_ITER = 61616;\n+    // the KDF algorithm that generate the symmetric key given the password\n+    private static final String KDF_ALGO = \"PBKDF2WithHmacSHA512\";\n+    // The Id of any AES SecretKey is the AES-Wrap-ciphertext of this fixed 32 byte wide array.\n+    // Key wrapping encryption is deterministic (same plaintext generates the same ciphertext)\n+    // and the probability that two different keys map the same plaintext to the same ciphertext is very small\n+    // (2^-256, much lower than the UUID collision of 2^-128), assuming AES is indistinguishable from a pseudorandom permutation.\n+    private static final byte[] KEY_ID_PLAINTEXT = \"wrapping known text forms key id\".getBytes(StandardCharsets.UTF_8);\n+\n+    public static byte[] wrap(SecretKey wrappingKey, SecretKey keyToWrap) throws NoSuchPaddingException,\n+        NoSuchAlgorithmException,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjExMDM2MQ==", "bodyText": "NIT/question: do we even need these checks, won't c.init or c.unwrap fail anyway if the algorithm is off?", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402110361", "createdAt": "2020-04-02T07:38:44Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/AESKeyUtils.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.repositories.encrypted;\n+\n+import javax.crypto.Cipher;\n+import javax.crypto.IllegalBlockSizeException;\n+import javax.crypto.NoSuchPaddingException;\n+import javax.crypto.SecretKey;\n+import javax.crypto.SecretKeyFactory;\n+import javax.crypto.spec.PBEKeySpec;\n+import javax.crypto.spec.SecretKeySpec;\n+import java.nio.charset.StandardCharsets;\n+import java.security.InvalidKeyException;\n+import java.security.Key;\n+import java.security.NoSuchAlgorithmException;\n+import java.security.spec.InvalidKeySpecException;\n+import java.util.Base64;\n+\n+public final class AESKeyUtils {\n+    public static final int KEY_LENGTH_IN_BYTES = 32; // 256-bit AES key\n+    public static final int WRAPPED_KEY_LENGTH_IN_BYTES = KEY_LENGTH_IN_BYTES + 8; // https://www.ietf.org/rfc/rfc3394.txt section 2.2\n+    // parameter for the KDF function, it's a funny and unusual iter count larger than 60k\n+    private static final int KDF_ITER = 61616;\n+    // the KDF algorithm that generate the symmetric key given the password\n+    private static final String KDF_ALGO = \"PBKDF2WithHmacSHA512\";\n+    // The Id of any AES SecretKey is the AES-Wrap-ciphertext of this fixed 32 byte wide array.\n+    // Key wrapping encryption is deterministic (same plaintext generates the same ciphertext)\n+    // and the probability that two different keys map the same plaintext to the same ciphertext is very small\n+    // (2^-256, much lower than the UUID collision of 2^-128), assuming AES is indistinguishable from a pseudorandom permutation.\n+    private static final byte[] KEY_ID_PLAINTEXT = \"wrapping known text forms key id\".getBytes(StandardCharsets.UTF_8);\n+\n+    public static byte[] wrap(SecretKey wrappingKey, SecretKey keyToWrap) throws NoSuchPaddingException,\n+        NoSuchAlgorithmException,\n+        InvalidKeyException,\n+        IllegalBlockSizeException {\n+        if (false == \"AES\".equals(wrappingKey.getAlgorithm())) {\n+            throw new IllegalArgumentException(\"wrappingKey argument is not an AES Key\");\n+        }\n+        if (false == \"AES\".equals(keyToWrap.getAlgorithm())) {\n+            throw new IllegalArgumentException(\"toWrapKey argument is not an AES Key\");\n+        }\n+        Cipher c = Cipher.getInstance(\"AESWrap\");\n+        c.init(Cipher.WRAP_MODE, wrappingKey);\n+        return c.wrap(keyToWrap);\n+    }\n+\n+    public static SecretKey unwrap(SecretKey wrappingKey, byte[] keyToUnwrap) throws NoSuchPaddingException,\n+        NoSuchAlgorithmException,\n+        InvalidKeyException {\n+        if (false == \"AES\".equals(wrappingKey.getAlgorithm())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjExNDY1OA==", "bodyText": "NIT: I added a utility for this the other day, you can use\nfinal InputStream firstComponent = Streams.noCloseStream(first);\nfinal InputStream secondComponent = Streams.noCloseStream(second);\nto shorten this :)", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402114658", "createdAt": "2020-04-02T07:46:55Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/ChainingInputStream.java", "diffHunk": "@@ -72,6 +75,74 @@\n      */\n     private boolean closed;\n \n+    /**\n+     * Returns a new {@link ChainingInputStream} that concatenates the bytes to be read from the first\n+     * input stream with the bytes from the second input stream. The stream arguments must support\n+     * the {@code mark} and {@code reset} operations; otherwise use {@link SequenceInputStream}.\n+     *\n+     * @param first the input stream supplying the first bytes of the returned {@link ChainingInputStream}\n+     * @param second the input stream supplying the bytes after the {@code first} input stream has been exhausted\n+     */\n+    public static ChainingInputStream chain(InputStream first, InputStream second) {\n+        if (false == Objects.requireNonNull(first).markSupported()) {\n+            throw new IllegalArgumentException(\"The first component input stream does not support mark\");\n+        }\n+        if (false == Objects.requireNonNull(second).markSupported()) {\n+            throw new IllegalArgumentException(\"The second component input stream does not support mark\");\n+        }\n+        final InputStream firstComponent = new FilterInputStream(first) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjExNTY5MQ==", "bodyText": "NIT: IOUtils.close(super, first, second); should do the same as this method?", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402115691", "createdAt": "2020-04-02T07:48:34Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/ChainingInputStream.java", "diffHunk": "@@ -72,6 +75,74 @@\n      */\n     private boolean closed;\n \n+    /**\n+     * Returns a new {@link ChainingInputStream} that concatenates the bytes to be read from the first\n+     * input stream with the bytes from the second input stream. The stream arguments must support\n+     * the {@code mark} and {@code reset} operations; otherwise use {@link SequenceInputStream}.\n+     *\n+     * @param first the input stream supplying the first bytes of the returned {@link ChainingInputStream}\n+     * @param second the input stream supplying the bytes after the {@code first} input stream has been exhausted\n+     */\n+    public static ChainingInputStream chain(InputStream first, InputStream second) {\n+        if (false == Objects.requireNonNull(first).markSupported()) {\n+            throw new IllegalArgumentException(\"The first component input stream does not support mark\");\n+        }\n+        if (false == Objects.requireNonNull(second).markSupported()) {\n+            throw new IllegalArgumentException(\"The second component input stream does not support mark\");\n+        }\n+        final InputStream firstComponent = new FilterInputStream(first) {\n+            @Override\n+            public void close() {\n+                // silence close\n+                // \"first\" can be reused, and the {@code ChainingInputStream} eagerly closes components after every use\n+                // \"first\" is closed when the returned {@code ChainingInputStream} is closed\n+            }\n+        };\n+        final InputStream secondComponent = new FilterInputStream(second) {\n+            @Override\n+            public void close() {\n+                // silence close\n+                // \"second\" can be reused, and the {@code ChainingInputStream} eagerly closes components after every use\n+                // \"second\" is closed when the returned {@code ChainingInputStream} is closed\n+            }\n+        };\n+        // be sure to remember the start of components because they might be reused\n+        firstComponent.mark(Integer.MAX_VALUE);\n+        secondComponent.mark(Integer.MAX_VALUE);\n+\n+        return new ChainingInputStream() {\n+\n+            @Override\n+            InputStream nextComponent(InputStream currentComponentIn) throws IOException {\n+                if (currentComponentIn == null) {\n+                    // when returning the next component, start from its beginning\n+                    firstComponent.reset();\n+                    return firstComponent;\n+                } else if (currentComponentIn == firstComponent) {\n+                    // when returning the next component, start from its beginning\n+                    secondComponent.reset();\n+                    return secondComponent;\n+                } else if (currentComponentIn == secondComponent) {\n+                    return null;\n+                } else {\n+                    throw new IllegalStateException(\"Unexpected component input stream\");\n+                }\n+            }\n+\n+            @Override\n+            public void close() throws IOException {\n+                Exception superException = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjExNjIxMg==", "bodyText": "throw new IOException(\"Mark/reset not supported\"); in this method?", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402116212", "createdAt": "2020-04-02T07:49:24Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/DecryptionPacketsInputStream.java", "diffHunk": "@@ -115,14 +117,25 @@ public boolean markSupported() {\n     }\n \n     @Override\n-    public void mark(int readlimit) {\n-    }\n+    public void mark(int readlimit) {}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjExNjU5Ng==", "bodyText": "NIT: IOUtils.close(super, first, second); should do the same as this method?", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402116596", "createdAt": "2020-04-02T07:50:00Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/DecryptionPacketsInputStream.java", "diffHunk": "@@ -115,14 +117,25 @@ public boolean markSupported() {\n     }\n \n     @Override\n-    public void mark(int readlimit) {\n-    }\n+    public void mark(int readlimit) {}\n \n     @Override\n     public void reset() throws IOException {\n         throw new IOException(\"Mark/reset not supported\");\n     }\n \n+    @Override\n+    public void close() throws IOException {\n+        Exception superException = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjExODQzMQ==", "bodyText": "Now that you're not reading the int I think you can shorten this to long packetIvCounter = ByteUtils.readLongLE(packetBuffer, 0);", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402118431", "createdAt": "2020-04-02T07:52:56Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/DecryptionPacketsInputStream.java", "diffHunk": "@@ -131,11 +144,7 @@ private int decrypt(PrefixInputStream packetInputStream) throws IOException {\n         }\n         // extract the nonce and the counter from the packet IV\n         ByteBuffer ivBuffer = ByteBuffer.wrap(packetBuffer, 0, GCM_IV_LENGTH_IN_BYTES).order(ByteOrder.LITTLE_ENDIAN);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjExOTg0MA==", "bodyText": "NIT: that's a strange comment :) we don't really comment on why stuff isn't final anywhere else I think.", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402119840", "createdAt": "2020-04-02T07:55:21Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepository.java", "diffHunk": "@@ -6,11 +6,739 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n-public class EncryptedRepository {\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.lucene.index.IndexCommit;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.metadata.MetaData;\n+import org.elasticsearch.cluster.metadata.RepositoryMetaData;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.CheckedFunction;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.blobstore.BlobContainer;\n+import org.elasticsearch.common.blobstore.BlobMetaData;\n+import org.elasticsearch.common.blobstore.BlobPath;\n+import org.elasticsearch.common.blobstore.BlobStore;\n+import org.elasticsearch.common.blobstore.DeleteResult;\n+import org.elasticsearch.common.blobstore.support.AbstractBlobContainer;\n+import org.elasticsearch.common.cache.Cache;\n+import org.elasticsearch.common.cache.CacheBuilder;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.io.Streams;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.index.store.Store;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoryException;\n+import org.elasticsearch.repositories.ShardGenerations;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.SnapshotInfo;\n+import org.elasticsearch.snapshots.SnapshotShardFailure;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.SecretKey;\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.NoSuchFileException;\n+import java.security.GeneralSecurityException;\n+import java.security.SecureRandom;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+// not-final for tests", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEyMDgxOQ==", "bodyText": "NIT: weird formatting? I'd at least join this line with the ) above", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402120819", "createdAt": "2020-04-02T07:57:02Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepository.java", "diffHunk": "@@ -6,11 +6,739 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n-public class EncryptedRepository {\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.lucene.index.IndexCommit;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.metadata.MetaData;\n+import org.elasticsearch.cluster.metadata.RepositoryMetaData;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.CheckedFunction;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.blobstore.BlobContainer;\n+import org.elasticsearch.common.blobstore.BlobMetaData;\n+import org.elasticsearch.common.blobstore.BlobPath;\n+import org.elasticsearch.common.blobstore.BlobStore;\n+import org.elasticsearch.common.blobstore.DeleteResult;\n+import org.elasticsearch.common.blobstore.support.AbstractBlobContainer;\n+import org.elasticsearch.common.cache.Cache;\n+import org.elasticsearch.common.cache.CacheBuilder;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.io.Streams;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.index.store.Store;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoryException;\n+import org.elasticsearch.repositories.ShardGenerations;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.SnapshotInfo;\n+import org.elasticsearch.snapshots.SnapshotShardFailure;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.SecretKey;\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.NoSuchFileException;\n+import java.security.GeneralSecurityException;\n+import java.security.SecureRandom;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+// not-final for tests\n+public class EncryptedRepository extends BlobStoreRepository {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepository.class);\n+    // the following constants are fixed by definition\n     static final int GCM_TAG_LENGTH_IN_BYTES = 16;\n     static final int GCM_IV_LENGTH_IN_BYTES = 12;\n-    static final int AES_BLOCK_SIZE_IN_BYTES = 128;\n+    static final int AES_BLOCK_LENGTH_IN_BYTES = 128;\n+    // the following constants require careful thought before changing because they will break backwards compatibility\n     static final String DATA_ENCRYPTION_SCHEME = \"AES/GCM/NoPadding\";\n     static final long PACKET_START_COUNTER = Long.MIN_VALUE;\n-    static final int MAX_PACKET_LENGTH_IN_BYTES = 1 << 30;\n+    static final int MAX_PACKET_LENGTH_IN_BYTES = 8 << 20; // 8MB\n+    // this should be smaller than {@code #MAX_PACKET_LENGTH_IN_BYTES} and it's what {@code EncryptionPacketsInputStream} uses\n+    // during encryption and what {@code DecryptionPacketsInputStream} expects during decryption (it is not configurable)\n+    static final int PACKET_LENGTH_IN_BYTES = 64 * (1 << 10); // 64KB\n+    // the path of the blob container holding all the DEKs\n+    // this is relative to the root base path holding the encrypted blobs (i.e. the repository root base path)\n+    static final String DEK_ROOT_CONTAINER = \".encryption-metadata\"; // package private for tests\n+    static final int DEK_ID_LENGTH = 22; // {@code org.elasticsearch.common.UUIDS} length\n+\n+    // the following constants can be changed freely\n+    private static final String RAND_ALGO = \"SHA1PRNG\";\n+    // each snapshot metadata contains an unforgeable identifier of the repository password of the master node that started the snapshot\n+    // this hash is then verified on each data node before the actual shard files snapshot, as well as on the\n+    // master node that finalizes the snapshot (could be a different master node, if a master failover occurred during the snapshot)\n+    static final String PASSWORD_ID_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordId\";\n+    static final String PASSWORD_ID_SALT_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordIdSalt\";\n+    private static final int DEK_CACHE_WEIGHT = 2048;\n+\n+    // this is the repository instance to which all blob reads and writes are forwarded to (it stores both the encrypted blobs, as well\n+    // as the associated encrypted DEKs)\n+    private final BlobStoreRepository delegatedRepository;\n+    // every data blob is encrypted with its randomly generated AES key (DEK)\n+    private final Supplier<Tuple<String, SecretKey>> DEKGenerator;\n+    // license is checked before every snapshot operations; protected non-final for tests\n+    protected Supplier<XPackLicenseState> licenseStateSupplier;\n+    private final char[] repositoryPassword;\n+    private final String localRepositoryPasswordId;\n+    private final String localRepositoryPasswordIdSalt;\n+    private final AtomicReference<String> validatedRepositoryPasswordId;\n+    private final Cache<String, SecretKey> DEKCache;\n+\n+    /**\n+     * Returns the byte length (i.e. the storage size) of an encrypted blob, given the length of the blob's plaintext contents.\n+     *\n+     * @see EncryptionPacketsInputStream#getEncryptionLength(long, int)\n+     */\n+    public static long getEncryptedBlobByteLength(long plaintextBlobByteLength) {\n+        return (long) DEK_ID_LENGTH /* UUID byte length */\n+            + EncryptionPacketsInputStream.getEncryptionLength(plaintextBlobByteLength, PACKET_LENGTH_IN_BYTES);\n+    }\n+\n+    protected EncryptedRepository(\n+        RepositoryMetaData metadata,\n+        NamedXContentRegistry namedXContentRegistry,\n+        ClusterService clusterService,\n+        BlobStoreRepository delegatedRepository,\n+        Supplier<XPackLicenseState> licenseStateSupplier,\n+        char[] repositoryPassword\n+    )\n+        throws GeneralSecurityException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 120}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEyMjIzMg==", "bodyText": "NIT: This can just be a volatile String? We never really use any AtomicReference magic on this do we?", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402122232", "createdAt": "2020-04-02T07:59:27Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepository.java", "diffHunk": "@@ -6,11 +6,739 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n-public class EncryptedRepository {\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.lucene.index.IndexCommit;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.metadata.MetaData;\n+import org.elasticsearch.cluster.metadata.RepositoryMetaData;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.CheckedFunction;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.blobstore.BlobContainer;\n+import org.elasticsearch.common.blobstore.BlobMetaData;\n+import org.elasticsearch.common.blobstore.BlobPath;\n+import org.elasticsearch.common.blobstore.BlobStore;\n+import org.elasticsearch.common.blobstore.DeleteResult;\n+import org.elasticsearch.common.blobstore.support.AbstractBlobContainer;\n+import org.elasticsearch.common.cache.Cache;\n+import org.elasticsearch.common.cache.CacheBuilder;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.io.Streams;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.index.store.Store;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoryException;\n+import org.elasticsearch.repositories.ShardGenerations;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.SnapshotInfo;\n+import org.elasticsearch.snapshots.SnapshotShardFailure;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.SecretKey;\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.NoSuchFileException;\n+import java.security.GeneralSecurityException;\n+import java.security.SecureRandom;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+// not-final for tests\n+public class EncryptedRepository extends BlobStoreRepository {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepository.class);\n+    // the following constants are fixed by definition\n     static final int GCM_TAG_LENGTH_IN_BYTES = 16;\n     static final int GCM_IV_LENGTH_IN_BYTES = 12;\n-    static final int AES_BLOCK_SIZE_IN_BYTES = 128;\n+    static final int AES_BLOCK_LENGTH_IN_BYTES = 128;\n+    // the following constants require careful thought before changing because they will break backwards compatibility\n     static final String DATA_ENCRYPTION_SCHEME = \"AES/GCM/NoPadding\";\n     static final long PACKET_START_COUNTER = Long.MIN_VALUE;\n-    static final int MAX_PACKET_LENGTH_IN_BYTES = 1 << 30;\n+    static final int MAX_PACKET_LENGTH_IN_BYTES = 8 << 20; // 8MB\n+    // this should be smaller than {@code #MAX_PACKET_LENGTH_IN_BYTES} and it's what {@code EncryptionPacketsInputStream} uses\n+    // during encryption and what {@code DecryptionPacketsInputStream} expects during decryption (it is not configurable)\n+    static final int PACKET_LENGTH_IN_BYTES = 64 * (1 << 10); // 64KB\n+    // the path of the blob container holding all the DEKs\n+    // this is relative to the root base path holding the encrypted blobs (i.e. the repository root base path)\n+    static final String DEK_ROOT_CONTAINER = \".encryption-metadata\"; // package private for tests\n+    static final int DEK_ID_LENGTH = 22; // {@code org.elasticsearch.common.UUIDS} length\n+\n+    // the following constants can be changed freely\n+    private static final String RAND_ALGO = \"SHA1PRNG\";\n+    // each snapshot metadata contains an unforgeable identifier of the repository password of the master node that started the snapshot\n+    // this hash is then verified on each data node before the actual shard files snapshot, as well as on the\n+    // master node that finalizes the snapshot (could be a different master node, if a master failover occurred during the snapshot)\n+    static final String PASSWORD_ID_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordId\";\n+    static final String PASSWORD_ID_SALT_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordIdSalt\";\n+    private static final int DEK_CACHE_WEIGHT = 2048;\n+\n+    // this is the repository instance to which all blob reads and writes are forwarded to (it stores both the encrypted blobs, as well\n+    // as the associated encrypted DEKs)\n+    private final BlobStoreRepository delegatedRepository;\n+    // every data blob is encrypted with its randomly generated AES key (DEK)\n+    private final Supplier<Tuple<String, SecretKey>> DEKGenerator;\n+    // license is checked before every snapshot operations; protected non-final for tests\n+    protected Supplier<XPackLicenseState> licenseStateSupplier;\n+    private final char[] repositoryPassword;\n+    private final String localRepositoryPasswordId;\n+    private final String localRepositoryPasswordIdSalt;\n+    private final AtomicReference<String> validatedRepositoryPasswordId;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEyMzMyMQ==", "bodyText": "logger.trace(\"Snapshot metadata for local repository password  [{}] and [{}]\", localRepositoryPasswordIdSalt, localRepositoryPasswordId); should be fine here as well, we're not computing anything in the params so no need to use the message supplier pattern IMO.", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402123321", "createdAt": "2020-04-02T08:01:28Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepository.java", "diffHunk": "@@ -6,11 +6,739 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n-public class EncryptedRepository {\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.lucene.index.IndexCommit;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.metadata.MetaData;\n+import org.elasticsearch.cluster.metadata.RepositoryMetaData;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.CheckedFunction;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.blobstore.BlobContainer;\n+import org.elasticsearch.common.blobstore.BlobMetaData;\n+import org.elasticsearch.common.blobstore.BlobPath;\n+import org.elasticsearch.common.blobstore.BlobStore;\n+import org.elasticsearch.common.blobstore.DeleteResult;\n+import org.elasticsearch.common.blobstore.support.AbstractBlobContainer;\n+import org.elasticsearch.common.cache.Cache;\n+import org.elasticsearch.common.cache.CacheBuilder;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.io.Streams;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.index.store.Store;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoryException;\n+import org.elasticsearch.repositories.ShardGenerations;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.SnapshotInfo;\n+import org.elasticsearch.snapshots.SnapshotShardFailure;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.SecretKey;\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.NoSuchFileException;\n+import java.security.GeneralSecurityException;\n+import java.security.SecureRandom;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+// not-final for tests\n+public class EncryptedRepository extends BlobStoreRepository {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepository.class);\n+    // the following constants are fixed by definition\n     static final int GCM_TAG_LENGTH_IN_BYTES = 16;\n     static final int GCM_IV_LENGTH_IN_BYTES = 12;\n-    static final int AES_BLOCK_SIZE_IN_BYTES = 128;\n+    static final int AES_BLOCK_LENGTH_IN_BYTES = 128;\n+    // the following constants require careful thought before changing because they will break backwards compatibility\n     static final String DATA_ENCRYPTION_SCHEME = \"AES/GCM/NoPadding\";\n     static final long PACKET_START_COUNTER = Long.MIN_VALUE;\n-    static final int MAX_PACKET_LENGTH_IN_BYTES = 1 << 30;\n+    static final int MAX_PACKET_LENGTH_IN_BYTES = 8 << 20; // 8MB\n+    // this should be smaller than {@code #MAX_PACKET_LENGTH_IN_BYTES} and it's what {@code EncryptionPacketsInputStream} uses\n+    // during encryption and what {@code DecryptionPacketsInputStream} expects during decryption (it is not configurable)\n+    static final int PACKET_LENGTH_IN_BYTES = 64 * (1 << 10); // 64KB\n+    // the path of the blob container holding all the DEKs\n+    // this is relative to the root base path holding the encrypted blobs (i.e. the repository root base path)\n+    static final String DEK_ROOT_CONTAINER = \".encryption-metadata\"; // package private for tests\n+    static final int DEK_ID_LENGTH = 22; // {@code org.elasticsearch.common.UUIDS} length\n+\n+    // the following constants can be changed freely\n+    private static final String RAND_ALGO = \"SHA1PRNG\";\n+    // each snapshot metadata contains an unforgeable identifier of the repository password of the master node that started the snapshot\n+    // this hash is then verified on each data node before the actual shard files snapshot, as well as on the\n+    // master node that finalizes the snapshot (could be a different master node, if a master failover occurred during the snapshot)\n+    static final String PASSWORD_ID_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordId\";\n+    static final String PASSWORD_ID_SALT_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordIdSalt\";\n+    private static final int DEK_CACHE_WEIGHT = 2048;\n+\n+    // this is the repository instance to which all blob reads and writes are forwarded to (it stores both the encrypted blobs, as well\n+    // as the associated encrypted DEKs)\n+    private final BlobStoreRepository delegatedRepository;\n+    // every data blob is encrypted with its randomly generated AES key (DEK)\n+    private final Supplier<Tuple<String, SecretKey>> DEKGenerator;\n+    // license is checked before every snapshot operations; protected non-final for tests\n+    protected Supplier<XPackLicenseState> licenseStateSupplier;\n+    private final char[] repositoryPassword;\n+    private final String localRepositoryPasswordId;\n+    private final String localRepositoryPasswordIdSalt;\n+    private final AtomicReference<String> validatedRepositoryPasswordId;\n+    private final Cache<String, SecretKey> DEKCache;\n+\n+    /**\n+     * Returns the byte length (i.e. the storage size) of an encrypted blob, given the length of the blob's plaintext contents.\n+     *\n+     * @see EncryptionPacketsInputStream#getEncryptionLength(long, int)\n+     */\n+    public static long getEncryptedBlobByteLength(long plaintextBlobByteLength) {\n+        return (long) DEK_ID_LENGTH /* UUID byte length */\n+            + EncryptionPacketsInputStream.getEncryptionLength(plaintextBlobByteLength, PACKET_LENGTH_IN_BYTES);\n+    }\n+\n+    protected EncryptedRepository(\n+        RepositoryMetaData metadata,\n+        NamedXContentRegistry namedXContentRegistry,\n+        ClusterService clusterService,\n+        BlobStoreRepository delegatedRepository,\n+        Supplier<XPackLicenseState> licenseStateSupplier,\n+        char[] repositoryPassword\n+    )\n+        throws GeneralSecurityException {\n+        super(\n+            metadata,\n+            namedXContentRegistry,\n+            clusterService,\n+            BlobPath.cleanPath() /* the encrypted repository uses a hardcoded empty\n+                                 base blob path but the base path setting is honored for the delegated repository */\n+        );\n+        this.delegatedRepository = delegatedRepository;\n+        this.DEKGenerator = createDEKGenerator();\n+        this.licenseStateSupplier = licenseStateSupplier;\n+        this.repositoryPassword = repositoryPassword;\n+        // the password \"id\" and validated\n+        this.localRepositoryPasswordIdSalt = UUIDs.randomBase64UUID();\n+        this.localRepositoryPasswordId = AESKeyUtils.computeId(\n+            AESKeyUtils.generatePasswordBasedKey(repositoryPassword, localRepositoryPasswordIdSalt.getBytes(StandardCharsets.UTF_8))\n+        );\n+        this.validatedRepositoryPasswordId = new AtomicReference<>(this.localRepositoryPasswordId);\n+        // stores decrypted DEKs; DEKs are reused to encrypt/decrypt multiple independent blobs\n+        this.DEKCache = CacheBuilder.<String, SecretKey>builder().setMaximumWeight(DEK_CACHE_WEIGHT).build();\n+        if (isReadOnly() != delegatedRepository.isReadOnly()) {\n+            throw new RepositoryException(\n+                metadata.name(),\n+                \"Unexpected fatal internal error\",\n+                new IllegalStateException(\"The encrypted repository must be read-only iff the delegate repository is read-only\")\n+            );\n+        }\n+    }\n+\n+    /**\n+     * The repository hook method which populates the snapshot metadata with the salted password hash of the repository on the (master)\n+     * node that starts of the snapshot operation. All the other actions associated with the same snapshot operation will first verify\n+     * that the local repository password checks with the hash from the snapshot metadata.\n+     * <p>\n+     * In addition, if the installed license does not comply with encrypted snapshots, this throws an exception, which aborts the snapshot\n+     * operation.\n+     *\n+     * See {@link org.elasticsearch.repositories.Repository#adaptUserMetadata(Map)}.\n+     *\n+     * @param userMetadata the snapshot metadata as received from the calling user\n+     * @return the snapshot metadata containing the salted password hash of the node initializing the snapshot\n+     */\n+    @Override\n+    public Map<String, Object> adaptUserMetadata(Map<String, Object> userMetadata) {\n+        // because populating the snapshot metadata must be done before the actual snapshot is first initialized,\n+        // we take the opportunity to validate the license and abort if non-compliant\n+        if (false == licenseStateSupplier.get().isEncryptedSnapshotAllowed()) {\n+            throw LicenseUtils.newComplianceException(\"encrypted snapshots\");\n+        }\n+        Map<String, Object> snapshotUserMetadata = new HashMap<>();\n+        if (userMetadata != null) {\n+            snapshotUserMetadata.putAll(userMetadata);\n+        }\n+        // set out the ID of the repository secret\n+        // this is then checked before every snapshot operation (i.e. {@link #snapshotShard} and {@link #finalizeSnapshot})\n+        // to assure that all participating nodes in the snapshot operation are using the same repository secret\n+        snapshotUserMetadata.put(PASSWORD_ID_SALT_USER_METADATA_KEY, localRepositoryPasswordIdSalt);\n+        snapshotUserMetadata.put(PASSWORD_ID_USER_METADATA_KEY, localRepositoryPasswordId);\n+        logger.trace(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 178}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEyNDA3OQ==", "bodyText": "Why nest exceptions instead of the below? :)\n            throw new RepositoryException(\n                metadata.name(),\n                \"The encrypted repository must be read-only iff the delegate repository is read-only\"\n            );", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402124079", "createdAt": "2020-04-02T08:02:52Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepository.java", "diffHunk": "@@ -6,11 +6,739 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n-public class EncryptedRepository {\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.lucene.index.IndexCommit;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.metadata.MetaData;\n+import org.elasticsearch.cluster.metadata.RepositoryMetaData;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.CheckedFunction;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.blobstore.BlobContainer;\n+import org.elasticsearch.common.blobstore.BlobMetaData;\n+import org.elasticsearch.common.blobstore.BlobPath;\n+import org.elasticsearch.common.blobstore.BlobStore;\n+import org.elasticsearch.common.blobstore.DeleteResult;\n+import org.elasticsearch.common.blobstore.support.AbstractBlobContainer;\n+import org.elasticsearch.common.cache.Cache;\n+import org.elasticsearch.common.cache.CacheBuilder;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.io.Streams;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.index.store.Store;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoryException;\n+import org.elasticsearch.repositories.ShardGenerations;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.SnapshotInfo;\n+import org.elasticsearch.snapshots.SnapshotShardFailure;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.SecretKey;\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.NoSuchFileException;\n+import java.security.GeneralSecurityException;\n+import java.security.SecureRandom;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+// not-final for tests\n+public class EncryptedRepository extends BlobStoreRepository {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepository.class);\n+    // the following constants are fixed by definition\n     static final int GCM_TAG_LENGTH_IN_BYTES = 16;\n     static final int GCM_IV_LENGTH_IN_BYTES = 12;\n-    static final int AES_BLOCK_SIZE_IN_BYTES = 128;\n+    static final int AES_BLOCK_LENGTH_IN_BYTES = 128;\n+    // the following constants require careful thought before changing because they will break backwards compatibility\n     static final String DATA_ENCRYPTION_SCHEME = \"AES/GCM/NoPadding\";\n     static final long PACKET_START_COUNTER = Long.MIN_VALUE;\n-    static final int MAX_PACKET_LENGTH_IN_BYTES = 1 << 30;\n+    static final int MAX_PACKET_LENGTH_IN_BYTES = 8 << 20; // 8MB\n+    // this should be smaller than {@code #MAX_PACKET_LENGTH_IN_BYTES} and it's what {@code EncryptionPacketsInputStream} uses\n+    // during encryption and what {@code DecryptionPacketsInputStream} expects during decryption (it is not configurable)\n+    static final int PACKET_LENGTH_IN_BYTES = 64 * (1 << 10); // 64KB\n+    // the path of the blob container holding all the DEKs\n+    // this is relative to the root base path holding the encrypted blobs (i.e. the repository root base path)\n+    static final String DEK_ROOT_CONTAINER = \".encryption-metadata\"; // package private for tests\n+    static final int DEK_ID_LENGTH = 22; // {@code org.elasticsearch.common.UUIDS} length\n+\n+    // the following constants can be changed freely\n+    private static final String RAND_ALGO = \"SHA1PRNG\";\n+    // each snapshot metadata contains an unforgeable identifier of the repository password of the master node that started the snapshot\n+    // this hash is then verified on each data node before the actual shard files snapshot, as well as on the\n+    // master node that finalizes the snapshot (could be a different master node, if a master failover occurred during the snapshot)\n+    static final String PASSWORD_ID_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordId\";\n+    static final String PASSWORD_ID_SALT_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordIdSalt\";\n+    private static final int DEK_CACHE_WEIGHT = 2048;\n+\n+    // this is the repository instance to which all blob reads and writes are forwarded to (it stores both the encrypted blobs, as well\n+    // as the associated encrypted DEKs)\n+    private final BlobStoreRepository delegatedRepository;\n+    // every data blob is encrypted with its randomly generated AES key (DEK)\n+    private final Supplier<Tuple<String, SecretKey>> DEKGenerator;\n+    // license is checked before every snapshot operations; protected non-final for tests\n+    protected Supplier<XPackLicenseState> licenseStateSupplier;\n+    private final char[] repositoryPassword;\n+    private final String localRepositoryPasswordId;\n+    private final String localRepositoryPasswordIdSalt;\n+    private final AtomicReference<String> validatedRepositoryPasswordId;\n+    private final Cache<String, SecretKey> DEKCache;\n+\n+    /**\n+     * Returns the byte length (i.e. the storage size) of an encrypted blob, given the length of the blob's plaintext contents.\n+     *\n+     * @see EncryptionPacketsInputStream#getEncryptionLength(long, int)\n+     */\n+    public static long getEncryptedBlobByteLength(long plaintextBlobByteLength) {\n+        return (long) DEK_ID_LENGTH /* UUID byte length */\n+            + EncryptionPacketsInputStream.getEncryptionLength(plaintextBlobByteLength, PACKET_LENGTH_IN_BYTES);\n+    }\n+\n+    protected EncryptedRepository(\n+        RepositoryMetaData metadata,\n+        NamedXContentRegistry namedXContentRegistry,\n+        ClusterService clusterService,\n+        BlobStoreRepository delegatedRepository,\n+        Supplier<XPackLicenseState> licenseStateSupplier,\n+        char[] repositoryPassword\n+    )\n+        throws GeneralSecurityException {\n+        super(\n+            metadata,\n+            namedXContentRegistry,\n+            clusterService,\n+            BlobPath.cleanPath() /* the encrypted repository uses a hardcoded empty\n+                                 base blob path but the base path setting is honored for the delegated repository */\n+        );\n+        this.delegatedRepository = delegatedRepository;\n+        this.DEKGenerator = createDEKGenerator();\n+        this.licenseStateSupplier = licenseStateSupplier;\n+        this.repositoryPassword = repositoryPassword;\n+        // the password \"id\" and validated\n+        this.localRepositoryPasswordIdSalt = UUIDs.randomBase64UUID();\n+        this.localRepositoryPasswordId = AESKeyUtils.computeId(\n+            AESKeyUtils.generatePasswordBasedKey(repositoryPassword, localRepositoryPasswordIdSalt.getBytes(StandardCharsets.UTF_8))\n+        );\n+        this.validatedRepositoryPasswordId = new AtomicReference<>(this.localRepositoryPasswordId);\n+        // stores decrypted DEKs; DEKs are reused to encrypt/decrypt multiple independent blobs\n+        this.DEKCache = CacheBuilder.<String, SecretKey>builder().setMaximumWeight(DEK_CACHE_WEIGHT).build();\n+        if (isReadOnly() != delegatedRepository.isReadOnly()) {\n+            throw new RepositoryException(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 141}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEyNDg3Mw==", "bodyText": "Metadata is never null, no need for this check I think", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402124873", "createdAt": "2020-04-02T08:04:18Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepository.java", "diffHunk": "@@ -6,11 +6,739 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n-public class EncryptedRepository {\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.lucene.index.IndexCommit;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.metadata.MetaData;\n+import org.elasticsearch.cluster.metadata.RepositoryMetaData;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.CheckedFunction;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.blobstore.BlobContainer;\n+import org.elasticsearch.common.blobstore.BlobMetaData;\n+import org.elasticsearch.common.blobstore.BlobPath;\n+import org.elasticsearch.common.blobstore.BlobStore;\n+import org.elasticsearch.common.blobstore.DeleteResult;\n+import org.elasticsearch.common.blobstore.support.AbstractBlobContainer;\n+import org.elasticsearch.common.cache.Cache;\n+import org.elasticsearch.common.cache.CacheBuilder;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.io.Streams;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.index.store.Store;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoryException;\n+import org.elasticsearch.repositories.ShardGenerations;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.SnapshotInfo;\n+import org.elasticsearch.snapshots.SnapshotShardFailure;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.SecretKey;\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.NoSuchFileException;\n+import java.security.GeneralSecurityException;\n+import java.security.SecureRandom;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+// not-final for tests\n+public class EncryptedRepository extends BlobStoreRepository {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepository.class);\n+    // the following constants are fixed by definition\n     static final int GCM_TAG_LENGTH_IN_BYTES = 16;\n     static final int GCM_IV_LENGTH_IN_BYTES = 12;\n-    static final int AES_BLOCK_SIZE_IN_BYTES = 128;\n+    static final int AES_BLOCK_LENGTH_IN_BYTES = 128;\n+    // the following constants require careful thought before changing because they will break backwards compatibility\n     static final String DATA_ENCRYPTION_SCHEME = \"AES/GCM/NoPadding\";\n     static final long PACKET_START_COUNTER = Long.MIN_VALUE;\n-    static final int MAX_PACKET_LENGTH_IN_BYTES = 1 << 30;\n+    static final int MAX_PACKET_LENGTH_IN_BYTES = 8 << 20; // 8MB\n+    // this should be smaller than {@code #MAX_PACKET_LENGTH_IN_BYTES} and it's what {@code EncryptionPacketsInputStream} uses\n+    // during encryption and what {@code DecryptionPacketsInputStream} expects during decryption (it is not configurable)\n+    static final int PACKET_LENGTH_IN_BYTES = 64 * (1 << 10); // 64KB\n+    // the path of the blob container holding all the DEKs\n+    // this is relative to the root base path holding the encrypted blobs (i.e. the repository root base path)\n+    static final String DEK_ROOT_CONTAINER = \".encryption-metadata\"; // package private for tests\n+    static final int DEK_ID_LENGTH = 22; // {@code org.elasticsearch.common.UUIDS} length\n+\n+    // the following constants can be changed freely\n+    private static final String RAND_ALGO = \"SHA1PRNG\";\n+    // each snapshot metadata contains an unforgeable identifier of the repository password of the master node that started the snapshot\n+    // this hash is then verified on each data node before the actual shard files snapshot, as well as on the\n+    // master node that finalizes the snapshot (could be a different master node, if a master failover occurred during the snapshot)\n+    static final String PASSWORD_ID_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordId\";\n+    static final String PASSWORD_ID_SALT_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordIdSalt\";\n+    private static final int DEK_CACHE_WEIGHT = 2048;\n+\n+    // this is the repository instance to which all blob reads and writes are forwarded to (it stores both the encrypted blobs, as well\n+    // as the associated encrypted DEKs)\n+    private final BlobStoreRepository delegatedRepository;\n+    // every data blob is encrypted with its randomly generated AES key (DEK)\n+    private final Supplier<Tuple<String, SecretKey>> DEKGenerator;\n+    // license is checked before every snapshot operations; protected non-final for tests\n+    protected Supplier<XPackLicenseState> licenseStateSupplier;\n+    private final char[] repositoryPassword;\n+    private final String localRepositoryPasswordId;\n+    private final String localRepositoryPasswordIdSalt;\n+    private final AtomicReference<String> validatedRepositoryPasswordId;\n+    private final Cache<String, SecretKey> DEKCache;\n+\n+    /**\n+     * Returns the byte length (i.e. the storage size) of an encrypted blob, given the length of the blob's plaintext contents.\n+     *\n+     * @see EncryptionPacketsInputStream#getEncryptionLength(long, int)\n+     */\n+    public static long getEncryptedBlobByteLength(long plaintextBlobByteLength) {\n+        return (long) DEK_ID_LENGTH /* UUID byte length */\n+            + EncryptionPacketsInputStream.getEncryptionLength(plaintextBlobByteLength, PACKET_LENGTH_IN_BYTES);\n+    }\n+\n+    protected EncryptedRepository(\n+        RepositoryMetaData metadata,\n+        NamedXContentRegistry namedXContentRegistry,\n+        ClusterService clusterService,\n+        BlobStoreRepository delegatedRepository,\n+        Supplier<XPackLicenseState> licenseStateSupplier,\n+        char[] repositoryPassword\n+    )\n+        throws GeneralSecurityException {\n+        super(\n+            metadata,\n+            namedXContentRegistry,\n+            clusterService,\n+            BlobPath.cleanPath() /* the encrypted repository uses a hardcoded empty\n+                                 base blob path but the base path setting is honored for the delegated repository */\n+        );\n+        this.delegatedRepository = delegatedRepository;\n+        this.DEKGenerator = createDEKGenerator();\n+        this.licenseStateSupplier = licenseStateSupplier;\n+        this.repositoryPassword = repositoryPassword;\n+        // the password \"id\" and validated\n+        this.localRepositoryPasswordIdSalt = UUIDs.randomBase64UUID();\n+        this.localRepositoryPasswordId = AESKeyUtils.computeId(\n+            AESKeyUtils.generatePasswordBasedKey(repositoryPassword, localRepositoryPasswordIdSalt.getBytes(StandardCharsets.UTF_8))\n+        );\n+        this.validatedRepositoryPasswordId = new AtomicReference<>(this.localRepositoryPasswordId);\n+        // stores decrypted DEKs; DEKs are reused to encrypt/decrypt multiple independent blobs\n+        this.DEKCache = CacheBuilder.<String, SecretKey>builder().setMaximumWeight(DEK_CACHE_WEIGHT).build();\n+        if (isReadOnly() != delegatedRepository.isReadOnly()) {\n+            throw new RepositoryException(\n+                metadata.name(),\n+                \"Unexpected fatal internal error\",\n+                new IllegalStateException(\"The encrypted repository must be read-only iff the delegate repository is read-only\")\n+            );\n+        }\n+    }\n+\n+    /**\n+     * The repository hook method which populates the snapshot metadata with the salted password hash of the repository on the (master)\n+     * node that starts of the snapshot operation. All the other actions associated with the same snapshot operation will first verify\n+     * that the local repository password checks with the hash from the snapshot metadata.\n+     * <p>\n+     * In addition, if the installed license does not comply with encrypted snapshots, this throws an exception, which aborts the snapshot\n+     * operation.\n+     *\n+     * See {@link org.elasticsearch.repositories.Repository#adaptUserMetadata(Map)}.\n+     *\n+     * @param userMetadata the snapshot metadata as received from the calling user\n+     * @return the snapshot metadata containing the salted password hash of the node initializing the snapshot\n+     */\n+    @Override\n+    public Map<String, Object> adaptUserMetadata(Map<String, Object> userMetadata) {\n+        // because populating the snapshot metadata must be done before the actual snapshot is first initialized,\n+        // we take the opportunity to validate the license and abort if non-compliant\n+        if (false == licenseStateSupplier.get().isEncryptedSnapshotAllowed()) {\n+            throw LicenseUtils.newComplianceException(\"encrypted snapshots\");\n+        }\n+        Map<String, Object> snapshotUserMetadata = new HashMap<>();\n+        if (userMetadata != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 170}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEzMzg0MA==", "bodyText": "This can just be an assertion I think", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402133840", "createdAt": "2020-04-02T08:20:40Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepository.java", "diffHunk": "@@ -6,11 +6,739 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n-public class EncryptedRepository {\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.lucene.index.IndexCommit;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.metadata.MetaData;\n+import org.elasticsearch.cluster.metadata.RepositoryMetaData;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.CheckedFunction;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.blobstore.BlobContainer;\n+import org.elasticsearch.common.blobstore.BlobMetaData;\n+import org.elasticsearch.common.blobstore.BlobPath;\n+import org.elasticsearch.common.blobstore.BlobStore;\n+import org.elasticsearch.common.blobstore.DeleteResult;\n+import org.elasticsearch.common.blobstore.support.AbstractBlobContainer;\n+import org.elasticsearch.common.cache.Cache;\n+import org.elasticsearch.common.cache.CacheBuilder;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.io.Streams;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.index.store.Store;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoryException;\n+import org.elasticsearch.repositories.ShardGenerations;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.SnapshotInfo;\n+import org.elasticsearch.snapshots.SnapshotShardFailure;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.SecretKey;\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.NoSuchFileException;\n+import java.security.GeneralSecurityException;\n+import java.security.SecureRandom;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+// not-final for tests\n+public class EncryptedRepository extends BlobStoreRepository {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepository.class);\n+    // the following constants are fixed by definition\n     static final int GCM_TAG_LENGTH_IN_BYTES = 16;\n     static final int GCM_IV_LENGTH_IN_BYTES = 12;\n-    static final int AES_BLOCK_SIZE_IN_BYTES = 128;\n+    static final int AES_BLOCK_LENGTH_IN_BYTES = 128;\n+    // the following constants require careful thought before changing because they will break backwards compatibility\n     static final String DATA_ENCRYPTION_SCHEME = \"AES/GCM/NoPadding\";\n     static final long PACKET_START_COUNTER = Long.MIN_VALUE;\n-    static final int MAX_PACKET_LENGTH_IN_BYTES = 1 << 30;\n+    static final int MAX_PACKET_LENGTH_IN_BYTES = 8 << 20; // 8MB\n+    // this should be smaller than {@code #MAX_PACKET_LENGTH_IN_BYTES} and it's what {@code EncryptionPacketsInputStream} uses\n+    // during encryption and what {@code DecryptionPacketsInputStream} expects during decryption (it is not configurable)\n+    static final int PACKET_LENGTH_IN_BYTES = 64 * (1 << 10); // 64KB\n+    // the path of the blob container holding all the DEKs\n+    // this is relative to the root base path holding the encrypted blobs (i.e. the repository root base path)\n+    static final String DEK_ROOT_CONTAINER = \".encryption-metadata\"; // package private for tests\n+    static final int DEK_ID_LENGTH = 22; // {@code org.elasticsearch.common.UUIDS} length\n+\n+    // the following constants can be changed freely\n+    private static final String RAND_ALGO = \"SHA1PRNG\";\n+    // each snapshot metadata contains an unforgeable identifier of the repository password of the master node that started the snapshot\n+    // this hash is then verified on each data node before the actual shard files snapshot, as well as on the\n+    // master node that finalizes the snapshot (could be a different master node, if a master failover occurred during the snapshot)\n+    static final String PASSWORD_ID_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordId\";\n+    static final String PASSWORD_ID_SALT_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordIdSalt\";\n+    private static final int DEK_CACHE_WEIGHT = 2048;\n+\n+    // this is the repository instance to which all blob reads and writes are forwarded to (it stores both the encrypted blobs, as well\n+    // as the associated encrypted DEKs)\n+    private final BlobStoreRepository delegatedRepository;\n+    // every data blob is encrypted with its randomly generated AES key (DEK)\n+    private final Supplier<Tuple<String, SecretKey>> DEKGenerator;\n+    // license is checked before every snapshot operations; protected non-final for tests\n+    protected Supplier<XPackLicenseState> licenseStateSupplier;\n+    private final char[] repositoryPassword;\n+    private final String localRepositoryPasswordId;\n+    private final String localRepositoryPasswordIdSalt;\n+    private final AtomicReference<String> validatedRepositoryPasswordId;\n+    private final Cache<String, SecretKey> DEKCache;\n+\n+    /**\n+     * Returns the byte length (i.e. the storage size) of an encrypted blob, given the length of the blob's plaintext contents.\n+     *\n+     * @see EncryptionPacketsInputStream#getEncryptionLength(long, int)\n+     */\n+    public static long getEncryptedBlobByteLength(long plaintextBlobByteLength) {\n+        return (long) DEK_ID_LENGTH /* UUID byte length */\n+            + EncryptionPacketsInputStream.getEncryptionLength(plaintextBlobByteLength, PACKET_LENGTH_IN_BYTES);\n+    }\n+\n+    protected EncryptedRepository(\n+        RepositoryMetaData metadata,\n+        NamedXContentRegistry namedXContentRegistry,\n+        ClusterService clusterService,\n+        BlobStoreRepository delegatedRepository,\n+        Supplier<XPackLicenseState> licenseStateSupplier,\n+        char[] repositoryPassword\n+    )\n+        throws GeneralSecurityException {\n+        super(\n+            metadata,\n+            namedXContentRegistry,\n+            clusterService,\n+            BlobPath.cleanPath() /* the encrypted repository uses a hardcoded empty\n+                                 base blob path but the base path setting is honored for the delegated repository */\n+        );\n+        this.delegatedRepository = delegatedRepository;\n+        this.DEKGenerator = createDEKGenerator();\n+        this.licenseStateSupplier = licenseStateSupplier;\n+        this.repositoryPassword = repositoryPassword;\n+        // the password \"id\" and validated\n+        this.localRepositoryPasswordIdSalt = UUIDs.randomBase64UUID();\n+        this.localRepositoryPasswordId = AESKeyUtils.computeId(\n+            AESKeyUtils.generatePasswordBasedKey(repositoryPassword, localRepositoryPasswordIdSalt.getBytes(StandardCharsets.UTF_8))\n+        );\n+        this.validatedRepositoryPasswordId = new AtomicReference<>(this.localRepositoryPasswordId);\n+        // stores decrypted DEKs; DEKs are reused to encrypt/decrypt multiple independent blobs\n+        this.DEKCache = CacheBuilder.<String, SecretKey>builder().setMaximumWeight(DEK_CACHE_WEIGHT).build();\n+        if (isReadOnly() != delegatedRepository.isReadOnly()) {\n+            throw new RepositoryException(\n+                metadata.name(),\n+                \"Unexpected fatal internal error\",\n+                new IllegalStateException(\"The encrypted repository must be read-only iff the delegate repository is read-only\")\n+            );\n+        }\n+    }\n+\n+    /**\n+     * The repository hook method which populates the snapshot metadata with the salted password hash of the repository on the (master)\n+     * node that starts of the snapshot operation. All the other actions associated with the same snapshot operation will first verify\n+     * that the local repository password checks with the hash from the snapshot metadata.\n+     * <p>\n+     * In addition, if the installed license does not comply with encrypted snapshots, this throws an exception, which aborts the snapshot\n+     * operation.\n+     *\n+     * See {@link org.elasticsearch.repositories.Repository#adaptUserMetadata(Map)}.\n+     *\n+     * @param userMetadata the snapshot metadata as received from the calling user\n+     * @return the snapshot metadata containing the salted password hash of the node initializing the snapshot\n+     */\n+    @Override\n+    public Map<String, Object> adaptUserMetadata(Map<String, Object> userMetadata) {\n+        // because populating the snapshot metadata must be done before the actual snapshot is first initialized,\n+        // we take the opportunity to validate the license and abort if non-compliant\n+        if (false == licenseStateSupplier.get().isEncryptedSnapshotAllowed()) {\n+            throw LicenseUtils.newComplianceException(\"encrypted snapshots\");\n+        }\n+        Map<String, Object> snapshotUserMetadata = new HashMap<>();\n+        if (userMetadata != null) {\n+            snapshotUserMetadata.putAll(userMetadata);\n+        }\n+        // set out the ID of the repository secret\n+        // this is then checked before every snapshot operation (i.e. {@link #snapshotShard} and {@link #finalizeSnapshot})\n+        // to assure that all participating nodes in the snapshot operation are using the same repository secret\n+        snapshotUserMetadata.put(PASSWORD_ID_SALT_USER_METADATA_KEY, localRepositoryPasswordIdSalt);\n+        snapshotUserMetadata.put(PASSWORD_ID_USER_METADATA_KEY, localRepositoryPasswordId);\n+        logger.trace(\n+            () -> new ParameterizedMessage(\n+                \"Snapshot metadata for local repository password  [{}] and [{}]\",\n+                localRepositoryPasswordIdSalt,\n+                localRepositoryPasswordId\n+            )\n+        );\n+        return Map.copyOf(snapshotUserMetadata);\n+    }\n+\n+    @Override\n+    public void finalizeSnapshot(\n+        SnapshotId snapshotId,\n+        ShardGenerations shardGenerations,\n+        long startTime,\n+        String failure,\n+        int totalShards,\n+        List<SnapshotShardFailure> shardFailures,\n+        long repositoryStateId,\n+        boolean includeGlobalState,\n+        MetaData clusterMetaData,\n+        Map<String, Object> userMetadata,\n+        Version repositoryMetaVersion,\n+        ActionListener<SnapshotInfo> listener\n+    ) {\n+        try {\n+            validateLocalRepositorySecret(userMetadata);\n+        } catch (RepositoryException passwordValidationException) {\n+            listener.onFailure(passwordValidationException);\n+            return;\n+        } finally {\n+            // remove the repository password id from the snapshot metadata so that the id is not displayed in the API response to the user\n+            userMetadata = new HashMap<>(userMetadata);\n+            userMetadata.remove(PASSWORD_ID_USER_METADATA_KEY);\n+            userMetadata.remove(PASSWORD_ID_SALT_USER_METADATA_KEY);\n+        }\n+        super.finalizeSnapshot(\n+            snapshotId,\n+            shardGenerations,\n+            startTime,\n+            failure,\n+            totalShards,\n+            shardFailures,\n+            repositoryStateId,\n+            includeGlobalState,\n+            clusterMetaData,\n+            userMetadata,\n+            repositoryMetaVersion,\n+            listener\n+        );\n+    }\n+\n+    @Override\n+    public void snapshotShard(\n+        Store store,\n+        MapperService mapperService,\n+        SnapshotId snapshotId,\n+        IndexId indexId,\n+        IndexCommit snapshotIndexCommit,\n+        String shardStateIdentifier,\n+        IndexShardSnapshotStatus snapshotStatus,\n+        Version repositoryMetaVersion,\n+        Map<String, Object> userMetadata,\n+        ActionListener<String> listener\n+    ) {\n+        try {\n+            validateLocalRepositorySecret(userMetadata);\n+        } catch (RepositoryException passwordValidationException) {\n+            listener.onFailure(passwordValidationException);\n+            return;\n+        }\n+        super.snapshotShard(\n+            store,\n+            mapperService,\n+            snapshotId,\n+            indexId,\n+            snapshotIndexCommit,\n+            shardStateIdentifier,\n+            snapshotStatus,\n+            repositoryMetaVersion,\n+            userMetadata,\n+            listener\n+        );\n+    }\n+\n+    @Override\n+    protected BlobStore createBlobStore() {\n+        final Supplier<Tuple<String, SecretKey>> DEKGenerator;\n+        if (isReadOnly()) {\n+            // make sure that a read-only repository can't encrypt anything\n+            DEKGenerator = () -> {\n+                throw new RepositoryException(\n+                    metadata.name(),\n+                    \"Unexpected fatal internal error\",\n+                    new IllegalStateException(\"DEKs are required for encryption but this is a read-only repository\")\n+                );\n+            };\n+        } else {\n+            DEKGenerator = this.DEKGenerator;\n+        }\n+        return new EncryptedBlobStore(\n+            delegatedRepository.blobStore(),\n+            delegatedRepository.basePath(),\n+            metadata.name(),\n+            this::generateKEK,\n+            DEKGenerator,\n+            DEKCache\n+        );\n+    }\n+\n+    @Override\n+    protected void doStart() {\n+        this.delegatedRepository.start();\n+        super.doStart();\n+    }\n+\n+    @Override\n+    protected void doStop() {\n+        super.doStop();\n+        this.delegatedRepository.stop();\n+    }\n+\n+    @Override\n+    protected void doClose() {\n+        super.doClose();\n+        this.delegatedRepository.close();\n+    }\n+\n+    private Supplier<Tuple<String, SecretKey>> createDEKGenerator() throws GeneralSecurityException {\n+        // DEK and DEK Ids MUST be generated randomly (with independent random instances)\n+        final SecureRandom DEKSecureRandom = SecureRandom.getInstance(RAND_ALGO);\n+        final SecureRandom DEKIdSecureRandom = SecureRandom.getInstance(RAND_ALGO);\n+        final KeyGenerator DEKGenerator = KeyGenerator.getInstance(DATA_ENCRYPTION_SCHEME.split(\"/\")[0]);\n+        DEKGenerator.init(AESKeyUtils.KEY_LENGTH_IN_BYTES * Byte.SIZE, DEKSecureRandom);\n+        return () -> {\n+            final String DEKId = UUIDs.randomBase64UUID(DEKIdSecureRandom);\n+            final SecretKey DEK = DEKGenerator.generateKey();\n+            logger.debug(() -> new ParameterizedMessage(\"Repository [{}]] generated new DEK [{}]\", metadata.name(), DEKId));\n+            return new Tuple<>(DEKId, DEK);\n+        };\n+    }\n+\n+    // pkg-private for tests\n+    Tuple<String, SecretKey> generateKEK(String DEKId) {\n+        try {\n+            // we rely on the DEK Id being generated randomly so it can be used as a salt\n+            final byte[] KEKsalt = DEKId.getBytes(StandardCharsets.UTF_8);\n+            final SecretKey KEK = AESKeyUtils.generatePasswordBasedKey(repositoryPassword, KEKsalt);\n+            final String KEKId = AESKeyUtils.computeId(KEK);\n+            logger.debug(() -> new ParameterizedMessage(\"Repository [{}] computed KEK [{}] for DEK [{}]\", metadata.name(), KEKId, DEKId));\n+            return new Tuple<>(KEKId, KEK);\n+        } catch (GeneralSecurityException e) {\n+            throw new RepositoryException(metadata.name(), \"Failure to generate KEK to wrap the DEK [\" + DEKId + \"]\", e);\n+        }\n+    }\n+\n+    /**\n+     * Called before the shard snapshot and finalize operations, on the data and master nodes. This validates that the repository\n+     * secret on the master node that started the snapshot operation is identical to the repository secret on the local node.\n+     *\n+     * @param snapshotUserMetadata the snapshot metadata containing the repository secret id to verify\n+     * @throws RepositoryException if the repository secret id on the local node mismatches the master's\n+     */\n+    private void validateLocalRepositorySecret(Map<String, Object> snapshotUserMetadata) throws RepositoryException {\n+        if (snapshotUserMetadata == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 342}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEzNDA1Mw==", "bodyText": "Same here, assertion should be fine, we have full control of this map end-to-end I think", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402134053", "createdAt": "2020-04-02T08:21:04Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepository.java", "diffHunk": "@@ -6,11 +6,739 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n-public class EncryptedRepository {\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.lucene.index.IndexCommit;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.metadata.MetaData;\n+import org.elasticsearch.cluster.metadata.RepositoryMetaData;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.CheckedFunction;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.blobstore.BlobContainer;\n+import org.elasticsearch.common.blobstore.BlobMetaData;\n+import org.elasticsearch.common.blobstore.BlobPath;\n+import org.elasticsearch.common.blobstore.BlobStore;\n+import org.elasticsearch.common.blobstore.DeleteResult;\n+import org.elasticsearch.common.blobstore.support.AbstractBlobContainer;\n+import org.elasticsearch.common.cache.Cache;\n+import org.elasticsearch.common.cache.CacheBuilder;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.io.Streams;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.index.store.Store;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoryException;\n+import org.elasticsearch.repositories.ShardGenerations;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.SnapshotInfo;\n+import org.elasticsearch.snapshots.SnapshotShardFailure;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.SecretKey;\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.NoSuchFileException;\n+import java.security.GeneralSecurityException;\n+import java.security.SecureRandom;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+// not-final for tests\n+public class EncryptedRepository extends BlobStoreRepository {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepository.class);\n+    // the following constants are fixed by definition\n     static final int GCM_TAG_LENGTH_IN_BYTES = 16;\n     static final int GCM_IV_LENGTH_IN_BYTES = 12;\n-    static final int AES_BLOCK_SIZE_IN_BYTES = 128;\n+    static final int AES_BLOCK_LENGTH_IN_BYTES = 128;\n+    // the following constants require careful thought before changing because they will break backwards compatibility\n     static final String DATA_ENCRYPTION_SCHEME = \"AES/GCM/NoPadding\";\n     static final long PACKET_START_COUNTER = Long.MIN_VALUE;\n-    static final int MAX_PACKET_LENGTH_IN_BYTES = 1 << 30;\n+    static final int MAX_PACKET_LENGTH_IN_BYTES = 8 << 20; // 8MB\n+    // this should be smaller than {@code #MAX_PACKET_LENGTH_IN_BYTES} and it's what {@code EncryptionPacketsInputStream} uses\n+    // during encryption and what {@code DecryptionPacketsInputStream} expects during decryption (it is not configurable)\n+    static final int PACKET_LENGTH_IN_BYTES = 64 * (1 << 10); // 64KB\n+    // the path of the blob container holding all the DEKs\n+    // this is relative to the root base path holding the encrypted blobs (i.e. the repository root base path)\n+    static final String DEK_ROOT_CONTAINER = \".encryption-metadata\"; // package private for tests\n+    static final int DEK_ID_LENGTH = 22; // {@code org.elasticsearch.common.UUIDS} length\n+\n+    // the following constants can be changed freely\n+    private static final String RAND_ALGO = \"SHA1PRNG\";\n+    // each snapshot metadata contains an unforgeable identifier of the repository password of the master node that started the snapshot\n+    // this hash is then verified on each data node before the actual shard files snapshot, as well as on the\n+    // master node that finalizes the snapshot (could be a different master node, if a master failover occurred during the snapshot)\n+    static final String PASSWORD_ID_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordId\";\n+    static final String PASSWORD_ID_SALT_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordIdSalt\";\n+    private static final int DEK_CACHE_WEIGHT = 2048;\n+\n+    // this is the repository instance to which all blob reads and writes are forwarded to (it stores both the encrypted blobs, as well\n+    // as the associated encrypted DEKs)\n+    private final BlobStoreRepository delegatedRepository;\n+    // every data blob is encrypted with its randomly generated AES key (DEK)\n+    private final Supplier<Tuple<String, SecretKey>> DEKGenerator;\n+    // license is checked before every snapshot operations; protected non-final for tests\n+    protected Supplier<XPackLicenseState> licenseStateSupplier;\n+    private final char[] repositoryPassword;\n+    private final String localRepositoryPasswordId;\n+    private final String localRepositoryPasswordIdSalt;\n+    private final AtomicReference<String> validatedRepositoryPasswordId;\n+    private final Cache<String, SecretKey> DEKCache;\n+\n+    /**\n+     * Returns the byte length (i.e. the storage size) of an encrypted blob, given the length of the blob's plaintext contents.\n+     *\n+     * @see EncryptionPacketsInputStream#getEncryptionLength(long, int)\n+     */\n+    public static long getEncryptedBlobByteLength(long plaintextBlobByteLength) {\n+        return (long) DEK_ID_LENGTH /* UUID byte length */\n+            + EncryptionPacketsInputStream.getEncryptionLength(plaintextBlobByteLength, PACKET_LENGTH_IN_BYTES);\n+    }\n+\n+    protected EncryptedRepository(\n+        RepositoryMetaData metadata,\n+        NamedXContentRegistry namedXContentRegistry,\n+        ClusterService clusterService,\n+        BlobStoreRepository delegatedRepository,\n+        Supplier<XPackLicenseState> licenseStateSupplier,\n+        char[] repositoryPassword\n+    )\n+        throws GeneralSecurityException {\n+        super(\n+            metadata,\n+            namedXContentRegistry,\n+            clusterService,\n+            BlobPath.cleanPath() /* the encrypted repository uses a hardcoded empty\n+                                 base blob path but the base path setting is honored for the delegated repository */\n+        );\n+        this.delegatedRepository = delegatedRepository;\n+        this.DEKGenerator = createDEKGenerator();\n+        this.licenseStateSupplier = licenseStateSupplier;\n+        this.repositoryPassword = repositoryPassword;\n+        // the password \"id\" and validated\n+        this.localRepositoryPasswordIdSalt = UUIDs.randomBase64UUID();\n+        this.localRepositoryPasswordId = AESKeyUtils.computeId(\n+            AESKeyUtils.generatePasswordBasedKey(repositoryPassword, localRepositoryPasswordIdSalt.getBytes(StandardCharsets.UTF_8))\n+        );\n+        this.validatedRepositoryPasswordId = new AtomicReference<>(this.localRepositoryPasswordId);\n+        // stores decrypted DEKs; DEKs are reused to encrypt/decrypt multiple independent blobs\n+        this.DEKCache = CacheBuilder.<String, SecretKey>builder().setMaximumWeight(DEK_CACHE_WEIGHT).build();\n+        if (isReadOnly() != delegatedRepository.isReadOnly()) {\n+            throw new RepositoryException(\n+                metadata.name(),\n+                \"Unexpected fatal internal error\",\n+                new IllegalStateException(\"The encrypted repository must be read-only iff the delegate repository is read-only\")\n+            );\n+        }\n+    }\n+\n+    /**\n+     * The repository hook method which populates the snapshot metadata with the salted password hash of the repository on the (master)\n+     * node that starts of the snapshot operation. All the other actions associated with the same snapshot operation will first verify\n+     * that the local repository password checks with the hash from the snapshot metadata.\n+     * <p>\n+     * In addition, if the installed license does not comply with encrypted snapshots, this throws an exception, which aborts the snapshot\n+     * operation.\n+     *\n+     * See {@link org.elasticsearch.repositories.Repository#adaptUserMetadata(Map)}.\n+     *\n+     * @param userMetadata the snapshot metadata as received from the calling user\n+     * @return the snapshot metadata containing the salted password hash of the node initializing the snapshot\n+     */\n+    @Override\n+    public Map<String, Object> adaptUserMetadata(Map<String, Object> userMetadata) {\n+        // because populating the snapshot metadata must be done before the actual snapshot is first initialized,\n+        // we take the opportunity to validate the license and abort if non-compliant\n+        if (false == licenseStateSupplier.get().isEncryptedSnapshotAllowed()) {\n+            throw LicenseUtils.newComplianceException(\"encrypted snapshots\");\n+        }\n+        Map<String, Object> snapshotUserMetadata = new HashMap<>();\n+        if (userMetadata != null) {\n+            snapshotUserMetadata.putAll(userMetadata);\n+        }\n+        // set out the ID of the repository secret\n+        // this is then checked before every snapshot operation (i.e. {@link #snapshotShard} and {@link #finalizeSnapshot})\n+        // to assure that all participating nodes in the snapshot operation are using the same repository secret\n+        snapshotUserMetadata.put(PASSWORD_ID_SALT_USER_METADATA_KEY, localRepositoryPasswordIdSalt);\n+        snapshotUserMetadata.put(PASSWORD_ID_USER_METADATA_KEY, localRepositoryPasswordId);\n+        logger.trace(\n+            () -> new ParameterizedMessage(\n+                \"Snapshot metadata for local repository password  [{}] and [{}]\",\n+                localRepositoryPasswordIdSalt,\n+                localRepositoryPasswordId\n+            )\n+        );\n+        return Map.copyOf(snapshotUserMetadata);\n+    }\n+\n+    @Override\n+    public void finalizeSnapshot(\n+        SnapshotId snapshotId,\n+        ShardGenerations shardGenerations,\n+        long startTime,\n+        String failure,\n+        int totalShards,\n+        List<SnapshotShardFailure> shardFailures,\n+        long repositoryStateId,\n+        boolean includeGlobalState,\n+        MetaData clusterMetaData,\n+        Map<String, Object> userMetadata,\n+        Version repositoryMetaVersion,\n+        ActionListener<SnapshotInfo> listener\n+    ) {\n+        try {\n+            validateLocalRepositorySecret(userMetadata);\n+        } catch (RepositoryException passwordValidationException) {\n+            listener.onFailure(passwordValidationException);\n+            return;\n+        } finally {\n+            // remove the repository password id from the snapshot metadata so that the id is not displayed in the API response to the user\n+            userMetadata = new HashMap<>(userMetadata);\n+            userMetadata.remove(PASSWORD_ID_USER_METADATA_KEY);\n+            userMetadata.remove(PASSWORD_ID_SALT_USER_METADATA_KEY);\n+        }\n+        super.finalizeSnapshot(\n+            snapshotId,\n+            shardGenerations,\n+            startTime,\n+            failure,\n+            totalShards,\n+            shardFailures,\n+            repositoryStateId,\n+            includeGlobalState,\n+            clusterMetaData,\n+            userMetadata,\n+            repositoryMetaVersion,\n+            listener\n+        );\n+    }\n+\n+    @Override\n+    public void snapshotShard(\n+        Store store,\n+        MapperService mapperService,\n+        SnapshotId snapshotId,\n+        IndexId indexId,\n+        IndexCommit snapshotIndexCommit,\n+        String shardStateIdentifier,\n+        IndexShardSnapshotStatus snapshotStatus,\n+        Version repositoryMetaVersion,\n+        Map<String, Object> userMetadata,\n+        ActionListener<String> listener\n+    ) {\n+        try {\n+            validateLocalRepositorySecret(userMetadata);\n+        } catch (RepositoryException passwordValidationException) {\n+            listener.onFailure(passwordValidationException);\n+            return;\n+        }\n+        super.snapshotShard(\n+            store,\n+            mapperService,\n+            snapshotId,\n+            indexId,\n+            snapshotIndexCommit,\n+            shardStateIdentifier,\n+            snapshotStatus,\n+            repositoryMetaVersion,\n+            userMetadata,\n+            listener\n+        );\n+    }\n+\n+    @Override\n+    protected BlobStore createBlobStore() {\n+        final Supplier<Tuple<String, SecretKey>> DEKGenerator;\n+        if (isReadOnly()) {\n+            // make sure that a read-only repository can't encrypt anything\n+            DEKGenerator = () -> {\n+                throw new RepositoryException(\n+                    metadata.name(),\n+                    \"Unexpected fatal internal error\",\n+                    new IllegalStateException(\"DEKs are required for encryption but this is a read-only repository\")\n+                );\n+            };\n+        } else {\n+            DEKGenerator = this.DEKGenerator;\n+        }\n+        return new EncryptedBlobStore(\n+            delegatedRepository.blobStore(),\n+            delegatedRepository.basePath(),\n+            metadata.name(),\n+            this::generateKEK,\n+            DEKGenerator,\n+            DEKCache\n+        );\n+    }\n+\n+    @Override\n+    protected void doStart() {\n+        this.delegatedRepository.start();\n+        super.doStart();\n+    }\n+\n+    @Override\n+    protected void doStop() {\n+        super.doStop();\n+        this.delegatedRepository.stop();\n+    }\n+\n+    @Override\n+    protected void doClose() {\n+        super.doClose();\n+        this.delegatedRepository.close();\n+    }\n+\n+    private Supplier<Tuple<String, SecretKey>> createDEKGenerator() throws GeneralSecurityException {\n+        // DEK and DEK Ids MUST be generated randomly (with independent random instances)\n+        final SecureRandom DEKSecureRandom = SecureRandom.getInstance(RAND_ALGO);\n+        final SecureRandom DEKIdSecureRandom = SecureRandom.getInstance(RAND_ALGO);\n+        final KeyGenerator DEKGenerator = KeyGenerator.getInstance(DATA_ENCRYPTION_SCHEME.split(\"/\")[0]);\n+        DEKGenerator.init(AESKeyUtils.KEY_LENGTH_IN_BYTES * Byte.SIZE, DEKSecureRandom);\n+        return () -> {\n+            final String DEKId = UUIDs.randomBase64UUID(DEKIdSecureRandom);\n+            final SecretKey DEK = DEKGenerator.generateKey();\n+            logger.debug(() -> new ParameterizedMessage(\"Repository [{}]] generated new DEK [{}]\", metadata.name(), DEKId));\n+            return new Tuple<>(DEKId, DEK);\n+        };\n+    }\n+\n+    // pkg-private for tests\n+    Tuple<String, SecretKey> generateKEK(String DEKId) {\n+        try {\n+            // we rely on the DEK Id being generated randomly so it can be used as a salt\n+            final byte[] KEKsalt = DEKId.getBytes(StandardCharsets.UTF_8);\n+            final SecretKey KEK = AESKeyUtils.generatePasswordBasedKey(repositoryPassword, KEKsalt);\n+            final String KEKId = AESKeyUtils.computeId(KEK);\n+            logger.debug(() -> new ParameterizedMessage(\"Repository [{}] computed KEK [{}] for DEK [{}]\", metadata.name(), KEKId, DEKId));\n+            return new Tuple<>(KEKId, KEK);\n+        } catch (GeneralSecurityException e) {\n+            throw new RepositoryException(metadata.name(), \"Failure to generate KEK to wrap the DEK [\" + DEKId + \"]\", e);\n+        }\n+    }\n+\n+    /**\n+     * Called before the shard snapshot and finalize operations, on the data and master nodes. This validates that the repository\n+     * secret on the master node that started the snapshot operation is identical to the repository secret on the local node.\n+     *\n+     * @param snapshotUserMetadata the snapshot metadata containing the repository secret id to verify\n+     * @throws RepositoryException if the repository secret id on the local node mismatches the master's\n+     */\n+    private void validateLocalRepositorySecret(Map<String, Object> snapshotUserMetadata) throws RepositoryException {\n+        if (snapshotUserMetadata == null) {\n+            throw new RepositoryException(\n+                metadata.name(),\n+                \"Unexpected fatal internal error\",\n+                new IllegalStateException(\"Null snapshot metadata\")\n+            );\n+        }\n+        final Object masterRepositoryPasswordId = snapshotUserMetadata.get(PASSWORD_ID_USER_METADATA_KEY);\n+        if (false == masterRepositoryPasswordId instanceof String) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 350}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEzNTY0Mg==", "bodyText": "No need for the message supplier pattern here either I think", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402135642", "createdAt": "2020-04-02T08:23:47Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepository.java", "diffHunk": "@@ -6,11 +6,739 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n-public class EncryptedRepository {\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.lucene.index.IndexCommit;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.metadata.MetaData;\n+import org.elasticsearch.cluster.metadata.RepositoryMetaData;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.CheckedFunction;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.blobstore.BlobContainer;\n+import org.elasticsearch.common.blobstore.BlobMetaData;\n+import org.elasticsearch.common.blobstore.BlobPath;\n+import org.elasticsearch.common.blobstore.BlobStore;\n+import org.elasticsearch.common.blobstore.DeleteResult;\n+import org.elasticsearch.common.blobstore.support.AbstractBlobContainer;\n+import org.elasticsearch.common.cache.Cache;\n+import org.elasticsearch.common.cache.CacheBuilder;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.io.Streams;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.index.store.Store;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoryException;\n+import org.elasticsearch.repositories.ShardGenerations;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.SnapshotInfo;\n+import org.elasticsearch.snapshots.SnapshotShardFailure;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.SecretKey;\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.NoSuchFileException;\n+import java.security.GeneralSecurityException;\n+import java.security.SecureRandom;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+// not-final for tests\n+public class EncryptedRepository extends BlobStoreRepository {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepository.class);\n+    // the following constants are fixed by definition\n     static final int GCM_TAG_LENGTH_IN_BYTES = 16;\n     static final int GCM_IV_LENGTH_IN_BYTES = 12;\n-    static final int AES_BLOCK_SIZE_IN_BYTES = 128;\n+    static final int AES_BLOCK_LENGTH_IN_BYTES = 128;\n+    // the following constants require careful thought before changing because they will break backwards compatibility\n     static final String DATA_ENCRYPTION_SCHEME = \"AES/GCM/NoPadding\";\n     static final long PACKET_START_COUNTER = Long.MIN_VALUE;\n-    static final int MAX_PACKET_LENGTH_IN_BYTES = 1 << 30;\n+    static final int MAX_PACKET_LENGTH_IN_BYTES = 8 << 20; // 8MB\n+    // this should be smaller than {@code #MAX_PACKET_LENGTH_IN_BYTES} and it's what {@code EncryptionPacketsInputStream} uses\n+    // during encryption and what {@code DecryptionPacketsInputStream} expects during decryption (it is not configurable)\n+    static final int PACKET_LENGTH_IN_BYTES = 64 * (1 << 10); // 64KB\n+    // the path of the blob container holding all the DEKs\n+    // this is relative to the root base path holding the encrypted blobs (i.e. the repository root base path)\n+    static final String DEK_ROOT_CONTAINER = \".encryption-metadata\"; // package private for tests\n+    static final int DEK_ID_LENGTH = 22; // {@code org.elasticsearch.common.UUIDS} length\n+\n+    // the following constants can be changed freely\n+    private static final String RAND_ALGO = \"SHA1PRNG\";\n+    // each snapshot metadata contains an unforgeable identifier of the repository password of the master node that started the snapshot\n+    // this hash is then verified on each data node before the actual shard files snapshot, as well as on the\n+    // master node that finalizes the snapshot (could be a different master node, if a master failover occurred during the snapshot)\n+    static final String PASSWORD_ID_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordId\";\n+    static final String PASSWORD_ID_SALT_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordIdSalt\";\n+    private static final int DEK_CACHE_WEIGHT = 2048;\n+\n+    // this is the repository instance to which all blob reads and writes are forwarded to (it stores both the encrypted blobs, as well\n+    // as the associated encrypted DEKs)\n+    private final BlobStoreRepository delegatedRepository;\n+    // every data blob is encrypted with its randomly generated AES key (DEK)\n+    private final Supplier<Tuple<String, SecretKey>> DEKGenerator;\n+    // license is checked before every snapshot operations; protected non-final for tests\n+    protected Supplier<XPackLicenseState> licenseStateSupplier;\n+    private final char[] repositoryPassword;\n+    private final String localRepositoryPasswordId;\n+    private final String localRepositoryPasswordIdSalt;\n+    private final AtomicReference<String> validatedRepositoryPasswordId;\n+    private final Cache<String, SecretKey> DEKCache;\n+\n+    /**\n+     * Returns the byte length (i.e. the storage size) of an encrypted blob, given the length of the blob's plaintext contents.\n+     *\n+     * @see EncryptionPacketsInputStream#getEncryptionLength(long, int)\n+     */\n+    public static long getEncryptedBlobByteLength(long plaintextBlobByteLength) {\n+        return (long) DEK_ID_LENGTH /* UUID byte length */\n+            + EncryptionPacketsInputStream.getEncryptionLength(plaintextBlobByteLength, PACKET_LENGTH_IN_BYTES);\n+    }\n+\n+    protected EncryptedRepository(\n+        RepositoryMetaData metadata,\n+        NamedXContentRegistry namedXContentRegistry,\n+        ClusterService clusterService,\n+        BlobStoreRepository delegatedRepository,\n+        Supplier<XPackLicenseState> licenseStateSupplier,\n+        char[] repositoryPassword\n+    )\n+        throws GeneralSecurityException {\n+        super(\n+            metadata,\n+            namedXContentRegistry,\n+            clusterService,\n+            BlobPath.cleanPath() /* the encrypted repository uses a hardcoded empty\n+                                 base blob path but the base path setting is honored for the delegated repository */\n+        );\n+        this.delegatedRepository = delegatedRepository;\n+        this.DEKGenerator = createDEKGenerator();\n+        this.licenseStateSupplier = licenseStateSupplier;\n+        this.repositoryPassword = repositoryPassword;\n+        // the password \"id\" and validated\n+        this.localRepositoryPasswordIdSalt = UUIDs.randomBase64UUID();\n+        this.localRepositoryPasswordId = AESKeyUtils.computeId(\n+            AESKeyUtils.generatePasswordBasedKey(repositoryPassword, localRepositoryPasswordIdSalt.getBytes(StandardCharsets.UTF_8))\n+        );\n+        this.validatedRepositoryPasswordId = new AtomicReference<>(this.localRepositoryPasswordId);\n+        // stores decrypted DEKs; DEKs are reused to encrypt/decrypt multiple independent blobs\n+        this.DEKCache = CacheBuilder.<String, SecretKey>builder().setMaximumWeight(DEK_CACHE_WEIGHT).build();\n+        if (isReadOnly() != delegatedRepository.isReadOnly()) {\n+            throw new RepositoryException(\n+                metadata.name(),\n+                \"Unexpected fatal internal error\",\n+                new IllegalStateException(\"The encrypted repository must be read-only iff the delegate repository is read-only\")\n+            );\n+        }\n+    }\n+\n+    /**\n+     * The repository hook method which populates the snapshot metadata with the salted password hash of the repository on the (master)\n+     * node that starts of the snapshot operation. All the other actions associated with the same snapshot operation will first verify\n+     * that the local repository password checks with the hash from the snapshot metadata.\n+     * <p>\n+     * In addition, if the installed license does not comply with encrypted snapshots, this throws an exception, which aborts the snapshot\n+     * operation.\n+     *\n+     * See {@link org.elasticsearch.repositories.Repository#adaptUserMetadata(Map)}.\n+     *\n+     * @param userMetadata the snapshot metadata as received from the calling user\n+     * @return the snapshot metadata containing the salted password hash of the node initializing the snapshot\n+     */\n+    @Override\n+    public Map<String, Object> adaptUserMetadata(Map<String, Object> userMetadata) {\n+        // because populating the snapshot metadata must be done before the actual snapshot is first initialized,\n+        // we take the opportunity to validate the license and abort if non-compliant\n+        if (false == licenseStateSupplier.get().isEncryptedSnapshotAllowed()) {\n+            throw LicenseUtils.newComplianceException(\"encrypted snapshots\");\n+        }\n+        Map<String, Object> snapshotUserMetadata = new HashMap<>();\n+        if (userMetadata != null) {\n+            snapshotUserMetadata.putAll(userMetadata);\n+        }\n+        // set out the ID of the repository secret\n+        // this is then checked before every snapshot operation (i.e. {@link #snapshotShard} and {@link #finalizeSnapshot})\n+        // to assure that all participating nodes in the snapshot operation are using the same repository secret\n+        snapshotUserMetadata.put(PASSWORD_ID_SALT_USER_METADATA_KEY, localRepositoryPasswordIdSalt);\n+        snapshotUserMetadata.put(PASSWORD_ID_USER_METADATA_KEY, localRepositoryPasswordId);\n+        logger.trace(\n+            () -> new ParameterizedMessage(\n+                \"Snapshot metadata for local repository password  [{}] and [{}]\",\n+                localRepositoryPasswordIdSalt,\n+                localRepositoryPasswordId\n+            )\n+        );\n+        return Map.copyOf(snapshotUserMetadata);\n+    }\n+\n+    @Override\n+    public void finalizeSnapshot(\n+        SnapshotId snapshotId,\n+        ShardGenerations shardGenerations,\n+        long startTime,\n+        String failure,\n+        int totalShards,\n+        List<SnapshotShardFailure> shardFailures,\n+        long repositoryStateId,\n+        boolean includeGlobalState,\n+        MetaData clusterMetaData,\n+        Map<String, Object> userMetadata,\n+        Version repositoryMetaVersion,\n+        ActionListener<SnapshotInfo> listener\n+    ) {\n+        try {\n+            validateLocalRepositorySecret(userMetadata);\n+        } catch (RepositoryException passwordValidationException) {\n+            listener.onFailure(passwordValidationException);\n+            return;\n+        } finally {\n+            // remove the repository password id from the snapshot metadata so that the id is not displayed in the API response to the user\n+            userMetadata = new HashMap<>(userMetadata);\n+            userMetadata.remove(PASSWORD_ID_USER_METADATA_KEY);\n+            userMetadata.remove(PASSWORD_ID_SALT_USER_METADATA_KEY);\n+        }\n+        super.finalizeSnapshot(\n+            snapshotId,\n+            shardGenerations,\n+            startTime,\n+            failure,\n+            totalShards,\n+            shardFailures,\n+            repositoryStateId,\n+            includeGlobalState,\n+            clusterMetaData,\n+            userMetadata,\n+            repositoryMetaVersion,\n+            listener\n+        );\n+    }\n+\n+    @Override\n+    public void snapshotShard(\n+        Store store,\n+        MapperService mapperService,\n+        SnapshotId snapshotId,\n+        IndexId indexId,\n+        IndexCommit snapshotIndexCommit,\n+        String shardStateIdentifier,\n+        IndexShardSnapshotStatus snapshotStatus,\n+        Version repositoryMetaVersion,\n+        Map<String, Object> userMetadata,\n+        ActionListener<String> listener\n+    ) {\n+        try {\n+            validateLocalRepositorySecret(userMetadata);\n+        } catch (RepositoryException passwordValidationException) {\n+            listener.onFailure(passwordValidationException);\n+            return;\n+        }\n+        super.snapshotShard(\n+            store,\n+            mapperService,\n+            snapshotId,\n+            indexId,\n+            snapshotIndexCommit,\n+            shardStateIdentifier,\n+            snapshotStatus,\n+            repositoryMetaVersion,\n+            userMetadata,\n+            listener\n+        );\n+    }\n+\n+    @Override\n+    protected BlobStore createBlobStore() {\n+        final Supplier<Tuple<String, SecretKey>> DEKGenerator;\n+        if (isReadOnly()) {\n+            // make sure that a read-only repository can't encrypt anything\n+            DEKGenerator = () -> {\n+                throw new RepositoryException(\n+                    metadata.name(),\n+                    \"Unexpected fatal internal error\",\n+                    new IllegalStateException(\"DEKs are required for encryption but this is a read-only repository\")\n+                );\n+            };\n+        } else {\n+            DEKGenerator = this.DEKGenerator;\n+        }\n+        return new EncryptedBlobStore(\n+            delegatedRepository.blobStore(),\n+            delegatedRepository.basePath(),\n+            metadata.name(),\n+            this::generateKEK,\n+            DEKGenerator,\n+            DEKCache\n+        );\n+    }\n+\n+    @Override\n+    protected void doStart() {\n+        this.delegatedRepository.start();\n+        super.doStart();\n+    }\n+\n+    @Override\n+    protected void doStop() {\n+        super.doStop();\n+        this.delegatedRepository.stop();\n+    }\n+\n+    @Override\n+    protected void doClose() {\n+        super.doClose();\n+        this.delegatedRepository.close();\n+    }\n+\n+    private Supplier<Tuple<String, SecretKey>> createDEKGenerator() throws GeneralSecurityException {\n+        // DEK and DEK Ids MUST be generated randomly (with independent random instances)\n+        final SecureRandom DEKSecureRandom = SecureRandom.getInstance(RAND_ALGO);\n+        final SecureRandom DEKIdSecureRandom = SecureRandom.getInstance(RAND_ALGO);\n+        final KeyGenerator DEKGenerator = KeyGenerator.getInstance(DATA_ENCRYPTION_SCHEME.split(\"/\")[0]);\n+        DEKGenerator.init(AESKeyUtils.KEY_LENGTH_IN_BYTES * Byte.SIZE, DEKSecureRandom);\n+        return () -> {\n+            final String DEKId = UUIDs.randomBase64UUID(DEKIdSecureRandom);\n+            final SecretKey DEK = DEKGenerator.generateKey();\n+            logger.debug(() -> new ParameterizedMessage(\"Repository [{}]] generated new DEK [{}]\", metadata.name(), DEKId));\n+            return new Tuple<>(DEKId, DEK);\n+        };\n+    }\n+\n+    // pkg-private for tests\n+    Tuple<String, SecretKey> generateKEK(String DEKId) {\n+        try {\n+            // we rely on the DEK Id being generated randomly so it can be used as a salt\n+            final byte[] KEKsalt = DEKId.getBytes(StandardCharsets.UTF_8);\n+            final SecretKey KEK = AESKeyUtils.generatePasswordBasedKey(repositoryPassword, KEKsalt);\n+            final String KEKId = AESKeyUtils.computeId(KEK);\n+            logger.debug(() -> new ParameterizedMessage(\"Repository [{}] computed KEK [{}] for DEK [{}]\", metadata.name(), KEKId, DEKId));\n+            return new Tuple<>(KEKId, KEK);\n+        } catch (GeneralSecurityException e) {\n+            throw new RepositoryException(metadata.name(), \"Failure to generate KEK to wrap the DEK [\" + DEKId + \"]\", e);\n+        }\n+    }\n+\n+    /**\n+     * Called before the shard snapshot and finalize operations, on the data and master nodes. This validates that the repository\n+     * secret on the master node that started the snapshot operation is identical to the repository secret on the local node.\n+     *\n+     * @param snapshotUserMetadata the snapshot metadata containing the repository secret id to verify\n+     * @throws RepositoryException if the repository secret id on the local node mismatches the master's\n+     */\n+    private void validateLocalRepositorySecret(Map<String, Object> snapshotUserMetadata) throws RepositoryException {\n+        if (snapshotUserMetadata == null) {\n+            throw new RepositoryException(\n+                metadata.name(),\n+                \"Unexpected fatal internal error\",\n+                new IllegalStateException(\"Null snapshot metadata\")\n+            );\n+        }\n+        final Object masterRepositoryPasswordId = snapshotUserMetadata.get(PASSWORD_ID_USER_METADATA_KEY);\n+        if (false == masterRepositoryPasswordId instanceof String) {\n+            throw new RepositoryException(\n+                metadata.name(),\n+                \"Unexpected fatal internal error\",\n+                new IllegalStateException(\"Snapshot metadata does not contain the repository password id as a String\")\n+            );\n+        }\n+        if (false == validatedRepositoryPasswordId.get().equals(masterRepositoryPasswordId)) {\n+            final Object masterRepositoryPasswordIdSalt = snapshotUserMetadata.get(PASSWORD_ID_SALT_USER_METADATA_KEY);\n+            if (false == masterRepositoryPasswordIdSalt instanceof String) {\n+                throw new RepositoryException(\n+                    metadata.name(),\n+                    \"Unexpected fatal internal error\",\n+                    new IllegalStateException(\"Snapshot metadata does not contain the repository password salt as a String\")\n+                );\n+            }\n+            final String computedRepositoryPasswordId;\n+            try {\n+                computedRepositoryPasswordId = AESKeyUtils.computeId(\n+                    AESKeyUtils.generatePasswordBasedKey(\n+                        repositoryPassword,\n+                        ((String) masterRepositoryPasswordIdSalt).getBytes(StandardCharsets.UTF_8)\n+                    )\n+                );\n+            } catch (Exception e) {\n+                throw new RepositoryException(metadata.name(), \"Unexpected fatal internal error\", e);\n+            }\n+            if (computedRepositoryPasswordId.equals(masterRepositoryPasswordId)) {\n+                this.validatedRepositoryPasswordId.set(computedRepositoryPasswordId);\n+            } else {\n+                throw new RepositoryException(\n+                    metadata.name(),\n+                    \"Repository secret id mismatch. The local node's repository secret, the keystore setting [\"\n+                        + EncryptedRepositoryPlugin.ENCRYPTION_PASSWORD_SETTING.getConcreteSettingForNamespace(\n+                            EncryptedRepositoryPlugin.PASSWORD_NAME_SETTING.get(metadata.settings())\n+                        ).getKey()\n+                        + \"], is different compared to the elected master node's which started the snapshot operation\"\n+                );\n+            }\n+        }\n+    }\n+\n+    // pkg-private for tests\n+    static final class EncryptedBlobStore implements BlobStore {\n+        private final BlobStore delegatedBlobStore;\n+        private final BlobPath delegatedBasePath;\n+        private final String repositoryName;\n+        private final Function<String, Tuple<String, SecretKey>> getKEKforDEK;\n+        private final Cache<String, SecretKey> DEKCache;\n+        private final CheckedSupplier<SingleUseKey, IOException> singleUseDEKSupplier;\n+\n+        EncryptedBlobStore(\n+            BlobStore delegatedBlobStore,\n+            BlobPath delegatedBasePath,\n+            String repositoryName,\n+            Function<String, Tuple<String, SecretKey>> getKEKforDEK,\n+            Supplier<Tuple<String, SecretKey>> DEKGenerator,\n+            Cache<String, SecretKey> DEKCache\n+        ) {\n+            this.delegatedBlobStore = delegatedBlobStore;\n+            this.delegatedBasePath = delegatedBasePath;\n+            this.repositoryName = repositoryName;\n+            this.getKEKforDEK = getKEKforDEK;\n+            this.DEKCache = DEKCache;\n+            this.singleUseDEKSupplier = SingleUseKey.createSingleUseKeySupplier(() -> {\n+                Tuple<String, SecretKey> newDEK = DEKGenerator.get();\n+                // store the newly generated DEK before making it available\n+                storeDEK(newDEK.v1(), newDEK.v2());\n+                return newDEK;\n+            });\n+        }\n+\n+        // pkg-private for tests\n+        SecretKey getDEKById(String DEKId) throws IOException {\n+            try {\n+                return DEKCache.computeIfAbsent(DEKId, ignored -> loadDEK(DEKId));\n+            } catch (ExecutionException e) {\n+                // some exception types are to be expected\n+                if (e.getCause() instanceof IOException) {\n+                    throw (IOException) e.getCause();\n+                } else if (e.getCause() instanceof ElasticsearchException) {\n+                    throw (ElasticsearchException) e.getCause();\n+                } else {\n+                    throw new RepositoryException(repositoryName, \"Unexpected exception retrieving DEK [\" + DEKId + \"]\", e);\n+                }\n+            }\n+        }\n+\n+        private SecretKey loadDEK(String DEKId) throws IOException {\n+            final BlobPath DEKBlobPath = delegatedBasePath.add(DEK_ROOT_CONTAINER).add(DEKId);\n+            logger.debug(\n+                () -> new ParameterizedMessage(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 441}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjE1MjQyNw==", "bodyText": "This should be an assertion? Also maybe just make getKeyId return a BytesReference so we don't have to do the string to byte[] conversion here all the time. It's kind of confusing to handle something that is a bunch of bytes as a string only to convert it to byte[] before every use?", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402152427", "createdAt": "2020-04-02T08:50:54Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepository.java", "diffHunk": "@@ -6,11 +6,739 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n-public class EncryptedRepository {\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.lucene.index.IndexCommit;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.metadata.MetaData;\n+import org.elasticsearch.cluster.metadata.RepositoryMetaData;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.CheckedFunction;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.blobstore.BlobContainer;\n+import org.elasticsearch.common.blobstore.BlobMetaData;\n+import org.elasticsearch.common.blobstore.BlobPath;\n+import org.elasticsearch.common.blobstore.BlobStore;\n+import org.elasticsearch.common.blobstore.DeleteResult;\n+import org.elasticsearch.common.blobstore.support.AbstractBlobContainer;\n+import org.elasticsearch.common.cache.Cache;\n+import org.elasticsearch.common.cache.CacheBuilder;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.io.Streams;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.index.store.Store;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoryException;\n+import org.elasticsearch.repositories.ShardGenerations;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.SnapshotInfo;\n+import org.elasticsearch.snapshots.SnapshotShardFailure;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.SecretKey;\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.NoSuchFileException;\n+import java.security.GeneralSecurityException;\n+import java.security.SecureRandom;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+// not-final for tests\n+public class EncryptedRepository extends BlobStoreRepository {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepository.class);\n+    // the following constants are fixed by definition\n     static final int GCM_TAG_LENGTH_IN_BYTES = 16;\n     static final int GCM_IV_LENGTH_IN_BYTES = 12;\n-    static final int AES_BLOCK_SIZE_IN_BYTES = 128;\n+    static final int AES_BLOCK_LENGTH_IN_BYTES = 128;\n+    // the following constants require careful thought before changing because they will break backwards compatibility\n     static final String DATA_ENCRYPTION_SCHEME = \"AES/GCM/NoPadding\";\n     static final long PACKET_START_COUNTER = Long.MIN_VALUE;\n-    static final int MAX_PACKET_LENGTH_IN_BYTES = 1 << 30;\n+    static final int MAX_PACKET_LENGTH_IN_BYTES = 8 << 20; // 8MB\n+    // this should be smaller than {@code #MAX_PACKET_LENGTH_IN_BYTES} and it's what {@code EncryptionPacketsInputStream} uses\n+    // during encryption and what {@code DecryptionPacketsInputStream} expects during decryption (it is not configurable)\n+    static final int PACKET_LENGTH_IN_BYTES = 64 * (1 << 10); // 64KB\n+    // the path of the blob container holding all the DEKs\n+    // this is relative to the root base path holding the encrypted blobs (i.e. the repository root base path)\n+    static final String DEK_ROOT_CONTAINER = \".encryption-metadata\"; // package private for tests\n+    static final int DEK_ID_LENGTH = 22; // {@code org.elasticsearch.common.UUIDS} length\n+\n+    // the following constants can be changed freely\n+    private static final String RAND_ALGO = \"SHA1PRNG\";\n+    // each snapshot metadata contains an unforgeable identifier of the repository password of the master node that started the snapshot\n+    // this hash is then verified on each data node before the actual shard files snapshot, as well as on the\n+    // master node that finalizes the snapshot (could be a different master node, if a master failover occurred during the snapshot)\n+    static final String PASSWORD_ID_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordId\";\n+    static final String PASSWORD_ID_SALT_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordIdSalt\";\n+    private static final int DEK_CACHE_WEIGHT = 2048;\n+\n+    // this is the repository instance to which all blob reads and writes are forwarded to (it stores both the encrypted blobs, as well\n+    // as the associated encrypted DEKs)\n+    private final BlobStoreRepository delegatedRepository;\n+    // every data blob is encrypted with its randomly generated AES key (DEK)\n+    private final Supplier<Tuple<String, SecretKey>> DEKGenerator;\n+    // license is checked before every snapshot operations; protected non-final for tests\n+    protected Supplier<XPackLicenseState> licenseStateSupplier;\n+    private final char[] repositoryPassword;\n+    private final String localRepositoryPasswordId;\n+    private final String localRepositoryPasswordIdSalt;\n+    private final AtomicReference<String> validatedRepositoryPasswordId;\n+    private final Cache<String, SecretKey> DEKCache;\n+\n+    /**\n+     * Returns the byte length (i.e. the storage size) of an encrypted blob, given the length of the blob's plaintext contents.\n+     *\n+     * @see EncryptionPacketsInputStream#getEncryptionLength(long, int)\n+     */\n+    public static long getEncryptedBlobByteLength(long plaintextBlobByteLength) {\n+        return (long) DEK_ID_LENGTH /* UUID byte length */\n+            + EncryptionPacketsInputStream.getEncryptionLength(plaintextBlobByteLength, PACKET_LENGTH_IN_BYTES);\n+    }\n+\n+    protected EncryptedRepository(\n+        RepositoryMetaData metadata,\n+        NamedXContentRegistry namedXContentRegistry,\n+        ClusterService clusterService,\n+        BlobStoreRepository delegatedRepository,\n+        Supplier<XPackLicenseState> licenseStateSupplier,\n+        char[] repositoryPassword\n+    )\n+        throws GeneralSecurityException {\n+        super(\n+            metadata,\n+            namedXContentRegistry,\n+            clusterService,\n+            BlobPath.cleanPath() /* the encrypted repository uses a hardcoded empty\n+                                 base blob path but the base path setting is honored for the delegated repository */\n+        );\n+        this.delegatedRepository = delegatedRepository;\n+        this.DEKGenerator = createDEKGenerator();\n+        this.licenseStateSupplier = licenseStateSupplier;\n+        this.repositoryPassword = repositoryPassword;\n+        // the password \"id\" and validated\n+        this.localRepositoryPasswordIdSalt = UUIDs.randomBase64UUID();\n+        this.localRepositoryPasswordId = AESKeyUtils.computeId(\n+            AESKeyUtils.generatePasswordBasedKey(repositoryPassword, localRepositoryPasswordIdSalt.getBytes(StandardCharsets.UTF_8))\n+        );\n+        this.validatedRepositoryPasswordId = new AtomicReference<>(this.localRepositoryPasswordId);\n+        // stores decrypted DEKs; DEKs are reused to encrypt/decrypt multiple independent blobs\n+        this.DEKCache = CacheBuilder.<String, SecretKey>builder().setMaximumWeight(DEK_CACHE_WEIGHT).build();\n+        if (isReadOnly() != delegatedRepository.isReadOnly()) {\n+            throw new RepositoryException(\n+                metadata.name(),\n+                \"Unexpected fatal internal error\",\n+                new IllegalStateException(\"The encrypted repository must be read-only iff the delegate repository is read-only\")\n+            );\n+        }\n+    }\n+\n+    /**\n+     * The repository hook method which populates the snapshot metadata with the salted password hash of the repository on the (master)\n+     * node that starts of the snapshot operation. All the other actions associated with the same snapshot operation will first verify\n+     * that the local repository password checks with the hash from the snapshot metadata.\n+     * <p>\n+     * In addition, if the installed license does not comply with encrypted snapshots, this throws an exception, which aborts the snapshot\n+     * operation.\n+     *\n+     * See {@link org.elasticsearch.repositories.Repository#adaptUserMetadata(Map)}.\n+     *\n+     * @param userMetadata the snapshot metadata as received from the calling user\n+     * @return the snapshot metadata containing the salted password hash of the node initializing the snapshot\n+     */\n+    @Override\n+    public Map<String, Object> adaptUserMetadata(Map<String, Object> userMetadata) {\n+        // because populating the snapshot metadata must be done before the actual snapshot is first initialized,\n+        // we take the opportunity to validate the license and abort if non-compliant\n+        if (false == licenseStateSupplier.get().isEncryptedSnapshotAllowed()) {\n+            throw LicenseUtils.newComplianceException(\"encrypted snapshots\");\n+        }\n+        Map<String, Object> snapshotUserMetadata = new HashMap<>();\n+        if (userMetadata != null) {\n+            snapshotUserMetadata.putAll(userMetadata);\n+        }\n+        // set out the ID of the repository secret\n+        // this is then checked before every snapshot operation (i.e. {@link #snapshotShard} and {@link #finalizeSnapshot})\n+        // to assure that all participating nodes in the snapshot operation are using the same repository secret\n+        snapshotUserMetadata.put(PASSWORD_ID_SALT_USER_METADATA_KEY, localRepositoryPasswordIdSalt);\n+        snapshotUserMetadata.put(PASSWORD_ID_USER_METADATA_KEY, localRepositoryPasswordId);\n+        logger.trace(\n+            () -> new ParameterizedMessage(\n+                \"Snapshot metadata for local repository password  [{}] and [{}]\",\n+                localRepositoryPasswordIdSalt,\n+                localRepositoryPasswordId\n+            )\n+        );\n+        return Map.copyOf(snapshotUserMetadata);\n+    }\n+\n+    @Override\n+    public void finalizeSnapshot(\n+        SnapshotId snapshotId,\n+        ShardGenerations shardGenerations,\n+        long startTime,\n+        String failure,\n+        int totalShards,\n+        List<SnapshotShardFailure> shardFailures,\n+        long repositoryStateId,\n+        boolean includeGlobalState,\n+        MetaData clusterMetaData,\n+        Map<String, Object> userMetadata,\n+        Version repositoryMetaVersion,\n+        ActionListener<SnapshotInfo> listener\n+    ) {\n+        try {\n+            validateLocalRepositorySecret(userMetadata);\n+        } catch (RepositoryException passwordValidationException) {\n+            listener.onFailure(passwordValidationException);\n+            return;\n+        } finally {\n+            // remove the repository password id from the snapshot metadata so that the id is not displayed in the API response to the user\n+            userMetadata = new HashMap<>(userMetadata);\n+            userMetadata.remove(PASSWORD_ID_USER_METADATA_KEY);\n+            userMetadata.remove(PASSWORD_ID_SALT_USER_METADATA_KEY);\n+        }\n+        super.finalizeSnapshot(\n+            snapshotId,\n+            shardGenerations,\n+            startTime,\n+            failure,\n+            totalShards,\n+            shardFailures,\n+            repositoryStateId,\n+            includeGlobalState,\n+            clusterMetaData,\n+            userMetadata,\n+            repositoryMetaVersion,\n+            listener\n+        );\n+    }\n+\n+    @Override\n+    public void snapshotShard(\n+        Store store,\n+        MapperService mapperService,\n+        SnapshotId snapshotId,\n+        IndexId indexId,\n+        IndexCommit snapshotIndexCommit,\n+        String shardStateIdentifier,\n+        IndexShardSnapshotStatus snapshotStatus,\n+        Version repositoryMetaVersion,\n+        Map<String, Object> userMetadata,\n+        ActionListener<String> listener\n+    ) {\n+        try {\n+            validateLocalRepositorySecret(userMetadata);\n+        } catch (RepositoryException passwordValidationException) {\n+            listener.onFailure(passwordValidationException);\n+            return;\n+        }\n+        super.snapshotShard(\n+            store,\n+            mapperService,\n+            snapshotId,\n+            indexId,\n+            snapshotIndexCommit,\n+            shardStateIdentifier,\n+            snapshotStatus,\n+            repositoryMetaVersion,\n+            userMetadata,\n+            listener\n+        );\n+    }\n+\n+    @Override\n+    protected BlobStore createBlobStore() {\n+        final Supplier<Tuple<String, SecretKey>> DEKGenerator;\n+        if (isReadOnly()) {\n+            // make sure that a read-only repository can't encrypt anything\n+            DEKGenerator = () -> {\n+                throw new RepositoryException(\n+                    metadata.name(),\n+                    \"Unexpected fatal internal error\",\n+                    new IllegalStateException(\"DEKs are required for encryption but this is a read-only repository\")\n+                );\n+            };\n+        } else {\n+            DEKGenerator = this.DEKGenerator;\n+        }\n+        return new EncryptedBlobStore(\n+            delegatedRepository.blobStore(),\n+            delegatedRepository.basePath(),\n+            metadata.name(),\n+            this::generateKEK,\n+            DEKGenerator,\n+            DEKCache\n+        );\n+    }\n+\n+    @Override\n+    protected void doStart() {\n+        this.delegatedRepository.start();\n+        super.doStart();\n+    }\n+\n+    @Override\n+    protected void doStop() {\n+        super.doStop();\n+        this.delegatedRepository.stop();\n+    }\n+\n+    @Override\n+    protected void doClose() {\n+        super.doClose();\n+        this.delegatedRepository.close();\n+    }\n+\n+    private Supplier<Tuple<String, SecretKey>> createDEKGenerator() throws GeneralSecurityException {\n+        // DEK and DEK Ids MUST be generated randomly (with independent random instances)\n+        final SecureRandom DEKSecureRandom = SecureRandom.getInstance(RAND_ALGO);\n+        final SecureRandom DEKIdSecureRandom = SecureRandom.getInstance(RAND_ALGO);\n+        final KeyGenerator DEKGenerator = KeyGenerator.getInstance(DATA_ENCRYPTION_SCHEME.split(\"/\")[0]);\n+        DEKGenerator.init(AESKeyUtils.KEY_LENGTH_IN_BYTES * Byte.SIZE, DEKSecureRandom);\n+        return () -> {\n+            final String DEKId = UUIDs.randomBase64UUID(DEKIdSecureRandom);\n+            final SecretKey DEK = DEKGenerator.generateKey();\n+            logger.debug(() -> new ParameterizedMessage(\"Repository [{}]] generated new DEK [{}]\", metadata.name(), DEKId));\n+            return new Tuple<>(DEKId, DEK);\n+        };\n+    }\n+\n+    // pkg-private for tests\n+    Tuple<String, SecretKey> generateKEK(String DEKId) {\n+        try {\n+            // we rely on the DEK Id being generated randomly so it can be used as a salt\n+            final byte[] KEKsalt = DEKId.getBytes(StandardCharsets.UTF_8);\n+            final SecretKey KEK = AESKeyUtils.generatePasswordBasedKey(repositoryPassword, KEKsalt);\n+            final String KEKId = AESKeyUtils.computeId(KEK);\n+            logger.debug(() -> new ParameterizedMessage(\"Repository [{}] computed KEK [{}] for DEK [{}]\", metadata.name(), KEKId, DEKId));\n+            return new Tuple<>(KEKId, KEK);\n+        } catch (GeneralSecurityException e) {\n+            throw new RepositoryException(metadata.name(), \"Failure to generate KEK to wrap the DEK [\" + DEKId + \"]\", e);\n+        }\n+    }\n+\n+    /**\n+     * Called before the shard snapshot and finalize operations, on the data and master nodes. This validates that the repository\n+     * secret on the master node that started the snapshot operation is identical to the repository secret on the local node.\n+     *\n+     * @param snapshotUserMetadata the snapshot metadata containing the repository secret id to verify\n+     * @throws RepositoryException if the repository secret id on the local node mismatches the master's\n+     */\n+    private void validateLocalRepositorySecret(Map<String, Object> snapshotUserMetadata) throws RepositoryException {\n+        if (snapshotUserMetadata == null) {\n+            throw new RepositoryException(\n+                metadata.name(),\n+                \"Unexpected fatal internal error\",\n+                new IllegalStateException(\"Null snapshot metadata\")\n+            );\n+        }\n+        final Object masterRepositoryPasswordId = snapshotUserMetadata.get(PASSWORD_ID_USER_METADATA_KEY);\n+        if (false == masterRepositoryPasswordId instanceof String) {\n+            throw new RepositoryException(\n+                metadata.name(),\n+                \"Unexpected fatal internal error\",\n+                new IllegalStateException(\"Snapshot metadata does not contain the repository password id as a String\")\n+            );\n+        }\n+        if (false == validatedRepositoryPasswordId.get().equals(masterRepositoryPasswordId)) {\n+            final Object masterRepositoryPasswordIdSalt = snapshotUserMetadata.get(PASSWORD_ID_SALT_USER_METADATA_KEY);\n+            if (false == masterRepositoryPasswordIdSalt instanceof String) {\n+                throw new RepositoryException(\n+                    metadata.name(),\n+                    \"Unexpected fatal internal error\",\n+                    new IllegalStateException(\"Snapshot metadata does not contain the repository password salt as a String\")\n+                );\n+            }\n+            final String computedRepositoryPasswordId;\n+            try {\n+                computedRepositoryPasswordId = AESKeyUtils.computeId(\n+                    AESKeyUtils.generatePasswordBasedKey(\n+                        repositoryPassword,\n+                        ((String) masterRepositoryPasswordIdSalt).getBytes(StandardCharsets.UTF_8)\n+                    )\n+                );\n+            } catch (Exception e) {\n+                throw new RepositoryException(metadata.name(), \"Unexpected fatal internal error\", e);\n+            }\n+            if (computedRepositoryPasswordId.equals(masterRepositoryPasswordId)) {\n+                this.validatedRepositoryPasswordId.set(computedRepositoryPasswordId);\n+            } else {\n+                throw new RepositoryException(\n+                    metadata.name(),\n+                    \"Repository secret id mismatch. The local node's repository secret, the keystore setting [\"\n+                        + EncryptedRepositoryPlugin.ENCRYPTION_PASSWORD_SETTING.getConcreteSettingForNamespace(\n+                            EncryptedRepositoryPlugin.PASSWORD_NAME_SETTING.get(metadata.settings())\n+                        ).getKey()\n+                        + \"], is different compared to the elected master node's which started the snapshot operation\"\n+                );\n+            }\n+        }\n+    }\n+\n+    // pkg-private for tests\n+    static final class EncryptedBlobStore implements BlobStore {\n+        private final BlobStore delegatedBlobStore;\n+        private final BlobPath delegatedBasePath;\n+        private final String repositoryName;\n+        private final Function<String, Tuple<String, SecretKey>> getKEKforDEK;\n+        private final Cache<String, SecretKey> DEKCache;\n+        private final CheckedSupplier<SingleUseKey, IOException> singleUseDEKSupplier;\n+\n+        EncryptedBlobStore(\n+            BlobStore delegatedBlobStore,\n+            BlobPath delegatedBasePath,\n+            String repositoryName,\n+            Function<String, Tuple<String, SecretKey>> getKEKforDEK,\n+            Supplier<Tuple<String, SecretKey>> DEKGenerator,\n+            Cache<String, SecretKey> DEKCache\n+        ) {\n+            this.delegatedBlobStore = delegatedBlobStore;\n+            this.delegatedBasePath = delegatedBasePath;\n+            this.repositoryName = repositoryName;\n+            this.getKEKforDEK = getKEKforDEK;\n+            this.DEKCache = DEKCache;\n+            this.singleUseDEKSupplier = SingleUseKey.createSingleUseKeySupplier(() -> {\n+                Tuple<String, SecretKey> newDEK = DEKGenerator.get();\n+                // store the newly generated DEK before making it available\n+                storeDEK(newDEK.v1(), newDEK.v2());\n+                return newDEK;\n+            });\n+        }\n+\n+        // pkg-private for tests\n+        SecretKey getDEKById(String DEKId) throws IOException {\n+            try {\n+                return DEKCache.computeIfAbsent(DEKId, ignored -> loadDEK(DEKId));\n+            } catch (ExecutionException e) {\n+                // some exception types are to be expected\n+                if (e.getCause() instanceof IOException) {\n+                    throw (IOException) e.getCause();\n+                } else if (e.getCause() instanceof ElasticsearchException) {\n+                    throw (ElasticsearchException) e.getCause();\n+                } else {\n+                    throw new RepositoryException(repositoryName, \"Unexpected exception retrieving DEK [\" + DEKId + \"]\", e);\n+                }\n+            }\n+        }\n+\n+        private SecretKey loadDEK(String DEKId) throws IOException {\n+            final BlobPath DEKBlobPath = delegatedBasePath.add(DEK_ROOT_CONTAINER).add(DEKId);\n+            logger.debug(\n+                () -> new ParameterizedMessage(\n+                    \"Repository [{}] loading wrapped DEK [{}] from blob path {}\",\n+                    repositoryName,\n+                    DEKId,\n+                    DEKBlobPath\n+                )\n+            );\n+            final BlobContainer DEKBlobContainer = delegatedBlobStore.blobContainer(DEKBlobPath);\n+            final Tuple<String, SecretKey> KEK = getKEKforDEK.apply(DEKId);\n+            logger.trace(\n+                () -> new ParameterizedMessage(\"Repository [{}] using KEK [{}] to unwrap DEK [{}]\", repositoryName, KEK.v1(), DEKId)\n+            );\n+            final byte[] encryptedDEKBytes = new byte[AESKeyUtils.WRAPPED_KEY_LENGTH_IN_BYTES];\n+            try (InputStream encryptedDEKInputStream = DEKBlobContainer.readBlob(KEK.v1())) {\n+                final int bytesRead = Streams.readFully(encryptedDEKInputStream, encryptedDEKBytes);\n+                if (bytesRead != AESKeyUtils.WRAPPED_KEY_LENGTH_IN_BYTES) {\n+                    throw new RepositoryException(\n+                        repositoryName,\n+                        \"Wrapped DEK [\" + DEKId + \"] has smaller length [\" + bytesRead + \"] \" + \"than expected\"\n+                    );\n+                }\n+                if (encryptedDEKInputStream.read() != -1) {\n+                    throw new RepositoryException(repositoryName, \"Wrapped DEK [\" + DEKId + \"] is larger than expected\");\n+                }\n+            } catch (NoSuchFileException e) {\n+                // do NOT throw IOException when the DEK does not exist, as this is a decryption problem, and IOExceptions\n+                // can move the repository in the corrupted state\n+                throw new ElasticsearchException(\n+                    \"Failure to read and decrypt DEK [\"\n+                        + DEKId\n+                        + \"] from \"\n+                        + DEKBlobContainer.path()\n+                        + \". Most likely the repository password is incorrect, where previous \"\n+                        + \"snapshots have used a different password.\",\n+                    e\n+                );\n+            }\n+            logger.trace(\n+                () -> new ParameterizedMessage(\n+                    \"Repository [{}] successfully read DEK [{}] from path {} {}\",\n+                    repositoryName,\n+                    DEKId,\n+                    DEKBlobPath,\n+                    KEK.v1()\n+                )\n+            );\n+            try {\n+                final SecretKey DEK = AESKeyUtils.unwrap(KEK.v2(), encryptedDEKBytes);\n+                logger.debug(\n+                    () -> new ParameterizedMessage(\n+                        \"Repository [{}] successfully loaded DEK [{}] from path {} {}\",\n+                        repositoryName,\n+                        DEKId,\n+                        DEKBlobPath,\n+                        KEK.v1()\n+                    )\n+                );\n+                return DEK;\n+            } catch (GeneralSecurityException e) {\n+                throw new RepositoryException(\n+                    repositoryName,\n+                    \"Failure to AES unwrap the DEK [\"\n+                        + DEKId\n+                        + \"]. \"\n+                        + \"Most likely the encryption metadata in the repository has been corrupted\",\n+                    e\n+                );\n+            }\n+        }\n+\n+        // pkg-private for tests\n+        void storeDEK(String DEKId, SecretKey DEK) throws IOException {\n+            final BlobPath DEKBlobPath = delegatedBasePath.add(DEK_ROOT_CONTAINER).add(DEKId);\n+            logger.debug(\n+                () -> new ParameterizedMessage(\n+                    \"Repository [{}] storing wrapped DEK [{}] under blob path {}\",\n+                    repositoryName,\n+                    DEKId,\n+                    DEKBlobPath\n+                )\n+            );\n+            final BlobContainer DEKBlobContainer = delegatedBlobStore.blobContainer(DEKBlobPath);\n+            final Tuple<String, SecretKey> KEK = getKEKforDEK.apply(DEKId);\n+            logger.trace(\n+                () -> new ParameterizedMessage(\"Repository [{}] using KEK [{}] to wrap DEK [{}]\", repositoryName, KEK.v1(), DEKId)\n+            );\n+            final byte[] encryptedDEKBytes;\n+            try {\n+                encryptedDEKBytes = AESKeyUtils.wrap(KEK.v2(), DEK);\n+                if (encryptedDEKBytes.length != AESKeyUtils.WRAPPED_KEY_LENGTH_IN_BYTES) {\n+                    throw new RepositoryException(\n+                        repositoryName,\n+                        \"Wrapped DEK [\" + DEKId + \"] has unexpected length [\" + encryptedDEKBytes.length + \"]\"\n+                    );\n+                }\n+            } catch (GeneralSecurityException e) {\n+                // throw unchecked ElasticsearchException; IOExceptions are interpreted differently and can move the repository in the\n+                // corrupted state\n+                throw new RepositoryException(repositoryName, \"Failure to AES wrap the DEK [\" + DEKId + \"]\", e);\n+            }\n+            logger.trace(() -> new ParameterizedMessage(\"Repository [{}] successfully wrapped DEK [{}]\", repositoryName, DEKId));\n+            try (InputStream encryptedDEKInputStream = new ByteArrayInputStream(encryptedDEKBytes)) {\n+                DEKBlobContainer.writeBlobAtomic(KEK.v1(), encryptedDEKInputStream, encryptedDEKBytes.length, true);\n+            }\n+            logger.debug(\n+                () -> new ParameterizedMessage(\n+                    \"Repository [{}] successfully stored DEK [{}] under path {} {}\",\n+                    repositoryName,\n+                    DEKId,\n+                    DEKBlobPath,\n+                    KEK.v1()\n+                )\n+            );\n+        }\n+\n+        @Override\n+        public BlobContainer blobContainer(BlobPath path) {\n+            final BlobContainer delegatedBlobContainer = delegatedBlobStore.blobContainer(delegatedBasePath.append(path));\n+            return new EncryptedBlobContainer(path, repositoryName, delegatedBlobContainer, singleUseDEKSupplier, this::getDEKById);\n+        }\n+\n+        @Override\n+        public void close() {\n+            // do NOT close delegatedBlobStore; it will be closed when the inner delegatedRepository is closed\n+        }\n+\n+    }\n+\n+    private static final class EncryptedBlobContainer extends AbstractBlobContainer {\n+        private final String repositoryName;\n+        private final BlobContainer delegatedBlobContainer;\n+        // supplier for the DEK used for encryption (snapshot)\n+        private final CheckedSupplier<SingleUseKey, IOException> singleUseDEKSupplier;\n+        // retrieves the DEK required for decryption (restore)\n+        private final CheckedFunction<String, SecretKey, IOException> getDEKById;\n+\n+        EncryptedBlobContainer(\n+            BlobPath path, // this path contains the {@code EncryptedRepository#basePath} which, importantly, is empty\n+            String repositoryName,\n+            BlobContainer delegatedBlobContainer,\n+            CheckedSupplier<SingleUseKey, IOException> singleUseDEKSupplier,\n+            CheckedFunction<String, SecretKey, IOException> getDEKById\n+        ) {\n+            super(path);\n+            this.repositoryName = repositoryName;\n+            if (DEK_ROOT_CONTAINER.equals(path.getRootPath())) {\n+                throw new RepositoryException(\n+                    repositoryName,\n+                    \"Unexpected internal error\",\n+                    new IllegalArgumentException(\"Cannot descend into the DEK blob container \" + path)\n+                );\n+            }\n+            this.delegatedBlobContainer = delegatedBlobContainer;\n+            this.singleUseDEKSupplier = singleUseDEKSupplier;\n+            this.getDEKById = getDEKById;\n+        }\n+\n+        /**\n+         * Returns a new {@link InputStream} for the given {@code blobName} that can be used to read the contents of the blob.\n+         * The returned {@code InputStream} transparently handles the decryption of the blob contents, by first working out\n+         * the blob name of the associated DEK id, reading and decrypting the DEK (given the repository secret key, unless the DEK is\n+         * already cached because other blobs required it before), and lastly reading and decrypting the data blob,\n+         * in a streaming fashion, by employing the {@link DecryptionPacketsInputStream}.\n+         * The {@code DecryptionPacketsInputStream} does not return un-authenticated data.\n+         *\n+         * @param   blobName The name of the blob to get an {@link InputStream} for.\n+         */\n+        @Override\n+        public InputStream readBlob(String blobName) throws IOException {\n+            // This MIGHT require two concurrent readBlob connections if the DEK is not already in the cache and if the encrypted blob\n+            // is large enough so that the underlying network library keeps the connection open after reading the prepended DEK ID.\n+            // Arguably this is a problem only under lab conditions, when the storage service is saturated only by the first read\n+            // connection of the pair, so that the second read connection (for the DEK) can not be fulfilled.\n+            // In this case the second connection will time-out which will trigger the closing of the first one, therefore\n+            // allowing other pair connections to complete.\n+            // In this situation the restore process should slowly make headway, albeit under read-timeout exceptions\n+            final InputStream encryptedDataInputStream = delegatedBlobContainer.readBlob(blobName);\n+            try {\n+                // read the DEK Id (fixed length) which is prepended to the encrypted blob\n+                final byte[] DEKIdBytes = new byte[DEK_ID_LENGTH];\n+                final int bytesRead = Streams.readFully(encryptedDataInputStream, DEKIdBytes);\n+                if (bytesRead != DEK_ID_LENGTH) {\n+                    throw new RepositoryException(repositoryName, \"The encrypted blob [\" + blobName + \"] is too small [\" + bytesRead + \"]\");\n+                }\n+                final String DEKId = new String(DEKIdBytes, StandardCharsets.UTF_8);\n+                // might open a connection to read and decrypt the DEK, but most likely it will be served from cache\n+                final SecretKey DEK = getDEKById.apply(DEKId);\n+                // read and decrypt the rest of the blob\n+                return new DecryptionPacketsInputStream(encryptedDataInputStream, DEK, PACKET_LENGTH_IN_BYTES);\n+            } catch (Exception e) {\n+                try {\n+                    encryptedDataInputStream.close();\n+                } catch (IOException closeEx) {\n+                    e.addSuppressed(closeEx);\n+                }\n+                throw e;\n+            }\n+        }\n+\n+        /**\n+         * Reads the blob content from the input stream and writes it to the container in a new blob with the given name.\n+         * If {@code failIfAlreadyExists} is {@code true} and a blob with the same name already exists, the write operation will fail;\n+         * otherwise, if {@code failIfAlreadyExists} is {@code false} the blob is overwritten.\n+         * The contents are encrypted in a streaming fashion. The DEK (encryption key) is randomly generated and reused for encrypting\n+         * subsequent blobs such that the same IV is not reused together with the same key.\n+         * The DEK encryption key is separately stored in a different blob, which is encrypted with the repository key.\n+         *\n+         * @param   blobName\n+         *          The name of the blob to write the contents of the input stream to.\n+         * @param   inputStream\n+         *          The input stream from which to retrieve the bytes to write to the blob.\n+         * @param   blobSize\n+         *          The size of the blob to be written, in bytes. The actual number of bytes written to the storage service is larger\n+         *          because of encryption and authentication overhead. It is implementation dependent whether this value is used\n+         *          in writing the blob to the repository.\n+         * @param   failIfAlreadyExists\n+         *          whether to throw a FileAlreadyExistsException if the given blob already exists\n+         */\n+        @Override\n+        public void writeBlob(String blobName, InputStream inputStream, long blobSize, boolean failIfAlreadyExists) throws IOException {\n+            // reuse, but possibly generate and store a new DEK\n+            final SingleUseKey singleUseNonceAndDEK = singleUseDEKSupplier.get();\n+            final byte[] DEKIdBytes = singleUseNonceAndDEK.getKeyId().getBytes(StandardCharsets.UTF_8);\n+            if (DEKIdBytes.length != DEK_ID_LENGTH) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 664}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjE1Mjk4Mw==", "bodyText": "NIT: random empty line", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402152983", "createdAt": "2020-04-02T08:51:45Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepository.java", "diffHunk": "@@ -6,11 +6,739 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n-public class EncryptedRepository {\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.lucene.index.IndexCommit;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.metadata.MetaData;\n+import org.elasticsearch.cluster.metadata.RepositoryMetaData;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.CheckedFunction;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.blobstore.BlobContainer;\n+import org.elasticsearch.common.blobstore.BlobMetaData;\n+import org.elasticsearch.common.blobstore.BlobPath;\n+import org.elasticsearch.common.blobstore.BlobStore;\n+import org.elasticsearch.common.blobstore.DeleteResult;\n+import org.elasticsearch.common.blobstore.support.AbstractBlobContainer;\n+import org.elasticsearch.common.cache.Cache;\n+import org.elasticsearch.common.cache.CacheBuilder;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.io.Streams;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.index.store.Store;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoryException;\n+import org.elasticsearch.repositories.ShardGenerations;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.SnapshotInfo;\n+import org.elasticsearch.snapshots.SnapshotShardFailure;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.SecretKey;\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.NoSuchFileException;\n+import java.security.GeneralSecurityException;\n+import java.security.SecureRandom;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+// not-final for tests\n+public class EncryptedRepository extends BlobStoreRepository {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepository.class);\n+    // the following constants are fixed by definition\n     static final int GCM_TAG_LENGTH_IN_BYTES = 16;\n     static final int GCM_IV_LENGTH_IN_BYTES = 12;\n-    static final int AES_BLOCK_SIZE_IN_BYTES = 128;\n+    static final int AES_BLOCK_LENGTH_IN_BYTES = 128;\n+    // the following constants require careful thought before changing because they will break backwards compatibility\n     static final String DATA_ENCRYPTION_SCHEME = \"AES/GCM/NoPadding\";\n     static final long PACKET_START_COUNTER = Long.MIN_VALUE;\n-    static final int MAX_PACKET_LENGTH_IN_BYTES = 1 << 30;\n+    static final int MAX_PACKET_LENGTH_IN_BYTES = 8 << 20; // 8MB\n+    // this should be smaller than {@code #MAX_PACKET_LENGTH_IN_BYTES} and it's what {@code EncryptionPacketsInputStream} uses\n+    // during encryption and what {@code DecryptionPacketsInputStream} expects during decryption (it is not configurable)\n+    static final int PACKET_LENGTH_IN_BYTES = 64 * (1 << 10); // 64KB\n+    // the path of the blob container holding all the DEKs\n+    // this is relative to the root base path holding the encrypted blobs (i.e. the repository root base path)\n+    static final String DEK_ROOT_CONTAINER = \".encryption-metadata\"; // package private for tests\n+    static final int DEK_ID_LENGTH = 22; // {@code org.elasticsearch.common.UUIDS} length\n+\n+    // the following constants can be changed freely\n+    private static final String RAND_ALGO = \"SHA1PRNG\";\n+    // each snapshot metadata contains an unforgeable identifier of the repository password of the master node that started the snapshot\n+    // this hash is then verified on each data node before the actual shard files snapshot, as well as on the\n+    // master node that finalizes the snapshot (could be a different master node, if a master failover occurred during the snapshot)\n+    static final String PASSWORD_ID_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordId\";\n+    static final String PASSWORD_ID_SALT_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordIdSalt\";\n+    private static final int DEK_CACHE_WEIGHT = 2048;\n+\n+    // this is the repository instance to which all blob reads and writes are forwarded to (it stores both the encrypted blobs, as well\n+    // as the associated encrypted DEKs)\n+    private final BlobStoreRepository delegatedRepository;\n+    // every data blob is encrypted with its randomly generated AES key (DEK)\n+    private final Supplier<Tuple<String, SecretKey>> DEKGenerator;\n+    // license is checked before every snapshot operations; protected non-final for tests\n+    protected Supplier<XPackLicenseState> licenseStateSupplier;\n+    private final char[] repositoryPassword;\n+    private final String localRepositoryPasswordId;\n+    private final String localRepositoryPasswordIdSalt;\n+    private final AtomicReference<String> validatedRepositoryPasswordId;\n+    private final Cache<String, SecretKey> DEKCache;\n+\n+    /**\n+     * Returns the byte length (i.e. the storage size) of an encrypted blob, given the length of the blob's plaintext contents.\n+     *\n+     * @see EncryptionPacketsInputStream#getEncryptionLength(long, int)\n+     */\n+    public static long getEncryptedBlobByteLength(long plaintextBlobByteLength) {\n+        return (long) DEK_ID_LENGTH /* UUID byte length */\n+            + EncryptionPacketsInputStream.getEncryptionLength(plaintextBlobByteLength, PACKET_LENGTH_IN_BYTES);\n+    }\n+\n+    protected EncryptedRepository(\n+        RepositoryMetaData metadata,\n+        NamedXContentRegistry namedXContentRegistry,\n+        ClusterService clusterService,\n+        BlobStoreRepository delegatedRepository,\n+        Supplier<XPackLicenseState> licenseStateSupplier,\n+        char[] repositoryPassword\n+    )\n+        throws GeneralSecurityException {\n+        super(\n+            metadata,\n+            namedXContentRegistry,\n+            clusterService,\n+            BlobPath.cleanPath() /* the encrypted repository uses a hardcoded empty\n+                                 base blob path but the base path setting is honored for the delegated repository */\n+        );\n+        this.delegatedRepository = delegatedRepository;\n+        this.DEKGenerator = createDEKGenerator();\n+        this.licenseStateSupplier = licenseStateSupplier;\n+        this.repositoryPassword = repositoryPassword;\n+        // the password \"id\" and validated\n+        this.localRepositoryPasswordIdSalt = UUIDs.randomBase64UUID();\n+        this.localRepositoryPasswordId = AESKeyUtils.computeId(\n+            AESKeyUtils.generatePasswordBasedKey(repositoryPassword, localRepositoryPasswordIdSalt.getBytes(StandardCharsets.UTF_8))\n+        );\n+        this.validatedRepositoryPasswordId = new AtomicReference<>(this.localRepositoryPasswordId);\n+        // stores decrypted DEKs; DEKs are reused to encrypt/decrypt multiple independent blobs\n+        this.DEKCache = CacheBuilder.<String, SecretKey>builder().setMaximumWeight(DEK_CACHE_WEIGHT).build();\n+        if (isReadOnly() != delegatedRepository.isReadOnly()) {\n+            throw new RepositoryException(\n+                metadata.name(),\n+                \"Unexpected fatal internal error\",\n+                new IllegalStateException(\"The encrypted repository must be read-only iff the delegate repository is read-only\")\n+            );\n+        }\n+    }\n+\n+    /**\n+     * The repository hook method which populates the snapshot metadata with the salted password hash of the repository on the (master)\n+     * node that starts of the snapshot operation. All the other actions associated with the same snapshot operation will first verify\n+     * that the local repository password checks with the hash from the snapshot metadata.\n+     * <p>\n+     * In addition, if the installed license does not comply with encrypted snapshots, this throws an exception, which aborts the snapshot\n+     * operation.\n+     *\n+     * See {@link org.elasticsearch.repositories.Repository#adaptUserMetadata(Map)}.\n+     *\n+     * @param userMetadata the snapshot metadata as received from the calling user\n+     * @return the snapshot metadata containing the salted password hash of the node initializing the snapshot\n+     */\n+    @Override\n+    public Map<String, Object> adaptUserMetadata(Map<String, Object> userMetadata) {\n+        // because populating the snapshot metadata must be done before the actual snapshot is first initialized,\n+        // we take the opportunity to validate the license and abort if non-compliant\n+        if (false == licenseStateSupplier.get().isEncryptedSnapshotAllowed()) {\n+            throw LicenseUtils.newComplianceException(\"encrypted snapshots\");\n+        }\n+        Map<String, Object> snapshotUserMetadata = new HashMap<>();\n+        if (userMetadata != null) {\n+            snapshotUserMetadata.putAll(userMetadata);\n+        }\n+        // set out the ID of the repository secret\n+        // this is then checked before every snapshot operation (i.e. {@link #snapshotShard} and {@link #finalizeSnapshot})\n+        // to assure that all participating nodes in the snapshot operation are using the same repository secret\n+        snapshotUserMetadata.put(PASSWORD_ID_SALT_USER_METADATA_KEY, localRepositoryPasswordIdSalt);\n+        snapshotUserMetadata.put(PASSWORD_ID_USER_METADATA_KEY, localRepositoryPasswordId);\n+        logger.trace(\n+            () -> new ParameterizedMessage(\n+                \"Snapshot metadata for local repository password  [{}] and [{}]\",\n+                localRepositoryPasswordIdSalt,\n+                localRepositoryPasswordId\n+            )\n+        );\n+        return Map.copyOf(snapshotUserMetadata);\n+    }\n+\n+    @Override\n+    public void finalizeSnapshot(\n+        SnapshotId snapshotId,\n+        ShardGenerations shardGenerations,\n+        long startTime,\n+        String failure,\n+        int totalShards,\n+        List<SnapshotShardFailure> shardFailures,\n+        long repositoryStateId,\n+        boolean includeGlobalState,\n+        MetaData clusterMetaData,\n+        Map<String, Object> userMetadata,\n+        Version repositoryMetaVersion,\n+        ActionListener<SnapshotInfo> listener\n+    ) {\n+        try {\n+            validateLocalRepositorySecret(userMetadata);\n+        } catch (RepositoryException passwordValidationException) {\n+            listener.onFailure(passwordValidationException);\n+            return;\n+        } finally {\n+            // remove the repository password id from the snapshot metadata so that the id is not displayed in the API response to the user\n+            userMetadata = new HashMap<>(userMetadata);\n+            userMetadata.remove(PASSWORD_ID_USER_METADATA_KEY);\n+            userMetadata.remove(PASSWORD_ID_SALT_USER_METADATA_KEY);\n+        }\n+        super.finalizeSnapshot(\n+            snapshotId,\n+            shardGenerations,\n+            startTime,\n+            failure,\n+            totalShards,\n+            shardFailures,\n+            repositoryStateId,\n+            includeGlobalState,\n+            clusterMetaData,\n+            userMetadata,\n+            repositoryMetaVersion,\n+            listener\n+        );\n+    }\n+\n+    @Override\n+    public void snapshotShard(\n+        Store store,\n+        MapperService mapperService,\n+        SnapshotId snapshotId,\n+        IndexId indexId,\n+        IndexCommit snapshotIndexCommit,\n+        String shardStateIdentifier,\n+        IndexShardSnapshotStatus snapshotStatus,\n+        Version repositoryMetaVersion,\n+        Map<String, Object> userMetadata,\n+        ActionListener<String> listener\n+    ) {\n+        try {\n+            validateLocalRepositorySecret(userMetadata);\n+        } catch (RepositoryException passwordValidationException) {\n+            listener.onFailure(passwordValidationException);\n+            return;\n+        }\n+        super.snapshotShard(\n+            store,\n+            mapperService,\n+            snapshotId,\n+            indexId,\n+            snapshotIndexCommit,\n+            shardStateIdentifier,\n+            snapshotStatus,\n+            repositoryMetaVersion,\n+            userMetadata,\n+            listener\n+        );\n+    }\n+\n+    @Override\n+    protected BlobStore createBlobStore() {\n+        final Supplier<Tuple<String, SecretKey>> DEKGenerator;\n+        if (isReadOnly()) {\n+            // make sure that a read-only repository can't encrypt anything\n+            DEKGenerator = () -> {\n+                throw new RepositoryException(\n+                    metadata.name(),\n+                    \"Unexpected fatal internal error\",\n+                    new IllegalStateException(\"DEKs are required for encryption but this is a read-only repository\")\n+                );\n+            };\n+        } else {\n+            DEKGenerator = this.DEKGenerator;\n+        }\n+        return new EncryptedBlobStore(\n+            delegatedRepository.blobStore(),\n+            delegatedRepository.basePath(),\n+            metadata.name(),\n+            this::generateKEK,\n+            DEKGenerator,\n+            DEKCache\n+        );\n+    }\n+\n+    @Override\n+    protected void doStart() {\n+        this.delegatedRepository.start();\n+        super.doStart();\n+    }\n+\n+    @Override\n+    protected void doStop() {\n+        super.doStop();\n+        this.delegatedRepository.stop();\n+    }\n+\n+    @Override\n+    protected void doClose() {\n+        super.doClose();\n+        this.delegatedRepository.close();\n+    }\n+\n+    private Supplier<Tuple<String, SecretKey>> createDEKGenerator() throws GeneralSecurityException {\n+        // DEK and DEK Ids MUST be generated randomly (with independent random instances)\n+        final SecureRandom DEKSecureRandom = SecureRandom.getInstance(RAND_ALGO);\n+        final SecureRandom DEKIdSecureRandom = SecureRandom.getInstance(RAND_ALGO);\n+        final KeyGenerator DEKGenerator = KeyGenerator.getInstance(DATA_ENCRYPTION_SCHEME.split(\"/\")[0]);\n+        DEKGenerator.init(AESKeyUtils.KEY_LENGTH_IN_BYTES * Byte.SIZE, DEKSecureRandom);\n+        return () -> {\n+            final String DEKId = UUIDs.randomBase64UUID(DEKIdSecureRandom);\n+            final SecretKey DEK = DEKGenerator.generateKey();\n+            logger.debug(() -> new ParameterizedMessage(\"Repository [{}]] generated new DEK [{}]\", metadata.name(), DEKId));\n+            return new Tuple<>(DEKId, DEK);\n+        };\n+    }\n+\n+    // pkg-private for tests\n+    Tuple<String, SecretKey> generateKEK(String DEKId) {\n+        try {\n+            // we rely on the DEK Id being generated randomly so it can be used as a salt\n+            final byte[] KEKsalt = DEKId.getBytes(StandardCharsets.UTF_8);\n+            final SecretKey KEK = AESKeyUtils.generatePasswordBasedKey(repositoryPassword, KEKsalt);\n+            final String KEKId = AESKeyUtils.computeId(KEK);\n+            logger.debug(() -> new ParameterizedMessage(\"Repository [{}] computed KEK [{}] for DEK [{}]\", metadata.name(), KEKId, DEKId));\n+            return new Tuple<>(KEKId, KEK);\n+        } catch (GeneralSecurityException e) {\n+            throw new RepositoryException(metadata.name(), \"Failure to generate KEK to wrap the DEK [\" + DEKId + \"]\", e);\n+        }\n+    }\n+\n+    /**\n+     * Called before the shard snapshot and finalize operations, on the data and master nodes. This validates that the repository\n+     * secret on the master node that started the snapshot operation is identical to the repository secret on the local node.\n+     *\n+     * @param snapshotUserMetadata the snapshot metadata containing the repository secret id to verify\n+     * @throws RepositoryException if the repository secret id on the local node mismatches the master's\n+     */\n+    private void validateLocalRepositorySecret(Map<String, Object> snapshotUserMetadata) throws RepositoryException {\n+        if (snapshotUserMetadata == null) {\n+            throw new RepositoryException(\n+                metadata.name(),\n+                \"Unexpected fatal internal error\",\n+                new IllegalStateException(\"Null snapshot metadata\")\n+            );\n+        }\n+        final Object masterRepositoryPasswordId = snapshotUserMetadata.get(PASSWORD_ID_USER_METADATA_KEY);\n+        if (false == masterRepositoryPasswordId instanceof String) {\n+            throw new RepositoryException(\n+                metadata.name(),\n+                \"Unexpected fatal internal error\",\n+                new IllegalStateException(\"Snapshot metadata does not contain the repository password id as a String\")\n+            );\n+        }\n+        if (false == validatedRepositoryPasswordId.get().equals(masterRepositoryPasswordId)) {\n+            final Object masterRepositoryPasswordIdSalt = snapshotUserMetadata.get(PASSWORD_ID_SALT_USER_METADATA_KEY);\n+            if (false == masterRepositoryPasswordIdSalt instanceof String) {\n+                throw new RepositoryException(\n+                    metadata.name(),\n+                    \"Unexpected fatal internal error\",\n+                    new IllegalStateException(\"Snapshot metadata does not contain the repository password salt as a String\")\n+                );\n+            }\n+            final String computedRepositoryPasswordId;\n+            try {\n+                computedRepositoryPasswordId = AESKeyUtils.computeId(\n+                    AESKeyUtils.generatePasswordBasedKey(\n+                        repositoryPassword,\n+                        ((String) masterRepositoryPasswordIdSalt).getBytes(StandardCharsets.UTF_8)\n+                    )\n+                );\n+            } catch (Exception e) {\n+                throw new RepositoryException(metadata.name(), \"Unexpected fatal internal error\", e);\n+            }\n+            if (computedRepositoryPasswordId.equals(masterRepositoryPasswordId)) {\n+                this.validatedRepositoryPasswordId.set(computedRepositoryPasswordId);\n+            } else {\n+                throw new RepositoryException(\n+                    metadata.name(),\n+                    \"Repository secret id mismatch. The local node's repository secret, the keystore setting [\"\n+                        + EncryptedRepositoryPlugin.ENCRYPTION_PASSWORD_SETTING.getConcreteSettingForNamespace(\n+                            EncryptedRepositoryPlugin.PASSWORD_NAME_SETTING.get(metadata.settings())\n+                        ).getKey()\n+                        + \"], is different compared to the elected master node's which started the snapshot operation\"\n+                );\n+            }\n+        }\n+    }\n+\n+    // pkg-private for tests\n+    static final class EncryptedBlobStore implements BlobStore {\n+        private final BlobStore delegatedBlobStore;\n+        private final BlobPath delegatedBasePath;\n+        private final String repositoryName;\n+        private final Function<String, Tuple<String, SecretKey>> getKEKforDEK;\n+        private final Cache<String, SecretKey> DEKCache;\n+        private final CheckedSupplier<SingleUseKey, IOException> singleUseDEKSupplier;\n+\n+        EncryptedBlobStore(\n+            BlobStore delegatedBlobStore,\n+            BlobPath delegatedBasePath,\n+            String repositoryName,\n+            Function<String, Tuple<String, SecretKey>> getKEKforDEK,\n+            Supplier<Tuple<String, SecretKey>> DEKGenerator,\n+            Cache<String, SecretKey> DEKCache\n+        ) {\n+            this.delegatedBlobStore = delegatedBlobStore;\n+            this.delegatedBasePath = delegatedBasePath;\n+            this.repositoryName = repositoryName;\n+            this.getKEKforDEK = getKEKforDEK;\n+            this.DEKCache = DEKCache;\n+            this.singleUseDEKSupplier = SingleUseKey.createSingleUseKeySupplier(() -> {\n+                Tuple<String, SecretKey> newDEK = DEKGenerator.get();\n+                // store the newly generated DEK before making it available\n+                storeDEK(newDEK.v1(), newDEK.v2());\n+                return newDEK;\n+            });\n+        }\n+\n+        // pkg-private for tests\n+        SecretKey getDEKById(String DEKId) throws IOException {\n+            try {\n+                return DEKCache.computeIfAbsent(DEKId, ignored -> loadDEK(DEKId));\n+            } catch (ExecutionException e) {\n+                // some exception types are to be expected\n+                if (e.getCause() instanceof IOException) {\n+                    throw (IOException) e.getCause();\n+                } else if (e.getCause() instanceof ElasticsearchException) {\n+                    throw (ElasticsearchException) e.getCause();\n+                } else {\n+                    throw new RepositoryException(repositoryName, \"Unexpected exception retrieving DEK [\" + DEKId + \"]\", e);\n+                }\n+            }\n+        }\n+\n+        private SecretKey loadDEK(String DEKId) throws IOException {\n+            final BlobPath DEKBlobPath = delegatedBasePath.add(DEK_ROOT_CONTAINER).add(DEKId);\n+            logger.debug(\n+                () -> new ParameterizedMessage(\n+                    \"Repository [{}] loading wrapped DEK [{}] from blob path {}\",\n+                    repositoryName,\n+                    DEKId,\n+                    DEKBlobPath\n+                )\n+            );\n+            final BlobContainer DEKBlobContainer = delegatedBlobStore.blobContainer(DEKBlobPath);\n+            final Tuple<String, SecretKey> KEK = getKEKforDEK.apply(DEKId);\n+            logger.trace(\n+                () -> new ParameterizedMessage(\"Repository [{}] using KEK [{}] to unwrap DEK [{}]\", repositoryName, KEK.v1(), DEKId)\n+            );\n+            final byte[] encryptedDEKBytes = new byte[AESKeyUtils.WRAPPED_KEY_LENGTH_IN_BYTES];\n+            try (InputStream encryptedDEKInputStream = DEKBlobContainer.readBlob(KEK.v1())) {\n+                final int bytesRead = Streams.readFully(encryptedDEKInputStream, encryptedDEKBytes);\n+                if (bytesRead != AESKeyUtils.WRAPPED_KEY_LENGTH_IN_BYTES) {\n+                    throw new RepositoryException(\n+                        repositoryName,\n+                        \"Wrapped DEK [\" + DEKId + \"] has smaller length [\" + bytesRead + \"] \" + \"than expected\"\n+                    );\n+                }\n+                if (encryptedDEKInputStream.read() != -1) {\n+                    throw new RepositoryException(repositoryName, \"Wrapped DEK [\" + DEKId + \"] is larger than expected\");\n+                }\n+            } catch (NoSuchFileException e) {\n+                // do NOT throw IOException when the DEK does not exist, as this is a decryption problem, and IOExceptions\n+                // can move the repository in the corrupted state\n+                throw new ElasticsearchException(\n+                    \"Failure to read and decrypt DEK [\"\n+                        + DEKId\n+                        + \"] from \"\n+                        + DEKBlobContainer.path()\n+                        + \". Most likely the repository password is incorrect, where previous \"\n+                        + \"snapshots have used a different password.\",\n+                    e\n+                );\n+            }\n+            logger.trace(\n+                () -> new ParameterizedMessage(\n+                    \"Repository [{}] successfully read DEK [{}] from path {} {}\",\n+                    repositoryName,\n+                    DEKId,\n+                    DEKBlobPath,\n+                    KEK.v1()\n+                )\n+            );\n+            try {\n+                final SecretKey DEK = AESKeyUtils.unwrap(KEK.v2(), encryptedDEKBytes);\n+                logger.debug(\n+                    () -> new ParameterizedMessage(\n+                        \"Repository [{}] successfully loaded DEK [{}] from path {} {}\",\n+                        repositoryName,\n+                        DEKId,\n+                        DEKBlobPath,\n+                        KEK.v1()\n+                    )\n+                );\n+                return DEK;\n+            } catch (GeneralSecurityException e) {\n+                throw new RepositoryException(\n+                    repositoryName,\n+                    \"Failure to AES unwrap the DEK [\"\n+                        + DEKId\n+                        + \"]. \"\n+                        + \"Most likely the encryption metadata in the repository has been corrupted\",\n+                    e\n+                );\n+            }\n+        }\n+\n+        // pkg-private for tests\n+        void storeDEK(String DEKId, SecretKey DEK) throws IOException {\n+            final BlobPath DEKBlobPath = delegatedBasePath.add(DEK_ROOT_CONTAINER).add(DEKId);\n+            logger.debug(\n+                () -> new ParameterizedMessage(\n+                    \"Repository [{}] storing wrapped DEK [{}] under blob path {}\",\n+                    repositoryName,\n+                    DEKId,\n+                    DEKBlobPath\n+                )\n+            );\n+            final BlobContainer DEKBlobContainer = delegatedBlobStore.blobContainer(DEKBlobPath);\n+            final Tuple<String, SecretKey> KEK = getKEKforDEK.apply(DEKId);\n+            logger.trace(\n+                () -> new ParameterizedMessage(\"Repository [{}] using KEK [{}] to wrap DEK [{}]\", repositoryName, KEK.v1(), DEKId)\n+            );\n+            final byte[] encryptedDEKBytes;\n+            try {\n+                encryptedDEKBytes = AESKeyUtils.wrap(KEK.v2(), DEK);\n+                if (encryptedDEKBytes.length != AESKeyUtils.WRAPPED_KEY_LENGTH_IN_BYTES) {\n+                    throw new RepositoryException(\n+                        repositoryName,\n+                        \"Wrapped DEK [\" + DEKId + \"] has unexpected length [\" + encryptedDEKBytes.length + \"]\"\n+                    );\n+                }\n+            } catch (GeneralSecurityException e) {\n+                // throw unchecked ElasticsearchException; IOExceptions are interpreted differently and can move the repository in the\n+                // corrupted state\n+                throw new RepositoryException(repositoryName, \"Failure to AES wrap the DEK [\" + DEKId + \"]\", e);\n+            }\n+            logger.trace(() -> new ParameterizedMessage(\"Repository [{}] successfully wrapped DEK [{}]\", repositoryName, DEKId));\n+            try (InputStream encryptedDEKInputStream = new ByteArrayInputStream(encryptedDEKBytes)) {\n+                DEKBlobContainer.writeBlobAtomic(KEK.v1(), encryptedDEKInputStream, encryptedDEKBytes.length, true);\n+            }\n+            logger.debug(\n+                () -> new ParameterizedMessage(\n+                    \"Repository [{}] successfully stored DEK [{}] under path {} {}\",\n+                    repositoryName,\n+                    DEKId,\n+                    DEKBlobPath,\n+                    KEK.v1()\n+                )\n+            );\n+        }\n+\n+        @Override\n+        public BlobContainer blobContainer(BlobPath path) {\n+            final BlobContainer delegatedBlobContainer = delegatedBlobStore.blobContainer(delegatedBasePath.append(path));\n+            return new EncryptedBlobContainer(path, repositoryName, delegatedBlobContainer, singleUseDEKSupplier, this::getDEKById);\n+        }\n+\n+        @Override\n+        public void close() {\n+            // do NOT close delegatedBlobStore; it will be closed when the inner delegatedRepository is closed\n+        }\n+\n+    }\n+\n+    private static final class EncryptedBlobContainer extends AbstractBlobContainer {\n+        private final String repositoryName;\n+        private final BlobContainer delegatedBlobContainer;\n+        // supplier for the DEK used for encryption (snapshot)\n+        private final CheckedSupplier<SingleUseKey, IOException> singleUseDEKSupplier;\n+        // retrieves the DEK required for decryption (restore)\n+        private final CheckedFunction<String, SecretKey, IOException> getDEKById;\n+\n+        EncryptedBlobContainer(\n+            BlobPath path, // this path contains the {@code EncryptedRepository#basePath} which, importantly, is empty\n+            String repositoryName,\n+            BlobContainer delegatedBlobContainer,\n+            CheckedSupplier<SingleUseKey, IOException> singleUseDEKSupplier,\n+            CheckedFunction<String, SecretKey, IOException> getDEKById\n+        ) {\n+            super(path);\n+            this.repositoryName = repositoryName;\n+            if (DEK_ROOT_CONTAINER.equals(path.getRootPath())) {\n+                throw new RepositoryException(\n+                    repositoryName,\n+                    \"Unexpected internal error\",\n+                    new IllegalArgumentException(\"Cannot descend into the DEK blob container \" + path)\n+                );\n+            }\n+            this.delegatedBlobContainer = delegatedBlobContainer;\n+            this.singleUseDEKSupplier = singleUseDEKSupplier;\n+            this.getDEKById = getDEKById;\n+        }\n+\n+        /**\n+         * Returns a new {@link InputStream} for the given {@code blobName} that can be used to read the contents of the blob.\n+         * The returned {@code InputStream} transparently handles the decryption of the blob contents, by first working out\n+         * the blob name of the associated DEK id, reading and decrypting the DEK (given the repository secret key, unless the DEK is\n+         * already cached because other blobs required it before), and lastly reading and decrypting the data blob,\n+         * in a streaming fashion, by employing the {@link DecryptionPacketsInputStream}.\n+         * The {@code DecryptionPacketsInputStream} does not return un-authenticated data.\n+         *\n+         * @param   blobName The name of the blob to get an {@link InputStream} for.\n+         */\n+        @Override\n+        public InputStream readBlob(String blobName) throws IOException {\n+            // This MIGHT require two concurrent readBlob connections if the DEK is not already in the cache and if the encrypted blob\n+            // is large enough so that the underlying network library keeps the connection open after reading the prepended DEK ID.\n+            // Arguably this is a problem only under lab conditions, when the storage service is saturated only by the first read\n+            // connection of the pair, so that the second read connection (for the DEK) can not be fulfilled.\n+            // In this case the second connection will time-out which will trigger the closing of the first one, therefore\n+            // allowing other pair connections to complete.\n+            // In this situation the restore process should slowly make headway, albeit under read-timeout exceptions\n+            final InputStream encryptedDataInputStream = delegatedBlobContainer.readBlob(blobName);\n+            try {\n+                // read the DEK Id (fixed length) which is prepended to the encrypted blob\n+                final byte[] DEKIdBytes = new byte[DEK_ID_LENGTH];\n+                final int bytesRead = Streams.readFully(encryptedDataInputStream, DEKIdBytes);\n+                if (bytesRead != DEK_ID_LENGTH) {\n+                    throw new RepositoryException(repositoryName, \"The encrypted blob [\" + blobName + \"] is too small [\" + bytesRead + \"]\");\n+                }\n+                final String DEKId = new String(DEKIdBytes, StandardCharsets.UTF_8);\n+                // might open a connection to read and decrypt the DEK, but most likely it will be served from cache\n+                final SecretKey DEK = getDEKById.apply(DEKId);\n+                // read and decrypt the rest of the blob\n+                return new DecryptionPacketsInputStream(encryptedDataInputStream, DEK, PACKET_LENGTH_IN_BYTES);\n+            } catch (Exception e) {\n+                try {\n+                    encryptedDataInputStream.close();\n+                } catch (IOException closeEx) {\n+                    e.addSuppressed(closeEx);\n+                }\n+                throw e;\n+            }\n+        }\n+\n+        /**\n+         * Reads the blob content from the input stream and writes it to the container in a new blob with the given name.\n+         * If {@code failIfAlreadyExists} is {@code true} and a blob with the same name already exists, the write operation will fail;\n+         * otherwise, if {@code failIfAlreadyExists} is {@code false} the blob is overwritten.\n+         * The contents are encrypted in a streaming fashion. The DEK (encryption key) is randomly generated and reused for encrypting\n+         * subsequent blobs such that the same IV is not reused together with the same key.\n+         * The DEK encryption key is separately stored in a different blob, which is encrypted with the repository key.\n+         *\n+         * @param   blobName\n+         *          The name of the blob to write the contents of the input stream to.\n+         * @param   inputStream\n+         *          The input stream from which to retrieve the bytes to write to the blob.\n+         * @param   blobSize\n+         *          The size of the blob to be written, in bytes. The actual number of bytes written to the storage service is larger\n+         *          because of encryption and authentication overhead. It is implementation dependent whether this value is used\n+         *          in writing the blob to the repository.\n+         * @param   failIfAlreadyExists\n+         *          whether to throw a FileAlreadyExistsException if the given blob already exists\n+         */\n+        @Override\n+        public void writeBlob(String blobName, InputStream inputStream, long blobSize, boolean failIfAlreadyExists) throws IOException {\n+            // reuse, but possibly generate and store a new DEK\n+            final SingleUseKey singleUseNonceAndDEK = singleUseDEKSupplier.get();\n+            final byte[] DEKIdBytes = singleUseNonceAndDEK.getKeyId().getBytes(StandardCharsets.UTF_8);\n+            if (DEKIdBytes.length != DEK_ID_LENGTH) {\n+                throw new RepositoryException(\n+                    repositoryName,\n+                    \"Unexpected internal error\",\n+                    new IllegalStateException(\"Unexpected DEK Id length [\" + DEKIdBytes.length + \"]\")\n+                );\n+            }\n+            final long encryptedBlobSize = getEncryptedBlobByteLength(blobSize);\n+            try (\n+                InputStream encryptedInputStream = ChainingInputStream.chain(\n+                    new ByteArrayInputStream(DEKIdBytes),\n+                    new EncryptionPacketsInputStream(\n+                        inputStream,\n+                        singleUseNonceAndDEK.getKey(),\n+                        singleUseNonceAndDEK.getNonce(),\n+                        PACKET_LENGTH_IN_BYTES\n+                    )\n+                )\n+            ) {\n+                delegatedBlobContainer.writeBlob(blobName, encryptedInputStream, encryptedBlobSize, failIfAlreadyExists);\n+            }\n+        }\n+\n+        @Override\n+        public void writeBlobAtomic(String blobName, InputStream inputStream, long blobSize, boolean failIfAlreadyExists)\n+            throws IOException {\n+            // the encrypted repository does not offer an alternative implementation for atomic writes\n+            // fallback to regular write\n+            writeBlob(blobName, inputStream, blobSize, failIfAlreadyExists);\n+        }\n+\n+        @Override\n+        public DeleteResult delete() throws IOException {\n+            return delegatedBlobContainer.delete();\n+        }\n+\n+        @Override\n+        public void deleteBlobsIgnoringIfNotExists(List<String> blobNames) throws IOException {\n+            delegatedBlobContainer.deleteBlobsIgnoringIfNotExists(blobNames);\n+        }\n+\n+        @Override\n+        public Map<String, BlobMetaData> listBlobs() throws IOException {\n+            return delegatedBlobContainer.listBlobs();\n+        }\n+\n+        @Override\n+        public Map<String, BlobMetaData> listBlobsByPrefix(String blobNamePrefix) throws IOException {\n+            return delegatedBlobContainer.listBlobsByPrefix(blobNamePrefix);\n+        }\n+\n+        @Override\n+        public Map<String, BlobContainer> children() throws IOException {\n+            final Map<String, BlobContainer> childEncryptedBlobContainers = delegatedBlobContainer.children();\n+            final Map<String, BlobContainer> resultBuilder = new HashMap<>(childEncryptedBlobContainers.size());\n+            for (Map.Entry<String, BlobContainer> childBlobContainer : childEncryptedBlobContainers.entrySet()) {\n+                if (childBlobContainer.getKey().equals(DEK_ROOT_CONTAINER) && path().isEmpty()) {\n+                    // do not descend into the DEK blob container\n+                    continue;\n+                }\n+                // get an encrypted blob container for each child\n+                // Note that the encryption metadata blob container might be missing\n+                resultBuilder.put(\n+                    childBlobContainer.getKey(),\n+                    new EncryptedBlobContainer(\n+                        path().add(childBlobContainer.getKey()),\n+                        repositoryName,\n+                        childBlobContainer.getValue(),\n+                        singleUseDEKSupplier,\n+                        getDEKById\n+                    )\n+                );\n+            }\n+            return Map.copyOf(resultBuilder);\n+        }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 739}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjE1NDA5Mw==", "bodyText": "Why not HDFS? :)", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402154093", "createdAt": "2020-04-02T08:53:34Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepositoryPlugin.java", "diffHunk": "@@ -6,26 +6,153 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.cluster.metadata.RepositoryMetaData;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.settings.SecureSetting;\n+import org.elasticsearch.common.settings.SecureString;\n import org.elasticsearch.common.settings.Setting;\n-import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.env.Environment;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n import org.elasticsearch.plugins.Plugin;\n-import org.elasticsearch.plugins.ReloadablePlugin;\n import org.elasticsearch.plugins.RepositoryPlugin;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.xpack.core.XPackPlugin;\n \n+import java.security.GeneralSecurityException;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n \n-public final class EncryptedRepositoryPlugin extends Plugin implements RepositoryPlugin, ReloadablePlugin {\n+public class EncryptedRepositoryPlugin extends Plugin implements RepositoryPlugin {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepositoryPlugin.class);\n+    static final String REPOSITORY_TYPE_NAME = \"encrypted\";\n+    static final List<String> SUPPORTED_ENCRYPTED_TYPE_NAMES = Arrays.asList(\"fs\", \"gcs\", \"azure\", \"s3\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjE1NzA5Nw==", "bodyText": "I think this should just be a BytesReference a explained above", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402157097", "createdAt": "2020-04-02T08:58:10Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/SingleUseKey.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.repositories.encrypted;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.collect.Tuple;\n+\n+import javax.crypto.SecretKey;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+/**\n+ * Container class for a {@code SecretKey} with a unique identifier, and a 4-byte wide {@code Integer} nonce, that can be used for a\n+ * single encryption operation. Use {@link #createSingleUseKeySupplier(CheckedSupplier)} to obtain a {@code Supplier} that returns\n+ * a new {@link SingleUseKey} instance on every invocation. The number of unique {@code SecretKey}s (and their associated identifiers)\n+ * generated is minimized and, at the same time, ensuring that a given {@code nonce} is not reused with the same key.\n+ */\n+final class SingleUseKey {\n+    private static final Logger logger = LogManager.getLogger(SingleUseKey.class);\n+    static final int MIN_NONCE = Integer.MIN_VALUE;\n+    static final int MAX_NONCE = Integer.MAX_VALUE;\n+    private static final int MAX_ATTEMPTS = 9;\n+    private static final SingleUseKey EXPIRED_KEY = new SingleUseKey(null, null, MAX_NONCE);\n+\n+    private final String keyId;\n+    private final SecretKey key;\n+    private final Integer nonce;\n+\n+    // for tests use only!\n+    SingleUseKey(String KeyId, SecretKey Key, Integer nonce) {\n+        this.keyId = KeyId;\n+        this.key = Key;\n+        this.nonce = nonce;\n+    }\n+\n+    public String getKeyId() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjE1NzQyOA==", "bodyText": "Can this ever be null?", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r402157428", "createdAt": "2020-04-02T08:58:41Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/SingleUseKey.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.repositories.encrypted;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.collect.Tuple;\n+\n+import javax.crypto.SecretKey;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+/**\n+ * Container class for a {@code SecretKey} with a unique identifier, and a 4-byte wide {@code Integer} nonce, that can be used for a\n+ * single encryption operation. Use {@link #createSingleUseKeySupplier(CheckedSupplier)} to obtain a {@code Supplier} that returns\n+ * a new {@link SingleUseKey} instance on every invocation. The number of unique {@code SecretKey}s (and their associated identifiers)\n+ * generated is minimized and, at the same time, ensuring that a given {@code nonce} is not reused with the same key.\n+ */\n+final class SingleUseKey {\n+    private static final Logger logger = LogManager.getLogger(SingleUseKey.class);\n+    static final int MIN_NONCE = Integer.MIN_VALUE;\n+    static final int MAX_NONCE = Integer.MAX_VALUE;\n+    private static final int MAX_ATTEMPTS = 9;\n+    private static final SingleUseKey EXPIRED_KEY = new SingleUseKey(null, null, MAX_NONCE);\n+\n+    private final String keyId;\n+    private final SecretKey key;\n+    private final Integer nonce;\n+\n+    // for tests use only!\n+    SingleUseKey(String KeyId, SecretKey Key, Integer nonce) {\n+        this.keyId = KeyId;\n+        this.key = Key;\n+        this.nonce = nonce;\n+    }\n+\n+    public String getKeyId() {\n+        return keyId;\n+    }\n+\n+    public SecretKey getKey() {\n+        return key;\n+    }\n+\n+    public Integer getNonce() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d152a68924a4149d4b407017b5fab50c5d7979"}, "originalPosition": 50}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg3OTYwODAx", "url": "https://github.com/elastic/elasticsearch/pull/53352#pullrequestreview-387960801", "createdAt": "2020-04-06T06:25:12Z", "commit": {"oid": "fc4e98a30826dde5ae1b6abf50bc238aa485b481"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk0MzE2MjE0", "url": "https://github.com/elastic/elasticsearch/pull/53352#pullrequestreview-394316214", "createdAt": "2020-04-16T05:51:37Z", "commit": {"oid": "fc4e98a30826dde5ae1b6abf50bc238aa485b481"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwNTo1MTozN1rOGGVjeA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwNjozNTozOVrOGGWjRw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI5Nzc4NA==", "bodyText": "Can you clarify why we don't validate the per-packet nonce anymore?", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r409297784", "createdAt": "2020-04-16T05:51:37Z", "author": {"login": "tvernum"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/DecryptionPacketsInputStream.java", "diffHunk": "@@ -124,19 +123,19 @@ public void reset() throws IOException {\n         throw new IOException(\"Mark/reset not supported\");\n     }\n \n+    @Override\n+    public void close() throws IOException {\n+        IOUtils.close(super::close, source);\n+    }\n+\n     private int decrypt(PrefixInputStream packetInputStream) throws IOException {\n         // read only the IV prefix into the packet buffer\n         int ivLength = packetInputStream.readNBytes(packetBuffer, 0, GCM_IV_LENGTH_IN_BYTES);\n         if (ivLength != GCM_IV_LENGTH_IN_BYTES) {\n             throw new IOException(\"Packet heading IV error. Unexpected length [\" + ivLength + \"].\");\n         }\n-        // extract the nonce and the counter from the packet IV\n-        ByteBuffer ivBuffer = ByteBuffer.wrap(packetBuffer, 0, GCM_IV_LENGTH_IN_BYTES).order(ByteOrder.LITTLE_ENDIAN);\n-        int packetIvNonce = ivBuffer.getInt(0);\n-        long packetIvCounter = ivBuffer.getLong(Integer.BYTES);\n-        if (packetIvNonce != nonce) {\n-            throw new IOException(\"Packet nonce mismatch. Expecting [\" + nonce + \"], but got [\" + packetIvNonce + \"].\");\n-        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fc4e98a30826dde5ae1b6abf50bc238aa485b481"}, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI5ODExNg==", "bodyText": "The reason for the offset (Integer.BYTES) is a bit less clear now that we don't read the nonce, can we add a comment or something to explain it?", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r409298116", "createdAt": "2020-04-16T05:52:35Z", "author": {"login": "tvernum"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/DecryptionPacketsInputStream.java", "diffHunk": "@@ -124,19 +123,19 @@ public void reset() throws IOException {\n         throw new IOException(\"Mark/reset not supported\");\n     }\n \n+    @Override\n+    public void close() throws IOException {\n+        IOUtils.close(super::close, source);\n+    }\n+\n     private int decrypt(PrefixInputStream packetInputStream) throws IOException {\n         // read only the IV prefix into the packet buffer\n         int ivLength = packetInputStream.readNBytes(packetBuffer, 0, GCM_IV_LENGTH_IN_BYTES);\n         if (ivLength != GCM_IV_LENGTH_IN_BYTES) {\n             throw new IOException(\"Packet heading IV error. Unexpected length [\" + ivLength + \"].\");\n         }\n-        // extract the nonce and the counter from the packet IV\n-        ByteBuffer ivBuffer = ByteBuffer.wrap(packetBuffer, 0, GCM_IV_LENGTH_IN_BYTES).order(ByteOrder.LITTLE_ENDIAN);\n-        int packetIvNonce = ivBuffer.getInt(0);\n-        long packetIvCounter = ivBuffer.getLong(Integer.BYTES);\n-        if (packetIvNonce != nonce) {\n-            throw new IOException(\"Packet nonce mismatch. Expecting [\" + nonce + \"], but got [\" + packetIvNonce + \"].\");\n-        }\n+        // extract the counter from the packet IV\n+        long packetIvCounter = ByteUtils.readLongLE(packetBuffer, Integer.BYTES);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fc4e98a30826dde5ae1b6abf50bc238aa485b481"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTMwOTIzOQ==", "bodyText": "Won't this plugin be loaded on every node of the default distribution? That means ever non-platinum node prints out this warning at every startup. That doesn't sound right to me.", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r409309239", "createdAt": "2020-04-16T06:23:26Z", "author": {"login": "tvernum"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepositoryPlugin.java", "diffHunk": "@@ -6,25 +6,153 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.cluster.metadata.RepositoryMetadata;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.settings.SecureSetting;\n+import org.elasticsearch.common.settings.SecureString;\n import org.elasticsearch.common.settings.Setting;\n-import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.env.Environment;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n import org.elasticsearch.plugins.Plugin;\n-import org.elasticsearch.plugins.ReloadablePlugin;\n import org.elasticsearch.plugins.RepositoryPlugin;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.xpack.core.XPackPlugin;\n \n+import java.security.GeneralSecurityException;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n \n-public final class EncryptedRepositoryPlugin extends Plugin implements RepositoryPlugin, ReloadablePlugin {\n+public class EncryptedRepositoryPlugin extends Plugin implements RepositoryPlugin {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepositoryPlugin.class);\n+    static final String REPOSITORY_TYPE_NAME = \"encrypted\";\n+    // TODO add at least hdfs, and investigate supporting all `BlobStoreRepository` implementations\n+    static final List<String> SUPPORTED_ENCRYPTED_TYPE_NAMES = Arrays.asList(\"fs\", \"gcs\", \"azure\", \"s3\");\n+    static final Setting.AffixSetting<SecureString> ENCRYPTION_PASSWORD_SETTING = Setting.affixKeySetting(\n+        \"repository.encrypted.\",\n+        \"password\",\n+        key -> SecureSetting.secureString(key, null)\n+    );\n+    static final Setting<String> DELEGATE_TYPE_SETTING = Setting.simpleString(\"delegate_type\", \"\");\n+    static final Setting<String> PASSWORD_NAME_SETTING = Setting.simpleString(\"password_name\", \"\");\n \n-    public EncryptedRepositoryPlugin(final Settings settings) {}\n+    // \"protected\" because it is overloaded for tests\n+    protected XPackLicenseState getLicenseState() {\n+        return XPackPlugin.getSharedLicenseState();\n+    }\n+\n+    public EncryptedRepositoryPlugin() {\n+        if (false == getLicenseState().isEncryptedSnapshotAllowed()) {\n+            logger.warn(\n+                \"Snapshotting to an encrypted repository is not permitted for the current license.\"\n+                    + \"All the other operations over the encrypted repository, eg. restore, work without restrictions.\",\n+                LicenseUtils.newComplianceException(\"encrypted snapshots\")\n+            );", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fc4e98a30826dde5ae1b6abf50bc238aa485b481"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTMxMDMyMg==", "bodyText": "Why a char[] rather than SecureString ?", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r409310322", "createdAt": "2020-04-16T06:26:12Z", "author": {"login": "tvernum"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepositoryPlugin.java", "diffHunk": "@@ -6,25 +6,153 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.cluster.metadata.RepositoryMetadata;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.settings.SecureSetting;\n+import org.elasticsearch.common.settings.SecureString;\n import org.elasticsearch.common.settings.Setting;\n-import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.env.Environment;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n import org.elasticsearch.plugins.Plugin;\n-import org.elasticsearch.plugins.ReloadablePlugin;\n import org.elasticsearch.plugins.RepositoryPlugin;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.xpack.core.XPackPlugin;\n \n+import java.security.GeneralSecurityException;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n \n-public final class EncryptedRepositoryPlugin extends Plugin implements RepositoryPlugin, ReloadablePlugin {\n+public class EncryptedRepositoryPlugin extends Plugin implements RepositoryPlugin {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepositoryPlugin.class);\n+    static final String REPOSITORY_TYPE_NAME = \"encrypted\";\n+    // TODO add at least hdfs, and investigate supporting all `BlobStoreRepository` implementations\n+    static final List<String> SUPPORTED_ENCRYPTED_TYPE_NAMES = Arrays.asList(\"fs\", \"gcs\", \"azure\", \"s3\");\n+    static final Setting.AffixSetting<SecureString> ENCRYPTION_PASSWORD_SETTING = Setting.affixKeySetting(\n+        \"repository.encrypted.\",\n+        \"password\",\n+        key -> SecureSetting.secureString(key, null)\n+    );\n+    static final Setting<String> DELEGATE_TYPE_SETTING = Setting.simpleString(\"delegate_type\", \"\");\n+    static final Setting<String> PASSWORD_NAME_SETTING = Setting.simpleString(\"password_name\", \"\");\n \n-    public EncryptedRepositoryPlugin(final Settings settings) {}\n+    // \"protected\" because it is overloaded for tests\n+    protected XPackLicenseState getLicenseState() {\n+        return XPackPlugin.getSharedLicenseState();\n+    }\n+\n+    public EncryptedRepositoryPlugin() {\n+        if (false == getLicenseState().isEncryptedSnapshotAllowed()) {\n+            logger.warn(\n+                \"Snapshotting to an encrypted repository is not permitted for the current license.\"\n+                    + \"All the other operations over the encrypted repository, eg. restore, work without restrictions.\",\n+                LicenseUtils.newComplianceException(\"encrypted snapshots\")\n+            );\n+        }\n+    }\n \n     @Override\n     public List<Setting<?>> getSettings() {\n-        return List.of();\n+        return List.of(ENCRYPTION_PASSWORD_SETTING);\n     }\n \n     @Override\n-    public void reload(Settings settings) {\n-        // Secure settings should be readable inside this method.\n+    public Map<String, Repository.Factory> getRepositories(Environment env, NamedXContentRegistry registry, ClusterService clusterService) {\n+        // load all the passwords from the keystore in memory because the keystore is not readable when the repository is created\n+        final Map<String, char[]> repositoryPasswordsMapBuilder = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fc4e98a30826dde5ae1b6abf50bc238aa485b481"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTMxMjk3Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                throw new IllegalArgumentException(\"Unsupported delegate repository type [\" + DELEGATE_TYPE_SETTING.getKey() + \"]\");\n          \n          \n            \n                                throw new IllegalArgumentException(\"Unsupported delegate repository type [\" + delegateType \n          \n          \n            \n                                    + \"] for setting [\" + DELEGATE_TYPE_SETTING.getKey() + \"]\");", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r409312976", "createdAt": "2020-04-16T06:32:52Z", "author": {"login": "tvernum"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepositoryPlugin.java", "diffHunk": "@@ -6,25 +6,153 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.cluster.metadata.RepositoryMetadata;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.settings.SecureSetting;\n+import org.elasticsearch.common.settings.SecureString;\n import org.elasticsearch.common.settings.Setting;\n-import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.env.Environment;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n import org.elasticsearch.plugins.Plugin;\n-import org.elasticsearch.plugins.ReloadablePlugin;\n import org.elasticsearch.plugins.RepositoryPlugin;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.xpack.core.XPackPlugin;\n \n+import java.security.GeneralSecurityException;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n \n-public final class EncryptedRepositoryPlugin extends Plugin implements RepositoryPlugin, ReloadablePlugin {\n+public class EncryptedRepositoryPlugin extends Plugin implements RepositoryPlugin {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepositoryPlugin.class);\n+    static final String REPOSITORY_TYPE_NAME = \"encrypted\";\n+    // TODO add at least hdfs, and investigate supporting all `BlobStoreRepository` implementations\n+    static final List<String> SUPPORTED_ENCRYPTED_TYPE_NAMES = Arrays.asList(\"fs\", \"gcs\", \"azure\", \"s3\");\n+    static final Setting.AffixSetting<SecureString> ENCRYPTION_PASSWORD_SETTING = Setting.affixKeySetting(\n+        \"repository.encrypted.\",\n+        \"password\",\n+        key -> SecureSetting.secureString(key, null)\n+    );\n+    static final Setting<String> DELEGATE_TYPE_SETTING = Setting.simpleString(\"delegate_type\", \"\");\n+    static final Setting<String> PASSWORD_NAME_SETTING = Setting.simpleString(\"password_name\", \"\");\n \n-    public EncryptedRepositoryPlugin(final Settings settings) {}\n+    // \"protected\" because it is overloaded for tests\n+    protected XPackLicenseState getLicenseState() {\n+        return XPackPlugin.getSharedLicenseState();\n+    }\n+\n+    public EncryptedRepositoryPlugin() {\n+        if (false == getLicenseState().isEncryptedSnapshotAllowed()) {\n+            logger.warn(\n+                \"Snapshotting to an encrypted repository is not permitted for the current license.\"\n+                    + \"All the other operations over the encrypted repository, eg. restore, work without restrictions.\",\n+                LicenseUtils.newComplianceException(\"encrypted snapshots\")\n+            );\n+        }\n+    }\n \n     @Override\n     public List<Setting<?>> getSettings() {\n-        return List.of();\n+        return List.of(ENCRYPTION_PASSWORD_SETTING);\n     }\n \n     @Override\n-    public void reload(Settings settings) {\n-        // Secure settings should be readable inside this method.\n+    public Map<String, Repository.Factory> getRepositories(Environment env, NamedXContentRegistry registry, ClusterService clusterService) {\n+        // load all the passwords from the keystore in memory because the keystore is not readable when the repository is created\n+        final Map<String, char[]> repositoryPasswordsMapBuilder = new HashMap<>();\n+        for (String passwordName : ENCRYPTION_PASSWORD_SETTING.getNamespaces(env.settings())) {\n+            Setting<SecureString> passwordSetting = ENCRYPTION_PASSWORD_SETTING.getConcreteSettingForNamespace(passwordName);\n+            SecureString encryptionPassword = passwordSetting.get(env.settings());\n+            repositoryPasswordsMapBuilder.put(passwordName, encryptionPassword.getChars());\n+            logger.debug(\"Loaded repository password [{}] from the node keystore\", passwordName);\n+        }\n+        final Map<String, char[]> repositoryPasswordsMap = Map.copyOf(repositoryPasswordsMapBuilder);\n+\n+        return Collections.singletonMap(REPOSITORY_TYPE_NAME, new Repository.Factory() {\n+\n+            @Override\n+            public Repository create(RepositoryMetadata metadata) {\n+                throw new UnsupportedOperationException();\n+            }\n+\n+            @Override\n+            public Repository create(RepositoryMetadata metadata, Function<String, Repository.Factory> typeLookup) throws Exception {\n+                final String delegateType = DELEGATE_TYPE_SETTING.get(metadata.settings());\n+                if (Strings.hasLength(delegateType) == false) {\n+                    throw new IllegalArgumentException(\"Repository setting [\" + DELEGATE_TYPE_SETTING.getKey() + \"] must be set\");\n+                }\n+                if (REPOSITORY_TYPE_NAME.equals(delegateType)) {\n+                    throw new IllegalArgumentException(\n+                        \"Cannot encrypt an already encrypted repository. [\"\n+                            + DELEGATE_TYPE_SETTING.getKey()\n+                            + \"] must not be equal to [\"\n+                            + REPOSITORY_TYPE_NAME\n+                            + \"]\"\n+                    );\n+                }\n+                final Repository.Factory factory = typeLookup.apply(delegateType);\n+                if (null == factory || false == SUPPORTED_ENCRYPTED_TYPE_NAMES.contains(delegateType)) {\n+                    throw new IllegalArgumentException(\"Unsupported delegate repository type [\" + DELEGATE_TYPE_SETTING.getKey() + \"]\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fc4e98a30826dde5ae1b6abf50bc238aa485b481"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTMxNDExOQ==", "bodyText": "We can come back to it later, but I feel like this setting name implies that the variable part should be the name of the repo, but it's actually the name of the password on the repo.\nI would be more inclined to have repostory.encrypted.password.<name> but it's not a priority for this PR.", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r409314119", "createdAt": "2020-04-16T06:35:39Z", "author": {"login": "tvernum"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepositoryPlugin.java", "diffHunk": "@@ -6,25 +6,153 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.cluster.metadata.RepositoryMetadata;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.settings.SecureSetting;\n+import org.elasticsearch.common.settings.SecureString;\n import org.elasticsearch.common.settings.Setting;\n-import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.env.Environment;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n import org.elasticsearch.plugins.Plugin;\n-import org.elasticsearch.plugins.ReloadablePlugin;\n import org.elasticsearch.plugins.RepositoryPlugin;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.xpack.core.XPackPlugin;\n \n+import java.security.GeneralSecurityException;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n \n-public final class EncryptedRepositoryPlugin extends Plugin implements RepositoryPlugin, ReloadablePlugin {\n+public class EncryptedRepositoryPlugin extends Plugin implements RepositoryPlugin {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepositoryPlugin.class);\n+    static final String REPOSITORY_TYPE_NAME = \"encrypted\";\n+    // TODO add at least hdfs, and investigate supporting all `BlobStoreRepository` implementations\n+    static final List<String> SUPPORTED_ENCRYPTED_TYPE_NAMES = Arrays.asList(\"fs\", \"gcs\", \"azure\", \"s3\");\n+    static final Setting.AffixSetting<SecureString> ENCRYPTION_PASSWORD_SETTING = Setting.affixKeySetting(\n+        \"repository.encrypted.\",\n+        \"password\",\n+        key -> SecureSetting.secureString(key, null)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fc4e98a30826dde5ae1b6abf50bc238aa485b481"}, "originalPosition": 42}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAxNTA4MTUz", "url": "https://github.com/elastic/elasticsearch/pull/53352#pullrequestreview-401508153", "createdAt": "2020-04-28T05:31:05Z", "commit": {"oid": "fc4e98a30826dde5ae1b6abf50bc238aa485b481"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQwNTozMTowNVrOGNDPaA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQwNTo0MTo0NlrOGNDeHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjMzNzc2OA==", "bodyText": "A few small suggestions:\n\nI think printing the license mode will assist understanding the message.\nIt needs whitespace between the joined sentences\nOur typical idiom is to use parameters rather than string concatenation.\n\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                logger.warn(\n          \n          \n            \n                                    \"Encrypted snapshots are not allowed for the currently installed license.\"\n          \n          \n            \n                                        + \"Snapshots to the [\"\n          \n          \n            \n                                        + metadata.name()\n          \n          \n            \n                                        + \"] encrypted repository are not permitted.\"\n          \n          \n            \n                                        + \"All the other operations, including restore, work without restrictions.\",\n          \n          \n            \n                                    LicenseUtils.newComplianceException(\"encrypted snapshots\")\n          \n          \n            \n                                logger.warn(new ParameterizedMessage(\n          \n          \n            \n                                    \"Encrypted snapshots are not allowed for the currently installed license [{}].\"\n          \n          \n            \n                                        + \" Snapshots to the [{}] encrypted repository are not permitted.\"\n          \n          \n            \n                                        + \" All the other operations, including restore, work without restrictions.\",\n          \n          \n            \n                                        getLicenseState().getOperationMode().description(), metadata.name()),\n          \n          \n            \n                                    LicenseUtils.newComplianceException(\"encrypted snapshots\")", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r416337768", "createdAt": "2020-04-28T05:31:05Z", "author": {"login": "tvernum"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepositoryPlugin.java", "diffHunk": "@@ -6,25 +6,153 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.cluster.metadata.RepositoryMetadata;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.settings.SecureSetting;\n+import org.elasticsearch.common.settings.SecureString;\n import org.elasticsearch.common.settings.Setting;\n-import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.env.Environment;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n import org.elasticsearch.plugins.Plugin;\n-import org.elasticsearch.plugins.ReloadablePlugin;\n import org.elasticsearch.plugins.RepositoryPlugin;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.xpack.core.XPackPlugin;\n \n+import java.security.GeneralSecurityException;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n \n-public final class EncryptedRepositoryPlugin extends Plugin implements RepositoryPlugin, ReloadablePlugin {\n+public class EncryptedRepositoryPlugin extends Plugin implements RepositoryPlugin {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepositoryPlugin.class);\n+    static final String REPOSITORY_TYPE_NAME = \"encrypted\";\n+    // TODO add at least hdfs, and investigate supporting all `BlobStoreRepository` implementations\n+    static final List<String> SUPPORTED_ENCRYPTED_TYPE_NAMES = Arrays.asList(\"fs\", \"gcs\", \"azure\", \"s3\");\n+    static final Setting.AffixSetting<SecureString> ENCRYPTION_PASSWORD_SETTING = Setting.affixKeySetting(\n+        \"repository.encrypted.\",\n+        \"password\",\n+        key -> SecureSetting.secureString(key, null)\n+    );\n+    static final Setting<String> DELEGATE_TYPE_SETTING = Setting.simpleString(\"delegate_type\", \"\");\n+    static final Setting<String> PASSWORD_NAME_SETTING = Setting.simpleString(\"password_name\", \"\");\n \n-    public EncryptedRepositoryPlugin(final Settings settings) {}\n+    // \"protected\" because it is overloaded for tests\n+    protected XPackLicenseState getLicenseState() {\n+        return XPackPlugin.getSharedLicenseState();\n+    }\n+\n+    public EncryptedRepositoryPlugin() {\n+        if (false == getLicenseState().isEncryptedSnapshotAllowed()) {\n+            logger.warn(\n+                \"Snapshotting to an encrypted repository is not permitted for the current license.\"\n+                    + \"All the other operations over the encrypted repository, eg. restore, work without restrictions.\",\n+                LicenseUtils.newComplianceException(\"encrypted snapshots\")\n+            );\n+        }\n+    }\n \n     @Override\n     public List<Setting<?>> getSettings() {\n-        return List.of();\n+        return List.of(ENCRYPTION_PASSWORD_SETTING);\n     }\n \n     @Override\n-    public void reload(Settings settings) {\n-        // Secure settings should be readable inside this method.\n+    public Map<String, Repository.Factory> getRepositories(Environment env, NamedXContentRegistry registry, ClusterService clusterService) {\n+        // load all the passwords from the keystore in memory because the keystore is not readable when the repository is created\n+        final Map<String, char[]> repositoryPasswordsMapBuilder = new HashMap<>();\n+        for (String passwordName : ENCRYPTION_PASSWORD_SETTING.getNamespaces(env.settings())) {\n+            Setting<SecureString> passwordSetting = ENCRYPTION_PASSWORD_SETTING.getConcreteSettingForNamespace(passwordName);\n+            SecureString encryptionPassword = passwordSetting.get(env.settings());\n+            repositoryPasswordsMapBuilder.put(passwordName, encryptionPassword.getChars());\n+            logger.debug(\"Loaded repository password [{}] from the node keystore\", passwordName);\n+        }\n+        final Map<String, char[]> repositoryPasswordsMap = Map.copyOf(repositoryPasswordsMapBuilder);\n+\n+        return Collections.singletonMap(REPOSITORY_TYPE_NAME, new Repository.Factory() {\n+\n+            @Override\n+            public Repository create(RepositoryMetadata metadata) {\n+                throw new UnsupportedOperationException();\n+            }\n+\n+            @Override\n+            public Repository create(RepositoryMetadata metadata, Function<String, Repository.Factory> typeLookup) throws Exception {\n+                final String delegateType = DELEGATE_TYPE_SETTING.get(metadata.settings());\n+                if (Strings.hasLength(delegateType) == false) {\n+                    throw new IllegalArgumentException(\"Repository setting [\" + DELEGATE_TYPE_SETTING.getKey() + \"] must be set\");\n+                }\n+                if (REPOSITORY_TYPE_NAME.equals(delegateType)) {\n+                    throw new IllegalArgumentException(\n+                        \"Cannot encrypt an already encrypted repository. [\"\n+                            + DELEGATE_TYPE_SETTING.getKey()\n+                            + \"] must not be equal to [\"\n+                            + REPOSITORY_TYPE_NAME\n+                            + \"]\"\n+                    );\n+                }\n+                final Repository.Factory factory = typeLookup.apply(delegateType);\n+                if (null == factory || false == SUPPORTED_ENCRYPTED_TYPE_NAMES.contains(delegateType)) {\n+                    throw new IllegalArgumentException(\"Unsupported delegate repository type [\" + DELEGATE_TYPE_SETTING.getKey() + \"]\");\n+                }\n+                final String repositoryPasswordName = PASSWORD_NAME_SETTING.get(metadata.settings());\n+                if (Strings.hasLength(repositoryPasswordName) == false) {\n+                    throw new IllegalArgumentException(\"Repository setting [\" + PASSWORD_NAME_SETTING.getKey() + \"] must be set\");\n+                }\n+                final char[] repositoryPassword = repositoryPasswordsMap.get(repositoryPasswordName);\n+                if (repositoryPassword == null) {\n+                    throw new IllegalArgumentException(\n+                        \"Secure setting [\"\n+                            + ENCRYPTION_PASSWORD_SETTING.getConcreteSettingForNamespace(repositoryPasswordName).getKey()\n+                            + \"] must be set\"\n+                    );\n+                }\n+                final Repository delegatedRepository = factory.create(\n+                    new RepositoryMetadata(metadata.name(), delegateType, metadata.settings())\n+                );\n+                if (false == (delegatedRepository instanceof BlobStoreRepository) || delegatedRepository instanceof EncryptedRepository) {\n+                    throw new IllegalArgumentException(\"Unsupported delegate repository type [\" + DELEGATE_TYPE_SETTING.getKey() + \"]\");\n+                }\n+                if (false == getLicenseState().isEncryptedSnapshotAllowed()) {\n+                    logger.warn(\n+                        \"Encrypted snapshots are not allowed for the currently installed license.\"\n+                            + \"Snapshots to the [\"\n+                            + metadata.name()\n+                            + \"] encrypted repository are not permitted.\"\n+                            + \"All the other operations, including restore, work without restrictions.\",\n+                        LicenseUtils.newComplianceException(\"encrypted snapshots\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fc4e98a30826dde5ae1b6abf50bc238aa485b481"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjMzOTI4NQ==", "bodyText": "If this is for tests only, why is it referenced in the class javadoc? I'm a little confused about how this class ought to be used.", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r416339285", "createdAt": "2020-04-28T05:35:26Z", "author": {"login": "tvernum"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/SingleUseKey.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.repositories.encrypted;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+\n+import javax.crypto.SecretKey;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+/**\n+ * Container class for a {@code SecretKey} with a unique identifier, and a 4-byte wide {@code Integer} nonce, that can be used for a\n+ * single encryption operation. Use {@link #createSingleUseKeySupplier(CheckedSupplier)} to obtain a {@code Supplier} that returns\n+ * a new {@link SingleUseKey} instance on every invocation. The number of unique {@code SecretKey}s (and their associated identifiers)\n+ * generated is minimized and, at the same time, ensuring that a given {@code nonce} is not reused with the same key.\n+ */\n+final class SingleUseKey {\n+    private static final Logger logger = LogManager.getLogger(SingleUseKey.class);\n+    static final int MIN_NONCE = Integer.MIN_VALUE;\n+    static final int MAX_NONCE = Integer.MAX_VALUE;\n+    private static final int MAX_ATTEMPTS = 9;\n+    private static final SingleUseKey EXPIRED_KEY = new SingleUseKey(null, null, MAX_NONCE);\n+\n+    private final BytesReference keyId;\n+    private final SecretKey key;\n+    private final int nonce;\n+\n+    // for tests use only!\n+    SingleUseKey(BytesReference KeyId, SecretKey Key, int nonce) {\n+        this.keyId = KeyId;\n+        this.key = Key;\n+        this.nonce = nonce;\n+    }\n+\n+    public BytesReference getKeyId() {\n+        return keyId;\n+    }\n+\n+    public SecretKey getKey() {\n+        return key;\n+    }\n+\n+    public int getNonce() {\n+        return nonce;\n+    }\n+\n+    /**\n+     * Returns a {@code Supplier} of {@code SingleUseKey}s so that no two instances contain the same key and nonce pair.\n+     * A new key is generated only when the {@code nonce} space has been exhausted.\n+     */\n+    static <T extends Exception> CheckedSupplier<SingleUseKey, T> createSingleUseKeySupplier(\n+        CheckedSupplier<Tuple<BytesReference, SecretKey>, T> keyGenerator\n+    ) {\n+        final AtomicReference<SingleUseKey> keyCurrentlyInUse = new AtomicReference<>(EXPIRED_KEY);\n+        return createSingleUseKeySupplier(keyGenerator, keyCurrentlyInUse);\n+    }\n+\n+    // for tests use only", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fc4e98a30826dde5ae1b6abf50bc238aa485b481"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjMzOTkxNA==", "bodyText": "This feels like overuse of a Tuple, at the very least can we have a javadoc explaining what the elements mean?", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r416339914", "createdAt": "2020-04-28T05:37:08Z", "author": {"login": "tvernum"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/SingleUseKey.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.repositories.encrypted;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+\n+import javax.crypto.SecretKey;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+/**\n+ * Container class for a {@code SecretKey} with a unique identifier, and a 4-byte wide {@code Integer} nonce, that can be used for a\n+ * single encryption operation. Use {@link #createSingleUseKeySupplier(CheckedSupplier)} to obtain a {@code Supplier} that returns\n+ * a new {@link SingleUseKey} instance on every invocation. The number of unique {@code SecretKey}s (and their associated identifiers)\n+ * generated is minimized and, at the same time, ensuring that a given {@code nonce} is not reused with the same key.\n+ */\n+final class SingleUseKey {\n+    private static final Logger logger = LogManager.getLogger(SingleUseKey.class);\n+    static final int MIN_NONCE = Integer.MIN_VALUE;\n+    static final int MAX_NONCE = Integer.MAX_VALUE;\n+    private static final int MAX_ATTEMPTS = 9;\n+    private static final SingleUseKey EXPIRED_KEY = new SingleUseKey(null, null, MAX_NONCE);\n+\n+    private final BytesReference keyId;\n+    private final SecretKey key;\n+    private final int nonce;\n+\n+    // for tests use only!\n+    SingleUseKey(BytesReference KeyId, SecretKey Key, int nonce) {\n+        this.keyId = KeyId;\n+        this.key = Key;\n+        this.nonce = nonce;\n+    }\n+\n+    public BytesReference getKeyId() {\n+        return keyId;\n+    }\n+\n+    public SecretKey getKey() {\n+        return key;\n+    }\n+\n+    public int getNonce() {\n+        return nonce;\n+    }\n+\n+    /**\n+     * Returns a {@code Supplier} of {@code SingleUseKey}s so that no two instances contain the same key and nonce pair.\n+     * A new key is generated only when the {@code nonce} space has been exhausted.\n+     */\n+    static <T extends Exception> CheckedSupplier<SingleUseKey, T> createSingleUseKeySupplier(\n+        CheckedSupplier<Tuple<BytesReference, SecretKey>, T> keyGenerator\n+    ) {\n+        final AtomicReference<SingleUseKey> keyCurrentlyInUse = new AtomicReference<>(EXPIRED_KEY);\n+        return createSingleUseKeySupplier(keyGenerator, keyCurrentlyInUse);\n+    }\n+\n+    // for tests use only\n+    static <T extends Exception> CheckedSupplier<SingleUseKey, T> createSingleUseKeySupplier(\n+        CheckedSupplier<Tuple<BytesReference, SecretKey>, T> keyGenerator,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fc4e98a30826dde5ae1b6abf50bc238aa485b481"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjM0MTUzMg==", "bodyText": "This feels like a complicated way to produce a Supplier of a set of keys with a sequential nonce.\nDoes it really need the complexity of AtomicReference over a synchronized method?\nIt feels like the general concept could be written quite simply with a class that extends Supplier, has an internal counter and is synchronized on get (or uses an AtomicInteger for the counter).\nI presume there is a reason why you took this approach instead, but the code doesn't tell me why that is.", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r416341532", "createdAt": "2020-04-28T05:41:46Z", "author": {"login": "tvernum"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/SingleUseKey.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.repositories.encrypted;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.collect.Tuple;\n+\n+import javax.crypto.SecretKey;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+/**\n+ * Container class for a {@code SecretKey} with a unique identifier, and a 4-byte wide {@code Integer} nonce, that can be used for a\n+ * single encryption operation. Use {@link #createSingleUseKeySupplier(CheckedSupplier)} to obtain a {@code Supplier} that returns\n+ * a new {@link SingleUseKey} instance on every invocation. The number of unique {@code SecretKey}s (and their associated identifiers)\n+ * generated is minimized and, at the same time, ensuring that a given {@code nonce} is not reused with the same key.\n+ */\n+final class SingleUseKey {\n+    private static final Logger logger = LogManager.getLogger(SingleUseKey.class);\n+    static final int MIN_NONCE = Integer.MIN_VALUE;\n+    static final int MAX_NONCE = Integer.MAX_VALUE;\n+    private static final int MAX_ATTEMPTS = 9;\n+    private static final SingleUseKey EXPIRED_KEY = new SingleUseKey(null, null, MAX_NONCE);\n+\n+    private final BytesReference keyId;\n+    private final SecretKey key;\n+    private final int nonce;\n+\n+    // for tests use only!\n+    SingleUseKey(BytesReference KeyId, SecretKey Key, int nonce) {\n+        this.keyId = KeyId;\n+        this.key = Key;\n+        this.nonce = nonce;\n+    }\n+\n+    public BytesReference getKeyId() {\n+        return keyId;\n+    }\n+\n+    public SecretKey getKey() {\n+        return key;\n+    }\n+\n+    public int getNonce() {\n+        return nonce;\n+    }\n+\n+    /**\n+     * Returns a {@code Supplier} of {@code SingleUseKey}s so that no two instances contain the same key and nonce pair.\n+     * A new key is generated only when the {@code nonce} space has been exhausted.\n+     */\n+    static <T extends Exception> CheckedSupplier<SingleUseKey, T> createSingleUseKeySupplier(\n+        CheckedSupplier<Tuple<BytesReference, SecretKey>, T> keyGenerator\n+    ) {\n+        final AtomicReference<SingleUseKey> keyCurrentlyInUse = new AtomicReference<>(EXPIRED_KEY);\n+        return createSingleUseKeySupplier(keyGenerator, keyCurrentlyInUse);\n+    }\n+\n+    // for tests use only\n+    static <T extends Exception> CheckedSupplier<SingleUseKey, T> createSingleUseKeySupplier(\n+        CheckedSupplier<Tuple<BytesReference, SecretKey>, T> keyGenerator,\n+        AtomicReference<SingleUseKey> keyCurrentlyInUse\n+    ) {\n+        final Object lock = new Object();\n+        return () -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fc4e98a30826dde5ae1b6abf50bc238aa485b481"}, "originalPosition": 72}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIwNjQ0OTE4", "url": "https://github.com/elastic/elasticsearch/pull/53352#pullrequestreview-420644918", "createdAt": "2020-05-29T04:29:33Z", "commit": {"oid": "6eac6bfd83a87e37cf5f0f1e83dca50156a1bf31"}, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQwNDoyOTozNFrOGcOa5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQwNTo1Njo0NlrOGcPstQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI0OTU3Mw==", "bodyText": "A few questions.\n\n\nGiven that KEY_ID_PLAINTEXT is not really a key, just a magic string of bytes, AESWrap seems like an odd choice. Is that purely because it is deterministic, or is there some other reason why we'd use AESWrap for generate a key-id?\n\n\nYour statement that\n\nthe ciphertext reveals no information on the key\n\nseems overly confident. This is a known-plaintext scenario, so it seems like there is at least the risk of revealing information about the key. What's the basis for your analysis that this is safe?\n\n\nWhy is this done with purely with encryption, and not hashing? At first glance (based purely on the need to generate an id for a secret key without revealing information about the key) that a hash (or HMAC) is more appropriate here.", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r432249573", "createdAt": "2020-05-29T04:29:34Z", "author": {"login": "tvernum"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/AESKeyUtils.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.repositories.encrypted;\n+\n+import org.elasticsearch.common.settings.SecureString;\n+\n+import javax.crypto.Cipher;\n+import javax.crypto.SecretKey;\n+import javax.crypto.SecretKeyFactory;\n+import javax.crypto.spec.PBEKeySpec;\n+import javax.crypto.spec.SecretKeySpec;\n+import java.nio.charset.StandardCharsets;\n+import java.security.GeneralSecurityException;\n+import java.security.Key;\n+import java.util.Base64;\n+\n+public final class AESKeyUtils {\n+    public static final int KEY_LENGTH_IN_BYTES = 32; // 256-bit AES key\n+    public static final int WRAPPED_KEY_LENGTH_IN_BYTES = KEY_LENGTH_IN_BYTES + 8; // https://www.ietf.org/rfc/rfc3394.txt section 2.2\n+    // parameter for the KDF function, it's a funny and unusual iter count larger than 60k\n+    private static final int KDF_ITER = 61616;\n+    // the KDF algorithm that generate the symmetric key given the password\n+    private static final String KDF_ALGO = \"PBKDF2WithHmacSHA512\";\n+    // The Id of any AES SecretKey is the AES-Wrap-ciphertext of this fixed 32 byte wide array.\n+    // Key wrapping encryption is deterministic (same plaintext generates the same ciphertext)\n+    // and the probability that two different keys map the same plaintext to the same ciphertext is very small\n+    // (2^-256, much lower than the UUID collision of 2^-128), assuming AES is indistinguishable from a pseudorandom permutation.\n+    private static final byte[] KEY_ID_PLAINTEXT = \"wrapping known text forms key id\".getBytes(StandardCharsets.UTF_8);\n+\n+    public static byte[] wrap(SecretKey wrappingKey, SecretKey keyToWrap) throws GeneralSecurityException {\n+        assert \"AES\".equals(wrappingKey.getAlgorithm());\n+        assert \"AES\".equals(keyToWrap.getAlgorithm());\n+        Cipher c = Cipher.getInstance(\"AESWrap\");\n+        c.init(Cipher.WRAP_MODE, wrappingKey);\n+        return c.wrap(keyToWrap);\n+    }\n+\n+    public static SecretKey unwrap(SecretKey wrappingKey, byte[] keyToUnwrap) throws GeneralSecurityException {\n+        assert \"AES\".equals(wrappingKey.getAlgorithm());\n+        assert keyToUnwrap.length == WRAPPED_KEY_LENGTH_IN_BYTES;\n+        Cipher c = Cipher.getInstance(\"AESWrap\");\n+        c.init(Cipher.UNWRAP_MODE, wrappingKey);\n+        Key unwrappedKey = c.unwrap(keyToUnwrap, \"AES\", Cipher.SECRET_KEY);\n+        return new SecretKeySpec(unwrappedKey.getEncoded(), \"AES\"); // make sure unwrapped key is \"AES\"\n+    }\n+\n+    /**\n+     * Computes the ID of the given AES {@code SecretKey}.\n+     * The ID can be published as it does not leak any information about the key.\n+     * Different {@code SecretKey}s have different IDs with a very high probability.\n+     * <p>\n+     * The ID is the ciphertext of a known plaintext, using the AES Wrap cipher algorithm.\n+     * AES Wrap algorithm is deterministic, i.e. encryption using the same key, of the same plaintext, generates the same ciphertext.\n+     * Moreover, the ciphertext reveals no information on the key, and the probability of collision of ciphertexts given different\n+     * keys is statistically negligible.\n+     */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eac6bfd83a87e37cf5f0f1e83dca50156a1bf31"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI1MTk5Nw==", "bodyText": "Assuming I understand this correctly, I think it would be helpful to add a why here:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                // master node that finalizes the snapshot (could be a different master node, if a master failover occurred during the snapshot)\n          \n          \n            \n                // master node that finalizes the snapshot (could be a different master node, if a master failover occurred during the snapshot)\n          \n          \n            \n                // This ensures that all nodes that participate in the snapshot agree on the value of the master encryption key, so that\n          \n          \n            \n                // every shard that is included in the snapshot is encrypted with a consistent key.\n          \n      \n    \n    \n  \n\nOr maybe just a link to #validateLocalRepositorySecret...", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r432251997", "createdAt": "2020-05-29T04:41:06Z", "author": {"login": "tvernum"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepository.java", "diffHunk": "@@ -6,11 +6,682 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n-public class EncryptedRepository {\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.lucene.index.IndexCommit;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.metadata.RepositoryMetadata;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.CheckedFunction;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.blobstore.BlobContainer;\n+import org.elasticsearch.common.blobstore.BlobMetadata;\n+import org.elasticsearch.common.blobstore.BlobPath;\n+import org.elasticsearch.common.blobstore.BlobStore;\n+import org.elasticsearch.common.blobstore.DeleteResult;\n+import org.elasticsearch.common.blobstore.support.AbstractBlobContainer;\n+import org.elasticsearch.common.bytes.BytesArray;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.cache.Cache;\n+import org.elasticsearch.common.cache.CacheBuilder;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.io.Streams;\n+import org.elasticsearch.common.settings.SecureString;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.index.store.Store;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoryData;\n+import org.elasticsearch.repositories.RepositoryException;\n+import org.elasticsearch.repositories.RepositoryStats;\n+import org.elasticsearch.repositories.ShardGenerations;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.SnapshotInfo;\n+import org.elasticsearch.snapshots.SnapshotShardFailure;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.SecretKey;\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.NoSuchFileException;\n+import java.security.GeneralSecurityException;\n+import java.security.SecureRandom;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+public class EncryptedRepository extends BlobStoreRepository {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepository.class);\n+    // the following constants are fixed by definition\n     static final int GCM_TAG_LENGTH_IN_BYTES = 16;\n     static final int GCM_IV_LENGTH_IN_BYTES = 12;\n-    static final int AES_BLOCK_SIZE_IN_BYTES = 128;\n+    static final int AES_BLOCK_LENGTH_IN_BYTES = 128;\n+    // the following constants require careful thought before changing because they will break backwards compatibility\n     static final String DATA_ENCRYPTION_SCHEME = \"AES/GCM/NoPadding\";\n     static final long PACKET_START_COUNTER = Long.MIN_VALUE;\n-    static final int MAX_PACKET_LENGTH_IN_BYTES = 1 << 30;\n+    static final int MAX_PACKET_LENGTH_IN_BYTES = 8 << 20; // 8MB\n+    // this should be smaller than {@code #MAX_PACKET_LENGTH_IN_BYTES} and it's what {@code EncryptionPacketsInputStream} uses\n+    // during encryption and what {@code DecryptionPacketsInputStream} expects during decryption (it is not configurable)\n+    static final int PACKET_LENGTH_IN_BYTES = 64 * (1 << 10); // 64KB\n+    // the path of the blob container holding all the DEKs\n+    // this is relative to the root base path holding the encrypted blobs (i.e. the repository root base path)\n+    static final String DEK_ROOT_CONTAINER = \".encryption-metadata\"; // package private for tests\n+    static final int DEK_ID_LENGTH = 22; // {@code org.elasticsearch.common.UUIDS} length\n+\n+    // the following constants can be changed freely\n+    private static final String RAND_ALGO = \"SHA1PRNG\";\n+    // each snapshot metadata contains an unforgeable identifier of the repository password of the master node that started the snapshot\n+    // this hash is then verified on each data node before the actual shard files snapshot, as well as on the\n+    // master node that finalizes the snapshot (could be a different master node, if a master failover occurred during the snapshot)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eac6bfd83a87e37cf5f0f1e83dca50156a1bf31"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI1MjEwMA==", "bodyText": "The use of identifier and hash here confuse me. Are they the same thing?\nI think they are, and some of the confusion comes from the fact (covered above) that we generate an \"id\" from the key's content, which is intended to work a bit like a hash, but isn't actually a hash.", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r432252100", "createdAt": "2020-05-29T04:41:33Z", "author": {"login": "tvernum"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepository.java", "diffHunk": "@@ -6,11 +6,682 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n-public class EncryptedRepository {\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.lucene.index.IndexCommit;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.metadata.RepositoryMetadata;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.CheckedFunction;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.blobstore.BlobContainer;\n+import org.elasticsearch.common.blobstore.BlobMetadata;\n+import org.elasticsearch.common.blobstore.BlobPath;\n+import org.elasticsearch.common.blobstore.BlobStore;\n+import org.elasticsearch.common.blobstore.DeleteResult;\n+import org.elasticsearch.common.blobstore.support.AbstractBlobContainer;\n+import org.elasticsearch.common.bytes.BytesArray;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.cache.Cache;\n+import org.elasticsearch.common.cache.CacheBuilder;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.io.Streams;\n+import org.elasticsearch.common.settings.SecureString;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.index.store.Store;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoryData;\n+import org.elasticsearch.repositories.RepositoryException;\n+import org.elasticsearch.repositories.RepositoryStats;\n+import org.elasticsearch.repositories.ShardGenerations;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.SnapshotInfo;\n+import org.elasticsearch.snapshots.SnapshotShardFailure;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.SecretKey;\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.NoSuchFileException;\n+import java.security.GeneralSecurityException;\n+import java.security.SecureRandom;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+public class EncryptedRepository extends BlobStoreRepository {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepository.class);\n+    // the following constants are fixed by definition\n     static final int GCM_TAG_LENGTH_IN_BYTES = 16;\n     static final int GCM_IV_LENGTH_IN_BYTES = 12;\n-    static final int AES_BLOCK_SIZE_IN_BYTES = 128;\n+    static final int AES_BLOCK_LENGTH_IN_BYTES = 128;\n+    // the following constants require careful thought before changing because they will break backwards compatibility\n     static final String DATA_ENCRYPTION_SCHEME = \"AES/GCM/NoPadding\";\n     static final long PACKET_START_COUNTER = Long.MIN_VALUE;\n-    static final int MAX_PACKET_LENGTH_IN_BYTES = 1 << 30;\n+    static final int MAX_PACKET_LENGTH_IN_BYTES = 8 << 20; // 8MB\n+    // this should be smaller than {@code #MAX_PACKET_LENGTH_IN_BYTES} and it's what {@code EncryptionPacketsInputStream} uses\n+    // during encryption and what {@code DecryptionPacketsInputStream} expects during decryption (it is not configurable)\n+    static final int PACKET_LENGTH_IN_BYTES = 64 * (1 << 10); // 64KB\n+    // the path of the blob container holding all the DEKs\n+    // this is relative to the root base path holding the encrypted blobs (i.e. the repository root base path)\n+    static final String DEK_ROOT_CONTAINER = \".encryption-metadata\"; // package private for tests\n+    static final int DEK_ID_LENGTH = 22; // {@code org.elasticsearch.common.UUIDS} length\n+\n+    // the following constants can be changed freely\n+    private static final String RAND_ALGO = \"SHA1PRNG\";\n+    // each snapshot metadata contains an unforgeable identifier of the repository password of the master node that started the snapshot\n+    // this hash is then verified on each data node before the actual shard files snapshot, as well as on the", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eac6bfd83a87e37cf5f0f1e83dca50156a1bf31"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI1OTk5OA==", "bodyText": "Personal preference\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private final Supplier<Tuple<BytesReference, SecretKey>> DEKGenerator;\n          \n          \n            \n                private final Supplier<Tuple<BytesReference, SecretKey>> dekGenerator;", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r432259998", "createdAt": "2020-05-29T05:17:20Z", "author": {"login": "tvernum"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepository.java", "diffHunk": "@@ -6,11 +6,682 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n-public class EncryptedRepository {\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.lucene.index.IndexCommit;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.metadata.RepositoryMetadata;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.CheckedFunction;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.blobstore.BlobContainer;\n+import org.elasticsearch.common.blobstore.BlobMetadata;\n+import org.elasticsearch.common.blobstore.BlobPath;\n+import org.elasticsearch.common.blobstore.BlobStore;\n+import org.elasticsearch.common.blobstore.DeleteResult;\n+import org.elasticsearch.common.blobstore.support.AbstractBlobContainer;\n+import org.elasticsearch.common.bytes.BytesArray;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.cache.Cache;\n+import org.elasticsearch.common.cache.CacheBuilder;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.io.Streams;\n+import org.elasticsearch.common.settings.SecureString;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.index.store.Store;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoryData;\n+import org.elasticsearch.repositories.RepositoryException;\n+import org.elasticsearch.repositories.RepositoryStats;\n+import org.elasticsearch.repositories.ShardGenerations;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.SnapshotInfo;\n+import org.elasticsearch.snapshots.SnapshotShardFailure;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.SecretKey;\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.NoSuchFileException;\n+import java.security.GeneralSecurityException;\n+import java.security.SecureRandom;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+public class EncryptedRepository extends BlobStoreRepository {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepository.class);\n+    // the following constants are fixed by definition\n     static final int GCM_TAG_LENGTH_IN_BYTES = 16;\n     static final int GCM_IV_LENGTH_IN_BYTES = 12;\n-    static final int AES_BLOCK_SIZE_IN_BYTES = 128;\n+    static final int AES_BLOCK_LENGTH_IN_BYTES = 128;\n+    // the following constants require careful thought before changing because they will break backwards compatibility\n     static final String DATA_ENCRYPTION_SCHEME = \"AES/GCM/NoPadding\";\n     static final long PACKET_START_COUNTER = Long.MIN_VALUE;\n-    static final int MAX_PACKET_LENGTH_IN_BYTES = 1 << 30;\n+    static final int MAX_PACKET_LENGTH_IN_BYTES = 8 << 20; // 8MB\n+    // this should be smaller than {@code #MAX_PACKET_LENGTH_IN_BYTES} and it's what {@code EncryptionPacketsInputStream} uses\n+    // during encryption and what {@code DecryptionPacketsInputStream} expects during decryption (it is not configurable)\n+    static final int PACKET_LENGTH_IN_BYTES = 64 * (1 << 10); // 64KB\n+    // the path of the blob container holding all the DEKs\n+    // this is relative to the root base path holding the encrypted blobs (i.e. the repository root base path)\n+    static final String DEK_ROOT_CONTAINER = \".encryption-metadata\"; // package private for tests\n+    static final int DEK_ID_LENGTH = 22; // {@code org.elasticsearch.common.UUIDS} length\n+\n+    // the following constants can be changed freely\n+    private static final String RAND_ALGO = \"SHA1PRNG\";\n+    // each snapshot metadata contains an unforgeable identifier of the repository password of the master node that started the snapshot\n+    // this hash is then verified on each data node before the actual shard files snapshot, as well as on the\n+    // master node that finalizes the snapshot (could be a different master node, if a master failover occurred during the snapshot)\n+    static final String PASSWORD_ID_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordId\";\n+    static final String PASSWORD_ID_SALT_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordIdSalt\";\n+    private static final int DEK_CACHE_WEIGHT = 2048;\n+\n+    // this is the repository instance to which all blob reads and writes are forwarded to (it stores both the encrypted blobs, as well\n+    // as the associated encrypted DEKs)\n+    private final BlobStoreRepository delegatedRepository;\n+    // every data blob is encrypted with its randomly generated AES key (DEK)\n+    private final Supplier<Tuple<BytesReference, SecretKey>> DEKGenerator;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eac6bfd83a87e37cf5f0f1e83dca50156a1bf31"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI2MDA2MQ==", "bodyText": "My preference:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private final Cache<String, SecretKey> DEKCache;\n          \n          \n            \n                private final Cache<String, SecretKey> dekCache;", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r432260061", "createdAt": "2020-05-29T05:17:35Z", "author": {"login": "tvernum"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepository.java", "diffHunk": "@@ -6,11 +6,682 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n-public class EncryptedRepository {\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.lucene.index.IndexCommit;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.metadata.RepositoryMetadata;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.CheckedFunction;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.blobstore.BlobContainer;\n+import org.elasticsearch.common.blobstore.BlobMetadata;\n+import org.elasticsearch.common.blobstore.BlobPath;\n+import org.elasticsearch.common.blobstore.BlobStore;\n+import org.elasticsearch.common.blobstore.DeleteResult;\n+import org.elasticsearch.common.blobstore.support.AbstractBlobContainer;\n+import org.elasticsearch.common.bytes.BytesArray;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.cache.Cache;\n+import org.elasticsearch.common.cache.CacheBuilder;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.io.Streams;\n+import org.elasticsearch.common.settings.SecureString;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.index.store.Store;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoryData;\n+import org.elasticsearch.repositories.RepositoryException;\n+import org.elasticsearch.repositories.RepositoryStats;\n+import org.elasticsearch.repositories.ShardGenerations;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.SnapshotInfo;\n+import org.elasticsearch.snapshots.SnapshotShardFailure;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.SecretKey;\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.NoSuchFileException;\n+import java.security.GeneralSecurityException;\n+import java.security.SecureRandom;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+public class EncryptedRepository extends BlobStoreRepository {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepository.class);\n+    // the following constants are fixed by definition\n     static final int GCM_TAG_LENGTH_IN_BYTES = 16;\n     static final int GCM_IV_LENGTH_IN_BYTES = 12;\n-    static final int AES_BLOCK_SIZE_IN_BYTES = 128;\n+    static final int AES_BLOCK_LENGTH_IN_BYTES = 128;\n+    // the following constants require careful thought before changing because they will break backwards compatibility\n     static final String DATA_ENCRYPTION_SCHEME = \"AES/GCM/NoPadding\";\n     static final long PACKET_START_COUNTER = Long.MIN_VALUE;\n-    static final int MAX_PACKET_LENGTH_IN_BYTES = 1 << 30;\n+    static final int MAX_PACKET_LENGTH_IN_BYTES = 8 << 20; // 8MB\n+    // this should be smaller than {@code #MAX_PACKET_LENGTH_IN_BYTES} and it's what {@code EncryptionPacketsInputStream} uses\n+    // during encryption and what {@code DecryptionPacketsInputStream} expects during decryption (it is not configurable)\n+    static final int PACKET_LENGTH_IN_BYTES = 64 * (1 << 10); // 64KB\n+    // the path of the blob container holding all the DEKs\n+    // this is relative to the root base path holding the encrypted blobs (i.e. the repository root base path)\n+    static final String DEK_ROOT_CONTAINER = \".encryption-metadata\"; // package private for tests\n+    static final int DEK_ID_LENGTH = 22; // {@code org.elasticsearch.common.UUIDS} length\n+\n+    // the following constants can be changed freely\n+    private static final String RAND_ALGO = \"SHA1PRNG\";\n+    // each snapshot metadata contains an unforgeable identifier of the repository password of the master node that started the snapshot\n+    // this hash is then verified on each data node before the actual shard files snapshot, as well as on the\n+    // master node that finalizes the snapshot (could be a different master node, if a master failover occurred during the snapshot)\n+    static final String PASSWORD_ID_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordId\";\n+    static final String PASSWORD_ID_SALT_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordIdSalt\";\n+    private static final int DEK_CACHE_WEIGHT = 2048;\n+\n+    // this is the repository instance to which all blob reads and writes are forwarded to (it stores both the encrypted blobs, as well\n+    // as the associated encrypted DEKs)\n+    private final BlobStoreRepository delegatedRepository;\n+    // every data blob is encrypted with its randomly generated AES key (DEK)\n+    private final Supplier<Tuple<BytesReference, SecretKey>> DEKGenerator;\n+    // license is checked before every snapshot operations; protected non-final for tests\n+    protected Supplier<XPackLicenseState> licenseStateSupplier;\n+    private final SecureString repositoryPassword;\n+    private final String localRepositoryPasswordId;\n+    private final String localRepositoryPasswordIdSalt;\n+    private volatile String validatedRepositoryPasswordId;\n+    private final Cache<String, SecretKey> DEKCache;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eac6bfd83a87e37cf5f0f1e83dca50156a1bf31"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI2MTAzMQ==", "bodyText": "I wonder whether there's any value, at some future point, in adding encryption stats.\nI'm not familiar enough with repo stats to know, but it feels like it's worth considering.", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r432261031", "createdAt": "2020-05-29T05:21:31Z", "author": {"login": "tvernum"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepository.java", "diffHunk": "@@ -6,11 +6,682 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n-public class EncryptedRepository {\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.lucene.index.IndexCommit;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.metadata.RepositoryMetadata;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.CheckedFunction;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.blobstore.BlobContainer;\n+import org.elasticsearch.common.blobstore.BlobMetadata;\n+import org.elasticsearch.common.blobstore.BlobPath;\n+import org.elasticsearch.common.blobstore.BlobStore;\n+import org.elasticsearch.common.blobstore.DeleteResult;\n+import org.elasticsearch.common.blobstore.support.AbstractBlobContainer;\n+import org.elasticsearch.common.bytes.BytesArray;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.cache.Cache;\n+import org.elasticsearch.common.cache.CacheBuilder;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.io.Streams;\n+import org.elasticsearch.common.settings.SecureString;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.index.store.Store;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoryData;\n+import org.elasticsearch.repositories.RepositoryException;\n+import org.elasticsearch.repositories.RepositoryStats;\n+import org.elasticsearch.repositories.ShardGenerations;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.SnapshotInfo;\n+import org.elasticsearch.snapshots.SnapshotShardFailure;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.SecretKey;\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.NoSuchFileException;\n+import java.security.GeneralSecurityException;\n+import java.security.SecureRandom;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+public class EncryptedRepository extends BlobStoreRepository {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepository.class);\n+    // the following constants are fixed by definition\n     static final int GCM_TAG_LENGTH_IN_BYTES = 16;\n     static final int GCM_IV_LENGTH_IN_BYTES = 12;\n-    static final int AES_BLOCK_SIZE_IN_BYTES = 128;\n+    static final int AES_BLOCK_LENGTH_IN_BYTES = 128;\n+    // the following constants require careful thought before changing because they will break backwards compatibility\n     static final String DATA_ENCRYPTION_SCHEME = \"AES/GCM/NoPadding\";\n     static final long PACKET_START_COUNTER = Long.MIN_VALUE;\n-    static final int MAX_PACKET_LENGTH_IN_BYTES = 1 << 30;\n+    static final int MAX_PACKET_LENGTH_IN_BYTES = 8 << 20; // 8MB\n+    // this should be smaller than {@code #MAX_PACKET_LENGTH_IN_BYTES} and it's what {@code EncryptionPacketsInputStream} uses\n+    // during encryption and what {@code DecryptionPacketsInputStream} expects during decryption (it is not configurable)\n+    static final int PACKET_LENGTH_IN_BYTES = 64 * (1 << 10); // 64KB\n+    // the path of the blob container holding all the DEKs\n+    // this is relative to the root base path holding the encrypted blobs (i.e. the repository root base path)\n+    static final String DEK_ROOT_CONTAINER = \".encryption-metadata\"; // package private for tests\n+    static final int DEK_ID_LENGTH = 22; // {@code org.elasticsearch.common.UUIDS} length\n+\n+    // the following constants can be changed freely\n+    private static final String RAND_ALGO = \"SHA1PRNG\";\n+    // each snapshot metadata contains an unforgeable identifier of the repository password of the master node that started the snapshot\n+    // this hash is then verified on each data node before the actual shard files snapshot, as well as on the\n+    // master node that finalizes the snapshot (could be a different master node, if a master failover occurred during the snapshot)\n+    static final String PASSWORD_ID_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordId\";\n+    static final String PASSWORD_ID_SALT_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordIdSalt\";\n+    private static final int DEK_CACHE_WEIGHT = 2048;\n+\n+    // this is the repository instance to which all blob reads and writes are forwarded to (it stores both the encrypted blobs, as well\n+    // as the associated encrypted DEKs)\n+    private final BlobStoreRepository delegatedRepository;\n+    // every data blob is encrypted with its randomly generated AES key (DEK)\n+    private final Supplier<Tuple<BytesReference, SecretKey>> DEKGenerator;\n+    // license is checked before every snapshot operations; protected non-final for tests\n+    protected Supplier<XPackLicenseState> licenseStateSupplier;\n+    private final SecureString repositoryPassword;\n+    private final String localRepositoryPasswordId;\n+    private final String localRepositoryPasswordIdSalt;\n+    private volatile String validatedRepositoryPasswordId;\n+    private final Cache<String, SecretKey> DEKCache;\n+\n+    /**\n+     * Returns the byte length (i.e. the storage size) of an encrypted blob, given the length of the blob's plaintext contents.\n+     *\n+     * @see EncryptionPacketsInputStream#getEncryptionLength(long, int)\n+     */\n+    public static long getEncryptedBlobByteLength(long plaintextBlobByteLength) {\n+        return (long) DEK_ID_LENGTH /* UUID byte length */\n+            + EncryptionPacketsInputStream.getEncryptionLength(plaintextBlobByteLength, PACKET_LENGTH_IN_BYTES);\n+    }\n+\n+    protected EncryptedRepository(\n+        RepositoryMetadata metadata,\n+        NamedXContentRegistry namedXContentRegistry,\n+        ClusterService clusterService,\n+        BlobStoreRepository delegatedRepository,\n+        Supplier<XPackLicenseState> licenseStateSupplier,\n+        SecureString repositoryPassword\n+    ) throws GeneralSecurityException {\n+        super(\n+            metadata,\n+            namedXContentRegistry,\n+            clusterService,\n+            BlobPath.cleanPath() /* the encrypted repository uses a hardcoded empty\n+                                 base blob path but the base path setting is honored for the delegated repository */\n+        );\n+        this.delegatedRepository = delegatedRepository;\n+        this.DEKGenerator = createDEKGenerator();\n+        this.licenseStateSupplier = licenseStateSupplier;\n+        this.repositoryPassword = repositoryPassword;\n+        // the password \"id\" and validated\n+        this.localRepositoryPasswordIdSalt = UUIDs.randomBase64UUID();\n+        this.localRepositoryPasswordId = AESKeyUtils.computeId(\n+            AESKeyUtils.generatePasswordBasedKey(repositoryPassword, localRepositoryPasswordIdSalt)\n+        );\n+        this.validatedRepositoryPasswordId = this.localRepositoryPasswordId;\n+        // stores decrypted DEKs; DEKs are reused to encrypt/decrypt multiple independent blobs\n+        this.DEKCache = CacheBuilder.<String, SecretKey>builder().setMaximumWeight(DEK_CACHE_WEIGHT).build();\n+        if (isReadOnly() != delegatedRepository.isReadOnly()) {\n+            throw new RepositoryException(\n+                metadata.name(),\n+                \"Unexpected fatal internal error\",\n+                new IllegalStateException(\"The encrypted repository must be read-only iff the delegate repository is read-only\")\n+            );\n+        }\n+    }\n+\n+    @Override\n+    public RepositoryStats stats() {\n+        return this.delegatedRepository.stats();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eac6bfd83a87e37cf5f0f1e83dca50156a1bf31"}, "originalPosition": 154}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI2NTIwNA==", "bodyText": "I have a personal preference to avoid having local vars that shadow fields.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    final Supplier<Tuple<BytesReference, SecretKey>> DEKGenerator;\n          \n          \n            \n                    final Supplier<Tuple<BytesReference, SecretKey>> blobDEKGenerator;", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r432265204", "createdAt": "2020-05-29T05:37:29Z", "author": {"login": "tvernum"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepository.java", "diffHunk": "@@ -6,11 +6,682 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n-public class EncryptedRepository {\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.lucene.index.IndexCommit;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.metadata.RepositoryMetadata;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.CheckedFunction;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.blobstore.BlobContainer;\n+import org.elasticsearch.common.blobstore.BlobMetadata;\n+import org.elasticsearch.common.blobstore.BlobPath;\n+import org.elasticsearch.common.blobstore.BlobStore;\n+import org.elasticsearch.common.blobstore.DeleteResult;\n+import org.elasticsearch.common.blobstore.support.AbstractBlobContainer;\n+import org.elasticsearch.common.bytes.BytesArray;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.cache.Cache;\n+import org.elasticsearch.common.cache.CacheBuilder;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.io.Streams;\n+import org.elasticsearch.common.settings.SecureString;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.index.store.Store;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoryData;\n+import org.elasticsearch.repositories.RepositoryException;\n+import org.elasticsearch.repositories.RepositoryStats;\n+import org.elasticsearch.repositories.ShardGenerations;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.SnapshotInfo;\n+import org.elasticsearch.snapshots.SnapshotShardFailure;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.SecretKey;\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.NoSuchFileException;\n+import java.security.GeneralSecurityException;\n+import java.security.SecureRandom;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+public class EncryptedRepository extends BlobStoreRepository {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepository.class);\n+    // the following constants are fixed by definition\n     static final int GCM_TAG_LENGTH_IN_BYTES = 16;\n     static final int GCM_IV_LENGTH_IN_BYTES = 12;\n-    static final int AES_BLOCK_SIZE_IN_BYTES = 128;\n+    static final int AES_BLOCK_LENGTH_IN_BYTES = 128;\n+    // the following constants require careful thought before changing because they will break backwards compatibility\n     static final String DATA_ENCRYPTION_SCHEME = \"AES/GCM/NoPadding\";\n     static final long PACKET_START_COUNTER = Long.MIN_VALUE;\n-    static final int MAX_PACKET_LENGTH_IN_BYTES = 1 << 30;\n+    static final int MAX_PACKET_LENGTH_IN_BYTES = 8 << 20; // 8MB\n+    // this should be smaller than {@code #MAX_PACKET_LENGTH_IN_BYTES} and it's what {@code EncryptionPacketsInputStream} uses\n+    // during encryption and what {@code DecryptionPacketsInputStream} expects during decryption (it is not configurable)\n+    static final int PACKET_LENGTH_IN_BYTES = 64 * (1 << 10); // 64KB\n+    // the path of the blob container holding all the DEKs\n+    // this is relative to the root base path holding the encrypted blobs (i.e. the repository root base path)\n+    static final String DEK_ROOT_CONTAINER = \".encryption-metadata\"; // package private for tests\n+    static final int DEK_ID_LENGTH = 22; // {@code org.elasticsearch.common.UUIDS} length\n+\n+    // the following constants can be changed freely\n+    private static final String RAND_ALGO = \"SHA1PRNG\";\n+    // each snapshot metadata contains an unforgeable identifier of the repository password of the master node that started the snapshot\n+    // this hash is then verified on each data node before the actual shard files snapshot, as well as on the\n+    // master node that finalizes the snapshot (could be a different master node, if a master failover occurred during the snapshot)\n+    static final String PASSWORD_ID_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordId\";\n+    static final String PASSWORD_ID_SALT_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordIdSalt\";\n+    private static final int DEK_CACHE_WEIGHT = 2048;\n+\n+    // this is the repository instance to which all blob reads and writes are forwarded to (it stores both the encrypted blobs, as well\n+    // as the associated encrypted DEKs)\n+    private final BlobStoreRepository delegatedRepository;\n+    // every data blob is encrypted with its randomly generated AES key (DEK)\n+    private final Supplier<Tuple<BytesReference, SecretKey>> DEKGenerator;\n+    // license is checked before every snapshot operations; protected non-final for tests\n+    protected Supplier<XPackLicenseState> licenseStateSupplier;\n+    private final SecureString repositoryPassword;\n+    private final String localRepositoryPasswordId;\n+    private final String localRepositoryPasswordIdSalt;\n+    private volatile String validatedRepositoryPasswordId;\n+    private final Cache<String, SecretKey> DEKCache;\n+\n+    /**\n+     * Returns the byte length (i.e. the storage size) of an encrypted blob, given the length of the blob's plaintext contents.\n+     *\n+     * @see EncryptionPacketsInputStream#getEncryptionLength(long, int)\n+     */\n+    public static long getEncryptedBlobByteLength(long plaintextBlobByteLength) {\n+        return (long) DEK_ID_LENGTH /* UUID byte length */\n+            + EncryptionPacketsInputStream.getEncryptionLength(plaintextBlobByteLength, PACKET_LENGTH_IN_BYTES);\n+    }\n+\n+    protected EncryptedRepository(\n+        RepositoryMetadata metadata,\n+        NamedXContentRegistry namedXContentRegistry,\n+        ClusterService clusterService,\n+        BlobStoreRepository delegatedRepository,\n+        Supplier<XPackLicenseState> licenseStateSupplier,\n+        SecureString repositoryPassword\n+    ) throws GeneralSecurityException {\n+        super(\n+            metadata,\n+            namedXContentRegistry,\n+            clusterService,\n+            BlobPath.cleanPath() /* the encrypted repository uses a hardcoded empty\n+                                 base blob path but the base path setting is honored for the delegated repository */\n+        );\n+        this.delegatedRepository = delegatedRepository;\n+        this.DEKGenerator = createDEKGenerator();\n+        this.licenseStateSupplier = licenseStateSupplier;\n+        this.repositoryPassword = repositoryPassword;\n+        // the password \"id\" and validated\n+        this.localRepositoryPasswordIdSalt = UUIDs.randomBase64UUID();\n+        this.localRepositoryPasswordId = AESKeyUtils.computeId(\n+            AESKeyUtils.generatePasswordBasedKey(repositoryPassword, localRepositoryPasswordIdSalt)\n+        );\n+        this.validatedRepositoryPasswordId = this.localRepositoryPasswordId;\n+        // stores decrypted DEKs; DEKs are reused to encrypt/decrypt multiple independent blobs\n+        this.DEKCache = CacheBuilder.<String, SecretKey>builder().setMaximumWeight(DEK_CACHE_WEIGHT).build();\n+        if (isReadOnly() != delegatedRepository.isReadOnly()) {\n+            throw new RepositoryException(\n+                metadata.name(),\n+                \"Unexpected fatal internal error\",\n+                new IllegalStateException(\"The encrypted repository must be read-only iff the delegate repository is read-only\")\n+            );\n+        }\n+    }\n+\n+    @Override\n+    public RepositoryStats stats() {\n+        return this.delegatedRepository.stats();\n+    }\n+\n+    /**\n+     * The repository hook method which populates the snapshot metadata with the salted password hash of the repository on the (master)\n+     * node that starts of the snapshot operation. All the other actions associated with the same snapshot operation will first verify\n+     * that the local repository password checks with the hash from the snapshot metadata.\n+     * <p>\n+     * In addition, if the installed license does not comply with encrypted snapshots, this throws an exception, which aborts the snapshot\n+     * operation.\n+     *\n+     * See {@link org.elasticsearch.repositories.Repository#adaptUserMetadata(Map)}.\n+     *\n+     * @param userMetadata the snapshot metadata as received from the calling user\n+     * @return the snapshot metadata containing the salted password hash of the node initializing the snapshot\n+     */\n+    @Override\n+    public Map<String, Object> adaptUserMetadata(Map<String, Object> userMetadata) {\n+        // because populating the snapshot metadata must be done before the actual snapshot is first initialized,\n+        // we take the opportunity to validate the license and abort if non-compliant\n+        if (false == licenseStateSupplier.get().isAllowed(XPackLicenseState.Feature.ENCRYPTED_SNAPSHOT)) {\n+            throw LicenseUtils.newComplianceException(\"encrypted snapshots\");\n+        }\n+        Map<String, Object> snapshotUserMetadata = new HashMap<>();\n+        if (userMetadata != null) {\n+            snapshotUserMetadata.putAll(userMetadata);\n+        }\n+        // set out the ID of the repository secret\n+        // this is then checked before every snapshot operation (i.e. {@link #snapshotShard} and {@link #finalizeSnapshot})\n+        // to assure that all participating nodes in the snapshot operation are using the same repository secret\n+        snapshotUserMetadata.put(PASSWORD_ID_SALT_USER_METADATA_KEY, localRepositoryPasswordIdSalt);\n+        snapshotUserMetadata.put(PASSWORD_ID_USER_METADATA_KEY, localRepositoryPasswordId);\n+        logger.trace(\n+            \"Snapshot metadata for local repository password  [{}] and [{}]\",\n+            localRepositoryPasswordIdSalt,\n+            localRepositoryPasswordId\n+        );\n+        return Map.copyOf(snapshotUserMetadata);\n+    }\n+\n+    @Override\n+    public void finalizeSnapshot(\n+        SnapshotId snapshotId,\n+        ShardGenerations shardGenerations,\n+        long startTime,\n+        String failure,\n+        int totalShards,\n+        List<SnapshotShardFailure> shardFailures,\n+        long repositoryStateId,\n+        boolean includeGlobalState,\n+        Metadata clusterMetadata,\n+        Map<String, Object> userMetadata,\n+        Version repositoryMetaVersion,\n+        Function<ClusterState, ClusterState> stateTransformer,\n+        ActionListener<Tuple<RepositoryData, SnapshotInfo>> listener\n+    ) {\n+        try {\n+            validateLocalRepositorySecret(userMetadata);\n+        } catch (RepositoryException passwordValidationException) {\n+            listener.onFailure(passwordValidationException);\n+            return;\n+        } finally {\n+            // remove the repository password id from the snapshot metadata so that the id is not displayed in the API response to the user\n+            userMetadata = new HashMap<>(userMetadata);\n+            userMetadata.remove(PASSWORD_ID_USER_METADATA_KEY);\n+            userMetadata.remove(PASSWORD_ID_SALT_USER_METADATA_KEY);\n+        }\n+        super.finalizeSnapshot(\n+            snapshotId,\n+            shardGenerations,\n+            startTime,\n+            failure,\n+            totalShards,\n+            shardFailures,\n+            repositoryStateId,\n+            includeGlobalState,\n+            clusterMetadata,\n+            userMetadata,\n+            repositoryMetaVersion,\n+            stateTransformer,\n+            listener\n+        );\n+    }\n+\n+    @Override\n+    public void snapshotShard(\n+        Store store,\n+        MapperService mapperService,\n+        SnapshotId snapshotId,\n+        IndexId indexId,\n+        IndexCommit snapshotIndexCommit,\n+        String shardStateIdentifier,\n+        IndexShardSnapshotStatus snapshotStatus,\n+        Version repositoryMetaVersion,\n+        Map<String, Object> userMetadata,\n+        ActionListener<String> listener\n+    ) {\n+        try {\n+            validateLocalRepositorySecret(userMetadata);\n+        } catch (RepositoryException passwordValidationException) {\n+            listener.onFailure(passwordValidationException);\n+            return;\n+        }\n+        super.snapshotShard(\n+            store,\n+            mapperService,\n+            snapshotId,\n+            indexId,\n+            snapshotIndexCommit,\n+            shardStateIdentifier,\n+            snapshotStatus,\n+            repositoryMetaVersion,\n+            userMetadata,\n+            listener\n+        );\n+    }\n+\n+    @Override\n+    protected BlobStore createBlobStore() {\n+        final Supplier<Tuple<BytesReference, SecretKey>> DEKGenerator;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eac6bfd83a87e37cf5f0f1e83dca50156a1bf31"}, "originalPosition": 273}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI2NzA2Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                    \"Wrapped DEK [\" + DEKId + \"] has smaller length [\" + bytesRead + \"] \" + \"than expected\"\n          \n          \n            \n                                    \"Wrapped DEK [\" + DEKId + \"] has smaller length [\" + bytesRead + \"] than expected\"", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r432267062", "createdAt": "2020-05-29T05:44:41Z", "author": {"login": "tvernum"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepository.java", "diffHunk": "@@ -6,11 +6,682 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n-public class EncryptedRepository {\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.lucene.index.IndexCommit;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.metadata.RepositoryMetadata;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.CheckedFunction;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.blobstore.BlobContainer;\n+import org.elasticsearch.common.blobstore.BlobMetadata;\n+import org.elasticsearch.common.blobstore.BlobPath;\n+import org.elasticsearch.common.blobstore.BlobStore;\n+import org.elasticsearch.common.blobstore.DeleteResult;\n+import org.elasticsearch.common.blobstore.support.AbstractBlobContainer;\n+import org.elasticsearch.common.bytes.BytesArray;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.cache.Cache;\n+import org.elasticsearch.common.cache.CacheBuilder;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.io.Streams;\n+import org.elasticsearch.common.settings.SecureString;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.index.store.Store;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoryData;\n+import org.elasticsearch.repositories.RepositoryException;\n+import org.elasticsearch.repositories.RepositoryStats;\n+import org.elasticsearch.repositories.ShardGenerations;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.SnapshotInfo;\n+import org.elasticsearch.snapshots.SnapshotShardFailure;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.SecretKey;\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.NoSuchFileException;\n+import java.security.GeneralSecurityException;\n+import java.security.SecureRandom;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+public class EncryptedRepository extends BlobStoreRepository {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepository.class);\n+    // the following constants are fixed by definition\n     static final int GCM_TAG_LENGTH_IN_BYTES = 16;\n     static final int GCM_IV_LENGTH_IN_BYTES = 12;\n-    static final int AES_BLOCK_SIZE_IN_BYTES = 128;\n+    static final int AES_BLOCK_LENGTH_IN_BYTES = 128;\n+    // the following constants require careful thought before changing because they will break backwards compatibility\n     static final String DATA_ENCRYPTION_SCHEME = \"AES/GCM/NoPadding\";\n     static final long PACKET_START_COUNTER = Long.MIN_VALUE;\n-    static final int MAX_PACKET_LENGTH_IN_BYTES = 1 << 30;\n+    static final int MAX_PACKET_LENGTH_IN_BYTES = 8 << 20; // 8MB\n+    // this should be smaller than {@code #MAX_PACKET_LENGTH_IN_BYTES} and it's what {@code EncryptionPacketsInputStream} uses\n+    // during encryption and what {@code DecryptionPacketsInputStream} expects during decryption (it is not configurable)\n+    static final int PACKET_LENGTH_IN_BYTES = 64 * (1 << 10); // 64KB\n+    // the path of the blob container holding all the DEKs\n+    // this is relative to the root base path holding the encrypted blobs (i.e. the repository root base path)\n+    static final String DEK_ROOT_CONTAINER = \".encryption-metadata\"; // package private for tests\n+    static final int DEK_ID_LENGTH = 22; // {@code org.elasticsearch.common.UUIDS} length\n+\n+    // the following constants can be changed freely\n+    private static final String RAND_ALGO = \"SHA1PRNG\";\n+    // each snapshot metadata contains an unforgeable identifier of the repository password of the master node that started the snapshot\n+    // this hash is then verified on each data node before the actual shard files snapshot, as well as on the\n+    // master node that finalizes the snapshot (could be a different master node, if a master failover occurred during the snapshot)\n+    static final String PASSWORD_ID_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordId\";\n+    static final String PASSWORD_ID_SALT_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordIdSalt\";\n+    private static final int DEK_CACHE_WEIGHT = 2048;\n+\n+    // this is the repository instance to which all blob reads and writes are forwarded to (it stores both the encrypted blobs, as well\n+    // as the associated encrypted DEKs)\n+    private final BlobStoreRepository delegatedRepository;\n+    // every data blob is encrypted with its randomly generated AES key (DEK)\n+    private final Supplier<Tuple<BytesReference, SecretKey>> DEKGenerator;\n+    // license is checked before every snapshot operations; protected non-final for tests\n+    protected Supplier<XPackLicenseState> licenseStateSupplier;\n+    private final SecureString repositoryPassword;\n+    private final String localRepositoryPasswordId;\n+    private final String localRepositoryPasswordIdSalt;\n+    private volatile String validatedRepositoryPasswordId;\n+    private final Cache<String, SecretKey> DEKCache;\n+\n+    /**\n+     * Returns the byte length (i.e. the storage size) of an encrypted blob, given the length of the blob's plaintext contents.\n+     *\n+     * @see EncryptionPacketsInputStream#getEncryptionLength(long, int)\n+     */\n+    public static long getEncryptedBlobByteLength(long plaintextBlobByteLength) {\n+        return (long) DEK_ID_LENGTH /* UUID byte length */\n+            + EncryptionPacketsInputStream.getEncryptionLength(plaintextBlobByteLength, PACKET_LENGTH_IN_BYTES);\n+    }\n+\n+    protected EncryptedRepository(\n+        RepositoryMetadata metadata,\n+        NamedXContentRegistry namedXContentRegistry,\n+        ClusterService clusterService,\n+        BlobStoreRepository delegatedRepository,\n+        Supplier<XPackLicenseState> licenseStateSupplier,\n+        SecureString repositoryPassword\n+    ) throws GeneralSecurityException {\n+        super(\n+            metadata,\n+            namedXContentRegistry,\n+            clusterService,\n+            BlobPath.cleanPath() /* the encrypted repository uses a hardcoded empty\n+                                 base blob path but the base path setting is honored for the delegated repository */\n+        );\n+        this.delegatedRepository = delegatedRepository;\n+        this.DEKGenerator = createDEKGenerator();\n+        this.licenseStateSupplier = licenseStateSupplier;\n+        this.repositoryPassword = repositoryPassword;\n+        // the password \"id\" and validated\n+        this.localRepositoryPasswordIdSalt = UUIDs.randomBase64UUID();\n+        this.localRepositoryPasswordId = AESKeyUtils.computeId(\n+            AESKeyUtils.generatePasswordBasedKey(repositoryPassword, localRepositoryPasswordIdSalt)\n+        );\n+        this.validatedRepositoryPasswordId = this.localRepositoryPasswordId;\n+        // stores decrypted DEKs; DEKs are reused to encrypt/decrypt multiple independent blobs\n+        this.DEKCache = CacheBuilder.<String, SecretKey>builder().setMaximumWeight(DEK_CACHE_WEIGHT).build();\n+        if (isReadOnly() != delegatedRepository.isReadOnly()) {\n+            throw new RepositoryException(\n+                metadata.name(),\n+                \"Unexpected fatal internal error\",\n+                new IllegalStateException(\"The encrypted repository must be read-only iff the delegate repository is read-only\")\n+            );\n+        }\n+    }\n+\n+    @Override\n+    public RepositoryStats stats() {\n+        return this.delegatedRepository.stats();\n+    }\n+\n+    /**\n+     * The repository hook method which populates the snapshot metadata with the salted password hash of the repository on the (master)\n+     * node that starts of the snapshot operation. All the other actions associated with the same snapshot operation will first verify\n+     * that the local repository password checks with the hash from the snapshot metadata.\n+     * <p>\n+     * In addition, if the installed license does not comply with encrypted snapshots, this throws an exception, which aborts the snapshot\n+     * operation.\n+     *\n+     * See {@link org.elasticsearch.repositories.Repository#adaptUserMetadata(Map)}.\n+     *\n+     * @param userMetadata the snapshot metadata as received from the calling user\n+     * @return the snapshot metadata containing the salted password hash of the node initializing the snapshot\n+     */\n+    @Override\n+    public Map<String, Object> adaptUserMetadata(Map<String, Object> userMetadata) {\n+        // because populating the snapshot metadata must be done before the actual snapshot is first initialized,\n+        // we take the opportunity to validate the license and abort if non-compliant\n+        if (false == licenseStateSupplier.get().isAllowed(XPackLicenseState.Feature.ENCRYPTED_SNAPSHOT)) {\n+            throw LicenseUtils.newComplianceException(\"encrypted snapshots\");\n+        }\n+        Map<String, Object> snapshotUserMetadata = new HashMap<>();\n+        if (userMetadata != null) {\n+            snapshotUserMetadata.putAll(userMetadata);\n+        }\n+        // set out the ID of the repository secret\n+        // this is then checked before every snapshot operation (i.e. {@link #snapshotShard} and {@link #finalizeSnapshot})\n+        // to assure that all participating nodes in the snapshot operation are using the same repository secret\n+        snapshotUserMetadata.put(PASSWORD_ID_SALT_USER_METADATA_KEY, localRepositoryPasswordIdSalt);\n+        snapshotUserMetadata.put(PASSWORD_ID_USER_METADATA_KEY, localRepositoryPasswordId);\n+        logger.trace(\n+            \"Snapshot metadata for local repository password  [{}] and [{}]\",\n+            localRepositoryPasswordIdSalt,\n+            localRepositoryPasswordId\n+        );\n+        return Map.copyOf(snapshotUserMetadata);\n+    }\n+\n+    @Override\n+    public void finalizeSnapshot(\n+        SnapshotId snapshotId,\n+        ShardGenerations shardGenerations,\n+        long startTime,\n+        String failure,\n+        int totalShards,\n+        List<SnapshotShardFailure> shardFailures,\n+        long repositoryStateId,\n+        boolean includeGlobalState,\n+        Metadata clusterMetadata,\n+        Map<String, Object> userMetadata,\n+        Version repositoryMetaVersion,\n+        Function<ClusterState, ClusterState> stateTransformer,\n+        ActionListener<Tuple<RepositoryData, SnapshotInfo>> listener\n+    ) {\n+        try {\n+            validateLocalRepositorySecret(userMetadata);\n+        } catch (RepositoryException passwordValidationException) {\n+            listener.onFailure(passwordValidationException);\n+            return;\n+        } finally {\n+            // remove the repository password id from the snapshot metadata so that the id is not displayed in the API response to the user\n+            userMetadata = new HashMap<>(userMetadata);\n+            userMetadata.remove(PASSWORD_ID_USER_METADATA_KEY);\n+            userMetadata.remove(PASSWORD_ID_SALT_USER_METADATA_KEY);\n+        }\n+        super.finalizeSnapshot(\n+            snapshotId,\n+            shardGenerations,\n+            startTime,\n+            failure,\n+            totalShards,\n+            shardFailures,\n+            repositoryStateId,\n+            includeGlobalState,\n+            clusterMetadata,\n+            userMetadata,\n+            repositoryMetaVersion,\n+            stateTransformer,\n+            listener\n+        );\n+    }\n+\n+    @Override\n+    public void snapshotShard(\n+        Store store,\n+        MapperService mapperService,\n+        SnapshotId snapshotId,\n+        IndexId indexId,\n+        IndexCommit snapshotIndexCommit,\n+        String shardStateIdentifier,\n+        IndexShardSnapshotStatus snapshotStatus,\n+        Version repositoryMetaVersion,\n+        Map<String, Object> userMetadata,\n+        ActionListener<String> listener\n+    ) {\n+        try {\n+            validateLocalRepositorySecret(userMetadata);\n+        } catch (RepositoryException passwordValidationException) {\n+            listener.onFailure(passwordValidationException);\n+            return;\n+        }\n+        super.snapshotShard(\n+            store,\n+            mapperService,\n+            snapshotId,\n+            indexId,\n+            snapshotIndexCommit,\n+            shardStateIdentifier,\n+            snapshotStatus,\n+            repositoryMetaVersion,\n+            userMetadata,\n+            listener\n+        );\n+    }\n+\n+    @Override\n+    protected BlobStore createBlobStore() {\n+        final Supplier<Tuple<BytesReference, SecretKey>> DEKGenerator;\n+        if (isReadOnly()) {\n+            // make sure that a read-only repository can't encrypt anything\n+            DEKGenerator = () -> {\n+                throw new RepositoryException(\n+                    metadata.name(),\n+                    \"Unexpected fatal internal error\",\n+                    new IllegalStateException(\"DEKs are required for encryption but this is a read-only repository\")\n+                );\n+            };\n+        } else {\n+            DEKGenerator = this.DEKGenerator;\n+        }\n+        return new EncryptedBlobStore(\n+            delegatedRepository.blobStore(),\n+            delegatedRepository.basePath(),\n+            metadata.name(),\n+            this::generateKEK,\n+            DEKGenerator,\n+            DEKCache\n+        );\n+    }\n+\n+    @Override\n+    protected void doStart() {\n+        this.delegatedRepository.start();\n+        super.doStart();\n+    }\n+\n+    @Override\n+    protected void doStop() {\n+        super.doStop();\n+        this.delegatedRepository.stop();\n+    }\n+\n+    @Override\n+    protected void doClose() {\n+        super.doClose();\n+        this.delegatedRepository.close();\n+    }\n+\n+    private Supplier<Tuple<BytesReference, SecretKey>> createDEKGenerator() throws GeneralSecurityException {\n+        // DEK and DEK Ids MUST be generated randomly (with independent random instances)\n+        final SecureRandom DEKSecureRandom = SecureRandom.getInstance(RAND_ALGO);\n+        final SecureRandom DEKIdSecureRandom = SecureRandom.getInstance(RAND_ALGO);\n+        final KeyGenerator DEKGenerator = KeyGenerator.getInstance(DATA_ENCRYPTION_SCHEME.split(\"/\")[0]);\n+        DEKGenerator.init(AESKeyUtils.KEY_LENGTH_IN_BYTES * Byte.SIZE, DEKSecureRandom);\n+        return () -> {\n+            final BytesReference DEKId = new BytesArray(UUIDs.randomBase64UUID(DEKIdSecureRandom));\n+            final SecretKey DEK = DEKGenerator.generateKey();\n+            logger.debug(\"Repository [{}] generated new DEK [{}]\", metadata.name(), DEKId);\n+            return new Tuple<>(DEKId, DEK);\n+        };\n+    }\n+\n+    // pkg-private for tests\n+    Tuple<String, SecretKey> generateKEK(String DEKId) {\n+        try {\n+            // we rely on the DEK Id being generated randomly so it can be used as a salt\n+            final SecretKey KEK = AESKeyUtils.generatePasswordBasedKey(repositoryPassword, DEKId);\n+            final String KEKId = AESKeyUtils.computeId(KEK);\n+            logger.debug(\"Repository [{}] computed KEK [{}] for DEK [{}]\", metadata.name(), KEKId, DEKId);\n+            return new Tuple<>(KEKId, KEK);\n+        } catch (GeneralSecurityException e) {\n+            throw new RepositoryException(metadata.name(), \"Failure to generate KEK to wrap the DEK [\" + DEKId + \"]\", e);\n+        }\n+    }\n+\n+    /**\n+     * Called before the shard snapshot and finalize operations, on the data and master nodes. This validates that the repository\n+     * secret on the master node that started the snapshot operation is identical to the repository secret on the local node.\n+     *\n+     * @param snapshotUserMetadata the snapshot metadata containing the repository secret id to verify\n+     * @throws RepositoryException if the repository secret id on the local node mismatches the master's\n+     */\n+    private void validateLocalRepositorySecret(Map<String, Object> snapshotUserMetadata) throws RepositoryException {\n+        assert snapshotUserMetadata != null;\n+        assert snapshotUserMetadata.get(PASSWORD_ID_USER_METADATA_KEY) instanceof String;\n+        final String masterRepositoryPasswordId = (String) snapshotUserMetadata.get(PASSWORD_ID_USER_METADATA_KEY);\n+        if (false == masterRepositoryPasswordId.equals(validatedRepositoryPasswordId)) {\n+            assert snapshotUserMetadata.get(PASSWORD_ID_SALT_USER_METADATA_KEY) instanceof String;\n+            final String masterRepositoryPasswordIdSalt = (String) snapshotUserMetadata.get(PASSWORD_ID_SALT_USER_METADATA_KEY);\n+            final String computedRepositoryPasswordId;\n+            try {\n+                computedRepositoryPasswordId = AESKeyUtils.computeId(\n+                    AESKeyUtils.generatePasswordBasedKey(repositoryPassword, masterRepositoryPasswordIdSalt)\n+                );\n+            } catch (Exception e) {\n+                throw new RepositoryException(metadata.name(), \"Unexpected fatal internal error\", e);\n+            }\n+            if (computedRepositoryPasswordId.equals(masterRepositoryPasswordId)) {\n+                this.validatedRepositoryPasswordId = computedRepositoryPasswordId;\n+            } else {\n+                throw new RepositoryException(\n+                    metadata.name(),\n+                    \"Repository secret id mismatch. The local node's repository secret, the keystore setting [\"\n+                        + EncryptedRepositoryPlugin.ENCRYPTION_PASSWORD_SETTING.getConcreteSettingForNamespace(\n+                            EncryptedRepositoryPlugin.PASSWORD_NAME_SETTING.get(metadata.settings())\n+                        ).getKey()\n+                        + \"], is different compared to the elected master node's which started the snapshot operation\"\n+                );\n+            }\n+        }\n+    }\n+\n+    // pkg-private for tests\n+    static final class EncryptedBlobStore implements BlobStore {\n+        private final BlobStore delegatedBlobStore;\n+        private final BlobPath delegatedBasePath;\n+        private final String repositoryName;\n+        private final Function<String, Tuple<String, SecretKey>> getKEKforDEK;\n+        private final Cache<String, SecretKey> DEKCache;\n+        private final CheckedSupplier<SingleUseKey, IOException> singleUseDEKSupplier;\n+\n+        EncryptedBlobStore(\n+            BlobStore delegatedBlobStore,\n+            BlobPath delegatedBasePath,\n+            String repositoryName,\n+            Function<String, Tuple<String, SecretKey>> getKEKforDEK,\n+            Supplier<Tuple<BytesReference, SecretKey>> DEKGenerator,\n+            Cache<String, SecretKey> DEKCache\n+        ) {\n+            this.delegatedBlobStore = delegatedBlobStore;\n+            this.delegatedBasePath = delegatedBasePath;\n+            this.repositoryName = repositoryName;\n+            this.getKEKforDEK = getKEKforDEK;\n+            this.DEKCache = DEKCache;\n+            this.singleUseDEKSupplier = SingleUseKey.createSingleUseKeySupplier(() -> {\n+                Tuple<BytesReference, SecretKey> newDEK = DEKGenerator.get();\n+                // store the newly generated DEK before making it available\n+                storeDEK(newDEK.v1().utf8ToString(), newDEK.v2());\n+                return newDEK;\n+            });\n+        }\n+\n+        // pkg-private for tests\n+        SecretKey getDEKById(String DEKId) throws IOException {\n+            try {\n+                return DEKCache.computeIfAbsent(DEKId, ignored -> loadDEK(DEKId));\n+            } catch (ExecutionException e) {\n+                // some exception types are to be expected\n+                if (e.getCause() instanceof IOException) {\n+                    throw (IOException) e.getCause();\n+                } else if (e.getCause() instanceof ElasticsearchException) {\n+                    throw (ElasticsearchException) e.getCause();\n+                } else {\n+                    throw new RepositoryException(repositoryName, \"Unexpected exception retrieving DEK [\" + DEKId + \"]\", e);\n+                }\n+            }\n+        }\n+\n+        private SecretKey loadDEK(String DEKId) throws IOException {\n+            final BlobPath DEKBlobPath = delegatedBasePath.add(DEK_ROOT_CONTAINER).add(DEKId);\n+            logger.debug(\"Repository [{}] loading wrapped DEK [{}] from blob path {}\", repositoryName, DEKId, DEKBlobPath);\n+            final BlobContainer DEKBlobContainer = delegatedBlobStore.blobContainer(DEKBlobPath);\n+            final Tuple<String, SecretKey> KEK = getKEKforDEK.apply(DEKId);\n+            logger.trace(\"Repository [{}] using KEK [{}] to unwrap DEK [{}]\", repositoryName, KEK.v1(), DEKId);\n+            final byte[] encryptedDEKBytes = new byte[AESKeyUtils.WRAPPED_KEY_LENGTH_IN_BYTES];\n+            try (InputStream encryptedDEKInputStream = DEKBlobContainer.readBlob(KEK.v1())) {\n+                final int bytesRead = Streams.readFully(encryptedDEKInputStream, encryptedDEKBytes);\n+                if (bytesRead != AESKeyUtils.WRAPPED_KEY_LENGTH_IN_BYTES) {\n+                    throw new RepositoryException(\n+                        repositoryName,\n+                        \"Wrapped DEK [\" + DEKId + \"] has smaller length [\" + bytesRead + \"] \" + \"than expected\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eac6bfd83a87e37cf5f0f1e83dca50156a1bf31"}, "originalPosition": 436}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI3MDUxNw==", "bodyText": "Again, personal preference, but I much prefer to unpack a tuple as soon as its read.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        final Tuple<String, SecretKey> KEK = getKEKforDEK.apply(DEKId);\n          \n          \n            \n                        final Tuple<String, SecretKey> kekTup = getKEKforDEK.apply(DEKId);\n          \n          \n            \n                        final String kekId = kekTup.v1();\n          \n          \n            \n                        final SecretKey kek = kekTup.v2();", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r432270517", "createdAt": "2020-05-29T05:56:46Z", "author": {"login": "tvernum"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepository.java", "diffHunk": "@@ -6,11 +6,682 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n-public class EncryptedRepository {\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.lucene.index.IndexCommit;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.metadata.RepositoryMetadata;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.CheckedFunction;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.blobstore.BlobContainer;\n+import org.elasticsearch.common.blobstore.BlobMetadata;\n+import org.elasticsearch.common.blobstore.BlobPath;\n+import org.elasticsearch.common.blobstore.BlobStore;\n+import org.elasticsearch.common.blobstore.DeleteResult;\n+import org.elasticsearch.common.blobstore.support.AbstractBlobContainer;\n+import org.elasticsearch.common.bytes.BytesArray;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.cache.Cache;\n+import org.elasticsearch.common.cache.CacheBuilder;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.io.Streams;\n+import org.elasticsearch.common.settings.SecureString;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.index.store.Store;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoryData;\n+import org.elasticsearch.repositories.RepositoryException;\n+import org.elasticsearch.repositories.RepositoryStats;\n+import org.elasticsearch.repositories.ShardGenerations;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.SnapshotInfo;\n+import org.elasticsearch.snapshots.SnapshotShardFailure;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.SecretKey;\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.NoSuchFileException;\n+import java.security.GeneralSecurityException;\n+import java.security.SecureRandom;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+public class EncryptedRepository extends BlobStoreRepository {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepository.class);\n+    // the following constants are fixed by definition\n     static final int GCM_TAG_LENGTH_IN_BYTES = 16;\n     static final int GCM_IV_LENGTH_IN_BYTES = 12;\n-    static final int AES_BLOCK_SIZE_IN_BYTES = 128;\n+    static final int AES_BLOCK_LENGTH_IN_BYTES = 128;\n+    // the following constants require careful thought before changing because they will break backwards compatibility\n     static final String DATA_ENCRYPTION_SCHEME = \"AES/GCM/NoPadding\";\n     static final long PACKET_START_COUNTER = Long.MIN_VALUE;\n-    static final int MAX_PACKET_LENGTH_IN_BYTES = 1 << 30;\n+    static final int MAX_PACKET_LENGTH_IN_BYTES = 8 << 20; // 8MB\n+    // this should be smaller than {@code #MAX_PACKET_LENGTH_IN_BYTES} and it's what {@code EncryptionPacketsInputStream} uses\n+    // during encryption and what {@code DecryptionPacketsInputStream} expects during decryption (it is not configurable)\n+    static final int PACKET_LENGTH_IN_BYTES = 64 * (1 << 10); // 64KB\n+    // the path of the blob container holding all the DEKs\n+    // this is relative to the root base path holding the encrypted blobs (i.e. the repository root base path)\n+    static final String DEK_ROOT_CONTAINER = \".encryption-metadata\"; // package private for tests\n+    static final int DEK_ID_LENGTH = 22; // {@code org.elasticsearch.common.UUIDS} length\n+\n+    // the following constants can be changed freely\n+    private static final String RAND_ALGO = \"SHA1PRNG\";\n+    // each snapshot metadata contains an unforgeable identifier of the repository password of the master node that started the snapshot\n+    // this hash is then verified on each data node before the actual shard files snapshot, as well as on the\n+    // master node that finalizes the snapshot (could be a different master node, if a master failover occurred during the snapshot)\n+    static final String PASSWORD_ID_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordId\";\n+    static final String PASSWORD_ID_SALT_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordIdSalt\";\n+    private static final int DEK_CACHE_WEIGHT = 2048;\n+\n+    // this is the repository instance to which all blob reads and writes are forwarded to (it stores both the encrypted blobs, as well\n+    // as the associated encrypted DEKs)\n+    private final BlobStoreRepository delegatedRepository;\n+    // every data blob is encrypted with its randomly generated AES key (DEK)\n+    private final Supplier<Tuple<BytesReference, SecretKey>> DEKGenerator;\n+    // license is checked before every snapshot operations; protected non-final for tests\n+    protected Supplier<XPackLicenseState> licenseStateSupplier;\n+    private final SecureString repositoryPassword;\n+    private final String localRepositoryPasswordId;\n+    private final String localRepositoryPasswordIdSalt;\n+    private volatile String validatedRepositoryPasswordId;\n+    private final Cache<String, SecretKey> DEKCache;\n+\n+    /**\n+     * Returns the byte length (i.e. the storage size) of an encrypted blob, given the length of the blob's plaintext contents.\n+     *\n+     * @see EncryptionPacketsInputStream#getEncryptionLength(long, int)\n+     */\n+    public static long getEncryptedBlobByteLength(long plaintextBlobByteLength) {\n+        return (long) DEK_ID_LENGTH /* UUID byte length */\n+            + EncryptionPacketsInputStream.getEncryptionLength(plaintextBlobByteLength, PACKET_LENGTH_IN_BYTES);\n+    }\n+\n+    protected EncryptedRepository(\n+        RepositoryMetadata metadata,\n+        NamedXContentRegistry namedXContentRegistry,\n+        ClusterService clusterService,\n+        BlobStoreRepository delegatedRepository,\n+        Supplier<XPackLicenseState> licenseStateSupplier,\n+        SecureString repositoryPassword\n+    ) throws GeneralSecurityException {\n+        super(\n+            metadata,\n+            namedXContentRegistry,\n+            clusterService,\n+            BlobPath.cleanPath() /* the encrypted repository uses a hardcoded empty\n+                                 base blob path but the base path setting is honored for the delegated repository */\n+        );\n+        this.delegatedRepository = delegatedRepository;\n+        this.DEKGenerator = createDEKGenerator();\n+        this.licenseStateSupplier = licenseStateSupplier;\n+        this.repositoryPassword = repositoryPassword;\n+        // the password \"id\" and validated\n+        this.localRepositoryPasswordIdSalt = UUIDs.randomBase64UUID();\n+        this.localRepositoryPasswordId = AESKeyUtils.computeId(\n+            AESKeyUtils.generatePasswordBasedKey(repositoryPassword, localRepositoryPasswordIdSalt)\n+        );\n+        this.validatedRepositoryPasswordId = this.localRepositoryPasswordId;\n+        // stores decrypted DEKs; DEKs are reused to encrypt/decrypt multiple independent blobs\n+        this.DEKCache = CacheBuilder.<String, SecretKey>builder().setMaximumWeight(DEK_CACHE_WEIGHT).build();\n+        if (isReadOnly() != delegatedRepository.isReadOnly()) {\n+            throw new RepositoryException(\n+                metadata.name(),\n+                \"Unexpected fatal internal error\",\n+                new IllegalStateException(\"The encrypted repository must be read-only iff the delegate repository is read-only\")\n+            );\n+        }\n+    }\n+\n+    @Override\n+    public RepositoryStats stats() {\n+        return this.delegatedRepository.stats();\n+    }\n+\n+    /**\n+     * The repository hook method which populates the snapshot metadata with the salted password hash of the repository on the (master)\n+     * node that starts of the snapshot operation. All the other actions associated with the same snapshot operation will first verify\n+     * that the local repository password checks with the hash from the snapshot metadata.\n+     * <p>\n+     * In addition, if the installed license does not comply with encrypted snapshots, this throws an exception, which aborts the snapshot\n+     * operation.\n+     *\n+     * See {@link org.elasticsearch.repositories.Repository#adaptUserMetadata(Map)}.\n+     *\n+     * @param userMetadata the snapshot metadata as received from the calling user\n+     * @return the snapshot metadata containing the salted password hash of the node initializing the snapshot\n+     */\n+    @Override\n+    public Map<String, Object> adaptUserMetadata(Map<String, Object> userMetadata) {\n+        // because populating the snapshot metadata must be done before the actual snapshot is first initialized,\n+        // we take the opportunity to validate the license and abort if non-compliant\n+        if (false == licenseStateSupplier.get().isAllowed(XPackLicenseState.Feature.ENCRYPTED_SNAPSHOT)) {\n+            throw LicenseUtils.newComplianceException(\"encrypted snapshots\");\n+        }\n+        Map<String, Object> snapshotUserMetadata = new HashMap<>();\n+        if (userMetadata != null) {\n+            snapshotUserMetadata.putAll(userMetadata);\n+        }\n+        // set out the ID of the repository secret\n+        // this is then checked before every snapshot operation (i.e. {@link #snapshotShard} and {@link #finalizeSnapshot})\n+        // to assure that all participating nodes in the snapshot operation are using the same repository secret\n+        snapshotUserMetadata.put(PASSWORD_ID_SALT_USER_METADATA_KEY, localRepositoryPasswordIdSalt);\n+        snapshotUserMetadata.put(PASSWORD_ID_USER_METADATA_KEY, localRepositoryPasswordId);\n+        logger.trace(\n+            \"Snapshot metadata for local repository password  [{}] and [{}]\",\n+            localRepositoryPasswordIdSalt,\n+            localRepositoryPasswordId\n+        );\n+        return Map.copyOf(snapshotUserMetadata);\n+    }\n+\n+    @Override\n+    public void finalizeSnapshot(\n+        SnapshotId snapshotId,\n+        ShardGenerations shardGenerations,\n+        long startTime,\n+        String failure,\n+        int totalShards,\n+        List<SnapshotShardFailure> shardFailures,\n+        long repositoryStateId,\n+        boolean includeGlobalState,\n+        Metadata clusterMetadata,\n+        Map<String, Object> userMetadata,\n+        Version repositoryMetaVersion,\n+        Function<ClusterState, ClusterState> stateTransformer,\n+        ActionListener<Tuple<RepositoryData, SnapshotInfo>> listener\n+    ) {\n+        try {\n+            validateLocalRepositorySecret(userMetadata);\n+        } catch (RepositoryException passwordValidationException) {\n+            listener.onFailure(passwordValidationException);\n+            return;\n+        } finally {\n+            // remove the repository password id from the snapshot metadata so that the id is not displayed in the API response to the user\n+            userMetadata = new HashMap<>(userMetadata);\n+            userMetadata.remove(PASSWORD_ID_USER_METADATA_KEY);\n+            userMetadata.remove(PASSWORD_ID_SALT_USER_METADATA_KEY);\n+        }\n+        super.finalizeSnapshot(\n+            snapshotId,\n+            shardGenerations,\n+            startTime,\n+            failure,\n+            totalShards,\n+            shardFailures,\n+            repositoryStateId,\n+            includeGlobalState,\n+            clusterMetadata,\n+            userMetadata,\n+            repositoryMetaVersion,\n+            stateTransformer,\n+            listener\n+        );\n+    }\n+\n+    @Override\n+    public void snapshotShard(\n+        Store store,\n+        MapperService mapperService,\n+        SnapshotId snapshotId,\n+        IndexId indexId,\n+        IndexCommit snapshotIndexCommit,\n+        String shardStateIdentifier,\n+        IndexShardSnapshotStatus snapshotStatus,\n+        Version repositoryMetaVersion,\n+        Map<String, Object> userMetadata,\n+        ActionListener<String> listener\n+    ) {\n+        try {\n+            validateLocalRepositorySecret(userMetadata);\n+        } catch (RepositoryException passwordValidationException) {\n+            listener.onFailure(passwordValidationException);\n+            return;\n+        }\n+        super.snapshotShard(\n+            store,\n+            mapperService,\n+            snapshotId,\n+            indexId,\n+            snapshotIndexCommit,\n+            shardStateIdentifier,\n+            snapshotStatus,\n+            repositoryMetaVersion,\n+            userMetadata,\n+            listener\n+        );\n+    }\n+\n+    @Override\n+    protected BlobStore createBlobStore() {\n+        final Supplier<Tuple<BytesReference, SecretKey>> DEKGenerator;\n+        if (isReadOnly()) {\n+            // make sure that a read-only repository can't encrypt anything\n+            DEKGenerator = () -> {\n+                throw new RepositoryException(\n+                    metadata.name(),\n+                    \"Unexpected fatal internal error\",\n+                    new IllegalStateException(\"DEKs are required for encryption but this is a read-only repository\")\n+                );\n+            };\n+        } else {\n+            DEKGenerator = this.DEKGenerator;\n+        }\n+        return new EncryptedBlobStore(\n+            delegatedRepository.blobStore(),\n+            delegatedRepository.basePath(),\n+            metadata.name(),\n+            this::generateKEK,\n+            DEKGenerator,\n+            DEKCache\n+        );\n+    }\n+\n+    @Override\n+    protected void doStart() {\n+        this.delegatedRepository.start();\n+        super.doStart();\n+    }\n+\n+    @Override\n+    protected void doStop() {\n+        super.doStop();\n+        this.delegatedRepository.stop();\n+    }\n+\n+    @Override\n+    protected void doClose() {\n+        super.doClose();\n+        this.delegatedRepository.close();\n+    }\n+\n+    private Supplier<Tuple<BytesReference, SecretKey>> createDEKGenerator() throws GeneralSecurityException {\n+        // DEK and DEK Ids MUST be generated randomly (with independent random instances)\n+        final SecureRandom DEKSecureRandom = SecureRandom.getInstance(RAND_ALGO);\n+        final SecureRandom DEKIdSecureRandom = SecureRandom.getInstance(RAND_ALGO);\n+        final KeyGenerator DEKGenerator = KeyGenerator.getInstance(DATA_ENCRYPTION_SCHEME.split(\"/\")[0]);\n+        DEKGenerator.init(AESKeyUtils.KEY_LENGTH_IN_BYTES * Byte.SIZE, DEKSecureRandom);\n+        return () -> {\n+            final BytesReference DEKId = new BytesArray(UUIDs.randomBase64UUID(DEKIdSecureRandom));\n+            final SecretKey DEK = DEKGenerator.generateKey();\n+            logger.debug(\"Repository [{}] generated new DEK [{}]\", metadata.name(), DEKId);\n+            return new Tuple<>(DEKId, DEK);\n+        };\n+    }\n+\n+    // pkg-private for tests\n+    Tuple<String, SecretKey> generateKEK(String DEKId) {\n+        try {\n+            // we rely on the DEK Id being generated randomly so it can be used as a salt\n+            final SecretKey KEK = AESKeyUtils.generatePasswordBasedKey(repositoryPassword, DEKId);\n+            final String KEKId = AESKeyUtils.computeId(KEK);\n+            logger.debug(\"Repository [{}] computed KEK [{}] for DEK [{}]\", metadata.name(), KEKId, DEKId);\n+            return new Tuple<>(KEKId, KEK);\n+        } catch (GeneralSecurityException e) {\n+            throw new RepositoryException(metadata.name(), \"Failure to generate KEK to wrap the DEK [\" + DEKId + \"]\", e);\n+        }\n+    }\n+\n+    /**\n+     * Called before the shard snapshot and finalize operations, on the data and master nodes. This validates that the repository\n+     * secret on the master node that started the snapshot operation is identical to the repository secret on the local node.\n+     *\n+     * @param snapshotUserMetadata the snapshot metadata containing the repository secret id to verify\n+     * @throws RepositoryException if the repository secret id on the local node mismatches the master's\n+     */\n+    private void validateLocalRepositorySecret(Map<String, Object> snapshotUserMetadata) throws RepositoryException {\n+        assert snapshotUserMetadata != null;\n+        assert snapshotUserMetadata.get(PASSWORD_ID_USER_METADATA_KEY) instanceof String;\n+        final String masterRepositoryPasswordId = (String) snapshotUserMetadata.get(PASSWORD_ID_USER_METADATA_KEY);\n+        if (false == masterRepositoryPasswordId.equals(validatedRepositoryPasswordId)) {\n+            assert snapshotUserMetadata.get(PASSWORD_ID_SALT_USER_METADATA_KEY) instanceof String;\n+            final String masterRepositoryPasswordIdSalt = (String) snapshotUserMetadata.get(PASSWORD_ID_SALT_USER_METADATA_KEY);\n+            final String computedRepositoryPasswordId;\n+            try {\n+                computedRepositoryPasswordId = AESKeyUtils.computeId(\n+                    AESKeyUtils.generatePasswordBasedKey(repositoryPassword, masterRepositoryPasswordIdSalt)\n+                );\n+            } catch (Exception e) {\n+                throw new RepositoryException(metadata.name(), \"Unexpected fatal internal error\", e);\n+            }\n+            if (computedRepositoryPasswordId.equals(masterRepositoryPasswordId)) {\n+                this.validatedRepositoryPasswordId = computedRepositoryPasswordId;\n+            } else {\n+                throw new RepositoryException(\n+                    metadata.name(),\n+                    \"Repository secret id mismatch. The local node's repository secret, the keystore setting [\"\n+                        + EncryptedRepositoryPlugin.ENCRYPTION_PASSWORD_SETTING.getConcreteSettingForNamespace(\n+                            EncryptedRepositoryPlugin.PASSWORD_NAME_SETTING.get(metadata.settings())\n+                        ).getKey()\n+                        + \"], is different compared to the elected master node's which started the snapshot operation\"\n+                );\n+            }\n+        }\n+    }\n+\n+    // pkg-private for tests\n+    static final class EncryptedBlobStore implements BlobStore {\n+        private final BlobStore delegatedBlobStore;\n+        private final BlobPath delegatedBasePath;\n+        private final String repositoryName;\n+        private final Function<String, Tuple<String, SecretKey>> getKEKforDEK;\n+        private final Cache<String, SecretKey> DEKCache;\n+        private final CheckedSupplier<SingleUseKey, IOException> singleUseDEKSupplier;\n+\n+        EncryptedBlobStore(\n+            BlobStore delegatedBlobStore,\n+            BlobPath delegatedBasePath,\n+            String repositoryName,\n+            Function<String, Tuple<String, SecretKey>> getKEKforDEK,\n+            Supplier<Tuple<BytesReference, SecretKey>> DEKGenerator,\n+            Cache<String, SecretKey> DEKCache\n+        ) {\n+            this.delegatedBlobStore = delegatedBlobStore;\n+            this.delegatedBasePath = delegatedBasePath;\n+            this.repositoryName = repositoryName;\n+            this.getKEKforDEK = getKEKforDEK;\n+            this.DEKCache = DEKCache;\n+            this.singleUseDEKSupplier = SingleUseKey.createSingleUseKeySupplier(() -> {\n+                Tuple<BytesReference, SecretKey> newDEK = DEKGenerator.get();\n+                // store the newly generated DEK before making it available\n+                storeDEK(newDEK.v1().utf8ToString(), newDEK.v2());\n+                return newDEK;\n+            });\n+        }\n+\n+        // pkg-private for tests\n+        SecretKey getDEKById(String DEKId) throws IOException {\n+            try {\n+                return DEKCache.computeIfAbsent(DEKId, ignored -> loadDEK(DEKId));\n+            } catch (ExecutionException e) {\n+                // some exception types are to be expected\n+                if (e.getCause() instanceof IOException) {\n+                    throw (IOException) e.getCause();\n+                } else if (e.getCause() instanceof ElasticsearchException) {\n+                    throw (ElasticsearchException) e.getCause();\n+                } else {\n+                    throw new RepositoryException(repositoryName, \"Unexpected exception retrieving DEK [\" + DEKId + \"]\", e);\n+                }\n+            }\n+        }\n+\n+        private SecretKey loadDEK(String DEKId) throws IOException {\n+            final BlobPath DEKBlobPath = delegatedBasePath.add(DEK_ROOT_CONTAINER).add(DEKId);\n+            logger.debug(\"Repository [{}] loading wrapped DEK [{}] from blob path {}\", repositoryName, DEKId, DEKBlobPath);\n+            final BlobContainer DEKBlobContainer = delegatedBlobStore.blobContainer(DEKBlobPath);\n+            final Tuple<String, SecretKey> KEK = getKEKforDEK.apply(DEKId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eac6bfd83a87e37cf5f0f1e83dca50156a1bf31"}, "originalPosition": 428}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM1OTkyMzA5", "url": "https://github.com/elastic/elasticsearch/pull/53352#pullrequestreview-435992309", "createdAt": "2020-06-23T17:18:06Z", "commit": {"oid": "dd3e8fba4c9e633ce015b4a87e2c011e7471aac0"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxNzoxODowNlrOGnzBUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxNzoxODowNlrOGnzBUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM4MzU2OA==", "bodyText": "@tvernum regarding your inquiry about encrypted repo versioning:\nEncrypted blobs have only the DEK Id (plaintext UUID) prepended, so the repo currently doesn't support snapshots of multiple versions. If we plan that future encrypted repos be backwards compatible with the current version, in a way that the new version be able to work with a repo of the current version, then we might be in trouble.  In this case, any given snapshot can technically contain blobs encrypted in multiple versions, so we have to rely on the encrypted blob itself to specify which version of the repo encryption \"scheme\" to use (when decrypting, i.e. snapshot restore).\nI will be adding this item to the list from #41910 . I concur we mustn't release before we have some way to accommodate possible future versions of the repo.\nBut, blob level versioning is tricky. I remember I coded serialisation of version headers tacked on encrypted blobs. Probably the version header must be authenticated, but not encrypted. All that is messy and I really appreciate the simplicity of just prepending a plaintext UUID to the encrypted blob (the current approach).\nI think prepending a \"magic byte\" to the UUID (which prepends the encrypted blobs) should be enough. Future versions might have a different value for the magic byte (which they might need to authenticate but not encrypt) and they might not even need one because they would infer the DEK by some other, more efficient,  means (eg. a snapshot-level dictionary of blob name to DEK content).", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r444383568", "createdAt": "2020-06-23T17:18:06Z", "author": {"login": "albertzaharovits"}, "path": "x-pack/plugin/repository-encrypted/src/main/java/org/elasticsearch/repositories/encrypted/EncryptedRepository.java", "diffHunk": "@@ -6,11 +6,694 @@\n \n package org.elasticsearch.repositories.encrypted;\n \n-public class EncryptedRepository {\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.lucene.index.IndexCommit;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.metadata.RepositoryMetadata;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.CheckedFunction;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.blobstore.BlobContainer;\n+import org.elasticsearch.common.blobstore.BlobMetadata;\n+import org.elasticsearch.common.blobstore.BlobPath;\n+import org.elasticsearch.common.blobstore.BlobStore;\n+import org.elasticsearch.common.blobstore.DeleteResult;\n+import org.elasticsearch.common.blobstore.support.AbstractBlobContainer;\n+import org.elasticsearch.common.bytes.BytesArray;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.cache.Cache;\n+import org.elasticsearch.common.cache.CacheBuilder;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.io.Streams;\n+import org.elasticsearch.common.settings.SecureString;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.index.store.Store;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoryData;\n+import org.elasticsearch.repositories.RepositoryException;\n+import org.elasticsearch.repositories.RepositoryStats;\n+import org.elasticsearch.repositories.ShardGenerations;\n+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.SnapshotInfo;\n+import org.elasticsearch.snapshots.SnapshotShardFailure;\n+\n+import javax.crypto.KeyGenerator;\n+import javax.crypto.SecretKey;\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.NoSuchFileException;\n+import java.security.GeneralSecurityException;\n+import java.security.SecureRandom;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+public class EncryptedRepository extends BlobStoreRepository {\n+    static final Logger logger = LogManager.getLogger(EncryptedRepository.class);\n+    // the following constants are fixed by definition\n     static final int GCM_TAG_LENGTH_IN_BYTES = 16;\n     static final int GCM_IV_LENGTH_IN_BYTES = 12;\n-    static final int AES_BLOCK_SIZE_IN_BYTES = 128;\n+    static final int AES_BLOCK_LENGTH_IN_BYTES = 128;\n+    // the following constants require careful thought before changing because they will break backwards compatibility\n     static final String DATA_ENCRYPTION_SCHEME = \"AES/GCM/NoPadding\";\n     static final long PACKET_START_COUNTER = Long.MIN_VALUE;\n-    static final int MAX_PACKET_LENGTH_IN_BYTES = 1 << 30;\n+    static final int MAX_PACKET_LENGTH_IN_BYTES = 8 << 20; // 8MB\n+    // this should be smaller than {@code #MAX_PACKET_LENGTH_IN_BYTES} and it's what {@code EncryptionPacketsInputStream} uses\n+    // during encryption and what {@code DecryptionPacketsInputStream} expects during decryption (it is not configurable)\n+    static final int PACKET_LENGTH_IN_BYTES = 64 * (1 << 10); // 64KB\n+    // the path of the blob container holding all the DEKs\n+    // this is relative to the root base path holding the encrypted blobs (i.e. the repository root base path)\n+    static final String DEK_ROOT_CONTAINER = \".encryption-metadata\"; // package private for tests\n+    static final int DEK_ID_LENGTH = 22; // {@code org.elasticsearch.common.UUIDS} length\n+\n+    // the following constants can be changed freely\n+    private static final String RAND_ALGO = \"SHA1PRNG\";\n+\n+    // the snapshot metadata (residing in the cluster state for the lifetime of the snapshot)\n+    // contains the salted hash of the repository password as present on the master node (which starts the snapshot operation).\n+    // The hash is verified on each data node, before initiating the actual shard files snapshot, as well\n+    // as on the master node that finalizes the snapshot (which could be a different master node from the one that started\n+    // the operation if a master failover occurred during the snapshot).\n+    // This ensures that all participating nodes in the snapshot operation agree on the value of the key encryption key, so that\n+    // all the data included in a snapshot is encrypted using the same password.\n+    static final String PASSWORD_HASH_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordHash\";\n+    static final String PASSWORD_SALT_USER_METADATA_KEY = EncryptedRepository.class.getName() + \".repositoryPasswordSalt\";\n+    private static final int DEK_CACHE_WEIGHT = 2048;\n+\n+    // this is the repository instance to which all blob reads and writes are forwarded to (it stores both the encrypted blobs, as well\n+    // as the associated encrypted DEKs)\n+    private final BlobStoreRepository delegatedRepository;\n+    // every data blob is encrypted with its randomly generated AES key (DEK)\n+    private final Supplier<Tuple<BytesReference, SecretKey>> dekGenerator;\n+    // license is checked before every snapshot operations; protected non-final for tests\n+    protected Supplier<XPackLicenseState> licenseStateSupplier;\n+    private final SecureString repositoryPassword;\n+    private final String localRepositoryPasswordHash;\n+    private final String localRepositoryPasswordSalt;\n+    private volatile String validatedLocalRepositoryPasswordHash;\n+    private final Cache<String, SecretKey> dekCache;\n+\n+    /**\n+     * Returns the byte length (i.e. the storage size) of an encrypted blob, given the length of the blob's plaintext contents.\n+     *\n+     * @see EncryptionPacketsInputStream#getEncryptionLength(long, int)\n+     */\n+    public static long getEncryptedBlobByteLength(long plaintextBlobByteLength) {\n+        return (long) DEK_ID_LENGTH /* UUID byte length */\n+            + EncryptionPacketsInputStream.getEncryptionLength(plaintextBlobByteLength, PACKET_LENGTH_IN_BYTES);\n+    }\n+\n+    protected EncryptedRepository(\n+        RepositoryMetadata metadata,\n+        NamedXContentRegistry namedXContentRegistry,\n+        ClusterService clusterService,\n+        BlobStoreRepository delegatedRepository,\n+        Supplier<XPackLicenseState> licenseStateSupplier,\n+        SecureString repositoryPassword\n+    ) throws GeneralSecurityException {\n+        super(\n+            metadata,\n+            namedXContentRegistry,\n+            clusterService,\n+            BlobPath.cleanPath() /* the encrypted repository uses a hardcoded empty\n+                                 base blob path but the base path setting is honored for the delegated repository */\n+        );\n+        this.delegatedRepository = delegatedRepository;\n+        this.dekGenerator = createDEKGenerator();\n+        this.licenseStateSupplier = licenseStateSupplier;\n+        this.repositoryPassword = repositoryPassword;\n+        // the salt used to generate an irreversible \"hash\"; it is generated randomly but it's fixed for the lifetime of the\n+        // repository solely for efficiency reasons\n+        this.localRepositoryPasswordSalt = UUIDs.randomBase64UUID();\n+        // the \"hash\" of the repository password from the local node is not actually a hash but the ciphertext of a\n+        // known-plaintext using a key derived from the repository password using a random salt\n+        this.localRepositoryPasswordHash = AESKeyUtils.computeId(\n+            AESKeyUtils.generatePasswordBasedKey(repositoryPassword, localRepositoryPasswordSalt)\n+        );\n+        // a \"hash\" computed locally is also locally trusted (trivially)\n+        this.validatedLocalRepositoryPasswordHash = this.localRepositoryPasswordHash;\n+        // stores decrypted DEKs; DEKs are reused to encrypt/decrypt multiple independent blobs\n+        this.dekCache = CacheBuilder.<String, SecretKey>builder().setMaximumWeight(DEK_CACHE_WEIGHT).build();\n+        if (isReadOnly() != delegatedRepository.isReadOnly()) {\n+            throw new RepositoryException(\n+                metadata.name(),\n+                \"Unexpected fatal internal error\",\n+                new IllegalStateException(\"The encrypted repository must be read-only iff the delegate repository is read-only\")\n+            );\n+        }\n+    }\n+\n+    @Override\n+    public RepositoryStats stats() {\n+        return this.delegatedRepository.stats();\n+    }\n+\n+    /**\n+     * The repository hook method which populates the snapshot metadata with the salted password hash of the repository on the (master)\n+     * node that starts of the snapshot operation. All the other actions associated with the same snapshot operation will first verify\n+     * that the local repository password checks with the hash from the snapshot metadata.\n+     * <p>\n+     * In addition, if the installed license does not comply with the \"encrypted snapshots\" feature, this method throws an exception,\n+     * which aborts the snapshot operation.\n+     *\n+     * See {@link org.elasticsearch.repositories.Repository#adaptUserMetadata(Map)}.\n+     *\n+     * @param userMetadata the snapshot metadata as received from the calling user\n+     * @return the snapshot metadata containing the salted password hash of the node initializing the snapshot\n+     */\n+    @Override\n+    public Map<String, Object> adaptUserMetadata(Map<String, Object> userMetadata) {\n+        // because populating the snapshot metadata must be done before the actual snapshot is first initialized,\n+        // we take the opportunity to validate the license and abort if non-compliant\n+        if (false == licenseStateSupplier.get().isAllowed(XPackLicenseState.Feature.ENCRYPTED_SNAPSHOT)) {\n+            throw LicenseUtils.newComplianceException(\"encrypted snapshots\");\n+        }\n+        Map<String, Object> snapshotUserMetadata = new HashMap<>();\n+        if (userMetadata != null) {\n+            snapshotUserMetadata.putAll(userMetadata);\n+        }\n+        // fill in the hash of the repository password, which is then checked before every snapshot operation\n+        // (i.e. {@link #snapshotShard} and {@link #finalizeSnapshot}) to ensure that all participating nodes\n+        // in the snapshot operation use the same repository password\n+        snapshotUserMetadata.put(PASSWORD_SALT_USER_METADATA_KEY, localRepositoryPasswordSalt);\n+        snapshotUserMetadata.put(PASSWORD_HASH_USER_METADATA_KEY, localRepositoryPasswordHash);\n+        logger.trace(\n+            \"Snapshot metadata for local repository password  [{}] and [{}]\",\n+            localRepositoryPasswordSalt,\n+            localRepositoryPasswordHash\n+        );\n+        return Map.copyOf(snapshotUserMetadata);\n+    }\n+\n+    @Override\n+    public void finalizeSnapshot(\n+        SnapshotId snapshotId,\n+        ShardGenerations shardGenerations,\n+        long startTime,\n+        String failure,\n+        int totalShards,\n+        List<SnapshotShardFailure> shardFailures,\n+        long repositoryStateId,\n+        boolean includeGlobalState,\n+        Metadata clusterMetadata,\n+        Map<String, Object> userMetadata,\n+        Version repositoryMetaVersion,\n+        Function<ClusterState, ClusterState> stateTransformer,\n+        ActionListener<Tuple<RepositoryData, SnapshotInfo>> listener\n+    ) {\n+        try {\n+            validateLocalRepositorySecret(userMetadata);\n+        } catch (RepositoryException passwordValidationException) {\n+            listener.onFailure(passwordValidationException);\n+            return;\n+        } finally {\n+            // remove the repository password hash (and salt) from the snapshot metadata so that it is not displayed in the API response\n+            // to the user\n+            userMetadata = new HashMap<>(userMetadata);\n+            userMetadata.remove(PASSWORD_HASH_USER_METADATA_KEY);\n+            userMetadata.remove(PASSWORD_SALT_USER_METADATA_KEY);\n+        }\n+        super.finalizeSnapshot(\n+            snapshotId,\n+            shardGenerations,\n+            startTime,\n+            failure,\n+            totalShards,\n+            shardFailures,\n+            repositoryStateId,\n+            includeGlobalState,\n+            clusterMetadata,\n+            userMetadata,\n+            repositoryMetaVersion,\n+            stateTransformer,\n+            listener\n+        );\n+    }\n+\n+    @Override\n+    public void snapshotShard(\n+        Store store,\n+        MapperService mapperService,\n+        SnapshotId snapshotId,\n+        IndexId indexId,\n+        IndexCommit snapshotIndexCommit,\n+        String shardStateIdentifier,\n+        IndexShardSnapshotStatus snapshotStatus,\n+        Version repositoryMetaVersion,\n+        Map<String, Object> userMetadata,\n+        ActionListener<String> listener\n+    ) {\n+        try {\n+            validateLocalRepositorySecret(userMetadata);\n+        } catch (RepositoryException passwordValidationException) {\n+            listener.onFailure(passwordValidationException);\n+            return;\n+        }\n+        super.snapshotShard(\n+            store,\n+            mapperService,\n+            snapshotId,\n+            indexId,\n+            snapshotIndexCommit,\n+            shardStateIdentifier,\n+            snapshotStatus,\n+            repositoryMetaVersion,\n+            userMetadata,\n+            listener\n+        );\n+    }\n+\n+    @Override\n+    protected BlobStore createBlobStore() {\n+        final Supplier<Tuple<BytesReference, SecretKey>> blobStoreDEKGenerator;\n+        if (isReadOnly()) {\n+            // make sure that a read-only repository can't encrypt anything\n+            blobStoreDEKGenerator = () -> {\n+                throw new RepositoryException(\n+                    metadata.name(),\n+                    \"Unexpected fatal internal error\",\n+                    new IllegalStateException(\"DEKs are required for encryption but this is a read-only repository\")\n+                );\n+            };\n+        } else {\n+            blobStoreDEKGenerator = this.dekGenerator;\n+        }\n+        return new EncryptedBlobStore(\n+            delegatedRepository.blobStore(),\n+            delegatedRepository.basePath(),\n+            metadata.name(),\n+            this::generateKEK,\n+            blobStoreDEKGenerator,\n+            dekCache\n+        );\n+    }\n+\n+    @Override\n+    protected void doStart() {\n+        this.delegatedRepository.start();\n+        super.doStart();\n+    }\n+\n+    @Override\n+    protected void doStop() {\n+        super.doStop();\n+        this.delegatedRepository.stop();\n+    }\n+\n+    @Override\n+    protected void doClose() {\n+        super.doClose();\n+        this.delegatedRepository.close();\n+    }\n+\n+    private Supplier<Tuple<BytesReference, SecretKey>> createDEKGenerator() throws GeneralSecurityException {\n+        // DEK and DEK Ids MUST be generated randomly (with independent random instances)\n+        final SecureRandom dekSecureRandom = SecureRandom.getInstance(RAND_ALGO);\n+        final SecureRandom dekIdSecureRandom = SecureRandom.getInstance(RAND_ALGO);\n+        final KeyGenerator dekGenerator = KeyGenerator.getInstance(DATA_ENCRYPTION_SCHEME.split(\"/\")[0]);\n+        dekGenerator.init(AESKeyUtils.KEY_LENGTH_IN_BYTES * Byte.SIZE, dekSecureRandom);\n+        return () -> {\n+            final BytesReference dekId = new BytesArray(UUIDs.randomBase64UUID(dekIdSecureRandom));\n+            final SecretKey dek = dekGenerator.generateKey();\n+            logger.debug(\"Repository [{}] generated new DEK [{}]\", metadata.name(), dekId);\n+            return new Tuple<>(dekId, dek);\n+        };\n+    }\n+\n+    // pkg-private for tests\n+    Tuple<String, SecretKey> generateKEK(String dekId) {\n+        try {\n+            // we rely on the DEK Id being generated randomly so it can be used as a salt\n+            final SecretKey kek = AESKeyUtils.generatePasswordBasedKey(repositoryPassword, dekId);\n+            final String kekId = AESKeyUtils.computeId(kek);\n+            logger.debug(\"Repository [{}] computed KEK [{}] for DEK [{}]\", metadata.name(), kekId, dekId);\n+            return new Tuple<>(kekId, kek);\n+        } catch (GeneralSecurityException e) {\n+            throw new RepositoryException(metadata.name(), \"Failure to generate KEK to wrap the DEK [\" + dekId + \"]\", e);\n+        }\n+    }\n+\n+    /**\n+     * Called before the shard snapshot and finalize operations, on the data and master nodes. This validates that the repository\n+     * password on the master node that started the snapshot operation is identical to the repository password on the local node.\n+     *\n+     * @param snapshotUserMetadata the snapshot metadata containing the repository password hash to assert\n+     * @throws RepositoryException if the repository password hash on the local node mismatches the master's\n+     */\n+    private void validateLocalRepositorySecret(Map<String, Object> snapshotUserMetadata) throws RepositoryException {\n+        assert snapshotUserMetadata != null;\n+        assert snapshotUserMetadata.get(PASSWORD_HASH_USER_METADATA_KEY) instanceof String;\n+        final String masterRepositoryPasswordId = (String) snapshotUserMetadata.get(PASSWORD_HASH_USER_METADATA_KEY);\n+        if (false == masterRepositoryPasswordId.equals(validatedLocalRepositoryPasswordHash)) {\n+            assert snapshotUserMetadata.get(PASSWORD_SALT_USER_METADATA_KEY) instanceof String;\n+            final String masterRepositoryPasswordIdSalt = (String) snapshotUserMetadata.get(PASSWORD_SALT_USER_METADATA_KEY);\n+            final String computedRepositoryPasswordId;\n+            try {\n+                computedRepositoryPasswordId = AESKeyUtils.computeId(\n+                    AESKeyUtils.generatePasswordBasedKey(repositoryPassword, masterRepositoryPasswordIdSalt)\n+                );\n+            } catch (Exception e) {\n+                throw new RepositoryException(metadata.name(), \"Unexpected fatal internal error\", e);\n+            }\n+            if (computedRepositoryPasswordId.equals(masterRepositoryPasswordId)) {\n+                this.validatedLocalRepositoryPasswordHash = computedRepositoryPasswordId;\n+            } else {\n+                throw new RepositoryException(\n+                    metadata.name(),\n+                    \"Repository password mismatch. The local node's repository password, from the keystore setting [\"\n+                        + EncryptedRepositoryPlugin.ENCRYPTION_PASSWORD_SETTING.getConcreteSettingForNamespace(\n+                            EncryptedRepositoryPlugin.PASSWORD_NAME_SETTING.get(metadata.settings())\n+                        ).getKey()\n+                        + \"], is different compared to the elected master node's which started the snapshot operation\"\n+                );\n+            }\n+        }\n+    }\n+\n+    // pkg-private for tests\n+    static final class EncryptedBlobStore implements BlobStore {\n+        private final BlobStore delegatedBlobStore;\n+        private final BlobPath delegatedBasePath;\n+        private final String repositoryName;\n+        private final Function<String, Tuple<String, SecretKey>> getKEKforDEK;\n+        private final Cache<String, SecretKey> dekCache;\n+        private final CheckedSupplier<SingleUseKey, IOException> singleUseDEKSupplier;\n+\n+        EncryptedBlobStore(\n+            BlobStore delegatedBlobStore,\n+            BlobPath delegatedBasePath,\n+            String repositoryName,\n+            Function<String, Tuple<String, SecretKey>> getKEKforDEK,\n+            Supplier<Tuple<BytesReference, SecretKey>> dekGenerator,\n+            Cache<String, SecretKey> dekCache\n+        ) {\n+            this.delegatedBlobStore = delegatedBlobStore;\n+            this.delegatedBasePath = delegatedBasePath;\n+            this.repositoryName = repositoryName;\n+            this.getKEKforDEK = getKEKforDEK;\n+            this.dekCache = dekCache;\n+            this.singleUseDEKSupplier = SingleUseKey.createSingleUseKeySupplier(() -> {\n+                Tuple<BytesReference, SecretKey> newDEK = dekGenerator.get();\n+                // store the newly generated DEK before making it available\n+                storeDEK(newDEK.v1().utf8ToString(), newDEK.v2());\n+                return newDEK;\n+            });\n+        }\n+\n+        // pkg-private for tests\n+        SecretKey getDEKById(String dekId) throws IOException {\n+            try {\n+                return dekCache.computeIfAbsent(dekId, ignored -> loadDEK(dekId));\n+            } catch (ExecutionException e) {\n+                // some exception types are to be expected\n+                if (e.getCause() instanceof IOException) {\n+                    throw (IOException) e.getCause();\n+                } else if (e.getCause() instanceof ElasticsearchException) {\n+                    throw (ElasticsearchException) e.getCause();\n+                } else {\n+                    throw new RepositoryException(repositoryName, \"Unexpected exception retrieving DEK [\" + dekId + \"]\", e);\n+                }\n+            }\n+        }\n+\n+        private SecretKey loadDEK(String dekId) throws IOException {\n+            final BlobPath dekBlobPath = delegatedBasePath.add(DEK_ROOT_CONTAINER).add(dekId);\n+            logger.debug(\"Repository [{}] loading wrapped DEK [{}] from blob path {}\", repositoryName, dekId, dekBlobPath);\n+            final BlobContainer dekBlobContainer = delegatedBlobStore.blobContainer(dekBlobPath);\n+            final Tuple<String, SecretKey> kekTuple = getKEKforDEK.apply(dekId);\n+            final String kekId = kekTuple.v1();\n+            final SecretKey kek = kekTuple.v2();\n+            logger.trace(\"Repository [{}] using KEK [{}] to unwrap DEK [{}]\", repositoryName, kekId, dekId);\n+            final byte[] encryptedDEKBytes = new byte[AESKeyUtils.WRAPPED_KEY_LENGTH_IN_BYTES];\n+            try (InputStream encryptedDEKInputStream = dekBlobContainer.readBlob(kekId)) {\n+                final int bytesRead = Streams.readFully(encryptedDEKInputStream, encryptedDEKBytes);\n+                if (bytesRead != AESKeyUtils.WRAPPED_KEY_LENGTH_IN_BYTES) {\n+                    throw new RepositoryException(\n+                        repositoryName,\n+                        \"Wrapped DEK [\" + dekId + \"] has smaller length [\" + bytesRead + \"] than expected\"\n+                    );\n+                }\n+                if (encryptedDEKInputStream.read() != -1) {\n+                    throw new RepositoryException(repositoryName, \"Wrapped DEK [\" + dekId + \"] is larger than expected\");\n+                }\n+            } catch (NoSuchFileException e) {\n+                // do NOT throw IOException when the DEK does not exist, as this is a decryption problem, and IOExceptions\n+                // can move the repository in the corrupted state\n+                throw new ElasticsearchException(\n+                    \"Failure to read and decrypt DEK [\"\n+                        + dekId\n+                        + \"] from \"\n+                        + dekBlobContainer.path()\n+                        + \". Most likely the repository password is incorrect, where previous \"\n+                        + \"snapshots have used a different password.\",\n+                    e\n+                );\n+            }\n+            logger.trace(\"Repository [{}] successfully read DEK [{}] from path {} {}\", repositoryName, dekId, dekBlobPath, kekId);\n+            try {\n+                final SecretKey dek = AESKeyUtils.unwrap(kek, encryptedDEKBytes);\n+                logger.debug(\"Repository [{}] successfully loaded DEK [{}] from path {} {}\", repositoryName, dekId, dekBlobPath, kekId);\n+                return dek;\n+            } catch (GeneralSecurityException e) {\n+                throw new RepositoryException(\n+                    repositoryName,\n+                    \"Failure to AES unwrap the DEK [\"\n+                        + dekId\n+                        + \"]. \"\n+                        + \"Most likely the encryption metadata in the repository has been corrupted\",\n+                    e\n+                );\n+            }\n+        }\n+\n+        // pkg-private for tests\n+        void storeDEK(String dekId, SecretKey dek) throws IOException {\n+            final BlobPath dekBlobPath = delegatedBasePath.add(DEK_ROOT_CONTAINER).add(dekId);\n+            logger.debug(\"Repository [{}] storing wrapped DEK [{}] under blob path {}\", repositoryName, dekId, dekBlobPath);\n+            final BlobContainer dekBlobContainer = delegatedBlobStore.blobContainer(dekBlobPath);\n+            final Tuple<String, SecretKey> kek = getKEKforDEK.apply(dekId);\n+            logger.trace(\"Repository [{}] using KEK [{}] to wrap DEK [{}]\", repositoryName, kek.v1(), dekId);\n+            final byte[] encryptedDEKBytes;\n+            try {\n+                encryptedDEKBytes = AESKeyUtils.wrap(kek.v2(), dek);\n+                if (encryptedDEKBytes.length != AESKeyUtils.WRAPPED_KEY_LENGTH_IN_BYTES) {\n+                    throw new RepositoryException(\n+                        repositoryName,\n+                        \"Wrapped DEK [\" + dekId + \"] has unexpected length [\" + encryptedDEKBytes.length + \"]\"\n+                    );\n+                }\n+            } catch (GeneralSecurityException e) {\n+                // throw unchecked ElasticsearchException; IOExceptions are interpreted differently and can move the repository in the\n+                // corrupted state\n+                throw new RepositoryException(repositoryName, \"Failure to AES wrap the DEK [\" + dekId + \"]\", e);\n+            }\n+            logger.trace(\"Repository [{}] successfully wrapped DEK [{}]\", repositoryName, dekId);\n+            try (InputStream encryptedDEKInputStream = new ByteArrayInputStream(encryptedDEKBytes)) {\n+                dekBlobContainer.writeBlobAtomic(kek.v1(), encryptedDEKInputStream, encryptedDEKBytes.length, true);\n+            }\n+            logger.debug(\"Repository [{}] successfully stored DEK [{}] under path {} {}\", repositoryName, dekId, dekBlobPath, kek.v1());\n+        }\n+\n+        @Override\n+        public BlobContainer blobContainer(BlobPath path) {\n+            final Iterator<String> pathIterator = path.iterator();\n+            BlobPath delegatedBlobContainerPath = delegatedBasePath;\n+            while (pathIterator.hasNext()) {\n+                delegatedBlobContainerPath = delegatedBlobContainerPath.add(pathIterator.next());\n+            }\n+            final BlobContainer delegatedBlobContainer = delegatedBlobStore.blobContainer(delegatedBlobContainerPath);\n+            return new EncryptedBlobContainer(path, repositoryName, delegatedBlobContainer, singleUseDEKSupplier, this::getDEKById);\n+        }\n+\n+        @Override\n+        public void close() {\n+            // do NOT close delegatedBlobStore; it will be closed when the inner delegatedRepository is closed\n+        }\n+    }\n+\n+    private static final class EncryptedBlobContainer extends AbstractBlobContainer {\n+        private final String repositoryName;\n+        private final BlobContainer delegatedBlobContainer;\n+        // supplier for the DEK used for encryption (snapshot)\n+        private final CheckedSupplier<SingleUseKey, IOException> singleUseDEKSupplier;\n+        // retrieves the DEK required for decryption (restore)\n+        private final CheckedFunction<String, SecretKey, IOException> getDEKById;\n+\n+        EncryptedBlobContainer(\n+            BlobPath path, // this path contains the {@code EncryptedRepository#basePath} which, importantly, is empty\n+            String repositoryName,\n+            BlobContainer delegatedBlobContainer,\n+            CheckedSupplier<SingleUseKey, IOException> singleUseDEKSupplier,\n+            CheckedFunction<String, SecretKey, IOException> getDEKById\n+        ) {\n+            super(path);\n+            this.repositoryName = repositoryName;\n+            final String rootPathElement = path.iterator().hasNext() ? path.iterator().next() : null;\n+            if (DEK_ROOT_CONTAINER.equals(rootPathElement)) {\n+                throw new RepositoryException(repositoryName, \"Cannot descend into the DEK blob container \" + path);\n+            }\n+            this.delegatedBlobContainer = delegatedBlobContainer;\n+            this.singleUseDEKSupplier = singleUseDEKSupplier;\n+            this.getDEKById = getDEKById;\n+        }\n+\n+        /**\n+         * Returns a new {@link InputStream} for the given {@code blobName} that can be used to read the contents of the blob.\n+         * The returned {@code InputStream} transparently handles the decryption of the blob contents, by first working out\n+         * the blob name of the associated DEK id, reading and decrypting the DEK (given the repository password, unless the DEK is\n+         * already cached because it had been used for other blobs before), and lastly reading and decrypting the data blob,\n+         * in a streaming fashion, by employing the {@link DecryptionPacketsInputStream}.\n+         * The {@code DecryptionPacketsInputStream} does not return un-authenticated data.\n+         *\n+         * @param   blobName The name of the blob to get an {@link InputStream} for.\n+         */\n+        @Override\n+        public InputStream readBlob(String blobName) throws IOException {\n+            // This MIGHT require two concurrent readBlob connections if the DEK is not already in the cache and if the encrypted blob\n+            // is large enough so that the underlying network library keeps the connection open after reading the prepended DEK ID.\n+            // Arguably this is a problem only under lab conditions, when the storage service is saturated only by the first read\n+            // connection of the pair, so that the second read connection (for the DEK) can not be fulfilled.\n+            // In this case the second connection will time-out which will trigger the closing of the first one, therefore\n+            // allowing other pair connections to complete.\n+            // In this situation the restore process should slowly make headway, albeit under read-timeout exceptions\n+            final InputStream encryptedDataInputStream = delegatedBlobContainer.readBlob(blobName);\n+            try {\n+                // read the DEK Id (fixed length) which is prepended to the encrypted blob\n+                final byte[] dekIdBytes = new byte[DEK_ID_LENGTH];\n+                final int bytesRead = Streams.readFully(encryptedDataInputStream, dekIdBytes);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dd3e8fba4c9e633ce015b4a87e2c011e7471aac0"}, "originalPosition": 578}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQwNTYyNDY2", "url": "https://github.com/elastic/elasticsearch/pull/53352#pullrequestreview-440562466", "createdAt": "2020-07-01T05:49:51Z", "commit": {"oid": "dd3e8fba4c9e633ce015b4a87e2c011e7471aac0"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQwNTo0OTo1MVrOGrXpIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQwNTo0OTo1MVrOGrXpIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODEyOTMxMw==", "bodyText": "Should we not also verify that the id is constant? That is\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    assertThat(AESKeyUtils.computeId(key1), not(equalTo(AESKeyUtils.computeId(key2))));\n          \n          \n            \n                    assertThat(AESKeyUtils.computeId(key1), not(equalTo(AESKeyUtils.computeId(key2))));\n          \n          \n            \n                    assertThat(AESKeyUtils.computeId(key1), equalTo(AESKeyUtils.computeId(key1)));\n          \n          \n            \n                    assertThat(AESKeyUtils.computeId(key2), equalTo(AESKeyUtils.computeId(key2)));", "url": "https://github.com/elastic/elasticsearch/pull/53352#discussion_r448129313", "createdAt": "2020-07-01T05:49:51Z", "author": {"login": "tvernum"}, "path": "x-pack/plugin/repository-encrypted/src/test/java/org/elasticsearch/repositories/encrypted/AESKeyUtilsTests.java", "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.repositories.encrypted;\n+\n+import org.elasticsearch.test.ESTestCase;\n+\n+import javax.crypto.SecretKey;\n+import javax.crypto.spec.SecretKeySpec;\n+\n+import java.security.InvalidKeyException;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.not;\n+\n+public class AESKeyUtilsTests extends ESTestCase {\n+\n+    public void testWrapUnwrap() throws Exception {\n+        byte[] keyToWrapBytes = randomByteArrayOfLength(AESKeyUtils.KEY_LENGTH_IN_BYTES);\n+        SecretKey keyToWrap = new SecretKeySpec(keyToWrapBytes, \"AES\");\n+        byte[] wrappingKeyBytes = randomByteArrayOfLength(AESKeyUtils.KEY_LENGTH_IN_BYTES);\n+        SecretKey wrappingKey = new SecretKeySpec(wrappingKeyBytes, \"AES\");\n+        byte[] wrappedKey = AESKeyUtils.wrap(wrappingKey, keyToWrap);\n+        assertThat(wrappedKey.length, equalTo(AESKeyUtils.WRAPPED_KEY_LENGTH_IN_BYTES));\n+        SecretKey unwrappedKey = AESKeyUtils.unwrap(wrappingKey, wrappedKey);\n+        assertThat(unwrappedKey, equalTo(keyToWrap));\n+    }\n+\n+    public void testComputeId() throws Exception {\n+        byte[] key1Bytes = randomByteArrayOfLength(AESKeyUtils.KEY_LENGTH_IN_BYTES);\n+        SecretKey key1 = new SecretKeySpec(key1Bytes, \"AES\");\n+        byte[] key2Bytes = randomByteArrayOfLength(AESKeyUtils.KEY_LENGTH_IN_BYTES);\n+        SecretKey key2 = new SecretKeySpec(key2Bytes, \"AES\");\n+        assertThat(AESKeyUtils.computeId(key1), not(equalTo(AESKeyUtils.computeId(key2))));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dd3e8fba4c9e633ce015b4a87e2c011e7471aac0"}, "originalPosition": 37}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ac724cf797be2ff4c58337954fa4ca3ea521c4cd", "author": {"user": {"login": "albertzaharovits", "name": "Albert Zaharovits"}}, "url": "https://github.com/elastic/elasticsearch/commit/ac724cf797be2ff4c58337954fa4ca3ea521c4cd", "committedDate": "2020-11-25T23:41:15Z", "message": "Merge branch 'repository-encrypted-client-side' into reuse-DEKs-universally"}, "afterCommit": {"oid": "dd3e8fba4c9e633ce015b4a87e2c011e7471aac0", "author": {"user": {"login": "albertzaharovits", "name": "Albert Zaharovits"}}, "url": "https://github.com/elastic/elasticsearch/commit/dd3e8fba4c9e633ce015b4a87e2c011e7471aac0", "committedDate": "2020-06-23T14:05:46Z", "message": "Merge branch 'repository-encrypted-client-side' into reuse-DEKs-universally"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6a3dd25649418ec69f4ebb9962689cc485082207", "author": {"user": {"login": "albertzaharovits", "name": "Albert Zaharovits"}}, "url": "https://github.com/elastic/elasticsearch/commit/6a3dd25649418ec69f4ebb9962689cc485082207", "committedDate": "2020-11-28T14:37:49Z", "message": "Build gradle for cloud repos exports test jar"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9037d00ff061bb980eca2561db06bbd7703dfec8", "author": {"user": {"login": "albertzaharovits", "name": "Albert Zaharovits"}}, "url": "https://github.com/elastic/elasticsearch/commit/9037d00ff061bb980eca2561db06bbd7703dfec8", "committedDate": "2020-11-29T15:08:39Z", "message": "Repository integ tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cae71f2c1dd423f3bad033478953d7fc9874ba43", "author": {"user": {"login": "albertzaharovits", "name": "Albert Zaharovits"}}, "url": "https://github.com/elastic/elasticsearch/commit/cae71f2c1dd423f3bad033478953d7fc9874ba43", "committedDate": "2020-11-29T15:39:01Z", "message": "Barely sufficient license check"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "00308a952dcab13115c1a57d9dcb26e79009e014", "author": {"user": {"login": "albertzaharovits", "name": "Albert Zaharovits"}}, "url": "https://github.com/elastic/elasticsearch/commit/00308a952dcab13115c1a57d9dcb26e79009e014", "committedDate": "2020-11-29T15:42:07Z", "message": "Repository encrypted apply patch"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "467b36ba9aba9e7ce2b317e9193a3932942d5012", "author": {"user": {"login": "albertzaharovits", "name": "Albert Zaharovits"}}, "url": "https://github.com/elastic/elasticsearch/commit/467b36ba9aba9e7ce2b317e9193a3932942d5012", "committedDate": "2020-11-29T15:55:07Z", "message": "build.gradle modernize and \"enable integ tests\""}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d7c3298c9ca35bfd039fd9cf333810c79e8d80d8", "author": {"user": {"login": "albertzaharovits", "name": "Albert Zaharovits"}}, "url": "https://github.com/elastic/elasticsearch/commit/d7c3298c9ca35bfd039fd9cf333810c79e8d80d8", "committedDate": "2020-11-29T18:59:29Z", "message": "Compilation problems"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3ad727efece0ae42224ff40d82bd24c103d8a46d", "author": {"user": {"login": "albertzaharovits", "name": "Albert Zaharovits"}}, "url": "https://github.com/elastic/elasticsearch/commit/3ad727efece0ae42224ff40d82bd24c103d8a46d", "committedDate": "2020-11-29T19:01:40Z", "message": "Spotless"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "37fbd4c8acfcdc92c36001283007362618103e14", "author": {"user": {"login": "albertzaharovits", "name": "Albert Zaharovits"}}, "url": "https://github.com/elastic/elasticsearch/commit/37fbd4c8acfcdc92c36001283007362618103e14", "committedDate": "2020-11-30T07:41:19Z", "message": "Repository azure and repository gcs work"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "af03a92e40ed387122ddc143f095503c2a02b37a", "author": {"user": {"login": "albertzaharovits", "name": "Albert Zaharovits"}}, "url": "https://github.com/elastic/elasticsearch/commit/af03a92e40ed387122ddc143f095503c2a02b37a", "committedDate": "2020-11-30T19:53:09Z", "message": "Before moving the internal cluster tests to the dedicated source set"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0023f770b88f4084b2a29cad4cb1061d366c9765", "author": {"user": {"login": "albertzaharovits", "name": "Albert Zaharovits"}}, "url": "https://github.com/elastic/elasticsearch/commit/0023f770b88f4084b2a29cad4cb1061d366c9765", "committedDate": "2020-11-30T22:33:32Z", "message": "Hooray!"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "40dab2dbd28d6b81493c9b8fd8f8f02c2bdcc483", "author": {"user": {"login": "albertzaharovits", "name": "Albert Zaharovits"}}, "url": "https://github.com/elastic/elasticsearch/commit/40dab2dbd28d6b81493c9b8fd8f8f02c2bdcc483", "committedDate": "2020-11-30T22:53:52Z", "message": "More than one connection open at one time for ESMockAPIBasedRepo"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "dd3e8fba4c9e633ce015b4a87e2c011e7471aac0", "author": {"user": {"login": "albertzaharovits", "name": "Albert Zaharovits"}}, "url": "https://github.com/elastic/elasticsearch/commit/dd3e8fba4c9e633ce015b4a87e2c011e7471aac0", "committedDate": "2020-06-23T14:05:46Z", "message": "Merge branch 'repository-encrypted-client-side' into reuse-DEKs-universally"}, "afterCommit": {"oid": "40dab2dbd28d6b81493c9b8fd8f8f02c2bdcc483", "author": {"user": {"login": "albertzaharovits", "name": "Albert Zaharovits"}}, "url": "https://github.com/elastic/elasticsearch/commit/40dab2dbd28d6b81493c9b8fd8f8f02c2bdcc483", "committedDate": "2020-11-30T22:53:52Z", "message": "More than one connection open at one time for ESMockAPIBasedRepo"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6db2ca20173ac73a16d4d639b34c0b6844e0655f", "author": {"user": {"login": "albertzaharovits", "name": "Albert Zaharovits"}}, "url": "https://github.com/elastic/elasticsearch/commit/6db2ca20173ac73a16d4d639b34c0b6844e0655f", "committedDate": "2020-12-01T09:30:18Z", "message": "Merge branch 'repository-encrypted-client-side-reformated' into reuse-DEKs-universally-reformated"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e27502732ed18e42480cabf2e58aa44e3faff76d", "author": {"user": {"login": "albertzaharovits", "name": "Albert Zaharovits"}}, "url": "https://github.com/elastic/elasticsearch/commit/e27502732ed18e42480cabf2e58aa44e3faff76d", "committedDate": "2020-12-01T09:45:55Z", "message": "Hdfs compilation check"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e70b55db68e274a25cbd87a82a9e1bf383d3e71e", "author": {"user": {"login": "albertzaharovits", "name": "Albert Zaharovits"}}, "url": "https://github.com/elastic/elasticsearch/commit/e70b55db68e274a25cbd87a82a9e1bf383d3e71e", "committedDate": "2020-12-01T10:19:29Z", "message": "Checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6e346a1a11596b7accbdf7afbe8a79c7377078b3", "author": {"user": {"login": "albertzaharovits", "name": "Albert Zaharovits"}}, "url": "https://github.com/elastic/elasticsearch/commit/6e346a1a11596b7accbdf7afbe8a79c7377078b3", "committedDate": "2020-12-01T15:42:19Z", "message": "Nit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "50f97b1bf19852719740162b6954c8dd05300845", "author": {"user": {"login": "albertzaharovits", "name": "Albert Zaharovits"}}, "url": "https://github.com/elastic/elasticsearch/commit/50f97b1bf19852719740162b6954c8dd05300845", "committedDate": "2020-12-01T15:53:29Z", "message": "Update x-pack/plugin/repository-encrypted/src/test/java/org/elasticsearch/repositories/encrypted/AESKeyUtilsTests.java\n\nCo-authored-by: Tim Vernum <tim@adjective.org>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "97ad4d5d2877db80b7f7d78ec1eb3a7f3a7041e0", "author": {"user": {"login": "albertzaharovits", "name": "Albert Zaharovits"}}, "url": "https://github.com/elastic/elasticsearch/commit/97ad4d5d2877db80b7f7d78ec1eb3a7f3a7041e0", "committedDate": "2020-12-02T11:34:13Z", "message": "Hdfs integ tests do not preserve repo contents after delete"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c1585327cd885d2100e60a85f2cc9a810adf1476", "author": {"user": {"login": "albertzaharovits", "name": "Albert Zaharovits"}}, "url": "https://github.com/elastic/elasticsearch/commit/c1585327cd885d2100e60a85f2cc9a810adf1476", "committedDate": "2020-12-02T13:14:01Z", "message": "Merge branch 'repository-encrypted-client-side-reformated' into reuse-DEKs-universally-reformated"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1706, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}