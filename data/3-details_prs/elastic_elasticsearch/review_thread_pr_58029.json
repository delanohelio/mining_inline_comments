{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMzNTczOTY3", "number": 58029, "reviewThreads": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxMzoyOTo0OVrOEFDx1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQyMTowNDozOVrOEIh1Pw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNzQwMjQ0OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/cluster/ClusterInfo.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxMzoyOTo0OVrOGjD_wQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQxMDowMjoxMFrOGjrhMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQxODgxNw==", "bodyText": "use writeMap?", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r439418817", "createdAt": "2020-06-12T13:29:49Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/cluster/ClusterInfo.java", "diffHunk": "@@ -109,6 +127,14 @@ public void writeTo(StreamOutput out) throws IOException {\n             c.key.writeTo(out);\n             out.writeString(c.value);\n         }\n+\n+        if (out.getVersion().onOrAfter(StoreStats.RESERVED_BYTES_VERSION)) {\n+            out.writeVInt(this.reservedSpace.size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a6a7cc083e744897a58b57f0425e6f6970f082b"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2NjM1Mw==", "bodyText": "An ImmutableOpenMap isn't a Map \ud83d\ude22", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440066353", "createdAt": "2020-06-15T10:02:10Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/cluster/ClusterInfo.java", "diffHunk": "@@ -109,6 +127,14 @@ public void writeTo(StreamOutput out) throws IOException {\n             c.key.writeTo(out);\n             out.writeString(c.value);\n         }\n+\n+        if (out.getVersion().onOrAfter(StoreStats.RESERVED_BYTES_VERSION)) {\n+            out.writeVInt(this.reservedSpace.size());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQxODgxNw=="}, "originalCommit": {"oid": "4a6a7cc083e744897a58b57f0425e6f6970f082b"}, "originalPosition": 84}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNzQ5MjY4OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/index/shard/IndexShard.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxMzo1NjoxMFrOGjE5fA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQxMDoyMDoxOFrOGjsHXA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQzMzU5Ng==", "bodyText": "can we avoid going under the global mutex here? Perhaps by adding a method to recoveryState (which has its own synchronization).", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r439433596", "createdAt": "2020-06-12T13:56:10Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/index/shard/IndexShard.java", "diffHunk": "@@ -1004,8 +1004,24 @@ public GetStats getStats() {\n     }\n \n     public StoreStats storeStats() {\n+        final LongSupplier remainingRecoveryBytesSupplier;\n+        synchronized (mutex) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a6a7cc083e744897a58b57f0425e6f6970f082b"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2OTE4Ng==", "bodyText": "recoveryState is nonvolatile and assigned under mutex so I think we cannot avoid synchronising on mutex here. Note that we do almost no work under the mutex itself. Would you rather make recoveryState volatile?", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440069186", "createdAt": "2020-06-15T10:07:10Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/index/shard/IndexShard.java", "diffHunk": "@@ -1004,8 +1004,24 @@ public GetStats getStats() {\n     }\n \n     public StoreStats storeStats() {\n+        final LongSupplier remainingRecoveryBytesSupplier;\n+        synchronized (mutex) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQzMzU5Ng=="}, "originalCommit": {"oid": "4a6a7cc083e744897a58b57f0425e6f6970f082b"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA3NDE4Mw==", "bodyText": "yeah, I'd prefer that. I'm scared of stats calls going under this mutex, as we currently do some heavy operations under that mutex (e.g. flush on closing), which ofc we should not.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440074183", "createdAt": "2020-06-15T10:16:32Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/index/shard/IndexShard.java", "diffHunk": "@@ -1004,8 +1004,24 @@ public GetStats getStats() {\n     }\n \n     public StoreStats storeStats() {\n+        final LongSupplier remainingRecoveryBytesSupplier;\n+        synchronized (mutex) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQzMzU5Ng=="}, "originalCommit": {"oid": "4a6a7cc083e744897a58b57f0425e6f6970f082b"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA3NjEyNA==", "bodyText": "Ok I pushed a5275ed", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440076124", "createdAt": "2020-06-15T10:20:18Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/index/shard/IndexShard.java", "diffHunk": "@@ -1004,8 +1004,24 @@ public GetStats getStats() {\n     }\n \n     public StoreStats storeStats() {\n+        final LongSupplier remainingRecoveryBytesSupplier;\n+        synchronized (mutex) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQzMzU5Ng=="}, "originalCommit": {"oid": "4a6a7cc083e744897a58b57f0425e6f6970f082b"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNzUwNDg5OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/index/shard/IndexShard.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxMzo1ODozNFrOGjFBIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQxMDowNToxMlrOGjroBA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQzNTU1Mw==", "bodyText": "why 0 here instead of UNKNOWN_RESERVED_BYTES?", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r439435553", "createdAt": "2020-06-12T13:58:34Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/index/shard/IndexShard.java", "diffHunk": "@@ -1004,8 +1004,24 @@ public GetStats getStats() {\n     }\n \n     public StoreStats storeStats() {\n+        final LongSupplier remainingRecoveryBytesSupplier;\n+        synchronized (mutex) {\n+            if (recoveryState == null) {\n+                remainingRecoveryBytesSupplier = () -> 0L;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a6a7cc083e744897a58b57f0425e6f6970f082b"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2ODEwMA==", "bodyText": "Ah you're right, this indicates that recovery hasn't started, not that no recovery is required. I pushed 6a7060c.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440068100", "createdAt": "2020-06-15T10:05:12Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/index/shard/IndexShard.java", "diffHunk": "@@ -1004,8 +1004,24 @@ public GetStats getStats() {\n     }\n \n     public StoreStats storeStats() {\n+        final LongSupplier remainingRecoveryBytesSupplier;\n+        synchronized (mutex) {\n+            if (recoveryState == null) {\n+                remainingRecoveryBytesSupplier = () -> 0L;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQzNTU1Mw=="}, "originalCommit": {"oid": "4a6a7cc083e744897a58b57f0425e6f6970f082b"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0MTY2NjU3OnYy", "diffSide": "RIGHT", "path": "docs/reference/cluster/stats.asciidoc", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQwOTo0NDowNVrOGjq4cA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQxMTowMDo1MFrOGjtWYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA1NTkyMA==", "bodyText": "I think these stats will be cluster-wide and not per node?", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440055920", "createdAt": "2020-06-15T09:44:05Z", "author": {"login": "henningandersen"}, "path": "docs/reference/cluster/stats.asciidoc", "diffHunk": "@@ -231,6 +231,18 @@ Total size of all shards assigned to selected nodes.\n `size_in_bytes`::\n (integer)\n Total size, in bytes, of all shards assigned to selected nodes.\n+\n+`reserved`::\n+(<<byte-units,byte value>>)\n+A prediction of how much larger the shard stores on this node will eventually", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a6a7cc083e744897a58b57f0425e6f6970f082b"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA5NjM1NQ==", "bodyText": "Thanks, yes. Actually not quite cluster-wide since you can select a subset of nodes here but \"these nodes\" is awkward so I removed it in b89a567.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440096355", "createdAt": "2020-06-15T11:00:50Z", "author": {"login": "DaveCTurner"}, "path": "docs/reference/cluster/stats.asciidoc", "diffHunk": "@@ -231,6 +231,18 @@ Total size of all shards assigned to selected nodes.\n `size_in_bytes`::\n (integer)\n Total size, in bytes, of all shards assigned to selected nodes.\n+\n+`reserved`::\n+(<<byte-units,byte value>>)\n+A prediction of how much larger the shard stores on this node will eventually", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA1NTkyMA=="}, "originalCommit": {"oid": "4a6a7cc083e744897a58b57f0425e6f6970f082b"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0MTY5NjM5OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/cluster/InternalClusterInfoService.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQwOTo1MjowNlrOGjrK7g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwNjo0NDoxN1rOGoE__Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2MDY1NA==", "bodyText": "Is there an added race condition risk here? In that we risk using a cluster-info combined of an old reserved space and a new shard-sizes for making decisions and thus could be either under or over-estimating the usage?\nI think it would be nicer to encapsulate the two in one object that is then assigned once to a volatile field.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440060654", "createdAt": "2020-06-15T09:52:06Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/cluster/InternalClusterInfoService.java", "diffHunk": "@@ -318,15 +323,21 @@ public void onFailure(Exception e) {\n             }\n         });\n \n-        final CountDownLatch indicesLatch = updateIndicesStats(new ActionListener<IndicesStatsResponse>() {\n+        final CountDownLatch indicesLatch = updateIndicesStats(new ActionListener<>() {\n             @Override\n             public void onResponse(IndicesStatsResponse indicesStatsResponse) {\n-                ShardStats[] stats = indicesStatsResponse.getShards();\n-                ImmutableOpenMap.Builder<String, Long> newShardSizes = ImmutableOpenMap.builder();\n-                ImmutableOpenMap.Builder<ShardRouting, String> newShardRoutingToDataPath = ImmutableOpenMap.builder();\n-                buildShardLevelInfo(logger, stats, newShardSizes, newShardRoutingToDataPath);\n-                shardSizes = newShardSizes.build();\n-                shardRoutingToDataPath = newShardRoutingToDataPath.build();\n+                final ShardStats[] stats = indicesStatsResponse.getShards();\n+                final ImmutableOpenMap.Builder<String, Long> shardSizeByIdentifierBuilder = ImmutableOpenMap.builder();\n+                final ImmutableOpenMap.Builder<ShardRouting, String> dataPathByShardRoutingBuilder = ImmutableOpenMap.builder();\n+                final Map<ClusterInfo.NodeAndPath, ClusterInfo.ReservedSpace.Builder> reservedSpaceBuilders = new HashMap<>();\n+                buildShardLevelInfo(logger, stats, shardSizeByIdentifierBuilder, dataPathByShardRoutingBuilder, reservedSpaceBuilders);\n+\n+                final ImmutableOpenMap.Builder<ClusterInfo.NodeAndPath, ClusterInfo.ReservedSpace> rsrvdSpace = ImmutableOpenMap.builder();\n+                reservedSpaceBuilders.forEach((nodeAndPath, builder) -> rsrvdSpace.put(nodeAndPath, builder.build()));\n+\n+                shardSizes = shardSizeByIdentifierBuilder.build();\n+                shardRoutingToDataPath = dataPathByShardRoutingBuilder.build();\n+                reservedSpace = rsrvdSpace.build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a6a7cc083e744897a58b57f0425e6f6970f082b"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA5NzY4OA==", "bodyText": "Race conditions abound here. We're also relying on the disk usage from the nodes stats which may be received at a completely different time, we don't synchronise the collection of stats on the nodes themselves either, and the store size comes from a cached value anyway. I adjusted this bit of code in 9639659 but that's certainly not a complete fix.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440097688", "createdAt": "2020-06-15T11:03:43Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/cluster/InternalClusterInfoService.java", "diffHunk": "@@ -318,15 +323,21 @@ public void onFailure(Exception e) {\n             }\n         });\n \n-        final CountDownLatch indicesLatch = updateIndicesStats(new ActionListener<IndicesStatsResponse>() {\n+        final CountDownLatch indicesLatch = updateIndicesStats(new ActionListener<>() {\n             @Override\n             public void onResponse(IndicesStatsResponse indicesStatsResponse) {\n-                ShardStats[] stats = indicesStatsResponse.getShards();\n-                ImmutableOpenMap.Builder<String, Long> newShardSizes = ImmutableOpenMap.builder();\n-                ImmutableOpenMap.Builder<ShardRouting, String> newShardRoutingToDataPath = ImmutableOpenMap.builder();\n-                buildShardLevelInfo(logger, stats, newShardSizes, newShardRoutingToDataPath);\n-                shardSizes = newShardSizes.build();\n-                shardRoutingToDataPath = newShardRoutingToDataPath.build();\n+                final ShardStats[] stats = indicesStatsResponse.getShards();\n+                final ImmutableOpenMap.Builder<String, Long> shardSizeByIdentifierBuilder = ImmutableOpenMap.builder();\n+                final ImmutableOpenMap.Builder<ShardRouting, String> dataPathByShardRoutingBuilder = ImmutableOpenMap.builder();\n+                final Map<ClusterInfo.NodeAndPath, ClusterInfo.ReservedSpace.Builder> reservedSpaceBuilders = new HashMap<>();\n+                buildShardLevelInfo(logger, stats, shardSizeByIdentifierBuilder, dataPathByShardRoutingBuilder, reservedSpaceBuilders);\n+\n+                final ImmutableOpenMap.Builder<ClusterInfo.NodeAndPath, ClusterInfo.ReservedSpace> rsrvdSpace = ImmutableOpenMap.builder();\n+                reservedSpaceBuilders.forEach((nodeAndPath, builder) -> rsrvdSpace.put(nodeAndPath, builder.build()));\n+\n+                shardSizes = shardSizeByIdentifierBuilder.build();\n+                shardRoutingToDataPath = dataPathByShardRoutingBuilder.build();\n+                reservedSpace = rsrvdSpace.build();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2MDY1NA=="}, "originalCommit": {"oid": "4a6a7cc083e744897a58b57f0425e6f6970f082b"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDY3ODE0MQ==", "bodyText": "Agreed and thanks for the change, looks good.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444678141", "createdAt": "2020-06-24T06:44:17Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/cluster/InternalClusterInfoService.java", "diffHunk": "@@ -318,15 +323,21 @@ public void onFailure(Exception e) {\n             }\n         });\n \n-        final CountDownLatch indicesLatch = updateIndicesStats(new ActionListener<IndicesStatsResponse>() {\n+        final CountDownLatch indicesLatch = updateIndicesStats(new ActionListener<>() {\n             @Override\n             public void onResponse(IndicesStatsResponse indicesStatsResponse) {\n-                ShardStats[] stats = indicesStatsResponse.getShards();\n-                ImmutableOpenMap.Builder<String, Long> newShardSizes = ImmutableOpenMap.builder();\n-                ImmutableOpenMap.Builder<ShardRouting, String> newShardRoutingToDataPath = ImmutableOpenMap.builder();\n-                buildShardLevelInfo(logger, stats, newShardSizes, newShardRoutingToDataPath);\n-                shardSizes = newShardSizes.build();\n-                shardRoutingToDataPath = newShardRoutingToDataPath.build();\n+                final ShardStats[] stats = indicesStatsResponse.getShards();\n+                final ImmutableOpenMap.Builder<String, Long> shardSizeByIdentifierBuilder = ImmutableOpenMap.builder();\n+                final ImmutableOpenMap.Builder<ShardRouting, String> dataPathByShardRoutingBuilder = ImmutableOpenMap.builder();\n+                final Map<ClusterInfo.NodeAndPath, ClusterInfo.ReservedSpace.Builder> reservedSpaceBuilders = new HashMap<>();\n+                buildShardLevelInfo(logger, stats, shardSizeByIdentifierBuilder, dataPathByShardRoutingBuilder, reservedSpaceBuilders);\n+\n+                final ImmutableOpenMap.Builder<ClusterInfo.NodeAndPath, ClusterInfo.ReservedSpace> rsrvdSpace = ImmutableOpenMap.builder();\n+                reservedSpaceBuilders.forEach((nodeAndPath, builder) -> rsrvdSpace.put(nodeAndPath, builder.build()));\n+\n+                shardSizes = shardSizeByIdentifierBuilder.build();\n+                shardRoutingToDataPath = dataPathByShardRoutingBuilder.build();\n+                reservedSpace = rsrvdSpace.build();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2MDY1NA=="}, "originalCommit": {"oid": "4a6a7cc083e744897a58b57f0425e6f6970f082b"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0MTcyODEzOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/cluster/InternalClusterInfoService.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQxMDowMTowOFrOGjrfCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwODozMjo1MlrOGoIV8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2NTgwMg==", "bodyText": "I would have thought this should merge the contents to accommodate for all shards on a specific NodePath rather than only the first encountered? Or am I missing something?", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440065802", "createdAt": "2020-06-15T10:01:08Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/cluster/InternalClusterInfoService.java", "diffHunk": "@@ -383,16 +395,28 @@ public void addListener(Consumer<ClusterInfo> clusterInfoConsumer) {\n         listeners.add(clusterInfoConsumer);\n     }\n \n-    static void buildShardLevelInfo(Logger logger, ShardStats[] stats, ImmutableOpenMap.Builder<String, Long> newShardSizes,\n-                                    ImmutableOpenMap.Builder<ShardRouting, String> newShardRoutingToDataPath) {\n+    static void buildShardLevelInfo(Logger logger, ShardStats[] stats, ImmutableOpenMap.Builder<String, Long> shardSizes,\n+                                    ImmutableOpenMap.Builder<ShardRouting, String> newShardRoutingToDataPath,\n+                                    Map<ClusterInfo.NodeAndPath, ClusterInfo.ReservedSpace.Builder> reservedSpaceByShard) {\n         for (ShardStats s : stats) {\n-            newShardRoutingToDataPath.put(s.getShardRouting(), s.getDataPath());\n-            long size = s.getStats().getStore().sizeInBytes();\n-            String sid = ClusterInfo.shardIdentifierFromRouting(s.getShardRouting());\n+            final ShardRouting shardRouting = s.getShardRouting();\n+            newShardRoutingToDataPath.put(shardRouting, s.getDataPath());\n+\n+            final StoreStats storeStats = s.getStats().getStore();\n+            final long size = storeStats.sizeInBytes();\n+            final long reserved = storeStats.getReservedSize().getBytes();\n+\n+            final String shardIdentifier = ClusterInfo.shardIdentifierFromRouting(shardRouting);\n             if (logger.isTraceEnabled()) {\n-                logger.trace(\"shard: {} size: {}\", sid, size);\n+                logger.trace(\"shard: {} size: {} reserved: {}\", shardIdentifier, size, reserved);\n+            }\n+            shardSizes.put(shardIdentifier, size);\n+\n+            if (reserved != StoreStats.UNKNOWN_RESERVED_BYTES) {\n+                reservedSpaceByShard.computeIfAbsent(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a6a7cc083e744897a58b57f0425e6f6970f082b"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA5ODEzNA==", "bodyText": "am I missing something?\n\nPossibly a closing bracket \ud83d\ude01 We compute a new builder if absent, but then .add() the stats to the builder for each relevant shard.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440098134", "createdAt": "2020-06-15T11:04:42Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/cluster/InternalClusterInfoService.java", "diffHunk": "@@ -383,16 +395,28 @@ public void addListener(Consumer<ClusterInfo> clusterInfoConsumer) {\n         listeners.add(clusterInfoConsumer);\n     }\n \n-    static void buildShardLevelInfo(Logger logger, ShardStats[] stats, ImmutableOpenMap.Builder<String, Long> newShardSizes,\n-                                    ImmutableOpenMap.Builder<ShardRouting, String> newShardRoutingToDataPath) {\n+    static void buildShardLevelInfo(Logger logger, ShardStats[] stats, ImmutableOpenMap.Builder<String, Long> shardSizes,\n+                                    ImmutableOpenMap.Builder<ShardRouting, String> newShardRoutingToDataPath,\n+                                    Map<ClusterInfo.NodeAndPath, ClusterInfo.ReservedSpace.Builder> reservedSpaceByShard) {\n         for (ShardStats s : stats) {\n-            newShardRoutingToDataPath.put(s.getShardRouting(), s.getDataPath());\n-            long size = s.getStats().getStore().sizeInBytes();\n-            String sid = ClusterInfo.shardIdentifierFromRouting(s.getShardRouting());\n+            final ShardRouting shardRouting = s.getShardRouting();\n+            newShardRoutingToDataPath.put(shardRouting, s.getDataPath());\n+\n+            final StoreStats storeStats = s.getStats().getStore();\n+            final long size = storeStats.sizeInBytes();\n+            final long reserved = storeStats.getReservedSize().getBytes();\n+\n+            final String shardIdentifier = ClusterInfo.shardIdentifierFromRouting(shardRouting);\n             if (logger.isTraceEnabled()) {\n-                logger.trace(\"shard: {} size: {}\", sid, size);\n+                logger.trace(\"shard: {} size: {} reserved: {}\", shardIdentifier, size, reserved);\n+            }\n+            shardSizes.put(shardIdentifier, size);\n+\n+            if (reserved != StoreStats.UNKNOWN_RESERVED_BYTES) {\n+                reservedSpaceByShard.computeIfAbsent(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2NTgwMg=="}, "originalCommit": {"oid": "4a6a7cc083e744897a58b57f0425e6f6970f082b"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDY3NjczMA==", "bodyText": "I see it now ! Thanks.\nnit: maybe put the .add part on the next line.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444676730", "createdAt": "2020-06-24T06:40:51Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/cluster/InternalClusterInfoService.java", "diffHunk": "@@ -383,16 +395,28 @@ public void addListener(Consumer<ClusterInfo> clusterInfoConsumer) {\n         listeners.add(clusterInfoConsumer);\n     }\n \n-    static void buildShardLevelInfo(Logger logger, ShardStats[] stats, ImmutableOpenMap.Builder<String, Long> newShardSizes,\n-                                    ImmutableOpenMap.Builder<ShardRouting, String> newShardRoutingToDataPath) {\n+    static void buildShardLevelInfo(Logger logger, ShardStats[] stats, ImmutableOpenMap.Builder<String, Long> shardSizes,\n+                                    ImmutableOpenMap.Builder<ShardRouting, String> newShardRoutingToDataPath,\n+                                    Map<ClusterInfo.NodeAndPath, ClusterInfo.ReservedSpace.Builder> reservedSpaceByShard) {\n         for (ShardStats s : stats) {\n-            newShardRoutingToDataPath.put(s.getShardRouting(), s.getDataPath());\n-            long size = s.getStats().getStore().sizeInBytes();\n-            String sid = ClusterInfo.shardIdentifierFromRouting(s.getShardRouting());\n+            final ShardRouting shardRouting = s.getShardRouting();\n+            newShardRoutingToDataPath.put(shardRouting, s.getDataPath());\n+\n+            final StoreStats storeStats = s.getStats().getStore();\n+            final long size = storeStats.sizeInBytes();\n+            final long reserved = storeStats.getReservedSize().getBytes();\n+\n+            final String shardIdentifier = ClusterInfo.shardIdentifierFromRouting(shardRouting);\n             if (logger.isTraceEnabled()) {\n-                logger.trace(\"shard: {} size: {}\", sid, size);\n+                logger.trace(\"shard: {} size: {} reserved: {}\", shardIdentifier, size, reserved);\n+            }\n+            shardSizes.put(shardIdentifier, size);\n+\n+            if (reserved != StoreStats.UNKNOWN_RESERVED_BYTES) {\n+                reservedSpaceByShard.computeIfAbsent(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2NTgwMg=="}, "originalCommit": {"oid": "4a6a7cc083e744897a58b57f0425e6f6970f082b"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDczMjkxMg==", "bodyText": "Sure, I introduced an intermediate variable in bf9faca.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444732912", "createdAt": "2020-06-24T08:32:52Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/cluster/InternalClusterInfoService.java", "diffHunk": "@@ -383,16 +395,28 @@ public void addListener(Consumer<ClusterInfo> clusterInfoConsumer) {\n         listeners.add(clusterInfoConsumer);\n     }\n \n-    static void buildShardLevelInfo(Logger logger, ShardStats[] stats, ImmutableOpenMap.Builder<String, Long> newShardSizes,\n-                                    ImmutableOpenMap.Builder<ShardRouting, String> newShardRoutingToDataPath) {\n+    static void buildShardLevelInfo(Logger logger, ShardStats[] stats, ImmutableOpenMap.Builder<String, Long> shardSizes,\n+                                    ImmutableOpenMap.Builder<ShardRouting, String> newShardRoutingToDataPath,\n+                                    Map<ClusterInfo.NodeAndPath, ClusterInfo.ReservedSpace.Builder> reservedSpaceByShard) {\n         for (ShardStats s : stats) {\n-            newShardRoutingToDataPath.put(s.getShardRouting(), s.getDataPath());\n-            long size = s.getStats().getStore().sizeInBytes();\n-            String sid = ClusterInfo.shardIdentifierFromRouting(s.getShardRouting());\n+            final ShardRouting shardRouting = s.getShardRouting();\n+            newShardRoutingToDataPath.put(shardRouting, s.getDataPath());\n+\n+            final StoreStats storeStats = s.getStats().getStore();\n+            final long size = storeStats.sizeInBytes();\n+            final long reserved = storeStats.getReservedSize().getBytes();\n+\n+            final String shardIdentifier = ClusterInfo.shardIdentifierFromRouting(shardRouting);\n             if (logger.isTraceEnabled()) {\n-                logger.trace(\"shard: {} size: {}\", sid, size);\n+                logger.trace(\"shard: {} size: {} reserved: {}\", shardIdentifier, size, reserved);\n+            }\n+            shardSizes.put(shardIdentifier, size);\n+\n+            if (reserved != StoreStats.UNKNOWN_RESERVED_BYTES) {\n+                reservedSpaceByShard.computeIfAbsent(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2NTgwMg=="}, "originalCommit": {"oid": "4a6a7cc083e744897a58b57f0425e6f6970f082b"}, "originalPosition": 105}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0MTc1MTI4OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdMonitor.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQxMDowNzo0NlrOGjrtkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwODozNjoyNlrOGoIeAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2OTUyMQ==", "bodyText": "AFAICS this compensation affects two functionalities:\n\nTriggering a reroute when going under low threshold\nAuto-releasing indices when disk usage goes below high threshold.\n\nI think 1) is fine, but I am a bit concerned about 2), since the primary reason we only release when under high threshold is to have some hysteresis to not trigger flood-stage on/off rapidly. I think I would prefer to do the auto-release based on the non-compensated number (just like we move to flood-stage based on that), but am curious on your thoughts on this.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440069521", "createdAt": "2020-06-15T10:07:46Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdMonitor.java", "diffHunk": "@@ -140,6 +140,10 @@ public void onNewInfo(ClusterInfo info) {\n             final DiskUsage usage = entry.value;\n             final RoutingNode routingNode = routingNodes.node(node);\n \n+            final long reservedSpace = info.getReservedSpace(usage.getNodeId(), usage.getPath()).getTotal();\n+            final DiskUsage usageWithReservedSpace = new DiskUsage(usage.getNodeId(), usage.getNodeName(), usage.getPath(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a6a7cc083e744897a58b57f0425e6f6970f082b"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDIwMDcxNA==", "bodyText": "Yes, this is a good point. I'll work on addressing that.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440200714", "createdAt": "2020-06-15T14:05:57Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdMonitor.java", "diffHunk": "@@ -140,6 +140,10 @@ public void onNewInfo(ClusterInfo info) {\n             final DiskUsage usage = entry.value;\n             final RoutingNode routingNode = routingNodes.node(node);\n \n+            final long reservedSpace = info.getReservedSpace(usage.getNodeId(), usage.getPath()).getTotal();\n+            final DiskUsage usageWithReservedSpace = new DiskUsage(usage.getNodeId(), usage.getNodeName(), usage.getPath(),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2OTUyMQ=="}, "originalCommit": {"oid": "4a6a7cc083e744897a58b57f0425e6f6970f082b"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjA4Njc4NA==", "bodyText": "I'm no longer sure about this. The compensated disk usage is never less than the non-compensated one, so auto-releasing based on the compensated number has more hysteresis than today's behaviour. Is the additional hysteresis the thing that concerns you @henningandersen or has one of us got our logic backwards?", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r442086784", "createdAt": "2020-06-18T09:16:07Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdMonitor.java", "diffHunk": "@@ -140,6 +140,10 @@ public void onNewInfo(ClusterInfo info) {\n             final DiskUsage usage = entry.value;\n             final RoutingNode routingNode = routingNodes.node(node);\n \n+            final long reservedSpace = info.getReservedSpace(usage.getNodeId(), usage.getPath()).getTotal();\n+            final DiskUsage usageWithReservedSpace = new DiskUsage(usage.getNodeId(), usage.getNodeName(), usage.getPath(),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2OTUyMQ=="}, "originalCommit": {"oid": "4a6a7cc083e744897a58b57f0425e6f6970f082b"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDY3NTE5OA==", "bodyText": "Yes, that is my concern. Something cured the situation (deleted index, moved shards etc.), but due to an otherwise unrelated recovery, we would keep halting indexing until that recovery is done. I would prefer to resume indexing (i.e., release the block) and then perhaps later find out that we need to halt it again. If cluster is truly full, we will get to that point, but if it is has enough space, we are likely to cure it before hitting the flood stage again anyway.\nI think the additional hysteresis is unnecessary. AFAIK, we have not seen that the block was flapping too frequently and using the non-compensated number, we would simply keep the behavior unmodified from this PR.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444675198", "createdAt": "2020-06-24T06:36:52Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdMonitor.java", "diffHunk": "@@ -140,6 +140,10 @@ public void onNewInfo(ClusterInfo info) {\n             final DiskUsage usage = entry.value;\n             final RoutingNode routingNode = routingNodes.node(node);\n \n+            final long reservedSpace = info.getReservedSpace(usage.getNodeId(), usage.getPath()).getTotal();\n+            final DiskUsage usageWithReservedSpace = new DiskUsage(usage.getNodeId(), usage.getNodeName(), usage.getPath(),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2OTUyMQ=="}, "originalCommit": {"oid": "4a6a7cc083e744897a58b57f0425e6f6970f082b"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDczNDk3OQ==", "bodyText": "I see, right. I don't think the additional hysteresis would be much of a problem in practice (if you hit the flood-stage watermark you already lost) and continuing to recover onto a node that's breached the flood-stage watermark is likely the real bug here. However it turns out not to add too much complexity so I adjusted this in d8afaf3.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444734979", "createdAt": "2020-06-24T08:36:26Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdMonitor.java", "diffHunk": "@@ -140,6 +140,10 @@ public void onNewInfo(ClusterInfo info) {\n             final DiskUsage usage = entry.value;\n             final RoutingNode routingNode = routingNodes.node(node);\n \n+            final long reservedSpace = info.getReservedSpace(usage.getNodeId(), usage.getPath()).getTotal();\n+            final DiskUsage usageWithReservedSpace = new DiskUsage(usage.getNodeId(), usage.getNodeName(), usage.getPath(),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2OTUyMQ=="}, "originalCommit": {"oid": "4a6a7cc083e744897a58b57f0425e6f6970f082b"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0MTgwNjE0OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/index/shard/StoreRecovery.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQxMDoyNTowNVrOGjsQ8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwODozMzozM1rOGoIXpA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA3ODU3Ng==", "bodyText": "Not sure I understand why this needs to be in a finally?", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440078576", "createdAt": "2020-06-15T10:25:05Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/index/shard/StoreRecovery.java", "diffHunk": "@@ -403,13 +404,15 @@ private void internalRecoverFromStore(IndexShard indexShard) throws IndexShardRe\n                     writeEmptyRetentionLeasesFile(indexShard);\n                 }\n                 // since we recover from local, just fill the files and size\n+                final RecoveryState.Index index = recoveryState.getIndex();\n                 try {\n-                    final RecoveryState.Index index = recoveryState.getIndex();\n                     if (si != null) {\n                         addRecoveredFileDetails(si, store, index);\n                     }\n                 } catch (IOException e) {\n                     logger.debug(\"failed to list file details\", e);\n+                } finally {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6a7060c3d7d79adedf06d3058c41b7da62e0a56c"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDEwMjY3OQ==", "bodyText": "IIRC an IOException here can happen if force-allocating a stale primary, but is not fatal. I didn't investigate further since it doesn't really matter for our purposes: we reuse all the local files anyway so the reserved space is zero.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440102679", "createdAt": "2020-06-15T11:14:02Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/index/shard/StoreRecovery.java", "diffHunk": "@@ -403,13 +404,15 @@ private void internalRecoverFromStore(IndexShard indexShard) throws IndexShardRe\n                     writeEmptyRetentionLeasesFile(indexShard);\n                 }\n                 // since we recover from local, just fill the files and size\n+                final RecoveryState.Index index = recoveryState.getIndex();\n                 try {\n-                    final RecoveryState.Index index = recoveryState.getIndex();\n                     if (si != null) {\n                         addRecoveredFileDetails(si, store, index);\n                     }\n                 } catch (IOException e) {\n                     logger.debug(\"failed to list file details\", e);\n+                } finally {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA3ODU3Ng=="}, "originalCommit": {"oid": "6a7060c3d7d79adedf06d3058c41b7da62e0a56c"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDY2NzI3MA==", "bodyText": "Still not sure why the finally block is necessary, since the catch clause for IOException does not rethrow?\nIt seems illogical that in this block a finally block is necessary, whereas in the next block it is not?\nI mean it will work fine either way... So feel free to disregard this if you prefer.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444667270", "createdAt": "2020-06-24T06:16:13Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/index/shard/StoreRecovery.java", "diffHunk": "@@ -403,13 +404,15 @@ private void internalRecoverFromStore(IndexShard indexShard) throws IndexShardRe\n                     writeEmptyRetentionLeasesFile(indexShard);\n                 }\n                 // since we recover from local, just fill the files and size\n+                final RecoveryState.Index index = recoveryState.getIndex();\n                 try {\n-                    final RecoveryState.Index index = recoveryState.getIndex();\n                     if (si != null) {\n                         addRecoveredFileDetails(si, store, index);\n                     }\n                 } catch (IOException e) {\n                     logger.debug(\"failed to list file details\", e);\n+                } finally {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA3ODU3Ng=="}, "originalCommit": {"oid": "6a7060c3d7d79adedf06d3058c41b7da62e0a56c"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDczMzM0OA==", "bodyText": "Oh, I see now. Fixed in cf23d43.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444733348", "createdAt": "2020-06-24T08:33:33Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/index/shard/StoreRecovery.java", "diffHunk": "@@ -403,13 +404,15 @@ private void internalRecoverFromStore(IndexShard indexShard) throws IndexShardRe\n                     writeEmptyRetentionLeasesFile(indexShard);\n                 }\n                 // since we recover from local, just fill the files and size\n+                final RecoveryState.Index index = recoveryState.getIndex();\n                 try {\n-                    final RecoveryState.Index index = recoveryState.getIndex();\n                     if (si != null) {\n                         addRecoveredFileDetails(si, store, index);\n                     }\n                 } catch (IOException e) {\n                     logger.debug(\"failed to list file details\", e);\n+                } finally {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA3ODU3Ng=="}, "originalCommit": {"oid": "6a7060c3d7d79adedf06d3058c41b7da62e0a56c"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0MTg2MjAxOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQxMDo0MzoxMVrOGjs02Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQxNDoyNDo0N1rOGj0hwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA4Nzc2OQ==", "bodyText": "We count reserved space as only the space for the original files in phase 1 of recovery. This makes us slightly more optimistic than desired, in that any changes coming in after getting the original file list are not accounted for as reserved. For instance in cases like described in #58011.\nI wonder if it (for recoveries and relocations) was more precise to adjust by adding (primarySize - alreadyRecovered) - or just (primarySize - replicaSize), where we track each replica individually? This unfortunately does not give us snapshot, which the presented mechanism does, i.e. , we probably need both.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440087769", "createdAt": "2020-06-15T10:43:11Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java", "diffHunk": "@@ -98,9 +99,16 @@ public DiskThresholdDecider(Settings settings, ClusterSettings clusterSettings)\n      */\n     public static long sizeOfRelocatingShards(RoutingNode node, boolean subtractShardsMovingAway, String dataPath, ClusterInfo clusterInfo,\n                                               Metadata metadata, RoutingTable routingTable) {\n-        long totalSize = 0L;\n-\n-        for (ShardRouting routing : node.shardsWithState(ShardRoutingState.INITIALIZING)) {\n+        // Account for reserved space wherever it is available\n+        final ClusterInfo.ReservedSpace reservedSpace = clusterInfo.getReservedSpace(node.nodeId(), dataPath);\n+        long totalSize = reservedSpace.getTotal();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a5275ed96d0e07dec02a7c5d5e0ecb990f872fd1"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDIxMzk1Mw==", "bodyText": "We discussed this via another channel. The idea to use (primarySize - replicaSize) does not work well in the partial recovery case, since we do not remove existing files on the target until the end of phase 1.\nI think the replacement here is good enough.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440213953", "createdAt": "2020-06-15T14:24:47Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java", "diffHunk": "@@ -98,9 +99,16 @@ public DiskThresholdDecider(Settings settings, ClusterSettings clusterSettings)\n      */\n     public static long sizeOfRelocatingShards(RoutingNode node, boolean subtractShardsMovingAway, String dataPath, ClusterInfo clusterInfo,\n                                               Metadata metadata, RoutingTable routingTable) {\n-        long totalSize = 0L;\n-\n-        for (ShardRouting routing : node.shardsWithState(ShardRoutingState.INITIALIZING)) {\n+        // Account for reserved space wherever it is available\n+        final ClusterInfo.ReservedSpace reservedSpace = clusterInfo.getReservedSpace(node.nodeId(), dataPath);\n+        long totalSize = reservedSpace.getTotal();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA4Nzc2OQ=="}, "originalCommit": {"oid": "a5275ed96d0e07dec02a7c5d5e0ecb990f872fd1"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3MTYyMTIyOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/cluster/InternalClusterInfoService.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxMToxMjo0OFrOGoNpjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxMTozNDozMFrOGoOQ4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDgxOTg1Mw==", "bodyText": "add comment here // single volatile read", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444819853", "createdAt": "2020-06-24T11:12:48Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/cluster/InternalClusterInfoService.java", "diffHunk": "@@ -200,7 +201,9 @@ public void clusterChanged(ClusterChangedEvent event) {\n \n     @Override\n     public ClusterInfo getClusterInfo() {\n-        return new ClusterInfo(leastAvailableSpaceUsages, mostAvailableSpaceUsages, shardSizes, shardRoutingToDataPath);\n+        final IndicesStatsSummary indicesStatsSummary = this.indicesStatsSummary;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e75e1ff2f96e1b8096276bd2369b436eab8d36b"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDgyOTkyMA==", "bodyText": "\ud83d\udc4d 78d353e", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444829920", "createdAt": "2020-06-24T11:34:30Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/cluster/InternalClusterInfoService.java", "diffHunk": "@@ -200,7 +201,9 @@ public void clusterChanged(ClusterChangedEvent event) {\n \n     @Override\n     public ClusterInfo getClusterInfo() {\n-        return new ClusterInfo(leastAvailableSpaceUsages, mostAvailableSpaceUsages, shardSizes, shardRoutingToDataPath);\n+        final IndicesStatsSummary indicesStatsSummary = this.indicesStatsSummary;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDgxOTg1Mw=="}, "originalCommit": {"oid": "4e75e1ff2f96e1b8096276bd2369b436eab8d36b"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3MTYzNjUzOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdMonitor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxMToxNzo0OVrOGoNy0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxMTozNDoyM1rOGoOQrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDgyMjIyNA==", "bodyText": "Can you move the creation of this object to the place where it's first used? Or should we  alternatively call the other usage instead usageWithoutReservedSpace to make it clearer  when we are using one vs the other", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444822224", "createdAt": "2020-06-24T11:17:49Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdMonitor.java", "diffHunk": "@@ -140,6 +140,10 @@ public void onNewInfo(ClusterInfo info) {\n             final DiskUsage usage = entry.value;\n             final RoutingNode routingNode = routingNodes.node(node);\n \n+            final long reservedSpace = info.getReservedSpace(usage.getNodeId(), usage.getPath()).getTotal();\n+            final DiskUsage usageWithReservedSpace = new DiskUsage(usage.getNodeId(), usage.getNodeName(), usage.getPath(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e75e1ff2f96e1b8096276bd2369b436eab8d36b"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDgyOTg3MA==", "bodyText": "I tried renaming it but I found that harder to distinguish (usageWithoutReservedSpace and usageWithReservedSpace are pretty similar to the eye). Moved the construction lower down in 56ecdb7.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444829870", "createdAt": "2020-06-24T11:34:23Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdMonitor.java", "diffHunk": "@@ -140,6 +140,10 @@ public void onNewInfo(ClusterInfo info) {\n             final DiskUsage usage = entry.value;\n             final RoutingNode routingNode = routingNodes.node(node);\n \n+            final long reservedSpace = info.getReservedSpace(usage.getNodeId(), usage.getPath()).getTotal();\n+            final DiskUsage usageWithReservedSpace = new DiskUsage(usage.getNodeId(), usage.getNodeName(), usage.getPath(),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDgyMjIyNA=="}, "originalCommit": {"oid": "4e75e1ff2f96e1b8096276bd2369b436eab8d36b"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3MTY0Mzc1OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdMonitor.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxMToyMDoxM1rOGoN3Mw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxMTo0Njo0NlrOGoOoow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDgyMzM0Nw==", "bodyText": "Control flow is  a bit crazy in this method now. Any thoughts on simplifying it?", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444823347", "createdAt": "2020-06-24T11:20:13Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdMonitor.java", "diffHunk": "@@ -158,18 +162,26 @@ public void onNewInfo(ClusterInfo info) {\n                 logger.warn(\"flood stage disk watermark [{}] exceeded on {}, all indices on this node will be marked read-only\",\n                     diskThresholdSettings.describeFloodStageThreshold(), usage);\n \n-            } else if (usage.getFreeBytes() < diskThresholdSettings.getFreeBytesThresholdHigh().getBytes() ||\n-                usage.getFreeDiskAsPercentage() < diskThresholdSettings.getFreeDiskThresholdHigh()) {\n+                continue;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e75e1ff2f96e1b8096276bd2369b436eab8d36b"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDgzMzAzNw==", "bodyText": "Yes, I was considering introducing an explicit state machine for each node as I have always found this logic a little hard to follow. Not convinced it's worth it, I think the tests have pretty good coverage.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444833037", "createdAt": "2020-06-24T11:40:48Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdMonitor.java", "diffHunk": "@@ -158,18 +162,26 @@ public void onNewInfo(ClusterInfo info) {\n                 logger.warn(\"flood stage disk watermark [{}] exceeded on {}, all indices on this node will be marked read-only\",\n                     diskThresholdSettings.describeFloodStageThreshold(), usage);\n \n-            } else if (usage.getFreeBytes() < diskThresholdSettings.getFreeBytesThresholdHigh().getBytes() ||\n-                usage.getFreeDiskAsPercentage() < diskThresholdSettings.getFreeDiskThresholdHigh()) {\n+                continue;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDgyMzM0Nw=="}, "originalCommit": {"oid": "4e75e1ff2f96e1b8096276bd2369b436eab8d36b"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDgzNjAwMw==", "bodyText": "ok, the tests are a good argument. Let's proceed as is then", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444836003", "createdAt": "2020-06-24T11:46:46Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdMonitor.java", "diffHunk": "@@ -158,18 +162,26 @@ public void onNewInfo(ClusterInfo info) {\n                 logger.warn(\"flood stage disk watermark [{}] exceeded on {}, all indices on this node will be marked read-only\",\n                     diskThresholdSettings.describeFloodStageThreshold(), usage);\n \n-            } else if (usage.getFreeBytes() < diskThresholdSettings.getFreeBytesThresholdHigh().getBytes() ||\n-                usage.getFreeDiskAsPercentage() < diskThresholdSettings.getFreeDiskThresholdHigh()) {\n+                continue;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDgyMzM0Nw=="}, "originalCommit": {"oid": "4e75e1ff2f96e1b8096276bd2369b436eab8d36b"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3MzcyOTE3OnYy", "diffSide": "RIGHT", "path": "docs/reference/cluster/stats.asciidoc", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQyMDo0NzoyOFrOGoijVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMzo1MzozNlrOGq9eKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE2MjMyNg==", "bodyText": "I am slightly torn on the -1b value here. It only takes one shard with unknown reserved size to hide the summarized value. And mostly this is just bad timing anyway, the information we have is not a consistent snapshot across the cluster and interpreting correlations between different parts of the stats in a very precise manner is unlikely to be fruitful.\nAlso, it looks as if TransportClusterStatsAction.nodeOperation only summarizes started shards, so I wonder if the reserved bytes will ever be anything but 0 here? Am I missing something (would not be the first time \ud83d\ude42 ).\nI think I am in favor of either removing this from cluster stats (if we think it is always 0) or changing StoreStats.add to treat unknown as 0 (or ideally, do everything we can to figure out the expected size like look at primary size, but that is a bigger ask and something for another day).", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r445162326", "createdAt": "2020-06-24T20:47:28Z", "author": {"login": "henningandersen"}, "path": "docs/reference/cluster/stats.asciidoc", "diffHunk": "@@ -231,6 +231,18 @@ Total size of all shards assigned to selected nodes.\n `size_in_bytes`::\n (integer)\n Total size, in bytes, of all shards assigned to selected nodes.\n+\n+`reserved`::\n+(<<byte-units,byte value>>)\n+A prediction of how much larger the shard stores will eventually grow due to\n+ongoing peer recoveries, restoring snapshots, and similar activities. A value\n+of `-1b` indicates that this is not available.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "56ecdb71c243a9fdac03826d8c5b210ccb18d23b"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTM2Nzk4MA==", "bodyText": "With this change the cluster-wide reserved size will indeed be zero as long as all nodes in the cluster are sufficiently new. It may be -1b in clusters with a mix of versions since older versions do not know how to supply this value.\nWith an upcoming change, however, it will be positive for some active shards (namely, searchable snapshots that are still warming up). It shouldn't be unknown for active shards on sufficiently new versions indeed, but I would still rather distinguish \"nothing is reserved\" from \"unknown\" in case this is helpful for some future analysis of a diagnostics bundle.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r445367980", "createdAt": "2020-06-25T07:44:14Z", "author": {"login": "DaveCTurner"}, "path": "docs/reference/cluster/stats.asciidoc", "diffHunk": "@@ -231,6 +231,18 @@ Total size of all shards assigned to selected nodes.\n `size_in_bytes`::\n (integer)\n Total size, in bytes, of all shards assigned to selected nodes.\n+\n+`reserved`::\n+(<<byte-units,byte value>>)\n+A prediction of how much larger the shard stores will eventually grow due to\n+ongoing peer recoveries, restoring snapshots, and similar activities. A value\n+of `-1b` indicates that this is not available.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE2MjMyNg=="}, "originalCommit": {"oid": "56ecdb71c243a9fdac03826d8c5b210ccb18d23b"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTU5MjU0OQ==", "bodyText": "I think of that statement in the opposite way, in that I could be unlucky to get a diagnostics with -1 out and then know nothing about the reserved space at a node summary level.\nAlso, in the mixed cluster case, I would prefer to assume 0 from old versions. It would otherwise stay -1 at the summarized level until all data nodes are upgraded, which again hides the actual number.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r445592549", "createdAt": "2020-06-25T14:16:39Z", "author": {"login": "henningandersen"}, "path": "docs/reference/cluster/stats.asciidoc", "diffHunk": "@@ -231,6 +231,18 @@ Total size of all shards assigned to selected nodes.\n `size_in_bytes`::\n (integer)\n Total size, in bytes, of all shards assigned to selected nodes.\n+\n+`reserved`::\n+(<<byte-units,byte value>>)\n+A prediction of how much larger the shard stores will eventually grow due to\n+ongoing peer recoveries, restoring snapshots, and similar activities. A value\n+of `-1b` indicates that this is not available.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE2MjMyNg=="}, "originalCommit": {"oid": "56ecdb71c243a9fdac03826d8c5b210ccb18d23b"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjkyMzA0Ng==", "bodyText": "Ok, I pushed 6cee87b with your idea to treat unknown as 0 in the aggregated stats, but still report -1 in the shard-level stats.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r446923046", "createdAt": "2020-06-29T12:13:39Z", "author": {"login": "DaveCTurner"}, "path": "docs/reference/cluster/stats.asciidoc", "diffHunk": "@@ -231,6 +231,18 @@ Total size of all shards assigned to selected nodes.\n `size_in_bytes`::\n (integer)\n Total size, in bytes, of all shards assigned to selected nodes.\n+\n+`reserved`::\n+(<<byte-units,byte value>>)\n+A prediction of how much larger the shard stores will eventually grow due to\n+ongoing peer recoveries, restoring snapshots, and similar activities. A value\n+of `-1b` indicates that this is not available.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE2MjMyNg=="}, "originalCommit": {"oid": "56ecdb71c243a9fdac03826d8c5b210ccb18d23b"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzcwMDUyMA==", "bodyText": "I think we can then leave out the -1 notice here? May still need to be on the node-stats due to the shard level info, but AFAICS, it can never be -1 at cluster stats level?", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r447700520", "createdAt": "2020-06-30T13:53:36Z", "author": {"login": "henningandersen"}, "path": "docs/reference/cluster/stats.asciidoc", "diffHunk": "@@ -231,6 +231,18 @@ Total size of all shards assigned to selected nodes.\n `size_in_bytes`::\n (integer)\n Total size, in bytes, of all shards assigned to selected nodes.\n+\n+`reserved`::\n+(<<byte-units,byte value>>)\n+A prediction of how much larger the shard stores will eventually grow due to\n+ongoing peer recoveries, restoring snapshots, and similar activities. A value\n+of `-1b` indicates that this is not available.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE2MjMyNg=="}, "originalCommit": {"oid": "56ecdb71c243a9fdac03826d8c5b210ccb18d23b"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3Mzc4MzY3OnYy", "diffSide": "RIGHT", "path": "docs/reference/cluster/nodes-stats.asciidoc", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQyMTowNDozOVrOGojFoA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQxNDoxODoxM1rOGo84Vg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE3MTEwNA==", "bodyText": "See comment below on -1b, I think I would be in favor of ignoring unknowns when summarizing reserved stats.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r445171104", "createdAt": "2020-06-24T21:04:39Z", "author": {"login": "henningandersen"}, "path": "docs/reference/cluster/nodes-stats.asciidoc", "diffHunk": "@@ -245,6 +245,18 @@ Total size of all shards assigned to the node.\n `size_in_bytes`::\n (integer)\n Total size, in bytes, of all shards assigned to the node.\n+\n+`reserved`::\n+(<<byte-units,byte value>>)\n+A prediction of how much larger the shard stores on this node will eventually\n+grow due to ongoing peer recoveries, restoring snapshots, and similar\n+activities. A value of `-1b` indicates that this is not available.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "56ecdb71c243a9fdac03826d8c5b210ccb18d23b"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTM3MTIwOQ==", "bodyText": "GET _nodes/stats?level=shards reports this value on a shard-by-shard basis, and includes initialising shards, so it could well be unknown in some of these cases.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r445371209", "createdAt": "2020-06-25T07:50:11Z", "author": {"login": "DaveCTurner"}, "path": "docs/reference/cluster/nodes-stats.asciidoc", "diffHunk": "@@ -245,6 +245,18 @@ Total size of all shards assigned to the node.\n `size_in_bytes`::\n (integer)\n Total size, in bytes, of all shards assigned to the node.\n+\n+`reserved`::\n+(<<byte-units,byte value>>)\n+A prediction of how much larger the shard stores on this node will eventually\n+grow due to ongoing peer recoveries, restoring snapshots, and similar\n+activities. A value of `-1b` indicates that this is not available.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE3MTEwNA=="}, "originalCommit": {"oid": "56ecdb71c243a9fdac03826d8c5b210ccb18d23b"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTU5MzY4Ng==", "bodyText": "I think that on a shard by shard basis, -1 could make sense (though I find it hard to think of a case where it matters).\nBut on a summarized level, getting -1 out because the stats are pulled at an unfortunate time seems to hide more information than it gives.", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r445593686", "createdAt": "2020-06-25T14:18:13Z", "author": {"login": "henningandersen"}, "path": "docs/reference/cluster/nodes-stats.asciidoc", "diffHunk": "@@ -245,6 +245,18 @@ Total size of all shards assigned to the node.\n `size_in_bytes`::\n (integer)\n Total size, in bytes, of all shards assigned to the node.\n+\n+`reserved`::\n+(<<byte-units,byte value>>)\n+A prediction of how much larger the shard stores on this node will eventually\n+grow due to ongoing peer recoveries, restoring snapshots, and similar\n+activities. A value of `-1b` indicates that this is not available.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE3MTEwNA=="}, "originalCommit": {"oid": "56ecdb71c243a9fdac03826d8c5b210ccb18d23b"}, "originalPosition": 9}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1576, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}