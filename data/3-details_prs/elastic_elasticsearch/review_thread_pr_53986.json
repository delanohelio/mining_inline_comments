{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkyNDM4MzQy", "number": 53986, "reviewThreads": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQwMToyMzo1OVrODse8nw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQxMzoyMTo1NFrOD3MR7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3OTcwOTc1OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/aggregations/metrics/AggregateMetricBackedMaxAggregator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQwMToyMzo1OVrOF9XE5A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxMjoxOTozOFrOF-S9uA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg4NTU0MA==", "bodyText": "Future todo (not for this PR): I wonder if there is a way we could extract the BKD optimization in Core so that it can be shared by Core + Pre-aggregated metrics.\nBut not for today, future project :)", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r399885540", "createdAt": "2020-03-30T01:23:59Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/aggregations/metrics/AggregateMetricBackedMaxAggregator.java", "diffHunk": "@@ -0,0 +1,200 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.aggregatemetric.aggregations.metrics;\n+\n+import org.apache.lucene.index.LeafReader;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.PointValues;\n+import org.apache.lucene.search.CollectionTerminatedException;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.util.Bits;\n+import org.apache.lucene.util.FutureArrays;\n+import org.elasticsearch.common.lease.Releasables;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.util.DoubleArray;\n+import org.elasticsearch.index.fielddata.NumericDoubleValues;\n+import org.elasticsearch.index.fielddata.SortedNumericDoubleValues;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.MultiValueMode;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.elasticsearch.search.aggregations.LeafBucketCollectorBase;\n+import org.elasticsearch.search.aggregations.metrics.InternalMax;\n+import org.elasticsearch.search.aggregations.metrics.NumericMetricsAggregator;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.xpack.aggregatemetric.aggregations.support.AggregateMetricsValuesSource;\n+import org.elasticsearch.xpack.aggregatemetric.mapper.AggregateDoubleMetricFieldMapper.Metric;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+\n+import static org.elasticsearch.search.aggregations.metrics.MinAggregator.getPointReaderOrNull;\n+\n+class AggregateMetricBackedMaxAggregator extends NumericMetricsAggregator.SingleValue {\n+\n+    private final AggregateMetricsValuesSource.AggregateDoubleMetric valuesSource;\n+    final DocValueFormat formatter;\n+\n+    final String pointField;\n+    final Function<byte[], Number> pointConverter;\n+\n+    DoubleArray maxes;\n+\n+    AggregateMetricBackedMaxAggregator(\n+        String name,\n+        ValuesSourceConfig config,\n+        AggregateMetricsValuesSource.AggregateDoubleMetric valuesSource,\n+        SearchContext context,\n+        Aggregator parent,\n+        List<PipelineAggregator> pipelineAggregators,\n+        Map<String, Object> metaData\n+    )\n+        throws IOException {\n+        super(name, context, parent, pipelineAggregators, metaData);\n+        this.valuesSource = valuesSource;\n+        if (valuesSource != null) {\n+            maxes = context.bigArrays().newDoubleArray(1, false);\n+            maxes.fill(0, maxes.size(), Double.NEGATIVE_INFINITY);\n+        }\n+        this.formatter = config.format();\n+        this.pointConverter = getPointReaderOrNull(context, parent, config);\n+        if (pointConverter != null) {\n+            pointField = config.fieldContext().field();\n+        } else {\n+            pointField = null;\n+        }\n+    }\n+\n+    @Override\n+    public ScoreMode scoreMode() {\n+        return valuesSource != null && valuesSource.needsScores() ? ScoreMode.COMPLETE : ScoreMode.COMPLETE_NO_SCORES;\n+    }\n+\n+    @Override\n+    public LeafBucketCollector getLeafCollector(LeafReaderContext ctx, final LeafBucketCollector sub) throws IOException {\n+        if (valuesSource == null) {\n+            if (parent != null) {\n+                return LeafBucketCollector.NO_OP_COLLECTOR;\n+            } else {\n+                // we have no parent and the values source is empty so we can skip collecting hits.\n+                throw new CollectionTerminatedException();\n+            }\n+        }\n+        if (pointConverter != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "21da92a7fab32b4bc820eca6f000118ba4ff06ca"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg2Njc0NA==", "bodyText": "For this PR I removed all point reader / bkd optimizations", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r400866744", "createdAt": "2020-03-31T12:19:38Z", "author": {"login": "csoulios"}, "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/aggregations/metrics/AggregateMetricBackedMaxAggregator.java", "diffHunk": "@@ -0,0 +1,200 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.aggregatemetric.aggregations.metrics;\n+\n+import org.apache.lucene.index.LeafReader;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.PointValues;\n+import org.apache.lucene.search.CollectionTerminatedException;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.util.Bits;\n+import org.apache.lucene.util.FutureArrays;\n+import org.elasticsearch.common.lease.Releasables;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.util.DoubleArray;\n+import org.elasticsearch.index.fielddata.NumericDoubleValues;\n+import org.elasticsearch.index.fielddata.SortedNumericDoubleValues;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.MultiValueMode;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.elasticsearch.search.aggregations.LeafBucketCollectorBase;\n+import org.elasticsearch.search.aggregations.metrics.InternalMax;\n+import org.elasticsearch.search.aggregations.metrics.NumericMetricsAggregator;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.xpack.aggregatemetric.aggregations.support.AggregateMetricsValuesSource;\n+import org.elasticsearch.xpack.aggregatemetric.mapper.AggregateDoubleMetricFieldMapper.Metric;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+\n+import static org.elasticsearch.search.aggregations.metrics.MinAggregator.getPointReaderOrNull;\n+\n+class AggregateMetricBackedMaxAggregator extends NumericMetricsAggregator.SingleValue {\n+\n+    private final AggregateMetricsValuesSource.AggregateDoubleMetric valuesSource;\n+    final DocValueFormat formatter;\n+\n+    final String pointField;\n+    final Function<byte[], Number> pointConverter;\n+\n+    DoubleArray maxes;\n+\n+    AggregateMetricBackedMaxAggregator(\n+        String name,\n+        ValuesSourceConfig config,\n+        AggregateMetricsValuesSource.AggregateDoubleMetric valuesSource,\n+        SearchContext context,\n+        Aggregator parent,\n+        List<PipelineAggregator> pipelineAggregators,\n+        Map<String, Object> metaData\n+    )\n+        throws IOException {\n+        super(name, context, parent, pipelineAggregators, metaData);\n+        this.valuesSource = valuesSource;\n+        if (valuesSource != null) {\n+            maxes = context.bigArrays().newDoubleArray(1, false);\n+            maxes.fill(0, maxes.size(), Double.NEGATIVE_INFINITY);\n+        }\n+        this.formatter = config.format();\n+        this.pointConverter = getPointReaderOrNull(context, parent, config);\n+        if (pointConverter != null) {\n+            pointField = config.fieldContext().field();\n+        } else {\n+            pointField = null;\n+        }\n+    }\n+\n+    @Override\n+    public ScoreMode scoreMode() {\n+        return valuesSource != null && valuesSource.needsScores() ? ScoreMode.COMPLETE : ScoreMode.COMPLETE_NO_SCORES;\n+    }\n+\n+    @Override\n+    public LeafBucketCollector getLeafCollector(LeafReaderContext ctx, final LeafBucketCollector sub) throws IOException {\n+        if (valuesSource == null) {\n+            if (parent != null) {\n+                return LeafBucketCollector.NO_OP_COLLECTOR;\n+            } else {\n+                // we have no parent and the values source is empty so we can skip collecting hits.\n+                throw new CollectionTerminatedException();\n+            }\n+        }\n+        if (pointConverter != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg4NTU0MA=="}, "originalCommit": {"oid": "21da92a7fab32b4bc820eca6f000118ba4ff06ca"}, "originalPosition": 91}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3OTcyNjkzOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/aggregations/metrics/AggregateMetricBackedMaxAggregator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQwMTozODoyOVrOF9XObA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxMjoxMDoyOFrOF-SoKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg4Nzk4MA==", "bodyText": "I think this won't end up working, or rather, will never return a valid pointConverter and so all the associated BKD logic is not needed.  E.g. MinAggregator#getPointReaderOrNull() fetches the field context and then does naive instanceof checks to see what kind of field it is (number or date atm).  Which I believe won't match because the field here is actually the pre-aggregated field class.\nWe'd need some way to tell that function (or create a new one) which metric to get out of the pre-agg field, which is harder since it's in Core.\nIt's a nice optimization but also pretty niche... I think it would be ok to remove all the point reader / bkd optimization from these aggregators to keep them simple.  We can add them back later.", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r399887980", "createdAt": "2020-03-30T01:38:29Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/aggregations/metrics/AggregateMetricBackedMaxAggregator.java", "diffHunk": "@@ -0,0 +1,200 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.aggregatemetric.aggregations.metrics;\n+\n+import org.apache.lucene.index.LeafReader;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.PointValues;\n+import org.apache.lucene.search.CollectionTerminatedException;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.util.Bits;\n+import org.apache.lucene.util.FutureArrays;\n+import org.elasticsearch.common.lease.Releasables;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.util.DoubleArray;\n+import org.elasticsearch.index.fielddata.NumericDoubleValues;\n+import org.elasticsearch.index.fielddata.SortedNumericDoubleValues;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.MultiValueMode;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.elasticsearch.search.aggregations.LeafBucketCollectorBase;\n+import org.elasticsearch.search.aggregations.metrics.InternalMax;\n+import org.elasticsearch.search.aggregations.metrics.NumericMetricsAggregator;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.xpack.aggregatemetric.aggregations.support.AggregateMetricsValuesSource;\n+import org.elasticsearch.xpack.aggregatemetric.mapper.AggregateDoubleMetricFieldMapper.Metric;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+\n+import static org.elasticsearch.search.aggregations.metrics.MinAggregator.getPointReaderOrNull;\n+\n+class AggregateMetricBackedMaxAggregator extends NumericMetricsAggregator.SingleValue {\n+\n+    private final AggregateMetricsValuesSource.AggregateDoubleMetric valuesSource;\n+    final DocValueFormat formatter;\n+\n+    final String pointField;\n+    final Function<byte[], Number> pointConverter;\n+\n+    DoubleArray maxes;\n+\n+    AggregateMetricBackedMaxAggregator(\n+        String name,\n+        ValuesSourceConfig config,\n+        AggregateMetricsValuesSource.AggregateDoubleMetric valuesSource,\n+        SearchContext context,\n+        Aggregator parent,\n+        List<PipelineAggregator> pipelineAggregators,\n+        Map<String, Object> metaData\n+    )\n+        throws IOException {\n+        super(name, context, parent, pipelineAggregators, metaData);\n+        this.valuesSource = valuesSource;\n+        if (valuesSource != null) {\n+            maxes = context.bigArrays().newDoubleArray(1, false);\n+            maxes.fill(0, maxes.size(), Double.NEGATIVE_INFINITY);\n+        }\n+        this.formatter = config.format();\n+        this.pointConverter = getPointReaderOrNull(context, parent, config);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "21da92a7fab32b4bc820eca6f000118ba4ff06ca"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg2MTIyNA==", "bodyText": "Removed all point reader / bkd optimization", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r400861224", "createdAt": "2020-03-31T12:10:28Z", "author": {"login": "csoulios"}, "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/aggregations/metrics/AggregateMetricBackedMaxAggregator.java", "diffHunk": "@@ -0,0 +1,200 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.aggregatemetric.aggregations.metrics;\n+\n+import org.apache.lucene.index.LeafReader;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.PointValues;\n+import org.apache.lucene.search.CollectionTerminatedException;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.util.Bits;\n+import org.apache.lucene.util.FutureArrays;\n+import org.elasticsearch.common.lease.Releasables;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.util.DoubleArray;\n+import org.elasticsearch.index.fielddata.NumericDoubleValues;\n+import org.elasticsearch.index.fielddata.SortedNumericDoubleValues;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.MultiValueMode;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.elasticsearch.search.aggregations.LeafBucketCollectorBase;\n+import org.elasticsearch.search.aggregations.metrics.InternalMax;\n+import org.elasticsearch.search.aggregations.metrics.NumericMetricsAggregator;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.xpack.aggregatemetric.aggregations.support.AggregateMetricsValuesSource;\n+import org.elasticsearch.xpack.aggregatemetric.mapper.AggregateDoubleMetricFieldMapper.Metric;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+\n+import static org.elasticsearch.search.aggregations.metrics.MinAggregator.getPointReaderOrNull;\n+\n+class AggregateMetricBackedMaxAggregator extends NumericMetricsAggregator.SingleValue {\n+\n+    private final AggregateMetricsValuesSource.AggregateDoubleMetric valuesSource;\n+    final DocValueFormat formatter;\n+\n+    final String pointField;\n+    final Function<byte[], Number> pointConverter;\n+\n+    DoubleArray maxes;\n+\n+    AggregateMetricBackedMaxAggregator(\n+        String name,\n+        ValuesSourceConfig config,\n+        AggregateMetricsValuesSource.AggregateDoubleMetric valuesSource,\n+        SearchContext context,\n+        Aggregator parent,\n+        List<PipelineAggregator> pipelineAggregators,\n+        Map<String, Object> metaData\n+    )\n+        throws IOException {\n+        super(name, context, parent, pipelineAggregators, metaData);\n+        this.valuesSource = valuesSource;\n+        if (valuesSource != null) {\n+            maxes = context.bigArrays().newDoubleArray(1, false);\n+            maxes.fill(0, maxes.size(), Double.NEGATIVE_INFINITY);\n+        }\n+        this.formatter = config.format();\n+        this.pointConverter = getPointReaderOrNull(context, parent, config);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg4Nzk4MA=="}, "originalCommit": {"oid": "21da92a7fab32b4bc820eca6f000118ba4ff06ca"}, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3OTcyODE4OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/aggregations/metrics/AggregateMetricBackedMinAggregator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQwMTozOTowN1rOF9XPDQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQwMTozOTowN1rOF9XPDQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg4ODE0MQ==", "bodyText": "Ditto here too", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r399888141", "createdAt": "2020-03-30T01:39:07Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/aggregations/metrics/AggregateMetricBackedMinAggregator.java", "diffHunk": "@@ -0,0 +1,232 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.aggregatemetric.aggregations.metrics;\n+\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.LeafReader;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.PointValues;\n+import org.apache.lucene.search.CollectionTerminatedException;\n+import org.apache.lucene.search.MatchAllDocsQuery;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.util.Bits;\n+import org.elasticsearch.common.lease.Releasables;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.util.DoubleArray;\n+import org.elasticsearch.index.fielddata.NumericDoubleValues;\n+import org.elasticsearch.index.fielddata.SortedNumericDoubleValues;\n+import org.elasticsearch.index.mapper.DateFieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.MultiValueMode;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.elasticsearch.search.aggregations.LeafBucketCollectorBase;\n+import org.elasticsearch.search.aggregations.metrics.InternalMin;\n+import org.elasticsearch.search.aggregations.metrics.NumericMetricsAggregator;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.xpack.aggregatemetric.aggregations.support.AggregateMetricsValuesSource;\n+import org.elasticsearch.xpack.aggregatemetric.mapper.AggregateDoubleMetricFieldMapper.Metric;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+\n+class AggregateMetricBackedMinAggregator extends NumericMetricsAggregator.SingleValue {\n+    private static final int MAX_BKD_LOOKUPS = 1024;\n+\n+    private final AggregateMetricsValuesSource.AggregateDoubleMetric valuesSource;\n+    final DocValueFormat format;\n+\n+    final String pointField;\n+    final Function<byte[], Number> pointConverter;\n+\n+    DoubleArray mins;\n+\n+    AggregateMetricBackedMinAggregator(\n+        String name,\n+        ValuesSourceConfig config,\n+        AggregateMetricsValuesSource.AggregateDoubleMetric valuesSource,\n+        SearchContext context,\n+        Aggregator parent,\n+        List<PipelineAggregator> pipelineAggregators,\n+        Map<String, Object> metaData\n+    )\n+        throws IOException {\n+        super(name, context, parent, pipelineAggregators, metaData);\n+        this.valuesSource = valuesSource;\n+        if (valuesSource != null) {\n+            mins = context.bigArrays().newDoubleArray(1, false);\n+            mins.fill(0, mins.size(), Double.POSITIVE_INFINITY);\n+        }\n+        this.format = config.format();\n+        this.pointConverter = getPointReaderOrNull(context, parent, config);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "21da92a7fab32b4bc820eca6f000118ba4ff06ca"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3OTcyOTQzOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/aggregations/support/AggregateMetricsValuesSourceType.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQwMTo0MDoxOFrOF9XPwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQwMTo0MDoxOFrOF9XPwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg4ODMyMA==", "bodyText": "Tiny nit: !(indexFieldData ... ) instead of ... == false", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r399888320", "createdAt": "2020-03-30T01:40:18Z", "author": {"login": "polyfractal"}, "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/aggregations/support/AggregateMetricsValuesSourceType.java", "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.aggregatemetric.aggregations.support;\n+\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.script.AggregationScript;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AggregationExecutionException;\n+import org.elasticsearch.search.aggregations.support.FieldContext;\n+import org.elasticsearch.search.aggregations.support.ValueType;\n+import org.elasticsearch.search.aggregations.support.ValuesSource;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceType;\n+import org.elasticsearch.xpack.aggregatemetric.fielddata.IndexAggregateDoubleMetricFieldData;\n+\n+import java.util.Locale;\n+import java.util.function.LongSupplier;\n+\n+public enum AggregateMetricsValuesSourceType implements ValuesSourceType {\n+\n+    AGGREGATE_METRIC() {\n+        @Override\n+        public ValuesSource getEmpty() {\n+            throw new IllegalArgumentException(\"Can't deal with unmapped AggregateMetricsValuesSource type \" + this.value());\n+        }\n+\n+        @Override\n+        public ValuesSource getScript(AggregationScript.LeafFactory script, ValueType scriptValueType) {\n+            throw new AggregationExecutionException(\"Value source of type [\" + this.value() + \"] is not supported by scripts\");\n+        }\n+\n+        @Override\n+        public ValuesSource getField(FieldContext fieldContext, AggregationScript.LeafFactory script) {\n+            final IndexFieldData<?> indexFieldData = fieldContext.indexFieldData();\n+\n+            if (!(indexFieldData instanceof IndexAggregateDoubleMetricFieldData)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "21da92a7fab32b4bc820eca6f000118ba4ff06ca"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4MTMyNDk1OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapper.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxMTo1NjowNlrOF9mMRw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxMTo0NjoxNFrOGJBY0w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDEzMzE5MQ==", "bodyText": "Should we ensure that we  have a single value per document when parsing ?", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r400133191", "createdAt": "2020-03-30T11:56:06Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapper.java", "diffHunk": "@@ -0,0 +1,689 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.aggregatemetric.mapper;\n+\n+import org.apache.lucene.index.DocValues;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.IndexableField;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.NumericDocValues;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.SortField;\n+import org.elasticsearch.common.Explicit;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.time.DateMathParser;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.XContentSubParser;\n+import org.elasticsearch.common.xcontent.support.XContentMapValues;\n+import org.elasticsearch.index.IndexSettings;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.IndexFieldDataCache;\n+import org.elasticsearch.index.fielddata.ScriptDocValues;\n+import org.elasticsearch.index.fielddata.SortedBinaryDocValues;\n+import org.elasticsearch.index.fielddata.SortedNumericDoubleValues;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SimpleMappedFieldType;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryRewriteContext;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.indices.breaker.CircuitBreakerService;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.MultiValueMode;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceType;\n+import org.elasticsearch.search.sort.BucketedSort;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.xpack.aggregatemetric.aggregations.support.AggregateMetricsValuesSourceType;\n+import org.elasticsearch.xpack.aggregatemetric.fielddata.IndexAggregateDoubleMetricFieldData;\n+import org.elasticsearch.xpack.aggregatemetric.fielddata.LeafAggregateDoubleMetricFieldData;\n+\n+import java.io.IOException;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.EnumMap;\n+import java.util.EnumSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import static org.elasticsearch.common.xcontent.XContentParserUtils.ensureExpectedToken;\n+\n+/** A {@link FieldMapper} for a field containing aggregate metrics such as min/max/value_count etc. */\n+public class AggregateDoubleMetricFieldMapper extends FieldMapper {\n+\n+    public static final String CONTENT_TYPE = \"aggregate_metric_double\";\n+    public static final String SUBFIELD_SEPARATOR = \"._\";\n+\n+    /**\n+     * Return the name of a subfield of an aggregate metric field\n+     *\n+     * @param fieldName the name of the aggregate metric field\n+     * @param metric    the metric type the subfield corresponds to\n+     * @return the name of the subfield\n+     */\n+    public static String subfieldName(String fieldName, Metric metric) {\n+        return fieldName + AggregateDoubleMetricFieldMapper.SUBFIELD_SEPARATOR + metric.name();\n+    }\n+\n+    /**\n+     * Mapping field names\n+     */\n+    public static class Names {\n+        public static final ParseField IGNORE_MALFORMED = new ParseField(\"ignore_malformed\");\n+        public static final ParseField METRICS = new ParseField(\"metrics\");\n+        public static final ParseField DEFAULT_METRIC = new ParseField(\"default_metric\");\n+    }\n+\n+    /**\n+     * Enum of aggregate metrics supported by this field mapper\n+     */\n+    public enum Metric {\n+        min,\n+        max,\n+        sum,\n+        value_count;\n+    }\n+\n+    public static class Defaults {\n+        public static final Explicit<Boolean> IGNORE_MALFORMED = new Explicit<>(false, false);\n+        public static final Explicit<Set<Metric>> METRICS = new Explicit<>(Collections.emptySet(), false);\n+        public static final Explicit<Metric> DEFAULT_METRIC = new Explicit<>(Metric.max, false);\n+        public static final AggregateDoubleMetricFieldType FIELD_TYPE = new AggregateDoubleMetricFieldType();\n+    }\n+\n+    public static class Builder extends FieldMapper.Builder<AggregateDoubleMetricFieldMapper.Builder, AggregateDoubleMetricFieldMapper> {\n+\n+        private Boolean ignoreMalformed;\n+\n+        /**\n+         * The aggregated metrics supported by the field type\n+         */\n+        private EnumSet<Metric> metrics;\n+\n+        /**\n+         * Set the default metric so that query operations are delegated to it.\n+         */\n+        private Metric defaultMetric;\n+\n+        public Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder ignoreMalformed(boolean ignoreMalformed) {\n+            this.ignoreMalformed = ignoreMalformed;\n+            return builder;\n+        }\n+\n+        protected Explicit<Boolean> ignoreMalformed(BuilderContext context) {\n+            if (ignoreMalformed != null) {\n+                return new Explicit<>(ignoreMalformed, true);\n+            }\n+            if (context.indexSettings() != null) {\n+                return new Explicit<>(IGNORE_MALFORMED_SETTING.get(context.indexSettings()), false);\n+            }\n+            return AggregateDoubleMetricFieldMapper.Defaults.IGNORE_MALFORMED;\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder defaultMetric(Metric defaultMetric) {\n+            this.defaultMetric = defaultMetric;\n+            return builder;\n+        }\n+\n+        protected Explicit<Metric> defaultMetric(BuilderContext context) {\n+            if (defaultMetric != null) {\n+                if (metrics != null && metrics.contains(defaultMetric) == false) {\n+                    // The default_metric is not defined in the \"metrics\" field\n+                    throw new IllegalArgumentException(\"Metric [\" + defaultMetric + \"] is not defined in the metrics field.\");\n+                }\n+                return new Explicit<>(defaultMetric, true);\n+            }\n+\n+            // If a single metric is contained, this should be the default\n+            if (metrics != null && metrics.size() == 1) {\n+                return new Explicit<>(metrics.iterator().next(), false);\n+            }\n+\n+            if (metrics.contains(Defaults.DEFAULT_METRIC.value())) {\n+                return Defaults.DEFAULT_METRIC;\n+            }\n+            throw new IllegalArgumentException(\n+                \"Property [\" + Names.DEFAULT_METRIC.getPreferredName() + \"] must be set for field [\" + name() + \"].\"\n+            );\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder metrics(EnumSet<Metric> metrics) {\n+            this.metrics = metrics;\n+            return builder;\n+        }\n+\n+        protected Explicit<Set<Metric>> metrics(BuilderContext context) {\n+            if (metrics != null) {\n+                return new Explicit<>(metrics, true);\n+            }\n+            return Defaults.METRICS;\n+        }\n+\n+        @Override\n+        public AggregateDoubleMetricFieldMapper build(BuilderContext context) {\n+            setupFieldType(context);\n+\n+            if (metrics == null || metrics.isEmpty()) {\n+                throw new IllegalArgumentException(\n+                    \"Property [\" + Names.METRICS.getPreferredName() + \"] must be set for field [\" + name() + \"].\"\n+                );\n+            }\n+\n+            EnumMap<Metric, NumberFieldMapper> metricMappers = new EnumMap<>(Metric.class);\n+            // Instantiate one NumberFieldMapper instance for each metric\n+            for (Metric m : this.metrics) {\n+                String fieldName = subfieldName(context.path().pathAsText(name), m);\n+                NumberFieldMapper.Builder builder;\n+\n+                if (m == Metric.value_count) {\n+                    // value_count metric can only be an integer and not a double\n+                    builder = new NumberFieldMapper.Builder(fieldName, NumberFieldMapper.NumberType.INTEGER);\n+                    builder.coerce(false);\n+                } else {\n+                    builder = new NumberFieldMapper.Builder(fieldName, NumberFieldMapper.NumberType.DOUBLE);\n+                }\n+                NumberFieldMapper fieldMapper = builder.build(context);\n+                metricMappers.put(m, fieldMapper);\n+            }\n+\n+            EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields = metricMappers.entrySet()\n+                .stream()\n+                .collect(\n+                    Collectors.toMap(\n+                        Map.Entry::getKey,\n+                        e -> e.getValue().fieldType(),\n+                        (l, r) -> { throw new IllegalArgumentException(\"Duplicate keys \" + l + \"and \" + r + \".\"); },\n+                        () -> new EnumMap<>(Metric.class)\n+                    )\n+                );\n+\n+            AggregateDoubleMetricFieldType metricFieldType = (AggregateDoubleMetricFieldType) fieldType;\n+            metricFieldType.setMetricFields(metricFields);\n+\n+            Explicit<Metric> defaultMetric = defaultMetric(context);\n+            metricFieldType.setDefaultMetric(defaultMetric.value());\n+\n+            return new AggregateDoubleMetricFieldMapper(\n+                name,\n+                metricFieldType,\n+                defaultFieldType,\n+                context.indexSettings(),\n+                multiFieldsBuilder.build(this, context),\n+                ignoreMalformed(context),\n+                metrics(context),\n+                defaultMetric,\n+                copyTo,\n+                metricMappers\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        @Override\n+        public Mapper.Builder<Builder, AggregateDoubleMetricFieldMapper> parse(\n+            String name,\n+            Map<String, Object> node,\n+            ParserContext parserContext\n+        ) throws MapperParsingException {\n+            AggregateDoubleMetricFieldMapper.Builder builder = new AggregateDoubleMetricFieldMapper.Builder(name);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(Names.METRICS.getPreferredName())) {\n+                    String metricsStr[] = XContentMapValues.nodeStringArrayValue(propNode);\n+                    // Make sure that metrics are supported\n+                    EnumSet<Metric> parsedMetrics = EnumSet.noneOf(Metric.class);\n+                    for (int i = 0; i < metricsStr.length; i++) {\n+                        try {\n+                            Metric m = Metric.valueOf(metricsStr[i]);\n+                            parsedMetrics.add(m);\n+                        } catch (IllegalArgumentException e) {\n+                            throw new IllegalArgumentException(\"Metric [\" + metricsStr[i] + \"] is not supported.\", e);\n+                        }\n+                    }\n+                    builder.metrics(parsedMetrics);\n+                    iterator.remove();\n+                } else if (propName.equals(Names.DEFAULT_METRIC.getPreferredName())) {\n+                    String defaultMetric = XContentMapValues.nodeStringValue(\n+                        propNode,\n+                        name + \".\" + Names.DEFAULT_METRIC.getPreferredName()\n+                    );\n+                    try {\n+                        Metric m = Metric.valueOf(defaultMetric);\n+                        builder.defaultMetric(m);\n+                        iterator.remove();\n+                    } catch (IllegalArgumentException e) {\n+                        throw new IllegalArgumentException(\"Metric [\" + defaultMetric + \"] is not supported.\", e);\n+                    }\n+                } else if (propName.equals(Names.IGNORE_MALFORMED.getPreferredName())) {\n+                    builder.ignoreMalformed(\n+                        XContentMapValues.nodeBooleanValue(propNode, name + \".\" + Names.IGNORE_MALFORMED.getPreferredName())\n+                    );\n+                    iterator.remove();\n+                } else if (TypeParsers.parseMultiField(builder, name, parserContext, propName, propNode)) {\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class AggregateDoubleMetricFieldType extends SimpleMappedFieldType {\n+\n+        private EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields;\n+\n+        private Metric defaultMetric;\n+\n+        public AggregateDoubleMetricFieldType() {}\n+\n+        AggregateDoubleMetricFieldType(AggregateDoubleMetricFieldType other) {\n+            super(other);\n+            this.metricFields = other.metricFields;\n+            this.defaultMetric = other.defaultMetric;\n+        }\n+\n+        @Override\n+        public MappedFieldType clone() {\n+            return new AggregateDoubleMetricFieldType(this);\n+        }\n+\n+        /**\n+         * Return a delegate field type for a given metric sub-field\n+         * @return a field type\n+         */\n+        private NumberFieldMapper.NumberFieldType delegateFieldType(Metric metric) {\n+            return metricFields.get(metric);\n+        }\n+\n+        /**\n+         * Return a delegate field type for the default metric sub-field\n+         * @return a field type\n+         */\n+        private NumberFieldMapper.NumberFieldType delegateFieldType() {\n+            return delegateFieldType(defaultMetric);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        private void setMetricFields(EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields) {\n+            checkIfFrozen();\n+            this.metricFields = metricFields;\n+        }\n+\n+        public void addMetricField(Metric m, NumberFieldMapper.NumberFieldType subfield) {\n+            checkIfFrozen();\n+            if (metricFields == null) {\n+                metricFields = new EnumMap<>(AggregateDoubleMetricFieldMapper.Metric.class);\n+            }\n+\n+            if (name() == null) {\n+                throw new IllegalArgumentException(\"Field of type [\" + typeName() + \"] must have a name before adding a subfield\");\n+            }\n+            String subfieldName = subfieldName(name(), m);\n+            subfield.setName(subfieldName);\n+            metricFields.put(m, subfield);\n+        }\n+\n+        public void setDefaultMetric(Metric defaultMetric) {\n+            checkIfFrozen();\n+            this.defaultMetric = defaultMetric;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return delegateFieldType().existsQuery(context);\n+        }\n+\n+        @Override\n+        public Query termQuery(Object value, QueryShardContext context) {\n+            return delegateFieldType().termQuery(value, context);\n+        }\n+\n+        @Override\n+        public Query termsQuery(List<?> values, QueryShardContext context) {\n+            return delegateFieldType().termsQuery(values, context);\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            return delegateFieldType().rangeQuery(lowerTerm, upperTerm, includeLower, includeUpper, context);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            return delegateFieldType().valueForDisplay(value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(String format, ZoneId timeZone) {\n+            return delegateFieldType().docValueFormat(format, timeZone);\n+        }\n+\n+        @Override\n+        public Relation isFieldWithinQuery(\n+            IndexReader reader,\n+            Object from,\n+            Object to,\n+            boolean includeLower,\n+            boolean includeUpper,\n+            ZoneId timeZone,\n+            DateMathParser dateMathParser,\n+            QueryRewriteContext context\n+        ) throws IOException {\n+            return delegateFieldType().isFieldWithinQuery(reader, from, to, includeLower, includeUpper, timeZone, dateMathParser, context);\n+        }\n+\n+        @Override\n+        public ValuesSourceType getValuesSourceType() {\n+            return AggregateMetricsValuesSourceType.AGGREGATE_METRIC;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            return new IndexFieldData.Builder() {\n+                @Override\n+                public IndexFieldData<?> build(\n+                    IndexSettings indexSettings,\n+                    MappedFieldType fieldType,\n+                    IndexFieldDataCache cache,\n+                    CircuitBreakerService breakerService,\n+                    MapperService mapperService\n+                ) {\n+                    return new IndexAggregateDoubleMetricFieldData(indexSettings.getIndex(), fieldType.name()) {\n+                        @Override\n+                        public LeafAggregateDoubleMetricFieldData load(LeafReaderContext context) {\n+                            return new LeafAggregateDoubleMetricFieldData() {\n+                                @Override\n+                                public SortedNumericDoubleValues getAggregateMetricValues(final Metric metric) throws IOException {\n+                                    try {\n+                                        final NumericDocValues values = DocValues.getNumeric(\n+                                            context.reader(),\n+                                            subfieldName(fieldName, metric)\n+                                        );\n+\n+                                        return new SortedNumericDoubleValues() {\n+                                            @Override\n+                                            public int docValueCount() {\n+                                                return 1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "21da92a7fab32b4bc820eca6f000118ba4ff06ca"}, "originalPosition": 431}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjExMzEwNw==", "bodyText": "Ensuring that values are not arrays are validated here:\n\n  \n    \n      elasticsearch/x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapper.java\n    \n    \n         Line 589\n      in\n      b9bf259\n    \n    \n    \n    \n\n        \n          \n           if (context.doc().getField(delegateFieldMapper.fieldType().name()) != null) { \n        \n    \n  \n\n\nThis code is tested at \n  \n    \n      elasticsearch/x-pack/plugin/mapper-aggregate-metric/src/test/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapperTests.java\n    \n    \n         Line 669\n      in\n      b9bf259\n    \n    \n    \n    \n\n        \n          \n           public void testParseArrayValue() throws Exception { \n        \n    \n  \n\n\nIs there anything else I should implement?", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r412113107", "createdAt": "2020-04-21T11:46:14Z", "author": {"login": "csoulios"}, "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapper.java", "diffHunk": "@@ -0,0 +1,689 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.aggregatemetric.mapper;\n+\n+import org.apache.lucene.index.DocValues;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.IndexableField;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.NumericDocValues;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.SortField;\n+import org.elasticsearch.common.Explicit;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.time.DateMathParser;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.XContentSubParser;\n+import org.elasticsearch.common.xcontent.support.XContentMapValues;\n+import org.elasticsearch.index.IndexSettings;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.IndexFieldDataCache;\n+import org.elasticsearch.index.fielddata.ScriptDocValues;\n+import org.elasticsearch.index.fielddata.SortedBinaryDocValues;\n+import org.elasticsearch.index.fielddata.SortedNumericDoubleValues;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SimpleMappedFieldType;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryRewriteContext;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.indices.breaker.CircuitBreakerService;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.MultiValueMode;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceType;\n+import org.elasticsearch.search.sort.BucketedSort;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.xpack.aggregatemetric.aggregations.support.AggregateMetricsValuesSourceType;\n+import org.elasticsearch.xpack.aggregatemetric.fielddata.IndexAggregateDoubleMetricFieldData;\n+import org.elasticsearch.xpack.aggregatemetric.fielddata.LeafAggregateDoubleMetricFieldData;\n+\n+import java.io.IOException;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.EnumMap;\n+import java.util.EnumSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import static org.elasticsearch.common.xcontent.XContentParserUtils.ensureExpectedToken;\n+\n+/** A {@link FieldMapper} for a field containing aggregate metrics such as min/max/value_count etc. */\n+public class AggregateDoubleMetricFieldMapper extends FieldMapper {\n+\n+    public static final String CONTENT_TYPE = \"aggregate_metric_double\";\n+    public static final String SUBFIELD_SEPARATOR = \"._\";\n+\n+    /**\n+     * Return the name of a subfield of an aggregate metric field\n+     *\n+     * @param fieldName the name of the aggregate metric field\n+     * @param metric    the metric type the subfield corresponds to\n+     * @return the name of the subfield\n+     */\n+    public static String subfieldName(String fieldName, Metric metric) {\n+        return fieldName + AggregateDoubleMetricFieldMapper.SUBFIELD_SEPARATOR + metric.name();\n+    }\n+\n+    /**\n+     * Mapping field names\n+     */\n+    public static class Names {\n+        public static final ParseField IGNORE_MALFORMED = new ParseField(\"ignore_malformed\");\n+        public static final ParseField METRICS = new ParseField(\"metrics\");\n+        public static final ParseField DEFAULT_METRIC = new ParseField(\"default_metric\");\n+    }\n+\n+    /**\n+     * Enum of aggregate metrics supported by this field mapper\n+     */\n+    public enum Metric {\n+        min,\n+        max,\n+        sum,\n+        value_count;\n+    }\n+\n+    public static class Defaults {\n+        public static final Explicit<Boolean> IGNORE_MALFORMED = new Explicit<>(false, false);\n+        public static final Explicit<Set<Metric>> METRICS = new Explicit<>(Collections.emptySet(), false);\n+        public static final Explicit<Metric> DEFAULT_METRIC = new Explicit<>(Metric.max, false);\n+        public static final AggregateDoubleMetricFieldType FIELD_TYPE = new AggregateDoubleMetricFieldType();\n+    }\n+\n+    public static class Builder extends FieldMapper.Builder<AggregateDoubleMetricFieldMapper.Builder, AggregateDoubleMetricFieldMapper> {\n+\n+        private Boolean ignoreMalformed;\n+\n+        /**\n+         * The aggregated metrics supported by the field type\n+         */\n+        private EnumSet<Metric> metrics;\n+\n+        /**\n+         * Set the default metric so that query operations are delegated to it.\n+         */\n+        private Metric defaultMetric;\n+\n+        public Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder ignoreMalformed(boolean ignoreMalformed) {\n+            this.ignoreMalformed = ignoreMalformed;\n+            return builder;\n+        }\n+\n+        protected Explicit<Boolean> ignoreMalformed(BuilderContext context) {\n+            if (ignoreMalformed != null) {\n+                return new Explicit<>(ignoreMalformed, true);\n+            }\n+            if (context.indexSettings() != null) {\n+                return new Explicit<>(IGNORE_MALFORMED_SETTING.get(context.indexSettings()), false);\n+            }\n+            return AggregateDoubleMetricFieldMapper.Defaults.IGNORE_MALFORMED;\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder defaultMetric(Metric defaultMetric) {\n+            this.defaultMetric = defaultMetric;\n+            return builder;\n+        }\n+\n+        protected Explicit<Metric> defaultMetric(BuilderContext context) {\n+            if (defaultMetric != null) {\n+                if (metrics != null && metrics.contains(defaultMetric) == false) {\n+                    // The default_metric is not defined in the \"metrics\" field\n+                    throw new IllegalArgumentException(\"Metric [\" + defaultMetric + \"] is not defined in the metrics field.\");\n+                }\n+                return new Explicit<>(defaultMetric, true);\n+            }\n+\n+            // If a single metric is contained, this should be the default\n+            if (metrics != null && metrics.size() == 1) {\n+                return new Explicit<>(metrics.iterator().next(), false);\n+            }\n+\n+            if (metrics.contains(Defaults.DEFAULT_METRIC.value())) {\n+                return Defaults.DEFAULT_METRIC;\n+            }\n+            throw new IllegalArgumentException(\n+                \"Property [\" + Names.DEFAULT_METRIC.getPreferredName() + \"] must be set for field [\" + name() + \"].\"\n+            );\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder metrics(EnumSet<Metric> metrics) {\n+            this.metrics = metrics;\n+            return builder;\n+        }\n+\n+        protected Explicit<Set<Metric>> metrics(BuilderContext context) {\n+            if (metrics != null) {\n+                return new Explicit<>(metrics, true);\n+            }\n+            return Defaults.METRICS;\n+        }\n+\n+        @Override\n+        public AggregateDoubleMetricFieldMapper build(BuilderContext context) {\n+            setupFieldType(context);\n+\n+            if (metrics == null || metrics.isEmpty()) {\n+                throw new IllegalArgumentException(\n+                    \"Property [\" + Names.METRICS.getPreferredName() + \"] must be set for field [\" + name() + \"].\"\n+                );\n+            }\n+\n+            EnumMap<Metric, NumberFieldMapper> metricMappers = new EnumMap<>(Metric.class);\n+            // Instantiate one NumberFieldMapper instance for each metric\n+            for (Metric m : this.metrics) {\n+                String fieldName = subfieldName(context.path().pathAsText(name), m);\n+                NumberFieldMapper.Builder builder;\n+\n+                if (m == Metric.value_count) {\n+                    // value_count metric can only be an integer and not a double\n+                    builder = new NumberFieldMapper.Builder(fieldName, NumberFieldMapper.NumberType.INTEGER);\n+                    builder.coerce(false);\n+                } else {\n+                    builder = new NumberFieldMapper.Builder(fieldName, NumberFieldMapper.NumberType.DOUBLE);\n+                }\n+                NumberFieldMapper fieldMapper = builder.build(context);\n+                metricMappers.put(m, fieldMapper);\n+            }\n+\n+            EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields = metricMappers.entrySet()\n+                .stream()\n+                .collect(\n+                    Collectors.toMap(\n+                        Map.Entry::getKey,\n+                        e -> e.getValue().fieldType(),\n+                        (l, r) -> { throw new IllegalArgumentException(\"Duplicate keys \" + l + \"and \" + r + \".\"); },\n+                        () -> new EnumMap<>(Metric.class)\n+                    )\n+                );\n+\n+            AggregateDoubleMetricFieldType metricFieldType = (AggregateDoubleMetricFieldType) fieldType;\n+            metricFieldType.setMetricFields(metricFields);\n+\n+            Explicit<Metric> defaultMetric = defaultMetric(context);\n+            metricFieldType.setDefaultMetric(defaultMetric.value());\n+\n+            return new AggregateDoubleMetricFieldMapper(\n+                name,\n+                metricFieldType,\n+                defaultFieldType,\n+                context.indexSettings(),\n+                multiFieldsBuilder.build(this, context),\n+                ignoreMalformed(context),\n+                metrics(context),\n+                defaultMetric,\n+                copyTo,\n+                metricMappers\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        @Override\n+        public Mapper.Builder<Builder, AggregateDoubleMetricFieldMapper> parse(\n+            String name,\n+            Map<String, Object> node,\n+            ParserContext parserContext\n+        ) throws MapperParsingException {\n+            AggregateDoubleMetricFieldMapper.Builder builder = new AggregateDoubleMetricFieldMapper.Builder(name);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(Names.METRICS.getPreferredName())) {\n+                    String metricsStr[] = XContentMapValues.nodeStringArrayValue(propNode);\n+                    // Make sure that metrics are supported\n+                    EnumSet<Metric> parsedMetrics = EnumSet.noneOf(Metric.class);\n+                    for (int i = 0; i < metricsStr.length; i++) {\n+                        try {\n+                            Metric m = Metric.valueOf(metricsStr[i]);\n+                            parsedMetrics.add(m);\n+                        } catch (IllegalArgumentException e) {\n+                            throw new IllegalArgumentException(\"Metric [\" + metricsStr[i] + \"] is not supported.\", e);\n+                        }\n+                    }\n+                    builder.metrics(parsedMetrics);\n+                    iterator.remove();\n+                } else if (propName.equals(Names.DEFAULT_METRIC.getPreferredName())) {\n+                    String defaultMetric = XContentMapValues.nodeStringValue(\n+                        propNode,\n+                        name + \".\" + Names.DEFAULT_METRIC.getPreferredName()\n+                    );\n+                    try {\n+                        Metric m = Metric.valueOf(defaultMetric);\n+                        builder.defaultMetric(m);\n+                        iterator.remove();\n+                    } catch (IllegalArgumentException e) {\n+                        throw new IllegalArgumentException(\"Metric [\" + defaultMetric + \"] is not supported.\", e);\n+                    }\n+                } else if (propName.equals(Names.IGNORE_MALFORMED.getPreferredName())) {\n+                    builder.ignoreMalformed(\n+                        XContentMapValues.nodeBooleanValue(propNode, name + \".\" + Names.IGNORE_MALFORMED.getPreferredName())\n+                    );\n+                    iterator.remove();\n+                } else if (TypeParsers.parseMultiField(builder, name, parserContext, propName, propNode)) {\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class AggregateDoubleMetricFieldType extends SimpleMappedFieldType {\n+\n+        private EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields;\n+\n+        private Metric defaultMetric;\n+\n+        public AggregateDoubleMetricFieldType() {}\n+\n+        AggregateDoubleMetricFieldType(AggregateDoubleMetricFieldType other) {\n+            super(other);\n+            this.metricFields = other.metricFields;\n+            this.defaultMetric = other.defaultMetric;\n+        }\n+\n+        @Override\n+        public MappedFieldType clone() {\n+            return new AggregateDoubleMetricFieldType(this);\n+        }\n+\n+        /**\n+         * Return a delegate field type for a given metric sub-field\n+         * @return a field type\n+         */\n+        private NumberFieldMapper.NumberFieldType delegateFieldType(Metric metric) {\n+            return metricFields.get(metric);\n+        }\n+\n+        /**\n+         * Return a delegate field type for the default metric sub-field\n+         * @return a field type\n+         */\n+        private NumberFieldMapper.NumberFieldType delegateFieldType() {\n+            return delegateFieldType(defaultMetric);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        private void setMetricFields(EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields) {\n+            checkIfFrozen();\n+            this.metricFields = metricFields;\n+        }\n+\n+        public void addMetricField(Metric m, NumberFieldMapper.NumberFieldType subfield) {\n+            checkIfFrozen();\n+            if (metricFields == null) {\n+                metricFields = new EnumMap<>(AggregateDoubleMetricFieldMapper.Metric.class);\n+            }\n+\n+            if (name() == null) {\n+                throw new IllegalArgumentException(\"Field of type [\" + typeName() + \"] must have a name before adding a subfield\");\n+            }\n+            String subfieldName = subfieldName(name(), m);\n+            subfield.setName(subfieldName);\n+            metricFields.put(m, subfield);\n+        }\n+\n+        public void setDefaultMetric(Metric defaultMetric) {\n+            checkIfFrozen();\n+            this.defaultMetric = defaultMetric;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return delegateFieldType().existsQuery(context);\n+        }\n+\n+        @Override\n+        public Query termQuery(Object value, QueryShardContext context) {\n+            return delegateFieldType().termQuery(value, context);\n+        }\n+\n+        @Override\n+        public Query termsQuery(List<?> values, QueryShardContext context) {\n+            return delegateFieldType().termsQuery(values, context);\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            return delegateFieldType().rangeQuery(lowerTerm, upperTerm, includeLower, includeUpper, context);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            return delegateFieldType().valueForDisplay(value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(String format, ZoneId timeZone) {\n+            return delegateFieldType().docValueFormat(format, timeZone);\n+        }\n+\n+        @Override\n+        public Relation isFieldWithinQuery(\n+            IndexReader reader,\n+            Object from,\n+            Object to,\n+            boolean includeLower,\n+            boolean includeUpper,\n+            ZoneId timeZone,\n+            DateMathParser dateMathParser,\n+            QueryRewriteContext context\n+        ) throws IOException {\n+            return delegateFieldType().isFieldWithinQuery(reader, from, to, includeLower, includeUpper, timeZone, dateMathParser, context);\n+        }\n+\n+        @Override\n+        public ValuesSourceType getValuesSourceType() {\n+            return AggregateMetricsValuesSourceType.AGGREGATE_METRIC;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            return new IndexFieldData.Builder() {\n+                @Override\n+                public IndexFieldData<?> build(\n+                    IndexSettings indexSettings,\n+                    MappedFieldType fieldType,\n+                    IndexFieldDataCache cache,\n+                    CircuitBreakerService breakerService,\n+                    MapperService mapperService\n+                ) {\n+                    return new IndexAggregateDoubleMetricFieldData(indexSettings.getIndex(), fieldType.name()) {\n+                        @Override\n+                        public LeafAggregateDoubleMetricFieldData load(LeafReaderContext context) {\n+                            return new LeafAggregateDoubleMetricFieldData() {\n+                                @Override\n+                                public SortedNumericDoubleValues getAggregateMetricValues(final Metric metric) throws IOException {\n+                                    try {\n+                                        final NumericDocValues values = DocValues.getNumeric(\n+                                            context.reader(),\n+                                            subfieldName(fieldName, metric)\n+                                        );\n+\n+                                        return new SortedNumericDoubleValues() {\n+                                            @Override\n+                                            public int docValueCount() {\n+                                                return 1;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDEzMzE5MQ=="}, "originalCommit": {"oid": "21da92a7fab32b4bc820eca6f000118ba4ff06ca"}, "originalPosition": 431}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4MTMyNzQ4OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapper.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxMTo1Njo1NFrOF9mN7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxNjo1NzoxM1rOGJOf1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDEzMzYxNQ==", "bodyText": "Shouldn't we return a sort field on the default metric ?", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r400133615", "createdAt": "2020-03-30T11:56:54Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapper.java", "diffHunk": "@@ -0,0 +1,689 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.aggregatemetric.mapper;\n+\n+import org.apache.lucene.index.DocValues;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.IndexableField;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.NumericDocValues;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.SortField;\n+import org.elasticsearch.common.Explicit;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.time.DateMathParser;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.XContentSubParser;\n+import org.elasticsearch.common.xcontent.support.XContentMapValues;\n+import org.elasticsearch.index.IndexSettings;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.IndexFieldDataCache;\n+import org.elasticsearch.index.fielddata.ScriptDocValues;\n+import org.elasticsearch.index.fielddata.SortedBinaryDocValues;\n+import org.elasticsearch.index.fielddata.SortedNumericDoubleValues;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SimpleMappedFieldType;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryRewriteContext;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.indices.breaker.CircuitBreakerService;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.MultiValueMode;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceType;\n+import org.elasticsearch.search.sort.BucketedSort;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.xpack.aggregatemetric.aggregations.support.AggregateMetricsValuesSourceType;\n+import org.elasticsearch.xpack.aggregatemetric.fielddata.IndexAggregateDoubleMetricFieldData;\n+import org.elasticsearch.xpack.aggregatemetric.fielddata.LeafAggregateDoubleMetricFieldData;\n+\n+import java.io.IOException;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.EnumMap;\n+import java.util.EnumSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import static org.elasticsearch.common.xcontent.XContentParserUtils.ensureExpectedToken;\n+\n+/** A {@link FieldMapper} for a field containing aggregate metrics such as min/max/value_count etc. */\n+public class AggregateDoubleMetricFieldMapper extends FieldMapper {\n+\n+    public static final String CONTENT_TYPE = \"aggregate_metric_double\";\n+    public static final String SUBFIELD_SEPARATOR = \"._\";\n+\n+    /**\n+     * Return the name of a subfield of an aggregate metric field\n+     *\n+     * @param fieldName the name of the aggregate metric field\n+     * @param metric    the metric type the subfield corresponds to\n+     * @return the name of the subfield\n+     */\n+    public static String subfieldName(String fieldName, Metric metric) {\n+        return fieldName + AggregateDoubleMetricFieldMapper.SUBFIELD_SEPARATOR + metric.name();\n+    }\n+\n+    /**\n+     * Mapping field names\n+     */\n+    public static class Names {\n+        public static final ParseField IGNORE_MALFORMED = new ParseField(\"ignore_malformed\");\n+        public static final ParseField METRICS = new ParseField(\"metrics\");\n+        public static final ParseField DEFAULT_METRIC = new ParseField(\"default_metric\");\n+    }\n+\n+    /**\n+     * Enum of aggregate metrics supported by this field mapper\n+     */\n+    public enum Metric {\n+        min,\n+        max,\n+        sum,\n+        value_count;\n+    }\n+\n+    public static class Defaults {\n+        public static final Explicit<Boolean> IGNORE_MALFORMED = new Explicit<>(false, false);\n+        public static final Explicit<Set<Metric>> METRICS = new Explicit<>(Collections.emptySet(), false);\n+        public static final Explicit<Metric> DEFAULT_METRIC = new Explicit<>(Metric.max, false);\n+        public static final AggregateDoubleMetricFieldType FIELD_TYPE = new AggregateDoubleMetricFieldType();\n+    }\n+\n+    public static class Builder extends FieldMapper.Builder<AggregateDoubleMetricFieldMapper.Builder, AggregateDoubleMetricFieldMapper> {\n+\n+        private Boolean ignoreMalformed;\n+\n+        /**\n+         * The aggregated metrics supported by the field type\n+         */\n+        private EnumSet<Metric> metrics;\n+\n+        /**\n+         * Set the default metric so that query operations are delegated to it.\n+         */\n+        private Metric defaultMetric;\n+\n+        public Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder ignoreMalformed(boolean ignoreMalformed) {\n+            this.ignoreMalformed = ignoreMalformed;\n+            return builder;\n+        }\n+\n+        protected Explicit<Boolean> ignoreMalformed(BuilderContext context) {\n+            if (ignoreMalformed != null) {\n+                return new Explicit<>(ignoreMalformed, true);\n+            }\n+            if (context.indexSettings() != null) {\n+                return new Explicit<>(IGNORE_MALFORMED_SETTING.get(context.indexSettings()), false);\n+            }\n+            return AggregateDoubleMetricFieldMapper.Defaults.IGNORE_MALFORMED;\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder defaultMetric(Metric defaultMetric) {\n+            this.defaultMetric = defaultMetric;\n+            return builder;\n+        }\n+\n+        protected Explicit<Metric> defaultMetric(BuilderContext context) {\n+            if (defaultMetric != null) {\n+                if (metrics != null && metrics.contains(defaultMetric) == false) {\n+                    // The default_metric is not defined in the \"metrics\" field\n+                    throw new IllegalArgumentException(\"Metric [\" + defaultMetric + \"] is not defined in the metrics field.\");\n+                }\n+                return new Explicit<>(defaultMetric, true);\n+            }\n+\n+            // If a single metric is contained, this should be the default\n+            if (metrics != null && metrics.size() == 1) {\n+                return new Explicit<>(metrics.iterator().next(), false);\n+            }\n+\n+            if (metrics.contains(Defaults.DEFAULT_METRIC.value())) {\n+                return Defaults.DEFAULT_METRIC;\n+            }\n+            throw new IllegalArgumentException(\n+                \"Property [\" + Names.DEFAULT_METRIC.getPreferredName() + \"] must be set for field [\" + name() + \"].\"\n+            );\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder metrics(EnumSet<Metric> metrics) {\n+            this.metrics = metrics;\n+            return builder;\n+        }\n+\n+        protected Explicit<Set<Metric>> metrics(BuilderContext context) {\n+            if (metrics != null) {\n+                return new Explicit<>(metrics, true);\n+            }\n+            return Defaults.METRICS;\n+        }\n+\n+        @Override\n+        public AggregateDoubleMetricFieldMapper build(BuilderContext context) {\n+            setupFieldType(context);\n+\n+            if (metrics == null || metrics.isEmpty()) {\n+                throw new IllegalArgumentException(\n+                    \"Property [\" + Names.METRICS.getPreferredName() + \"] must be set for field [\" + name() + \"].\"\n+                );\n+            }\n+\n+            EnumMap<Metric, NumberFieldMapper> metricMappers = new EnumMap<>(Metric.class);\n+            // Instantiate one NumberFieldMapper instance for each metric\n+            for (Metric m : this.metrics) {\n+                String fieldName = subfieldName(context.path().pathAsText(name), m);\n+                NumberFieldMapper.Builder builder;\n+\n+                if (m == Metric.value_count) {\n+                    // value_count metric can only be an integer and not a double\n+                    builder = new NumberFieldMapper.Builder(fieldName, NumberFieldMapper.NumberType.INTEGER);\n+                    builder.coerce(false);\n+                } else {\n+                    builder = new NumberFieldMapper.Builder(fieldName, NumberFieldMapper.NumberType.DOUBLE);\n+                }\n+                NumberFieldMapper fieldMapper = builder.build(context);\n+                metricMappers.put(m, fieldMapper);\n+            }\n+\n+            EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields = metricMappers.entrySet()\n+                .stream()\n+                .collect(\n+                    Collectors.toMap(\n+                        Map.Entry::getKey,\n+                        e -> e.getValue().fieldType(),\n+                        (l, r) -> { throw new IllegalArgumentException(\"Duplicate keys \" + l + \"and \" + r + \".\"); },\n+                        () -> new EnumMap<>(Metric.class)\n+                    )\n+                );\n+\n+            AggregateDoubleMetricFieldType metricFieldType = (AggregateDoubleMetricFieldType) fieldType;\n+            metricFieldType.setMetricFields(metricFields);\n+\n+            Explicit<Metric> defaultMetric = defaultMetric(context);\n+            metricFieldType.setDefaultMetric(defaultMetric.value());\n+\n+            return new AggregateDoubleMetricFieldMapper(\n+                name,\n+                metricFieldType,\n+                defaultFieldType,\n+                context.indexSettings(),\n+                multiFieldsBuilder.build(this, context),\n+                ignoreMalformed(context),\n+                metrics(context),\n+                defaultMetric,\n+                copyTo,\n+                metricMappers\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        @Override\n+        public Mapper.Builder<Builder, AggregateDoubleMetricFieldMapper> parse(\n+            String name,\n+            Map<String, Object> node,\n+            ParserContext parserContext\n+        ) throws MapperParsingException {\n+            AggregateDoubleMetricFieldMapper.Builder builder = new AggregateDoubleMetricFieldMapper.Builder(name);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(Names.METRICS.getPreferredName())) {\n+                    String metricsStr[] = XContentMapValues.nodeStringArrayValue(propNode);\n+                    // Make sure that metrics are supported\n+                    EnumSet<Metric> parsedMetrics = EnumSet.noneOf(Metric.class);\n+                    for (int i = 0; i < metricsStr.length; i++) {\n+                        try {\n+                            Metric m = Metric.valueOf(metricsStr[i]);\n+                            parsedMetrics.add(m);\n+                        } catch (IllegalArgumentException e) {\n+                            throw new IllegalArgumentException(\"Metric [\" + metricsStr[i] + \"] is not supported.\", e);\n+                        }\n+                    }\n+                    builder.metrics(parsedMetrics);\n+                    iterator.remove();\n+                } else if (propName.equals(Names.DEFAULT_METRIC.getPreferredName())) {\n+                    String defaultMetric = XContentMapValues.nodeStringValue(\n+                        propNode,\n+                        name + \".\" + Names.DEFAULT_METRIC.getPreferredName()\n+                    );\n+                    try {\n+                        Metric m = Metric.valueOf(defaultMetric);\n+                        builder.defaultMetric(m);\n+                        iterator.remove();\n+                    } catch (IllegalArgumentException e) {\n+                        throw new IllegalArgumentException(\"Metric [\" + defaultMetric + \"] is not supported.\", e);\n+                    }\n+                } else if (propName.equals(Names.IGNORE_MALFORMED.getPreferredName())) {\n+                    builder.ignoreMalformed(\n+                        XContentMapValues.nodeBooleanValue(propNode, name + \".\" + Names.IGNORE_MALFORMED.getPreferredName())\n+                    );\n+                    iterator.remove();\n+                } else if (TypeParsers.parseMultiField(builder, name, parserContext, propName, propNode)) {\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class AggregateDoubleMetricFieldType extends SimpleMappedFieldType {\n+\n+        private EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields;\n+\n+        private Metric defaultMetric;\n+\n+        public AggregateDoubleMetricFieldType() {}\n+\n+        AggregateDoubleMetricFieldType(AggregateDoubleMetricFieldType other) {\n+            super(other);\n+            this.metricFields = other.metricFields;\n+            this.defaultMetric = other.defaultMetric;\n+        }\n+\n+        @Override\n+        public MappedFieldType clone() {\n+            return new AggregateDoubleMetricFieldType(this);\n+        }\n+\n+        /**\n+         * Return a delegate field type for a given metric sub-field\n+         * @return a field type\n+         */\n+        private NumberFieldMapper.NumberFieldType delegateFieldType(Metric metric) {\n+            return metricFields.get(metric);\n+        }\n+\n+        /**\n+         * Return a delegate field type for the default metric sub-field\n+         * @return a field type\n+         */\n+        private NumberFieldMapper.NumberFieldType delegateFieldType() {\n+            return delegateFieldType(defaultMetric);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        private void setMetricFields(EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields) {\n+            checkIfFrozen();\n+            this.metricFields = metricFields;\n+        }\n+\n+        public void addMetricField(Metric m, NumberFieldMapper.NumberFieldType subfield) {\n+            checkIfFrozen();\n+            if (metricFields == null) {\n+                metricFields = new EnumMap<>(AggregateDoubleMetricFieldMapper.Metric.class);\n+            }\n+\n+            if (name() == null) {\n+                throw new IllegalArgumentException(\"Field of type [\" + typeName() + \"] must have a name before adding a subfield\");\n+            }\n+            String subfieldName = subfieldName(name(), m);\n+            subfield.setName(subfieldName);\n+            metricFields.put(m, subfield);\n+        }\n+\n+        public void setDefaultMetric(Metric defaultMetric) {\n+            checkIfFrozen();\n+            this.defaultMetric = defaultMetric;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return delegateFieldType().existsQuery(context);\n+        }\n+\n+        @Override\n+        public Query termQuery(Object value, QueryShardContext context) {\n+            return delegateFieldType().termQuery(value, context);\n+        }\n+\n+        @Override\n+        public Query termsQuery(List<?> values, QueryShardContext context) {\n+            return delegateFieldType().termsQuery(values, context);\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            return delegateFieldType().rangeQuery(lowerTerm, upperTerm, includeLower, includeUpper, context);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            return delegateFieldType().valueForDisplay(value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(String format, ZoneId timeZone) {\n+            return delegateFieldType().docValueFormat(format, timeZone);\n+        }\n+\n+        @Override\n+        public Relation isFieldWithinQuery(\n+            IndexReader reader,\n+            Object from,\n+            Object to,\n+            boolean includeLower,\n+            boolean includeUpper,\n+            ZoneId timeZone,\n+            DateMathParser dateMathParser,\n+            QueryRewriteContext context\n+        ) throws IOException {\n+            return delegateFieldType().isFieldWithinQuery(reader, from, to, includeLower, includeUpper, timeZone, dateMathParser, context);\n+        }\n+\n+        @Override\n+        public ValuesSourceType getValuesSourceType() {\n+            return AggregateMetricsValuesSourceType.AGGREGATE_METRIC;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            return new IndexFieldData.Builder() {\n+                @Override\n+                public IndexFieldData<?> build(\n+                    IndexSettings indexSettings,\n+                    MappedFieldType fieldType,\n+                    IndexFieldDataCache cache,\n+                    CircuitBreakerService breakerService,\n+                    MapperService mapperService\n+                ) {\n+                    return new IndexAggregateDoubleMetricFieldData(indexSettings.getIndex(), fieldType.name()) {\n+                        @Override\n+                        public LeafAggregateDoubleMetricFieldData load(LeafReaderContext context) {\n+                            return new LeafAggregateDoubleMetricFieldData() {\n+                                @Override\n+                                public SortedNumericDoubleValues getAggregateMetricValues(final Metric metric) throws IOException {\n+                                    try {\n+                                        final NumericDocValues values = DocValues.getNumeric(\n+                                            context.reader(),\n+                                            subfieldName(fieldName, metric)\n+                                        );\n+\n+                                        return new SortedNumericDoubleValues() {\n+                                            @Override\n+                                            public int docValueCount() {\n+                                                return 1;\n+                                            }\n+\n+                                            @Override\n+                                            public boolean advanceExact(int doc) throws IOException {\n+                                                return values.advanceExact(doc);\n+                                            }\n+\n+                                            @Override\n+                                            public double nextValue() throws IOException {\n+                                                return Double.longBitsToDouble(values.longValue());\n+                                            }\n+                                        };\n+                                    } catch (IOException e) {\n+                                        throw new IOException(\"Cannot load doc values\", e);\n+                                    }\n+                                }\n+\n+                                @Override\n+                                public ScriptDocValues<?> getScriptValues() {\n+                                    throw new UnsupportedOperationException(\n+                                        \"The [\" + CONTENT_TYPE + \"] field does not \" + \"support scripts\"\n+                                    );\n+                                }\n+\n+                                @Override\n+                                public SortedBinaryDocValues getBytesValues() {\n+                                    throw new UnsupportedOperationException(\n+                                        \"String representation of doc values \" + \"for [\" + CONTENT_TYPE + \"] fields is not supported\"\n+                                    );\n+                                }\n+\n+                                @Override\n+                                public long ramBytesUsed() {\n+                                    return 0; // Unknown\n+                                }\n+\n+                                @Override\n+                                public void close() {}\n+                            };\n+                        }\n+\n+                        @Override\n+                        public LeafAggregateDoubleMetricFieldData loadDirect(LeafReaderContext context) {\n+                            return load(context);\n+                        }\n+\n+                        @Override\n+                        public SortField sortField(\n+                            Object missingValue,\n+                            MultiValueMode sortMode,\n+                            XFieldComparatorSource.Nested nested,\n+                            boolean reverse\n+                        ) {\n+                            throw new UnsupportedOperationException(\"can't sort on the [\" + CONTENT_TYPE + \"] field\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "21da92a7fab32b4bc820eca6f000118ba4ff06ca"}, "originalPosition": 485}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjMyNzg5Mg==", "bodyText": "Fixed at 022dac2", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r412327892", "createdAt": "2020-04-21T16:57:13Z", "author": {"login": "csoulios"}, "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapper.java", "diffHunk": "@@ -0,0 +1,689 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.aggregatemetric.mapper;\n+\n+import org.apache.lucene.index.DocValues;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.IndexableField;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.NumericDocValues;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.SortField;\n+import org.elasticsearch.common.Explicit;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.time.DateMathParser;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.XContentSubParser;\n+import org.elasticsearch.common.xcontent.support.XContentMapValues;\n+import org.elasticsearch.index.IndexSettings;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.IndexFieldDataCache;\n+import org.elasticsearch.index.fielddata.ScriptDocValues;\n+import org.elasticsearch.index.fielddata.SortedBinaryDocValues;\n+import org.elasticsearch.index.fielddata.SortedNumericDoubleValues;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SimpleMappedFieldType;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryRewriteContext;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.indices.breaker.CircuitBreakerService;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.MultiValueMode;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceType;\n+import org.elasticsearch.search.sort.BucketedSort;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.xpack.aggregatemetric.aggregations.support.AggregateMetricsValuesSourceType;\n+import org.elasticsearch.xpack.aggregatemetric.fielddata.IndexAggregateDoubleMetricFieldData;\n+import org.elasticsearch.xpack.aggregatemetric.fielddata.LeafAggregateDoubleMetricFieldData;\n+\n+import java.io.IOException;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.EnumMap;\n+import java.util.EnumSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import static org.elasticsearch.common.xcontent.XContentParserUtils.ensureExpectedToken;\n+\n+/** A {@link FieldMapper} for a field containing aggregate metrics such as min/max/value_count etc. */\n+public class AggregateDoubleMetricFieldMapper extends FieldMapper {\n+\n+    public static final String CONTENT_TYPE = \"aggregate_metric_double\";\n+    public static final String SUBFIELD_SEPARATOR = \"._\";\n+\n+    /**\n+     * Return the name of a subfield of an aggregate metric field\n+     *\n+     * @param fieldName the name of the aggregate metric field\n+     * @param metric    the metric type the subfield corresponds to\n+     * @return the name of the subfield\n+     */\n+    public static String subfieldName(String fieldName, Metric metric) {\n+        return fieldName + AggregateDoubleMetricFieldMapper.SUBFIELD_SEPARATOR + metric.name();\n+    }\n+\n+    /**\n+     * Mapping field names\n+     */\n+    public static class Names {\n+        public static final ParseField IGNORE_MALFORMED = new ParseField(\"ignore_malformed\");\n+        public static final ParseField METRICS = new ParseField(\"metrics\");\n+        public static final ParseField DEFAULT_METRIC = new ParseField(\"default_metric\");\n+    }\n+\n+    /**\n+     * Enum of aggregate metrics supported by this field mapper\n+     */\n+    public enum Metric {\n+        min,\n+        max,\n+        sum,\n+        value_count;\n+    }\n+\n+    public static class Defaults {\n+        public static final Explicit<Boolean> IGNORE_MALFORMED = new Explicit<>(false, false);\n+        public static final Explicit<Set<Metric>> METRICS = new Explicit<>(Collections.emptySet(), false);\n+        public static final Explicit<Metric> DEFAULT_METRIC = new Explicit<>(Metric.max, false);\n+        public static final AggregateDoubleMetricFieldType FIELD_TYPE = new AggregateDoubleMetricFieldType();\n+    }\n+\n+    public static class Builder extends FieldMapper.Builder<AggregateDoubleMetricFieldMapper.Builder, AggregateDoubleMetricFieldMapper> {\n+\n+        private Boolean ignoreMalformed;\n+\n+        /**\n+         * The aggregated metrics supported by the field type\n+         */\n+        private EnumSet<Metric> metrics;\n+\n+        /**\n+         * Set the default metric so that query operations are delegated to it.\n+         */\n+        private Metric defaultMetric;\n+\n+        public Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder ignoreMalformed(boolean ignoreMalformed) {\n+            this.ignoreMalformed = ignoreMalformed;\n+            return builder;\n+        }\n+\n+        protected Explicit<Boolean> ignoreMalformed(BuilderContext context) {\n+            if (ignoreMalformed != null) {\n+                return new Explicit<>(ignoreMalformed, true);\n+            }\n+            if (context.indexSettings() != null) {\n+                return new Explicit<>(IGNORE_MALFORMED_SETTING.get(context.indexSettings()), false);\n+            }\n+            return AggregateDoubleMetricFieldMapper.Defaults.IGNORE_MALFORMED;\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder defaultMetric(Metric defaultMetric) {\n+            this.defaultMetric = defaultMetric;\n+            return builder;\n+        }\n+\n+        protected Explicit<Metric> defaultMetric(BuilderContext context) {\n+            if (defaultMetric != null) {\n+                if (metrics != null && metrics.contains(defaultMetric) == false) {\n+                    // The default_metric is not defined in the \"metrics\" field\n+                    throw new IllegalArgumentException(\"Metric [\" + defaultMetric + \"] is not defined in the metrics field.\");\n+                }\n+                return new Explicit<>(defaultMetric, true);\n+            }\n+\n+            // If a single metric is contained, this should be the default\n+            if (metrics != null && metrics.size() == 1) {\n+                return new Explicit<>(metrics.iterator().next(), false);\n+            }\n+\n+            if (metrics.contains(Defaults.DEFAULT_METRIC.value())) {\n+                return Defaults.DEFAULT_METRIC;\n+            }\n+            throw new IllegalArgumentException(\n+                \"Property [\" + Names.DEFAULT_METRIC.getPreferredName() + \"] must be set for field [\" + name() + \"].\"\n+            );\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder metrics(EnumSet<Metric> metrics) {\n+            this.metrics = metrics;\n+            return builder;\n+        }\n+\n+        protected Explicit<Set<Metric>> metrics(BuilderContext context) {\n+            if (metrics != null) {\n+                return new Explicit<>(metrics, true);\n+            }\n+            return Defaults.METRICS;\n+        }\n+\n+        @Override\n+        public AggregateDoubleMetricFieldMapper build(BuilderContext context) {\n+            setupFieldType(context);\n+\n+            if (metrics == null || metrics.isEmpty()) {\n+                throw new IllegalArgumentException(\n+                    \"Property [\" + Names.METRICS.getPreferredName() + \"] must be set for field [\" + name() + \"].\"\n+                );\n+            }\n+\n+            EnumMap<Metric, NumberFieldMapper> metricMappers = new EnumMap<>(Metric.class);\n+            // Instantiate one NumberFieldMapper instance for each metric\n+            for (Metric m : this.metrics) {\n+                String fieldName = subfieldName(context.path().pathAsText(name), m);\n+                NumberFieldMapper.Builder builder;\n+\n+                if (m == Metric.value_count) {\n+                    // value_count metric can only be an integer and not a double\n+                    builder = new NumberFieldMapper.Builder(fieldName, NumberFieldMapper.NumberType.INTEGER);\n+                    builder.coerce(false);\n+                } else {\n+                    builder = new NumberFieldMapper.Builder(fieldName, NumberFieldMapper.NumberType.DOUBLE);\n+                }\n+                NumberFieldMapper fieldMapper = builder.build(context);\n+                metricMappers.put(m, fieldMapper);\n+            }\n+\n+            EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields = metricMappers.entrySet()\n+                .stream()\n+                .collect(\n+                    Collectors.toMap(\n+                        Map.Entry::getKey,\n+                        e -> e.getValue().fieldType(),\n+                        (l, r) -> { throw new IllegalArgumentException(\"Duplicate keys \" + l + \"and \" + r + \".\"); },\n+                        () -> new EnumMap<>(Metric.class)\n+                    )\n+                );\n+\n+            AggregateDoubleMetricFieldType metricFieldType = (AggregateDoubleMetricFieldType) fieldType;\n+            metricFieldType.setMetricFields(metricFields);\n+\n+            Explicit<Metric> defaultMetric = defaultMetric(context);\n+            metricFieldType.setDefaultMetric(defaultMetric.value());\n+\n+            return new AggregateDoubleMetricFieldMapper(\n+                name,\n+                metricFieldType,\n+                defaultFieldType,\n+                context.indexSettings(),\n+                multiFieldsBuilder.build(this, context),\n+                ignoreMalformed(context),\n+                metrics(context),\n+                defaultMetric,\n+                copyTo,\n+                metricMappers\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        @Override\n+        public Mapper.Builder<Builder, AggregateDoubleMetricFieldMapper> parse(\n+            String name,\n+            Map<String, Object> node,\n+            ParserContext parserContext\n+        ) throws MapperParsingException {\n+            AggregateDoubleMetricFieldMapper.Builder builder = new AggregateDoubleMetricFieldMapper.Builder(name);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(Names.METRICS.getPreferredName())) {\n+                    String metricsStr[] = XContentMapValues.nodeStringArrayValue(propNode);\n+                    // Make sure that metrics are supported\n+                    EnumSet<Metric> parsedMetrics = EnumSet.noneOf(Metric.class);\n+                    for (int i = 0; i < metricsStr.length; i++) {\n+                        try {\n+                            Metric m = Metric.valueOf(metricsStr[i]);\n+                            parsedMetrics.add(m);\n+                        } catch (IllegalArgumentException e) {\n+                            throw new IllegalArgumentException(\"Metric [\" + metricsStr[i] + \"] is not supported.\", e);\n+                        }\n+                    }\n+                    builder.metrics(parsedMetrics);\n+                    iterator.remove();\n+                } else if (propName.equals(Names.DEFAULT_METRIC.getPreferredName())) {\n+                    String defaultMetric = XContentMapValues.nodeStringValue(\n+                        propNode,\n+                        name + \".\" + Names.DEFAULT_METRIC.getPreferredName()\n+                    );\n+                    try {\n+                        Metric m = Metric.valueOf(defaultMetric);\n+                        builder.defaultMetric(m);\n+                        iterator.remove();\n+                    } catch (IllegalArgumentException e) {\n+                        throw new IllegalArgumentException(\"Metric [\" + defaultMetric + \"] is not supported.\", e);\n+                    }\n+                } else if (propName.equals(Names.IGNORE_MALFORMED.getPreferredName())) {\n+                    builder.ignoreMalformed(\n+                        XContentMapValues.nodeBooleanValue(propNode, name + \".\" + Names.IGNORE_MALFORMED.getPreferredName())\n+                    );\n+                    iterator.remove();\n+                } else if (TypeParsers.parseMultiField(builder, name, parserContext, propName, propNode)) {\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class AggregateDoubleMetricFieldType extends SimpleMappedFieldType {\n+\n+        private EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields;\n+\n+        private Metric defaultMetric;\n+\n+        public AggregateDoubleMetricFieldType() {}\n+\n+        AggregateDoubleMetricFieldType(AggregateDoubleMetricFieldType other) {\n+            super(other);\n+            this.metricFields = other.metricFields;\n+            this.defaultMetric = other.defaultMetric;\n+        }\n+\n+        @Override\n+        public MappedFieldType clone() {\n+            return new AggregateDoubleMetricFieldType(this);\n+        }\n+\n+        /**\n+         * Return a delegate field type for a given metric sub-field\n+         * @return a field type\n+         */\n+        private NumberFieldMapper.NumberFieldType delegateFieldType(Metric metric) {\n+            return metricFields.get(metric);\n+        }\n+\n+        /**\n+         * Return a delegate field type for the default metric sub-field\n+         * @return a field type\n+         */\n+        private NumberFieldMapper.NumberFieldType delegateFieldType() {\n+            return delegateFieldType(defaultMetric);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        private void setMetricFields(EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields) {\n+            checkIfFrozen();\n+            this.metricFields = metricFields;\n+        }\n+\n+        public void addMetricField(Metric m, NumberFieldMapper.NumberFieldType subfield) {\n+            checkIfFrozen();\n+            if (metricFields == null) {\n+                metricFields = new EnumMap<>(AggregateDoubleMetricFieldMapper.Metric.class);\n+            }\n+\n+            if (name() == null) {\n+                throw new IllegalArgumentException(\"Field of type [\" + typeName() + \"] must have a name before adding a subfield\");\n+            }\n+            String subfieldName = subfieldName(name(), m);\n+            subfield.setName(subfieldName);\n+            metricFields.put(m, subfield);\n+        }\n+\n+        public void setDefaultMetric(Metric defaultMetric) {\n+            checkIfFrozen();\n+            this.defaultMetric = defaultMetric;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return delegateFieldType().existsQuery(context);\n+        }\n+\n+        @Override\n+        public Query termQuery(Object value, QueryShardContext context) {\n+            return delegateFieldType().termQuery(value, context);\n+        }\n+\n+        @Override\n+        public Query termsQuery(List<?> values, QueryShardContext context) {\n+            return delegateFieldType().termsQuery(values, context);\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            return delegateFieldType().rangeQuery(lowerTerm, upperTerm, includeLower, includeUpper, context);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            return delegateFieldType().valueForDisplay(value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(String format, ZoneId timeZone) {\n+            return delegateFieldType().docValueFormat(format, timeZone);\n+        }\n+\n+        @Override\n+        public Relation isFieldWithinQuery(\n+            IndexReader reader,\n+            Object from,\n+            Object to,\n+            boolean includeLower,\n+            boolean includeUpper,\n+            ZoneId timeZone,\n+            DateMathParser dateMathParser,\n+            QueryRewriteContext context\n+        ) throws IOException {\n+            return delegateFieldType().isFieldWithinQuery(reader, from, to, includeLower, includeUpper, timeZone, dateMathParser, context);\n+        }\n+\n+        @Override\n+        public ValuesSourceType getValuesSourceType() {\n+            return AggregateMetricsValuesSourceType.AGGREGATE_METRIC;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            return new IndexFieldData.Builder() {\n+                @Override\n+                public IndexFieldData<?> build(\n+                    IndexSettings indexSettings,\n+                    MappedFieldType fieldType,\n+                    IndexFieldDataCache cache,\n+                    CircuitBreakerService breakerService,\n+                    MapperService mapperService\n+                ) {\n+                    return new IndexAggregateDoubleMetricFieldData(indexSettings.getIndex(), fieldType.name()) {\n+                        @Override\n+                        public LeafAggregateDoubleMetricFieldData load(LeafReaderContext context) {\n+                            return new LeafAggregateDoubleMetricFieldData() {\n+                                @Override\n+                                public SortedNumericDoubleValues getAggregateMetricValues(final Metric metric) throws IOException {\n+                                    try {\n+                                        final NumericDocValues values = DocValues.getNumeric(\n+                                            context.reader(),\n+                                            subfieldName(fieldName, metric)\n+                                        );\n+\n+                                        return new SortedNumericDoubleValues() {\n+                                            @Override\n+                                            public int docValueCount() {\n+                                                return 1;\n+                                            }\n+\n+                                            @Override\n+                                            public boolean advanceExact(int doc) throws IOException {\n+                                                return values.advanceExact(doc);\n+                                            }\n+\n+                                            @Override\n+                                            public double nextValue() throws IOException {\n+                                                return Double.longBitsToDouble(values.longValue());\n+                                            }\n+                                        };\n+                                    } catch (IOException e) {\n+                                        throw new IOException(\"Cannot load doc values\", e);\n+                                    }\n+                                }\n+\n+                                @Override\n+                                public ScriptDocValues<?> getScriptValues() {\n+                                    throw new UnsupportedOperationException(\n+                                        \"The [\" + CONTENT_TYPE + \"] field does not \" + \"support scripts\"\n+                                    );\n+                                }\n+\n+                                @Override\n+                                public SortedBinaryDocValues getBytesValues() {\n+                                    throw new UnsupportedOperationException(\n+                                        \"String representation of doc values \" + \"for [\" + CONTENT_TYPE + \"] fields is not supported\"\n+                                    );\n+                                }\n+\n+                                @Override\n+                                public long ramBytesUsed() {\n+                                    return 0; // Unknown\n+                                }\n+\n+                                @Override\n+                                public void close() {}\n+                            };\n+                        }\n+\n+                        @Override\n+                        public LeafAggregateDoubleMetricFieldData loadDirect(LeafReaderContext context) {\n+                            return load(context);\n+                        }\n+\n+                        @Override\n+                        public SortField sortField(\n+                            Object missingValue,\n+                            MultiValueMode sortMode,\n+                            XFieldComparatorSource.Nested nested,\n+                            boolean reverse\n+                        ) {\n+                            throw new UnsupportedOperationException(\"can't sort on the [\" + CONTENT_TYPE + \"] field\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDEzMzYxNQ=="}, "originalCommit": {"oid": "21da92a7fab32b4bc820eca6f000118ba4ff06ca"}, "originalPosition": 485}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4MTMzMDg2OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapper.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxMTo1Nzo1N1rOF9mQIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxMTo1Nzo1N1rOF9mQIA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDEzNDE3Ng==", "bodyText": "nit: can you indent the alternatives ?", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r400134176", "createdAt": "2020-03-30T11:57:57Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapper.java", "diffHunk": "@@ -0,0 +1,689 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.aggregatemetric.mapper;\n+\n+import org.apache.lucene.index.DocValues;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.IndexableField;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.NumericDocValues;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.SortField;\n+import org.elasticsearch.common.Explicit;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.time.DateMathParser;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.XContentSubParser;\n+import org.elasticsearch.common.xcontent.support.XContentMapValues;\n+import org.elasticsearch.index.IndexSettings;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.IndexFieldDataCache;\n+import org.elasticsearch.index.fielddata.ScriptDocValues;\n+import org.elasticsearch.index.fielddata.SortedBinaryDocValues;\n+import org.elasticsearch.index.fielddata.SortedNumericDoubleValues;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SimpleMappedFieldType;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryRewriteContext;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.indices.breaker.CircuitBreakerService;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.MultiValueMode;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceType;\n+import org.elasticsearch.search.sort.BucketedSort;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.xpack.aggregatemetric.aggregations.support.AggregateMetricsValuesSourceType;\n+import org.elasticsearch.xpack.aggregatemetric.fielddata.IndexAggregateDoubleMetricFieldData;\n+import org.elasticsearch.xpack.aggregatemetric.fielddata.LeafAggregateDoubleMetricFieldData;\n+\n+import java.io.IOException;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.EnumMap;\n+import java.util.EnumSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import static org.elasticsearch.common.xcontent.XContentParserUtils.ensureExpectedToken;\n+\n+/** A {@link FieldMapper} for a field containing aggregate metrics such as min/max/value_count etc. */\n+public class AggregateDoubleMetricFieldMapper extends FieldMapper {\n+\n+    public static final String CONTENT_TYPE = \"aggregate_metric_double\";\n+    public static final String SUBFIELD_SEPARATOR = \"._\";\n+\n+    /**\n+     * Return the name of a subfield of an aggregate metric field\n+     *\n+     * @param fieldName the name of the aggregate metric field\n+     * @param metric    the metric type the subfield corresponds to\n+     * @return the name of the subfield\n+     */\n+    public static String subfieldName(String fieldName, Metric metric) {\n+        return fieldName + AggregateDoubleMetricFieldMapper.SUBFIELD_SEPARATOR + metric.name();\n+    }\n+\n+    /**\n+     * Mapping field names\n+     */\n+    public static class Names {\n+        public static final ParseField IGNORE_MALFORMED = new ParseField(\"ignore_malformed\");\n+        public static final ParseField METRICS = new ParseField(\"metrics\");\n+        public static final ParseField DEFAULT_METRIC = new ParseField(\"default_metric\");\n+    }\n+\n+    /**\n+     * Enum of aggregate metrics supported by this field mapper\n+     */\n+    public enum Metric {\n+        min,\n+        max,\n+        sum,\n+        value_count;\n+    }\n+\n+    public static class Defaults {\n+        public static final Explicit<Boolean> IGNORE_MALFORMED = new Explicit<>(false, false);\n+        public static final Explicit<Set<Metric>> METRICS = new Explicit<>(Collections.emptySet(), false);\n+        public static final Explicit<Metric> DEFAULT_METRIC = new Explicit<>(Metric.max, false);\n+        public static final AggregateDoubleMetricFieldType FIELD_TYPE = new AggregateDoubleMetricFieldType();\n+    }\n+\n+    public static class Builder extends FieldMapper.Builder<AggregateDoubleMetricFieldMapper.Builder, AggregateDoubleMetricFieldMapper> {\n+\n+        private Boolean ignoreMalformed;\n+\n+        /**\n+         * The aggregated metrics supported by the field type\n+         */\n+        private EnumSet<Metric> metrics;\n+\n+        /**\n+         * Set the default metric so that query operations are delegated to it.\n+         */\n+        private Metric defaultMetric;\n+\n+        public Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder ignoreMalformed(boolean ignoreMalformed) {\n+            this.ignoreMalformed = ignoreMalformed;\n+            return builder;\n+        }\n+\n+        protected Explicit<Boolean> ignoreMalformed(BuilderContext context) {\n+            if (ignoreMalformed != null) {\n+                return new Explicit<>(ignoreMalformed, true);\n+            }\n+            if (context.indexSettings() != null) {\n+                return new Explicit<>(IGNORE_MALFORMED_SETTING.get(context.indexSettings()), false);\n+            }\n+            return AggregateDoubleMetricFieldMapper.Defaults.IGNORE_MALFORMED;\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder defaultMetric(Metric defaultMetric) {\n+            this.defaultMetric = defaultMetric;\n+            return builder;\n+        }\n+\n+        protected Explicit<Metric> defaultMetric(BuilderContext context) {\n+            if (defaultMetric != null) {\n+                if (metrics != null && metrics.contains(defaultMetric) == false) {\n+                    // The default_metric is not defined in the \"metrics\" field\n+                    throw new IllegalArgumentException(\"Metric [\" + defaultMetric + \"] is not defined in the metrics field.\");\n+                }\n+                return new Explicit<>(defaultMetric, true);\n+            }\n+\n+            // If a single metric is contained, this should be the default\n+            if (metrics != null && metrics.size() == 1) {\n+                return new Explicit<>(metrics.iterator().next(), false);\n+            }\n+\n+            if (metrics.contains(Defaults.DEFAULT_METRIC.value())) {\n+                return Defaults.DEFAULT_METRIC;\n+            }\n+            throw new IllegalArgumentException(\n+                \"Property [\" + Names.DEFAULT_METRIC.getPreferredName() + \"] must be set for field [\" + name() + \"].\"\n+            );\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder metrics(EnumSet<Metric> metrics) {\n+            this.metrics = metrics;\n+            return builder;\n+        }\n+\n+        protected Explicit<Set<Metric>> metrics(BuilderContext context) {\n+            if (metrics != null) {\n+                return new Explicit<>(metrics, true);\n+            }\n+            return Defaults.METRICS;\n+        }\n+\n+        @Override\n+        public AggregateDoubleMetricFieldMapper build(BuilderContext context) {\n+            setupFieldType(context);\n+\n+            if (metrics == null || metrics.isEmpty()) {\n+                throw new IllegalArgumentException(\n+                    \"Property [\" + Names.METRICS.getPreferredName() + \"] must be set for field [\" + name() + \"].\"\n+                );\n+            }\n+\n+            EnumMap<Metric, NumberFieldMapper> metricMappers = new EnumMap<>(Metric.class);\n+            // Instantiate one NumberFieldMapper instance for each metric\n+            for (Metric m : this.metrics) {\n+                String fieldName = subfieldName(context.path().pathAsText(name), m);\n+                NumberFieldMapper.Builder builder;\n+\n+                if (m == Metric.value_count) {\n+                    // value_count metric can only be an integer and not a double\n+                    builder = new NumberFieldMapper.Builder(fieldName, NumberFieldMapper.NumberType.INTEGER);\n+                    builder.coerce(false);\n+                } else {\n+                    builder = new NumberFieldMapper.Builder(fieldName, NumberFieldMapper.NumberType.DOUBLE);\n+                }\n+                NumberFieldMapper fieldMapper = builder.build(context);\n+                metricMappers.put(m, fieldMapper);\n+            }\n+\n+            EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields = metricMappers.entrySet()\n+                .stream()\n+                .collect(\n+                    Collectors.toMap(\n+                        Map.Entry::getKey,\n+                        e -> e.getValue().fieldType(),\n+                        (l, r) -> { throw new IllegalArgumentException(\"Duplicate keys \" + l + \"and \" + r + \".\"); },\n+                        () -> new EnumMap<>(Metric.class)\n+                    )\n+                );\n+\n+            AggregateDoubleMetricFieldType metricFieldType = (AggregateDoubleMetricFieldType) fieldType;\n+            metricFieldType.setMetricFields(metricFields);\n+\n+            Explicit<Metric> defaultMetric = defaultMetric(context);\n+            metricFieldType.setDefaultMetric(defaultMetric.value());\n+\n+            return new AggregateDoubleMetricFieldMapper(\n+                name,\n+                metricFieldType,\n+                defaultFieldType,\n+                context.indexSettings(),\n+                multiFieldsBuilder.build(this, context),\n+                ignoreMalformed(context),\n+                metrics(context),\n+                defaultMetric,\n+                copyTo,\n+                metricMappers\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        @Override\n+        public Mapper.Builder<Builder, AggregateDoubleMetricFieldMapper> parse(\n+            String name,\n+            Map<String, Object> node,\n+            ParserContext parserContext\n+        ) throws MapperParsingException {\n+            AggregateDoubleMetricFieldMapper.Builder builder = new AggregateDoubleMetricFieldMapper.Builder(name);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(Names.METRICS.getPreferredName())) {\n+                    String metricsStr[] = XContentMapValues.nodeStringArrayValue(propNode);\n+                    // Make sure that metrics are supported\n+                    EnumSet<Metric> parsedMetrics = EnumSet.noneOf(Metric.class);\n+                    for (int i = 0; i < metricsStr.length; i++) {\n+                        try {\n+                            Metric m = Metric.valueOf(metricsStr[i]);\n+                            parsedMetrics.add(m);\n+                        } catch (IllegalArgumentException e) {\n+                            throw new IllegalArgumentException(\"Metric [\" + metricsStr[i] + \"] is not supported.\", e);\n+                        }\n+                    }\n+                    builder.metrics(parsedMetrics);\n+                    iterator.remove();\n+                } else if (propName.equals(Names.DEFAULT_METRIC.getPreferredName())) {\n+                    String defaultMetric = XContentMapValues.nodeStringValue(\n+                        propNode,\n+                        name + \".\" + Names.DEFAULT_METRIC.getPreferredName()\n+                    );\n+                    try {\n+                        Metric m = Metric.valueOf(defaultMetric);\n+                        builder.defaultMetric(m);\n+                        iterator.remove();\n+                    } catch (IllegalArgumentException e) {\n+                        throw new IllegalArgumentException(\"Metric [\" + defaultMetric + \"] is not supported.\", e);\n+                    }\n+                } else if (propName.equals(Names.IGNORE_MALFORMED.getPreferredName())) {\n+                    builder.ignoreMalformed(\n+                        XContentMapValues.nodeBooleanValue(propNode, name + \".\" + Names.IGNORE_MALFORMED.getPreferredName())\n+                    );\n+                    iterator.remove();\n+                } else if (TypeParsers.parseMultiField(builder, name, parserContext, propName, propNode)) {\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class AggregateDoubleMetricFieldType extends SimpleMappedFieldType {\n+\n+        private EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields;\n+\n+        private Metric defaultMetric;\n+\n+        public AggregateDoubleMetricFieldType() {}\n+\n+        AggregateDoubleMetricFieldType(AggregateDoubleMetricFieldType other) {\n+            super(other);\n+            this.metricFields = other.metricFields;\n+            this.defaultMetric = other.defaultMetric;\n+        }\n+\n+        @Override\n+        public MappedFieldType clone() {\n+            return new AggregateDoubleMetricFieldType(this);\n+        }\n+\n+        /**\n+         * Return a delegate field type for a given metric sub-field\n+         * @return a field type\n+         */\n+        private NumberFieldMapper.NumberFieldType delegateFieldType(Metric metric) {\n+            return metricFields.get(metric);\n+        }\n+\n+        /**\n+         * Return a delegate field type for the default metric sub-field\n+         * @return a field type\n+         */\n+        private NumberFieldMapper.NumberFieldType delegateFieldType() {\n+            return delegateFieldType(defaultMetric);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        private void setMetricFields(EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields) {\n+            checkIfFrozen();\n+            this.metricFields = metricFields;\n+        }\n+\n+        public void addMetricField(Metric m, NumberFieldMapper.NumberFieldType subfield) {\n+            checkIfFrozen();\n+            if (metricFields == null) {\n+                metricFields = new EnumMap<>(AggregateDoubleMetricFieldMapper.Metric.class);\n+            }\n+\n+            if (name() == null) {\n+                throw new IllegalArgumentException(\"Field of type [\" + typeName() + \"] must have a name before adding a subfield\");\n+            }\n+            String subfieldName = subfieldName(name(), m);\n+            subfield.setName(subfieldName);\n+            metricFields.put(m, subfield);\n+        }\n+\n+        public void setDefaultMetric(Metric defaultMetric) {\n+            checkIfFrozen();\n+            this.defaultMetric = defaultMetric;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return delegateFieldType().existsQuery(context);\n+        }\n+\n+        @Override\n+        public Query termQuery(Object value, QueryShardContext context) {\n+            return delegateFieldType().termQuery(value, context);\n+        }\n+\n+        @Override\n+        public Query termsQuery(List<?> values, QueryShardContext context) {\n+            return delegateFieldType().termsQuery(values, context);\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            return delegateFieldType().rangeQuery(lowerTerm, upperTerm, includeLower, includeUpper, context);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            return delegateFieldType().valueForDisplay(value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(String format, ZoneId timeZone) {\n+            return delegateFieldType().docValueFormat(format, timeZone);\n+        }\n+\n+        @Override\n+        public Relation isFieldWithinQuery(\n+            IndexReader reader,\n+            Object from,\n+            Object to,\n+            boolean includeLower,\n+            boolean includeUpper,\n+            ZoneId timeZone,\n+            DateMathParser dateMathParser,\n+            QueryRewriteContext context\n+        ) throws IOException {\n+            return delegateFieldType().isFieldWithinQuery(reader, from, to, includeLower, includeUpper, timeZone, dateMathParser, context);\n+        }\n+\n+        @Override\n+        public ValuesSourceType getValuesSourceType() {\n+            return AggregateMetricsValuesSourceType.AGGREGATE_METRIC;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            return new IndexFieldData.Builder() {\n+                @Override\n+                public IndexFieldData<?> build(\n+                    IndexSettings indexSettings,\n+                    MappedFieldType fieldType,\n+                    IndexFieldDataCache cache,\n+                    CircuitBreakerService breakerService,\n+                    MapperService mapperService\n+                ) {\n+                    return new IndexAggregateDoubleMetricFieldData(indexSettings.getIndex(), fieldType.name()) {\n+                        @Override\n+                        public LeafAggregateDoubleMetricFieldData load(LeafReaderContext context) {\n+                            return new LeafAggregateDoubleMetricFieldData() {\n+                                @Override\n+                                public SortedNumericDoubleValues getAggregateMetricValues(final Metric metric) throws IOException {\n+                                    try {\n+                                        final NumericDocValues values = DocValues.getNumeric(\n+                                            context.reader(),\n+                                            subfieldName(fieldName, metric)\n+                                        );\n+\n+                                        return new SortedNumericDoubleValues() {\n+                                            @Override\n+                                            public int docValueCount() {\n+                                                return 1;\n+                                            }\n+\n+                                            @Override\n+                                            public boolean advanceExact(int doc) throws IOException {\n+                                                return values.advanceExact(doc);\n+                                            }\n+\n+                                            @Override\n+                                            public double nextValue() throws IOException {\n+                                                return Double.longBitsToDouble(values.longValue());\n+                                            }\n+                                        };\n+                                    } catch (IOException e) {\n+                                        throw new IOException(\"Cannot load doc values\", e);\n+                                    }\n+                                }\n+\n+                                @Override\n+                                public ScriptDocValues<?> getScriptValues() {\n+                                    throw new UnsupportedOperationException(\n+                                        \"The [\" + CONTENT_TYPE + \"] field does not \" + \"support scripts\"\n+                                    );\n+                                }\n+\n+                                @Override\n+                                public SortedBinaryDocValues getBytesValues() {\n+                                    throw new UnsupportedOperationException(\n+                                        \"String representation of doc values \" + \"for [\" + CONTENT_TYPE + \"] fields is not supported\"\n+                                    );\n+                                }\n+\n+                                @Override\n+                                public long ramBytesUsed() {\n+                                    return 0; // Unknown\n+                                }\n+\n+                                @Override\n+                                public void close() {}\n+                            };\n+                        }\n+\n+                        @Override\n+                        public LeafAggregateDoubleMetricFieldData loadDirect(LeafReaderContext context) {\n+                            return load(context);\n+                        }\n+\n+                        @Override\n+                        public SortField sortField(\n+                            Object missingValue,\n+                            MultiValueMode sortMode,\n+                            XFieldComparatorSource.Nested nested,\n+                            boolean reverse\n+                        ) {\n+                            throw new UnsupportedOperationException(\"can't sort on the [\" + CONTENT_TYPE + \"] field\");\n+                        }\n+\n+                        @Override\n+                        public BucketedSort newBucketedSort(\n+                            BigArrays bigArrays,\n+                            Object missingValue,\n+                            MultiValueMode sortMode,\n+                            XFieldComparatorSource.Nested nested,\n+                            SortOrder sortOrder,\n+                            DocValueFormat format,\n+                            int bucketSize,\n+                            BucketedSort.ExtraData extra\n+                        ) {\n+                            throw new IllegalArgumentException(\"can't sort on the [\" + CONTENT_TYPE + \"] field\");\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+    }\n+\n+    private final EnumMap<Metric, NumberFieldMapper> metricFieldMappers;\n+\n+    private Explicit<Boolean> ignoreMalformed;\n+\n+    /** A set of metrics supported */\n+    private Explicit<Set<Metric>> metrics;\n+\n+    /** The default metric to be when querying this field type */\n+    protected Explicit<Metric> defaultMetric;\n+\n+    private AggregateDoubleMetricFieldMapper(\n+        String simpleName,\n+        MappedFieldType fieldType,\n+        MappedFieldType defaultFieldType,\n+        Settings indexSettings,\n+        MultiFields multiFields,\n+        Explicit<Boolean> ignoreMalformed,\n+        Explicit<Set<Metric>> metrics,\n+        Explicit<Metric> defaultMetric,\n+        CopyTo copyTo,\n+        EnumMap<Metric, NumberFieldMapper> metricFieldMappers\n+    ) {\n+        super(simpleName, fieldType, defaultFieldType, indexSettings, multiFields, copyTo);\n+        this.ignoreMalformed = ignoreMalformed;\n+        this.metrics = metrics;\n+        this.defaultMetric = defaultMetric;\n+        this.metricFieldMappers = metricFieldMappers;\n+    }\n+\n+    @Override\n+    public AggregateDoubleMetricFieldType fieldType() {\n+        return (AggregateDoubleMetricFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return fieldType.typeName();\n+    }\n+\n+    @Override\n+    protected AggregateDoubleMetricFieldMapper clone() {\n+        return (AggregateDoubleMetricFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    public Iterator<Mapper> iterator() {\n+        List<Mapper> mappers = new ArrayList<>(metricFieldMappers.values());\n+        return mappers.iterator();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context, List<IndexableField> fields) throws IOException {\n+        if (context.externalValueSet()) {\n+            throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] can't be used in multi-fields\");\n+        }\n+\n+        context.path().add(simpleName());\n+        XContentParser.Token token = null;\n+        XContentSubParser subParser = null;\n+\n+        try {\n+            token = context.parser().currentToken();\n+            if (token == XContentParser.Token.VALUE_NULL) {\n+                context.path().remove();\n+                return;\n+            }\n+\n+            ensureExpectedToken(XContentParser.Token.START_OBJECT, token, context.parser()::getTokenLocation);\n+            subParser = new XContentSubParser(context.parser());\n+            token = subParser.nextToken();\n+            while (token != XContentParser.Token.END_OBJECT) {\n+                // should be an object subfield with name a metric name\n+                ensureExpectedToken(XContentParser.Token.FIELD_NAME, token, subParser::getTokenLocation);\n+                String fieldName = subParser.currentName();\n+                Metric metric = Metric.valueOf(fieldName);\n+\n+                if (metrics.value().contains(metric) == false) {\n+                    throw new IllegalArgumentException(\n+                        \"Aggregate metric [\" + metric + \"] does not exist in the mapping of field [\" + fieldType.name() + \"]\"\n+                    );\n+                }\n+\n+                token = subParser.nextToken();\n+                // Make sure that the value is a number. Probably this will change when\n+                // new aggregate metric types are added (histogram, cardinality etc)\n+                ensureExpectedToken(XContentParser.Token.VALUE_NUMBER, token, subParser::getTokenLocation);\n+                NumberFieldMapper delegateFieldMapper = metricFieldMappers.get(metric);\n+\n+                if (context.doc().getField(delegateFieldMapper.fieldType().name()) != null) {\n+                    throw new IllegalArgumentException(\n+                        \"Field [\"\n+                            + name()\n+                            + \"] of type [\"\n+                            + typeName()\n+                            + \"] does not support indexing multiple values for the same field in the same document\"\n+                    );\n+                }\n+\n+                delegateFieldMapper.parse(context);\n+\n+                if (Metric.value_count == metric) {\n+                    Number n = context.doc().getField(delegateFieldMapper.fieldType().name()).numericValue();\n+                    if (n.intValue() < 0) {\n+                        throw new IllegalArgumentException(\n+                            \"Aggregate metric [\" + metric.name() + \"] of field [\" + fieldType.name() + \"] cannot be a negative number\"\n+                        );\n+                    }\n+                }\n+\n+                token = subParser.nextToken();\n+            }\n+\n+            for (Metric m : metrics.value()) {\n+                if (context.doc().getField(subfieldName(fieldType().name(), m)) == null) {\n+                    throw new IllegalArgumentException(\n+                        \"Aggregate metric field [\" + fieldType.name() + \"] must contain all metrics \" + metrics.value().toString()\n+                    );\n+                }\n+            }\n+        } catch (Exception e) {\n+            if (ignoreMalformed.value()) {\n+                if (subParser != null) {\n+                    // close the subParser so we advance to the end of the object\n+                    subParser.close();\n+                }\n+                context.addIgnoredField(fieldType().name());\n+            } else {\n+                // Rethrow exception as is. It is going to be caught and nested in a MapperParsingException\n+                // by its FieldMapper.MappedFieldType#parse()\n+                throw e;\n+            }\n+        }\n+        context.path().remove();\n+    }\n+\n+    @Override\n+    protected void doMerge(Mapper mergeWith) {\n+        super.doMerge(mergeWith);\n+        AggregateDoubleMetricFieldMapper other = (AggregateDoubleMetricFieldMapper) mergeWith;\n+        if (other.ignoreMalformed.explicit()) {\n+            this.ignoreMalformed = other.ignoreMalformed;\n+        }\n+\n+        if (other.metrics.explicit()) {\n+            if (this.metrics.value() != null\n+                && metrics.value().isEmpty() == false", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "21da92a7fab32b4bc820eca6f000118ba4ff06ca"}, "originalPosition": 652}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4MTMzODg1OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapper.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxMjowMDoyMVrOF9mVGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxMjowMDoyMVrOF9mVGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDEzNTQ0OQ==", "bodyText": "should also disallow removing a metric from an  existing mapping?", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r400135449", "createdAt": "2020-03-30T12:00:21Z", "author": {"login": "jimczi"}, "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapper.java", "diffHunk": "@@ -0,0 +1,689 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.aggregatemetric.mapper;\n+\n+import org.apache.lucene.index.DocValues;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.IndexableField;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.NumericDocValues;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.SortField;\n+import org.elasticsearch.common.Explicit;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.time.DateMathParser;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.XContentSubParser;\n+import org.elasticsearch.common.xcontent.support.XContentMapValues;\n+import org.elasticsearch.index.IndexSettings;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.IndexFieldDataCache;\n+import org.elasticsearch.index.fielddata.ScriptDocValues;\n+import org.elasticsearch.index.fielddata.SortedBinaryDocValues;\n+import org.elasticsearch.index.fielddata.SortedNumericDoubleValues;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SimpleMappedFieldType;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryRewriteContext;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.indices.breaker.CircuitBreakerService;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.MultiValueMode;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceType;\n+import org.elasticsearch.search.sort.BucketedSort;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.xpack.aggregatemetric.aggregations.support.AggregateMetricsValuesSourceType;\n+import org.elasticsearch.xpack.aggregatemetric.fielddata.IndexAggregateDoubleMetricFieldData;\n+import org.elasticsearch.xpack.aggregatemetric.fielddata.LeafAggregateDoubleMetricFieldData;\n+\n+import java.io.IOException;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.EnumMap;\n+import java.util.EnumSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import static org.elasticsearch.common.xcontent.XContentParserUtils.ensureExpectedToken;\n+\n+/** A {@link FieldMapper} for a field containing aggregate metrics such as min/max/value_count etc. */\n+public class AggregateDoubleMetricFieldMapper extends FieldMapper {\n+\n+    public static final String CONTENT_TYPE = \"aggregate_metric_double\";\n+    public static final String SUBFIELD_SEPARATOR = \"._\";\n+\n+    /**\n+     * Return the name of a subfield of an aggregate metric field\n+     *\n+     * @param fieldName the name of the aggregate metric field\n+     * @param metric    the metric type the subfield corresponds to\n+     * @return the name of the subfield\n+     */\n+    public static String subfieldName(String fieldName, Metric metric) {\n+        return fieldName + AggregateDoubleMetricFieldMapper.SUBFIELD_SEPARATOR + metric.name();\n+    }\n+\n+    /**\n+     * Mapping field names\n+     */\n+    public static class Names {\n+        public static final ParseField IGNORE_MALFORMED = new ParseField(\"ignore_malformed\");\n+        public static final ParseField METRICS = new ParseField(\"metrics\");\n+        public static final ParseField DEFAULT_METRIC = new ParseField(\"default_metric\");\n+    }\n+\n+    /**\n+     * Enum of aggregate metrics supported by this field mapper\n+     */\n+    public enum Metric {\n+        min,\n+        max,\n+        sum,\n+        value_count;\n+    }\n+\n+    public static class Defaults {\n+        public static final Explicit<Boolean> IGNORE_MALFORMED = new Explicit<>(false, false);\n+        public static final Explicit<Set<Metric>> METRICS = new Explicit<>(Collections.emptySet(), false);\n+        public static final Explicit<Metric> DEFAULT_METRIC = new Explicit<>(Metric.max, false);\n+        public static final AggregateDoubleMetricFieldType FIELD_TYPE = new AggregateDoubleMetricFieldType();\n+    }\n+\n+    public static class Builder extends FieldMapper.Builder<AggregateDoubleMetricFieldMapper.Builder, AggregateDoubleMetricFieldMapper> {\n+\n+        private Boolean ignoreMalformed;\n+\n+        /**\n+         * The aggregated metrics supported by the field type\n+         */\n+        private EnumSet<Metric> metrics;\n+\n+        /**\n+         * Set the default metric so that query operations are delegated to it.\n+         */\n+        private Metric defaultMetric;\n+\n+        public Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder ignoreMalformed(boolean ignoreMalformed) {\n+            this.ignoreMalformed = ignoreMalformed;\n+            return builder;\n+        }\n+\n+        protected Explicit<Boolean> ignoreMalformed(BuilderContext context) {\n+            if (ignoreMalformed != null) {\n+                return new Explicit<>(ignoreMalformed, true);\n+            }\n+            if (context.indexSettings() != null) {\n+                return new Explicit<>(IGNORE_MALFORMED_SETTING.get(context.indexSettings()), false);\n+            }\n+            return AggregateDoubleMetricFieldMapper.Defaults.IGNORE_MALFORMED;\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder defaultMetric(Metric defaultMetric) {\n+            this.defaultMetric = defaultMetric;\n+            return builder;\n+        }\n+\n+        protected Explicit<Metric> defaultMetric(BuilderContext context) {\n+            if (defaultMetric != null) {\n+                if (metrics != null && metrics.contains(defaultMetric) == false) {\n+                    // The default_metric is not defined in the \"metrics\" field\n+                    throw new IllegalArgumentException(\"Metric [\" + defaultMetric + \"] is not defined in the metrics field.\");\n+                }\n+                return new Explicit<>(defaultMetric, true);\n+            }\n+\n+            // If a single metric is contained, this should be the default\n+            if (metrics != null && metrics.size() == 1) {\n+                return new Explicit<>(metrics.iterator().next(), false);\n+            }\n+\n+            if (metrics.contains(Defaults.DEFAULT_METRIC.value())) {\n+                return Defaults.DEFAULT_METRIC;\n+            }\n+            throw new IllegalArgumentException(\n+                \"Property [\" + Names.DEFAULT_METRIC.getPreferredName() + \"] must be set for field [\" + name() + \"].\"\n+            );\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder metrics(EnumSet<Metric> metrics) {\n+            this.metrics = metrics;\n+            return builder;\n+        }\n+\n+        protected Explicit<Set<Metric>> metrics(BuilderContext context) {\n+            if (metrics != null) {\n+                return new Explicit<>(metrics, true);\n+            }\n+            return Defaults.METRICS;\n+        }\n+\n+        @Override\n+        public AggregateDoubleMetricFieldMapper build(BuilderContext context) {\n+            setupFieldType(context);\n+\n+            if (metrics == null || metrics.isEmpty()) {\n+                throw new IllegalArgumentException(\n+                    \"Property [\" + Names.METRICS.getPreferredName() + \"] must be set for field [\" + name() + \"].\"\n+                );\n+            }\n+\n+            EnumMap<Metric, NumberFieldMapper> metricMappers = new EnumMap<>(Metric.class);\n+            // Instantiate one NumberFieldMapper instance for each metric\n+            for (Metric m : this.metrics) {\n+                String fieldName = subfieldName(context.path().pathAsText(name), m);\n+                NumberFieldMapper.Builder builder;\n+\n+                if (m == Metric.value_count) {\n+                    // value_count metric can only be an integer and not a double\n+                    builder = new NumberFieldMapper.Builder(fieldName, NumberFieldMapper.NumberType.INTEGER);\n+                    builder.coerce(false);\n+                } else {\n+                    builder = new NumberFieldMapper.Builder(fieldName, NumberFieldMapper.NumberType.DOUBLE);\n+                }\n+                NumberFieldMapper fieldMapper = builder.build(context);\n+                metricMappers.put(m, fieldMapper);\n+            }\n+\n+            EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields = metricMappers.entrySet()\n+                .stream()\n+                .collect(\n+                    Collectors.toMap(\n+                        Map.Entry::getKey,\n+                        e -> e.getValue().fieldType(),\n+                        (l, r) -> { throw new IllegalArgumentException(\"Duplicate keys \" + l + \"and \" + r + \".\"); },\n+                        () -> new EnumMap<>(Metric.class)\n+                    )\n+                );\n+\n+            AggregateDoubleMetricFieldType metricFieldType = (AggregateDoubleMetricFieldType) fieldType;\n+            metricFieldType.setMetricFields(metricFields);\n+\n+            Explicit<Metric> defaultMetric = defaultMetric(context);\n+            metricFieldType.setDefaultMetric(defaultMetric.value());\n+\n+            return new AggregateDoubleMetricFieldMapper(\n+                name,\n+                metricFieldType,\n+                defaultFieldType,\n+                context.indexSettings(),\n+                multiFieldsBuilder.build(this, context),\n+                ignoreMalformed(context),\n+                metrics(context),\n+                defaultMetric,\n+                copyTo,\n+                metricMappers\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        @Override\n+        public Mapper.Builder<Builder, AggregateDoubleMetricFieldMapper> parse(\n+            String name,\n+            Map<String, Object> node,\n+            ParserContext parserContext\n+        ) throws MapperParsingException {\n+            AggregateDoubleMetricFieldMapper.Builder builder = new AggregateDoubleMetricFieldMapper.Builder(name);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(Names.METRICS.getPreferredName())) {\n+                    String metricsStr[] = XContentMapValues.nodeStringArrayValue(propNode);\n+                    // Make sure that metrics are supported\n+                    EnumSet<Metric> parsedMetrics = EnumSet.noneOf(Metric.class);\n+                    for (int i = 0; i < metricsStr.length; i++) {\n+                        try {\n+                            Metric m = Metric.valueOf(metricsStr[i]);\n+                            parsedMetrics.add(m);\n+                        } catch (IllegalArgumentException e) {\n+                            throw new IllegalArgumentException(\"Metric [\" + metricsStr[i] + \"] is not supported.\", e);\n+                        }\n+                    }\n+                    builder.metrics(parsedMetrics);\n+                    iterator.remove();\n+                } else if (propName.equals(Names.DEFAULT_METRIC.getPreferredName())) {\n+                    String defaultMetric = XContentMapValues.nodeStringValue(\n+                        propNode,\n+                        name + \".\" + Names.DEFAULT_METRIC.getPreferredName()\n+                    );\n+                    try {\n+                        Metric m = Metric.valueOf(defaultMetric);\n+                        builder.defaultMetric(m);\n+                        iterator.remove();\n+                    } catch (IllegalArgumentException e) {\n+                        throw new IllegalArgumentException(\"Metric [\" + defaultMetric + \"] is not supported.\", e);\n+                    }\n+                } else if (propName.equals(Names.IGNORE_MALFORMED.getPreferredName())) {\n+                    builder.ignoreMalformed(\n+                        XContentMapValues.nodeBooleanValue(propNode, name + \".\" + Names.IGNORE_MALFORMED.getPreferredName())\n+                    );\n+                    iterator.remove();\n+                } else if (TypeParsers.parseMultiField(builder, name, parserContext, propName, propNode)) {\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class AggregateDoubleMetricFieldType extends SimpleMappedFieldType {\n+\n+        private EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields;\n+\n+        private Metric defaultMetric;\n+\n+        public AggregateDoubleMetricFieldType() {}\n+\n+        AggregateDoubleMetricFieldType(AggregateDoubleMetricFieldType other) {\n+            super(other);\n+            this.metricFields = other.metricFields;\n+            this.defaultMetric = other.defaultMetric;\n+        }\n+\n+        @Override\n+        public MappedFieldType clone() {\n+            return new AggregateDoubleMetricFieldType(this);\n+        }\n+\n+        /**\n+         * Return a delegate field type for a given metric sub-field\n+         * @return a field type\n+         */\n+        private NumberFieldMapper.NumberFieldType delegateFieldType(Metric metric) {\n+            return metricFields.get(metric);\n+        }\n+\n+        /**\n+         * Return a delegate field type for the default metric sub-field\n+         * @return a field type\n+         */\n+        private NumberFieldMapper.NumberFieldType delegateFieldType() {\n+            return delegateFieldType(defaultMetric);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        private void setMetricFields(EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields) {\n+            checkIfFrozen();\n+            this.metricFields = metricFields;\n+        }\n+\n+        public void addMetricField(Metric m, NumberFieldMapper.NumberFieldType subfield) {\n+            checkIfFrozen();\n+            if (metricFields == null) {\n+                metricFields = new EnumMap<>(AggregateDoubleMetricFieldMapper.Metric.class);\n+            }\n+\n+            if (name() == null) {\n+                throw new IllegalArgumentException(\"Field of type [\" + typeName() + \"] must have a name before adding a subfield\");\n+            }\n+            String subfieldName = subfieldName(name(), m);\n+            subfield.setName(subfieldName);\n+            metricFields.put(m, subfield);\n+        }\n+\n+        public void setDefaultMetric(Metric defaultMetric) {\n+            checkIfFrozen();\n+            this.defaultMetric = defaultMetric;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return delegateFieldType().existsQuery(context);\n+        }\n+\n+        @Override\n+        public Query termQuery(Object value, QueryShardContext context) {\n+            return delegateFieldType().termQuery(value, context);\n+        }\n+\n+        @Override\n+        public Query termsQuery(List<?> values, QueryShardContext context) {\n+            return delegateFieldType().termsQuery(values, context);\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            return delegateFieldType().rangeQuery(lowerTerm, upperTerm, includeLower, includeUpper, context);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            return delegateFieldType().valueForDisplay(value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(String format, ZoneId timeZone) {\n+            return delegateFieldType().docValueFormat(format, timeZone);\n+        }\n+\n+        @Override\n+        public Relation isFieldWithinQuery(\n+            IndexReader reader,\n+            Object from,\n+            Object to,\n+            boolean includeLower,\n+            boolean includeUpper,\n+            ZoneId timeZone,\n+            DateMathParser dateMathParser,\n+            QueryRewriteContext context\n+        ) throws IOException {\n+            return delegateFieldType().isFieldWithinQuery(reader, from, to, includeLower, includeUpper, timeZone, dateMathParser, context);\n+        }\n+\n+        @Override\n+        public ValuesSourceType getValuesSourceType() {\n+            return AggregateMetricsValuesSourceType.AGGREGATE_METRIC;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            return new IndexFieldData.Builder() {\n+                @Override\n+                public IndexFieldData<?> build(\n+                    IndexSettings indexSettings,\n+                    MappedFieldType fieldType,\n+                    IndexFieldDataCache cache,\n+                    CircuitBreakerService breakerService,\n+                    MapperService mapperService\n+                ) {\n+                    return new IndexAggregateDoubleMetricFieldData(indexSettings.getIndex(), fieldType.name()) {\n+                        @Override\n+                        public LeafAggregateDoubleMetricFieldData load(LeafReaderContext context) {\n+                            return new LeafAggregateDoubleMetricFieldData() {\n+                                @Override\n+                                public SortedNumericDoubleValues getAggregateMetricValues(final Metric metric) throws IOException {\n+                                    try {\n+                                        final NumericDocValues values = DocValues.getNumeric(\n+                                            context.reader(),\n+                                            subfieldName(fieldName, metric)\n+                                        );\n+\n+                                        return new SortedNumericDoubleValues() {\n+                                            @Override\n+                                            public int docValueCount() {\n+                                                return 1;\n+                                            }\n+\n+                                            @Override\n+                                            public boolean advanceExact(int doc) throws IOException {\n+                                                return values.advanceExact(doc);\n+                                            }\n+\n+                                            @Override\n+                                            public double nextValue() throws IOException {\n+                                                return Double.longBitsToDouble(values.longValue());\n+                                            }\n+                                        };\n+                                    } catch (IOException e) {\n+                                        throw new IOException(\"Cannot load doc values\", e);\n+                                    }\n+                                }\n+\n+                                @Override\n+                                public ScriptDocValues<?> getScriptValues() {\n+                                    throw new UnsupportedOperationException(\n+                                        \"The [\" + CONTENT_TYPE + \"] field does not \" + \"support scripts\"\n+                                    );\n+                                }\n+\n+                                @Override\n+                                public SortedBinaryDocValues getBytesValues() {\n+                                    throw new UnsupportedOperationException(\n+                                        \"String representation of doc values \" + \"for [\" + CONTENT_TYPE + \"] fields is not supported\"\n+                                    );\n+                                }\n+\n+                                @Override\n+                                public long ramBytesUsed() {\n+                                    return 0; // Unknown\n+                                }\n+\n+                                @Override\n+                                public void close() {}\n+                            };\n+                        }\n+\n+                        @Override\n+                        public LeafAggregateDoubleMetricFieldData loadDirect(LeafReaderContext context) {\n+                            return load(context);\n+                        }\n+\n+                        @Override\n+                        public SortField sortField(\n+                            Object missingValue,\n+                            MultiValueMode sortMode,\n+                            XFieldComparatorSource.Nested nested,\n+                            boolean reverse\n+                        ) {\n+                            throw new UnsupportedOperationException(\"can't sort on the [\" + CONTENT_TYPE + \"] field\");\n+                        }\n+\n+                        @Override\n+                        public BucketedSort newBucketedSort(\n+                            BigArrays bigArrays,\n+                            Object missingValue,\n+                            MultiValueMode sortMode,\n+                            XFieldComparatorSource.Nested nested,\n+                            SortOrder sortOrder,\n+                            DocValueFormat format,\n+                            int bucketSize,\n+                            BucketedSort.ExtraData extra\n+                        ) {\n+                            throw new IllegalArgumentException(\"can't sort on the [\" + CONTENT_TYPE + \"] field\");\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+    }\n+\n+    private final EnumMap<Metric, NumberFieldMapper> metricFieldMappers;\n+\n+    private Explicit<Boolean> ignoreMalformed;\n+\n+    /** A set of metrics supported */\n+    private Explicit<Set<Metric>> metrics;\n+\n+    /** The default metric to be when querying this field type */\n+    protected Explicit<Metric> defaultMetric;\n+\n+    private AggregateDoubleMetricFieldMapper(\n+        String simpleName,\n+        MappedFieldType fieldType,\n+        MappedFieldType defaultFieldType,\n+        Settings indexSettings,\n+        MultiFields multiFields,\n+        Explicit<Boolean> ignoreMalformed,\n+        Explicit<Set<Metric>> metrics,\n+        Explicit<Metric> defaultMetric,\n+        CopyTo copyTo,\n+        EnumMap<Metric, NumberFieldMapper> metricFieldMappers\n+    ) {\n+        super(simpleName, fieldType, defaultFieldType, indexSettings, multiFields, copyTo);\n+        this.ignoreMalformed = ignoreMalformed;\n+        this.metrics = metrics;\n+        this.defaultMetric = defaultMetric;\n+        this.metricFieldMappers = metricFieldMappers;\n+    }\n+\n+    @Override\n+    public AggregateDoubleMetricFieldType fieldType() {\n+        return (AggregateDoubleMetricFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return fieldType.typeName();\n+    }\n+\n+    @Override\n+    protected AggregateDoubleMetricFieldMapper clone() {\n+        return (AggregateDoubleMetricFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    public Iterator<Mapper> iterator() {\n+        List<Mapper> mappers = new ArrayList<>(metricFieldMappers.values());\n+        return mappers.iterator();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context, List<IndexableField> fields) throws IOException {\n+        if (context.externalValueSet()) {\n+            throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] can't be used in multi-fields\");\n+        }\n+\n+        context.path().add(simpleName());\n+        XContentParser.Token token = null;\n+        XContentSubParser subParser = null;\n+\n+        try {\n+            token = context.parser().currentToken();\n+            if (token == XContentParser.Token.VALUE_NULL) {\n+                context.path().remove();\n+                return;\n+            }\n+\n+            ensureExpectedToken(XContentParser.Token.START_OBJECT, token, context.parser()::getTokenLocation);\n+            subParser = new XContentSubParser(context.parser());\n+            token = subParser.nextToken();\n+            while (token != XContentParser.Token.END_OBJECT) {\n+                // should be an object subfield with name a metric name\n+                ensureExpectedToken(XContentParser.Token.FIELD_NAME, token, subParser::getTokenLocation);\n+                String fieldName = subParser.currentName();\n+                Metric metric = Metric.valueOf(fieldName);\n+\n+                if (metrics.value().contains(metric) == false) {\n+                    throw new IllegalArgumentException(\n+                        \"Aggregate metric [\" + metric + \"] does not exist in the mapping of field [\" + fieldType.name() + \"]\"\n+                    );\n+                }\n+\n+                token = subParser.nextToken();\n+                // Make sure that the value is a number. Probably this will change when\n+                // new aggregate metric types are added (histogram, cardinality etc)\n+                ensureExpectedToken(XContentParser.Token.VALUE_NUMBER, token, subParser::getTokenLocation);\n+                NumberFieldMapper delegateFieldMapper = metricFieldMappers.get(metric);\n+\n+                if (context.doc().getField(delegateFieldMapper.fieldType().name()) != null) {\n+                    throw new IllegalArgumentException(\n+                        \"Field [\"\n+                            + name()\n+                            + \"] of type [\"\n+                            + typeName()\n+                            + \"] does not support indexing multiple values for the same field in the same document\"\n+                    );\n+                }\n+\n+                delegateFieldMapper.parse(context);\n+\n+                if (Metric.value_count == metric) {\n+                    Number n = context.doc().getField(delegateFieldMapper.fieldType().name()).numericValue();\n+                    if (n.intValue() < 0) {\n+                        throw new IllegalArgumentException(\n+                            \"Aggregate metric [\" + metric.name() + \"] of field [\" + fieldType.name() + \"] cannot be a negative number\"\n+                        );\n+                    }\n+                }\n+\n+                token = subParser.nextToken();\n+            }\n+\n+            for (Metric m : metrics.value()) {\n+                if (context.doc().getField(subfieldName(fieldType().name(), m)) == null) {\n+                    throw new IllegalArgumentException(\n+                        \"Aggregate metric field [\" + fieldType.name() + \"] must contain all metrics \" + metrics.value().toString()\n+                    );\n+                }\n+            }\n+        } catch (Exception e) {\n+            if (ignoreMalformed.value()) {\n+                if (subParser != null) {\n+                    // close the subParser so we advance to the end of the object\n+                    subParser.close();\n+                }\n+                context.addIgnoredField(fieldType().name());\n+            } else {\n+                // Rethrow exception as is. It is going to be caught and nested in a MapperParsingException\n+                // by its FieldMapper.MappedFieldType#parse()\n+                throw e;\n+            }\n+        }\n+        context.path().remove();\n+    }\n+\n+    @Override\n+    protected void doMerge(Mapper mergeWith) {\n+        super.doMerge(mergeWith);\n+        AggregateDoubleMetricFieldMapper other = (AggregateDoubleMetricFieldMapper) mergeWith;\n+        if (other.ignoreMalformed.explicit()) {\n+            this.ignoreMalformed = other.ignoreMalformed;\n+        }\n+\n+        if (other.metrics.explicit()) {\n+            if (this.metrics.value() != null\n+                && metrics.value().isEmpty() == false\n+                && metrics.value().containsAll(other.metrics.value()) == false) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "21da92a7fab32b4bc820eca6f000118ba4ff06ca"}, "originalPosition": 653}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2MDM5MTgwOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxMDo0OTo0NFrOGI_TpQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxNjoyNzoxNVrOGJNI2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjA3OTAxMw==", "bodyText": "When I changed the SUBFIELD_SEPARATOR from ._ to . the yaml test Test term query on aggregate metric field started failing because it returned 0 hits. When I change the separator back to ._, test becomes successful.\nI debugged the test but values seem to be stored correctly. @polyfractal @jimczi any idea what I am missing here?\nLink to test: \n  \n    \n      elasticsearch/x-pack/plugin/src/test/resources/rest-api-spec/test/aggregate-metrics/10_basic.yml\n    \n    \n         Line 57\n      in\n      b9bf259\n    \n    \n    \n    \n\n        \n          \n           \"Test term query on aggregate metric field\":", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r412079013", "createdAt": "2020-04-21T10:49:44Z", "author": {"login": "csoulios"}, "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapper.java", "diffHunk": "@@ -47,6 +66,18 @@\n public class AggregateDoubleMetricFieldMapper extends FieldMapper {\n \n     public static final String CONTENT_TYPE = \"aggregate_metric_double\";\n+    public static final String SUBFIELD_SEPARATOR = \".\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9bf2599eec5896d0c2412373231cb3700bc4442"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjMwNTYyNA==", "bodyText": "Issue solved. Many thanks to @polyfractal for spotting the problem.", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r412305624", "createdAt": "2020-04-21T16:27:15Z", "author": {"login": "csoulios"}, "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapper.java", "diffHunk": "@@ -47,6 +66,18 @@\n public class AggregateDoubleMetricFieldMapper extends FieldMapper {\n \n     public static final String CONTENT_TYPE = \"aggregate_metric_double\";\n+    public static final String SUBFIELD_SEPARATOR = \".\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjA3OTAxMw=="}, "originalCommit": {"oid": "b9bf2599eec5896d0c2412373231cb3700bc4442"}, "originalPosition": 53}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5MTk5NDcwOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapper.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQxMzoyMTo1NFrOGNTtSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQxMzoyMTo1NFrOGNTtSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjYwNzU2Mg==", "bodyText": "When parsing and inserting a value_count metric we took the decision to treat as integer (see \n  \n    \n      elasticsearch/x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapper.java\n    \n    \n         Line 200\n      in\n      32be5aa\n    \n    \n    \n    \n\n        \n          \n           builder = new NumberFieldMapper.Builder(fieldName, NumberFieldMapper.NumberType.INTEGER); \n        \n    \n  \n\n)\nSo when we aggregate documents, we must treat value_count sub-fields as longs and not as doubles. This part of the code is a bit ugly. Is there any better way to do this?", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r416607562", "createdAt": "2020-04-28T13:21:54Z", "author": {"login": "csoulios"}, "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapper.java", "diffHunk": "@@ -352,10 +395,118 @@ public Relation isFieldWithinQuery(\n         }\n \n         @Override\n-        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n-            return delegateFieldType().fielddataBuilder(fullyQualifiedIndexName);\n+        public ValuesSourceType getValuesSourceType() {\n+            return AggregateMetricsValuesSourceType.AGGREGATE_METRIC;\n         }\n \n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            return new IndexFieldData.Builder() {\n+                @Override\n+                public IndexFieldData<?> build(\n+                    IndexSettings indexSettings,\n+                    MappedFieldType fieldType,\n+                    IndexFieldDataCache cache,\n+                    CircuitBreakerService breakerService,\n+                    MapperService mapperService\n+                ) {\n+                    return new IndexAggregateDoubleMetricFieldData(indexSettings.getIndex(), fieldType.name()) {\n+                        @Override\n+                        public LeafAggregateDoubleMetricFieldData load(LeafReaderContext context) {\n+                            return new LeafAggregateDoubleMetricFieldData() {\n+                                @Override\n+                                public SortedNumericDoubleValues getAggregateMetricValues(final Metric metric) throws IOException {\n+                                    try {\n+                                        final SortedNumericDocValues values = DocValues.getSortedNumeric(\n+                                            context.reader(),\n+                                            subfieldName(fieldName, metric)\n+                                        );\n+\n+                                        return new SortedNumericDoubleValues() {\n+                                            @Override\n+                                            public int docValueCount() {\n+                                                return values.docValueCount();\n+                                            }\n+\n+                                            @Override\n+                                            public boolean advanceExact(int doc) throws IOException {\n+                                                return values.advanceExact(doc);\n+                                            }\n+\n+                                            @Override\n+                                            public double nextValue() throws IOException {\n+                                                long v = values.nextValue();\n+                                                if (metric == Metric.value_count) {\n+                                                    // Only value_count metrics are encoded as integers\n+                                                    return v;\n+                                                } else {\n+                                                    // All other metrics are encoded as doubles\n+                                                    return NumericUtils.sortableLongToDouble(v);\n+                                                }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "32be5aae223a5e876cc4aa1d6ca7890b01cb194c"}, "originalPosition": 212}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4218, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}