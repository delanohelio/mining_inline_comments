{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQyMDE4ODg2", "number": 58744, "title": "[Transform] separate pivot and extract function interface", "bodyText": "separate pivot from the indexer and introduce an abstraction layer, pivot becomes a function. This opens\nthe possibility to add more functions to transform.\ncleaned up version of #55287 after removing experimental code\npiggy backed fixes:\n\nwhen running geo tile group_by it could fail due to query clause limit (unreleased)\nnew style page size using settings was not validating limit of 10k (7.8)\n\nReview hints\n\nthe most important abstraction is the Function interface\nchange collection - the essential part for continuous transform - has been abstracted as Function.ChangeCollector, all pivot related parts are now in CompositeBucketsChangeCollector\n\nToDo's\nMust\n\n abstract progress gatherer\n\nFound problems not introduced by this PR\n\n update should validate ingest pipeline\n GeoTileFieldCollector can not run with pagesize > 1024\n validateConfig/Query should use ValidationException", "createdAt": "2020-06-30T13:12:06Z", "url": "https://github.com/elastic/elasticsearch/pull/58744", "merged": true, "mergeCommit": {"oid": "3280bd2c70158cb3fd3915e20f824c3bede5091a"}, "closed": true, "closedAt": "2020-07-14T08:21:36Z", "author": {"login": "hendrikmuhs"}, "timelineItems": {"totalCount": 20, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcwZ6zRAFqTQ0MDI3MzIyMQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABc0fv5XgBqjM1MzkwNTg3MTg=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQwMjczMjIx", "url": "https://github.com/elastic/elasticsearch/pull/58744#pullrequestreview-440273221", "createdAt": "2020-06-30T18:18:10Z", "commit": {"oid": "3216d52deab945391d315cde160c28145192d25b"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxODoxODoxMFrOGrI6zg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxODoyMzoyMVrOGrJGnA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg4ODA3OA==", "bodyText": "It seems here we are effectively switching on a class type. Why can't we take advantage of polymorphism?", "url": "https://github.com/elastic/elasticsearch/pull/58744#discussion_r447888078", "createdAt": "2020-06-30T18:18:10Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/pivot/Pivot.java", "diffHunk": "@@ -147,33 +205,58 @@ public SearchRequest buildSearchRequest(SourceConfig sourceConfig, Map<String, O\n         return searchRequest;\n     }\n \n-    public AggregationBuilder buildAggregation(Map<String, Object> position, int pageSize) {\n+    @Override\n+    public SearchSourceBuilder buildSearchQuery(SearchSourceBuilder builder, Map<String, Object> position, int pageSize) {\n         cachedCompositeAggregation.aggregateAfter(position);\n         cachedCompositeAggregation.size(pageSize);\n \n-        return cachedCompositeAggregation;\n+        return builder.size(0).aggregation(cachedCompositeAggregation);\n     }\n \n-    public CompositeAggregationBuilder buildIncrementalBucketUpdateAggregation(int pageSize) {\n+    @Override\n+    public ChangeCollector buildChangeCollector(String synchronizationField) {\n+        Map<String, FieldCollector> fieldCollectors = new HashMap<>();\n \n-        CompositeAggregationBuilder compositeAgg = createCompositeAggregationSources(config, true);\n-        compositeAgg.size(pageSize);\n-\n-        return compositeAgg;\n-    }\n-\n-    public Map<String, Set<String>> initialIncrementalBucketUpdateMap() {\n-\n-        Map<String, Set<String>> changedBuckets = new HashMap<>();\n         for (Entry<String, SingleGroupSource> entry : config.getGroupConfig().getGroups().entrySet()) {\n-            if (entry.getValue().supportsIncrementalBucketUpdate()) {\n-                changedBuckets.put(entry.getKey(), new HashSet<>());\n+            switch (entry.getValue().getType()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3216d52deab945391d315cde160c28145192d25b"}, "originalPosition": 204}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg5MTEwMA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            public class FunctionFactory {\n          \n          \n            \n            public final class FunctionFactory {", "url": "https://github.com/elastic/elasticsearch/pull/58744#discussion_r447891100", "createdAt": "2020-06-30T18:23:21Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/FunctionFactory.java", "diffHunk": "@@ -0,0 +1,30 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms;\n+\n+import org.elasticsearch.xpack.core.transform.transforms.TransformConfig;\n+import org.elasticsearch.xpack.transform.transforms.pivot.Pivot;\n+\n+/**\n+ * Factory for creating the runtime instance for a function given the configuration\n+ */\n+public class FunctionFactory {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3216d52deab945391d315cde160c28145192d25b"}, "originalPosition": 15}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQwNzc3NDQx", "url": "https://github.com/elastic/elasticsearch/pull/58744#pullrequestreview-440777441", "createdAt": "2020-07-01T11:18:47Z", "commit": {"oid": "3216d52deab945391d315cde160c28145192d25b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMToxODo0N1rOGrhtSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMToxODo0N1rOGrhtSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODI5NDIxOA==", "bodyText": "Add a private ctor if all the methods are static", "url": "https://github.com/elastic/elasticsearch/pull/58744#discussion_r448294218", "createdAt": "2020-07-01T11:18:47Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/FunctionFactory.java", "diffHunk": "@@ -0,0 +1,30 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms;\n+\n+import org.elasticsearch.xpack.core.transform.transforms.TransformConfig;\n+import org.elasticsearch.xpack.transform.transforms.pivot.Pivot;\n+\n+/**\n+ * Factory for creating the runtime instance for a function given the configuration\n+ */\n+public class FunctionFactory {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg5MTEwMA=="}, "originalCommit": {"oid": "3216d52deab945391d315cde160c28145192d25b"}, "originalPosition": 15}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQzMjk3NTQx", "url": "https://github.com/elastic/elasticsearch/pull/58744#pullrequestreview-443297541", "createdAt": "2020-07-06T18:02:57Z", "commit": {"oid": "81cbdda0391e2301251cab210e9b9b11fcf266b5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQxODowMjo1N1rOGthwSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQxODowMjo1N1rOGthwSQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDM5MjEzNw==", "bodyText": "I don't know what we are gaining by not having SingleGroupSource have a createFieldCollector method. We would avoid this switch statement.\nAre we just trying to keep from adding classes to core?", "url": "https://github.com/elastic/elasticsearch/pull/58744#discussion_r450392137", "createdAt": "2020-07-06T18:02:57Z", "author": {"login": "benwtrent"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/pivot/CompositeBucketsChangeCollector.java", "diffHunk": "@@ -0,0 +1,350 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.pivot;\n+\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.common.Rounding;\n+import org.elasticsearch.common.geo.GeoPoint;\n+import org.elasticsearch.geometry.Rectangle;\n+import org.elasticsearch.index.query.BoolQueryBuilder;\n+import org.elasticsearch.index.query.GeoBoundingBoxQueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.index.query.RangeQueryBuilder;\n+import org.elasticsearch.index.query.TermsQueryBuilder;\n+import org.elasticsearch.search.aggregations.AggregationBuilder;\n+import org.elasticsearch.search.aggregations.Aggregations;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation.Bucket;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.bucket.geogrid.GeoTileUtils;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.xpack.core.transform.transforms.pivot.DateHistogramGroupSource;\n+import org.elasticsearch.xpack.core.transform.transforms.pivot.SingleGroupSource;\n+import org.elasticsearch.xpack.transform.transforms.Function.ChangeCollector;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.Set;\n+\n+/**\n+ * Utility class to collect bucket changes\n+ */\n+public class CompositeBucketsChangeCollector implements ChangeCollector {\n+\n+    private final Map<String, FieldCollector> fieldCollectors;\n+    private final CompositeAggregationBuilder compositeAggregation;\n+    private Map<String, Object> afterKey = null;\n+\n+    interface FieldCollector {\n+        boolean collectChanges(Collection<? extends Bucket> buckets);\n+\n+        AggregationBuilder aggregateChanges();\n+\n+        QueryBuilder filterByChanges(long lastCheckpointTimestamp, long nextcheckpointTimestamp);\n+\n+        void clear();\n+    }\n+\n+    static class TermsFieldCollector implements FieldCollector {\n+\n+        private final String sourceFieldName;\n+        private final String targetFieldName;\n+        private final Set<String> changedTerms;\n+\n+        public TermsFieldCollector(final String sourceFieldName, final String targetFieldName) {\n+            this.sourceFieldName = sourceFieldName;\n+            this.targetFieldName = targetFieldName;\n+            this.changedTerms = new HashSet<>();\n+        }\n+\n+        @Override\n+        public boolean collectChanges(Collection<? extends Bucket> buckets) {\n+            changedTerms.clear();\n+\n+            for (Bucket b : buckets) {\n+                Object term = b.getKey().get(targetFieldName);\n+                if (term != null) {\n+                    changedTerms.add(term.toString());\n+                }\n+            }\n+\n+            return true;\n+        }\n+\n+        @Override\n+        public QueryBuilder filterByChanges(long lastCheckpointTimestamp, long nextcheckpointTimestamp) {\n+            if (changedTerms.isEmpty() == false) {\n+                return new TermsQueryBuilder(sourceFieldName, changedTerms);\n+            }\n+            return null;\n+        }\n+\n+        @Override\n+        public void clear() {\n+            changedTerms.clear();\n+        }\n+\n+        @Override\n+        public AggregationBuilder aggregateChanges() {\n+            return null;\n+        }\n+    }\n+\n+    static class DateHistogramFieldCollector implements FieldCollector {\n+\n+        private final String sourceFieldName;\n+        private final String targetFieldName;\n+        private final boolean isSynchronizationField;\n+        private final Rounding.Prepared rounding;\n+\n+        public DateHistogramFieldCollector(\n+            final String sourceFieldName,\n+            final String targetFieldName,\n+            final Rounding.Prepared rounding,\n+            final boolean isSynchronizationField\n+        ) {\n+            this.sourceFieldName = sourceFieldName;\n+            this.targetFieldName = targetFieldName;\n+            this.rounding = rounding;\n+            this.isSynchronizationField = isSynchronizationField;\n+        }\n+\n+        @Override\n+        public boolean collectChanges(Collection<? extends Bucket> buckets) {\n+            // todo: implementation for isSynchronizationField == false\n+            return false;\n+        }\n+\n+        @Override\n+        public QueryBuilder filterByChanges(long lastCheckpointTimestamp, long nextcheckpointTimestamp) {\n+            if (isSynchronizationField && lastCheckpointTimestamp > 0) {\n+                return new RangeQueryBuilder(sourceFieldName).gte(rounding.round(lastCheckpointTimestamp)).format(\"epoch_millis\");\n+            }\n+\n+            // todo: implementation for isSynchronizationField == false\n+\n+            return null;\n+        }\n+\n+        @Override\n+        public void clear() {}\n+\n+        @Override\n+        public AggregationBuilder aggregateChanges() {\n+            return null;\n+        }\n+\n+    }\n+\n+    static class HistogramFieldCollector implements FieldCollector {\n+\n+        private final String sourceFieldName;\n+        private final String targetFieldName;\n+\n+        public HistogramFieldCollector(final String sourceFieldName, final String targetFieldName) {\n+            this.sourceFieldName = sourceFieldName;\n+            this.targetFieldName = targetFieldName;\n+        }\n+\n+        @Override\n+        public boolean collectChanges(Collection<? extends Bucket> buckets) {\n+            return false;\n+        }\n+\n+        @Override\n+        public QueryBuilder filterByChanges(long lastCheckpointTimestamp, long nextcheckpointTimestamp) {\n+            return null;\n+        }\n+\n+        @Override\n+        public void clear() {}\n+\n+        @Override\n+        public AggregationBuilder aggregateChanges() {\n+            return null;\n+        }\n+    }\n+\n+    static class GeoTileFieldCollector implements FieldCollector {\n+\n+        private final String sourceFieldName;\n+        private final String targetFieldName;\n+        private final Set<String> changedBuckets;\n+\n+        public GeoTileFieldCollector(final String sourceFieldName, final String targetFieldName) {\n+            this.sourceFieldName = sourceFieldName;\n+            this.targetFieldName = targetFieldName;\n+            this.changedBuckets = new HashSet<>();\n+        }\n+\n+        @Override\n+        public boolean collectChanges(Collection<? extends Bucket> buckets) {\n+            changedBuckets.clear();\n+\n+            for (Bucket b : buckets) {\n+                Object bucket = b.getKey().get(targetFieldName);\n+                if (bucket != null) {\n+                    changedBuckets.add(bucket.toString());\n+                }\n+            }\n+\n+            return true;\n+        }\n+\n+        @Override\n+        public QueryBuilder filterByChanges(long lastCheckpointTimestamp, long nextcheckpointTimestamp) {\n+            // todo: this limited by indices.query.bool.max_clause_count, default 1024 which is lower than the maximum page size\n+            if (changedBuckets != null && changedBuckets.isEmpty() == false) {\n+                BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();\n+                changedBuckets.stream().map(GeoTileUtils::toBoundingBox).map(this::toGeoQuery).forEach(boolQueryBuilder::should);\n+                return boolQueryBuilder;\n+            }\n+            return null;\n+        }\n+\n+        @Override\n+        public void clear() {}\n+\n+        @Override\n+        public AggregationBuilder aggregateChanges() {\n+            return null;\n+        }\n+\n+        private GeoBoundingBoxQueryBuilder toGeoQuery(Rectangle rectangle) {\n+            return QueryBuilders.geoBoundingBoxQuery(sourceFieldName)\n+                .setCorners(\n+                    new GeoPoint(rectangle.getMaxLat(), rectangle.getMinLon()),\n+                    new GeoPoint(rectangle.getMinLat(), rectangle.getMaxLon())\n+                );\n+        }\n+    }\n+\n+    public CompositeBucketsChangeCollector(CompositeAggregationBuilder compositeAggregation, Map<String, FieldCollector> fieldCollectors) {\n+        this.compositeAggregation = compositeAggregation;\n+        this.fieldCollectors = fieldCollectors;\n+    }\n+\n+    @Override\n+    public boolean processSearchResponse(final SearchResponse searchResponse) {\n+        final Aggregations aggregations = searchResponse.getAggregations();\n+        if (aggregations == null) {\n+            return true;\n+        }\n+\n+        final CompositeAggregation agg = aggregations.get(compositeAggregation.getName());\n+\n+        Collection<? extends Bucket> buckets = agg.getBuckets();\n+        afterKey = agg.afterKey();\n+\n+        if (buckets.isEmpty()) {\n+            return true;\n+        }\n+\n+        for (FieldCollector fieldCollector : fieldCollectors.values()) {\n+            fieldCollector.collectChanges(buckets);\n+        }\n+\n+        return false;\n+    }\n+\n+    @Override\n+    public QueryBuilder buildFilterQuery(long lastCheckpointTimestamp, long nextcheckpointTimestamp) {\n+        BoolQueryBuilder filteredQuery = new BoolQueryBuilder();\n+\n+        for (FieldCollector fieldCollector : fieldCollectors.values()) {\n+            QueryBuilder filter = fieldCollector.filterByChanges(lastCheckpointTimestamp, nextcheckpointTimestamp);\n+            if (filter != null) {\n+                filteredQuery.filter(filter);\n+            }\n+        }\n+\n+        return filteredQuery;\n+    }\n+\n+    @Override\n+    public SearchSourceBuilder buildChangesQuery(SearchSourceBuilder sourceBuilder, Map<String, Object> position, int pageSize) {\n+\n+        CompositeAggregationBuilder changesAgg = this.compositeAggregation;\n+        changesAgg.size(pageSize).aggregateAfter(position);\n+        sourceBuilder.aggregation(changesAgg);\n+        sourceBuilder.size(0);\n+        for (FieldCollector fieldCollector : fieldCollectors.values()) {\n+            AggregationBuilder aggregationForField = fieldCollector.aggregateChanges();\n+\n+            if (aggregationForField != null) {\n+                sourceBuilder.aggregation(aggregationForField);\n+            }\n+        }\n+\n+        return sourceBuilder;\n+    }\n+\n+    @Override\n+    public void clear() {\n+        fieldCollectors.forEach((k, c) -> c.clear());\n+    }\n+\n+    @Override\n+    public Map<String, Object> getBucketPosition() {\n+        return afterKey;\n+    }\n+\n+    public static ChangeCollector buildChangeCollector(\n+        CompositeAggregationBuilder compositeAggregationBuilder,\n+        Map<String, SingleGroupSource> groups,\n+        String synchronizationField\n+    ) {\n+        Map<String, FieldCollector> fieldCollectors = createFieldCollectors(groups, synchronizationField);\n+        return new CompositeBucketsChangeCollector(compositeAggregationBuilder, fieldCollectors);\n+    }\n+\n+    static Map<String, FieldCollector> createFieldCollectors(Map<String, SingleGroupSource> groups, String synchronizationField) {\n+        Map<String, FieldCollector> fieldCollectors = new HashMap<>();\n+\n+        for (Entry<String, SingleGroupSource> entry : groups.entrySet()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "81cbdda0391e2301251cab210e9b9b11fcf266b5"}, "originalPosition": 312}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "500f92f2ca7872b6939d93c41fd63e01502b98fd", "author": {"user": {"login": "hendrikmuhs", "name": "Hendrik Muhs"}}, "url": "https://github.com/elastic/elasticsearch/commit/500f92f2ca7872b6939d93c41fd63e01502b98fd", "committedDate": "2020-07-06T18:42:55Z", "message": "checkstyle"}, "afterCommit": {"oid": "9275afa941c7e89f38548269252550b79f24d8ec", "author": {"user": {"login": "hendrikmuhs", "name": "Hendrik Muhs"}}, "url": "https://github.com/elastic/elasticsearch/commit/9275afa941c7e89f38548269252550b79f24d8ec", "committedDate": "2020-07-06T20:16:48Z", "message": "checkstyle"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "33a9cc39453c0a66b2af764aae2457cda1fa2127", "author": {"user": {"login": "hendrikmuhs", "name": "Hendrik Muhs"}}, "url": "https://github.com/elastic/elasticsearch/commit/33a9cc39453c0a66b2af764aae2457cda1fa2127", "committedDate": "2020-07-07T20:12:11Z", "message": "add a test for the terms field collector"}, "afterCommit": {"oid": "e36b418f02505f5df0045dff397f927836ce5ef9", "author": {"user": {"login": "hendrikmuhs", "name": "Hendrik Muhs"}}, "url": "https://github.com/elastic/elasticsearch/commit/e36b418f02505f5df0045dff397f927836ce5ef9", "committedDate": "2020-07-07T20:12:37Z", "message": "add a test for the terms field collector"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ0NjU5NzIy", "url": "https://github.com/elastic/elasticsearch/pull/58744#pullrequestreview-444659722", "createdAt": "2020-07-08T11:39:24Z", "commit": {"oid": "e36b418f02505f5df0045dff397f927836ce5ef9"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ1NDcwNzM4", "url": "https://github.com/elastic/elasticsearch/pull/58744#pullrequestreview-445470738", "createdAt": "2020-07-09T10:02:55Z", "commit": {"oid": "e36b418f02505f5df0045dff397f927836ce5ef9"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxMDowMjo1NVrOGvKaug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxMDowOTo1OFrOGvKp2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEwNjkzOA==", "bodyText": "If this is running in a different thread it will not fail the test as the exception does not propagate to the test runner. You need to set the exception to an atomic reference then check after the latch in the test thread.", "url": "https://github.com/elastic/elasticsearch/pull/58744#discussion_r452106938", "createdAt": "2020-07-09T10:02:55Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/transform/qa/single-node-tests/src/test/java/org/elasticsearch/xpack/transform/integration/TransformProgressIT.java", "diffHunk": "@@ -194,9 +182,41 @@ protected Settings restClientSettings() {\n         return Settings.builder().put(ThreadContext.PREFIX + \".Authorization\", token).build();\n     }\n \n+    private TransformProgress getProgress(Function function, SearchRequest searchRequest) throws Exception {\n+        CountDownLatch latch = new CountDownLatch(1);\n+        final AtomicReference<TransformProgress> progressHolder = new AtomicReference<>();\n+\n+        try (RestHighLevelClient restClient = new TestRestHighLevelClient()) {\n+            SearchResponse response = restClient.search(searchRequest, RequestOptions.DEFAULT);\n+\n+            function.getInitialProgressFromResponse(\n+                response,\n+                new LatchedActionListener<>(\n+                    ActionListener.wrap(progressHolder::set, e -> { fail(\"got unexpected exception: \" + e); }),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e36b418f02505f5df0045dff397f927836ce5ef9"}, "originalPosition": 133}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjExMDgwOQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                    TransformDestIndexSettings generateddestIndexSettings = TransformIndex.createTransformDestIndexSettings(\n          \n          \n            \n                                    TransformDestIndexSettings generatedDestIndexSettings = TransformIndex.createTransformDestIndexSettings(\n          \n      \n    \n    \n  \n\n^ Camel case Dest", "url": "https://github.com/elastic/elasticsearch/pull/58744#discussion_r452110809", "createdAt": "2020-07-09T10:09:58Z", "author": {"login": "davidkyle"}, "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/action/TransportPreviewTransformAction.java", "diffHunk": "@@ -211,69 +182,51 @@ private void getPreview(\n \n             listener.onResponse(new PreviewTransformAction.Response(docs, generateddestIndexSettings));\n         }, listener::onFailure);\n-        pivot.deduceMappings(client, source, ActionListener.wrap(deducedMappings -> {\n+        function.deduceMappings(client, source, ActionListener.wrap(deducedMappings -> {\n             mappings.set(deducedMappings);\n-            ClientHelper.executeWithHeadersAsync(\n-                threadPool.getThreadContext().getHeaders(),\n-                ClientHelper.TRANSFORM_ORIGIN,\n+            function.preview(\n                 client,\n-                SearchAction.INSTANCE,\n-                pivot.buildSearchRequest(source, null, NUMBER_OF_PREVIEW_BUCKETS),\n-                ActionListener.wrap(r -> {\n-                    try {\n-                        final Aggregations aggregations = r.getAggregations();\n-                        if (aggregations == null) {\n-                            listener.onFailure(\n-                                new ElasticsearchStatusException(\"Source indices have been deleted or closed.\", RestStatus.BAD_REQUEST)\n-                            );\n-                            return;\n-                        }\n-                        final CompositeAggregation agg = aggregations.get(COMPOSITE_AGGREGATION_NAME);\n-                        TransformIndexerStats stats = new TransformIndexerStats();\n-                        // remove all internal fields\n-\n-                        if (pipeline == null) {\n-                            List<Map<String, Object>> docs = pivot.extractResults(agg, deducedMappings, stats)\n-                                .peek(doc -> doc.keySet().removeIf(k -> k.startsWith(\"_\")))\n-                                .collect(Collectors.toList());\n-\n-                            TransformDestIndexSettings generateddestIndexSettings = TransformIndex.createTransformDestIndexSettings(\n-                                mappings.get(),\n-                                transformId,\n-                                Clock.systemUTC()\n+                threadPool.getThreadContext().getHeaders(),\n+                source,\n+                deducedMappings,\n+                NUMBER_OF_PREVIEW_BUCKETS,\n+                ActionListener.wrap(docs -> {\n+                    if (pipeline == null) {\n+                        TransformDestIndexSettings generateddestIndexSettings = TransformIndex.createTransformDestIndexSettings(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e36b418f02505f5df0045dff397f927836ce5ef9"}, "originalPosition": 151}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "902cbcd51a320cc73aba737f6116b5463edca91d", "author": {"user": {"login": "hendrikmuhs", "name": "Hendrik Muhs"}}, "url": "https://github.com/elastic/elasticsearch/commit/902cbcd51a320cc73aba737f6116b5463edca91d", "committedDate": "2020-07-13T11:29:20Z", "message": "separate pivot and extract function interface"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4e25abd60c9eca6116f87fdf5e7f3d6a1dc6c7b2", "author": {"user": {"login": "hendrikmuhs", "name": "Hendrik Muhs"}}, "url": "https://github.com/elastic/elasticsearch/commit/4e25abd60c9eca6116f87fdf5e7f3d6a1dc6c7b2", "committedDate": "2020-07-13T11:29:20Z", "message": "reactivate disabled indexer test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "11e2a883a173ca2d1ae6b65fa17f9e7e54bfa93e", "author": {"user": {"login": "hendrikmuhs", "name": "Hendrik Muhs"}}, "url": "https://github.com/elastic/elasticsearch/commit/11e2a883a173ca2d1ae6b65fa17f9e7e54bfa93e", "committedDate": "2020-07-13T11:29:20Z", "message": "make FunctionFactory final and effectively disable the constructor"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0349cedffb97568920f92b0c5670f51865418758", "author": {"user": {"login": "hendrikmuhs", "name": "Hendrik Muhs"}}, "url": "https://github.com/elastic/elasticsearch/commit/0349cedffb97568920f92b0c5670f51865418758", "committedDate": "2020-07-13T11:29:20Z", "message": "add progress to function interface"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b3fed214c72033fd3a73fc9f453504ac4972f946", "author": {"user": {"login": "hendrikmuhs", "name": "Hendrik Muhs"}}, "url": "https://github.com/elastic/elasticsearch/commit/b3fed214c72033fd3a73fc9f453504ac4972f946", "committedDate": "2020-07-13T11:29:20Z", "message": "move changecollector factory method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1a6e8f3c1655c45f5c1c9a2c2a21ba5f1facf378", "author": {"user": {"login": "hendrikmuhs", "name": "Hendrik Muhs"}}, "url": "https://github.com/elastic/elasticsearch/commit/1a6e8f3c1655c45f5c1c9a2c2a21ba5f1facf378", "committedDate": "2020-07-13T11:29:20Z", "message": "checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6072825ddf2e8486ecdcfa872ae669f02c81e5a5", "author": {"user": {"login": "hendrikmuhs", "name": "Hendrik Muhs"}}, "url": "https://github.com/elastic/elasticsearch/commit/6072825ddf2e8486ecdcfa872ae669f02c81e5a5", "committedDate": "2020-07-13T11:29:20Z", "message": "document the field collector interface and implement page limit for geotile\ncollector"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0cb39463cd21d5288b04ecb8c9fdb20f945cf94f", "author": {"user": {"login": "hendrikmuhs", "name": "Hendrik Muhs"}}, "url": "https://github.com/elastic/elasticsearch/commit/0cb39463cd21d5288b04ecb8c9fdb20f945cf94f", "committedDate": "2020-07-13T11:29:20Z", "message": "fix doc string"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b00dbd5009d093fc92d5ac5b1173ac91c2801b88", "author": {"user": {"login": "hendrikmuhs", "name": "Hendrik Muhs"}}, "url": "https://github.com/elastic/elasticsearch/commit/b00dbd5009d093fc92d5ac5b1173ac91c2801b88", "committedDate": "2020-07-13T11:29:20Z", "message": "add tests to adapt the page size by field collector"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "93f918c945d911b1582e234db0b4371dce574d18", "author": {"user": {"login": "hendrikmuhs", "name": "Hendrik Muhs"}}, "url": "https://github.com/elastic/elasticsearch/commit/93f918c945d911b1582e234db0b4371dce574d18", "committedDate": "2020-07-13T11:29:20Z", "message": "fix test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e55f92f1fbfcbecf4a7d2a323770c37b09518e7f", "author": {"user": {"login": "hendrikmuhs", "name": "Hendrik Muhs"}}, "url": "https://github.com/elastic/elasticsearch/commit/e55f92f1fbfcbecf4a7d2a323770c37b09518e7f", "committedDate": "2020-07-13T11:29:20Z", "message": "add a test for the terms field collector"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "12601c279da76deb186a412554f1395faae85205", "author": {"user": {"login": "hendrikmuhs", "name": "Hendrik Muhs"}}, "url": "https://github.com/elastic/elasticsearch/commit/12601c279da76deb186a412554f1395faae85205", "committedDate": "2020-07-13T11:29:20Z", "message": "apply review suggestions"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b4bb7cd7cef9ea5af35127717c8ae072119cb58b", "author": {"user": {"login": "hendrikmuhs", "name": "Hendrik Muhs"}}, "url": "https://github.com/elastic/elasticsearch/commit/b4bb7cd7cef9ea5af35127717c8ae072119cb58b", "committedDate": "2020-07-13T11:14:24Z", "message": "apply review suggestions"}, "afterCommit": {"oid": "12601c279da76deb186a412554f1395faae85205", "author": {"user": {"login": "hendrikmuhs", "name": "Hendrik Muhs"}}, "url": "https://github.com/elastic/elasticsearch/commit/12601c279da76deb186a412554f1395faae85205", "committedDate": "2020-07-13T11:29:20Z", "message": "apply review suggestions"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2594, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}