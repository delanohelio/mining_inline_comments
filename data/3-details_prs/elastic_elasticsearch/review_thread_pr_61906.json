{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDc4NjA2MDgy", "number": 61906, "reviewThreads": {"totalCount": 50, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQwODo1NjoyNVrOEhk1MA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxNToxNzo0M1rOEqyqWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzNjQxOTA0OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQwODo1NjoyNVrOHO9kWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOFQxMzoxNjo0M1rOHY9Mgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTQ1MDg0Mw==", "bodyText": "I'm not sure which thread-pool to use here. SNAPSHOT wasn't great because I feared allocation could be delayed by long-running backups. ASYNC_FETCH thread pool could turn out to be problematic as it might interfere with recoveries of local primaries (although that threadpool is generously sized).", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r485450843", "createdAt": "2020-09-09T08:56:25Z", "author": {"login": "ywelsch"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,197 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesServiceSupplier;\n+    private final Supplier<RerouteService> rerouteServiceSupplier;\n+\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> snapshotShardSizes;\n+\n+    private final Set<SnapshotShard> fetchingShards = Sets.newConcurrentHashSet();\n+\n+    public InternalSnapshotsInfoService(ThreadPool threadPool, Supplier<RepositoriesService> repositoriesServiceSupplier,\n+                                        Supplier<RerouteService> rerouteServiceSupplier) {\n+        this.threadPool = threadPool;\n+        this.repositoriesServiceSupplier = repositoriesServiceSupplier;\n+        this.rerouteServiceSupplier = rerouteServiceSupplier;\n+        snapshotShardSizes = ImmutableOpenMap.of();\n+    }\n+\n+    public static class SnapshotShard {\n+\n+        private final Snapshot snapshot;\n+        private final IndexId index;\n+        private final int shardId;\n+\n+        public SnapshotShard(Snapshot snapshot, IndexId index, int shardId) {\n+            this.snapshot = snapshot;\n+            this.index = index;\n+            this.shardId = shardId;\n+        }\n+\n+        public Snapshot getSnapshot() {\n+            return snapshot;\n+        }\n+\n+        public IndexId getIndex() {\n+            return index;\n+        }\n+\n+        public int getShardId() {\n+            return shardId;\n+        }\n+\n+        @Override\n+        public boolean equals(Object o) {\n+            if (this == o) return true;\n+            if (o == null || getClass() != o.getClass()) return false;\n+            SnapshotShard that = (SnapshotShard) o;\n+            return shardId == that.shardId &&\n+                snapshot.equals(that.snapshot) &&\n+                index.equals(that.index);\n+        }\n+\n+        @Override\n+        public int hashCode() {\n+            return Objects.hash(snapshot, index, shardId);\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"SnapshotShard{\" +\n+                \"snapshot=\" + snapshot +\n+                \", index=\" + index +\n+                \", shardId=\" + shardId +\n+                '}';\n+        }\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(snapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> requiredSnapshotShards = new HashSet<>();\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.id());\n+                    requiredSnapshotShards.add(snapshotShard);\n+                    // check if already populated entry\n+                    if (snapshotShardSizes.get(snapshotShard) == null) {\n+                        // check if already fetching snapshot info in progress\n+                        if (fetchingShards.add(snapshotShard)) {\n+                            // TODO: Use a dedicated threadpool here? Use FETCH thread pool?\n+                            threadPool.generic().execute(new AbstractRunnable() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5e64f308895ac9bfb2f33e5d30701b59cf3eb3cb"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTkzMDQ5OA==", "bodyText": "I agree with not using the SNAPSHOT thread pool here. I think we should reuse FETCH_SHARD_STORE or add a new one.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r495930498", "createdAt": "2020-09-28T13:16:43Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,197 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesServiceSupplier;\n+    private final Supplier<RerouteService> rerouteServiceSupplier;\n+\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> snapshotShardSizes;\n+\n+    private final Set<SnapshotShard> fetchingShards = Sets.newConcurrentHashSet();\n+\n+    public InternalSnapshotsInfoService(ThreadPool threadPool, Supplier<RepositoriesService> repositoriesServiceSupplier,\n+                                        Supplier<RerouteService> rerouteServiceSupplier) {\n+        this.threadPool = threadPool;\n+        this.repositoriesServiceSupplier = repositoriesServiceSupplier;\n+        this.rerouteServiceSupplier = rerouteServiceSupplier;\n+        snapshotShardSizes = ImmutableOpenMap.of();\n+    }\n+\n+    public static class SnapshotShard {\n+\n+        private final Snapshot snapshot;\n+        private final IndexId index;\n+        private final int shardId;\n+\n+        public SnapshotShard(Snapshot snapshot, IndexId index, int shardId) {\n+            this.snapshot = snapshot;\n+            this.index = index;\n+            this.shardId = shardId;\n+        }\n+\n+        public Snapshot getSnapshot() {\n+            return snapshot;\n+        }\n+\n+        public IndexId getIndex() {\n+            return index;\n+        }\n+\n+        public int getShardId() {\n+            return shardId;\n+        }\n+\n+        @Override\n+        public boolean equals(Object o) {\n+            if (this == o) return true;\n+            if (o == null || getClass() != o.getClass()) return false;\n+            SnapshotShard that = (SnapshotShard) o;\n+            return shardId == that.shardId &&\n+                snapshot.equals(that.snapshot) &&\n+                index.equals(that.index);\n+        }\n+\n+        @Override\n+        public int hashCode() {\n+            return Objects.hash(snapshot, index, shardId);\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"SnapshotShard{\" +\n+                \"snapshot=\" + snapshot +\n+                \", index=\" + index +\n+                \", shardId=\" + shardId +\n+                '}';\n+        }\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(snapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> requiredSnapshotShards = new HashSet<>();\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.id());\n+                    requiredSnapshotShards.add(snapshotShard);\n+                    // check if already populated entry\n+                    if (snapshotShardSizes.get(snapshotShard) == null) {\n+                        // check if already fetching snapshot info in progress\n+                        if (fetchingShards.add(snapshotShard)) {\n+                            // TODO: Use a dedicated threadpool here? Use FETCH thread pool?\n+                            threadPool.generic().execute(new AbstractRunnable() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTQ1MDg0Mw=="}, "originalCommit": {"oid": "5e64f308895ac9bfb2f33e5d30701b59cf3eb3cb"}, "originalPosition": 138}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExMDQ4MzQ3OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjoxNDozN1rOHZ2JDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjoxNDozN1rOHZ2JDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg2MzUwMg==", "bodyText": "On failures, every reroute will trigger another round of fetch of shard size(s) and lead to more warning logs. And in the meantime, the cluster is yellow due to ClusterShardHealth.getInactivePrimaryHealth.\nIn particular if this happens together with the bursts described below, it could be a burdensome load on the master node?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r496863502", "createdAt": "2020-09-29T16:14:37Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesServiceSupplier;\n+    private final Supplier<RerouteService> rerouteServiceSupplier;\n+\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> snapshotShardSizes;\n+\n+    private final Set<SnapshotShard> fetchingShards = Sets.newConcurrentHashSet();\n+\n+    public InternalSnapshotsInfoService(ThreadPool threadPool, Supplier<RepositoriesService> repositoriesServiceSupplier,\n+                                        Supplier<RerouteService> rerouteServiceSupplier) {\n+        this.threadPool = threadPool;\n+        this.repositoriesServiceSupplier = repositoriesServiceSupplier;\n+        this.rerouteServiceSupplier = rerouteServiceSupplier;\n+        snapshotShardSizes = ImmutableOpenMap.of();\n+    }\n+\n+    public static class SnapshotShard {\n+\n+        private final Snapshot snapshot;\n+        private final IndexId index;\n+        private final int shardId;\n+\n+        public SnapshotShard(Snapshot snapshot, IndexId index, int shardId) {\n+            this.snapshot = snapshot;\n+            this.index = index;\n+            this.shardId = shardId;\n+        }\n+\n+        public Snapshot getSnapshot() {\n+            return snapshot;\n+        }\n+\n+        public IndexId getIndex() {\n+            return index;\n+        }\n+\n+        public int getShardId() {\n+            return shardId;\n+        }\n+\n+        @Override\n+        public boolean equals(Object o) {\n+            if (this == o) {\n+                return true;\n+            }\n+            if (o == null || getClass() != o.getClass()) {\n+                return false;\n+            }\n+            final SnapshotShard that = (SnapshotShard) o;\n+            return shardId == that.shardId\n+                && snapshot.equals(that.snapshot)\n+                && index.equals(that.index);\n+        }\n+\n+        @Override\n+        public int hashCode() {\n+            return Objects.hash(snapshot, index, shardId);\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"SnapshotShard{\" +\n+                \"snapshot=\" + snapshot +\n+                \", index=\" + index +\n+                \", shardId=\" + shardId +\n+                '}';\n+        }\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(snapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> requiredSnapshotShards = new HashSet<>();\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.id());\n+                    requiredSnapshotShards.add(snapshotShard);\n+                    // check if already populated entry\n+                    if (snapshotShardSizes.get(snapshotShard) == null) {\n+                        // check if already fetching snapshot info in progress\n+                        if (fetchingShards.add(snapshotShard)) {\n+                            // TODO: Use a dedicated threadpool here? Use FETCH thread pool?\n+                            threadPool.generic().execute(new AbstractRunnable() {\n+                                @Override\n+                                public void onFailure(Exception e) {\n+                                    logger.warn(new ParameterizedMessage(\"failed to retrieve shard size information for {}\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb6daa1f9262d2b11f68ee18775db67c074b7da7"}, "originalPosition": 145}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExMDU5MjIwOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjozMzo1MVrOHZ3L6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQxMjo0OToyMVrOHab5cg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg4MDYxNw==", "bodyText": "I think this will lead to a burst of many requests to the blob store to get the shard size whenever a node holding searchable snapshots fails or is restarted.\nThis could block the generic thread pool for a while, potentially causing other issues. Similarly if moving to the FETCH_SHARD_STORE pool it might interfere with recoveries of primaries.\nGeneric pool has minimum 128 threads, which does mean a decent amount of parallel fetching from blobstore, but going for other pools would likely lower this considerably.\nIt also feels like a bad spot in our allocation to have a dependency on an external blob store, in particular if it responds very slowly for odd reasons. Once persistent cache is in place, we should be able to recover on our own without accessing the blob store.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r496880617", "createdAt": "2020-09-29T16:33:51Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesServiceSupplier;\n+    private final Supplier<RerouteService> rerouteServiceSupplier;\n+\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> snapshotShardSizes;\n+\n+    private final Set<SnapshotShard> fetchingShards = Sets.newConcurrentHashSet();\n+\n+    public InternalSnapshotsInfoService(ThreadPool threadPool, Supplier<RepositoriesService> repositoriesServiceSupplier,\n+                                        Supplier<RerouteService> rerouteServiceSupplier) {\n+        this.threadPool = threadPool;\n+        this.repositoriesServiceSupplier = repositoriesServiceSupplier;\n+        this.rerouteServiceSupplier = rerouteServiceSupplier;\n+        snapshotShardSizes = ImmutableOpenMap.of();\n+    }\n+\n+    public static class SnapshotShard {\n+\n+        private final Snapshot snapshot;\n+        private final IndexId index;\n+        private final int shardId;\n+\n+        public SnapshotShard(Snapshot snapshot, IndexId index, int shardId) {\n+            this.snapshot = snapshot;\n+            this.index = index;\n+            this.shardId = shardId;\n+        }\n+\n+        public Snapshot getSnapshot() {\n+            return snapshot;\n+        }\n+\n+        public IndexId getIndex() {\n+            return index;\n+        }\n+\n+        public int getShardId() {\n+            return shardId;\n+        }\n+\n+        @Override\n+        public boolean equals(Object o) {\n+            if (this == o) {\n+                return true;\n+            }\n+            if (o == null || getClass() != o.getClass()) {\n+                return false;\n+            }\n+            final SnapshotShard that = (SnapshotShard) o;\n+            return shardId == that.shardId\n+                && snapshot.equals(that.snapshot)\n+                && index.equals(that.index);\n+        }\n+\n+        @Override\n+        public int hashCode() {\n+            return Objects.hash(snapshot, index, shardId);\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"SnapshotShard{\" +\n+                \"snapshot=\" + snapshot +\n+                \", index=\" + index +\n+                \", shardId=\" + shardId +\n+                '}';\n+        }\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(snapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> requiredSnapshotShards = new HashSet<>();\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.id());\n+                    requiredSnapshotShards.add(snapshotShard);\n+                    // check if already populated entry\n+                    if (snapshotShardSizes.get(snapshotShard) == null) {\n+                        // check if already fetching snapshot info in progress\n+                        if (fetchingShards.add(snapshotShard)) {\n+                            // TODO: Use a dedicated threadpool here? Use FETCH thread pool?\n+                            threadPool.generic().execute(new AbstractRunnable() {\n+                                @Override\n+                                public void onFailure(Exception e) {\n+                                    logger.warn(new ParameterizedMessage(\"failed to retrieve shard size information for {}\",\n+                                        shardRouting), e);\n+                                }\n+\n+                                @Override\n+                                protected void doRun() {\n+                                    final RepositoriesService repositories = repositoriesServiceSupplier.get();\n+                                    assert repositories != null;\n+                                    final Repository repository = repositories.repository(snapshotShard.snapshot.getRepository());\n+                                    final IndexShardSnapshotStatus status =\n+                                        repository.getShardSnapshotStatus(snapshotRecoverySource.snapshot().getSnapshotId(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb6daa1f9262d2b11f68ee18775db67c074b7da7"}, "originalPosition": 155}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQ4MjA5OA==", "bodyText": "++ we must limit the concurrency here. This isn't just about threads (though that's reason enough) but also about memory to some degree.  org.elasticsearch.repositories.blobstore.BlobStoreRepository#getShardSnapshotStatus might use a few MB per shard in memory because the underlying metadata file that is loaded from the blobstore is non-trivial in size (we essentially have the same requests in the _status APIs for snapshot status and don't parallelize them there either at least for now because we have to be careful about the concurrency).", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r497482098", "createdAt": "2020-09-30T12:49:21Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesServiceSupplier;\n+    private final Supplier<RerouteService> rerouteServiceSupplier;\n+\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> snapshotShardSizes;\n+\n+    private final Set<SnapshotShard> fetchingShards = Sets.newConcurrentHashSet();\n+\n+    public InternalSnapshotsInfoService(ThreadPool threadPool, Supplier<RepositoriesService> repositoriesServiceSupplier,\n+                                        Supplier<RerouteService> rerouteServiceSupplier) {\n+        this.threadPool = threadPool;\n+        this.repositoriesServiceSupplier = repositoriesServiceSupplier;\n+        this.rerouteServiceSupplier = rerouteServiceSupplier;\n+        snapshotShardSizes = ImmutableOpenMap.of();\n+    }\n+\n+    public static class SnapshotShard {\n+\n+        private final Snapshot snapshot;\n+        private final IndexId index;\n+        private final int shardId;\n+\n+        public SnapshotShard(Snapshot snapshot, IndexId index, int shardId) {\n+            this.snapshot = snapshot;\n+            this.index = index;\n+            this.shardId = shardId;\n+        }\n+\n+        public Snapshot getSnapshot() {\n+            return snapshot;\n+        }\n+\n+        public IndexId getIndex() {\n+            return index;\n+        }\n+\n+        public int getShardId() {\n+            return shardId;\n+        }\n+\n+        @Override\n+        public boolean equals(Object o) {\n+            if (this == o) {\n+                return true;\n+            }\n+            if (o == null || getClass() != o.getClass()) {\n+                return false;\n+            }\n+            final SnapshotShard that = (SnapshotShard) o;\n+            return shardId == that.shardId\n+                && snapshot.equals(that.snapshot)\n+                && index.equals(that.index);\n+        }\n+\n+        @Override\n+        public int hashCode() {\n+            return Objects.hash(snapshot, index, shardId);\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"SnapshotShard{\" +\n+                \"snapshot=\" + snapshot +\n+                \", index=\" + index +\n+                \", shardId=\" + shardId +\n+                '}';\n+        }\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(snapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> requiredSnapshotShards = new HashSet<>();\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.id());\n+                    requiredSnapshotShards.add(snapshotShard);\n+                    // check if already populated entry\n+                    if (snapshotShardSizes.get(snapshotShard) == null) {\n+                        // check if already fetching snapshot info in progress\n+                        if (fetchingShards.add(snapshotShard)) {\n+                            // TODO: Use a dedicated threadpool here? Use FETCH thread pool?\n+                            threadPool.generic().execute(new AbstractRunnable() {\n+                                @Override\n+                                public void onFailure(Exception e) {\n+                                    logger.warn(new ParameterizedMessage(\"failed to retrieve shard size information for {}\",\n+                                        shardRouting), e);\n+                                }\n+\n+                                @Override\n+                                protected void doRun() {\n+                                    final RepositoriesService repositories = repositoriesServiceSupplier.get();\n+                                    assert repositories != null;\n+                                    final Repository repository = repositories.repository(snapshotShard.snapshot.getRepository());\n+                                    final IndexShardSnapshotStatus status =\n+                                        repository.getShardSnapshotStatus(snapshotRecoverySource.snapshot().getSnapshotId(),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg4MDYxNw=="}, "originalCommit": {"oid": "cb6daa1f9262d2b11f68ee18775db67c074b7da7"}, "originalPosition": 155}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNjkzNTQzOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQwODoxNTozOFrOHcSIUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQwOToxNjozOVrOHcUUDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTQxOTIxNw==", "bodyText": "This only need to be added on master nodes right? (relates #63223)", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499419217", "createdAt": "2020-10-05T08:15:38Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,308 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.concurrent.AdjustableSemaphore;\n+import org.elasticsearch.common.util.concurrent.RunOnce;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private final AdjustableSemaphore semaphore;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.semaphore = new AdjustableSemaphore(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings), false);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        clusterService.addListener(this);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f5ea5a9d9059598248ed25e0e383d3d242794269"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTQ1NDk5MQ==", "bodyText": "Good catch, I pushed 6c59655#diff-555b04095ef512902f5b90599d4a8da1R101-R103", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499454991", "createdAt": "2020-10-05T09:16:39Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,308 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.concurrent.AdjustableSemaphore;\n+import org.elasticsearch.common.util.concurrent.RunOnce;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private final AdjustableSemaphore semaphore;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.semaphore = new AdjustableSemaphore(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings), false);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        clusterService.addListener(this);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTQxOTIxNw=="}, "originalCommit": {"oid": "f5ea5a9d9059598248ed25e0e383d3d242794269"}, "originalPosition": 99}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNjk5Mjg2OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQwODozMTo0MFrOHcSrPw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQwOToxNzowOFrOHcUVYg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTQyODE1OQ==", "bodyText": "Do we really need a Semaphore here? Can't we just have these tasks increment a counter with incrementAndGet whenever we try to start one and if it's below the current limit + 1 we start a task? Then we only need to decrement the counter when we poll a null from the queue and it's all a lot easier isn't it?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499428159", "createdAt": "2020-10-05T08:31:40Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,308 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.concurrent.AdjustableSemaphore;\n+import org.elasticsearch.common.util.concurrent.RunOnce;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private final AdjustableSemaphore semaphore;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.semaphore = new AdjustableSemaphore(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings), false);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        clusterService.addListener(this);\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        semaphore.setMaxPermits(maxConcurrentFetches);\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, semaphore.getMaxPermits());\n+            for (int i = 0; i < nbFetchers; i++) {\n+                fetchNextSnapshotShard();\n+            }\n+        } else {\n+            synchronized (this) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        if (semaphore.tryAcquire()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f5ea5a9d9059598248ed25e0e383d3d242794269"}, "originalPosition": 171}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTQ1NTMzMA==", "bodyText": "Something like 6c59655?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499455330", "createdAt": "2020-10-05T09:17:08Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,308 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.concurrent.AdjustableSemaphore;\n+import org.elasticsearch.common.util.concurrent.RunOnce;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private final AdjustableSemaphore semaphore;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.semaphore = new AdjustableSemaphore(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings), false);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        clusterService.addListener(this);\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        semaphore.setMaxPermits(maxConcurrentFetches);\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, semaphore.getMaxPermits());\n+            for (int i = 0; i < nbFetchers; i++) {\n+                fetchNextSnapshotShard();\n+            }\n+        } else {\n+            synchronized (this) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        if (semaphore.tryAcquire()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTQyODE1OQ=="}, "originalCommit": {"oid": "f5ea5a9d9059598248ed25e0e383d3d242794269"}, "originalPosition": 171}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNzUxMTU2OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMDo0ODowNFrOHcXjGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNjoxNzo0OVrOHckYgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUwNzk5Mw==", "bodyText": "NIT: we could make this ActionListener just a static constant?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499507993", "createdAt": "2020-10-05T10:48:04Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {\n+                    fetchNextSnapshotShard();\n+                } else {\n+                    final int value = concurrentFetches.decrementAndGet();\n+                    assert value >= 0 : \"Unexpected value: \" + value;\n+                }\n+            }\n+        } else {\n+            synchronized (this) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        boolean success = false;\n+        try {\n+            final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n+            if (snapshotShard != null) {\n+                threadPool.executor(executorName()).execute(new AbstractRunnable() {\n+                    @Override\n+                    protected void doRun() {\n+                        if (clusterService.state().nodes().isLocalNodeElectedMaster() == false) {\n+                            logger.debug(\"skipping snapshot shard size retrieval for {} as node is no longer master\", snapshotShard);\n+                            return;\n+                        }\n+\n+                        final RepositoriesService repositories = repositoriesService.get();\n+                        assert repositories != null;\n+                        final Repository repository = repositories.repository(snapshotShard.snapshot.getRepository());\n+\n+                        logger.debug(\"fetching snapshot shard size for {}\", snapshotShard);\n+                        final IndexShardSnapshotStatus status = repository.getShardSnapshotStatus(\n+                            snapshotShard.snapshot().getSnapshotId(),\n+                            snapshotShard.index(),\n+                            snapshotShard.shardId()\n+                        );\n+\n+                        final long snapshotShardSize = status.asCopy().getTotalSize();\n+                        logger.debug(\"snapshot shard size for {}: {} bytes\", snapshotShard, snapshotShardSize);\n+\n+                        boolean updated = false;\n+                        synchronized (InternalSnapshotsInfoService.this) {\n+                            if (isMaster) {\n+                                final ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes =\n+                                    ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                                updated = newSnapshotShardSizes.put(snapshotShard, snapshotShardSize) == null;\n+                                knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                            }\n+                        }\n+                        if (updated) {\n+                            rerouteService.get().reroute(\"snapshot shard size updated\", Priority.HIGH,\n+                                ActionListener.wrap(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 218}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTcxODI3NA==", "bodyText": "Sure, I pushed bfd352c", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499718274", "createdAt": "2020-10-05T16:17:49Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {\n+                    fetchNextSnapshotShard();\n+                } else {\n+                    final int value = concurrentFetches.decrementAndGet();\n+                    assert value >= 0 : \"Unexpected value: \" + value;\n+                }\n+            }\n+        } else {\n+            synchronized (this) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        boolean success = false;\n+        try {\n+            final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n+            if (snapshotShard != null) {\n+                threadPool.executor(executorName()).execute(new AbstractRunnable() {\n+                    @Override\n+                    protected void doRun() {\n+                        if (clusterService.state().nodes().isLocalNodeElectedMaster() == false) {\n+                            logger.debug(\"skipping snapshot shard size retrieval for {} as node is no longer master\", snapshotShard);\n+                            return;\n+                        }\n+\n+                        final RepositoriesService repositories = repositoriesService.get();\n+                        assert repositories != null;\n+                        final Repository repository = repositories.repository(snapshotShard.snapshot.getRepository());\n+\n+                        logger.debug(\"fetching snapshot shard size for {}\", snapshotShard);\n+                        final IndexShardSnapshotStatus status = repository.getShardSnapshotStatus(\n+                            snapshotShard.snapshot().getSnapshotId(),\n+                            snapshotShard.index(),\n+                            snapshotShard.shardId()\n+                        );\n+\n+                        final long snapshotShardSize = status.asCopy().getTotalSize();\n+                        logger.debug(\"snapshot shard size for {}: {} bytes\", snapshotShard, snapshotShardSize);\n+\n+                        boolean updated = false;\n+                        synchronized (InternalSnapshotsInfoService.this) {\n+                            if (isMaster) {\n+                                final ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes =\n+                                    ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                                updated = newSnapshotShardSizes.put(snapshotShard, snapshotShardSize) == null;\n+                                knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                            }\n+                        }\n+                        if (updated) {\n+                            rerouteService.get().reroute(\"snapshot shard size updated\", Priority.HIGH,\n+                                ActionListener.wrap(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUwNzk5Mw=="}, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 218}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNzUyODc2OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMDo1Mzo0NlrOHcXt0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNjoxNzo1MlrOHckYnw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUxMDczOQ==", "bodyText": "This method can just be inlined, we never overwrite it?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499510739", "createdAt": "2020-10-05T10:53:46Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTcxODMwMw==", "bodyText": "This is a left-over, I removed it in f9ed974", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499718303", "createdAt": "2020-10-05T16:17:52Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUxMDczOQ=="}, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 107}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNzU0Njg3OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMDo1OTowNVrOHcX43g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMDo1OTowNVrOHcX43g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUxMzU2Ng==", "bodyText": "Maybe extract these two lines into a method releaseFetcher or so and with a one liner describing what this does since we use this in two spots?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499513566", "createdAt": "2020-10-05T10:59:05Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {\n+                    fetchNextSnapshotShard();\n+                } else {\n+                    final int value = concurrentFetches.decrementAndGet();\n+                    assert value >= 0 : \"Unexpected value: \" + value;\n+                }\n+            }\n+        } else {\n+            synchronized (this) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        boolean success = false;\n+        try {\n+            final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n+            if (snapshotShard != null) {\n+                threadPool.executor(executorName()).execute(new AbstractRunnable() {\n+                    @Override\n+                    protected void doRun() {\n+                        if (clusterService.state().nodes().isLocalNodeElectedMaster() == false) {\n+                            logger.debug(\"skipping snapshot shard size retrieval for {} as node is no longer master\", snapshotShard);\n+                            return;\n+                        }\n+\n+                        final RepositoriesService repositories = repositoriesService.get();\n+                        assert repositories != null;\n+                        final Repository repository = repositories.repository(snapshotShard.snapshot.getRepository());\n+\n+                        logger.debug(\"fetching snapshot shard size for {}\", snapshotShard);\n+                        final IndexShardSnapshotStatus status = repository.getShardSnapshotStatus(\n+                            snapshotShard.snapshot().getSnapshotId(),\n+                            snapshotShard.index(),\n+                            snapshotShard.shardId()\n+                        );\n+\n+                        final long snapshotShardSize = status.asCopy().getTotalSize();\n+                        logger.debug(\"snapshot shard size for {}: {} bytes\", snapshotShard, snapshotShardSize);\n+\n+                        boolean updated = false;\n+                        synchronized (InternalSnapshotsInfoService.this) {\n+                            if (isMaster) {\n+                                final ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes =\n+                                    ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                                updated = newSnapshotShardSizes.put(snapshotShard, snapshotShardSize) == null;\n+                                knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                            }\n+                        }\n+                        if (updated) {\n+                            rerouteService.get().reroute(\"snapshot shard size updated\", Priority.HIGH,\n+                                ActionListener.wrap(\n+                                    r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+                                    e -> logger.debug(\"reroute after snapshot shard size update failed\", e)));\n+                        }\n+                    }\n+\n+                    @Override\n+                    public void onFailure(Exception e) {\n+                        logger.warn(() -> new ParameterizedMessage(\"failed to retrieve shard size for {}\", snapshotShard), e);\n+                    }\n+\n+                    @Override\n+                    public void onAfter() {\n+                        unknownSnapshotShards.remove(snapshotShard);\n+                        fetchNextSnapshotShard();\n+                    }\n+                });\n+                success = true;\n+            }\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            logger.warn(\"snapshot shard size fetcher has been interrupted\", e);\n+        } finally {\n+            if (success == false) {\n+                final int value = concurrentFetches.decrementAndGet();\n+                assert value >= 0 : \"Unexpected value: \" + value;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 243}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNzU2MzEyOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMTowNDozMlrOHcYC-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNjoxNzo1N1rOHckY2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUxNjE1Mg==", "bodyText": "Maybe just make this a one liner with the above since we never really use status otherwise:\n                        final long snapshotShardSize = repository.getShardSnapshotStatus(\n                                snapshotShard.snapshot().getSnapshotId(),\n                                snapshotShard.index(),\n                                snapshotShard.shardId()\n                        ).asCopy().getTotalSize();", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499516152", "createdAt": "2020-10-05T11:04:32Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {\n+                    fetchNextSnapshotShard();\n+                } else {\n+                    final int value = concurrentFetches.decrementAndGet();\n+                    assert value >= 0 : \"Unexpected value: \" + value;\n+                }\n+            }\n+        } else {\n+            synchronized (this) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        boolean success = false;\n+        try {\n+            final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n+            if (snapshotShard != null) {\n+                threadPool.executor(executorName()).execute(new AbstractRunnable() {\n+                    @Override\n+                    protected void doRun() {\n+                        if (clusterService.state().nodes().isLocalNodeElectedMaster() == false) {\n+                            logger.debug(\"skipping snapshot shard size retrieval for {} as node is no longer master\", snapshotShard);\n+                            return;\n+                        }\n+\n+                        final RepositoriesService repositories = repositoriesService.get();\n+                        assert repositories != null;\n+                        final Repository repository = repositories.repository(snapshotShard.snapshot.getRepository());\n+\n+                        logger.debug(\"fetching snapshot shard size for {}\", snapshotShard);\n+                        final IndexShardSnapshotStatus status = repository.getShardSnapshotStatus(\n+                            snapshotShard.snapshot().getSnapshotId(),\n+                            snapshotShard.index(),\n+                            snapshotShard.shardId()\n+                        );\n+\n+                        final long snapshotShardSize = status.asCopy().getTotalSize();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 204}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTcxODM2MA==", "bodyText": "Ok, I pushed 866ba36", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499718360", "createdAt": "2020-10-05T16:17:57Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {\n+                    fetchNextSnapshotShard();\n+                } else {\n+                    final int value = concurrentFetches.decrementAndGet();\n+                    assert value >= 0 : \"Unexpected value: \" + value;\n+                }\n+            }\n+        } else {\n+            synchronized (this) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        boolean success = false;\n+        try {\n+            final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n+            if (snapshotShard != null) {\n+                threadPool.executor(executorName()).execute(new AbstractRunnable() {\n+                    @Override\n+                    protected void doRun() {\n+                        if (clusterService.state().nodes().isLocalNodeElectedMaster() == false) {\n+                            logger.debug(\"skipping snapshot shard size retrieval for {} as node is no longer master\", snapshotShard);\n+                            return;\n+                        }\n+\n+                        final RepositoriesService repositories = repositoriesService.get();\n+                        assert repositories != null;\n+                        final Repository repository = repositories.repository(snapshotShard.snapshot.getRepository());\n+\n+                        logger.debug(\"fetching snapshot shard size for {}\", snapshotShard);\n+                        final IndexShardSnapshotStatus status = repository.getShardSnapshotStatus(\n+                            snapshotShard.snapshot().getSnapshotId(),\n+                            snapshotShard.index(),\n+                            snapshotShard.shardId()\n+                        );\n+\n+                        final long snapshotShardSize = status.asCopy().getTotalSize();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUxNjE1Mg=="}, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 204}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNzU3NTg1OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMTowODozNlrOHcYKtw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNjoxODowM1rOHckZCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUxODEzNQ==", "bodyText": "NIT: Maybe just if (isMaster == false) ?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499518135", "createdAt": "2020-10-05T11:08:36Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {\n+                    fetchNextSnapshotShard();\n+                } else {\n+                    final int value = concurrentFetches.decrementAndGet();\n+                    assert value >= 0 : \"Unexpected value: \" + value;\n+                }\n+            }\n+        } else {\n+            synchronized (this) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        boolean success = false;\n+        try {\n+            final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n+            if (snapshotShard != null) {\n+                threadPool.executor(executorName()).execute(new AbstractRunnable() {\n+                    @Override\n+                    protected void doRun() {\n+                        if (clusterService.state().nodes().isLocalNodeElectedMaster() == false) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 188}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTcxODQxMA==", "bodyText": "Done in 7343b63", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499718410", "createdAt": "2020-10-05T16:18:03Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {\n+                    fetchNextSnapshotShard();\n+                } else {\n+                    final int value = concurrentFetches.decrementAndGet();\n+                    assert value >= 0 : \"Unexpected value: \" + value;\n+                }\n+            }\n+        } else {\n+            synchronized (this) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        boolean success = false;\n+        try {\n+            final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n+            if (snapshotShard != null) {\n+                threadPool.executor(executorName()).execute(new AbstractRunnable() {\n+                    @Override\n+                    protected void doRun() {\n+                        if (clusterService.state().nodes().isLocalNodeElectedMaster() == false) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUxODEzNQ=="}, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 188}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNzYwMDU4OnYy", "diffSide": "RIGHT", "path": "test/framework/src/main/java/org/elasticsearch/cluster/ESAllocationTestCase.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMToxNToyNVrOHcYY9A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNjoxODowNlrOHckZLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUyMTc4MA==", "bodyText": "Should we make sure to return the same size for the same shard consistently? (and maybe also assert that we are indeed dealing with a snapshot recovery routing here?)", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499521780", "createdAt": "2020-10-05T11:15:25Z", "author": {"login": "original-brownbear"}, "path": "test/framework/src/main/java/org/elasticsearch/cluster/ESAllocationTestCase.java", "diffHunk": "@@ -55,6 +58,14 @@\n     private static final ClusterSettings EMPTY_CLUSTER_SETTINGS =\n         new ClusterSettings(Settings.EMPTY, ClusterSettings.BUILT_IN_CLUSTER_SETTINGS);\n \n+    public static final SnapshotsInfoService SNAPSHOT_INFO_SERVICE_WITH_SHARD_SIZES = () ->\n+        new SnapshotShardSizeInfo(ImmutableOpenMap.of()) {\n+            @Override\n+            public Long getShardSize(ShardRouting shardRouting) {\n+                return randomNonNegativeLong();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTcxODQ0Nw==", "bodyText": "I think that it is trappy to always return an random size here. Test that rely on snapshot shard information should use their own implementation. I pushed 28de2d6 to add an assertion as you suggested + throw an unsupported exception here.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499718447", "createdAt": "2020-10-05T16:18:06Z", "author": {"login": "tlrx"}, "path": "test/framework/src/main/java/org/elasticsearch/cluster/ESAllocationTestCase.java", "diffHunk": "@@ -55,6 +58,14 @@\n     private static final ClusterSettings EMPTY_CLUSTER_SETTINGS =\n         new ClusterSettings(Settings.EMPTY, ClusterSettings.BUILT_IN_CLUSTER_SETTINGS);\n \n+    public static final SnapshotsInfoService SNAPSHOT_INFO_SERVICE_WITH_SHARD_SIZES = () ->\n+        new SnapshotShardSizeInfo(ImmutableOpenMap.of()) {\n+            @Override\n+            public Long getShardSize(ShardRouting shardRouting) {\n+                return randomNonNegativeLong();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUyMTc4MA=="}, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNzY5MDg0OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMTo0MTowOFrOHcZNPw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNjoxODowOVrOHckZUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUzNTE2Nw==", "bodyText": "Isn't updated always true since we won't double schedule a job for a certain shard's size ever?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499535167", "createdAt": "2020-10-05T11:41:08Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {\n+                    fetchNextSnapshotShard();\n+                } else {\n+                    final int value = concurrentFetches.decrementAndGet();\n+                    assert value >= 0 : \"Unexpected value: \" + value;\n+                }\n+            }\n+        } else {\n+            synchronized (this) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        boolean success = false;\n+        try {\n+            final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n+            if (snapshotShard != null) {\n+                threadPool.executor(executorName()).execute(new AbstractRunnable() {\n+                    @Override\n+                    protected void doRun() {\n+                        if (clusterService.state().nodes().isLocalNodeElectedMaster() == false) {\n+                            logger.debug(\"skipping snapshot shard size retrieval for {} as node is no longer master\", snapshotShard);\n+                            return;\n+                        }\n+\n+                        final RepositoriesService repositories = repositoriesService.get();\n+                        assert repositories != null;\n+                        final Repository repository = repositories.repository(snapshotShard.snapshot.getRepository());\n+\n+                        logger.debug(\"fetching snapshot shard size for {}\", snapshotShard);\n+                        final IndexShardSnapshotStatus status = repository.getShardSnapshotStatus(\n+                            snapshotShard.snapshot().getSnapshotId(),\n+                            snapshotShard.index(),\n+                            snapshotShard.shardId()\n+                        );\n+\n+                        final long snapshotShardSize = status.asCopy().getTotalSize();\n+                        logger.debug(\"snapshot shard size for {}: {} bytes\", snapshotShard, snapshotShardSize);\n+\n+                        boolean updated = false;\n+                        synchronized (InternalSnapshotsInfoService.this) {\n+                            if (isMaster) {\n+                                final ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes =\n+                                    ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                                updated = newSnapshotShardSizes.put(snapshotShard, snapshotShardSize) == null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 212}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTcxODQ4Mg==", "bodyText": "Indeed - I added an assertion on this in 2faf525", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499718482", "createdAt": "2020-10-05T16:18:09Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {\n+                    fetchNextSnapshotShard();\n+                } else {\n+                    final int value = concurrentFetches.decrementAndGet();\n+                    assert value >= 0 : \"Unexpected value: \" + value;\n+                }\n+            }\n+        } else {\n+            synchronized (this) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        boolean success = false;\n+        try {\n+            final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n+            if (snapshotShard != null) {\n+                threadPool.executor(executorName()).execute(new AbstractRunnable() {\n+                    @Override\n+                    protected void doRun() {\n+                        if (clusterService.state().nodes().isLocalNodeElectedMaster() == false) {\n+                            logger.debug(\"skipping snapshot shard size retrieval for {} as node is no longer master\", snapshotShard);\n+                            return;\n+                        }\n+\n+                        final RepositoriesService repositories = repositoriesService.get();\n+                        assert repositories != null;\n+                        final Repository repository = repositories.repository(snapshotShard.snapshot.getRepository());\n+\n+                        logger.debug(\"fetching snapshot shard size for {}\", snapshotShard);\n+                        final IndexShardSnapshotStatus status = repository.getShardSnapshotStatus(\n+                            snapshotShard.snapshot().getSnapshotId(),\n+                            snapshotShard.index(),\n+                            snapshotShard.shardId()\n+                        );\n+\n+                        final long snapshotShardSize = status.asCopy().getTotalSize();\n+                        logger.debug(\"snapshot shard size for {}: {} bytes\", snapshotShard, snapshotShardSize);\n+\n+                        boolean updated = false;\n+                        synchronized (InternalSnapshotsInfoService.this) {\n+                            if (isMaster) {\n+                                final ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes =\n+                                    ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                                updated = newSnapshotShardSizes.put(snapshotShard, snapshotShardSize) == null;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUzNTE2Nw=="}, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 212}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNzcwNDIyOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMTo0NDo1M1rOHcZVDw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNjoxODoxNVrOHckZiQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUzNzE2Nw==", "bodyText": "Should we assert that this returned true?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499537167", "createdAt": "2020-10-05T11:44:53Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {\n+                    fetchNextSnapshotShard();\n+                } else {\n+                    final int value = concurrentFetches.decrementAndGet();\n+                    assert value >= 0 : \"Unexpected value: \" + value;\n+                }\n+            }\n+        } else {\n+            synchronized (this) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        boolean success = false;\n+        try {\n+            final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n+            if (snapshotShard != null) {\n+                threadPool.executor(executorName()).execute(new AbstractRunnable() {\n+                    @Override\n+                    protected void doRun() {\n+                        if (clusterService.state().nodes().isLocalNodeElectedMaster() == false) {\n+                            logger.debug(\"skipping snapshot shard size retrieval for {} as node is no longer master\", snapshotShard);\n+                            return;\n+                        }\n+\n+                        final RepositoriesService repositories = repositoriesService.get();\n+                        assert repositories != null;\n+                        final Repository repository = repositories.repository(snapshotShard.snapshot.getRepository());\n+\n+                        logger.debug(\"fetching snapshot shard size for {}\", snapshotShard);\n+                        final IndexShardSnapshotStatus status = repository.getShardSnapshotStatus(\n+                            snapshotShard.snapshot().getSnapshotId(),\n+                            snapshotShard.index(),\n+                            snapshotShard.shardId()\n+                        );\n+\n+                        final long snapshotShardSize = status.asCopy().getTotalSize();\n+                        logger.debug(\"snapshot shard size for {}: {} bytes\", snapshotShard, snapshotShardSize);\n+\n+                        boolean updated = false;\n+                        synchronized (InternalSnapshotsInfoService.this) {\n+                            if (isMaster) {\n+                                final ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes =\n+                                    ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                                updated = newSnapshotShardSizes.put(snapshotShard, snapshotShardSize) == null;\n+                                knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                            }\n+                        }\n+                        if (updated) {\n+                            rerouteService.get().reroute(\"snapshot shard size updated\", Priority.HIGH,\n+                                ActionListener.wrap(\n+                                    r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+                                    e -> logger.debug(\"reroute after snapshot shard size update failed\", e)));\n+                        }\n+                    }\n+\n+                    @Override\n+                    public void onFailure(Exception e) {\n+                        logger.warn(() -> new ParameterizedMessage(\"failed to retrieve shard size for {}\", snapshotShard), e);\n+                    }\n+\n+                    @Override\n+                    public void onAfter() {\n+                        unknownSnapshotShards.remove(snapshotShard);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 231}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTcxODUzNw==", "bodyText": "I think we can -> a3dcb20", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499718537", "createdAt": "2020-10-05T16:18:15Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {\n+                    fetchNextSnapshotShard();\n+                } else {\n+                    final int value = concurrentFetches.decrementAndGet();\n+                    assert value >= 0 : \"Unexpected value: \" + value;\n+                }\n+            }\n+        } else {\n+            synchronized (this) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        boolean success = false;\n+        try {\n+            final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n+            if (snapshotShard != null) {\n+                threadPool.executor(executorName()).execute(new AbstractRunnable() {\n+                    @Override\n+                    protected void doRun() {\n+                        if (clusterService.state().nodes().isLocalNodeElectedMaster() == false) {\n+                            logger.debug(\"skipping snapshot shard size retrieval for {} as node is no longer master\", snapshotShard);\n+                            return;\n+                        }\n+\n+                        final RepositoriesService repositories = repositoriesService.get();\n+                        assert repositories != null;\n+                        final Repository repository = repositories.repository(snapshotShard.snapshot.getRepository());\n+\n+                        logger.debug(\"fetching snapshot shard size for {}\", snapshotShard);\n+                        final IndexShardSnapshotStatus status = repository.getShardSnapshotStatus(\n+                            snapshotShard.snapshot().getSnapshotId(),\n+                            snapshotShard.index(),\n+                            snapshotShard.shardId()\n+                        );\n+\n+                        final long snapshotShardSize = status.asCopy().getTotalSize();\n+                        logger.debug(\"snapshot shard size for {}: {} bytes\", snapshotShard, snapshotShardSize);\n+\n+                        boolean updated = false;\n+                        synchronized (InternalSnapshotsInfoService.this) {\n+                            if (isMaster) {\n+                                final ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes =\n+                                    ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                                updated = newSnapshotShardSizes.put(snapshotShard, snapshotShardSize) == null;\n+                                knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                            }\n+                        }\n+                        if (updated) {\n+                            rerouteService.get().reroute(\"snapshot shard size updated\", Priority.HIGH,\n+                                ActionListener.wrap(\n+                                    r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+                                    e -> logger.debug(\"reroute after snapshot shard size update failed\", e)));\n+                        }\n+                    }\n+\n+                    @Override\n+                    public void onFailure(Exception e) {\n+                        logger.warn(() -> new ParameterizedMessage(\"failed to retrieve shard size for {}\", snapshotShard), e);\n+                    }\n+\n+                    @Override\n+                    public void onAfter() {\n+                        unknownSnapshotShards.remove(snapshotShard);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUzNzE2Nw=="}, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 231}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNzcyMDUzOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMTo0OToyNlrOHcZe2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNjoxODoxOVrOHckZqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUzOTY3Mw==", "bodyText": "NIT: } else if (event.previousState().nodes().isLocalNodeElectedMaster()) { maybe so we don't execute this over and over?\nI also wonder if we even need to do this? Maybe we should instead just clean out unnecessary items in the map on event.routingTableChanged() if we're not master to not have to repopulate the map over and over in an unstable master situation where it might jump in and out of the cluster a few times (which would be really painful if we're dealing with a large number of shards)?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499539673", "createdAt": "2020-10-05T11:49:26Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {\n+                    fetchNextSnapshotShard();\n+                } else {\n+                    final int value = concurrentFetches.decrementAndGet();\n+                    assert value >= 0 : \"Unexpected value: \" + value;\n+                }\n+            }\n+        } else {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 171}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTcxODU3MQ==", "bodyText": "+1 on the previous state isLocalNodeElectedMaster() condition (ada6dd5).\nI added a //TODO for the other point you raise. I'm not sure we should do it but if we think we should I can do it in a follow up PR.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499718571", "createdAt": "2020-10-05T16:18:19Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {\n+                    fetchNextSnapshotShard();\n+                } else {\n+                    final int value = concurrentFetches.decrementAndGet();\n+                    assert value >= 0 : \"Unexpected value: \" + value;\n+                }\n+            }\n+        } else {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTUzOTY3Mw=="}, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 171}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNzcyMzk5OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/cluster/routing/allocation/DataTierAllocationDeciderTests.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMTo1MDoxNlrOHcZgzw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMTo1MDoxNlrOHcZgzw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU0MDE3NQ==", "bodyText": "NIT: space after null,", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499540175", "createdAt": "2020-10-05T11:50:16Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/cluster/routing/allocation/DataTierAllocationDeciderTests.java", "diffHunk": "@@ -553,7 +551,7 @@ public void testClusterAndIndex() {\n                 .put(DataTierAllocationDecider.INDEX_ROUTING_INCLUDE, \"data_warm,data_cold\")\n                 .build());\n         RoutingAllocation allocation = new RoutingAllocation(allocationDeciders, state.getRoutingNodes(), state,\n-            null, 0);\n+            null, null,0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 126}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNzcyNTUxOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/cluster/routing/allocation/DataTierAllocationDeciderTests.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMTo1MDozOFrOHcZhpQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMTo1MDozOFrOHcZhpQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU0MDM4OQ==", "bodyText": "NIT: Missing space here", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499540389", "createdAt": "2020-10-05T11:50:38Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/cluster/routing/allocation/DataTierAllocationDeciderTests.java", "diffHunk": "@@ -181,7 +183,7 @@ public void testIndexRequires() {\n                 .put(DataTierAllocationDecider.INDEX_ROUTING_REQUIRE, \"data_hot\")\n                 .build());\n         RoutingAllocation allocation = new RoutingAllocation(allocationDeciders, state.getRoutingNodes(), state,\n-            null, 0);\n+            null, null,0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNzcyNTczOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/cluster/routing/allocation/DataTierAllocationDeciderTests.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMTo1MDo0MlrOHcZhxg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMTo1MDo0MlrOHcZhxg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU0MDQyMg==", "bodyText": "NIT: Missing space here", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499540422", "createdAt": "2020-10-05T11:50:42Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/cluster/routing/allocation/DataTierAllocationDeciderTests.java", "diffHunk": "@@ -143,7 +145,7 @@ public void testClusterIncludes() {\n     public void testClusterExcludes() {\n         ClusterState state = prepareState(service.reroute(ClusterState.EMPTY_STATE, \"initial state\"));\n         RoutingAllocation allocation = new RoutingAllocation(allocationDeciders, state.getRoutingNodes(), state,\n-            null, 0);\n+            null, null,0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNzcyNTg3OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/cluster/routing/allocation/DataTierAllocationDeciderTests.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMTo1MDo0NFrOHcZh2g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMTo1MDo0NFrOHcZh2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU0MDQ0Mg==", "bodyText": "NIT: Missing space here", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499540442", "createdAt": "2020-10-05T11:50:44Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/cluster/routing/allocation/DataTierAllocationDeciderTests.java", "diffHunk": "@@ -108,7 +110,7 @@ public void testClusterRequires() {\n     public void testClusterIncludes() {\n         ClusterState state = prepareState(service.reroute(ClusterState.EMPTY_STATE, \"initial state\"));\n         RoutingAllocation allocation = new RoutingAllocation(allocationDeciders, state.getRoutingNodes(), state,\n-            null, 0);\n+            null, null,0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNzcyNjA3OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/cluster/routing/allocation/DataTierAllocationDeciderTests.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMTo1MDo0OFrOHcZh9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNjoxODoyN1rOHckZ-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU0MDQ3MQ==", "bodyText": "NIT: Missing space here", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499540471", "createdAt": "2020-10-05T11:50:48Z", "author": {"login": "original-brownbear"}, "path": "x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/cluster/routing/allocation/DataTierAllocationDeciderTests.java", "diffHunk": "@@ -74,7 +76,7 @@\n     public void testClusterRequires() {\n         ClusterState state = prepareState(service.reroute(ClusterState.EMPTY_STATE, \"initial state\"));\n         RoutingAllocation allocation = new RoutingAllocation(allocationDeciders, state.getRoutingNodes(), state,\n-            null, 0);\n+            null, null,0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTcxODY1MQ==", "bodyText": "Spaces addressed in b942b2d (sorry)", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499718651", "createdAt": "2020-10-05T16:18:27Z", "author": {"login": "tlrx"}, "path": "x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/cluster/routing/allocation/DataTierAllocationDeciderTests.java", "diffHunk": "@@ -74,7 +76,7 @@\n     public void testClusterRequires() {\n         ClusterState state = prepareState(service.reroute(ClusterState.EMPTY_STATE, \"initial state\"));\n         RoutingAllocation allocation = new RoutingAllocation(allocationDeciders, state.getRoutingNodes(), state,\n-            null, 0);\n+            null, null,0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU0MDQ3MQ=="}, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNzczMDM3OnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/snapshots/InternalSnapshotsInfoServiceTests.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMTo1MTo1OFrOHcZkgw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNjoxODozMVrOHckaJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU0MTEyMw==", "bodyText": "NIT: use org.elasticsearch.threadpool.ThreadPool#terminate(java.util.concurrent.ExecutorService, long, java.util.concurrent.TimeUnit) and assert it returns true?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499541123", "createdAt": "2020-10-05T11:51:58Z", "author": {"login": "original-brownbear"}, "path": "server/src/test/java/org/elasticsearch/snapshots/InternalSnapshotsInfoServiceTests.java", "diffHunk": "@@ -0,0 +1,336 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.node.DiscoveryNodes;\n+import org.elasticsearch.cluster.routing.IndexRoutingTable;\n+import org.elasticsearch.cluster.routing.IndexShardRoutingTable;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.RoutingTable;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.TestShardRouting;\n+import org.elasticsearch.cluster.service.ClusterApplier;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.FilterRepository;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.test.ClusterServiceUtils;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.threadpool.TestThreadPool;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.threadpool.ThreadPoolStats;\n+\n+import java.util.Collections;\n+import java.util.Locale;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Function;\n+\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_CREATION_DATE;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_REPLICAS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_SHARDS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_VERSION_CREATED;\n+import static org.elasticsearch.snapshots.InternalSnapshotsInfoService.INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING;\n+import static org.hamcrest.Matchers.allOf;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.lessThan;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Matchers.anyString;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+public class InternalSnapshotsInfoServiceTests extends ESTestCase {\n+\n+    private TestThreadPool threadPool;\n+    private ClusterService clusterService;\n+    private RepositoriesService repositoriesService;\n+    private RerouteService rerouteService;\n+\n+    @Override\n+    public void setUp() throws Exception {\n+        super.setUp();\n+        threadPool = new TestThreadPool(getTestName());\n+        clusterService = ClusterServiceUtils.createClusterService(threadPool);\n+        repositoriesService = mock(RepositoriesService.class);\n+        rerouteService = mock(RerouteService.class);\n+        doAnswer(invocation -> {\n+            @SuppressWarnings(\"unchecked\")\n+            final ActionListener<ClusterState> listener = (ActionListener<ClusterState>) invocation.getArguments()[2];\n+            listener.onResponse(clusterService.state());\n+            return null;\n+        }).when(rerouteService).reroute(anyString(), any(Priority.class), any());\n+    }\n+\n+    @Override\n+    public void tearDown() throws Exception {\n+        super.tearDown();\n+        threadPool.shutdownNow();\n+        threadPool.awaitTermination(30L, TimeUnit.SECONDS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTcxODY5Mw==", "bodyText": "Sure, see be18fad", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499718693", "createdAt": "2020-10-05T16:18:31Z", "author": {"login": "tlrx"}, "path": "server/src/test/java/org/elasticsearch/snapshots/InternalSnapshotsInfoServiceTests.java", "diffHunk": "@@ -0,0 +1,336 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.node.DiscoveryNodes;\n+import org.elasticsearch.cluster.routing.IndexRoutingTable;\n+import org.elasticsearch.cluster.routing.IndexShardRoutingTable;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.RoutingTable;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.TestShardRouting;\n+import org.elasticsearch.cluster.service.ClusterApplier;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.FilterRepository;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.test.ClusterServiceUtils;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.threadpool.TestThreadPool;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.threadpool.ThreadPoolStats;\n+\n+import java.util.Collections;\n+import java.util.Locale;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Function;\n+\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_CREATION_DATE;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_REPLICAS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_SHARDS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_VERSION_CREATED;\n+import static org.elasticsearch.snapshots.InternalSnapshotsInfoService.INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING;\n+import static org.hamcrest.Matchers.allOf;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.lessThan;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Matchers.anyString;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+public class InternalSnapshotsInfoServiceTests extends ESTestCase {\n+\n+    private TestThreadPool threadPool;\n+    private ClusterService clusterService;\n+    private RepositoriesService repositoriesService;\n+    private RerouteService rerouteService;\n+\n+    @Override\n+    public void setUp() throws Exception {\n+        super.setUp();\n+        threadPool = new TestThreadPool(getTestName());\n+        clusterService = ClusterServiceUtils.createClusterService(threadPool);\n+        repositoriesService = mock(RepositoriesService.class);\n+        rerouteService = mock(RerouteService.class);\n+        doAnswer(invocation -> {\n+            @SuppressWarnings(\"unchecked\")\n+            final ActionListener<ClusterState> listener = (ActionListener<ClusterState>) invocation.getArguments()[2];\n+            listener.onResponse(clusterService.state());\n+            return null;\n+        }).when(rerouteService).reroute(anyString(), any(Priority.class), any());\n+    }\n+\n+    @Override\n+    public void tearDown() throws Exception {\n+        super.tearDown();\n+        threadPool.shutdownNow();\n+        threadPool.awaitTermination(30L, TimeUnit.SECONDS);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU0MTEyMw=="}, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 111}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNzc1MDg4OnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/snapshots/InternalSnapshotsInfoServiceTests.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMTo1Nzo0MFrOHcZwqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNjoxODozNVrOHckaWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU0NDIzMg==", "bodyText": "NIT: Could do this in one go with the utilities we have as (also avoid mixing our own concurrency primitives with the JDK's):\n        PlainActionFuture.get(future -> clusterService.getClusterApplierService().onNewClusterState(reason,\n                () -> applier.apply(clusterService.state()),\n                new ClusterApplier.ClusterApplyListener() {\n                    @Override\n                    public void onSuccess(String source) {\n                        future.onResponse(source);\n                    }\n\n                    @Override\n                    public void onFailure(String source, Exception e) {\n                        future.onFailure(e);\n                    }\n                }));", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499544232", "createdAt": "2020-10-05T11:57:40Z", "author": {"login": "original-brownbear"}, "path": "server/src/test/java/org/elasticsearch/snapshots/InternalSnapshotsInfoServiceTests.java", "diffHunk": "@@ -0,0 +1,336 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.node.DiscoveryNodes;\n+import org.elasticsearch.cluster.routing.IndexRoutingTable;\n+import org.elasticsearch.cluster.routing.IndexShardRoutingTable;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.RoutingTable;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.TestShardRouting;\n+import org.elasticsearch.cluster.service.ClusterApplier;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.FilterRepository;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.test.ClusterServiceUtils;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.threadpool.TestThreadPool;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.threadpool.ThreadPoolStats;\n+\n+import java.util.Collections;\n+import java.util.Locale;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Function;\n+\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_CREATION_DATE;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_REPLICAS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_SHARDS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_VERSION_CREATED;\n+import static org.elasticsearch.snapshots.InternalSnapshotsInfoService.INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING;\n+import static org.hamcrest.Matchers.allOf;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.lessThan;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Matchers.anyString;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+public class InternalSnapshotsInfoServiceTests extends ESTestCase {\n+\n+    private TestThreadPool threadPool;\n+    private ClusterService clusterService;\n+    private RepositoriesService repositoriesService;\n+    private RerouteService rerouteService;\n+\n+    @Override\n+    public void setUp() throws Exception {\n+        super.setUp();\n+        threadPool = new TestThreadPool(getTestName());\n+        clusterService = ClusterServiceUtils.createClusterService(threadPool);\n+        repositoriesService = mock(RepositoriesService.class);\n+        rerouteService = mock(RerouteService.class);\n+        doAnswer(invocation -> {\n+            @SuppressWarnings(\"unchecked\")\n+            final ActionListener<ClusterState> listener = (ActionListener<ClusterState>) invocation.getArguments()[2];\n+            listener.onResponse(clusterService.state());\n+            return null;\n+        }).when(rerouteService).reroute(anyString(), any(Priority.class), any());\n+    }\n+\n+    @Override\n+    public void tearDown() throws Exception {\n+        super.tearDown();\n+        threadPool.shutdownNow();\n+        threadPool.awaitTermination(30L, TimeUnit.SECONDS);\n+        clusterService.close();\n+    }\n+\n+    public void testSnapshotShardSizes() throws Exception {\n+        final int maxConcurrentFetches = randomIntBetween(1, 10);\n+        final InternalSnapshotsInfoService snapshotsInfoService =\n+            new InternalSnapshotsInfoService(Settings.builder()\n+                .put(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.getKey(), maxConcurrentFetches)\n+                .build(), clusterService, () -> repositoriesService, () -> rerouteService);\n+\n+        final int numberOfShards = randomIntBetween(1, 50);\n+        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final long[] expectedShardSizes = new long[numberOfShards];\n+        for (int i = 0; i < expectedShardSizes.length; i++) {\n+            expectedShardSizes[i] = randomNonNegativeLong();\n+        }\n+\n+        final CountDownLatch latch = new CountDownLatch(1);\n+        when(repositoriesService.repository(\"_repo\"))\n+            .thenReturn(new FilterRepository(mock(Repository.class)) {\n+                @Override\n+                public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId shardId) {\n+                    try {\n+                        assertThat(indexId.getName(), equalTo(indexName));\n+                        assertThat(shardId.id(), allOf(greaterThanOrEqualTo(0), lessThan(numberOfShards)));\n+                        latch.await();\n+                        return IndexShardSnapshotStatus.newDone(0L, 0L, 0, 0, 0L, expectedShardSizes[shardId.id()], null);\n+                    } catch (InterruptedException e) {\n+                        throw new AssertionError(e);\n+                    }\n+                }\n+            });\n+\n+        applyClusterState(\"add-unassigned-shards\", clusterState -> addUnassignedShards(clusterState, indexName, numberOfShards));\n+        waitForMaxActiveGenericThreads(Math.min(numberOfShards, maxConcurrentFetches));\n+\n+        assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(numberOfShards));\n+        assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(0));\n+\n+        latch.countDown();\n+        waitForMaxActiveGenericThreads(0);\n+\n+        assertBusy(() -> {\n+            assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(numberOfShards));\n+            assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(0));\n+        });\n+        verify(rerouteService, times(numberOfShards)).reroute(anyString(), any(Priority.class), any());\n+\n+        for (int i = 0; i < numberOfShards; i++) {\n+            final ShardRouting shardRouting = clusterService.state().routingTable().index(indexName).shard(i).primaryShard();\n+            assertThat(snapshotsInfoService.snapshotShardSizes().getShardSize(shardRouting), equalTo(expectedShardSizes[i]));\n+        }\n+    }\n+\n+    public void testErroneousSnapshotShardSizes() throws Exception {\n+        final InternalSnapshotsInfoService snapshotsInfoService =\n+            new InternalSnapshotsInfoService(Settings.builder()\n+                .put(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.getKey(), randomIntBetween(1, 10))\n+                .build(), clusterService, () -> repositoriesService, () -> rerouteService);\n+\n+        final Set<InternalSnapshotsInfoService.SnapshotShard> succeed = Sets.newConcurrentHashSet();\n+        final Set<InternalSnapshotsInfoService.SnapshotShard> failed = Sets.newConcurrentHashSet();\n+        when(repositoriesService.repository(\"_repo\"))\n+            .thenReturn(new FilterRepository(mock(Repository.class)) {\n+                @Override\n+                public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId shardId) {\n+                    final InternalSnapshotsInfoService.SnapshotShard snapshotShard =\n+                        new InternalSnapshotsInfoService.SnapshotShard(new Snapshot(\"_repo\", snapshotId), indexId, shardId);\n+                    if (randomBoolean()) {\n+                        failed.add(snapshotShard);\n+                        throw new SnapshotException(snapshotShard.snapshot(), \"simulated\");\n+                    } else {\n+                        succeed.add(snapshotShard);\n+                        return IndexShardSnapshotStatus.newDone(0L, 0L, 0, 0, 0L, randomNonNegativeLong(), null);\n+                    }\n+                }\n+            });\n+\n+        final int maxShardsToCreate = scaledRandomIntBetween(10, 500);\n+        final Thread addSnapshotRestoreIndicesThread = new Thread(() -> {\n+            int remainingShards = maxShardsToCreate;\n+            while (remainingShards > 0) {\n+                final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+                final int numberOfShards = randomIntBetween(1, maxShardsToCreate);\n+                try {\n+                    applyClusterState(\"add-more-unassigned-shards-for-\" + indexName,\n+                        clusterState -> addUnassignedShards(clusterState, indexName, numberOfShards));\n+                } catch (Exception e) {\n+                    throw new AssertionError(e);\n+                } finally {\n+                    remainingShards -= numberOfShards;\n+                }\n+            }\n+        });\n+        addSnapshotRestoreIndicesThread.start();\n+\n+        assertBusy(() -> {\n+            assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(succeed.size()));\n+            assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(0));\n+        });\n+\n+        addSnapshotRestoreIndicesThread.join();\n+    }\n+\n+    public void testNoLongerMaster() throws Exception {\n+        final InternalSnapshotsInfoService snapshotsInfoService =\n+            new InternalSnapshotsInfoService(Settings.EMPTY, clusterService, () -> repositoriesService, () -> rerouteService);\n+\n+        when(repositoriesService.repository(\"_repo\"))\n+            .thenReturn(new FilterRepository(mock(Repository.class)) {\n+                @Override\n+                public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId shardId) {\n+                    return IndexShardSnapshotStatus.newDone(0L, 0L, 0, 0, 0L, randomNonNegativeLong(), null);\n+                }\n+            });\n+\n+        for (int i = 0; i < randomIntBetween(1, 10); i++) {\n+            final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+            final int nbShards =  randomIntBetween(1, 5);\n+            applyClusterState(\"restore-indices-when-master-\" + indexName,\n+                clusterState -> addUnassignedShards(clusterState, indexName, nbShards));\n+        }\n+\n+        applyClusterState(\"demote-current-master\", this::demoteMasterNode);\n+\n+        for (int i = 0; i < randomIntBetween(1, 10); i++) {\n+            final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+            final int nbShards =  randomIntBetween(1, 5);\n+            applyClusterState(\"restore-indices-when-no-longer-master-\" + indexName,\n+                clusterState -> addUnassignedShards(clusterState, indexName, nbShards));\n+        }\n+\n+        assertBusy(() -> {\n+            assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(0));\n+            assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(0));\n+        });\n+    }\n+\n+    private void applyClusterState(final String reason, final Function<ClusterState, ClusterState> applier) throws Exception {\n+        final CompletableFuture<String> future = new CompletableFuture<>();\n+        clusterService.getClusterApplierService().onNewClusterState(reason,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 252}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTcxODc0Ng==", "bodyText": "Indeed, thanks: 6dcff94", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499718746", "createdAt": "2020-10-05T16:18:35Z", "author": {"login": "tlrx"}, "path": "server/src/test/java/org/elasticsearch/snapshots/InternalSnapshotsInfoServiceTests.java", "diffHunk": "@@ -0,0 +1,336 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.node.DiscoveryNodes;\n+import org.elasticsearch.cluster.routing.IndexRoutingTable;\n+import org.elasticsearch.cluster.routing.IndexShardRoutingTable;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.RoutingTable;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.TestShardRouting;\n+import org.elasticsearch.cluster.service.ClusterApplier;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.FilterRepository;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.test.ClusterServiceUtils;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.threadpool.TestThreadPool;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.threadpool.ThreadPoolStats;\n+\n+import java.util.Collections;\n+import java.util.Locale;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Function;\n+\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_CREATION_DATE;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_REPLICAS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_SHARDS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_VERSION_CREATED;\n+import static org.elasticsearch.snapshots.InternalSnapshotsInfoService.INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING;\n+import static org.hamcrest.Matchers.allOf;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.lessThan;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Matchers.anyString;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+public class InternalSnapshotsInfoServiceTests extends ESTestCase {\n+\n+    private TestThreadPool threadPool;\n+    private ClusterService clusterService;\n+    private RepositoriesService repositoriesService;\n+    private RerouteService rerouteService;\n+\n+    @Override\n+    public void setUp() throws Exception {\n+        super.setUp();\n+        threadPool = new TestThreadPool(getTestName());\n+        clusterService = ClusterServiceUtils.createClusterService(threadPool);\n+        repositoriesService = mock(RepositoriesService.class);\n+        rerouteService = mock(RerouteService.class);\n+        doAnswer(invocation -> {\n+            @SuppressWarnings(\"unchecked\")\n+            final ActionListener<ClusterState> listener = (ActionListener<ClusterState>) invocation.getArguments()[2];\n+            listener.onResponse(clusterService.state());\n+            return null;\n+        }).when(rerouteService).reroute(anyString(), any(Priority.class), any());\n+    }\n+\n+    @Override\n+    public void tearDown() throws Exception {\n+        super.tearDown();\n+        threadPool.shutdownNow();\n+        threadPool.awaitTermination(30L, TimeUnit.SECONDS);\n+        clusterService.close();\n+    }\n+\n+    public void testSnapshotShardSizes() throws Exception {\n+        final int maxConcurrentFetches = randomIntBetween(1, 10);\n+        final InternalSnapshotsInfoService snapshotsInfoService =\n+            new InternalSnapshotsInfoService(Settings.builder()\n+                .put(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.getKey(), maxConcurrentFetches)\n+                .build(), clusterService, () -> repositoriesService, () -> rerouteService);\n+\n+        final int numberOfShards = randomIntBetween(1, 50);\n+        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final long[] expectedShardSizes = new long[numberOfShards];\n+        for (int i = 0; i < expectedShardSizes.length; i++) {\n+            expectedShardSizes[i] = randomNonNegativeLong();\n+        }\n+\n+        final CountDownLatch latch = new CountDownLatch(1);\n+        when(repositoriesService.repository(\"_repo\"))\n+            .thenReturn(new FilterRepository(mock(Repository.class)) {\n+                @Override\n+                public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId shardId) {\n+                    try {\n+                        assertThat(indexId.getName(), equalTo(indexName));\n+                        assertThat(shardId.id(), allOf(greaterThanOrEqualTo(0), lessThan(numberOfShards)));\n+                        latch.await();\n+                        return IndexShardSnapshotStatus.newDone(0L, 0L, 0, 0, 0L, expectedShardSizes[shardId.id()], null);\n+                    } catch (InterruptedException e) {\n+                        throw new AssertionError(e);\n+                    }\n+                }\n+            });\n+\n+        applyClusterState(\"add-unassigned-shards\", clusterState -> addUnassignedShards(clusterState, indexName, numberOfShards));\n+        waitForMaxActiveGenericThreads(Math.min(numberOfShards, maxConcurrentFetches));\n+\n+        assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(numberOfShards));\n+        assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(0));\n+\n+        latch.countDown();\n+        waitForMaxActiveGenericThreads(0);\n+\n+        assertBusy(() -> {\n+            assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(numberOfShards));\n+            assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(0));\n+        });\n+        verify(rerouteService, times(numberOfShards)).reroute(anyString(), any(Priority.class), any());\n+\n+        for (int i = 0; i < numberOfShards; i++) {\n+            final ShardRouting shardRouting = clusterService.state().routingTable().index(indexName).shard(i).primaryShard();\n+            assertThat(snapshotsInfoService.snapshotShardSizes().getShardSize(shardRouting), equalTo(expectedShardSizes[i]));\n+        }\n+    }\n+\n+    public void testErroneousSnapshotShardSizes() throws Exception {\n+        final InternalSnapshotsInfoService snapshotsInfoService =\n+            new InternalSnapshotsInfoService(Settings.builder()\n+                .put(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.getKey(), randomIntBetween(1, 10))\n+                .build(), clusterService, () -> repositoriesService, () -> rerouteService);\n+\n+        final Set<InternalSnapshotsInfoService.SnapshotShard> succeed = Sets.newConcurrentHashSet();\n+        final Set<InternalSnapshotsInfoService.SnapshotShard> failed = Sets.newConcurrentHashSet();\n+        when(repositoriesService.repository(\"_repo\"))\n+            .thenReturn(new FilterRepository(mock(Repository.class)) {\n+                @Override\n+                public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId shardId) {\n+                    final InternalSnapshotsInfoService.SnapshotShard snapshotShard =\n+                        new InternalSnapshotsInfoService.SnapshotShard(new Snapshot(\"_repo\", snapshotId), indexId, shardId);\n+                    if (randomBoolean()) {\n+                        failed.add(snapshotShard);\n+                        throw new SnapshotException(snapshotShard.snapshot(), \"simulated\");\n+                    } else {\n+                        succeed.add(snapshotShard);\n+                        return IndexShardSnapshotStatus.newDone(0L, 0L, 0, 0, 0L, randomNonNegativeLong(), null);\n+                    }\n+                }\n+            });\n+\n+        final int maxShardsToCreate = scaledRandomIntBetween(10, 500);\n+        final Thread addSnapshotRestoreIndicesThread = new Thread(() -> {\n+            int remainingShards = maxShardsToCreate;\n+            while (remainingShards > 0) {\n+                final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+                final int numberOfShards = randomIntBetween(1, maxShardsToCreate);\n+                try {\n+                    applyClusterState(\"add-more-unassigned-shards-for-\" + indexName,\n+                        clusterState -> addUnassignedShards(clusterState, indexName, numberOfShards));\n+                } catch (Exception e) {\n+                    throw new AssertionError(e);\n+                } finally {\n+                    remainingShards -= numberOfShards;\n+                }\n+            }\n+        });\n+        addSnapshotRestoreIndicesThread.start();\n+\n+        assertBusy(() -> {\n+            assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(succeed.size()));\n+            assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(0));\n+        });\n+\n+        addSnapshotRestoreIndicesThread.join();\n+    }\n+\n+    public void testNoLongerMaster() throws Exception {\n+        final InternalSnapshotsInfoService snapshotsInfoService =\n+            new InternalSnapshotsInfoService(Settings.EMPTY, clusterService, () -> repositoriesService, () -> rerouteService);\n+\n+        when(repositoriesService.repository(\"_repo\"))\n+            .thenReturn(new FilterRepository(mock(Repository.class)) {\n+                @Override\n+                public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId shardId) {\n+                    return IndexShardSnapshotStatus.newDone(0L, 0L, 0, 0, 0L, randomNonNegativeLong(), null);\n+                }\n+            });\n+\n+        for (int i = 0; i < randomIntBetween(1, 10); i++) {\n+            final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+            final int nbShards =  randomIntBetween(1, 5);\n+            applyClusterState(\"restore-indices-when-master-\" + indexName,\n+                clusterState -> addUnassignedShards(clusterState, indexName, nbShards));\n+        }\n+\n+        applyClusterState(\"demote-current-master\", this::demoteMasterNode);\n+\n+        for (int i = 0; i < randomIntBetween(1, 10); i++) {\n+            final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+            final int nbShards =  randomIntBetween(1, 5);\n+            applyClusterState(\"restore-indices-when-no-longer-master-\" + indexName,\n+                clusterState -> addUnassignedShards(clusterState, indexName, nbShards));\n+        }\n+\n+        assertBusy(() -> {\n+            assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(0));\n+            assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(0));\n+        });\n+    }\n+\n+    private void applyClusterState(final String reason, final Function<ClusterState, ClusterState> applier) throws Exception {\n+        final CompletableFuture<String> future = new CompletableFuture<>();\n+        clusterService.getClusterApplierService().onNewClusterState(reason,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU0NDIzMg=="}, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 252}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNzc5MTM5OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMjoxMDoyOVrOHcaJuw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNjoyMDoxMVrOHckeKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU1MDY1MQ==", "bodyText": "I think there is a race here, in that if all threads polled and found out that queue is empty but did not count down the counter yet, we could add to the queue here and risk that the increment results in a number higher than maxConcurrentFetches?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499550651", "createdAt": "2020-10-05T12:10:29Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 164}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU3Mjc2Mg==", "bodyText": "Right sorry for missing that ... looking at this again, do we even have to be so tricky here? :) Maybe we should just sychronize fetchNextSnapshotShard and this block:\n            for (int i = 0; i < nbFetchers; i++) {\n                final int activeFetches = concurrentFetches.incrementAndGet();\n                if (activeFetches < maxConcurrentFetches + 1) {\n                    fetchNextSnapshotShard();\n                } else {\n                    final int value = concurrentFetches.decrementAndGet();\n                    assert value >= 0 : \"Unexpected value: \" + value;\n                }\n            }\non the same mutex (e.g.  on queue) and use a normal int for the in-progress count (no need to bother with the count-down here then as well, we can just call fetchNextSnapshotShard() however often we are allowed in a loop and just adjust the in-progress count once)?  That seems the simplest and least error prone since the performance of the locking is not relevant here anyway?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499572762", "createdAt": "2020-10-05T12:49:24Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU1MDY1MQ=="}, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 164}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTcxOTcyMA==", "bodyText": "Following Armin's opinion for simplicity and usage of synchronized blocks I reworked the concurrency part in 674d6c9. I hope it makes things simpler but I must admit that I don't have clear ideas today so I'd appreciate more reviews there.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499719720", "createdAt": "2020-10-05T16:20:11Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU1MDY1MQ=="}, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 164}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNzk1NDg1OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMjo1NTo0MFrOHcbvig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxOTowMDoyNlrOHcp2cw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU3NjcxNA==", "bodyText": "I think there is a race with unknownSnapshotShards. It does take something extreme but in this case I think we might not read one of the shard sizes:\n\nA cluster state change results in queuing a read for a shard.\nThe read happens and populates knownSnapshotShards, but the thread is halted before removing from unkonwnSnapshotShards.\nA cluster state change removes the need for the shard (deleted index?).\nA cluster state change reintroduces the need to read the shard sizes. This will not add to queue, since this line did not complete yet on the original read.\nThe fetch thread removes shard from unknownSnapshotShards", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499576714", "createdAt": "2020-10-05T12:55:40Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {\n+                    fetchNextSnapshotShard();\n+                } else {\n+                    final int value = concurrentFetches.decrementAndGet();\n+                    assert value >= 0 : \"Unexpected value: \" + value;\n+                }\n+            }\n+        } else {\n+            synchronized (this) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        boolean success = false;\n+        try {\n+            final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n+            if (snapshotShard != null) {\n+                threadPool.executor(executorName()).execute(new AbstractRunnable() {\n+                    @Override\n+                    protected void doRun() {\n+                        if (clusterService.state().nodes().isLocalNodeElectedMaster() == false) {\n+                            logger.debug(\"skipping snapshot shard size retrieval for {} as node is no longer master\", snapshotShard);\n+                            return;\n+                        }\n+\n+                        final RepositoriesService repositories = repositoriesService.get();\n+                        assert repositories != null;\n+                        final Repository repository = repositories.repository(snapshotShard.snapshot.getRepository());\n+\n+                        logger.debug(\"fetching snapshot shard size for {}\", snapshotShard);\n+                        final IndexShardSnapshotStatus status = repository.getShardSnapshotStatus(\n+                            snapshotShard.snapshot().getSnapshotId(),\n+                            snapshotShard.index(),\n+                            snapshotShard.shardId()\n+                        );\n+\n+                        final long snapshotShardSize = status.asCopy().getTotalSize();\n+                        logger.debug(\"snapshot shard size for {}: {} bytes\", snapshotShard, snapshotShardSize);\n+\n+                        boolean updated = false;\n+                        synchronized (InternalSnapshotsInfoService.this) {\n+                            if (isMaster) {\n+                                final ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes =\n+                                    ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                                updated = newSnapshotShardSizes.put(snapshotShard, snapshotShardSize) == null;\n+                                knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                            }\n+                        }\n+                        if (updated) {\n+                            rerouteService.get().reroute(\"snapshot shard size updated\", Priority.HIGH,\n+                                ActionListener.wrap(\n+                                    r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+                                    e -> logger.debug(\"reroute after snapshot shard size update failed\", e)));\n+                        }\n+                    }\n+\n+                    @Override\n+                    public void onFailure(Exception e) {\n+                        logger.warn(() -> new ParameterizedMessage(\"failed to retrieve shard size for {}\", snapshotShard), e);\n+                    }\n+\n+                    @Override\n+                    public void onAfter() {\n+                        unknownSnapshotShards.remove(snapshotShard);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 231}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYwOTY3NA==", "bodyText": "but the thread is halted before removing from\n\nThis is impossible for a running node isn't it? We don't ever kill/interrupt actively executing threads on the generic pool and then keep going with the node?\n(can you even halt a thread in such a way that this method which is called in a finally block isn't executed every time we run this Runnable?)", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499609674", "createdAt": "2020-10-05T13:45:05Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {\n+                    fetchNextSnapshotShard();\n+                } else {\n+                    final int value = concurrentFetches.decrementAndGet();\n+                    assert value >= 0 : \"Unexpected value: \" + value;\n+                }\n+            }\n+        } else {\n+            synchronized (this) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        boolean success = false;\n+        try {\n+            final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n+            if (snapshotShard != null) {\n+                threadPool.executor(executorName()).execute(new AbstractRunnable() {\n+                    @Override\n+                    protected void doRun() {\n+                        if (clusterService.state().nodes().isLocalNodeElectedMaster() == false) {\n+                            logger.debug(\"skipping snapshot shard size retrieval for {} as node is no longer master\", snapshotShard);\n+                            return;\n+                        }\n+\n+                        final RepositoriesService repositories = repositoriesService.get();\n+                        assert repositories != null;\n+                        final Repository repository = repositories.repository(snapshotShard.snapshot.getRepository());\n+\n+                        logger.debug(\"fetching snapshot shard size for {}\", snapshotShard);\n+                        final IndexShardSnapshotStatus status = repository.getShardSnapshotStatus(\n+                            snapshotShard.snapshot().getSnapshotId(),\n+                            snapshotShard.index(),\n+                            snapshotShard.shardId()\n+                        );\n+\n+                        final long snapshotShardSize = status.asCopy().getTotalSize();\n+                        logger.debug(\"snapshot shard size for {}: {} bytes\", snapshotShard, snapshotShardSize);\n+\n+                        boolean updated = false;\n+                        synchronized (InternalSnapshotsInfoService.this) {\n+                            if (isMaster) {\n+                                final ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes =\n+                                    ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                                updated = newSnapshotShardSizes.put(snapshotShard, snapshotShardSize) == null;\n+                                knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                            }\n+                        }\n+                        if (updated) {\n+                            rerouteService.get().reroute(\"snapshot shard size updated\", Priority.HIGH,\n+                                ActionListener.wrap(\n+                                    r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+                                    e -> logger.debug(\"reroute after snapshot shard size update failed\", e)));\n+                        }\n+                    }\n+\n+                    @Override\n+                    public void onFailure(Exception e) {\n+                        logger.warn(() -> new ParameterizedMessage(\"failed to retrieve shard size for {}\", snapshotShard), e);\n+                    }\n+\n+                    @Override\n+                    public void onAfter() {\n+                        unknownSnapshotShards.remove(snapshotShard);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU3NjcxNA=="}, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 231}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYzOTk3Mw==", "bodyText": "I'm interested in Armin's questions answers, but besides this Henning raised a good point where the snapshot shard size should be removed from unknownSnapshotShards as soon as it is read, before it is added back to knownSnapshotShards", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499639973", "createdAt": "2020-10-05T14:27:13Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {\n+                    fetchNextSnapshotShard();\n+                } else {\n+                    final int value = concurrentFetches.decrementAndGet();\n+                    assert value >= 0 : \"Unexpected value: \" + value;\n+                }\n+            }\n+        } else {\n+            synchronized (this) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        boolean success = false;\n+        try {\n+            final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n+            if (snapshotShard != null) {\n+                threadPool.executor(executorName()).execute(new AbstractRunnable() {\n+                    @Override\n+                    protected void doRun() {\n+                        if (clusterService.state().nodes().isLocalNodeElectedMaster() == false) {\n+                            logger.debug(\"skipping snapshot shard size retrieval for {} as node is no longer master\", snapshotShard);\n+                            return;\n+                        }\n+\n+                        final RepositoriesService repositories = repositoriesService.get();\n+                        assert repositories != null;\n+                        final Repository repository = repositories.repository(snapshotShard.snapshot.getRepository());\n+\n+                        logger.debug(\"fetching snapshot shard size for {}\", snapshotShard);\n+                        final IndexShardSnapshotStatus status = repository.getShardSnapshotStatus(\n+                            snapshotShard.snapshot().getSnapshotId(),\n+                            snapshotShard.index(),\n+                            snapshotShard.shardId()\n+                        );\n+\n+                        final long snapshotShardSize = status.asCopy().getTotalSize();\n+                        logger.debug(\"snapshot shard size for {}: {} bytes\", snapshotShard, snapshotShardSize);\n+\n+                        boolean updated = false;\n+                        synchronized (InternalSnapshotsInfoService.this) {\n+                            if (isMaster) {\n+                                final ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes =\n+                                    ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                                updated = newSnapshotShardSizes.put(snapshotShard, snapshotShardSize) == null;\n+                                knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                            }\n+                        }\n+                        if (updated) {\n+                            rerouteService.get().reroute(\"snapshot shard size updated\", Priority.HIGH,\n+                                ActionListener.wrap(\n+                                    r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+                                    e -> logger.debug(\"reroute after snapshot shard size update failed\", e)));\n+                        }\n+                    }\n+\n+                    @Override\n+                    public void onFailure(Exception e) {\n+                        logger.warn(() -> new ParameterizedMessage(\"failed to retrieve shard size for {}\", snapshotShard), e);\n+                    }\n+\n+                    @Override\n+                    public void onAfter() {\n+                        unknownSnapshotShards.remove(snapshotShard);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU3NjcxNA=="}, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 231}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTgwNzg1OQ==", "bodyText": "I should probably have used \"paused\" rather than \"halted\". The finally block does run, but steps 3 and 4 could go in before it runs. Thanks for addressing this.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499807859", "createdAt": "2020-10-05T19:00:26Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.HashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private final ClusterService clusterService;\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private final AtomicInteger concurrentFetches;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.clusterService = clusterService;\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = Sets.newConcurrentHashSet();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.concurrentFetches = new AtomicInteger(0);\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    protected String executorName() {\n+        return ThreadPool.Names.GENERIC;\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = new HashSet<>();\n+\n+            int unknownShards = 0;\n+            for (ShardRouting shardRouting : event.state().routingTable().shardsWithState(ShardRoutingState.UNASSIGNED)) {\n+                if (shardRouting.primary() && shardRouting.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                    final RecoverySource.SnapshotRecoverySource snapshotRecoverySource =\n+                        (RecoverySource.SnapshotRecoverySource) shardRouting.recoverySource();\n+                    final SnapshotShard snapshotShard = new SnapshotShard(snapshotRecoverySource.snapshot(),\n+                        snapshotRecoverySource.index(), shardRouting.shardId());\n+                    onGoingSnapshotRecoveries.add(snapshotShard);\n+\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+            synchronized (this) {\n+                isMaster = true;\n+                ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+                for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+                    if (onGoingSnapshotRecoveries.contains(shard.value) == false) {\n+                        if (newSnapshotShardSizes == null) {\n+                            newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                        }\n+                        newSnapshotShardSizes.remove(shard.value);\n+                    }\n+                }\n+                if (newSnapshotShardSizes != null) {\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                final int activeFetches = concurrentFetches.incrementAndGet();\n+                if (activeFetches < maxConcurrentFetches + 1) {\n+                    fetchNextSnapshotShard();\n+                } else {\n+                    final int value = concurrentFetches.decrementAndGet();\n+                    assert value >= 0 : \"Unexpected value: \" + value;\n+                }\n+            }\n+        } else {\n+            synchronized (this) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        boolean success = false;\n+        try {\n+            final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n+            if (snapshotShard != null) {\n+                threadPool.executor(executorName()).execute(new AbstractRunnable() {\n+                    @Override\n+                    protected void doRun() {\n+                        if (clusterService.state().nodes().isLocalNodeElectedMaster() == false) {\n+                            logger.debug(\"skipping snapshot shard size retrieval for {} as node is no longer master\", snapshotShard);\n+                            return;\n+                        }\n+\n+                        final RepositoriesService repositories = repositoriesService.get();\n+                        assert repositories != null;\n+                        final Repository repository = repositories.repository(snapshotShard.snapshot.getRepository());\n+\n+                        logger.debug(\"fetching snapshot shard size for {}\", snapshotShard);\n+                        final IndexShardSnapshotStatus status = repository.getShardSnapshotStatus(\n+                            snapshotShard.snapshot().getSnapshotId(),\n+                            snapshotShard.index(),\n+                            snapshotShard.shardId()\n+                        );\n+\n+                        final long snapshotShardSize = status.asCopy().getTotalSize();\n+                        logger.debug(\"snapshot shard size for {}: {} bytes\", snapshotShard, snapshotShardSize);\n+\n+                        boolean updated = false;\n+                        synchronized (InternalSnapshotsInfoService.this) {\n+                            if (isMaster) {\n+                                final ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes =\n+                                    ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                                updated = newSnapshotShardSizes.put(snapshotShard, snapshotShardSize) == null;\n+                                knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                            }\n+                        }\n+                        if (updated) {\n+                            rerouteService.get().reroute(\"snapshot shard size updated\", Priority.HIGH,\n+                                ActionListener.wrap(\n+                                    r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+                                    e -> logger.debug(\"reroute after snapshot shard size update failed\", e)));\n+                        }\n+                    }\n+\n+                    @Override\n+                    public void onFailure(Exception e) {\n+                        logger.warn(() -> new ParameterizedMessage(\"failed to retrieve shard size for {}\", snapshotShard), e);\n+                    }\n+\n+                    @Override\n+                    public void onAfter() {\n+                        unknownSnapshotShards.remove(snapshotShard);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU3NjcxNA=="}, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 231}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyODA1MDE4OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshots.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMzoxODo1NFrOHccpdQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNjoxODo1MFrOHcka5g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU5MTU0MQ==", "bodyText": "This is unused?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499591541", "createdAt": "2020-10-05T13:18:54Z", "author": {"login": "DaveCTurner"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshots.java", "diffHunk": "@@ -150,6 +150,7 @@\n     private final SetOnce<BlobStoreCacheService> blobStoreCacheService = new SetOnce<>();\n     private final SetOnce<CacheService> cacheService = new SetOnce<>();\n     private final SetOnce<ThreadPool> threadPool = new SetOnce<>();\n+    private final SetOnce<ClusterService> clusterService = new SetOnce<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTcxODg4Ng==", "bodyText": "It is, I removed it in ae5895c", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499718886", "createdAt": "2020-10-05T16:18:50Z", "author": {"login": "tlrx"}, "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshots.java", "diffHunk": "@@ -150,6 +150,7 @@\n     private final SetOnce<BlobStoreCacheService> blobStoreCacheService = new SetOnce<>();\n     private final SetOnce<CacheService> cacheService = new SetOnce<>();\n     private final SetOnce<ThreadPool> threadPool = new SetOnce<>();\n+    private final SetOnce<ClusterService> clusterService = new SetOnce<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU5MTU0MQ=="}, "originalCommit": {"oid": "6c59655bd4c6d5c6ccc19c1a9c9324a3c170e910"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMDQ3NDA3OnYy", "diffSide": "LEFT", "path": "server/src/main/java/org/elasticsearch/cluster/ClusterInfo.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwMjozNjoyMlrOHcz9Vg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxMTowMDowMlrOHdA7IQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTk3MzQ2Mg==", "bodyText": "NIT: revert", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499973462", "createdAt": "2020-10-06T02:36:22Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/cluster/ClusterInfo.java", "diffHunk": "@@ -22,7 +22,6 @@\n import com.carrotsearch.hppc.ObjectHashSet;\n import com.carrotsearch.hppc.cursors.ObjectCursor;\n import com.carrotsearch.hppc.cursors.ObjectObjectCursor;\n-", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDE4NTg4OQ==", "bodyText": "Done in 881f621", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500185889", "createdAt": "2020-10-06T11:00:02Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/cluster/ClusterInfo.java", "diffHunk": "@@ -22,7 +22,6 @@\n import com.carrotsearch.hppc.ObjectHashSet;\n import com.carrotsearch.hppc.cursors.ObjectCursor;\n import com.carrotsearch.hppc.cursors.ObjectObjectCursor;\n-", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTk3MzQ2Mg=="}, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMDQ4ODU1OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwMjo0NToyNFrOHc0F2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxMTowMDowOFrOHdA7VQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTk3NTY0MQ==", "bodyText": "We can save some code here now that we have the mutex and don't need a concurrent collection any longer?\ne.g.\ndiff --git a/server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java b/server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java\nindex 43cd8cd11b1..a1917c3544b 100644\n--- a/server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java\n+++ b/server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java\n@@ -46,13 +46,12 @@ import org.elasticsearch.repositories.Repository;\n import org.elasticsearch.threadpool.ThreadPool;\n \n import java.util.Collections;\n+import java.util.Deque;\n import java.util.HashSet;\n import java.util.LinkedHashSet;\n+import java.util.LinkedList;\n import java.util.Objects;\n import java.util.Set;\n-import java.util.concurrent.BlockingQueue;\n-import java.util.concurrent.LinkedBlockingQueue;\n-import java.util.concurrent.TimeUnit;\n import java.util.function.Supplier;\n \n public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n@@ -81,7 +80,7 @@ public class InternalSnapshotsInfoService implements ClusterStateListener, Snaps\n     private final Set<SnapshotShard> unknownSnapshotShards;\n \n     /** a blocking queue used for concurrent fetching **/\n-    private final BlockingQueue<SnapshotShard> queue;\n+    private final Deque<SnapshotShard> queue;\n \n     private volatile int maxConcurrentFetches;\n     private volatile int activeFetches;\n@@ -99,7 +98,7 @@ public class InternalSnapshotsInfoService implements ClusterStateListener, Snaps\n         this.rerouteService = rerouteServiceSupplier;\n         this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n         this.unknownSnapshotShards  = new LinkedHashSet<>();\n-        this.queue = new LinkedBlockingQueue<>();\n+        this.queue = new LinkedList<>();\n         this.mutex = new Object();\n         this.activeFetches = 0;\n         this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n@@ -159,15 +158,10 @@ public class InternalSnapshotsInfoService implements ClusterStateListener, Snaps\n     private void fetchNextSnapshotShard() {\n         synchronized (mutex) {\n             if (activeFetches < maxConcurrentFetches) {\n-                try {\n-                    final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n-                    if (snapshotShard != null) {\n-                        threadPool.generic().execute(new FetchingSnapshotShardSizeRunnable(snapshotShard));\n-                        activeFetches += 1;\n-                    }\n-                } catch (InterruptedException e) {\n-                    Thread.currentThread().interrupt();\n-                    logger.warn(\"snapshot shard size fetcher has been interrupted\", e);\n+                final SnapshotShard snapshotShard = queue.pollFirst();\n+                if (snapshotShard != null) {\n+                    threadPool.generic().execute(new FetchingSnapshotShardSizeRunnable(snapshotShard));\n+                    activeFetches += 1;\n                 }\n             }\n             assert assertNumberOfConcurrentFetches();", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499975641", "createdAt": "2020-10-06T02:45:24Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private static final ActionListener<ClusterState> REROUTE_LISTENER = ActionListener.wrap(\n+        r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+        e -> logger.debug(\"reroute after snapshot shard size update failed\", e)\n+    );\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private volatile int activeFetches;\n+\n+    private final Object mutex;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = new LinkedHashSet<>();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.mutex = new Object();\n+        this.activeFetches = 0;\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = listOfSnapshotShards(event.state());\n+\n+            int unknownShards = 0;\n+            synchronized (mutex) {\n+                isMaster = true;\n+                for (SnapshotShard snapshotShard : onGoingSnapshotRecoveries) {\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+                // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+                cleanUpKnownSnapshotShardSizes(onGoingSnapshotRecoveries);\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                fetchNextSnapshotShard();\n+            }\n+        } else if (event.previousState().nodes().isLocalNodeElectedMaster()) {\n+            // TODO Maybe just clear out non-ongoing snapshot recoveries is the node is master eligible, so that we don't\n+            // have to repopulate the data over and over in an unstable master situation?\n+            synchronized (mutex) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        synchronized (mutex) {\n+            if (activeFetches < maxConcurrentFetches) {\n+                try {\n+                    final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 163}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAwOTk3Mg==", "bodyText": "Can we just use poll() and make the queue declaration non blocking? That also removes the need for interrupt handling.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500009972", "createdAt": "2020-10-06T05:14:21Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private static final ActionListener<ClusterState> REROUTE_LISTENER = ActionListener.wrap(\n+        r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+        e -> logger.debug(\"reroute after snapshot shard size update failed\", e)\n+    );\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private volatile int activeFetches;\n+\n+    private final Object mutex;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = new LinkedHashSet<>();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.mutex = new Object();\n+        this.activeFetches = 0;\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = listOfSnapshotShards(event.state());\n+\n+            int unknownShards = 0;\n+            synchronized (mutex) {\n+                isMaster = true;\n+                for (SnapshotShard snapshotShard : onGoingSnapshotRecoveries) {\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+                // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+                cleanUpKnownSnapshotShardSizes(onGoingSnapshotRecoveries);\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                fetchNextSnapshotShard();\n+            }\n+        } else if (event.previousState().nodes().isLocalNodeElectedMaster()) {\n+            // TODO Maybe just clear out non-ongoing snapshot recoveries is the node is master eligible, so that we don't\n+            // have to repopulate the data over and over in an unstable master situation?\n+            synchronized (mutex) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        synchronized (mutex) {\n+            if (activeFetches < maxConcurrentFetches) {\n+                try {\n+                    final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTk3NTY0MQ=="}, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 163}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDE4NTk0MQ==", "bodyText": "Makes perfect sense, thanks for noticing this! I pushed 528a848", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500185941", "createdAt": "2020-10-06T11:00:08Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private static final ActionListener<ClusterState> REROUTE_LISTENER = ActionListener.wrap(\n+        r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+        e -> logger.debug(\"reroute after snapshot shard size update failed\", e)\n+    );\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private volatile int activeFetches;\n+\n+    private final Object mutex;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = new LinkedHashSet<>();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.mutex = new Object();\n+        this.activeFetches = 0;\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = listOfSnapshotShards(event.state());\n+\n+            int unknownShards = 0;\n+            synchronized (mutex) {\n+                isMaster = true;\n+                for (SnapshotShard snapshotShard : onGoingSnapshotRecoveries) {\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+                // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+                cleanUpKnownSnapshotShardSizes(onGoingSnapshotRecoveries);\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                fetchNextSnapshotShard();\n+            }\n+        } else if (event.previousState().nodes().isLocalNodeElectedMaster()) {\n+            // TODO Maybe just clear out non-ongoing snapshot recoveries is the node is master eligible, so that we don't\n+            // have to repopulate the data over and over in an unstable master situation?\n+            synchronized (mutex) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        synchronized (mutex) {\n+            if (activeFetches < maxConcurrentFetches) {\n+                try {\n+                    final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTk3NTY0MQ=="}, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 163}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMDQ5MTgyOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwMjo0NzozMFrOHc0Hyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxMTowMDoxMlrOHdA7cQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTk3NjEzOA==", "bodyText": "This should now synchronise on the mutex as well shouldn't it?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499976138", "createdAt": "2020-10-06T02:47:30Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private static final ActionListener<ClusterState> REROUTE_LISTENER = ActionListener.wrap(\n+        r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+        e -> logger.debug(\"reroute after snapshot shard size update failed\", e)\n+    );\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private volatile int activeFetches;\n+\n+    private final Object mutex;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = new LinkedHashSet<>();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.mutex = new Object();\n+        this.activeFetches = 0;\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = listOfSnapshotShards(event.state());\n+\n+            int unknownShards = 0;\n+            synchronized (mutex) {\n+                isMaster = true;\n+                for (SnapshotShard snapshotShard : onGoingSnapshotRecoveries) {\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+                // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+                cleanUpKnownSnapshotShardSizes(onGoingSnapshotRecoveries);\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                fetchNextSnapshotShard();\n+            }\n+        } else if (event.previousState().nodes().isLocalNodeElectedMaster()) {\n+            // TODO Maybe just clear out non-ongoing snapshot recoveries is the node is master eligible, so that we don't\n+            // have to repopulate the data over and over in an unstable master situation?\n+            synchronized (mutex) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        synchronized (mutex) {\n+            if (activeFetches < maxConcurrentFetches) {\n+                try {\n+                    final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n+                    if (snapshotShard != null) {\n+                        threadPool.generic().execute(new FetchingSnapshotShardSizeRunnable(snapshotShard));\n+                        activeFetches += 1;\n+                    }\n+                } catch (InterruptedException e) {\n+                    Thread.currentThread().interrupt();\n+                    logger.warn(\"snapshot shard size fetcher has been interrupted\", e);\n+                }\n+            }\n+            assert assertNumberOfConcurrentFetches();\n+        }\n+    }\n+\n+    private class FetchingSnapshotShardSizeRunnable extends AbstractRunnable {\n+\n+        private final SnapshotShard snapshotShard;\n+        private boolean removed;\n+\n+        FetchingSnapshotShardSizeRunnable(SnapshotShard snapshotShard) {\n+            super();\n+            this.snapshotShard = snapshotShard;\n+            this.removed = false;\n+        }\n+\n+        @Override\n+        protected void doRun() throws Exception {\n+            final RepositoriesService repositories = repositoriesService.get();\n+            assert repositories != null;\n+            final Repository repository = repositories.repository(snapshotShard.snapshot.getRepository());\n+\n+            logger.debug(\"fetching snapshot shard size for {}\", snapshotShard);\n+            final long snapshotShardSize = repository.getShardSnapshotStatus(\n+                snapshotShard.snapshot().getSnapshotId(),\n+                snapshotShard.index(),\n+                snapshotShard.shardId()\n+            ).asCopy().getTotalSize();\n+\n+            logger.debug(\"snapshot shard size for {}: {} bytes\", snapshotShard, snapshotShardSize);\n+\n+            boolean updated = false;\n+            synchronized (mutex) {\n+                removed = unknownSnapshotShards.remove(snapshotShard);\n+                assert removed : \"snapshot shard to remove does not exist \" + snapshotShardSize;\n+                if (isMaster) {\n+                    final ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes =\n+                        ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                    updated = newSnapshotShardSizes.put(snapshotShard, snapshotShardSize) == null;\n+                    assert updated : \"snapshot shard size already exists for \" + snapshotShard;\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+                activeFetches -= 1;\n+                assert assertNumberOfConcurrentFetches();\n+            }\n+            if (updated) {\n+                rerouteService.get().reroute(\"snapshot shard size updated\", Priority.HIGH, REROUTE_LISTENER);\n+            }\n+        }\n+\n+        @Override\n+        public void onFailure(Exception e) {\n+            logger.warn(() -> new ParameterizedMessage(\"failed to retrieve shard size for {}\", snapshotShard), e);\n+            synchronized (mutex) {\n+                if (removed == false) {\n+                    unknownSnapshotShards.remove(snapshotShard);\n+                }\n+                activeFetches -= 1;\n+                assert assertNumberOfConcurrentFetches();\n+            }\n+        }\n+\n+        @Override\n+        public void onAfter() {\n+            fetchNextSnapshotShard();\n+        }\n+    }\n+\n+    private void cleanUpKnownSnapshotShardSizes(Set<SnapshotShard> requiredSnapshotShards) {\n+        assert Thread.holdsLock(mutex);\n+        ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+        for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+            if (requiredSnapshotShards.contains(shard.value) == false) {\n+                if (newSnapshotShardSizes == null) {\n+                    newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                }\n+                newSnapshotShardSizes.remove(shard.value);\n+            }\n+        }\n+        if (newSnapshotShardSizes != null) {\n+            knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+        }\n+    }\n+\n+    private boolean assertNumberOfConcurrentFetches() {\n+        assert activeFetches >= 0 : \"active fetches should be greater than or equal to zero but got: \" + activeFetches;\n+        assert activeFetches <= maxConcurrentFetches : activeFetches + \" <= \" + maxConcurrentFetches;\n+        return true;\n+    }\n+\n+    // used in tests\n+    int numberOfUnknownSnapshotShardSizes() {\n+        return unknownSnapshotShards.size();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 264}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDE4NTk2OQ==", "bodyText": "Yes -> a777c12", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500185969", "createdAt": "2020-10-06T11:00:12Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private static final ActionListener<ClusterState> REROUTE_LISTENER = ActionListener.wrap(\n+        r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+        e -> logger.debug(\"reroute after snapshot shard size update failed\", e)\n+    );\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private volatile int activeFetches;\n+\n+    private final Object mutex;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = new LinkedHashSet<>();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.mutex = new Object();\n+        this.activeFetches = 0;\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = listOfSnapshotShards(event.state());\n+\n+            int unknownShards = 0;\n+            synchronized (mutex) {\n+                isMaster = true;\n+                for (SnapshotShard snapshotShard : onGoingSnapshotRecoveries) {\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+                // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+                cleanUpKnownSnapshotShardSizes(onGoingSnapshotRecoveries);\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                fetchNextSnapshotShard();\n+            }\n+        } else if (event.previousState().nodes().isLocalNodeElectedMaster()) {\n+            // TODO Maybe just clear out non-ongoing snapshot recoveries is the node is master eligible, so that we don't\n+            // have to repopulate the data over and over in an unstable master situation?\n+            synchronized (mutex) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        synchronized (mutex) {\n+            if (activeFetches < maxConcurrentFetches) {\n+                try {\n+                    final SnapshotShard snapshotShard = queue.poll(0L, TimeUnit.MILLISECONDS);\n+                    if (snapshotShard != null) {\n+                        threadPool.generic().execute(new FetchingSnapshotShardSizeRunnable(snapshotShard));\n+                        activeFetches += 1;\n+                    }\n+                } catch (InterruptedException e) {\n+                    Thread.currentThread().interrupt();\n+                    logger.warn(\"snapshot shard size fetcher has been interrupted\", e);\n+                }\n+            }\n+            assert assertNumberOfConcurrentFetches();\n+        }\n+    }\n+\n+    private class FetchingSnapshotShardSizeRunnable extends AbstractRunnable {\n+\n+        private final SnapshotShard snapshotShard;\n+        private boolean removed;\n+\n+        FetchingSnapshotShardSizeRunnable(SnapshotShard snapshotShard) {\n+            super();\n+            this.snapshotShard = snapshotShard;\n+            this.removed = false;\n+        }\n+\n+        @Override\n+        protected void doRun() throws Exception {\n+            final RepositoriesService repositories = repositoriesService.get();\n+            assert repositories != null;\n+            final Repository repository = repositories.repository(snapshotShard.snapshot.getRepository());\n+\n+            logger.debug(\"fetching snapshot shard size for {}\", snapshotShard);\n+            final long snapshotShardSize = repository.getShardSnapshotStatus(\n+                snapshotShard.snapshot().getSnapshotId(),\n+                snapshotShard.index(),\n+                snapshotShard.shardId()\n+            ).asCopy().getTotalSize();\n+\n+            logger.debug(\"snapshot shard size for {}: {} bytes\", snapshotShard, snapshotShardSize);\n+\n+            boolean updated = false;\n+            synchronized (mutex) {\n+                removed = unknownSnapshotShards.remove(snapshotShard);\n+                assert removed : \"snapshot shard to remove does not exist \" + snapshotShardSize;\n+                if (isMaster) {\n+                    final ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes =\n+                        ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                    updated = newSnapshotShardSizes.put(snapshotShard, snapshotShardSize) == null;\n+                    assert updated : \"snapshot shard size already exists for \" + snapshotShard;\n+                    knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+                }\n+                activeFetches -= 1;\n+                assert assertNumberOfConcurrentFetches();\n+            }\n+            if (updated) {\n+                rerouteService.get().reroute(\"snapshot shard size updated\", Priority.HIGH, REROUTE_LISTENER);\n+            }\n+        }\n+\n+        @Override\n+        public void onFailure(Exception e) {\n+            logger.warn(() -> new ParameterizedMessage(\"failed to retrieve shard size for {}\", snapshotShard), e);\n+            synchronized (mutex) {\n+                if (removed == false) {\n+                    unknownSnapshotShards.remove(snapshotShard);\n+                }\n+                activeFetches -= 1;\n+                assert assertNumberOfConcurrentFetches();\n+            }\n+        }\n+\n+        @Override\n+        public void onAfter() {\n+            fetchNextSnapshotShard();\n+        }\n+    }\n+\n+    private void cleanUpKnownSnapshotShardSizes(Set<SnapshotShard> requiredSnapshotShards) {\n+        assert Thread.holdsLock(mutex);\n+        ImmutableOpenMap.Builder<SnapshotShard, Long> newSnapshotShardSizes = null;\n+        for (ObjectCursor<SnapshotShard> shard : knownSnapshotShardSizes.keys()) {\n+            if (requiredSnapshotShards.contains(shard.value) == false) {\n+                if (newSnapshotShardSizes == null) {\n+                    newSnapshotShardSizes = ImmutableOpenMap.builder(knownSnapshotShardSizes);\n+                }\n+                newSnapshotShardSizes.remove(shard.value);\n+            }\n+        }\n+        if (newSnapshotShardSizes != null) {\n+            knownSnapshotShardSizes = newSnapshotShardSizes.build();\n+        }\n+    }\n+\n+    private boolean assertNumberOfConcurrentFetches() {\n+        assert activeFetches >= 0 : \"active fetches should be greater than or equal to zero but got: \" + activeFetches;\n+        assert activeFetches <= maxConcurrentFetches : activeFetches + \" <= \" + maxConcurrentFetches;\n+        return true;\n+    }\n+\n+    // used in tests\n+    int numberOfUnknownSnapshotShardSizes() {\n+        return unknownSnapshotShards.size();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTk3NjEzOA=="}, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 264}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMDQ5NjMwOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwMjo1MDoxNVrOHc0KcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxMTowNDoyMFrOHdBD1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTk3NjgxNg==", "bodyText": "Should we also clear queue here?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r499976816", "createdAt": "2020-10-06T02:50:15Z", "author": {"login": "original-brownbear"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private static final ActionListener<ClusterState> REROUTE_LISTENER = ActionListener.wrap(\n+        r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+        e -> logger.debug(\"reroute after snapshot shard size update failed\", e)\n+    );\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private volatile int activeFetches;\n+\n+    private final Object mutex;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = new LinkedHashSet<>();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.mutex = new Object();\n+        this.activeFetches = 0;\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = listOfSnapshotShards(event.state());\n+\n+            int unknownShards = 0;\n+            synchronized (mutex) {\n+                isMaster = true;\n+                for (SnapshotShard snapshotShard : onGoingSnapshotRecoveries) {\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+                // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+                cleanUpKnownSnapshotShardSizes(onGoingSnapshotRecoveries);\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                fetchNextSnapshotShard();\n+            }\n+        } else if (event.previousState().nodes().isLocalNodeElectedMaster()) {\n+            // TODO Maybe just clear out non-ongoing snapshot recoveries is the node is master eligible, so that we don't\n+            // have to repopulate the data over and over in an unstable master situation?\n+            synchronized (mutex) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 153}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDE4ODExNg==", "bodyText": "Yes we should -> 4a716b0", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500188116", "createdAt": "2020-10-06T11:04:20Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private static final ActionListener<ClusterState> REROUTE_LISTENER = ActionListener.wrap(\n+        r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+        e -> logger.debug(\"reroute after snapshot shard size update failed\", e)\n+    );\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private volatile int activeFetches;\n+\n+    private final Object mutex;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = new LinkedHashSet<>();\n+        this.queue = new LinkedBlockingQueue<>();\n+        this.mutex = new Object();\n+        this.activeFetches = 0;\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = listOfSnapshotShards(event.state());\n+\n+            int unknownShards = 0;\n+            synchronized (mutex) {\n+                isMaster = true;\n+                for (SnapshotShard snapshotShard : onGoingSnapshotRecoveries) {\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+                // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+                cleanUpKnownSnapshotShardSizes(onGoingSnapshotRecoveries);\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                fetchNextSnapshotShard();\n+            }\n+        } else if (event.previousState().nodes().isLocalNodeElectedMaster()) {\n+            // TODO Maybe just clear out non-ongoing snapshot recoveries is the node is master eligible, so that we don't\n+            // have to repopulate the data over and over in an unstable master situation?\n+            synchronized (mutex) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTk3NjgxNg=="}, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 153}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMDcxOTQ2OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNToxNjoyMVrOHc2OCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxMTowNDoyOVrOHdBEIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAxMDUwNg==", "bodyText": "AFAICS, this is now fully protected by mutex.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500010506", "createdAt": "2020-10-06T05:16:21Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private static final ActionListener<ClusterState> REROUTE_LISTENER = ActionListener.wrap(\n+        r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+        e -> logger.debug(\"reroute after snapshot shard size update failed\", e)\n+    );\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private volatile int activeFetches;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDE4ODE5Mw==", "bodyText": "Good catch: a8e7475", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500188193", "createdAt": "2020-10-06T11:04:29Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private static final ActionListener<ClusterState> REROUTE_LISTENER = ActionListener.wrap(\n+        r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+        e -> logger.debug(\"reroute after snapshot shard size update failed\", e)\n+    );\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final BlockingQueue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private volatile int activeFetches;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAxMDUwNg=="}, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 87}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMDgzMTEyOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNjoxMzo1OFrOHc3ROw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxMToyMzowMFrOHdBpgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAyNzcwNw==", "bodyText": "This seems to assume that we only get here for unassigned shards, never for initializing shards. I have not found a smoking gun where we could get here in that case, but I would prefer to be more specific in the condition above to only go here for unassigned shards.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500027707", "createdAt": "2020-10-06T06:13:58Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java", "diffHunk": "@@ -482,6 +484,12 @@ public static long getExpectedShardSize(ShardRouting shard, long defaultValue, C\n             }\n             return targetShardSize == 0 ? defaultValue : targetShardSize;\n         } else {\n+            if (shard.active() == false\n+                && shard.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                final Long shardSize = snapshotShardSizeInfo.getShardSize(shard);\n+                assert shardSize != null : \"no shard size provided for \" + shard;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDE4ODI4NA==", "bodyText": "It seems reasonable indeed (0aaf829)", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500188284", "createdAt": "2020-10-06T11:04:40Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java", "diffHunk": "@@ -482,6 +484,12 @@ public static long getExpectedShardSize(ShardRouting shard, long defaultValue, C\n             }\n             return targetShardSize == 0 ? defaultValue : targetShardSize;\n         } else {\n+            if (shard.active() == false\n+                && shard.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                final Long shardSize = snapshotShardSizeInfo.getShardSize(shard);\n+                assert shardSize != null : \"no shard size provided for \" + shard;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAyNzcwNw=="}, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDE5Nzc2Mg==", "bodyText": "FWIW I think we don't get here for shards that are initialising from a snapshot today: the callers are canAllocate(), sizeOfRelocatingShards() and BalancedShardsAllocator#allocateUnassigned:\n\nBalancedShardsAllocator#allocateUnassigned only works with unassigned shards\nsizeOfRelocatingShards() only works with relocating shards (either source or target) which necessarily don't have recovery source SNAPSHOT,\ncanAllocate() only tries to allocate unassigned shards and shards that are fully started.\n\nI'm still +1 on this change.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500197762", "createdAt": "2020-10-06T11:23:00Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java", "diffHunk": "@@ -482,6 +484,12 @@ public static long getExpectedShardSize(ShardRouting shard, long defaultValue, C\n             }\n             return targetShardSize == 0 ? defaultValue : targetShardSize;\n         } else {\n+            if (shard.active() == false\n+                && shard.recoverySource().getType() == RecoverySource.Type.SNAPSHOT) {\n+                final Long shardSize = snapshotShardSizeInfo.getShardSize(shard);\n+                assert shardSize != null : \"no shard size provided for \" + shard;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAyNzcwNw=="}, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMDg3MjI0OnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/cluster/routing/allocation/ResizeAllocationDeciderTests.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNjozMDo0N1rOHc3p0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNjozMDo0N1rOHc3p0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAzNDAwMQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    RoutingAllocation routingAllocation = new RoutingAllocation(null, null, clusterState, null, null,0);\n          \n          \n            \n                    RoutingAllocation routingAllocation = new RoutingAllocation(null, null, clusterState, null, null, 0);", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500034001", "createdAt": "2020-10-06T06:30:47Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/cluster/routing/allocation/ResizeAllocationDeciderTests.java", "diffHunk": "@@ -104,7 +106,7 @@ private ClusterState createInitialClusterState(boolean startShards) {\n     public void testNonResizeRouting() {\n         ClusterState clusterState = createInitialClusterState(true);\n         ResizeAllocationDecider resizeAllocationDecider = new ResizeAllocationDecider();\n-        RoutingAllocation routingAllocation = new RoutingAllocation(null, null, clusterState, null, 0);\n+        RoutingAllocation routingAllocation = new RoutingAllocation(null, null, clusterState, null, null,0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMDg3Mjk0OnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/cluster/routing/allocation/ResizeAllocationDeciderTests.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNjozMTowMVrOHc3qOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNjozMTowMVrOHc3qOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAzNDEwNg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    RoutingAllocation routingAllocation = new RoutingAllocation(null, null, clusterState, null, null,0);\n          \n          \n            \n                    RoutingAllocation routingAllocation = new RoutingAllocation(null, null, clusterState, null, null, 0);", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500034106", "createdAt": "2020-10-06T06:31:01Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/cluster/routing/allocation/ResizeAllocationDeciderTests.java", "diffHunk": "@@ -128,7 +130,7 @@ public void testShrink() { // we don't handle shrink yet\n         Index idx = clusterState.metadata().index(\"target\").getIndex();\n \n         ResizeAllocationDecider resizeAllocationDecider = new ResizeAllocationDecider();\n-        RoutingAllocation routingAllocation = new RoutingAllocation(null, null, clusterState, null, 0);\n+        RoutingAllocation routingAllocation = new RoutingAllocation(null, null, clusterState, null, null,0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMDg3MzUwOnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/cluster/routing/allocation/ResizeAllocationDeciderTests.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNjozMToxNFrOHc3qig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNjozMToxNFrOHc3qig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAzNDE4Ng==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    RoutingAllocation routingAllocation = new RoutingAllocation(null, clusterState.getRoutingNodes(), clusterState, null, null,0);\n          \n          \n            \n                    RoutingAllocation routingAllocation = new RoutingAllocation(null, clusterState.getRoutingNodes(), clusterState, null, null, 0);", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500034186", "createdAt": "2020-10-06T06:31:14Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/cluster/routing/allocation/ResizeAllocationDeciderTests.java", "diffHunk": "@@ -156,7 +158,7 @@ public void testSourceNotActive() {\n \n \n         ResizeAllocationDecider resizeAllocationDecider = new ResizeAllocationDecider();\n-        RoutingAllocation routingAllocation = new RoutingAllocation(null, clusterState.getRoutingNodes(), clusterState, null, 0);\n+        RoutingAllocation routingAllocation = new RoutingAllocation(null, clusterState.getRoutingNodes(), clusterState, null, null,0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMDg3NDA4OnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/cluster/routing/allocation/ResizeAllocationDeciderTests.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNjozMToyOVrOHc3q5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNjozMToyOVrOHc3q5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAzNDI3OQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    RoutingAllocation routingAllocation = new RoutingAllocation(null, clusterState.getRoutingNodes(), clusterState, null, null,0);\n          \n          \n            \n                    RoutingAllocation routingAllocation = new RoutingAllocation(null, clusterState.getRoutingNodes(), clusterState, null, null, 0);", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500034279", "createdAt": "2020-10-06T06:31:29Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/cluster/routing/allocation/ResizeAllocationDeciderTests.java", "diffHunk": "@@ -196,7 +198,7 @@ public void testSourcePrimaryActive() {\n \n \n         ResizeAllocationDecider resizeAllocationDecider = new ResizeAllocationDecider();\n-        RoutingAllocation routingAllocation = new RoutingAllocation(null, clusterState.getRoutingNodes(), clusterState, null, 0);\n+        RoutingAllocation routingAllocation = new RoutingAllocation(null, clusterState.getRoutingNodes(), clusterState, null, null,0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMDkwNDE5OnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/FilterAllocationDeciderTests.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNjo0MzowM1rOHc39Rw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNjo0MzowM1rOHc39Rw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAzODk4Mw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        null, null,0);\n          \n          \n            \n                        null, null, 0);", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500038983", "createdAt": "2020-10-06T06:43:03Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/FilterAllocationDeciderTests.java", "diffHunk": "@@ -73,7 +75,7 @@ public void testFilterInitialRecovery() {\n \n         // after failing the shard we are unassigned since the node is blacklisted and we can't initialize on the other node\n         RoutingAllocation allocation = new RoutingAllocation(allocationDeciders, state.getRoutingNodes(), state,\n-            null, 0);\n+            null, null,0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMDkwNTA0OnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/FilterAllocationDeciderTests.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNjo0MzoyOFrOHc395g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNjo0MzoyOFrOHc395g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAzOTE0Mg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        null, null,0);\n          \n          \n            \n                        null, null, 0);", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500039142", "createdAt": "2020-10-06T06:43:28Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/FilterAllocationDeciderTests.java", "diffHunk": "@@ -124,7 +126,7 @@ public void testFilterInitialRecovery() {\n         assertEquals(routingTable.index(\"idx\").shard(0).primaryShard().currentNodeId(), \"node1\");\n \n         allocation = new RoutingAllocation(allocationDeciders, state.getRoutingNodes(), state,\n-            null, 0);\n+            null, null,0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMDkwNTcwOnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/RestoreInProgressAllocationDeciderTests.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNjo0Mzo0NFrOHc3-SA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNjo0Mzo0NFrOHc3-SA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAzOTI0MA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        clusterState.getRoutingNodes(), clusterState, null, null,0L);\n          \n          \n            \n                        clusterState.getRoutingNodes(), clusterState, null, null, 0L);", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500039240", "createdAt": "2020-10-06T06:43:44Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/RestoreInProgressAllocationDeciderTests.java", "diffHunk": "@@ -193,7 +193,7 @@ private ClusterState createInitialClusterState() {\n     private Decision executeAllocation(final ClusterState clusterState, final ShardRouting shardRouting) {\n         final AllocationDecider decider = new RestoreInProgressAllocationDecider();\n         final RoutingAllocation allocation = new RoutingAllocation(new AllocationDeciders(Collections.singleton(decider)),\n-            clusterState.getRoutingNodes(), clusterState, null, 0L);\n+            clusterState.getRoutingNodes(), clusterState, null, null,0L);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMDkwNjg2OnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/gateway/PrimaryShardAllocatorTests.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNjo0NDowOVrOHc3-8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNjo0NDowOVrOHc3-8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAzOTQwOA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    RoutingAllocation allocation = getRestoreRoutingAllocation(yesAllocationDeciders(), randomLong(),\"allocId\");\n          \n          \n            \n                    RoutingAllocation allocation = getRestoreRoutingAllocation(yesAllocationDeciders(), randomLong(), \"allocId\");", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500039408", "createdAt": "2020-10-06T06:44:09Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/gateway/PrimaryShardAllocatorTests.java", "diffHunk": "@@ -341,7 +343,7 @@ public void testFoundAllocationButNoDecider() {\n      * deciders say yes, we allocate to that node.\n      */\n     public void testRestore() {\n-        RoutingAllocation allocation = getRestoreRoutingAllocation(yesAllocationDeciders(), \"allocId\");\n+        RoutingAllocation allocation = getRestoreRoutingAllocation(yesAllocationDeciders(), randomLong(),\"allocId\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMDkwNzQ2OnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/gateway/PrimaryShardAllocatorTests.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNjo0NDoxOFrOHc3_Rw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxMTowNDo1NFrOHdBE4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAzOTQ5NQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    RoutingAllocation allocation = getRestoreRoutingAllocation(throttleAllocationDeciders(), randomLong(),\"allocId\");\n          \n          \n            \n                    RoutingAllocation allocation = getRestoreRoutingAllocation(throttleAllocationDeciders(), randomLong(), \"allocId\");", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500039495", "createdAt": "2020-10-06T06:44:18Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/gateway/PrimaryShardAllocatorTests.java", "diffHunk": "@@ -355,7 +357,7 @@ public void testRestore() {\n      * deciders say throttle, we add it to ignored shards.\n      */\n     public void testRestoreThrottle() {\n-        RoutingAllocation allocation = getRestoreRoutingAllocation(throttleAllocationDeciders(), \"allocId\");\n+        RoutingAllocation allocation = getRestoreRoutingAllocation(throttleAllocationDeciders(), randomLong(),\"allocId\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDE4ODM4NQ==", "bodyText": "Sorry for the noise, the reported spaces issues are addressed in 42ba44f", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500188385", "createdAt": "2020-10-06T11:04:54Z", "author": {"login": "tlrx"}, "path": "server/src/test/java/org/elasticsearch/gateway/PrimaryShardAllocatorTests.java", "diffHunk": "@@ -355,7 +357,7 @@ public void testRestore() {\n      * deciders say throttle, we add it to ignored shards.\n      */\n     public void testRestoreThrottle() {\n-        RoutingAllocation allocation = getRestoreRoutingAllocation(throttleAllocationDeciders(), \"allocId\");\n+        RoutingAllocation allocation = getRestoreRoutingAllocation(throttleAllocationDeciders(), randomLong(),\"allocId\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAzOTQ5NQ=="}, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMDkxOTcyOnYy", "diffSide": "RIGHT", "path": "test/framework/src/main/java/org/elasticsearch/cluster/ESAllocationTestCase.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNjo0ODozNFrOHc4GiQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxMTowNTowMVrOHdBFJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA0MTM1Mw==", "bodyText": "I find this name confusing, since this service has no shard sizes? Should it be ...WITH_NO_SHARD_SIZES?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500041353", "createdAt": "2020-10-06T06:48:34Z", "author": {"login": "henningandersen"}, "path": "test/framework/src/main/java/org/elasticsearch/cluster/ESAllocationTestCase.java", "diffHunk": "@@ -55,6 +59,16 @@\n     private static final ClusterSettings EMPTY_CLUSTER_SETTINGS =\n         new ClusterSettings(Settings.EMPTY, ClusterSettings.BUILT_IN_CLUSTER_SETTINGS);\n \n+    public static final SnapshotsInfoService SNAPSHOT_INFO_SERVICE_WITH_SHARD_SIZES = () ->", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDE4ODQ1Mw==", "bodyText": "Indeed -> 212c8e3", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500188453", "createdAt": "2020-10-06T11:05:01Z", "author": {"login": "tlrx"}, "path": "test/framework/src/main/java/org/elasticsearch/cluster/ESAllocationTestCase.java", "diffHunk": "@@ -55,6 +59,16 @@\n     private static final ClusterSettings EMPTY_CLUSTER_SETTINGS =\n         new ClusterSettings(Settings.EMPTY, ClusterSettings.BUILT_IN_CLUSTER_SETTINGS);\n \n+    public static final SnapshotsInfoService SNAPSHOT_INFO_SERVICE_WITH_SHARD_SIZES = () ->", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA0MTM1Mw=="}, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMDk1NTc0OnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/ccr/src/main/java/org/elasticsearch/xpack/ccr/repository/CcrRepository.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNjo1OTo1OFrOHc4bzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwNzozODo0NlrOHgZWNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA0Njc5OA==", "bodyText": "I think we are missing a test for this.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500046798", "createdAt": "2020-10-06T06:59:58Z", "author": {"login": "henningandersen"}, "path": "x-pack/plugin/ccr/src/main/java/org/elasticsearch/xpack/ccr/repository/CcrRepository.java", "diffHunk": "@@ -429,8 +433,23 @@ void acquireRetentionLeaseOnLeader(\n     }\n \n     @Override\n-    public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId leaderShardId) {\n-        throw new UnsupportedOperationException(\"Unsupported for repository of type: \" + TYPE);\n+    public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId index, ShardId shardId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzczMTc2NA==", "bodyText": "I opened #63590 for this.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r503731764", "createdAt": "2020-10-13T07:38:46Z", "author": {"login": "tlrx"}, "path": "x-pack/plugin/ccr/src/main/java/org/elasticsearch/xpack/ccr/repository/CcrRepository.java", "diffHunk": "@@ -429,8 +433,23 @@ void acquireRetentionLeaseOnLeader(\n     }\n \n     @Override\n-    public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId leaderShardId) {\n-        throw new UnsupportedOperationException(\"Unsupported for repository of type: \" + TYPE);\n+    public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId index, ShardId shardId) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA0Njc5OA=="}, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMDk2ODAwOnYy", "diffSide": "RIGHT", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ilm/AllocationRoutedStep.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNzowNDoxOFrOHc4jhw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxMTowNToyNFrOHdBGAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA0ODc3NQ==", "bodyText": "This change seems odd to me. I suppose the allocationDeciders are effectively unused, but in that case I would still prefer to pass down allocationDeciders.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500048775", "createdAt": "2020-10-06T07:04:18Z", "author": {"login": "henningandersen"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ilm/AllocationRoutedStep.java", "diffHunk": "@@ -70,8 +70,8 @@ public Result isConditionMet(Index index, ClusterState clusterState) {\n     static int getPendingAllocations(Index index, AllocationDeciders allocationDeciders, ClusterState clusterState) {\n         // All the allocation attributes are already set so just need to check\n         // if the allocation has happened\n-        RoutingAllocation allocation = new RoutingAllocation(allocationDeciders, clusterState.getRoutingNodes(), clusterState, null,\n-            System.nanoTime());\n+        RoutingAllocation allocation = new RoutingAllocation(ALLOCATION_DECIDERS, clusterState.getRoutingNodes(), clusterState, null,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDE4ODY3Mg==", "bodyText": "Thanks for catching this! It seems that git's merge algorithm did not report a conflict when I merged master back to this branch :(\nIt is fixed in 3dd593d", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500188672", "createdAt": "2020-10-06T11:05:24Z", "author": {"login": "tlrx"}, "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ilm/AllocationRoutedStep.java", "diffHunk": "@@ -70,8 +70,8 @@ public Result isConditionMet(Index index, ClusterState clusterState) {\n     static int getPendingAllocations(Index index, AllocationDeciders allocationDeciders, ClusterState clusterState) {\n         // All the allocation attributes are already set so just need to check\n         // if the allocation has happened\n-        RoutingAllocation allocation = new RoutingAllocation(allocationDeciders, clusterState.getRoutingNodes(), clusterState, null,\n-            System.nanoTime());\n+        RoutingAllocation allocation = new RoutingAllocation(ALLOCATION_DECIDERS, clusterState.getRoutingNodes(), clusterState, null,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA0ODc3NQ=="}, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMTAzNzc3OnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/snapshots/InternalSnapshotsInfoServiceTests.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNzoyNjo0MVrOHc5O9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxMTowNjoxOFrOHdBH0g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA1OTg5NA==", "bodyText": "I would think that assertBusy is unnecessary here, given that we wait for generic thread pool to be unused?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500059894", "createdAt": "2020-10-06T07:26:41Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/snapshots/InternalSnapshotsInfoServiceTests.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.node.DiscoveryNodes;\n+import org.elasticsearch.cluster.routing.IndexRoutingTable;\n+import org.elasticsearch.cluster.routing.IndexShardRoutingTable;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.RoutingTable;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.TestShardRouting;\n+import org.elasticsearch.cluster.service.ClusterApplier;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.FilterRepository;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.test.ClusterServiceUtils;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.threadpool.TestThreadPool;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.threadpool.ThreadPoolStats;\n+\n+import java.util.Collections;\n+import java.util.Locale;\n+import java.util.Set;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Function;\n+\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_CREATION_DATE;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_REPLICAS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_SHARDS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_VERSION_CREATED;\n+import static org.elasticsearch.snapshots.InternalSnapshotsInfoService.INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING;\n+import static org.hamcrest.Matchers.allOf;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.lessThan;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Matchers.anyString;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+public class InternalSnapshotsInfoServiceTests extends ESTestCase {\n+\n+    private TestThreadPool threadPool;\n+    private ClusterService clusterService;\n+    private RepositoriesService repositoriesService;\n+    private RerouteService rerouteService;\n+\n+    @Override\n+    public void setUp() throws Exception {\n+        super.setUp();\n+        threadPool = new TestThreadPool(getTestName());\n+        clusterService = ClusterServiceUtils.createClusterService(threadPool);\n+        repositoriesService = mock(RepositoriesService.class);\n+        rerouteService = mock(RerouteService.class);\n+        doAnswer(invocation -> {\n+            @SuppressWarnings(\"unchecked\")\n+            final ActionListener<ClusterState> listener = (ActionListener<ClusterState>) invocation.getArguments()[2];\n+            listener.onResponse(clusterService.state());\n+            return null;\n+        }).when(rerouteService).reroute(anyString(), any(Priority.class), any());\n+    }\n+\n+    @Override\n+    public void tearDown() throws Exception {\n+        super.tearDown();\n+        final boolean terminated = terminate(threadPool);\n+        assert terminated;\n+        clusterService.close();\n+    }\n+\n+    public void testSnapshotShardSizes() throws Exception {\n+        final int maxConcurrentFetches = randomIntBetween(1, 10);\n+        final InternalSnapshotsInfoService snapshotsInfoService =\n+            new InternalSnapshotsInfoService(Settings.builder()\n+                .put(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.getKey(), maxConcurrentFetches)\n+                .build(), clusterService, () -> repositoriesService, () -> rerouteService);\n+\n+        final int numberOfShards = randomIntBetween(1, 50);\n+        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final long[] expectedShardSizes = new long[numberOfShards];\n+        for (int i = 0; i < expectedShardSizes.length; i++) {\n+            expectedShardSizes[i] = randomNonNegativeLong();\n+        }\n+\n+        final CountDownLatch latch = new CountDownLatch(1);\n+        when(repositoriesService.repository(\"_repo\"))\n+            .thenReturn(new FilterRepository(mock(Repository.class)) {\n+                @Override\n+                public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId shardId) {\n+                    try {\n+                        assertThat(indexId.getName(), equalTo(indexName));\n+                        assertThat(shardId.id(), allOf(greaterThanOrEqualTo(0), lessThan(numberOfShards)));\n+                        latch.await();\n+                        return IndexShardSnapshotStatus.newDone(0L, 0L, 0, 0, 0L, expectedShardSizes[shardId.id()], null);\n+                    } catch (InterruptedException e) {\n+                        throw new AssertionError(e);\n+                    }\n+                }\n+            });\n+\n+        applyClusterState(\"add-unassigned-shards\", clusterState -> addUnassignedShards(clusterState, indexName, numberOfShards));\n+        waitForMaxActiveGenericThreads(Math.min(numberOfShards, maxConcurrentFetches));\n+\n+        assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(numberOfShards));\n+        assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(0));\n+\n+        latch.countDown();\n+        waitForMaxActiveGenericThreads(0);\n+\n+        assertBusy(() -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 154}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDE4OTEzOA==", "bodyText": "I'd expect something like this too but ThreadPoolExecutor#getActiveCount() returns an approximate numbers of active threads. It works well when active threads are blocked but waiting for 0 does not make much sense here. I removed waitForMaxActiveGenericThreads(0) to only rely on the assertBusy() (39da087)", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500189138", "createdAt": "2020-10-06T11:06:18Z", "author": {"login": "tlrx"}, "path": "server/src/test/java/org/elasticsearch/snapshots/InternalSnapshotsInfoServiceTests.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.node.DiscoveryNodes;\n+import org.elasticsearch.cluster.routing.IndexRoutingTable;\n+import org.elasticsearch.cluster.routing.IndexShardRoutingTable;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.RoutingTable;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.TestShardRouting;\n+import org.elasticsearch.cluster.service.ClusterApplier;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.FilterRepository;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.test.ClusterServiceUtils;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.threadpool.TestThreadPool;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.threadpool.ThreadPoolStats;\n+\n+import java.util.Collections;\n+import java.util.Locale;\n+import java.util.Set;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Function;\n+\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_CREATION_DATE;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_REPLICAS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_SHARDS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_VERSION_CREATED;\n+import static org.elasticsearch.snapshots.InternalSnapshotsInfoService.INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING;\n+import static org.hamcrest.Matchers.allOf;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.lessThan;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Matchers.anyString;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+public class InternalSnapshotsInfoServiceTests extends ESTestCase {\n+\n+    private TestThreadPool threadPool;\n+    private ClusterService clusterService;\n+    private RepositoriesService repositoriesService;\n+    private RerouteService rerouteService;\n+\n+    @Override\n+    public void setUp() throws Exception {\n+        super.setUp();\n+        threadPool = new TestThreadPool(getTestName());\n+        clusterService = ClusterServiceUtils.createClusterService(threadPool);\n+        repositoriesService = mock(RepositoriesService.class);\n+        rerouteService = mock(RerouteService.class);\n+        doAnswer(invocation -> {\n+            @SuppressWarnings(\"unchecked\")\n+            final ActionListener<ClusterState> listener = (ActionListener<ClusterState>) invocation.getArguments()[2];\n+            listener.onResponse(clusterService.state());\n+            return null;\n+        }).when(rerouteService).reroute(anyString(), any(Priority.class), any());\n+    }\n+\n+    @Override\n+    public void tearDown() throws Exception {\n+        super.tearDown();\n+        final boolean terminated = terminate(threadPool);\n+        assert terminated;\n+        clusterService.close();\n+    }\n+\n+    public void testSnapshotShardSizes() throws Exception {\n+        final int maxConcurrentFetches = randomIntBetween(1, 10);\n+        final InternalSnapshotsInfoService snapshotsInfoService =\n+            new InternalSnapshotsInfoService(Settings.builder()\n+                .put(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.getKey(), maxConcurrentFetches)\n+                .build(), clusterService, () -> repositoriesService, () -> rerouteService);\n+\n+        final int numberOfShards = randomIntBetween(1, 50);\n+        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final long[] expectedShardSizes = new long[numberOfShards];\n+        for (int i = 0; i < expectedShardSizes.length; i++) {\n+            expectedShardSizes[i] = randomNonNegativeLong();\n+        }\n+\n+        final CountDownLatch latch = new CountDownLatch(1);\n+        when(repositoriesService.repository(\"_repo\"))\n+            .thenReturn(new FilterRepository(mock(Repository.class)) {\n+                @Override\n+                public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId shardId) {\n+                    try {\n+                        assertThat(indexId.getName(), equalTo(indexName));\n+                        assertThat(shardId.id(), allOf(greaterThanOrEqualTo(0), lessThan(numberOfShards)));\n+                        latch.await();\n+                        return IndexShardSnapshotStatus.newDone(0L, 0L, 0, 0, 0L, expectedShardSizes[shardId.id()], null);\n+                    } catch (InterruptedException e) {\n+                        throw new AssertionError(e);\n+                    }\n+                }\n+            });\n+\n+        applyClusterState(\"add-unassigned-shards\", clusterState -> addUnassignedShards(clusterState, indexName, numberOfShards));\n+        waitForMaxActiveGenericThreads(Math.min(numberOfShards, maxConcurrentFetches));\n+\n+        assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(numberOfShards));\n+        assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(0));\n+\n+        latch.countDown();\n+        waitForMaxActiveGenericThreads(0);\n+\n+        assertBusy(() -> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA1OTg5NA=="}, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 154}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMTA3NTE3OnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/snapshots/InternalSnapshotsInfoServiceTests.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNzozNzowOVrOHc5l9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxMTowNjoyNlrOHdBIEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA2NTc4Mg==", "bodyText": "I think we risk these two assertions being OK if they run before any of the threads start adding anything? If that happens on most runs, the test does not verify anything.\nI wonder if it was good enough to just do this after the join below? Or keep it here but add it below the join too.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500065782", "createdAt": "2020-10-06T07:37:09Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/snapshots/InternalSnapshotsInfoServiceTests.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.node.DiscoveryNodes;\n+import org.elasticsearch.cluster.routing.IndexRoutingTable;\n+import org.elasticsearch.cluster.routing.IndexShardRoutingTable;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.RoutingTable;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.TestShardRouting;\n+import org.elasticsearch.cluster.service.ClusterApplier;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.FilterRepository;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.test.ClusterServiceUtils;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.threadpool.TestThreadPool;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.threadpool.ThreadPoolStats;\n+\n+import java.util.Collections;\n+import java.util.Locale;\n+import java.util.Set;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Function;\n+\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_CREATION_DATE;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_REPLICAS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_SHARDS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_VERSION_CREATED;\n+import static org.elasticsearch.snapshots.InternalSnapshotsInfoService.INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING;\n+import static org.hamcrest.Matchers.allOf;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.lessThan;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Matchers.anyString;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+public class InternalSnapshotsInfoServiceTests extends ESTestCase {\n+\n+    private TestThreadPool threadPool;\n+    private ClusterService clusterService;\n+    private RepositoriesService repositoriesService;\n+    private RerouteService rerouteService;\n+\n+    @Override\n+    public void setUp() throws Exception {\n+        super.setUp();\n+        threadPool = new TestThreadPool(getTestName());\n+        clusterService = ClusterServiceUtils.createClusterService(threadPool);\n+        repositoriesService = mock(RepositoriesService.class);\n+        rerouteService = mock(RerouteService.class);\n+        doAnswer(invocation -> {\n+            @SuppressWarnings(\"unchecked\")\n+            final ActionListener<ClusterState> listener = (ActionListener<ClusterState>) invocation.getArguments()[2];\n+            listener.onResponse(clusterService.state());\n+            return null;\n+        }).when(rerouteService).reroute(anyString(), any(Priority.class), any());\n+    }\n+\n+    @Override\n+    public void tearDown() throws Exception {\n+        super.tearDown();\n+        final boolean terminated = terminate(threadPool);\n+        assert terminated;\n+        clusterService.close();\n+    }\n+\n+    public void testSnapshotShardSizes() throws Exception {\n+        final int maxConcurrentFetches = randomIntBetween(1, 10);\n+        final InternalSnapshotsInfoService snapshotsInfoService =\n+            new InternalSnapshotsInfoService(Settings.builder()\n+                .put(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.getKey(), maxConcurrentFetches)\n+                .build(), clusterService, () -> repositoriesService, () -> rerouteService);\n+\n+        final int numberOfShards = randomIntBetween(1, 50);\n+        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final long[] expectedShardSizes = new long[numberOfShards];\n+        for (int i = 0; i < expectedShardSizes.length; i++) {\n+            expectedShardSizes[i] = randomNonNegativeLong();\n+        }\n+\n+        final CountDownLatch latch = new CountDownLatch(1);\n+        when(repositoriesService.repository(\"_repo\"))\n+            .thenReturn(new FilterRepository(mock(Repository.class)) {\n+                @Override\n+                public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId shardId) {\n+                    try {\n+                        assertThat(indexId.getName(), equalTo(indexName));\n+                        assertThat(shardId.id(), allOf(greaterThanOrEqualTo(0), lessThan(numberOfShards)));\n+                        latch.await();\n+                        return IndexShardSnapshotStatus.newDone(0L, 0L, 0, 0, 0L, expectedShardSizes[shardId.id()], null);\n+                    } catch (InterruptedException e) {\n+                        throw new AssertionError(e);\n+                    }\n+                }\n+            });\n+\n+        applyClusterState(\"add-unassigned-shards\", clusterState -> addUnassignedShards(clusterState, indexName, numberOfShards));\n+        waitForMaxActiveGenericThreads(Math.min(numberOfShards, maxConcurrentFetches));\n+\n+        assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(numberOfShards));\n+        assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(0));\n+\n+        latch.countDown();\n+        waitForMaxActiveGenericThreads(0);\n+\n+        assertBusy(() -> {\n+            assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(numberOfShards));\n+            assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(0));\n+        });\n+        verify(rerouteService, times(numberOfShards)).reroute(anyString(), any(Priority.class), any());\n+\n+        for (int i = 0; i < numberOfShards; i++) {\n+            final ShardRouting shardRouting = clusterService.state().routingTable().index(indexName).shard(i).primaryShard();\n+            assertThat(snapshotsInfoService.snapshotShardSizes().getShardSize(shardRouting), equalTo(expectedShardSizes[i]));\n+        }\n+    }\n+\n+    public void testErroneousSnapshotShardSizes() throws Exception {\n+        final InternalSnapshotsInfoService snapshotsInfoService =\n+            new InternalSnapshotsInfoService(Settings.builder()\n+                .put(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.getKey(), randomIntBetween(1, 10))\n+                .build(), clusterService, () -> repositoriesService, () -> rerouteService);\n+\n+        final Set<InternalSnapshotsInfoService.SnapshotShard> succeed = Sets.newConcurrentHashSet();\n+        final Set<InternalSnapshotsInfoService.SnapshotShard> failed = Sets.newConcurrentHashSet();\n+        when(repositoriesService.repository(\"_repo\"))\n+            .thenReturn(new FilterRepository(mock(Repository.class)) {\n+                @Override\n+                public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId shardId) {\n+                    final InternalSnapshotsInfoService.SnapshotShard snapshotShard =\n+                        new InternalSnapshotsInfoService.SnapshotShard(new Snapshot(\"_repo\", snapshotId), indexId, shardId);\n+                    if (randomBoolean()) {\n+                        failed.add(snapshotShard);\n+                        throw new SnapshotException(snapshotShard.snapshot(), \"simulated\");\n+                    } else {\n+                        succeed.add(snapshotShard);\n+                        return IndexShardSnapshotStatus.newDone(0L, 0L, 0, 0, 0L, randomNonNegativeLong(), null);\n+                    }\n+                }\n+            });\n+\n+        final int maxShardsToCreate = scaledRandomIntBetween(10, 500);\n+        final Thread addSnapshotRestoreIndicesThread = new Thread(() -> {\n+            int remainingShards = maxShardsToCreate;\n+            while (remainingShards > 0) {\n+                final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+                final int numberOfShards = randomIntBetween(1, maxShardsToCreate);\n+                try {\n+                    applyClusterState(\"add-more-unassigned-shards-for-\" + indexName,\n+                        clusterState -> addUnassignedShards(clusterState, indexName, numberOfShards));\n+                } catch (Exception e) {\n+                    throw new AssertionError(e);\n+                } finally {\n+                    remainingShards -= numberOfShards;\n+                }\n+            }\n+        });\n+        addSnapshotRestoreIndicesThread.start();\n+\n+        assertBusy(() -> {\n+            assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(succeed.size()));\n+            assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(0));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 210}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDE4OTIwMQ==", "bodyText": "You're right, not sure why I moved this before the join.\n\nI wonder if it was good enough to just do this after the join below?\n\nDone in 3732dd2.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500189201", "createdAt": "2020-10-06T11:06:26Z", "author": {"login": "tlrx"}, "path": "server/src/test/java/org/elasticsearch/snapshots/InternalSnapshotsInfoServiceTests.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.node.DiscoveryNodes;\n+import org.elasticsearch.cluster.routing.IndexRoutingTable;\n+import org.elasticsearch.cluster.routing.IndexShardRoutingTable;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.RoutingTable;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.TestShardRouting;\n+import org.elasticsearch.cluster.service.ClusterApplier;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.FilterRepository;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.test.ClusterServiceUtils;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.threadpool.TestThreadPool;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.threadpool.ThreadPoolStats;\n+\n+import java.util.Collections;\n+import java.util.Locale;\n+import java.util.Set;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Function;\n+\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_CREATION_DATE;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_REPLICAS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_SHARDS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_VERSION_CREATED;\n+import static org.elasticsearch.snapshots.InternalSnapshotsInfoService.INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING;\n+import static org.hamcrest.Matchers.allOf;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.lessThan;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Matchers.anyString;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+public class InternalSnapshotsInfoServiceTests extends ESTestCase {\n+\n+    private TestThreadPool threadPool;\n+    private ClusterService clusterService;\n+    private RepositoriesService repositoriesService;\n+    private RerouteService rerouteService;\n+\n+    @Override\n+    public void setUp() throws Exception {\n+        super.setUp();\n+        threadPool = new TestThreadPool(getTestName());\n+        clusterService = ClusterServiceUtils.createClusterService(threadPool);\n+        repositoriesService = mock(RepositoriesService.class);\n+        rerouteService = mock(RerouteService.class);\n+        doAnswer(invocation -> {\n+            @SuppressWarnings(\"unchecked\")\n+            final ActionListener<ClusterState> listener = (ActionListener<ClusterState>) invocation.getArguments()[2];\n+            listener.onResponse(clusterService.state());\n+            return null;\n+        }).when(rerouteService).reroute(anyString(), any(Priority.class), any());\n+    }\n+\n+    @Override\n+    public void tearDown() throws Exception {\n+        super.tearDown();\n+        final boolean terminated = terminate(threadPool);\n+        assert terminated;\n+        clusterService.close();\n+    }\n+\n+    public void testSnapshotShardSizes() throws Exception {\n+        final int maxConcurrentFetches = randomIntBetween(1, 10);\n+        final InternalSnapshotsInfoService snapshotsInfoService =\n+            new InternalSnapshotsInfoService(Settings.builder()\n+                .put(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.getKey(), maxConcurrentFetches)\n+                .build(), clusterService, () -> repositoriesService, () -> rerouteService);\n+\n+        final int numberOfShards = randomIntBetween(1, 50);\n+        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final long[] expectedShardSizes = new long[numberOfShards];\n+        for (int i = 0; i < expectedShardSizes.length; i++) {\n+            expectedShardSizes[i] = randomNonNegativeLong();\n+        }\n+\n+        final CountDownLatch latch = new CountDownLatch(1);\n+        when(repositoriesService.repository(\"_repo\"))\n+            .thenReturn(new FilterRepository(mock(Repository.class)) {\n+                @Override\n+                public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId shardId) {\n+                    try {\n+                        assertThat(indexId.getName(), equalTo(indexName));\n+                        assertThat(shardId.id(), allOf(greaterThanOrEqualTo(0), lessThan(numberOfShards)));\n+                        latch.await();\n+                        return IndexShardSnapshotStatus.newDone(0L, 0L, 0, 0, 0L, expectedShardSizes[shardId.id()], null);\n+                    } catch (InterruptedException e) {\n+                        throw new AssertionError(e);\n+                    }\n+                }\n+            });\n+\n+        applyClusterState(\"add-unassigned-shards\", clusterState -> addUnassignedShards(clusterState, indexName, numberOfShards));\n+        waitForMaxActiveGenericThreads(Math.min(numberOfShards, maxConcurrentFetches));\n+\n+        assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(numberOfShards));\n+        assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(0));\n+\n+        latch.countDown();\n+        waitForMaxActiveGenericThreads(0);\n+\n+        assertBusy(() -> {\n+            assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(numberOfShards));\n+            assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(0));\n+        });\n+        verify(rerouteService, times(numberOfShards)).reroute(anyString(), any(Priority.class), any());\n+\n+        for (int i = 0; i < numberOfShards; i++) {\n+            final ShardRouting shardRouting = clusterService.state().routingTable().index(indexName).shard(i).primaryShard();\n+            assertThat(snapshotsInfoService.snapshotShardSizes().getShardSize(shardRouting), equalTo(expectedShardSizes[i]));\n+        }\n+    }\n+\n+    public void testErroneousSnapshotShardSizes() throws Exception {\n+        final InternalSnapshotsInfoService snapshotsInfoService =\n+            new InternalSnapshotsInfoService(Settings.builder()\n+                .put(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.getKey(), randomIntBetween(1, 10))\n+                .build(), clusterService, () -> repositoriesService, () -> rerouteService);\n+\n+        final Set<InternalSnapshotsInfoService.SnapshotShard> succeed = Sets.newConcurrentHashSet();\n+        final Set<InternalSnapshotsInfoService.SnapshotShard> failed = Sets.newConcurrentHashSet();\n+        when(repositoriesService.repository(\"_repo\"))\n+            .thenReturn(new FilterRepository(mock(Repository.class)) {\n+                @Override\n+                public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId shardId) {\n+                    final InternalSnapshotsInfoService.SnapshotShard snapshotShard =\n+                        new InternalSnapshotsInfoService.SnapshotShard(new Snapshot(\"_repo\", snapshotId), indexId, shardId);\n+                    if (randomBoolean()) {\n+                        failed.add(snapshotShard);\n+                        throw new SnapshotException(snapshotShard.snapshot(), \"simulated\");\n+                    } else {\n+                        succeed.add(snapshotShard);\n+                        return IndexShardSnapshotStatus.newDone(0L, 0L, 0, 0, 0L, randomNonNegativeLong(), null);\n+                    }\n+                }\n+            });\n+\n+        final int maxShardsToCreate = scaledRandomIntBetween(10, 500);\n+        final Thread addSnapshotRestoreIndicesThread = new Thread(() -> {\n+            int remainingShards = maxShardsToCreate;\n+            while (remainingShards > 0) {\n+                final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+                final int numberOfShards = randomIntBetween(1, maxShardsToCreate);\n+                try {\n+                    applyClusterState(\"add-more-unassigned-shards-for-\" + indexName,\n+                        clusterState -> addUnassignedShards(clusterState, indexName, numberOfShards));\n+                } catch (Exception e) {\n+                    throw new AssertionError(e);\n+                } finally {\n+                    remainingShards -= numberOfShards;\n+                }\n+            }\n+        });\n+        addSnapshotRestoreIndicesThread.start();\n+\n+        assertBusy(() -> {\n+            assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(succeed.size()));\n+            assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(0));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA2NTc4Mg=="}, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 210}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMTEwMTI4OnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/snapshots/InternalSnapshotsInfoServiceTests.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNzo0NDoyOVrOHc52dg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxMTowNjozOVrOHdBIfg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA3MDAwNg==", "bodyText": "I suppose this is somewhat verified by the reroute count check below, but I would like to add a counter for how many times getShardSnapshotStatus was called too and verify that it is correct.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500070006", "createdAt": "2020-10-06T07:44:29Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/snapshots/InternalSnapshotsInfoServiceTests.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.node.DiscoveryNodes;\n+import org.elasticsearch.cluster.routing.IndexRoutingTable;\n+import org.elasticsearch.cluster.routing.IndexShardRoutingTable;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.RoutingTable;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.TestShardRouting;\n+import org.elasticsearch.cluster.service.ClusterApplier;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.FilterRepository;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.test.ClusterServiceUtils;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.threadpool.TestThreadPool;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.threadpool.ThreadPoolStats;\n+\n+import java.util.Collections;\n+import java.util.Locale;\n+import java.util.Set;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Function;\n+\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_CREATION_DATE;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_REPLICAS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_SHARDS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_VERSION_CREATED;\n+import static org.elasticsearch.snapshots.InternalSnapshotsInfoService.INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING;\n+import static org.hamcrest.Matchers.allOf;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.lessThan;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Matchers.anyString;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+public class InternalSnapshotsInfoServiceTests extends ESTestCase {\n+\n+    private TestThreadPool threadPool;\n+    private ClusterService clusterService;\n+    private RepositoriesService repositoriesService;\n+    private RerouteService rerouteService;\n+\n+    @Override\n+    public void setUp() throws Exception {\n+        super.setUp();\n+        threadPool = new TestThreadPool(getTestName());\n+        clusterService = ClusterServiceUtils.createClusterService(threadPool);\n+        repositoriesService = mock(RepositoriesService.class);\n+        rerouteService = mock(RerouteService.class);\n+        doAnswer(invocation -> {\n+            @SuppressWarnings(\"unchecked\")\n+            final ActionListener<ClusterState> listener = (ActionListener<ClusterState>) invocation.getArguments()[2];\n+            listener.onResponse(clusterService.state());\n+            return null;\n+        }).when(rerouteService).reroute(anyString(), any(Priority.class), any());\n+    }\n+\n+    @Override\n+    public void tearDown() throws Exception {\n+        super.tearDown();\n+        final boolean terminated = terminate(threadPool);\n+        assert terminated;\n+        clusterService.close();\n+    }\n+\n+    public void testSnapshotShardSizes() throws Exception {\n+        final int maxConcurrentFetches = randomIntBetween(1, 10);\n+        final InternalSnapshotsInfoService snapshotsInfoService =\n+            new InternalSnapshotsInfoService(Settings.builder()\n+                .put(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.getKey(), maxConcurrentFetches)\n+                .build(), clusterService, () -> repositoriesService, () -> rerouteService);\n+\n+        final int numberOfShards = randomIntBetween(1, 50);\n+        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final long[] expectedShardSizes = new long[numberOfShards];\n+        for (int i = 0; i < expectedShardSizes.length; i++) {\n+            expectedShardSizes[i] = randomNonNegativeLong();\n+        }\n+\n+        final CountDownLatch latch = new CountDownLatch(1);\n+        when(repositoriesService.repository(\"_repo\"))\n+            .thenReturn(new FilterRepository(mock(Repository.class)) {\n+                @Override\n+                public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId shardId) {\n+                    try {\n+                        assertThat(indexId.getName(), equalTo(indexName));\n+                        assertThat(shardId.id(), allOf(greaterThanOrEqualTo(0), lessThan(numberOfShards)));\n+                        latch.await();\n+                        return IndexShardSnapshotStatus.newDone(0L, 0L, 0, 0, 0L, expectedShardSizes[shardId.id()], null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDE4OTMxMA==", "bodyText": "Makes sense, added in ac45f17", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500189310", "createdAt": "2020-10-06T11:06:39Z", "author": {"login": "tlrx"}, "path": "server/src/test/java/org/elasticsearch/snapshots/InternalSnapshotsInfoServiceTests.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.node.DiscoveryNodes;\n+import org.elasticsearch.cluster.routing.IndexRoutingTable;\n+import org.elasticsearch.cluster.routing.IndexShardRoutingTable;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.RoutingTable;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.TestShardRouting;\n+import org.elasticsearch.cluster.service.ClusterApplier;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.FilterRepository;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.test.ClusterServiceUtils;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.threadpool.TestThreadPool;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.threadpool.ThreadPoolStats;\n+\n+import java.util.Collections;\n+import java.util.Locale;\n+import java.util.Set;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Function;\n+\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_CREATION_DATE;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_REPLICAS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_SHARDS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_VERSION_CREATED;\n+import static org.elasticsearch.snapshots.InternalSnapshotsInfoService.INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING;\n+import static org.hamcrest.Matchers.allOf;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.lessThan;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Matchers.anyString;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+public class InternalSnapshotsInfoServiceTests extends ESTestCase {\n+\n+    private TestThreadPool threadPool;\n+    private ClusterService clusterService;\n+    private RepositoriesService repositoriesService;\n+    private RerouteService rerouteService;\n+\n+    @Override\n+    public void setUp() throws Exception {\n+        super.setUp();\n+        threadPool = new TestThreadPool(getTestName());\n+        clusterService = ClusterServiceUtils.createClusterService(threadPool);\n+        repositoriesService = mock(RepositoriesService.class);\n+        rerouteService = mock(RerouteService.class);\n+        doAnswer(invocation -> {\n+            @SuppressWarnings(\"unchecked\")\n+            final ActionListener<ClusterState> listener = (ActionListener<ClusterState>) invocation.getArguments()[2];\n+            listener.onResponse(clusterService.state());\n+            return null;\n+        }).when(rerouteService).reroute(anyString(), any(Priority.class), any());\n+    }\n+\n+    @Override\n+    public void tearDown() throws Exception {\n+        super.tearDown();\n+        final boolean terminated = terminate(threadPool);\n+        assert terminated;\n+        clusterService.close();\n+    }\n+\n+    public void testSnapshotShardSizes() throws Exception {\n+        final int maxConcurrentFetches = randomIntBetween(1, 10);\n+        final InternalSnapshotsInfoService snapshotsInfoService =\n+            new InternalSnapshotsInfoService(Settings.builder()\n+                .put(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.getKey(), maxConcurrentFetches)\n+                .build(), clusterService, () -> repositoriesService, () -> rerouteService);\n+\n+        final int numberOfShards = randomIntBetween(1, 50);\n+        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final long[] expectedShardSizes = new long[numberOfShards];\n+        for (int i = 0; i < expectedShardSizes.length; i++) {\n+            expectedShardSizes[i] = randomNonNegativeLong();\n+        }\n+\n+        final CountDownLatch latch = new CountDownLatch(1);\n+        when(repositoriesService.repository(\"_repo\"))\n+            .thenReturn(new FilterRepository(mock(Repository.class)) {\n+                @Override\n+                public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId shardId) {\n+                    try {\n+                        assertThat(indexId.getName(), equalTo(indexName));\n+                        assertThat(shardId.id(), allOf(greaterThanOrEqualTo(0), lessThan(numberOfShards)));\n+                        latch.await();\n+                        return IndexShardSnapshotStatus.newDone(0L, 0L, 0, 0, 0L, expectedShardSizes[shardId.id()], null);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA3MDAwNg=="}, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 138}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMTExNzY0OnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/snapshots/InternalSnapshotsInfoServiceTests.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwNzo0ODo1OVrOHc6Abg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxMTowNzowNVrOHdBJWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA3MjU1OA==", "bodyText": "Can we add more shards (or just one) here to verify that the deduplication works? We can verify that there is nothing on the queue and at the end that we get the right amount of repo calls.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500072558", "createdAt": "2020-10-06T07:48:59Z", "author": {"login": "henningandersen"}, "path": "server/src/test/java/org/elasticsearch/snapshots/InternalSnapshotsInfoServiceTests.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.node.DiscoveryNodes;\n+import org.elasticsearch.cluster.routing.IndexRoutingTable;\n+import org.elasticsearch.cluster.routing.IndexShardRoutingTable;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.RoutingTable;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.TestShardRouting;\n+import org.elasticsearch.cluster.service.ClusterApplier;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.FilterRepository;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.test.ClusterServiceUtils;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.threadpool.TestThreadPool;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.threadpool.ThreadPoolStats;\n+\n+import java.util.Collections;\n+import java.util.Locale;\n+import java.util.Set;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Function;\n+\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_CREATION_DATE;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_REPLICAS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_SHARDS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_VERSION_CREATED;\n+import static org.elasticsearch.snapshots.InternalSnapshotsInfoService.INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING;\n+import static org.hamcrest.Matchers.allOf;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.lessThan;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Matchers.anyString;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+public class InternalSnapshotsInfoServiceTests extends ESTestCase {\n+\n+    private TestThreadPool threadPool;\n+    private ClusterService clusterService;\n+    private RepositoriesService repositoriesService;\n+    private RerouteService rerouteService;\n+\n+    @Override\n+    public void setUp() throws Exception {\n+        super.setUp();\n+        threadPool = new TestThreadPool(getTestName());\n+        clusterService = ClusterServiceUtils.createClusterService(threadPool);\n+        repositoriesService = mock(RepositoriesService.class);\n+        rerouteService = mock(RerouteService.class);\n+        doAnswer(invocation -> {\n+            @SuppressWarnings(\"unchecked\")\n+            final ActionListener<ClusterState> listener = (ActionListener<ClusterState>) invocation.getArguments()[2];\n+            listener.onResponse(clusterService.state());\n+            return null;\n+        }).when(rerouteService).reroute(anyString(), any(Priority.class), any());\n+    }\n+\n+    @Override\n+    public void tearDown() throws Exception {\n+        super.tearDown();\n+        final boolean terminated = terminate(threadPool);\n+        assert terminated;\n+        clusterService.close();\n+    }\n+\n+    public void testSnapshotShardSizes() throws Exception {\n+        final int maxConcurrentFetches = randomIntBetween(1, 10);\n+        final InternalSnapshotsInfoService snapshotsInfoService =\n+            new InternalSnapshotsInfoService(Settings.builder()\n+                .put(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.getKey(), maxConcurrentFetches)\n+                .build(), clusterService, () -> repositoriesService, () -> rerouteService);\n+\n+        final int numberOfShards = randomIntBetween(1, 50);\n+        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final long[] expectedShardSizes = new long[numberOfShards];\n+        for (int i = 0; i < expectedShardSizes.length; i++) {\n+            expectedShardSizes[i] = randomNonNegativeLong();\n+        }\n+\n+        final CountDownLatch latch = new CountDownLatch(1);\n+        when(repositoriesService.repository(\"_repo\"))\n+            .thenReturn(new FilterRepository(mock(Repository.class)) {\n+                @Override\n+                public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId shardId) {\n+                    try {\n+                        assertThat(indexId.getName(), equalTo(indexName));\n+                        assertThat(shardId.id(), allOf(greaterThanOrEqualTo(0), lessThan(numberOfShards)));\n+                        latch.await();\n+                        return IndexShardSnapshotStatus.newDone(0L, 0L, 0, 0, 0L, expectedShardSizes[shardId.id()], null);\n+                    } catch (InterruptedException e) {\n+                        throw new AssertionError(e);\n+                    }\n+                }\n+            });\n+\n+        applyClusterState(\"add-unassigned-shards\", clusterState -> addUnassignedShards(clusterState, indexName, numberOfShards));\n+        waitForMaxActiveGenericThreads(Math.min(numberOfShards, maxConcurrentFetches));\n+\n+        assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(numberOfShards));\n+        assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(0));\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDE4OTUyOQ==", "bodyText": "I added 465c8fb that reapplies the last cluster state which should be enough I think\n(as the test verifies that there are no more unknown shard sizes and that the snapshot shard size have been fetched the right number of time).", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500189529", "createdAt": "2020-10-06T11:07:05Z", "author": {"login": "tlrx"}, "path": "server/src/test/java/org/elasticsearch/snapshots/InternalSnapshotsInfoServiceTests.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.node.DiscoveryNodes;\n+import org.elasticsearch.cluster.routing.IndexRoutingTable;\n+import org.elasticsearch.cluster.routing.IndexShardRoutingTable;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.RoutingTable;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.TestShardRouting;\n+import org.elasticsearch.cluster.service.ClusterApplier;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;\n+import org.elasticsearch.repositories.FilterRepository;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.test.ClusterServiceUtils;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.threadpool.TestThreadPool;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.threadpool.ThreadPoolStats;\n+\n+import java.util.Collections;\n+import java.util.Locale;\n+import java.util.Set;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Function;\n+\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_CREATION_DATE;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_REPLICAS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_SHARDS;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_VERSION_CREATED;\n+import static org.elasticsearch.snapshots.InternalSnapshotsInfoService.INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING;\n+import static org.hamcrest.Matchers.allOf;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.lessThan;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Matchers.anyString;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+public class InternalSnapshotsInfoServiceTests extends ESTestCase {\n+\n+    private TestThreadPool threadPool;\n+    private ClusterService clusterService;\n+    private RepositoriesService repositoriesService;\n+    private RerouteService rerouteService;\n+\n+    @Override\n+    public void setUp() throws Exception {\n+        super.setUp();\n+        threadPool = new TestThreadPool(getTestName());\n+        clusterService = ClusterServiceUtils.createClusterService(threadPool);\n+        repositoriesService = mock(RepositoriesService.class);\n+        rerouteService = mock(RerouteService.class);\n+        doAnswer(invocation -> {\n+            @SuppressWarnings(\"unchecked\")\n+            final ActionListener<ClusterState> listener = (ActionListener<ClusterState>) invocation.getArguments()[2];\n+            listener.onResponse(clusterService.state());\n+            return null;\n+        }).when(rerouteService).reroute(anyString(), any(Priority.class), any());\n+    }\n+\n+    @Override\n+    public void tearDown() throws Exception {\n+        super.tearDown();\n+        final boolean terminated = terminate(threadPool);\n+        assert terminated;\n+        clusterService.close();\n+    }\n+\n+    public void testSnapshotShardSizes() throws Exception {\n+        final int maxConcurrentFetches = randomIntBetween(1, 10);\n+        final InternalSnapshotsInfoService snapshotsInfoService =\n+            new InternalSnapshotsInfoService(Settings.builder()\n+                .put(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.getKey(), maxConcurrentFetches)\n+                .build(), clusterService, () -> repositoriesService, () -> rerouteService);\n+\n+        final int numberOfShards = randomIntBetween(1, 50);\n+        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final long[] expectedShardSizes = new long[numberOfShards];\n+        for (int i = 0; i < expectedShardSizes.length; i++) {\n+            expectedShardSizes[i] = randomNonNegativeLong();\n+        }\n+\n+        final CountDownLatch latch = new CountDownLatch(1);\n+        when(repositoriesService.repository(\"_repo\"))\n+            .thenReturn(new FilterRepository(mock(Repository.class)) {\n+                @Override\n+                public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, IndexId indexId, ShardId shardId) {\n+                    try {\n+                        assertThat(indexId.getName(), equalTo(indexName));\n+                        assertThat(shardId.id(), allOf(greaterThanOrEqualTo(0), lessThan(numberOfShards)));\n+                        latch.await();\n+                        return IndexShardSnapshotStatus.newDone(0L, 0L, 0, 0, 0L, expectedShardSizes[shardId.id()], null);\n+                    } catch (InterruptedException e) {\n+                        throw new AssertionError(e);\n+                    }\n+                }\n+            });\n+\n+        applyClusterState(\"add-unassigned-shards\", clusterState -> addUnassignedShards(clusterState, indexName, numberOfShards));\n+        waitForMaxActiveGenericThreads(Math.min(numberOfShards, maxConcurrentFetches));\n+\n+        assertThat(snapshotsInfoService.numberOfUnknownSnapshotShardSizes(), equalTo(numberOfShards));\n+        assertThat(snapshotsInfoService.numberOfKnownSnapshotShardSizes(), equalTo(0));\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDA3MjU1OA=="}, "originalCommit": {"oid": "291831f02ced1131a8aecb2104f6ca89853ae69b"}, "originalPosition": 150}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMjExOTYwOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxMjoyMzoyNlrOHdDtJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxMjoyMzoyNlrOHdDtJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDIzMTQ2MQ==", "bodyText": "I think this needs to be done before spawning the task: we assert that this is \u22650 elsewhere but that assertion will fail if it's decremented by the completion of the runnable before it's incremented here.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500231461", "createdAt": "2020-10-06T12:23:26Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,342 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.LinkedList;\n+import java.util.Objects;\n+import java.util.Queue;\n+import java.util.Set;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private static final ActionListener<ClusterState> REROUTE_LISTENER = ActionListener.wrap(\n+        r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+        e -> logger.debug(\"reroute after snapshot shard size update failed\", e)\n+    );\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final Queue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private int activeFetches;\n+\n+    private final Object mutex;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = new LinkedHashSet<>();\n+        this.queue = new LinkedList<>();\n+        this.mutex = new Object();\n+        this.activeFetches = 0;\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = listOfSnapshotShards(event.state());\n+\n+            int unknownShards = 0;\n+            synchronized (mutex) {\n+                isMaster = true;\n+                for (SnapshotShard snapshotShard : onGoingSnapshotRecoveries) {\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+                // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+                cleanUpKnownSnapshotShardSizes(onGoingSnapshotRecoveries);\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                fetchNextSnapshotShard();\n+            }\n+        } else if (event.previousState().nodes().isLocalNodeElectedMaster()) {\n+            // TODO Maybe just clear out non-ongoing snapshot recoveries is the node is master eligible, so that we don't\n+            // have to repopulate the data over and over in an unstable master situation?\n+            synchronized (mutex) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+                final Iterator<SnapshotShard> iterator = queue.iterator();\n+                while (iterator.hasNext()) {\n+                    final SnapshotShard snapshotShard = iterator.next();\n+                    final boolean removed = unknownSnapshotShards.remove(snapshotShard);\n+                    assert removed : \"snapshot shard to remove does not exist \" + snapshotShard;\n+                    iterator.remove();\n+                }\n+            }\n+        }\n+    }\n+\n+    private void fetchNextSnapshotShard() {\n+        synchronized (mutex) {\n+            if (activeFetches < maxConcurrentFetches) {\n+                final SnapshotShard snapshotShard = queue.poll();\n+                if (snapshotShard != null) {\n+                    threadPool.generic().execute(new FetchingSnapshotShardSizeRunnable(snapshotShard));\n+                    activeFetches += 1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "59ab20c3c3a450f4233753c131d62938bc602daa"}, "originalPosition": 172}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMjE0OTM0OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxMjozMDozMlrOHdD-vw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxMjozMDozMlrOHdD-vw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDIzNTk2Nw==", "bodyText": "Why not drain the queue using .poll() until it's empty?", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500235967", "createdAt": "2020-10-06T12:30:32Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,342 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.LinkedList;\n+import java.util.Objects;\n+import java.util.Queue;\n+import java.util.Set;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private static final ActionListener<ClusterState> REROUTE_LISTENER = ActionListener.wrap(\n+        r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+        e -> logger.debug(\"reroute after snapshot shard size update failed\", e)\n+    );\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final Queue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private int activeFetches;\n+\n+    private final Object mutex;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = new LinkedHashSet<>();\n+        this.queue = new LinkedList<>();\n+        this.mutex = new Object();\n+        this.activeFetches = 0;\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = listOfSnapshotShards(event.state());\n+\n+            int unknownShards = 0;\n+            synchronized (mutex) {\n+                isMaster = true;\n+                for (SnapshotShard snapshotShard : onGoingSnapshotRecoveries) {\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+                // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+                cleanUpKnownSnapshotShardSizes(onGoingSnapshotRecoveries);\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                fetchNextSnapshotShard();\n+            }\n+        } else if (event.previousState().nodes().isLocalNodeElectedMaster()) {\n+            // TODO Maybe just clear out non-ongoing snapshot recoveries is the node is master eligible, so that we don't\n+            // have to repopulate the data over and over in an unstable master situation?\n+            synchronized (mutex) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+                final Iterator<SnapshotShard> iterator = queue.iterator();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "59ab20c3c3a450f4233753c131d62938bc602daa"}, "originalPosition": 155}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMjE2ODU2OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxMjozNToxN1rOHdEKNQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxMjozNToxN1rOHdEKNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDIzODkwMQ==", "bodyText": "can we assert something about the state if neither of the previous if blocks matched (so this node isn't/wasn't just the master): isMaster == false, queue and unknownSnapshotShards and knownSnapshotShardSizes are all empty, ...", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500238901", "createdAt": "2020-10-06T12:35:17Z", "author": {"login": "DaveCTurner"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -0,0 +1,342 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.snapshots;\n+\n+import com.carrotsearch.hppc.cursors.ObjectCursor;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.cluster.ClusterChangedEvent;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.ClusterStateListener;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.RecoverySource;\n+import org.elasticsearch.cluster.routing.RerouteService;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.collect.ImmutableOpenMap;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.LinkedList;\n+import java.util.Objects;\n+import java.util.Queue;\n+import java.util.Set;\n+import java.util.function.Supplier;\n+\n+public class InternalSnapshotsInfoService implements ClusterStateListener, SnapshotsInfoService {\n+\n+    public static final Setting<Integer> INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING =\n+        Setting.intSetting(\"cluster.snapshot.info.max_concurrent_fetches\", 5, 1,\n+            Setting.Property.Dynamic, Setting.Property.NodeScope);\n+\n+    private static final Logger logger = LogManager.getLogger(InternalSnapshotsInfoService.class);\n+\n+    private static final ActionListener<ClusterState> REROUTE_LISTENER = ActionListener.wrap(\n+        r -> logger.trace(\"reroute after snapshot shard size update completed\"),\n+        e -> logger.debug(\"reroute after snapshot shard size update failed\", e)\n+    );\n+\n+    private final ThreadPool threadPool;\n+    private final Supplier<RepositoriesService> repositoriesService;\n+    private final Supplier<RerouteService> rerouteService;\n+\n+    /** contains the snapshot shards for which the size is known **/\n+    private volatile ImmutableOpenMap<SnapshotShard, Long> knownSnapshotShardSizes;\n+\n+    private volatile boolean isMaster;\n+\n+    /** contains the snapshot shards for which the size is unknown and must be fetched (or is being fetched) **/\n+    private final Set<SnapshotShard> unknownSnapshotShards;\n+\n+    /** a blocking queue used for concurrent fetching **/\n+    private final Queue<SnapshotShard> queue;\n+\n+    private volatile int maxConcurrentFetches;\n+    private int activeFetches;\n+\n+    private final Object mutex;\n+\n+    public InternalSnapshotsInfoService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final Supplier<RepositoriesService> repositoriesServiceSupplier,\n+        final Supplier<RerouteService> rerouteServiceSupplier\n+    ) {\n+        this.threadPool = clusterService.getClusterApplierService().threadPool();\n+        this.repositoriesService = repositoriesServiceSupplier;\n+        this.rerouteService = rerouteServiceSupplier;\n+        this.knownSnapshotShardSizes = ImmutableOpenMap.of();\n+        this.unknownSnapshotShards  = new LinkedHashSet<>();\n+        this.queue = new LinkedList<>();\n+        this.mutex = new Object();\n+        this.activeFetches = 0;\n+        this.maxConcurrentFetches = INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING.get(settings);\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        clusterSettings.addSettingsUpdateConsumer(INTERNAL_SNAPSHOT_INFO_MAX_CONCURRENT_FETCHES_SETTING, this::setMaxConcurrentFetches);\n+        if (DiscoveryNode.isMasterNode(settings)) {\n+            clusterService.addListener(this);\n+        }\n+    }\n+\n+    private void setMaxConcurrentFetches(Integer maxConcurrentFetches) {\n+        this.maxConcurrentFetches = maxConcurrentFetches;\n+    }\n+\n+    @Override\n+    public SnapshotShardSizeInfo snapshotShardSizes() {\n+        return new SnapshotShardSizeInfo(knownSnapshotShardSizes);\n+    }\n+\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        if (event.localNodeMaster()) {\n+            final Set<SnapshotShard> onGoingSnapshotRecoveries = listOfSnapshotShards(event.state());\n+\n+            int unknownShards = 0;\n+            synchronized (mutex) {\n+                isMaster = true;\n+                for (SnapshotShard snapshotShard : onGoingSnapshotRecoveries) {\n+                    // check if already populated entry\n+                    if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n+                        // check if already fetching snapshot info in progress\n+                        if (unknownSnapshotShards.add(snapshotShard)) {\n+                            queue.add(snapshotShard);\n+                            unknownShards += 1;\n+                        }\n+                    }\n+                }\n+                // Clean up keys from knownSnapshotShardSizes that are no longer needed for recoveries\n+                cleanUpKnownSnapshotShardSizes(onGoingSnapshotRecoveries);\n+            }\n+\n+            final int nbFetchers = Math.min(unknownShards, maxConcurrentFetches);\n+            for (int i = 0; i < nbFetchers; i++) {\n+                fetchNextSnapshotShard();\n+            }\n+        } else if (event.previousState().nodes().isLocalNodeElectedMaster()) {\n+            // TODO Maybe just clear out non-ongoing snapshot recoveries is the node is master eligible, so that we don't\n+            // have to repopulate the data over and over in an unstable master situation?\n+            synchronized (mutex) {\n+                // information only needed on current master\n+                knownSnapshotShardSizes = ImmutableOpenMap.of();\n+                isMaster = false;\n+                final Iterator<SnapshotShard> iterator = queue.iterator();\n+                while (iterator.hasNext()) {\n+                    final SnapshotShard snapshotShard = iterator.next();\n+                    final boolean removed = unknownSnapshotShards.remove(snapshotShard);\n+                    assert removed : \"snapshot shard to remove does not exist \" + snapshotShard;\n+                    iterator.remove();\n+                }\n+            }\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "59ab20c3c3a450f4233753c131d62938bc602daa"}, "originalPosition": 163}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMzA1Njg5OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxNToxNzo0M1rOHdMx7Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxNDoyNTowMFrOHehOGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDM4MDE0MQ==", "bodyText": "I think we should also remove this in cleanUpKnownSnapshotShardSizes to avoid this eventually potentially leading to a memory issue. We can do this in a follow-up too, no need to hold merging this PR.", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r500380141", "createdAt": "2020-10-06T15:17:43Z", "author": {"login": "henningandersen"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -132,6 +142,7 @@ public void clusterChanged(ClusterChangedEvent event) {\n                     if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n                         // check if already fetching snapshot info in progress\n                         if (unknownSnapshotShards.add(snapshotShard)) {\n+                            failedSnapshotShards.remove(snapshotShard); // retry the failed shard", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d9917489f22a731cd69ba33311dca9e9134aee1"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTc2MzYxMA==", "bodyText": "I opened #63492 to address this", "url": "https://github.com/elastic/elasticsearch/pull/61906#discussion_r501763610", "createdAt": "2020-10-08T14:25:00Z", "author": {"login": "tlrx"}, "path": "server/src/main/java/org/elasticsearch/snapshots/InternalSnapshotsInfoService.java", "diffHunk": "@@ -132,6 +142,7 @@ public void clusterChanged(ClusterChangedEvent event) {\n                     if (knownSnapshotShardSizes.containsKey(snapshotShard) == false) {\n                         // check if already fetching snapshot info in progress\n                         if (unknownSnapshotShards.add(snapshotShard)) {\n+                            failedSnapshotShards.remove(snapshotShard); // retry the failed shard", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDM4MDE0MQ=="}, "originalCommit": {"oid": "0d9917489f22a731cd69ba33311dca9e9134aee1"}, "originalPosition": 46}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1697, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}