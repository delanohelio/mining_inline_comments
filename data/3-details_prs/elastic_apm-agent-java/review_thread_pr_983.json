{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzU5OTY3NDMz", "number": 983, "reviewThreads": {"totalCount": 43, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQwNDowMzo0MFrODXujgQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQxNjo1NzoyMVrODf9J0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MjA2NTkzOnYy", "diffSide": "RIGHT", "path": "apm-agent-benchmarks/src/main/java/co/elastic/apm/agent/benchmark/AbstractMockApmServerBenchmark.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQwNDowMzo0MFrOFdLqLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQwOTozMTowNlrOFeTBmQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE0NDA0NQ==", "bodyText": "Leftovers?", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366144045", "createdAt": "2020-01-14T04:03:40Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-benchmarks/src/main/java/co/elastic/apm/agent/benchmark/AbstractMockApmServerBenchmark.java", "diffHunk": "@@ -85,6 +85,8 @@ public void setUp(Blackhole blackhole) throws IOException {\n                     .add(CoreConfiguration.ACTIVE, Boolean.toString(apmEnabled))\n                     .add(\"api_request_size\", \"10mb\")\n                     .add(\"capture_headers\", \"false\")\n+//                     .add(\"profiling_inferred_spans\", \"true\")\n+//                     .add(\"profiling_interval\", \"10s\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzMxMzMwNQ==", "bodyText": "Maybe leave it in so it's easy to do ad-hoc benchmarks with the profiler on. But as it's off by default I wouldn't include it in the actual benchmarking suite.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367313305", "createdAt": "2020-01-16T09:31:06Z", "author": {"login": "felixbarny"}, "path": "apm-agent-benchmarks/src/main/java/co/elastic/apm/agent/benchmark/AbstractMockApmServerBenchmark.java", "diffHunk": "@@ -85,6 +85,8 @@ public void setUp(Blackhole blackhole) throws IOException {\n                     .add(CoreConfiguration.ACTIVE, Boolean.toString(apmEnabled))\n                     .add(\"api_request_size\", \"10mb\")\n                     .add(\"capture_headers\", \"false\")\n+//                     .add(\"profiling_inferred_spans\", \"true\")\n+//                     .add(\"profiling_interval\", \"10s\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE0NDA0NQ=="}, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MjA4MzU2OnYy", "diffSide": "RIGHT", "path": "apm-agent-core/src/main/java/co/elastic/apm/agent/impl/transaction/TraceContext.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQwNDoyMToyNlrOFdL0vQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQwNDoyMToyNlrOFdL0vQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE0Njc0OQ==", "bodyText": "Extract, together with getLong, into a util class in the utils package.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366146749", "createdAt": "2020-01-14T04:21:26Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-core/src/main/java/co/elastic/apm/agent/impl/transaction/TraceContext.java", "diffHunk": "@@ -439,10 +467,81 @@ public ClassLoader getApplicationClassLoader() {\n         }\n     }\n \n+    public byte[] serialize() {\n+        byte[] result = new byte[SERIALIZED_LENGTH];\n+        serialize(result);\n+        return result;\n+    }\n+\n+    public void serialize(byte[] buffer) {\n+        int offset = 0;\n+        offset = traceId.toBytes(buffer, offset);\n+        offset = id.toBytes(buffer, offset);\n+        offset = transactionId.toBytes(buffer, offset);\n+        buffer[offset++] = flags;\n+        buffer[offset++] = (byte) (discard ? 1 : 0);\n+        putLong(buffer, offset, clock.getOffset());\n+    }\n+\n+    private void asChildOf(byte[] buffer, @Nullable String serviceName) {\n+        int offset = 0;\n+        offset = traceId.fromBytes(buffer, offset);\n+        offset = parentId.fromBytes(buffer, offset);\n+        offset = transactionId.fromBytes(buffer, offset);\n+        id.setToRandomValue();\n+        flags = buffer[offset++];\n+        discard = buffer[offset++] == (byte) 1;\n+        clock.init(getLong(buffer, offset));\n+        this.serviceName = serviceName;\n+        onMutation();\n+    }\n+\n+    public void deserialize(byte[] buffer, @Nullable String serviceName) {\n+        int offset = 0;\n+        offset = traceId.fromBytes(buffer, offset);\n+        offset = id.fromBytes(buffer, offset);\n+        offset = transactionId.fromBytes(buffer, offset);\n+        flags = buffer[offset++];\n+        discard = buffer[offset++] == (byte) 1;\n+        clock.init(getLong(buffer, offset));\n+        this.serviceName = serviceName;\n+        onMutation();\n+    }\n+\n+    public boolean traceIdAndIdEquals(byte[] serialized) {\n+        return id.dataEquals(serialized, traceId.getLength()) && traceId.dataEquals(serialized, 0);\n+    }\n+\n+    private static void putLong(byte[] buffer, int offset, long l) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 124}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MjA4NTUxOnYy", "diffSide": "RIGHT", "path": "apm-agent-core/src/main/java/co/elastic/apm/agent/impl/transaction/TraceContext.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQwNDoyMzowNlrOFdL11A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQwNDoyMzowNlrOFdL11A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE0NzAyOA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private long getLong(byte[] buffer, int offset) {\n          \n          \n            \n                private static long getLong(byte[] buffer, int offset) {", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366147028", "createdAt": "2020-01-14T04:23:06Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-core/src/main/java/co/elastic/apm/agent/impl/transaction/TraceContext.java", "diffHunk": "@@ -439,10 +467,81 @@ public ClassLoader getApplicationClassLoader() {\n         }\n     }\n \n+    public byte[] serialize() {\n+        byte[] result = new byte[SERIALIZED_LENGTH];\n+        serialize(result);\n+        return result;\n+    }\n+\n+    public void serialize(byte[] buffer) {\n+        int offset = 0;\n+        offset = traceId.toBytes(buffer, offset);\n+        offset = id.toBytes(buffer, offset);\n+        offset = transactionId.toBytes(buffer, offset);\n+        buffer[offset++] = flags;\n+        buffer[offset++] = (byte) (discard ? 1 : 0);\n+        putLong(buffer, offset, clock.getOffset());\n+    }\n+\n+    private void asChildOf(byte[] buffer, @Nullable String serviceName) {\n+        int offset = 0;\n+        offset = traceId.fromBytes(buffer, offset);\n+        offset = parentId.fromBytes(buffer, offset);\n+        offset = transactionId.fromBytes(buffer, offset);\n+        id.setToRandomValue();\n+        flags = buffer[offset++];\n+        discard = buffer[offset++] == (byte) 1;\n+        clock.init(getLong(buffer, offset));\n+        this.serviceName = serviceName;\n+        onMutation();\n+    }\n+\n+    public void deserialize(byte[] buffer, @Nullable String serviceName) {\n+        int offset = 0;\n+        offset = traceId.fromBytes(buffer, offset);\n+        offset = id.fromBytes(buffer, offset);\n+        offset = transactionId.fromBytes(buffer, offset);\n+        flags = buffer[offset++];\n+        discard = buffer[offset++] == (byte) 1;\n+        clock.init(getLong(buffer, offset));\n+        this.serviceName = serviceName;\n+        onMutation();\n+    }\n+\n+    public boolean traceIdAndIdEquals(byte[] serialized) {\n+        return id.dataEquals(serialized, traceId.getLength()) && traceId.dataEquals(serialized, 0);\n+    }\n+\n+    private static void putLong(byte[] buffer, int offset, long l) {\n+        buffer[offset++] = (byte) l;\n+        buffer[offset++] = (byte) (l >> 8);\n+        buffer[offset++] = (byte) (l >> 16);\n+        buffer[offset++] = (byte) (l >> 24);\n+        buffer[offset++] = (byte) (l >> 32);\n+        buffer[offset++] = (byte) (l >> 40);\n+        buffer[offset++] = (byte) (l >> 48);\n+        buffer[offset] = (byte) (l >> 56);\n+    }\n+\n+    private long getLong(byte[] buffer, int offset) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 135}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MjA5NTcwOnYy", "diffSide": "RIGHT", "path": "apm-agent-core/src/main/java/co/elastic/apm/agent/impl/transaction/TraceContext.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQwNDozMjo1M1rOFdL73w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQwOTo0NTowNFrOFeTcCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE0ODU3NQ==", "bodyText": "Is it actually used?", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366148575", "createdAt": "2020-01-14T04:32:53Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-core/src/main/java/co/elastic/apm/agent/impl/transaction/TraceContext.java", "diffHunk": "@@ -439,10 +467,81 @@ public ClassLoader getApplicationClassLoader() {\n         }\n     }\n \n+    public byte[] serialize() {\n+        byte[] result = new byte[SERIALIZED_LENGTH];\n+        serialize(result);\n+        return result;\n+    }\n+\n+    public void serialize(byte[] buffer) {\n+        int offset = 0;\n+        offset = traceId.toBytes(buffer, offset);\n+        offset = id.toBytes(buffer, offset);\n+        offset = transactionId.toBytes(buffer, offset);\n+        buffer[offset++] = flags;\n+        buffer[offset++] = (byte) (discard ? 1 : 0);\n+        putLong(buffer, offset, clock.getOffset());\n+    }\n+\n+    private void asChildOf(byte[] buffer, @Nullable String serviceName) {\n+        int offset = 0;\n+        offset = traceId.fromBytes(buffer, offset);\n+        offset = parentId.fromBytes(buffer, offset);\n+        offset = transactionId.fromBytes(buffer, offset);\n+        id.setToRandomValue();\n+        flags = buffer[offset++];\n+        discard = buffer[offset++] == (byte) 1;\n+        clock.init(getLong(buffer, offset));\n+        this.serviceName = serviceName;\n+        onMutation();\n+    }\n+\n+    public void deserialize(byte[] buffer, @Nullable String serviceName) {\n+        int offset = 0;\n+        offset = traceId.fromBytes(buffer, offset);\n+        offset = id.fromBytes(buffer, offset);\n+        offset = transactionId.fromBytes(buffer, offset);\n+        flags = buffer[offset++];\n+        discard = buffer[offset++] == (byte) 1;\n+        clock.init(getLong(buffer, offset));\n+        this.serviceName = serviceName;\n+        onMutation();\n+    }\n+\n+    public boolean traceIdAndIdEquals(byte[] serialized) {\n+        return id.dataEquals(serialized, traceId.getLength()) && traceId.dataEquals(serialized, 0);\n+    }\n+\n+    private static void putLong(byte[] buffer, int offset, long l) {\n+        buffer[offset++] = (byte) l;\n+        buffer[offset++] = (byte) (l >> 8);\n+        buffer[offset++] = (byte) (l >> 16);\n+        buffer[offset++] = (byte) (l >> 24);\n+        buffer[offset++] = (byte) (l >> 32);\n+        buffer[offset++] = (byte) (l >> 40);\n+        buffer[offset++] = (byte) (l >> 48);\n+        buffer[offset] = (byte) (l >> 56);\n+    }\n+\n+    private long getLong(byte[] buffer, int offset) {\n+        return ((long) buffer[offset + 7] << 56)\n+            | ((long) buffer[offset + 6] & 0xff) << 48\n+            | ((long) buffer[offset + 5] & 0xff) << 40\n+            | ((long) buffer[offset + 4] & 0xff) << 32\n+            | ((long) buffer[offset + 3] & 0xff) << 24\n+            | ((long) buffer[offset + 2] & 0xff) << 16\n+            | ((long) buffer[offset + 1] & 0xff) << 8\n+            | ((long) buffer[offset] & 0xff);\n+    }\n+\n     public interface ChildContextCreator<T> {\n         boolean asChildOf(TraceContext child, T parent);\n     }\n \n+    public interface ChildContextCreatorTwoArg<A, B> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzMyMDA3Mw==", "bodyText": "You're right, it's totally unused! It's a leftover from experimentation, I went a different route in the end: co.elastic.apm.agent.impl.transaction.TraceContext#deserialize(byte[] buffer, String serviceName).\nThis means I can remove quite some dependant code.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367320073", "createdAt": "2020-01-16T09:45:04Z", "author": {"login": "felixbarny"}, "path": "apm-agent-core/src/main/java/co/elastic/apm/agent/impl/transaction/TraceContext.java", "diffHunk": "@@ -439,10 +467,81 @@ public ClassLoader getApplicationClassLoader() {\n         }\n     }\n \n+    public byte[] serialize() {\n+        byte[] result = new byte[SERIALIZED_LENGTH];\n+        serialize(result);\n+        return result;\n+    }\n+\n+    public void serialize(byte[] buffer) {\n+        int offset = 0;\n+        offset = traceId.toBytes(buffer, offset);\n+        offset = id.toBytes(buffer, offset);\n+        offset = transactionId.toBytes(buffer, offset);\n+        buffer[offset++] = flags;\n+        buffer[offset++] = (byte) (discard ? 1 : 0);\n+        putLong(buffer, offset, clock.getOffset());\n+    }\n+\n+    private void asChildOf(byte[] buffer, @Nullable String serviceName) {\n+        int offset = 0;\n+        offset = traceId.fromBytes(buffer, offset);\n+        offset = parentId.fromBytes(buffer, offset);\n+        offset = transactionId.fromBytes(buffer, offset);\n+        id.setToRandomValue();\n+        flags = buffer[offset++];\n+        discard = buffer[offset++] == (byte) 1;\n+        clock.init(getLong(buffer, offset));\n+        this.serviceName = serviceName;\n+        onMutation();\n+    }\n+\n+    public void deserialize(byte[] buffer, @Nullable String serviceName) {\n+        int offset = 0;\n+        offset = traceId.fromBytes(buffer, offset);\n+        offset = id.fromBytes(buffer, offset);\n+        offset = transactionId.fromBytes(buffer, offset);\n+        flags = buffer[offset++];\n+        discard = buffer[offset++] == (byte) 1;\n+        clock.init(getLong(buffer, offset));\n+        this.serviceName = serviceName;\n+        onMutation();\n+    }\n+\n+    public boolean traceIdAndIdEquals(byte[] serialized) {\n+        return id.dataEquals(serialized, traceId.getLength()) && traceId.dataEquals(serialized, 0);\n+    }\n+\n+    private static void putLong(byte[] buffer, int offset, long l) {\n+        buffer[offset++] = (byte) l;\n+        buffer[offset++] = (byte) (l >> 8);\n+        buffer[offset++] = (byte) (l >> 16);\n+        buffer[offset++] = (byte) (l >> 24);\n+        buffer[offset++] = (byte) (l >> 32);\n+        buffer[offset++] = (byte) (l >> 40);\n+        buffer[offset++] = (byte) (l >> 48);\n+        buffer[offset] = (byte) (l >> 56);\n+    }\n+\n+    private long getLong(byte[] buffer, int offset) {\n+        return ((long) buffer[offset + 7] << 56)\n+            | ((long) buffer[offset + 6] & 0xff) << 48\n+            | ((long) buffer[offset + 5] & 0xff) << 40\n+            | ((long) buffer[offset + 4] & 0xff) << 32\n+            | ((long) buffer[offset + 3] & 0xff) << 24\n+            | ((long) buffer[offset + 2] & 0xff) << 16\n+            | ((long) buffer[offset + 1] & 0xff) << 8\n+            | ((long) buffer[offset] & 0xff);\n+    }\n+\n     public interface ChildContextCreator<T> {\n         boolean asChildOf(TraceContext child, T parent);\n     }\n \n+    public interface ChildContextCreatorTwoArg<A, B> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE0ODU3NQ=="}, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 150}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MjEwNTU3OnYy", "diffSide": "RIGHT", "path": "apm-agent-core/src/main/java/co/elastic/apm/agent/impl/transaction/Id.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQwNDozOTozOVrOFdMBNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQwNDozOTozOVrOFdMBNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE0OTk0Mg==", "bodyText": "I think it would make more sense to return the length of read bytes, rather than the end position of the reading action (which represent a state of the reader), but not something I would insist. In any case- javadoc would be nice here.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366149942", "createdAt": "2020-01-14T04:39:39Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-core/src/main/java/co/elastic/apm/agent/impl/transaction/Id.java", "diffHunk": "@@ -70,13 +70,15 @@ public void fromHexString(String hexEncodedString, int offset) {\n         onMutation();\n     }\n \n-    public void fromBytes(byte[] bytes, int offset) {\n+    public int fromBytes(byte[] bytes, int offset) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MjE1MTE1OnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/AsyncProfiler.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQwNToyMDo0M1rOFdMbjg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzo1MjowNVrOFeZ_Yw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE1NjY4Ng==", "bodyText": "Would ClassFileLocator.ForClassLoader.ofSystemLoader() locate bootstrap classes? Wouldn't .redefine(DirectNativeBinding.class) (which is equivalent to using the locator ClassFileLocator.ForClassLoader.of(DirectNativeBinding.class.getClassLoader())) be safer?\nAlso, the redefine method javadoc says:\n\nByte Buddy might be forced to add a method if a redefined class already defines a class initializer.\n\nwhich the redefine class does. I can't see why this would be a problem, just worth mentioning in case you can.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366156686", "createdAt": "2020-01-14T05:20:43Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/AsyncProfiler.java", "diffHunk": "@@ -0,0 +1,271 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+/*\n+ * Copyright 2018 Andrei Pangin\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.util.IOUtils;\n+import net.bytebuddy.ByteBuddy;\n+import net.bytebuddy.dynamic.ClassFileLocator;\n+import net.bytebuddy.dynamic.loading.ClassLoadingStrategy;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+\n+/**\n+ * Java API for in-process profiling. Serves as a wrapper around\n+ * async-profiler native library. This class is a singleton.\n+ * The first call to {@link #getInstance()} initiates loading of\n+ * libasyncProfiler.so.\n+ * <p>\n+ * This is based on https://github.com/jvm-profiling-tools/async-profiler/blob/master/src/java/one/profiler/AsyncProfiler.java,\n+ * under Apache License 2.0.\n+ * It is modified to allow it to be shaded into the {@code co.elastic.apm} namespace\n+ * </p>\n+ */\n+public abstract class AsyncProfiler {\n+\n+    @Nullable\n+    private static AsyncProfiler instance;\n+\n+    private final String version;\n+\n+    public AsyncProfiler() {\n+        this.version = version0();\n+    }\n+\n+    public static synchronized AsyncProfiler getInstance() {\n+        if (instance != null) {\n+            return instance;\n+        }\n+        instance = newInstance();\n+        return instance;\n+    }\n+\n+    /*\n+     * Allows AsyncProfiler to be shaded. JNI mapping works for a specific package so shading normally doesn't work.\n+     */\n+    private static AsyncProfiler newInstance() {\n+        try {\n+            return new ByteBuddy()\n+                .redefine(DirectNativeBinding.class, ClassFileLocator.ForClassLoader.ofSystemLoader())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQyNzQyNw==", "bodyText": "Would ClassFileLocator.ForClassLoader.ofSystemLoader() locate bootstrap classes?\n\nWe don't need to as attaching an Java agent always adds the classes to the system class loader.\nClassFileLocator.ForClassLoader.ofBootLoader() can't resolve resources added via Instrumentation.appendToBootstrapClassLoaderSearch. See https://stackoverflow.com/questions/51347432/why-cant-i-load-resources-which-are-appended-to-the-bootstrap-class-loader-sear", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367427427", "createdAt": "2020-01-16T13:52:05Z", "author": {"login": "felixbarny"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/AsyncProfiler.java", "diffHunk": "@@ -0,0 +1,271 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+/*\n+ * Copyright 2018 Andrei Pangin\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.util.IOUtils;\n+import net.bytebuddy.ByteBuddy;\n+import net.bytebuddy.dynamic.ClassFileLocator;\n+import net.bytebuddy.dynamic.loading.ClassLoadingStrategy;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+\n+/**\n+ * Java API for in-process profiling. Serves as a wrapper around\n+ * async-profiler native library. This class is a singleton.\n+ * The first call to {@link #getInstance()} initiates loading of\n+ * libasyncProfiler.so.\n+ * <p>\n+ * This is based on https://github.com/jvm-profiling-tools/async-profiler/blob/master/src/java/one/profiler/AsyncProfiler.java,\n+ * under Apache License 2.0.\n+ * It is modified to allow it to be shaded into the {@code co.elastic.apm} namespace\n+ * </p>\n+ */\n+public abstract class AsyncProfiler {\n+\n+    @Nullable\n+    private static AsyncProfiler instance;\n+\n+    private final String version;\n+\n+    public AsyncProfiler() {\n+        this.version = version0();\n+    }\n+\n+    public static synchronized AsyncProfiler getInstance() {\n+        if (instance != null) {\n+            return instance;\n+        }\n+        instance = newInstance();\n+        return instance;\n+    }\n+\n+    /*\n+     * Allows AsyncProfiler to be shaded. JNI mapping works for a specific package so shading normally doesn't work.\n+     */\n+    private static AsyncProfiler newInstance() {\n+        try {\n+            return new ByteBuddy()\n+                .redefine(DirectNativeBinding.class, ClassFileLocator.ForClassLoader.ofSystemLoader())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE1NjY4Ng=="}, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 86}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MjE1MjA0OnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/AsyncProfiler.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQwNToyMToyN1rOFdMcDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQwNToyMToyN1rOFdMcDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE1NjgxMg==", "bodyText": "\ud83d\ude2e", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366156812", "createdAt": "2020-01-14T05:21:27Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/AsyncProfiler.java", "diffHunk": "@@ -0,0 +1,271 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+/*\n+ * Copyright 2018 Andrei Pangin\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.util.IOUtils;\n+import net.bytebuddy.ByteBuddy;\n+import net.bytebuddy.dynamic.ClassFileLocator;\n+import net.bytebuddy.dynamic.loading.ClassLoadingStrategy;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+\n+/**\n+ * Java API for in-process profiling. Serves as a wrapper around\n+ * async-profiler native library. This class is a singleton.\n+ * The first call to {@link #getInstance()} initiates loading of\n+ * libasyncProfiler.so.\n+ * <p>\n+ * This is based on https://github.com/jvm-profiling-tools/async-profiler/blob/master/src/java/one/profiler/AsyncProfiler.java,\n+ * under Apache License 2.0.\n+ * It is modified to allow it to be shaded into the {@code co.elastic.apm} namespace\n+ * </p>\n+ */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MjYyMzQ5OnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQwOToyNzo1OFrOFdQ4RA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQwOToyNzo1OFrOFdQ4RA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjIyOTU3Mg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    if (major != 0 && minor != 9) {\n          \n          \n            \n                    if (major != 0 || minor != 9) {", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366229572", "createdAt": "2020-01-14T09:27:58Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "diffHunk": "@@ -0,0 +1,518 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+import co.elastic.apm.agent.profiler.collections.Int2IntHashMap;\n+import co.elastic.apm.agent.profiler.collections.Int2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * Parses the binary JFR file created by async-profiler.\n+ * May not work with JFR files created by an actual flight recorder.\n+ * <p>\n+ * The implementation is tuned with to minimize allocations when parsing a JFR file.\n+ * Most data structures can be reused by first {@linkplain #resetState() resetting the state} and then {@linkplain #parse(File, List, List) parsing}\n+ * another file.\n+ * </p>\n+ * <p>\n+ * The JFR file itself is mapped into memory via a {@link MappedByteBuffer}.\n+ * This does not consume heap memory, the operating system loads pages the file into memory as they are requested.\n+ * Unfortunately, unmapping a {@link MappedByteBuffer} can only be done by letting it be garbage collected.\n+ * </p>\n+ */\n+public class JfrParser implements Recyclable {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(JfrParser.class);\n+\n+    private static final byte[] MAGIC_BYTES = new byte[]{'F', 'L', 'R', '\\0'};\n+    private static final Set<String> JAVA_FRAME_TYPES = new HashSet<>(Arrays.asList(\"Interpreted\", \"JIT compiled\", \"Inlined\"));\n+\n+    @Nullable\n+    private MappedByteBuffer buffer;\n+    private int eventsOffset;\n+    private int metadataOffset;\n+    @Nullable\n+    private boolean[] isJavaFrameType;\n+    private final Int2IntHashMap classIdToClassNameSymbolId = new Int2IntHashMap(-1);\n+    private final Int2ObjectHashMap<Symbol> symbols = new Int2ObjectHashMap<>();\n+    private final Int2IntHashMap stackTraceIdToFilePositions = new Int2IntHashMap(-1);\n+    private final Long2ObjectHashMap<LazyStackFrame> framesByFrameId = new Long2ObjectHashMap<>();\n+    // used to resolve a symbol with minimal allocations\n+    private final StringBuilder symbolBuilder = new StringBuilder();\n+    @Nullable\n+    private List<WildcardMatcher> excludedClasses;\n+    @Nullable\n+    private List<WildcardMatcher> includedClasses;\n+\n+    /**\n+     * Initializes the parser to make it ready for {@link #getStackTrace(long, boolean, List)} to be called.\n+     *\n+     * @param file            the JFR file to parse\n+     * @param excludedClasses Class names to exclude in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @param includedClasses Class names to include in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void parse(File file, List<WildcardMatcher> excludedClasses, List<WildcardMatcher> includedClasses) throws IOException {\n+        this.excludedClasses = excludedClasses;\n+        this.includedClasses = includedClasses;\n+        try (RandomAccessFile raf = new RandomAccessFile(file, \"r\")) {\n+            FileChannel channel = raf.getChannel();\n+            logger.info(\"Parsing {} ({} bytes)\", file, channel.size());\n+            if (channel.size() > Integer.MAX_VALUE) {\n+                // mapping a file into memory is only possible for chunks of the file which fall into the Integer range (2GB)\n+                // that is because MappedByteBuffers are ByteBuffers which only accept ints in position(int pos)\n+                throw new IllegalArgumentException(\"Input file too large\");\n+            }\n+            this.buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, channel.size());\n+        }\n+        for (byte magicByte : MAGIC_BYTES) {\n+            if (buffer.get() != magicByte) {\n+                throw new IllegalArgumentException(\"Not a JFR file\");\n+            }\n+        }\n+        short major = buffer.getShort();\n+        short minor = buffer.getShort();\n+        if (major != 0 && minor != 9) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 115}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2Mjc2Njg1OnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxMDoxMzoyN1rOFdSQ9A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxMDoxMzoyN1rOFdSQ9A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjI1MjI3Ng==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        logger.info(startMessage);\n          \n          \n            \n                        logger.debug(startMessage);", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366252276", "createdAt": "2020-01-14T10:13:27Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#getStackTrace(long, boolean, List) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 100_000;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final AsyncProfiler asyncProfiler = AsyncProfiler.getInstance();\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"apm-sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+        }\n+    }\n+\n+    private RingBuffer<ActivationEvent> createRingBuffer() {\n+        return RingBuffer.<ActivationEvent>createMultiProducer(\n+            new EventFactory<ActivationEvent>() {\n+                @Override\n+                public ActivationEvent newInstance() {\n+                    return new ActivationEvent();\n+                }\n+            },\n+            RING_BUFFER_SIZE,\n+            new NoWaitStrategy());\n+    }\n+\n+    /**\n+     * Called whenever a span is activated.\n+     * <p>\n+     * This and {@link #onDeactivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onActivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(ACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * Called whenever a span is deactivated.\n+     * <p>\n+     * This and {@link #onActivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onDeactivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(DEACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public void run() {\n+        profilingSessions++;\n+        if (config.isProfilingDisabled()) {\n+            scheduler.schedule(this, config.getProfilingInterval().getMillis(), TimeUnit.MILLISECONDS);\n+            return;\n+        }\n+\n+        TimeDuration sampleRate = config.getSamplingInterval();\n+        TimeDuration profilingDuration = config.getProfilingDuration();\n+\n+        setProfilingSessionOngoing(true);\n+\n+        logger.debug(\"Start profiling session\");\n+        try {\n+            profile(sampleRate, profilingDuration);\n+        } catch (Exception e) {\n+            logger.error(\"Stopping profiler\", e);\n+            return;\n+        }\n+        logger.debug(\"End profiling session\");\n+\n+        boolean interrupted = Thread.currentThread().isInterrupted();\n+        boolean continueProfilingSession = config.isNonStopProfiling() && !interrupted && config.isProfilingEnabled();\n+        setProfilingSessionOngoing(continueProfilingSession);\n+\n+        if (!interrupted) {\n+            long delay = config.getProfilingInterval().getMillis() - profilingDuration.getMillis();\n+            scheduler.schedule(this, delay, TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private void profile(TimeDuration sampleRate, TimeDuration profilingDuration) throws Exception {\n+        try {\n+            String startMessage = asyncProfiler.execute(\"start,jfr,event=wall,interval=\" + sampleRate.getMillis() + \"ms,alluser,file=\" + jfrFile);\n+            logger.info(startMessage);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 274}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2Mjc2NzU1OnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxMDoxMzozOFrOFdSRVw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxMDoxMzozOFrOFdSRVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjI1MjM3NQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        logger.info(stopMessage);\n          \n          \n            \n                        logger.debug(stopMessage);", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366252375", "createdAt": "2020-01-14T10:13:38Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#getStackTrace(long, boolean, List) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 100_000;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final AsyncProfiler asyncProfiler = AsyncProfiler.getInstance();\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"apm-sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+        }\n+    }\n+\n+    private RingBuffer<ActivationEvent> createRingBuffer() {\n+        return RingBuffer.<ActivationEvent>createMultiProducer(\n+            new EventFactory<ActivationEvent>() {\n+                @Override\n+                public ActivationEvent newInstance() {\n+                    return new ActivationEvent();\n+                }\n+            },\n+            RING_BUFFER_SIZE,\n+            new NoWaitStrategy());\n+    }\n+\n+    /**\n+     * Called whenever a span is activated.\n+     * <p>\n+     * This and {@link #onDeactivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onActivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(ACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * Called whenever a span is deactivated.\n+     * <p>\n+     * This and {@link #onActivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onDeactivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(DEACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public void run() {\n+        profilingSessions++;\n+        if (config.isProfilingDisabled()) {\n+            scheduler.schedule(this, config.getProfilingInterval().getMillis(), TimeUnit.MILLISECONDS);\n+            return;\n+        }\n+\n+        TimeDuration sampleRate = config.getSamplingInterval();\n+        TimeDuration profilingDuration = config.getProfilingDuration();\n+\n+        setProfilingSessionOngoing(true);\n+\n+        logger.debug(\"Start profiling session\");\n+        try {\n+            profile(sampleRate, profilingDuration);\n+        } catch (Exception e) {\n+            logger.error(\"Stopping profiler\", e);\n+            return;\n+        }\n+        logger.debug(\"End profiling session\");\n+\n+        boolean interrupted = Thread.currentThread().isInterrupted();\n+        boolean continueProfilingSession = config.isNonStopProfiling() && !interrupted && config.isProfilingEnabled();\n+        setProfilingSessionOngoing(continueProfilingSession);\n+\n+        if (!interrupted) {\n+            long delay = config.getProfilingInterval().getMillis() - profilingDuration.getMillis();\n+            scheduler.schedule(this, delay, TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private void profile(TimeDuration sampleRate, TimeDuration profilingDuration) throws Exception {\n+        try {\n+            String startMessage = asyncProfiler.execute(\"start,jfr,event=wall,interval=\" + sampleRate.getMillis() + \"ms,alluser,file=\" + jfrFile);\n+            logger.info(startMessage);\n+\n+            consumeActivationEventsFromRingBufferAndWriteToFile(profilingDuration);\n+\n+            String stopMessage = asyncProfiler.execute(\"stop\");\n+            logger.info(stopMessage);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 279}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MjgwNjA4OnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxMDoyNDo0NlrOFdSnlw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxMDoyNDo0NlrOFdSnlw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjI1ODA3MQ==", "bodyText": "Consider adding a single-thread object pool for those", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366258071", "createdAt": "2020-01-14T10:24:46Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#getStackTrace(long, boolean, List) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 100_000;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final AsyncProfiler asyncProfiler = AsyncProfiler.getInstance();\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"apm-sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+        }\n+    }\n+\n+    private RingBuffer<ActivationEvent> createRingBuffer() {\n+        return RingBuffer.<ActivationEvent>createMultiProducer(\n+            new EventFactory<ActivationEvent>() {\n+                @Override\n+                public ActivationEvent newInstance() {\n+                    return new ActivationEvent();\n+                }\n+            },\n+            RING_BUFFER_SIZE,\n+            new NoWaitStrategy());\n+    }\n+\n+    /**\n+     * Called whenever a span is activated.\n+     * <p>\n+     * This and {@link #onDeactivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onActivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(ACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * Called whenever a span is deactivated.\n+     * <p>\n+     * This and {@link #onActivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onDeactivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(DEACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public void run() {\n+        profilingSessions++;\n+        if (config.isProfilingDisabled()) {\n+            scheduler.schedule(this, config.getProfilingInterval().getMillis(), TimeUnit.MILLISECONDS);\n+            return;\n+        }\n+\n+        TimeDuration sampleRate = config.getSamplingInterval();\n+        TimeDuration profilingDuration = config.getProfilingDuration();\n+\n+        setProfilingSessionOngoing(true);\n+\n+        logger.debug(\"Start profiling session\");\n+        try {\n+            profile(sampleRate, profilingDuration);\n+        } catch (Exception e) {\n+            logger.error(\"Stopping profiler\", e);\n+            return;\n+        }\n+        logger.debug(\"End profiling session\");\n+\n+        boolean interrupted = Thread.currentThread().isInterrupted();\n+        boolean continueProfilingSession = config.isNonStopProfiling() && !interrupted && config.isProfilingEnabled();\n+        setProfilingSessionOngoing(continueProfilingSession);\n+\n+        if (!interrupted) {\n+            long delay = config.getProfilingInterval().getMillis() - profilingDuration.getMillis();\n+            scheduler.schedule(this, delay, TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private void profile(TimeDuration sampleRate, TimeDuration profilingDuration) throws Exception {\n+        try {\n+            String startMessage = asyncProfiler.execute(\"start,jfr,event=wall,interval=\" + sampleRate.getMillis() + \"ms,alluser,file=\" + jfrFile);\n+            logger.info(startMessage);\n+\n+            consumeActivationEventsFromRingBufferAndWriteToFile(profilingDuration);\n+\n+            String stopMessage = asyncProfiler.execute(\"stop\");\n+            logger.info(stopMessage);\n+\n+            processTraces(jfrFile);\n+        } catch (InterruptedException e) {\n+            asyncProfiler.stop();\n+            Thread.currentThread().interrupt();\n+        }\n+    }\n+\n+    private void consumeActivationEventsFromRingBufferAndWriteToFile(TimeDuration profilingDuration) throws Exception {\n+        resetActivationEventBuffer();\n+        long threshold = System.currentTimeMillis() + profilingDuration.getMillis();\n+        long initialSleep = 100_000;\n+        long maxSleep = 10_000_000;\n+        long sleep = initialSleep;\n+        while (System.currentTimeMillis() < threshold) {\n+            if (activationEventBuffer.hasRemaining()) {\n+                EventPoller.PollState poll = consumeActivationEventsFromRingBufferAndWriteToFile();\n+                if (poll == EventPoller.PollState.PROCESSING) {\n+                    sleep = initialSleep;\n+                } else {\n+                    if (sleep < maxSleep) {\n+                        sleep *= 2;\n+                    }\n+                }\n+                LockSupport.parkNanos(sleep);\n+            } else {\n+                // the file is full, sleep the rest of the profilingDuration\n+                Thread.sleep(Math.max(0, threshold - System.currentTimeMillis()));\n+            }\n+        }\n+    }\n+\n+    private void resetActivationEventBuffer() {\n+        ((Buffer) activationEventBuffer).clear();\n+    }\n+\n+    EventPoller.PollState consumeActivationEventsFromRingBufferAndWriteToFile() throws Exception {\n+        return poller.poll(writeActivationEventToFileHandler);\n+    }\n+\n+    private void processTraces(File file) throws IOException {\n+        if (activationEventBuffer.position() == 0) {\n+            logger.debug(\"No activation events during this period. Skip processing stack traces.\");\n+            return;\n+        }\n+        List<WildcardMatcher> excludedClasses = config.getExcludedClasses();\n+        List<WildcardMatcher> includedClasses = config.getIncludedClasses();\n+        try {\n+            jfrParser.parse(file, excludedClasses, includedClasses);\n+            startProcessingActivationEventsFile();\n+            final SortedSet<StackTraceEvent> stackTraceEvents = getStackTraceEvents(jfrParser);\n+            if (logger.isDebugEnabled()) {\n+                logger.debug(\"Processing {} stack traces\", stackTraceEvents.size());\n+            }\n+            List<StackFrame> stackFrames = new ArrayList<>();\n+            ElasticApmTracer tracer = this.tracer;\n+            ActivationEvent event = new ActivationEvent();\n+            for (StackTraceEvent stackTrace : stackTraceEvents) {\n+                processActivationEventsUpTo(stackTrace.nanoTime, event);\n+                CallTree.Root root = profiledThreads.get(stackTrace.threadId);\n+                if (root != null) {\n+                    jfrParser.getStackTrace(stackTrace.stackTraceId, true, stackFrames);\n+                    root.addStackTrace(tracer, stackFrames, stackTrace.nanoTime);\n+                }\n+                stackFrames.clear();\n+            }\n+        } finally {\n+            jfrParser.resetState();\n+        }\n+    }\n+\n+    /**\n+     * Returns stack trace events of relevant threads sorted by timestamp.\n+     * The events in the JFR file are not in order.\n+     * Even for the same thread, a more recent event might come before an older event.\n+     * In order to be able to correlate stack trace events and activation events, both need to be in order.\n+     *\n+     * Returns only events for threads where at least one activation happened\n+     */\n+    private SortedSet<StackTraceEvent> getStackTraceEvents(JfrParser jfrParser) throws IOException {\n+        final LongHashSet nativeThreadIds = threadMapper.getNativeThreadIds();\n+        final SortedSet<StackTraceEvent> stackTraceEvents = new TreeSet<>();\n+        jfrParser.consumeStackTraces(new JfrParser.StackTraceConsumer() {\n+            @Override\n+            public void onCallTree(int threadId, long stackTraceId, long nanoTime) {\n+                if (nativeThreadIds.contains(threadId)) {\n+                    stackTraceEvents.add(new StackTraceEvent(nanoTime, stackTraceId, threadId));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 366}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MjgxNzIxOnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxMDoyNzo1M1rOFdSuVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxNTowOTowM1rOFecpyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjI1OTc5Ng==", "bodyText": "Consider adding time measurement of the processing and add a debug log", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366259796", "createdAt": "2020-01-14T10:27:53Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#getStackTrace(long, boolean, List) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 100_000;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final AsyncProfiler asyncProfiler = AsyncProfiler.getInstance();\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"apm-sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+        }\n+    }\n+\n+    private RingBuffer<ActivationEvent> createRingBuffer() {\n+        return RingBuffer.<ActivationEvent>createMultiProducer(\n+            new EventFactory<ActivationEvent>() {\n+                @Override\n+                public ActivationEvent newInstance() {\n+                    return new ActivationEvent();\n+                }\n+            },\n+            RING_BUFFER_SIZE,\n+            new NoWaitStrategy());\n+    }\n+\n+    /**\n+     * Called whenever a span is activated.\n+     * <p>\n+     * This and {@link #onDeactivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onActivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(ACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * Called whenever a span is deactivated.\n+     * <p>\n+     * This and {@link #onActivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onDeactivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(DEACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public void run() {\n+        profilingSessions++;\n+        if (config.isProfilingDisabled()) {\n+            scheduler.schedule(this, config.getProfilingInterval().getMillis(), TimeUnit.MILLISECONDS);\n+            return;\n+        }\n+\n+        TimeDuration sampleRate = config.getSamplingInterval();\n+        TimeDuration profilingDuration = config.getProfilingDuration();\n+\n+        setProfilingSessionOngoing(true);\n+\n+        logger.debug(\"Start profiling session\");\n+        try {\n+            profile(sampleRate, profilingDuration);\n+        } catch (Exception e) {\n+            logger.error(\"Stopping profiler\", e);\n+            return;\n+        }\n+        logger.debug(\"End profiling session\");\n+\n+        boolean interrupted = Thread.currentThread().isInterrupted();\n+        boolean continueProfilingSession = config.isNonStopProfiling() && !interrupted && config.isProfilingEnabled();\n+        setProfilingSessionOngoing(continueProfilingSession);\n+\n+        if (!interrupted) {\n+            long delay = config.getProfilingInterval().getMillis() - profilingDuration.getMillis();\n+            scheduler.schedule(this, delay, TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private void profile(TimeDuration sampleRate, TimeDuration profilingDuration) throws Exception {\n+        try {\n+            String startMessage = asyncProfiler.execute(\"start,jfr,event=wall,interval=\" + sampleRate.getMillis() + \"ms,alluser,file=\" + jfrFile);\n+            logger.info(startMessage);\n+\n+            consumeActivationEventsFromRingBufferAndWriteToFile(profilingDuration);\n+\n+            String stopMessage = asyncProfiler.execute(\"stop\");\n+            logger.info(stopMessage);\n+\n+            processTraces(jfrFile);\n+        } catch (InterruptedException e) {\n+            asyncProfiler.stop();\n+            Thread.currentThread().interrupt();\n+        }\n+    }\n+\n+    private void consumeActivationEventsFromRingBufferAndWriteToFile(TimeDuration profilingDuration) throws Exception {\n+        resetActivationEventBuffer();\n+        long threshold = System.currentTimeMillis() + profilingDuration.getMillis();\n+        long initialSleep = 100_000;\n+        long maxSleep = 10_000_000;\n+        long sleep = initialSleep;\n+        while (System.currentTimeMillis() < threshold) {\n+            if (activationEventBuffer.hasRemaining()) {\n+                EventPoller.PollState poll = consumeActivationEventsFromRingBufferAndWriteToFile();\n+                if (poll == EventPoller.PollState.PROCESSING) {\n+                    sleep = initialSleep;\n+                } else {\n+                    if (sleep < maxSleep) {\n+                        sleep *= 2;\n+                    }\n+                }\n+                LockSupport.parkNanos(sleep);\n+            } else {\n+                // the file is full, sleep the rest of the profilingDuration\n+                Thread.sleep(Math.max(0, threshold - System.currentTimeMillis()));\n+            }\n+        }\n+    }\n+\n+    private void resetActivationEventBuffer() {\n+        ((Buffer) activationEventBuffer).clear();\n+    }\n+\n+    EventPoller.PollState consumeActivationEventsFromRingBufferAndWriteToFile() throws Exception {\n+        return poller.poll(writeActivationEventToFileHandler);\n+    }\n+\n+    private void processTraces(File file) throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 320}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQyMzgwNw==", "bodyText": "What I was also thinking about is that we could create transactions and spans for this process - using the agent to monitor itself.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367423807", "createdAt": "2020-01-16T13:44:41Z", "author": {"login": "felixbarny"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#getStackTrace(long, boolean, List) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 100_000;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final AsyncProfiler asyncProfiler = AsyncProfiler.getInstance();\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"apm-sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+        }\n+    }\n+\n+    private RingBuffer<ActivationEvent> createRingBuffer() {\n+        return RingBuffer.<ActivationEvent>createMultiProducer(\n+            new EventFactory<ActivationEvent>() {\n+                @Override\n+                public ActivationEvent newInstance() {\n+                    return new ActivationEvent();\n+                }\n+            },\n+            RING_BUFFER_SIZE,\n+            new NoWaitStrategy());\n+    }\n+\n+    /**\n+     * Called whenever a span is activated.\n+     * <p>\n+     * This and {@link #onDeactivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onActivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(ACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * Called whenever a span is deactivated.\n+     * <p>\n+     * This and {@link #onActivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onDeactivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(DEACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public void run() {\n+        profilingSessions++;\n+        if (config.isProfilingDisabled()) {\n+            scheduler.schedule(this, config.getProfilingInterval().getMillis(), TimeUnit.MILLISECONDS);\n+            return;\n+        }\n+\n+        TimeDuration sampleRate = config.getSamplingInterval();\n+        TimeDuration profilingDuration = config.getProfilingDuration();\n+\n+        setProfilingSessionOngoing(true);\n+\n+        logger.debug(\"Start profiling session\");\n+        try {\n+            profile(sampleRate, profilingDuration);\n+        } catch (Exception e) {\n+            logger.error(\"Stopping profiler\", e);\n+            return;\n+        }\n+        logger.debug(\"End profiling session\");\n+\n+        boolean interrupted = Thread.currentThread().isInterrupted();\n+        boolean continueProfilingSession = config.isNonStopProfiling() && !interrupted && config.isProfilingEnabled();\n+        setProfilingSessionOngoing(continueProfilingSession);\n+\n+        if (!interrupted) {\n+            long delay = config.getProfilingInterval().getMillis() - profilingDuration.getMillis();\n+            scheduler.schedule(this, delay, TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private void profile(TimeDuration sampleRate, TimeDuration profilingDuration) throws Exception {\n+        try {\n+            String startMessage = asyncProfiler.execute(\"start,jfr,event=wall,interval=\" + sampleRate.getMillis() + \"ms,alluser,file=\" + jfrFile);\n+            logger.info(startMessage);\n+\n+            consumeActivationEventsFromRingBufferAndWriteToFile(profilingDuration);\n+\n+            String stopMessage = asyncProfiler.execute(\"stop\");\n+            logger.info(stopMessage);\n+\n+            processTraces(jfrFile);\n+        } catch (InterruptedException e) {\n+            asyncProfiler.stop();\n+            Thread.currentThread().interrupt();\n+        }\n+    }\n+\n+    private void consumeActivationEventsFromRingBufferAndWriteToFile(TimeDuration profilingDuration) throws Exception {\n+        resetActivationEventBuffer();\n+        long threshold = System.currentTimeMillis() + profilingDuration.getMillis();\n+        long initialSleep = 100_000;\n+        long maxSleep = 10_000_000;\n+        long sleep = initialSleep;\n+        while (System.currentTimeMillis() < threshold) {\n+            if (activationEventBuffer.hasRemaining()) {\n+                EventPoller.PollState poll = consumeActivationEventsFromRingBufferAndWriteToFile();\n+                if (poll == EventPoller.PollState.PROCESSING) {\n+                    sleep = initialSleep;\n+                } else {\n+                    if (sleep < maxSleep) {\n+                        sleep *= 2;\n+                    }\n+                }\n+                LockSupport.parkNanos(sleep);\n+            } else {\n+                // the file is full, sleep the rest of the profilingDuration\n+                Thread.sleep(Math.max(0, threshold - System.currentTimeMillis()));\n+            }\n+        }\n+    }\n+\n+    private void resetActivationEventBuffer() {\n+        ((Buffer) activationEventBuffer).clear();\n+    }\n+\n+    EventPoller.PollState consumeActivationEventsFromRingBufferAndWriteToFile() throws Exception {\n+        return poller.poll(writeActivationEventToFileHandler);\n+    }\n+\n+    private void processTraces(File file) throws IOException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjI1OTc5Ng=="}, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 320}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ0NjUwMA==", "bodyText": "And send to the same APM server?", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367446500", "createdAt": "2020-01-16T14:27:39Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#getStackTrace(long, boolean, List) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 100_000;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final AsyncProfiler asyncProfiler = AsyncProfiler.getInstance();\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"apm-sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+        }\n+    }\n+\n+    private RingBuffer<ActivationEvent> createRingBuffer() {\n+        return RingBuffer.<ActivationEvent>createMultiProducer(\n+            new EventFactory<ActivationEvent>() {\n+                @Override\n+                public ActivationEvent newInstance() {\n+                    return new ActivationEvent();\n+                }\n+            },\n+            RING_BUFFER_SIZE,\n+            new NoWaitStrategy());\n+    }\n+\n+    /**\n+     * Called whenever a span is activated.\n+     * <p>\n+     * This and {@link #onDeactivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onActivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(ACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * Called whenever a span is deactivated.\n+     * <p>\n+     * This and {@link #onActivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onDeactivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(DEACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public void run() {\n+        profilingSessions++;\n+        if (config.isProfilingDisabled()) {\n+            scheduler.schedule(this, config.getProfilingInterval().getMillis(), TimeUnit.MILLISECONDS);\n+            return;\n+        }\n+\n+        TimeDuration sampleRate = config.getSamplingInterval();\n+        TimeDuration profilingDuration = config.getProfilingDuration();\n+\n+        setProfilingSessionOngoing(true);\n+\n+        logger.debug(\"Start profiling session\");\n+        try {\n+            profile(sampleRate, profilingDuration);\n+        } catch (Exception e) {\n+            logger.error(\"Stopping profiler\", e);\n+            return;\n+        }\n+        logger.debug(\"End profiling session\");\n+\n+        boolean interrupted = Thread.currentThread().isInterrupted();\n+        boolean continueProfilingSession = config.isNonStopProfiling() && !interrupted && config.isProfilingEnabled();\n+        setProfilingSessionOngoing(continueProfilingSession);\n+\n+        if (!interrupted) {\n+            long delay = config.getProfilingInterval().getMillis() - profilingDuration.getMillis();\n+            scheduler.schedule(this, delay, TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private void profile(TimeDuration sampleRate, TimeDuration profilingDuration) throws Exception {\n+        try {\n+            String startMessage = asyncProfiler.execute(\"start,jfr,event=wall,interval=\" + sampleRate.getMillis() + \"ms,alluser,file=\" + jfrFile);\n+            logger.info(startMessage);\n+\n+            consumeActivationEventsFromRingBufferAndWriteToFile(profilingDuration);\n+\n+            String stopMessage = asyncProfiler.execute(\"stop\");\n+            logger.info(stopMessage);\n+\n+            processTraces(jfrFile);\n+        } catch (InterruptedException e) {\n+            asyncProfiler.stop();\n+            Thread.currentThread().interrupt();\n+        }\n+    }\n+\n+    private void consumeActivationEventsFromRingBufferAndWriteToFile(TimeDuration profilingDuration) throws Exception {\n+        resetActivationEventBuffer();\n+        long threshold = System.currentTimeMillis() + profilingDuration.getMillis();\n+        long initialSleep = 100_000;\n+        long maxSleep = 10_000_000;\n+        long sleep = initialSleep;\n+        while (System.currentTimeMillis() < threshold) {\n+            if (activationEventBuffer.hasRemaining()) {\n+                EventPoller.PollState poll = consumeActivationEventsFromRingBufferAndWriteToFile();\n+                if (poll == EventPoller.PollState.PROCESSING) {\n+                    sleep = initialSleep;\n+                } else {\n+                    if (sleep < maxSleep) {\n+                        sleep *= 2;\n+                    }\n+                }\n+                LockSupport.parkNanos(sleep);\n+            } else {\n+                // the file is full, sleep the rest of the profilingDuration\n+                Thread.sleep(Math.max(0, threshold - System.currentTimeMillis()));\n+            }\n+        }\n+    }\n+\n+    private void resetActivationEventBuffer() {\n+        ((Buffer) activationEventBuffer).clear();\n+    }\n+\n+    EventPoller.PollState consumeActivationEventsFromRingBufferAndWriteToFile() throws Exception {\n+        return poller.poll(writeActivationEventToFileHandler);\n+    }\n+\n+    private void processTraces(File file) throws IOException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjI1OTc5Ng=="}, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 320}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ2MTgyMA==", "bodyText": "Yes, with a special transaction.type. But that's not for this PR", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367461820", "createdAt": "2020-01-16T14:53:39Z", "author": {"login": "felixbarny"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#getStackTrace(long, boolean, List) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 100_000;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final AsyncProfiler asyncProfiler = AsyncProfiler.getInstance();\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"apm-sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+        }\n+    }\n+\n+    private RingBuffer<ActivationEvent> createRingBuffer() {\n+        return RingBuffer.<ActivationEvent>createMultiProducer(\n+            new EventFactory<ActivationEvent>() {\n+                @Override\n+                public ActivationEvent newInstance() {\n+                    return new ActivationEvent();\n+                }\n+            },\n+            RING_BUFFER_SIZE,\n+            new NoWaitStrategy());\n+    }\n+\n+    /**\n+     * Called whenever a span is activated.\n+     * <p>\n+     * This and {@link #onDeactivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onActivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(ACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * Called whenever a span is deactivated.\n+     * <p>\n+     * This and {@link #onActivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onDeactivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(DEACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public void run() {\n+        profilingSessions++;\n+        if (config.isProfilingDisabled()) {\n+            scheduler.schedule(this, config.getProfilingInterval().getMillis(), TimeUnit.MILLISECONDS);\n+            return;\n+        }\n+\n+        TimeDuration sampleRate = config.getSamplingInterval();\n+        TimeDuration profilingDuration = config.getProfilingDuration();\n+\n+        setProfilingSessionOngoing(true);\n+\n+        logger.debug(\"Start profiling session\");\n+        try {\n+            profile(sampleRate, profilingDuration);\n+        } catch (Exception e) {\n+            logger.error(\"Stopping profiler\", e);\n+            return;\n+        }\n+        logger.debug(\"End profiling session\");\n+\n+        boolean interrupted = Thread.currentThread().isInterrupted();\n+        boolean continueProfilingSession = config.isNonStopProfiling() && !interrupted && config.isProfilingEnabled();\n+        setProfilingSessionOngoing(continueProfilingSession);\n+\n+        if (!interrupted) {\n+            long delay = config.getProfilingInterval().getMillis() - profilingDuration.getMillis();\n+            scheduler.schedule(this, delay, TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private void profile(TimeDuration sampleRate, TimeDuration profilingDuration) throws Exception {\n+        try {\n+            String startMessage = asyncProfiler.execute(\"start,jfr,event=wall,interval=\" + sampleRate.getMillis() + \"ms,alluser,file=\" + jfrFile);\n+            logger.info(startMessage);\n+\n+            consumeActivationEventsFromRingBufferAndWriteToFile(profilingDuration);\n+\n+            String stopMessage = asyncProfiler.execute(\"stop\");\n+            logger.info(stopMessage);\n+\n+            processTraces(jfrFile);\n+        } catch (InterruptedException e) {\n+            asyncProfiler.stop();\n+            Thread.currentThread().interrupt();\n+        }\n+    }\n+\n+    private void consumeActivationEventsFromRingBufferAndWriteToFile(TimeDuration profilingDuration) throws Exception {\n+        resetActivationEventBuffer();\n+        long threshold = System.currentTimeMillis() + profilingDuration.getMillis();\n+        long initialSleep = 100_000;\n+        long maxSleep = 10_000_000;\n+        long sleep = initialSleep;\n+        while (System.currentTimeMillis() < threshold) {\n+            if (activationEventBuffer.hasRemaining()) {\n+                EventPoller.PollState poll = consumeActivationEventsFromRingBufferAndWriteToFile();\n+                if (poll == EventPoller.PollState.PROCESSING) {\n+                    sleep = initialSleep;\n+                } else {\n+                    if (sleep < maxSleep) {\n+                        sleep *= 2;\n+                    }\n+                }\n+                LockSupport.parkNanos(sleep);\n+            } else {\n+                // the file is full, sleep the rest of the profilingDuration\n+                Thread.sleep(Math.max(0, threshold - System.currentTimeMillis()));\n+            }\n+        }\n+    }\n+\n+    private void resetActivationEventBuffer() {\n+        ((Buffer) activationEventBuffer).clear();\n+    }\n+\n+    EventPoller.PollState consumeActivationEventsFromRingBufferAndWriteToFile() throws Exception {\n+        return poller.poll(writeActivationEventToFileHandler);\n+    }\n+\n+    private void processTraces(File file) throws IOException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjI1OTc5Ng=="}, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 320}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ3MTA0OQ==", "bodyText": "Not sure about that...\nApart from additional overhead and possible tracing data loss (eg full buffer), it's storage user pays for.\nAnyway, may be an interesting debug info/stats to have.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367471049", "createdAt": "2020-01-16T15:09:03Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#getStackTrace(long, boolean, List) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 100_000;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final AsyncProfiler asyncProfiler = AsyncProfiler.getInstance();\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"apm-sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+        }\n+    }\n+\n+    private RingBuffer<ActivationEvent> createRingBuffer() {\n+        return RingBuffer.<ActivationEvent>createMultiProducer(\n+            new EventFactory<ActivationEvent>() {\n+                @Override\n+                public ActivationEvent newInstance() {\n+                    return new ActivationEvent();\n+                }\n+            },\n+            RING_BUFFER_SIZE,\n+            new NoWaitStrategy());\n+    }\n+\n+    /**\n+     * Called whenever a span is activated.\n+     * <p>\n+     * This and {@link #onDeactivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onActivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(ACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * Called whenever a span is deactivated.\n+     * <p>\n+     * This and {@link #onActivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onDeactivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(DEACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public void run() {\n+        profilingSessions++;\n+        if (config.isProfilingDisabled()) {\n+            scheduler.schedule(this, config.getProfilingInterval().getMillis(), TimeUnit.MILLISECONDS);\n+            return;\n+        }\n+\n+        TimeDuration sampleRate = config.getSamplingInterval();\n+        TimeDuration profilingDuration = config.getProfilingDuration();\n+\n+        setProfilingSessionOngoing(true);\n+\n+        logger.debug(\"Start profiling session\");\n+        try {\n+            profile(sampleRate, profilingDuration);\n+        } catch (Exception e) {\n+            logger.error(\"Stopping profiler\", e);\n+            return;\n+        }\n+        logger.debug(\"End profiling session\");\n+\n+        boolean interrupted = Thread.currentThread().isInterrupted();\n+        boolean continueProfilingSession = config.isNonStopProfiling() && !interrupted && config.isProfilingEnabled();\n+        setProfilingSessionOngoing(continueProfilingSession);\n+\n+        if (!interrupted) {\n+            long delay = config.getProfilingInterval().getMillis() - profilingDuration.getMillis();\n+            scheduler.schedule(this, delay, TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private void profile(TimeDuration sampleRate, TimeDuration profilingDuration) throws Exception {\n+        try {\n+            String startMessage = asyncProfiler.execute(\"start,jfr,event=wall,interval=\" + sampleRate.getMillis() + \"ms,alluser,file=\" + jfrFile);\n+            logger.info(startMessage);\n+\n+            consumeActivationEventsFromRingBufferAndWriteToFile(profilingDuration);\n+\n+            String stopMessage = asyncProfiler.execute(\"stop\");\n+            logger.info(stopMessage);\n+\n+            processTraces(jfrFile);\n+        } catch (InterruptedException e) {\n+            asyncProfiler.stop();\n+            Thread.currentThread().interrupt();\n+        }\n+    }\n+\n+    private void consumeActivationEventsFromRingBufferAndWriteToFile(TimeDuration profilingDuration) throws Exception {\n+        resetActivationEventBuffer();\n+        long threshold = System.currentTimeMillis() + profilingDuration.getMillis();\n+        long initialSleep = 100_000;\n+        long maxSleep = 10_000_000;\n+        long sleep = initialSleep;\n+        while (System.currentTimeMillis() < threshold) {\n+            if (activationEventBuffer.hasRemaining()) {\n+                EventPoller.PollState poll = consumeActivationEventsFromRingBufferAndWriteToFile();\n+                if (poll == EventPoller.PollState.PROCESSING) {\n+                    sleep = initialSleep;\n+                } else {\n+                    if (sleep < maxSleep) {\n+                        sleep *= 2;\n+                    }\n+                }\n+                LockSupport.parkNanos(sleep);\n+            } else {\n+                // the file is full, sleep the rest of the profilingDuration\n+                Thread.sleep(Math.max(0, threshold - System.currentTimeMillis()));\n+            }\n+        }\n+    }\n+\n+    private void resetActivationEventBuffer() {\n+        ((Buffer) activationEventBuffer).clear();\n+    }\n+\n+    EventPoller.PollState consumeActivationEventsFromRingBufferAndWriteToFile() throws Exception {\n+        return poller.poll(writeActivationEventToFileHandler);\n+    }\n+\n+    private void processTraces(File file) throws IOException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjI1OTc5Ng=="}, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 320}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MzE1NzQ0OnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxMjozMjozOVrOFdV6lw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxNDo1NzoyN1rOFecOxQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMxMjA4Nw==", "bodyText": "I think this calls for Symbol's polymorphism - either a MethodSymbol and a ClassSymbol implementing a Symbol or a Symbol class and a ClassSymbol subclass.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366312087", "createdAt": "2020-01-14T12:32:39Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "diffHunk": "@@ -0,0 +1,518 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+import co.elastic.apm.agent.profiler.collections.Int2IntHashMap;\n+import co.elastic.apm.agent.profiler.collections.Int2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * Parses the binary JFR file created by async-profiler.\n+ * May not work with JFR files created by an actual flight recorder.\n+ * <p>\n+ * The implementation is tuned with to minimize allocations when parsing a JFR file.\n+ * Most data structures can be reused by first {@linkplain #resetState() resetting the state} and then {@linkplain #parse(File, List, List) parsing}\n+ * another file.\n+ * </p>\n+ * <p>\n+ * The JFR file itself is mapped into memory via a {@link MappedByteBuffer}.\n+ * This does not consume heap memory, the operating system loads pages the file into memory as they are requested.\n+ * Unfortunately, unmapping a {@link MappedByteBuffer} can only be done by letting it be garbage collected.\n+ * </p>\n+ */\n+public class JfrParser implements Recyclable {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(JfrParser.class);\n+\n+    private static final byte[] MAGIC_BYTES = new byte[]{'F', 'L', 'R', '\\0'};\n+    private static final Set<String> JAVA_FRAME_TYPES = new HashSet<>(Arrays.asList(\"Interpreted\", \"JIT compiled\", \"Inlined\"));\n+\n+    @Nullable\n+    private MappedByteBuffer buffer;\n+    private int eventsOffset;\n+    private int metadataOffset;\n+    @Nullable\n+    private boolean[] isJavaFrameType;\n+    private final Int2IntHashMap classIdToClassNameSymbolId = new Int2IntHashMap(-1);\n+    private final Int2ObjectHashMap<Symbol> symbols = new Int2ObjectHashMap<>();\n+    private final Int2IntHashMap stackTraceIdToFilePositions = new Int2IntHashMap(-1);\n+    private final Long2ObjectHashMap<LazyStackFrame> framesByFrameId = new Long2ObjectHashMap<>();\n+    // used to resolve a symbol with minimal allocations\n+    private final StringBuilder symbolBuilder = new StringBuilder();\n+    @Nullable\n+    private List<WildcardMatcher> excludedClasses;\n+    @Nullable\n+    private List<WildcardMatcher> includedClasses;\n+\n+    /**\n+     * Initializes the parser to make it ready for {@link #getStackTrace(long, boolean, List)} to be called.\n+     *\n+     * @param file            the JFR file to parse\n+     * @param excludedClasses Class names to exclude in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @param includedClasses Class names to include in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void parse(File file, List<WildcardMatcher> excludedClasses, List<WildcardMatcher> includedClasses) throws IOException {\n+        this.excludedClasses = excludedClasses;\n+        this.includedClasses = includedClasses;\n+        try (RandomAccessFile raf = new RandomAccessFile(file, \"r\")) {\n+            FileChannel channel = raf.getChannel();\n+            logger.info(\"Parsing {} ({} bytes)\", file, channel.size());\n+            if (channel.size() > Integer.MAX_VALUE) {\n+                // mapping a file into memory is only possible for chunks of the file which fall into the Integer range (2GB)\n+                // that is because MappedByteBuffers are ByteBuffers which only accept ints in position(int pos)\n+                throw new IllegalArgumentException(\"Input file too large\");\n+            }\n+            this.buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, channel.size());\n+        }\n+        for (byte magicByte : MAGIC_BYTES) {\n+            if (buffer.get() != magicByte) {\n+                throw new IllegalArgumentException(\"Not a JFR file\");\n+            }\n+        }\n+        short major = buffer.getShort();\n+        short minor = buffer.getShort();\n+        if (major != 0 && minor != 9) {\n+            throw new IllegalArgumentException(String.format(\"Can only parse version 0.9. Was %d.%d\", major, minor));\n+        }\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        metadataOffset = (int) buffer.getLong();\n+        eventsOffset = buffer.position();\n+\n+        setPosition(buffer, metadataOffset);\n+        int checkpointOffset = parseMetadata(buffer);\n+        setPosition(buffer, checkpointOffset);\n+        parseCheckpoint(buffer);\n+    }\n+\n+    private int parseMetadata(MappedByteBuffer buffer) throws IOException {\n+        int size = buffer.getInt();\n+        expectEventType(buffer, EventTypeId.EVENT_METADATA);\n+        int checkpointOffsetPosition = size - 16;\n+        setPosition(buffer, buffer.position() + checkpointOffsetPosition);\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        return (int) buffer.getLong();\n+    }\n+\n+    private void expectEventType(MappedByteBuffer buffer, int expectedEventType) throws IOException {\n+        int eventType = buffer.getInt();\n+        if (eventType != expectedEventType) {\n+            throw new IOException(\"Expected \" + expectedEventType + \" but got \" + eventType);\n+        }\n+    }\n+\n+    private void parseCheckpoint(MappedByteBuffer buffer) throws IOException {\n+        buffer.getInt(); // size\n+        expectEventType(buffer, EventTypeId.EVENT_CHECKPOINT);\n+        buffer.getLong(); // stop timestamp\n+        buffer.getLong(); // previous checkpoint - always 0 in async-profiler\n+        while (buffer.position() < metadataOffset) {\n+            parseContentType(buffer);\n+        }\n+    }\n+\n+    private void parseContentType(MappedByteBuffer buffer) throws IOException {\n+        int contentTypeId = buffer.getInt();\n+        logger.debug(\"Parsing content type {}\", contentTypeId);\n+        int count = buffer.getInt();\n+        switch (contentTypeId) {\n+            case ContentTypeId.CONTENT_THREAD:\n+                // currently no thread info\n+                break;\n+            case ContentTypeId.CONTENT_STACKTRACE:\n+                for (int i = 0; i < count; i++) {\n+                    int pos = buffer.position();\n+                    // always an integer\n+                    // see profiler.h\n+                    // MAX_CALLTRACES = 65536\n+                    int stackTraceKey = (int) buffer.getLong();\n+                    this.stackTraceIdToFilePositions.put(stackTraceKey, pos);\n+                    buffer.get(); // truncated\n+                    int numFrames = buffer.getInt();\n+                    int sizeOfFrame = 13;\n+                    setPosition(buffer, buffer.position() + numFrames * sizeOfFrame);\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_CLASS:\n+                for (int i = 0; i < count; i++) {\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    buffer.getLong(); // loader class\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int classNameSymbolId = (int) buffer.getLong();\n+                    classIdToClassNameSymbolId.put(classId, classNameSymbolId); // class name\n+                    buffer.getShort(); // access flags\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_METHOD:\n+                for (int i = 1; i <= count; i++) {\n+                    long id = buffer.getLong();\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int methodNameSymbolId = (int) buffer.getLong();\n+                    framesByFrameId.put(id, new LazyStackFrame(classId, methodNameSymbolId));\n+                    buffer.getLong(); // signature\n+                    buffer.getShort(); // modifiers\n+                    buffer.get(); // hidden\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_SYMBOL:\n+                for (int i = 0; i < count; i++) {\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int symbolId = (int) buffer.getLong();\n+                    int pos = buffer.position();\n+                    symbols.put(symbolId, new Symbol(pos));\n+                    skipString();\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_STATE:\n+                // we're not really interested in the thread states (async-profiler hard-codes state RUNNABLE) anyways\n+                // but we sill have to consume the bytes\n+                for (int i = 1; i <= count; i++) {\n+                    buffer.getShort();\n+                    skipString();\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_FRAME_TYPE:\n+                isJavaFrameType = new boolean[count + 1];\n+                for (int i = 1 ; i <= count; i++) {\n+                    int id = buffer.get();\n+                    if (i != id) {\n+                        throw new IllegalStateException(\"Expecting ids to be incrementing\");\n+                    }\n+                    isJavaFrameType[id] = JAVA_FRAME_TYPES.contains(readUtf8String().toString());\n+                }\n+                break;\n+            default:\n+                throw new IOException(\"Unknown content type \" + contentTypeId);\n+        }\n+    }\n+\n+    private void skipString() {\n+        short stringLength = buffer.getShort();\n+        setPosition(buffer, buffer.position() + stringLength);\n+    }\n+\n+    /**\n+     * Invokes the callback for each stack trace event in the JFR file.\n+     *\n+     * @param callback called for each stack trace event\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void consumeStackTraces(StackTraceConsumer callback) throws IOException {\n+        if (buffer == null) {\n+            throw new IllegalStateException(\"consumeStackTraces was called before parse\");\n+        }\n+        setPosition(buffer, eventsOffset);\n+        while (buffer.position() < metadataOffset) {\n+            int size = buffer.getInt();\n+            int eventType = buffer.getInt();\n+            if (eventType == EventTypeId.EVENT_RECORDING) {\n+                return;\n+            }\n+            if (eventType != EventTypeId.EVENT_EXECUTION_SAMPLE){\n+                throw new IOException(\"Expected \" + EventTypeId.EVENT_EXECUTION_SAMPLE + \" but got \" + eventType);\n+            }\n+            long nanoTime = buffer.getLong();\n+            int tid = buffer.getInt();\n+            long stackTraceId = buffer.getLong();\n+            short threadState = buffer.getShort();\n+            callback.onCallTree(tid, stackTraceId, nanoTime);\n+        }\n+    }\n+\n+    public interface StackTraceConsumer {\n+\n+        /**\n+         * @param threadId     The native thread id for with the event was recorded.\n+         *                     Note that this is not the same as {@link Thread#getId()}.\n+         * @param stackTraceId The id of the stack trace event.\n+         *                     Can be used to resolve the stack trace via {@link #getStackTrace(long, boolean, List)}\n+         * @param nanoTime     The timestamp of the event which can be correlated with {@link System#nanoTime()}\n+         */\n+        void onCallTree(int threadId, long stackTraceId, long nanoTime);\n+    }\n+\n+    /**\n+     * Resolves the stack trace with the given {@code stackTraceId}.\n+     * <p>\n+     * Note that his allocates strings for {@link Symbol#resolved} in case a stack frame has not already been resolved for the current JFR file yet.\n+     * These strings are currently not cached so this can create some GC pressure.\n+     * </p>\n+     *\n+     * @param stackTraceId   The id of the stack traced.\n+     *                       Used to look up the position of the file in which the given stack trace is stored via {@link #stackTraceIdToFilePositions}.\n+     * @param onlyJavaFrames If {@code true}, will only resolve {@code Interpreted}, {@code JIT compiled} and {@code Inlined} frames.\n+     *                       If {@code false}, will also resolve {@code Native}, {@code Kernel} and {@code C++} frames.\n+     * @param stackFrames    The mutable list where the stack frames are written to.\n+     *                       Don't forget to {@link List#clear()} the list before calling this method if the list is reused.\n+     */\n+    public void getStackTrace(long stackTraceId, boolean onlyJavaFrames, List<StackFrame> stackFrames) {\n+        if (buffer == null) {\n+            throw new IllegalStateException(\"getStackTrace was called before parse\");\n+        }\n+        MappedByteBuffer buffer = this.buffer;\n+        int position = buffer.position();\n+        setPosition(buffer, stackTraceIdToFilePositions.get((int) stackTraceId));\n+        long stackTraceIdFromFile = buffer.getLong();\n+        assert stackTraceId == stackTraceIdFromFile;\n+        buffer.get(); // truncated\n+        int numFrames = buffer.getInt();\n+        for (int i = 0; i < numFrames; i++) {\n+            long method = buffer.getLong();\n+            buffer.getInt(); // bci (always set to 0 by async-profiler)\n+            byte frameType = buffer.get();\n+            if (!onlyJavaFrames || isJavaFrameType(frameType)) {\n+                LazyStackFrame lazyStackFrame = framesByFrameId.get(method);\n+                if (lazyStackFrame.isIncluded(this)) {\n+                    StackFrame stackFrame = lazyStackFrame.resolve(this);\n+                    stackFrames.add(stackFrame);\n+                }\n+            }\n+        }\n+        setPosition(buffer, position);\n+    }\n+\n+    private boolean isJavaFrameType(byte frameType) {\n+        return isJavaFrameType[frameType];\n+    }\n+\n+    private StringBuilder resolveSymbol(int pos, boolean replaceSlashWithDot) {\n+        int currentPos = buffer.position();\n+        setPosition(buffer, pos);\n+        try {\n+            return readUtf8String(replaceSlashWithDot);\n+        } finally {\n+            setPosition(buffer, currentPos);\n+        }\n+    }\n+\n+    private boolean isClassIncluded(CharSequence className) {\n+        return WildcardMatcher.isAnyMatch(includedClasses, className) && WildcardMatcher.isNoneMatch(excludedClasses, className);\n+    }\n+\n+    private static void setPosition(MappedByteBuffer buffer, int pos) {\n+        // weird hack because of binary incompatibility introduced in Java 9\n+        // the return type was changed from Buffer to MappedByteBuffer\n+        // linking a method also incorporates the exact return type\n+        ((Buffer) buffer).position(pos);\n+    }\n+\n+    private StackFrame resolveStackFrame(int classId, int methodName) {\n+        Symbol classNameSymbol = symbols.get(classIdToClassNameSymbolId.get(classId));\n+        if (classNameSymbol.isClassNameIncluded(this)) {\n+            String className = classNameSymbol.resolveClassName(this);\n+            String method = symbols.get(methodName).resolve(this);\n+            return new StackFrame(className, Objects.requireNonNull(method));\n+        } else {\n+            return LazyStackFrame.EXCLUDED;\n+        }\n+    }\n+\n+    private StringBuilder readUtf8String() {\n+        return readUtf8String(false);\n+    }\n+\n+    private StringBuilder readUtf8String(boolean replaceSlashWithDot) {\n+        int size = buffer.getShort();\n+        StringBuilder symbolBuilder = this.symbolBuilder;\n+        symbolBuilder.setLength(0);\n+        for (int i = 0; i < size; i++) {\n+            char c = (char) buffer.get();\n+            if (replaceSlashWithDot && c == '/') {\n+                symbolBuilder.append('.');\n+            } else {\n+                symbolBuilder.append(c);\n+            }\n+        }\n+        return symbolBuilder;\n+    }\n+\n+    @Override\n+    public void resetState() {\n+        buffer = null;\n+        eventsOffset = 0;\n+        metadataOffset = 0;\n+        isJavaFrameType = null;\n+        classIdToClassNameSymbolId.clear();\n+        symbols.clear();\n+        stackTraceIdToFilePositions.clear();\n+        framesByFrameId.clear();\n+        symbolBuilder.setLength(0);\n+        excludedClasses = null;\n+        includedClasses = null;\n+    }\n+\n+    private interface EventTypeId {\n+        int EVENT_METADATA           = 0;\n+        int EVENT_CHECKPOINT         = 1;\n+        int EVENT_RECORDING          = 10;\n+        int EVENT_EXECUTION_SAMPLE   = 20;\n+    }\n+\n+    private interface ContentTypeId {\n+        int CONTENT_THREAD      = 7;\n+        int CONTENT_STACKTRACE  = 9;\n+        int CONTENT_CLASS       = 10;\n+        int CONTENT_METHOD      = 32;\n+        int CONTENT_SYMBOL      = 33;\n+        int CONTENT_STATE       = 34;\n+        int CONTENT_FRAME_TYPE  = 47;\n+    }\n+\n+    /**\n+     * Represents a single frame of a stack trace.\n+     * As stack frames are detached from stack traces, the same frame can occur in multiple stack traces.\n+     * That's why within a JFR file, a stack trace is basically represented as an array of pointers to stack frames.\n+     * <p>\n+     * The actual {@link StackFrame} is resolved lazily to avoid allocations when they are not needed.\n+     * That can be the case when not processing stack traces of particular threads, for example.\n+     * The resolved {@link #stackFrame} is then cached so that I/O is avoided when subsequently resolving the same frame.\n+     * </p>\n+     */\n+    private static class LazyStackFrame {\n+\n+        private final static StackFrame EXCLUDED = new StackFrame(\"excluded\", \"excluded\");\n+\n+        private final int classId;\n+        private final int methodName;\n+\n+        @Nullable\n+        private StackFrame stackFrame;\n+\n+        public LazyStackFrame(int classId, int methodName) {\n+            this.classId = classId;\n+            this.methodName = methodName;\n+        }\n+\n+        public StackFrame resolve(JfrParser parser) {\n+            if (stackFrame == null) {\n+                stackFrame = parser.resolveStackFrame(classId, methodName);\n+            }\n+            return stackFrame;\n+        }\n+\n+        /**\n+         * Returns {@code true} when the class name matches the matchers provided via {@link #parse(File, List, List)}\n+         *\n+         * @param parser\n+         * @return\n+         */\n+        public boolean isIncluded(JfrParser parser) {\n+            return resolve(parser) != EXCLUDED;\n+        }\n+    }\n+\n+    /**\n+     * A symbol is a UTF-8 string with an ID, representing a method name or class name, for example.\n+     * There's a specific section in the JFR file which contains all symbols.\n+     * <p>\n+     * Symbols are are {@link #resolve}d lazily to avoid allocations when they are not needed.\n+     * That can be the case when not processing stack traces of particular threads, for example.\n+     * The {@link #resolved} String is then cached so that I/O is avoided when subsequently resolving the same symbol.\n+     * </p>\n+     */\n+    private static class Symbol {\n+        private static final String EXCLUDED = \"3x cluded\";\n+        /**\n+         * The position in the JFR file which holds the symbol\n+         */\n+        private final int pos;\n+        @Nullable\n+        private String resolved;\n+\n+        private Symbol(int pos) {\n+            this.pos = pos;\n+        }\n+\n+        /**\n+         * Resolves a symbol representing a class name from the JFR file ({@link #buffer}).\n+         */\n+        @Nullable\n+        public String resolve(JfrParser parser) {\n+            return resolve(parser, false);\n+        }\n+\n+        /**\n+         * Resolves a symbol representing a class name from the JFR file ({@link #buffer}).\n+         * <p>\n+         * In the JFR file, class names are in their binary form (for example {@code foo/bar/Baz}.\n+         * This methods converts it to the form matching {@link Class#getName()} by replacing the slashes with dots.\n+         * </p>\n+         * <p>\n+         * Returns {@code null} if {@link #isClassNameIncluded(JfrParser)} returns {@code false}\n+         * </p>\n+         */\n+        @Nullable\n+        private String resolveClassName(JfrParser parser) {\n+            return resolve(parser, true);\n+        }\n+\n+        /**\n+         * Returns {@code true} when the class name matches the matchers provided via {@link #parse(File, List, List)}\n+         *\n+         * @param parser\n+         * @return\n+         */\n+        private boolean isClassNameIncluded(JfrParser parser) {\n+            return resolve(parser, true) != EXCLUDED;\n+        }\n+\n+        @Nullable\n+        private String resolve(JfrParser parser, boolean className) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 503}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQzNTU2NA==", "bodyText": "But a symbol does not know whether it's a class name symbol or a regular one.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367435564", "createdAt": "2020-01-16T14:07:36Z", "author": {"login": "felixbarny"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "diffHunk": "@@ -0,0 +1,518 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+import co.elastic.apm.agent.profiler.collections.Int2IntHashMap;\n+import co.elastic.apm.agent.profiler.collections.Int2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * Parses the binary JFR file created by async-profiler.\n+ * May not work with JFR files created by an actual flight recorder.\n+ * <p>\n+ * The implementation is tuned with to minimize allocations when parsing a JFR file.\n+ * Most data structures can be reused by first {@linkplain #resetState() resetting the state} and then {@linkplain #parse(File, List, List) parsing}\n+ * another file.\n+ * </p>\n+ * <p>\n+ * The JFR file itself is mapped into memory via a {@link MappedByteBuffer}.\n+ * This does not consume heap memory, the operating system loads pages the file into memory as they are requested.\n+ * Unfortunately, unmapping a {@link MappedByteBuffer} can only be done by letting it be garbage collected.\n+ * </p>\n+ */\n+public class JfrParser implements Recyclable {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(JfrParser.class);\n+\n+    private static final byte[] MAGIC_BYTES = new byte[]{'F', 'L', 'R', '\\0'};\n+    private static final Set<String> JAVA_FRAME_TYPES = new HashSet<>(Arrays.asList(\"Interpreted\", \"JIT compiled\", \"Inlined\"));\n+\n+    @Nullable\n+    private MappedByteBuffer buffer;\n+    private int eventsOffset;\n+    private int metadataOffset;\n+    @Nullable\n+    private boolean[] isJavaFrameType;\n+    private final Int2IntHashMap classIdToClassNameSymbolId = new Int2IntHashMap(-1);\n+    private final Int2ObjectHashMap<Symbol> symbols = new Int2ObjectHashMap<>();\n+    private final Int2IntHashMap stackTraceIdToFilePositions = new Int2IntHashMap(-1);\n+    private final Long2ObjectHashMap<LazyStackFrame> framesByFrameId = new Long2ObjectHashMap<>();\n+    // used to resolve a symbol with minimal allocations\n+    private final StringBuilder symbolBuilder = new StringBuilder();\n+    @Nullable\n+    private List<WildcardMatcher> excludedClasses;\n+    @Nullable\n+    private List<WildcardMatcher> includedClasses;\n+\n+    /**\n+     * Initializes the parser to make it ready for {@link #getStackTrace(long, boolean, List)} to be called.\n+     *\n+     * @param file            the JFR file to parse\n+     * @param excludedClasses Class names to exclude in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @param includedClasses Class names to include in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void parse(File file, List<WildcardMatcher> excludedClasses, List<WildcardMatcher> includedClasses) throws IOException {\n+        this.excludedClasses = excludedClasses;\n+        this.includedClasses = includedClasses;\n+        try (RandomAccessFile raf = new RandomAccessFile(file, \"r\")) {\n+            FileChannel channel = raf.getChannel();\n+            logger.info(\"Parsing {} ({} bytes)\", file, channel.size());\n+            if (channel.size() > Integer.MAX_VALUE) {\n+                // mapping a file into memory is only possible for chunks of the file which fall into the Integer range (2GB)\n+                // that is because MappedByteBuffers are ByteBuffers which only accept ints in position(int pos)\n+                throw new IllegalArgumentException(\"Input file too large\");\n+            }\n+            this.buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, channel.size());\n+        }\n+        for (byte magicByte : MAGIC_BYTES) {\n+            if (buffer.get() != magicByte) {\n+                throw new IllegalArgumentException(\"Not a JFR file\");\n+            }\n+        }\n+        short major = buffer.getShort();\n+        short minor = buffer.getShort();\n+        if (major != 0 && minor != 9) {\n+            throw new IllegalArgumentException(String.format(\"Can only parse version 0.9. Was %d.%d\", major, minor));\n+        }\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        metadataOffset = (int) buffer.getLong();\n+        eventsOffset = buffer.position();\n+\n+        setPosition(buffer, metadataOffset);\n+        int checkpointOffset = parseMetadata(buffer);\n+        setPosition(buffer, checkpointOffset);\n+        parseCheckpoint(buffer);\n+    }\n+\n+    private int parseMetadata(MappedByteBuffer buffer) throws IOException {\n+        int size = buffer.getInt();\n+        expectEventType(buffer, EventTypeId.EVENT_METADATA);\n+        int checkpointOffsetPosition = size - 16;\n+        setPosition(buffer, buffer.position() + checkpointOffsetPosition);\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        return (int) buffer.getLong();\n+    }\n+\n+    private void expectEventType(MappedByteBuffer buffer, int expectedEventType) throws IOException {\n+        int eventType = buffer.getInt();\n+        if (eventType != expectedEventType) {\n+            throw new IOException(\"Expected \" + expectedEventType + \" but got \" + eventType);\n+        }\n+    }\n+\n+    private void parseCheckpoint(MappedByteBuffer buffer) throws IOException {\n+        buffer.getInt(); // size\n+        expectEventType(buffer, EventTypeId.EVENT_CHECKPOINT);\n+        buffer.getLong(); // stop timestamp\n+        buffer.getLong(); // previous checkpoint - always 0 in async-profiler\n+        while (buffer.position() < metadataOffset) {\n+            parseContentType(buffer);\n+        }\n+    }\n+\n+    private void parseContentType(MappedByteBuffer buffer) throws IOException {\n+        int contentTypeId = buffer.getInt();\n+        logger.debug(\"Parsing content type {}\", contentTypeId);\n+        int count = buffer.getInt();\n+        switch (contentTypeId) {\n+            case ContentTypeId.CONTENT_THREAD:\n+                // currently no thread info\n+                break;\n+            case ContentTypeId.CONTENT_STACKTRACE:\n+                for (int i = 0; i < count; i++) {\n+                    int pos = buffer.position();\n+                    // always an integer\n+                    // see profiler.h\n+                    // MAX_CALLTRACES = 65536\n+                    int stackTraceKey = (int) buffer.getLong();\n+                    this.stackTraceIdToFilePositions.put(stackTraceKey, pos);\n+                    buffer.get(); // truncated\n+                    int numFrames = buffer.getInt();\n+                    int sizeOfFrame = 13;\n+                    setPosition(buffer, buffer.position() + numFrames * sizeOfFrame);\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_CLASS:\n+                for (int i = 0; i < count; i++) {\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    buffer.getLong(); // loader class\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int classNameSymbolId = (int) buffer.getLong();\n+                    classIdToClassNameSymbolId.put(classId, classNameSymbolId); // class name\n+                    buffer.getShort(); // access flags\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_METHOD:\n+                for (int i = 1; i <= count; i++) {\n+                    long id = buffer.getLong();\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int methodNameSymbolId = (int) buffer.getLong();\n+                    framesByFrameId.put(id, new LazyStackFrame(classId, methodNameSymbolId));\n+                    buffer.getLong(); // signature\n+                    buffer.getShort(); // modifiers\n+                    buffer.get(); // hidden\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_SYMBOL:\n+                for (int i = 0; i < count; i++) {\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int symbolId = (int) buffer.getLong();\n+                    int pos = buffer.position();\n+                    symbols.put(symbolId, new Symbol(pos));\n+                    skipString();\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_STATE:\n+                // we're not really interested in the thread states (async-profiler hard-codes state RUNNABLE) anyways\n+                // but we sill have to consume the bytes\n+                for (int i = 1; i <= count; i++) {\n+                    buffer.getShort();\n+                    skipString();\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_FRAME_TYPE:\n+                isJavaFrameType = new boolean[count + 1];\n+                for (int i = 1 ; i <= count; i++) {\n+                    int id = buffer.get();\n+                    if (i != id) {\n+                        throw new IllegalStateException(\"Expecting ids to be incrementing\");\n+                    }\n+                    isJavaFrameType[id] = JAVA_FRAME_TYPES.contains(readUtf8String().toString());\n+                }\n+                break;\n+            default:\n+                throw new IOException(\"Unknown content type \" + contentTypeId);\n+        }\n+    }\n+\n+    private void skipString() {\n+        short stringLength = buffer.getShort();\n+        setPosition(buffer, buffer.position() + stringLength);\n+    }\n+\n+    /**\n+     * Invokes the callback for each stack trace event in the JFR file.\n+     *\n+     * @param callback called for each stack trace event\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void consumeStackTraces(StackTraceConsumer callback) throws IOException {\n+        if (buffer == null) {\n+            throw new IllegalStateException(\"consumeStackTraces was called before parse\");\n+        }\n+        setPosition(buffer, eventsOffset);\n+        while (buffer.position() < metadataOffset) {\n+            int size = buffer.getInt();\n+            int eventType = buffer.getInt();\n+            if (eventType == EventTypeId.EVENT_RECORDING) {\n+                return;\n+            }\n+            if (eventType != EventTypeId.EVENT_EXECUTION_SAMPLE){\n+                throw new IOException(\"Expected \" + EventTypeId.EVENT_EXECUTION_SAMPLE + \" but got \" + eventType);\n+            }\n+            long nanoTime = buffer.getLong();\n+            int tid = buffer.getInt();\n+            long stackTraceId = buffer.getLong();\n+            short threadState = buffer.getShort();\n+            callback.onCallTree(tid, stackTraceId, nanoTime);\n+        }\n+    }\n+\n+    public interface StackTraceConsumer {\n+\n+        /**\n+         * @param threadId     The native thread id for with the event was recorded.\n+         *                     Note that this is not the same as {@link Thread#getId()}.\n+         * @param stackTraceId The id of the stack trace event.\n+         *                     Can be used to resolve the stack trace via {@link #getStackTrace(long, boolean, List)}\n+         * @param nanoTime     The timestamp of the event which can be correlated with {@link System#nanoTime()}\n+         */\n+        void onCallTree(int threadId, long stackTraceId, long nanoTime);\n+    }\n+\n+    /**\n+     * Resolves the stack trace with the given {@code stackTraceId}.\n+     * <p>\n+     * Note that his allocates strings for {@link Symbol#resolved} in case a stack frame has not already been resolved for the current JFR file yet.\n+     * These strings are currently not cached so this can create some GC pressure.\n+     * </p>\n+     *\n+     * @param stackTraceId   The id of the stack traced.\n+     *                       Used to look up the position of the file in which the given stack trace is stored via {@link #stackTraceIdToFilePositions}.\n+     * @param onlyJavaFrames If {@code true}, will only resolve {@code Interpreted}, {@code JIT compiled} and {@code Inlined} frames.\n+     *                       If {@code false}, will also resolve {@code Native}, {@code Kernel} and {@code C++} frames.\n+     * @param stackFrames    The mutable list where the stack frames are written to.\n+     *                       Don't forget to {@link List#clear()} the list before calling this method if the list is reused.\n+     */\n+    public void getStackTrace(long stackTraceId, boolean onlyJavaFrames, List<StackFrame> stackFrames) {\n+        if (buffer == null) {\n+            throw new IllegalStateException(\"getStackTrace was called before parse\");\n+        }\n+        MappedByteBuffer buffer = this.buffer;\n+        int position = buffer.position();\n+        setPosition(buffer, stackTraceIdToFilePositions.get((int) stackTraceId));\n+        long stackTraceIdFromFile = buffer.getLong();\n+        assert stackTraceId == stackTraceIdFromFile;\n+        buffer.get(); // truncated\n+        int numFrames = buffer.getInt();\n+        for (int i = 0; i < numFrames; i++) {\n+            long method = buffer.getLong();\n+            buffer.getInt(); // bci (always set to 0 by async-profiler)\n+            byte frameType = buffer.get();\n+            if (!onlyJavaFrames || isJavaFrameType(frameType)) {\n+                LazyStackFrame lazyStackFrame = framesByFrameId.get(method);\n+                if (lazyStackFrame.isIncluded(this)) {\n+                    StackFrame stackFrame = lazyStackFrame.resolve(this);\n+                    stackFrames.add(stackFrame);\n+                }\n+            }\n+        }\n+        setPosition(buffer, position);\n+    }\n+\n+    private boolean isJavaFrameType(byte frameType) {\n+        return isJavaFrameType[frameType];\n+    }\n+\n+    private StringBuilder resolveSymbol(int pos, boolean replaceSlashWithDot) {\n+        int currentPos = buffer.position();\n+        setPosition(buffer, pos);\n+        try {\n+            return readUtf8String(replaceSlashWithDot);\n+        } finally {\n+            setPosition(buffer, currentPos);\n+        }\n+    }\n+\n+    private boolean isClassIncluded(CharSequence className) {\n+        return WildcardMatcher.isAnyMatch(includedClasses, className) && WildcardMatcher.isNoneMatch(excludedClasses, className);\n+    }\n+\n+    private static void setPosition(MappedByteBuffer buffer, int pos) {\n+        // weird hack because of binary incompatibility introduced in Java 9\n+        // the return type was changed from Buffer to MappedByteBuffer\n+        // linking a method also incorporates the exact return type\n+        ((Buffer) buffer).position(pos);\n+    }\n+\n+    private StackFrame resolveStackFrame(int classId, int methodName) {\n+        Symbol classNameSymbol = symbols.get(classIdToClassNameSymbolId.get(classId));\n+        if (classNameSymbol.isClassNameIncluded(this)) {\n+            String className = classNameSymbol.resolveClassName(this);\n+            String method = symbols.get(methodName).resolve(this);\n+            return new StackFrame(className, Objects.requireNonNull(method));\n+        } else {\n+            return LazyStackFrame.EXCLUDED;\n+        }\n+    }\n+\n+    private StringBuilder readUtf8String() {\n+        return readUtf8String(false);\n+    }\n+\n+    private StringBuilder readUtf8String(boolean replaceSlashWithDot) {\n+        int size = buffer.getShort();\n+        StringBuilder symbolBuilder = this.symbolBuilder;\n+        symbolBuilder.setLength(0);\n+        for (int i = 0; i < size; i++) {\n+            char c = (char) buffer.get();\n+            if (replaceSlashWithDot && c == '/') {\n+                symbolBuilder.append('.');\n+            } else {\n+                symbolBuilder.append(c);\n+            }\n+        }\n+        return symbolBuilder;\n+    }\n+\n+    @Override\n+    public void resetState() {\n+        buffer = null;\n+        eventsOffset = 0;\n+        metadataOffset = 0;\n+        isJavaFrameType = null;\n+        classIdToClassNameSymbolId.clear();\n+        symbols.clear();\n+        stackTraceIdToFilePositions.clear();\n+        framesByFrameId.clear();\n+        symbolBuilder.setLength(0);\n+        excludedClasses = null;\n+        includedClasses = null;\n+    }\n+\n+    private interface EventTypeId {\n+        int EVENT_METADATA           = 0;\n+        int EVENT_CHECKPOINT         = 1;\n+        int EVENT_RECORDING          = 10;\n+        int EVENT_EXECUTION_SAMPLE   = 20;\n+    }\n+\n+    private interface ContentTypeId {\n+        int CONTENT_THREAD      = 7;\n+        int CONTENT_STACKTRACE  = 9;\n+        int CONTENT_CLASS       = 10;\n+        int CONTENT_METHOD      = 32;\n+        int CONTENT_SYMBOL      = 33;\n+        int CONTENT_STATE       = 34;\n+        int CONTENT_FRAME_TYPE  = 47;\n+    }\n+\n+    /**\n+     * Represents a single frame of a stack trace.\n+     * As stack frames are detached from stack traces, the same frame can occur in multiple stack traces.\n+     * That's why within a JFR file, a stack trace is basically represented as an array of pointers to stack frames.\n+     * <p>\n+     * The actual {@link StackFrame} is resolved lazily to avoid allocations when they are not needed.\n+     * That can be the case when not processing stack traces of particular threads, for example.\n+     * The resolved {@link #stackFrame} is then cached so that I/O is avoided when subsequently resolving the same frame.\n+     * </p>\n+     */\n+    private static class LazyStackFrame {\n+\n+        private final static StackFrame EXCLUDED = new StackFrame(\"excluded\", \"excluded\");\n+\n+        private final int classId;\n+        private final int methodName;\n+\n+        @Nullable\n+        private StackFrame stackFrame;\n+\n+        public LazyStackFrame(int classId, int methodName) {\n+            this.classId = classId;\n+            this.methodName = methodName;\n+        }\n+\n+        public StackFrame resolve(JfrParser parser) {\n+            if (stackFrame == null) {\n+                stackFrame = parser.resolveStackFrame(classId, methodName);\n+            }\n+            return stackFrame;\n+        }\n+\n+        /**\n+         * Returns {@code true} when the class name matches the matchers provided via {@link #parse(File, List, List)}\n+         *\n+         * @param parser\n+         * @return\n+         */\n+        public boolean isIncluded(JfrParser parser) {\n+            return resolve(parser) != EXCLUDED;\n+        }\n+    }\n+\n+    /**\n+     * A symbol is a UTF-8 string with an ID, representing a method name or class name, for example.\n+     * There's a specific section in the JFR file which contains all symbols.\n+     * <p>\n+     * Symbols are are {@link #resolve}d lazily to avoid allocations when they are not needed.\n+     * That can be the case when not processing stack traces of particular threads, for example.\n+     * The {@link #resolved} String is then cached so that I/O is avoided when subsequently resolving the same symbol.\n+     * </p>\n+     */\n+    private static class Symbol {\n+        private static final String EXCLUDED = \"3x cluded\";\n+        /**\n+         * The position in the JFR file which holds the symbol\n+         */\n+        private final int pos;\n+        @Nullable\n+        private String resolved;\n+\n+        private Symbol(int pos) {\n+            this.pos = pos;\n+        }\n+\n+        /**\n+         * Resolves a symbol representing a class name from the JFR file ({@link #buffer}).\n+         */\n+        @Nullable\n+        public String resolve(JfrParser parser) {\n+            return resolve(parser, false);\n+        }\n+\n+        /**\n+         * Resolves a symbol representing a class name from the JFR file ({@link #buffer}).\n+         * <p>\n+         * In the JFR file, class names are in their binary form (for example {@code foo/bar/Baz}.\n+         * This methods converts it to the form matching {@link Class#getName()} by replacing the slashes with dots.\n+         * </p>\n+         * <p>\n+         * Returns {@code null} if {@link #isClassNameIncluded(JfrParser)} returns {@code false}\n+         * </p>\n+         */\n+        @Nullable\n+        private String resolveClassName(JfrParser parser) {\n+            return resolve(parser, true);\n+        }\n+\n+        /**\n+         * Returns {@code true} when the class name matches the matchers provided via {@link #parse(File, List, List)}\n+         *\n+         * @param parser\n+         * @return\n+         */\n+        private boolean isClassNameIncluded(JfrParser parser) {\n+            return resolve(parser, true) != EXCLUDED;\n+        }\n+\n+        @Nullable\n+        private String resolve(JfrParser parser, boolean className) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMxMjA4Nw=="}, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 503}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ0OTUyOA==", "bodyText": "Ahh, you mean that when you create them based on the file you can't tell?", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367449528", "createdAt": "2020-01-16T14:32:46Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "diffHunk": "@@ -0,0 +1,518 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+import co.elastic.apm.agent.profiler.collections.Int2IntHashMap;\n+import co.elastic.apm.agent.profiler.collections.Int2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * Parses the binary JFR file created by async-profiler.\n+ * May not work with JFR files created by an actual flight recorder.\n+ * <p>\n+ * The implementation is tuned with to minimize allocations when parsing a JFR file.\n+ * Most data structures can be reused by first {@linkplain #resetState() resetting the state} and then {@linkplain #parse(File, List, List) parsing}\n+ * another file.\n+ * </p>\n+ * <p>\n+ * The JFR file itself is mapped into memory via a {@link MappedByteBuffer}.\n+ * This does not consume heap memory, the operating system loads pages the file into memory as they are requested.\n+ * Unfortunately, unmapping a {@link MappedByteBuffer} can only be done by letting it be garbage collected.\n+ * </p>\n+ */\n+public class JfrParser implements Recyclable {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(JfrParser.class);\n+\n+    private static final byte[] MAGIC_BYTES = new byte[]{'F', 'L', 'R', '\\0'};\n+    private static final Set<String> JAVA_FRAME_TYPES = new HashSet<>(Arrays.asList(\"Interpreted\", \"JIT compiled\", \"Inlined\"));\n+\n+    @Nullable\n+    private MappedByteBuffer buffer;\n+    private int eventsOffset;\n+    private int metadataOffset;\n+    @Nullable\n+    private boolean[] isJavaFrameType;\n+    private final Int2IntHashMap classIdToClassNameSymbolId = new Int2IntHashMap(-1);\n+    private final Int2ObjectHashMap<Symbol> symbols = new Int2ObjectHashMap<>();\n+    private final Int2IntHashMap stackTraceIdToFilePositions = new Int2IntHashMap(-1);\n+    private final Long2ObjectHashMap<LazyStackFrame> framesByFrameId = new Long2ObjectHashMap<>();\n+    // used to resolve a symbol with minimal allocations\n+    private final StringBuilder symbolBuilder = new StringBuilder();\n+    @Nullable\n+    private List<WildcardMatcher> excludedClasses;\n+    @Nullable\n+    private List<WildcardMatcher> includedClasses;\n+\n+    /**\n+     * Initializes the parser to make it ready for {@link #getStackTrace(long, boolean, List)} to be called.\n+     *\n+     * @param file            the JFR file to parse\n+     * @param excludedClasses Class names to exclude in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @param includedClasses Class names to include in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void parse(File file, List<WildcardMatcher> excludedClasses, List<WildcardMatcher> includedClasses) throws IOException {\n+        this.excludedClasses = excludedClasses;\n+        this.includedClasses = includedClasses;\n+        try (RandomAccessFile raf = new RandomAccessFile(file, \"r\")) {\n+            FileChannel channel = raf.getChannel();\n+            logger.info(\"Parsing {} ({} bytes)\", file, channel.size());\n+            if (channel.size() > Integer.MAX_VALUE) {\n+                // mapping a file into memory is only possible for chunks of the file which fall into the Integer range (2GB)\n+                // that is because MappedByteBuffers are ByteBuffers which only accept ints in position(int pos)\n+                throw new IllegalArgumentException(\"Input file too large\");\n+            }\n+            this.buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, channel.size());\n+        }\n+        for (byte magicByte : MAGIC_BYTES) {\n+            if (buffer.get() != magicByte) {\n+                throw new IllegalArgumentException(\"Not a JFR file\");\n+            }\n+        }\n+        short major = buffer.getShort();\n+        short minor = buffer.getShort();\n+        if (major != 0 && minor != 9) {\n+            throw new IllegalArgumentException(String.format(\"Can only parse version 0.9. Was %d.%d\", major, minor));\n+        }\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        metadataOffset = (int) buffer.getLong();\n+        eventsOffset = buffer.position();\n+\n+        setPosition(buffer, metadataOffset);\n+        int checkpointOffset = parseMetadata(buffer);\n+        setPosition(buffer, checkpointOffset);\n+        parseCheckpoint(buffer);\n+    }\n+\n+    private int parseMetadata(MappedByteBuffer buffer) throws IOException {\n+        int size = buffer.getInt();\n+        expectEventType(buffer, EventTypeId.EVENT_METADATA);\n+        int checkpointOffsetPosition = size - 16;\n+        setPosition(buffer, buffer.position() + checkpointOffsetPosition);\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        return (int) buffer.getLong();\n+    }\n+\n+    private void expectEventType(MappedByteBuffer buffer, int expectedEventType) throws IOException {\n+        int eventType = buffer.getInt();\n+        if (eventType != expectedEventType) {\n+            throw new IOException(\"Expected \" + expectedEventType + \" but got \" + eventType);\n+        }\n+    }\n+\n+    private void parseCheckpoint(MappedByteBuffer buffer) throws IOException {\n+        buffer.getInt(); // size\n+        expectEventType(buffer, EventTypeId.EVENT_CHECKPOINT);\n+        buffer.getLong(); // stop timestamp\n+        buffer.getLong(); // previous checkpoint - always 0 in async-profiler\n+        while (buffer.position() < metadataOffset) {\n+            parseContentType(buffer);\n+        }\n+    }\n+\n+    private void parseContentType(MappedByteBuffer buffer) throws IOException {\n+        int contentTypeId = buffer.getInt();\n+        logger.debug(\"Parsing content type {}\", contentTypeId);\n+        int count = buffer.getInt();\n+        switch (contentTypeId) {\n+            case ContentTypeId.CONTENT_THREAD:\n+                // currently no thread info\n+                break;\n+            case ContentTypeId.CONTENT_STACKTRACE:\n+                for (int i = 0; i < count; i++) {\n+                    int pos = buffer.position();\n+                    // always an integer\n+                    // see profiler.h\n+                    // MAX_CALLTRACES = 65536\n+                    int stackTraceKey = (int) buffer.getLong();\n+                    this.stackTraceIdToFilePositions.put(stackTraceKey, pos);\n+                    buffer.get(); // truncated\n+                    int numFrames = buffer.getInt();\n+                    int sizeOfFrame = 13;\n+                    setPosition(buffer, buffer.position() + numFrames * sizeOfFrame);\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_CLASS:\n+                for (int i = 0; i < count; i++) {\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    buffer.getLong(); // loader class\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int classNameSymbolId = (int) buffer.getLong();\n+                    classIdToClassNameSymbolId.put(classId, classNameSymbolId); // class name\n+                    buffer.getShort(); // access flags\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_METHOD:\n+                for (int i = 1; i <= count; i++) {\n+                    long id = buffer.getLong();\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int methodNameSymbolId = (int) buffer.getLong();\n+                    framesByFrameId.put(id, new LazyStackFrame(classId, methodNameSymbolId));\n+                    buffer.getLong(); // signature\n+                    buffer.getShort(); // modifiers\n+                    buffer.get(); // hidden\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_SYMBOL:\n+                for (int i = 0; i < count; i++) {\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int symbolId = (int) buffer.getLong();\n+                    int pos = buffer.position();\n+                    symbols.put(symbolId, new Symbol(pos));\n+                    skipString();\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_STATE:\n+                // we're not really interested in the thread states (async-profiler hard-codes state RUNNABLE) anyways\n+                // but we sill have to consume the bytes\n+                for (int i = 1; i <= count; i++) {\n+                    buffer.getShort();\n+                    skipString();\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_FRAME_TYPE:\n+                isJavaFrameType = new boolean[count + 1];\n+                for (int i = 1 ; i <= count; i++) {\n+                    int id = buffer.get();\n+                    if (i != id) {\n+                        throw new IllegalStateException(\"Expecting ids to be incrementing\");\n+                    }\n+                    isJavaFrameType[id] = JAVA_FRAME_TYPES.contains(readUtf8String().toString());\n+                }\n+                break;\n+            default:\n+                throw new IOException(\"Unknown content type \" + contentTypeId);\n+        }\n+    }\n+\n+    private void skipString() {\n+        short stringLength = buffer.getShort();\n+        setPosition(buffer, buffer.position() + stringLength);\n+    }\n+\n+    /**\n+     * Invokes the callback for each stack trace event in the JFR file.\n+     *\n+     * @param callback called for each stack trace event\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void consumeStackTraces(StackTraceConsumer callback) throws IOException {\n+        if (buffer == null) {\n+            throw new IllegalStateException(\"consumeStackTraces was called before parse\");\n+        }\n+        setPosition(buffer, eventsOffset);\n+        while (buffer.position() < metadataOffset) {\n+            int size = buffer.getInt();\n+            int eventType = buffer.getInt();\n+            if (eventType == EventTypeId.EVENT_RECORDING) {\n+                return;\n+            }\n+            if (eventType != EventTypeId.EVENT_EXECUTION_SAMPLE){\n+                throw new IOException(\"Expected \" + EventTypeId.EVENT_EXECUTION_SAMPLE + \" but got \" + eventType);\n+            }\n+            long nanoTime = buffer.getLong();\n+            int tid = buffer.getInt();\n+            long stackTraceId = buffer.getLong();\n+            short threadState = buffer.getShort();\n+            callback.onCallTree(tid, stackTraceId, nanoTime);\n+        }\n+    }\n+\n+    public interface StackTraceConsumer {\n+\n+        /**\n+         * @param threadId     The native thread id for with the event was recorded.\n+         *                     Note that this is not the same as {@link Thread#getId()}.\n+         * @param stackTraceId The id of the stack trace event.\n+         *                     Can be used to resolve the stack trace via {@link #getStackTrace(long, boolean, List)}\n+         * @param nanoTime     The timestamp of the event which can be correlated with {@link System#nanoTime()}\n+         */\n+        void onCallTree(int threadId, long stackTraceId, long nanoTime);\n+    }\n+\n+    /**\n+     * Resolves the stack trace with the given {@code stackTraceId}.\n+     * <p>\n+     * Note that his allocates strings for {@link Symbol#resolved} in case a stack frame has not already been resolved for the current JFR file yet.\n+     * These strings are currently not cached so this can create some GC pressure.\n+     * </p>\n+     *\n+     * @param stackTraceId   The id of the stack traced.\n+     *                       Used to look up the position of the file in which the given stack trace is stored via {@link #stackTraceIdToFilePositions}.\n+     * @param onlyJavaFrames If {@code true}, will only resolve {@code Interpreted}, {@code JIT compiled} and {@code Inlined} frames.\n+     *                       If {@code false}, will also resolve {@code Native}, {@code Kernel} and {@code C++} frames.\n+     * @param stackFrames    The mutable list where the stack frames are written to.\n+     *                       Don't forget to {@link List#clear()} the list before calling this method if the list is reused.\n+     */\n+    public void getStackTrace(long stackTraceId, boolean onlyJavaFrames, List<StackFrame> stackFrames) {\n+        if (buffer == null) {\n+            throw new IllegalStateException(\"getStackTrace was called before parse\");\n+        }\n+        MappedByteBuffer buffer = this.buffer;\n+        int position = buffer.position();\n+        setPosition(buffer, stackTraceIdToFilePositions.get((int) stackTraceId));\n+        long stackTraceIdFromFile = buffer.getLong();\n+        assert stackTraceId == stackTraceIdFromFile;\n+        buffer.get(); // truncated\n+        int numFrames = buffer.getInt();\n+        for (int i = 0; i < numFrames; i++) {\n+            long method = buffer.getLong();\n+            buffer.getInt(); // bci (always set to 0 by async-profiler)\n+            byte frameType = buffer.get();\n+            if (!onlyJavaFrames || isJavaFrameType(frameType)) {\n+                LazyStackFrame lazyStackFrame = framesByFrameId.get(method);\n+                if (lazyStackFrame.isIncluded(this)) {\n+                    StackFrame stackFrame = lazyStackFrame.resolve(this);\n+                    stackFrames.add(stackFrame);\n+                }\n+            }\n+        }\n+        setPosition(buffer, position);\n+    }\n+\n+    private boolean isJavaFrameType(byte frameType) {\n+        return isJavaFrameType[frameType];\n+    }\n+\n+    private StringBuilder resolveSymbol(int pos, boolean replaceSlashWithDot) {\n+        int currentPos = buffer.position();\n+        setPosition(buffer, pos);\n+        try {\n+            return readUtf8String(replaceSlashWithDot);\n+        } finally {\n+            setPosition(buffer, currentPos);\n+        }\n+    }\n+\n+    private boolean isClassIncluded(CharSequence className) {\n+        return WildcardMatcher.isAnyMatch(includedClasses, className) && WildcardMatcher.isNoneMatch(excludedClasses, className);\n+    }\n+\n+    private static void setPosition(MappedByteBuffer buffer, int pos) {\n+        // weird hack because of binary incompatibility introduced in Java 9\n+        // the return type was changed from Buffer to MappedByteBuffer\n+        // linking a method also incorporates the exact return type\n+        ((Buffer) buffer).position(pos);\n+    }\n+\n+    private StackFrame resolveStackFrame(int classId, int methodName) {\n+        Symbol classNameSymbol = symbols.get(classIdToClassNameSymbolId.get(classId));\n+        if (classNameSymbol.isClassNameIncluded(this)) {\n+            String className = classNameSymbol.resolveClassName(this);\n+            String method = symbols.get(methodName).resolve(this);\n+            return new StackFrame(className, Objects.requireNonNull(method));\n+        } else {\n+            return LazyStackFrame.EXCLUDED;\n+        }\n+    }\n+\n+    private StringBuilder readUtf8String() {\n+        return readUtf8String(false);\n+    }\n+\n+    private StringBuilder readUtf8String(boolean replaceSlashWithDot) {\n+        int size = buffer.getShort();\n+        StringBuilder symbolBuilder = this.symbolBuilder;\n+        symbolBuilder.setLength(0);\n+        for (int i = 0; i < size; i++) {\n+            char c = (char) buffer.get();\n+            if (replaceSlashWithDot && c == '/') {\n+                symbolBuilder.append('.');\n+            } else {\n+                symbolBuilder.append(c);\n+            }\n+        }\n+        return symbolBuilder;\n+    }\n+\n+    @Override\n+    public void resetState() {\n+        buffer = null;\n+        eventsOffset = 0;\n+        metadataOffset = 0;\n+        isJavaFrameType = null;\n+        classIdToClassNameSymbolId.clear();\n+        symbols.clear();\n+        stackTraceIdToFilePositions.clear();\n+        framesByFrameId.clear();\n+        symbolBuilder.setLength(0);\n+        excludedClasses = null;\n+        includedClasses = null;\n+    }\n+\n+    private interface EventTypeId {\n+        int EVENT_METADATA           = 0;\n+        int EVENT_CHECKPOINT         = 1;\n+        int EVENT_RECORDING          = 10;\n+        int EVENT_EXECUTION_SAMPLE   = 20;\n+    }\n+\n+    private interface ContentTypeId {\n+        int CONTENT_THREAD      = 7;\n+        int CONTENT_STACKTRACE  = 9;\n+        int CONTENT_CLASS       = 10;\n+        int CONTENT_METHOD      = 32;\n+        int CONTENT_SYMBOL      = 33;\n+        int CONTENT_STATE       = 34;\n+        int CONTENT_FRAME_TYPE  = 47;\n+    }\n+\n+    /**\n+     * Represents a single frame of a stack trace.\n+     * As stack frames are detached from stack traces, the same frame can occur in multiple stack traces.\n+     * That's why within a JFR file, a stack trace is basically represented as an array of pointers to stack frames.\n+     * <p>\n+     * The actual {@link StackFrame} is resolved lazily to avoid allocations when they are not needed.\n+     * That can be the case when not processing stack traces of particular threads, for example.\n+     * The resolved {@link #stackFrame} is then cached so that I/O is avoided when subsequently resolving the same frame.\n+     * </p>\n+     */\n+    private static class LazyStackFrame {\n+\n+        private final static StackFrame EXCLUDED = new StackFrame(\"excluded\", \"excluded\");\n+\n+        private final int classId;\n+        private final int methodName;\n+\n+        @Nullable\n+        private StackFrame stackFrame;\n+\n+        public LazyStackFrame(int classId, int methodName) {\n+            this.classId = classId;\n+            this.methodName = methodName;\n+        }\n+\n+        public StackFrame resolve(JfrParser parser) {\n+            if (stackFrame == null) {\n+                stackFrame = parser.resolveStackFrame(classId, methodName);\n+            }\n+            return stackFrame;\n+        }\n+\n+        /**\n+         * Returns {@code true} when the class name matches the matchers provided via {@link #parse(File, List, List)}\n+         *\n+         * @param parser\n+         * @return\n+         */\n+        public boolean isIncluded(JfrParser parser) {\n+            return resolve(parser) != EXCLUDED;\n+        }\n+    }\n+\n+    /**\n+     * A symbol is a UTF-8 string with an ID, representing a method name or class name, for example.\n+     * There's a specific section in the JFR file which contains all symbols.\n+     * <p>\n+     * Symbols are are {@link #resolve}d lazily to avoid allocations when they are not needed.\n+     * That can be the case when not processing stack traces of particular threads, for example.\n+     * The {@link #resolved} String is then cached so that I/O is avoided when subsequently resolving the same symbol.\n+     * </p>\n+     */\n+    private static class Symbol {\n+        private static final String EXCLUDED = \"3x cluded\";\n+        /**\n+         * The position in the JFR file which holds the symbol\n+         */\n+        private final int pos;\n+        @Nullable\n+        private String resolved;\n+\n+        private Symbol(int pos) {\n+            this.pos = pos;\n+        }\n+\n+        /**\n+         * Resolves a symbol representing a class name from the JFR file ({@link #buffer}).\n+         */\n+        @Nullable\n+        public String resolve(JfrParser parser) {\n+            return resolve(parser, false);\n+        }\n+\n+        /**\n+         * Resolves a symbol representing a class name from the JFR file ({@link #buffer}).\n+         * <p>\n+         * In the JFR file, class names are in their binary form (for example {@code foo/bar/Baz}.\n+         * This methods converts it to the form matching {@link Class#getName()} by replacing the slashes with dots.\n+         * </p>\n+         * <p>\n+         * Returns {@code null} if {@link #isClassNameIncluded(JfrParser)} returns {@code false}\n+         * </p>\n+         */\n+        @Nullable\n+        private String resolveClassName(JfrParser parser) {\n+            return resolve(parser, true);\n+        }\n+\n+        /**\n+         * Returns {@code true} when the class name matches the matchers provided via {@link #parse(File, List, List)}\n+         *\n+         * @param parser\n+         * @return\n+         */\n+        private boolean isClassNameIncluded(JfrParser parser) {\n+            return resolve(parser, true) != EXCLUDED;\n+        }\n+\n+        @Nullable\n+        private String resolve(JfrParser parser, boolean className) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMxMjA4Nw=="}, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 503}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ2NDEzMw==", "bodyText": "yes", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367464133", "createdAt": "2020-01-16T14:57:27Z", "author": {"login": "felixbarny"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "diffHunk": "@@ -0,0 +1,518 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+import co.elastic.apm.agent.profiler.collections.Int2IntHashMap;\n+import co.elastic.apm.agent.profiler.collections.Int2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * Parses the binary JFR file created by async-profiler.\n+ * May not work with JFR files created by an actual flight recorder.\n+ * <p>\n+ * The implementation is tuned with to minimize allocations when parsing a JFR file.\n+ * Most data structures can be reused by first {@linkplain #resetState() resetting the state} and then {@linkplain #parse(File, List, List) parsing}\n+ * another file.\n+ * </p>\n+ * <p>\n+ * The JFR file itself is mapped into memory via a {@link MappedByteBuffer}.\n+ * This does not consume heap memory, the operating system loads pages the file into memory as they are requested.\n+ * Unfortunately, unmapping a {@link MappedByteBuffer} can only be done by letting it be garbage collected.\n+ * </p>\n+ */\n+public class JfrParser implements Recyclable {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(JfrParser.class);\n+\n+    private static final byte[] MAGIC_BYTES = new byte[]{'F', 'L', 'R', '\\0'};\n+    private static final Set<String> JAVA_FRAME_TYPES = new HashSet<>(Arrays.asList(\"Interpreted\", \"JIT compiled\", \"Inlined\"));\n+\n+    @Nullable\n+    private MappedByteBuffer buffer;\n+    private int eventsOffset;\n+    private int metadataOffset;\n+    @Nullable\n+    private boolean[] isJavaFrameType;\n+    private final Int2IntHashMap classIdToClassNameSymbolId = new Int2IntHashMap(-1);\n+    private final Int2ObjectHashMap<Symbol> symbols = new Int2ObjectHashMap<>();\n+    private final Int2IntHashMap stackTraceIdToFilePositions = new Int2IntHashMap(-1);\n+    private final Long2ObjectHashMap<LazyStackFrame> framesByFrameId = new Long2ObjectHashMap<>();\n+    // used to resolve a symbol with minimal allocations\n+    private final StringBuilder symbolBuilder = new StringBuilder();\n+    @Nullable\n+    private List<WildcardMatcher> excludedClasses;\n+    @Nullable\n+    private List<WildcardMatcher> includedClasses;\n+\n+    /**\n+     * Initializes the parser to make it ready for {@link #getStackTrace(long, boolean, List)} to be called.\n+     *\n+     * @param file            the JFR file to parse\n+     * @param excludedClasses Class names to exclude in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @param includedClasses Class names to include in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void parse(File file, List<WildcardMatcher> excludedClasses, List<WildcardMatcher> includedClasses) throws IOException {\n+        this.excludedClasses = excludedClasses;\n+        this.includedClasses = includedClasses;\n+        try (RandomAccessFile raf = new RandomAccessFile(file, \"r\")) {\n+            FileChannel channel = raf.getChannel();\n+            logger.info(\"Parsing {} ({} bytes)\", file, channel.size());\n+            if (channel.size() > Integer.MAX_VALUE) {\n+                // mapping a file into memory is only possible for chunks of the file which fall into the Integer range (2GB)\n+                // that is because MappedByteBuffers are ByteBuffers which only accept ints in position(int pos)\n+                throw new IllegalArgumentException(\"Input file too large\");\n+            }\n+            this.buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, channel.size());\n+        }\n+        for (byte magicByte : MAGIC_BYTES) {\n+            if (buffer.get() != magicByte) {\n+                throw new IllegalArgumentException(\"Not a JFR file\");\n+            }\n+        }\n+        short major = buffer.getShort();\n+        short minor = buffer.getShort();\n+        if (major != 0 && minor != 9) {\n+            throw new IllegalArgumentException(String.format(\"Can only parse version 0.9. Was %d.%d\", major, minor));\n+        }\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        metadataOffset = (int) buffer.getLong();\n+        eventsOffset = buffer.position();\n+\n+        setPosition(buffer, metadataOffset);\n+        int checkpointOffset = parseMetadata(buffer);\n+        setPosition(buffer, checkpointOffset);\n+        parseCheckpoint(buffer);\n+    }\n+\n+    private int parseMetadata(MappedByteBuffer buffer) throws IOException {\n+        int size = buffer.getInt();\n+        expectEventType(buffer, EventTypeId.EVENT_METADATA);\n+        int checkpointOffsetPosition = size - 16;\n+        setPosition(buffer, buffer.position() + checkpointOffsetPosition);\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        return (int) buffer.getLong();\n+    }\n+\n+    private void expectEventType(MappedByteBuffer buffer, int expectedEventType) throws IOException {\n+        int eventType = buffer.getInt();\n+        if (eventType != expectedEventType) {\n+            throw new IOException(\"Expected \" + expectedEventType + \" but got \" + eventType);\n+        }\n+    }\n+\n+    private void parseCheckpoint(MappedByteBuffer buffer) throws IOException {\n+        buffer.getInt(); // size\n+        expectEventType(buffer, EventTypeId.EVENT_CHECKPOINT);\n+        buffer.getLong(); // stop timestamp\n+        buffer.getLong(); // previous checkpoint - always 0 in async-profiler\n+        while (buffer.position() < metadataOffset) {\n+            parseContentType(buffer);\n+        }\n+    }\n+\n+    private void parseContentType(MappedByteBuffer buffer) throws IOException {\n+        int contentTypeId = buffer.getInt();\n+        logger.debug(\"Parsing content type {}\", contentTypeId);\n+        int count = buffer.getInt();\n+        switch (contentTypeId) {\n+            case ContentTypeId.CONTENT_THREAD:\n+                // currently no thread info\n+                break;\n+            case ContentTypeId.CONTENT_STACKTRACE:\n+                for (int i = 0; i < count; i++) {\n+                    int pos = buffer.position();\n+                    // always an integer\n+                    // see profiler.h\n+                    // MAX_CALLTRACES = 65536\n+                    int stackTraceKey = (int) buffer.getLong();\n+                    this.stackTraceIdToFilePositions.put(stackTraceKey, pos);\n+                    buffer.get(); // truncated\n+                    int numFrames = buffer.getInt();\n+                    int sizeOfFrame = 13;\n+                    setPosition(buffer, buffer.position() + numFrames * sizeOfFrame);\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_CLASS:\n+                for (int i = 0; i < count; i++) {\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    buffer.getLong(); // loader class\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int classNameSymbolId = (int) buffer.getLong();\n+                    classIdToClassNameSymbolId.put(classId, classNameSymbolId); // class name\n+                    buffer.getShort(); // access flags\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_METHOD:\n+                for (int i = 1; i <= count; i++) {\n+                    long id = buffer.getLong();\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int methodNameSymbolId = (int) buffer.getLong();\n+                    framesByFrameId.put(id, new LazyStackFrame(classId, methodNameSymbolId));\n+                    buffer.getLong(); // signature\n+                    buffer.getShort(); // modifiers\n+                    buffer.get(); // hidden\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_SYMBOL:\n+                for (int i = 0; i < count; i++) {\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int symbolId = (int) buffer.getLong();\n+                    int pos = buffer.position();\n+                    symbols.put(symbolId, new Symbol(pos));\n+                    skipString();\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_STATE:\n+                // we're not really interested in the thread states (async-profiler hard-codes state RUNNABLE) anyways\n+                // but we sill have to consume the bytes\n+                for (int i = 1; i <= count; i++) {\n+                    buffer.getShort();\n+                    skipString();\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_FRAME_TYPE:\n+                isJavaFrameType = new boolean[count + 1];\n+                for (int i = 1 ; i <= count; i++) {\n+                    int id = buffer.get();\n+                    if (i != id) {\n+                        throw new IllegalStateException(\"Expecting ids to be incrementing\");\n+                    }\n+                    isJavaFrameType[id] = JAVA_FRAME_TYPES.contains(readUtf8String().toString());\n+                }\n+                break;\n+            default:\n+                throw new IOException(\"Unknown content type \" + contentTypeId);\n+        }\n+    }\n+\n+    private void skipString() {\n+        short stringLength = buffer.getShort();\n+        setPosition(buffer, buffer.position() + stringLength);\n+    }\n+\n+    /**\n+     * Invokes the callback for each stack trace event in the JFR file.\n+     *\n+     * @param callback called for each stack trace event\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void consumeStackTraces(StackTraceConsumer callback) throws IOException {\n+        if (buffer == null) {\n+            throw new IllegalStateException(\"consumeStackTraces was called before parse\");\n+        }\n+        setPosition(buffer, eventsOffset);\n+        while (buffer.position() < metadataOffset) {\n+            int size = buffer.getInt();\n+            int eventType = buffer.getInt();\n+            if (eventType == EventTypeId.EVENT_RECORDING) {\n+                return;\n+            }\n+            if (eventType != EventTypeId.EVENT_EXECUTION_SAMPLE){\n+                throw new IOException(\"Expected \" + EventTypeId.EVENT_EXECUTION_SAMPLE + \" but got \" + eventType);\n+            }\n+            long nanoTime = buffer.getLong();\n+            int tid = buffer.getInt();\n+            long stackTraceId = buffer.getLong();\n+            short threadState = buffer.getShort();\n+            callback.onCallTree(tid, stackTraceId, nanoTime);\n+        }\n+    }\n+\n+    public interface StackTraceConsumer {\n+\n+        /**\n+         * @param threadId     The native thread id for with the event was recorded.\n+         *                     Note that this is not the same as {@link Thread#getId()}.\n+         * @param stackTraceId The id of the stack trace event.\n+         *                     Can be used to resolve the stack trace via {@link #getStackTrace(long, boolean, List)}\n+         * @param nanoTime     The timestamp of the event which can be correlated with {@link System#nanoTime()}\n+         */\n+        void onCallTree(int threadId, long stackTraceId, long nanoTime);\n+    }\n+\n+    /**\n+     * Resolves the stack trace with the given {@code stackTraceId}.\n+     * <p>\n+     * Note that his allocates strings for {@link Symbol#resolved} in case a stack frame has not already been resolved for the current JFR file yet.\n+     * These strings are currently not cached so this can create some GC pressure.\n+     * </p>\n+     *\n+     * @param stackTraceId   The id of the stack traced.\n+     *                       Used to look up the position of the file in which the given stack trace is stored via {@link #stackTraceIdToFilePositions}.\n+     * @param onlyJavaFrames If {@code true}, will only resolve {@code Interpreted}, {@code JIT compiled} and {@code Inlined} frames.\n+     *                       If {@code false}, will also resolve {@code Native}, {@code Kernel} and {@code C++} frames.\n+     * @param stackFrames    The mutable list where the stack frames are written to.\n+     *                       Don't forget to {@link List#clear()} the list before calling this method if the list is reused.\n+     */\n+    public void getStackTrace(long stackTraceId, boolean onlyJavaFrames, List<StackFrame> stackFrames) {\n+        if (buffer == null) {\n+            throw new IllegalStateException(\"getStackTrace was called before parse\");\n+        }\n+        MappedByteBuffer buffer = this.buffer;\n+        int position = buffer.position();\n+        setPosition(buffer, stackTraceIdToFilePositions.get((int) stackTraceId));\n+        long stackTraceIdFromFile = buffer.getLong();\n+        assert stackTraceId == stackTraceIdFromFile;\n+        buffer.get(); // truncated\n+        int numFrames = buffer.getInt();\n+        for (int i = 0; i < numFrames; i++) {\n+            long method = buffer.getLong();\n+            buffer.getInt(); // bci (always set to 0 by async-profiler)\n+            byte frameType = buffer.get();\n+            if (!onlyJavaFrames || isJavaFrameType(frameType)) {\n+                LazyStackFrame lazyStackFrame = framesByFrameId.get(method);\n+                if (lazyStackFrame.isIncluded(this)) {\n+                    StackFrame stackFrame = lazyStackFrame.resolve(this);\n+                    stackFrames.add(stackFrame);\n+                }\n+            }\n+        }\n+        setPosition(buffer, position);\n+    }\n+\n+    private boolean isJavaFrameType(byte frameType) {\n+        return isJavaFrameType[frameType];\n+    }\n+\n+    private StringBuilder resolveSymbol(int pos, boolean replaceSlashWithDot) {\n+        int currentPos = buffer.position();\n+        setPosition(buffer, pos);\n+        try {\n+            return readUtf8String(replaceSlashWithDot);\n+        } finally {\n+            setPosition(buffer, currentPos);\n+        }\n+    }\n+\n+    private boolean isClassIncluded(CharSequence className) {\n+        return WildcardMatcher.isAnyMatch(includedClasses, className) && WildcardMatcher.isNoneMatch(excludedClasses, className);\n+    }\n+\n+    private static void setPosition(MappedByteBuffer buffer, int pos) {\n+        // weird hack because of binary incompatibility introduced in Java 9\n+        // the return type was changed from Buffer to MappedByteBuffer\n+        // linking a method also incorporates the exact return type\n+        ((Buffer) buffer).position(pos);\n+    }\n+\n+    private StackFrame resolveStackFrame(int classId, int methodName) {\n+        Symbol classNameSymbol = symbols.get(classIdToClassNameSymbolId.get(classId));\n+        if (classNameSymbol.isClassNameIncluded(this)) {\n+            String className = classNameSymbol.resolveClassName(this);\n+            String method = symbols.get(methodName).resolve(this);\n+            return new StackFrame(className, Objects.requireNonNull(method));\n+        } else {\n+            return LazyStackFrame.EXCLUDED;\n+        }\n+    }\n+\n+    private StringBuilder readUtf8String() {\n+        return readUtf8String(false);\n+    }\n+\n+    private StringBuilder readUtf8String(boolean replaceSlashWithDot) {\n+        int size = buffer.getShort();\n+        StringBuilder symbolBuilder = this.symbolBuilder;\n+        symbolBuilder.setLength(0);\n+        for (int i = 0; i < size; i++) {\n+            char c = (char) buffer.get();\n+            if (replaceSlashWithDot && c == '/') {\n+                symbolBuilder.append('.');\n+            } else {\n+                symbolBuilder.append(c);\n+            }\n+        }\n+        return symbolBuilder;\n+    }\n+\n+    @Override\n+    public void resetState() {\n+        buffer = null;\n+        eventsOffset = 0;\n+        metadataOffset = 0;\n+        isJavaFrameType = null;\n+        classIdToClassNameSymbolId.clear();\n+        symbols.clear();\n+        stackTraceIdToFilePositions.clear();\n+        framesByFrameId.clear();\n+        symbolBuilder.setLength(0);\n+        excludedClasses = null;\n+        includedClasses = null;\n+    }\n+\n+    private interface EventTypeId {\n+        int EVENT_METADATA           = 0;\n+        int EVENT_CHECKPOINT         = 1;\n+        int EVENT_RECORDING          = 10;\n+        int EVENT_EXECUTION_SAMPLE   = 20;\n+    }\n+\n+    private interface ContentTypeId {\n+        int CONTENT_THREAD      = 7;\n+        int CONTENT_STACKTRACE  = 9;\n+        int CONTENT_CLASS       = 10;\n+        int CONTENT_METHOD      = 32;\n+        int CONTENT_SYMBOL      = 33;\n+        int CONTENT_STATE       = 34;\n+        int CONTENT_FRAME_TYPE  = 47;\n+    }\n+\n+    /**\n+     * Represents a single frame of a stack trace.\n+     * As stack frames are detached from stack traces, the same frame can occur in multiple stack traces.\n+     * That's why within a JFR file, a stack trace is basically represented as an array of pointers to stack frames.\n+     * <p>\n+     * The actual {@link StackFrame} is resolved lazily to avoid allocations when they are not needed.\n+     * That can be the case when not processing stack traces of particular threads, for example.\n+     * The resolved {@link #stackFrame} is then cached so that I/O is avoided when subsequently resolving the same frame.\n+     * </p>\n+     */\n+    private static class LazyStackFrame {\n+\n+        private final static StackFrame EXCLUDED = new StackFrame(\"excluded\", \"excluded\");\n+\n+        private final int classId;\n+        private final int methodName;\n+\n+        @Nullable\n+        private StackFrame stackFrame;\n+\n+        public LazyStackFrame(int classId, int methodName) {\n+            this.classId = classId;\n+            this.methodName = methodName;\n+        }\n+\n+        public StackFrame resolve(JfrParser parser) {\n+            if (stackFrame == null) {\n+                stackFrame = parser.resolveStackFrame(classId, methodName);\n+            }\n+            return stackFrame;\n+        }\n+\n+        /**\n+         * Returns {@code true} when the class name matches the matchers provided via {@link #parse(File, List, List)}\n+         *\n+         * @param parser\n+         * @return\n+         */\n+        public boolean isIncluded(JfrParser parser) {\n+            return resolve(parser) != EXCLUDED;\n+        }\n+    }\n+\n+    /**\n+     * A symbol is a UTF-8 string with an ID, representing a method name or class name, for example.\n+     * There's a specific section in the JFR file which contains all symbols.\n+     * <p>\n+     * Symbols are are {@link #resolve}d lazily to avoid allocations when they are not needed.\n+     * That can be the case when not processing stack traces of particular threads, for example.\n+     * The {@link #resolved} String is then cached so that I/O is avoided when subsequently resolving the same symbol.\n+     * </p>\n+     */\n+    private static class Symbol {\n+        private static final String EXCLUDED = \"3x cluded\";\n+        /**\n+         * The position in the JFR file which holds the symbol\n+         */\n+        private final int pos;\n+        @Nullable\n+        private String resolved;\n+\n+        private Symbol(int pos) {\n+            this.pos = pos;\n+        }\n+\n+        /**\n+         * Resolves a symbol representing a class name from the JFR file ({@link #buffer}).\n+         */\n+        @Nullable\n+        public String resolve(JfrParser parser) {\n+            return resolve(parser, false);\n+        }\n+\n+        /**\n+         * Resolves a symbol representing a class name from the JFR file ({@link #buffer}).\n+         * <p>\n+         * In the JFR file, class names are in their binary form (for example {@code foo/bar/Baz}.\n+         * This methods converts it to the form matching {@link Class#getName()} by replacing the slashes with dots.\n+         * </p>\n+         * <p>\n+         * Returns {@code null} if {@link #isClassNameIncluded(JfrParser)} returns {@code false}\n+         * </p>\n+         */\n+        @Nullable\n+        private String resolveClassName(JfrParser parser) {\n+            return resolve(parser, true);\n+        }\n+\n+        /**\n+         * Returns {@code true} when the class name matches the matchers provided via {@link #parse(File, List, List)}\n+         *\n+         * @param parser\n+         * @return\n+         */\n+        private boolean isClassNameIncluded(JfrParser parser) {\n+            return resolve(parser, true) != EXCLUDED;\n+        }\n+\n+        @Nullable\n+        private String resolve(JfrParser parser, boolean className) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMxMjA4Nw=="}, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 503}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MzE3MzAwOnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxMjozODowMFrOFdWDyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxNDozNTozMlrOFebb9A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMxNDQ0Mg==", "bodyText": "Consider pooling StackFrames and use them with StringBuilders instead of Strings for class and method names, into which you can directly resolve from the file.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366314442", "createdAt": "2020-01-14T12:38:00Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "diffHunk": "@@ -0,0 +1,518 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+import co.elastic.apm.agent.profiler.collections.Int2IntHashMap;\n+import co.elastic.apm.agent.profiler.collections.Int2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * Parses the binary JFR file created by async-profiler.\n+ * May not work with JFR files created by an actual flight recorder.\n+ * <p>\n+ * The implementation is tuned with to minimize allocations when parsing a JFR file.\n+ * Most data structures can be reused by first {@linkplain #resetState() resetting the state} and then {@linkplain #parse(File, List, List) parsing}\n+ * another file.\n+ * </p>\n+ * <p>\n+ * The JFR file itself is mapped into memory via a {@link MappedByteBuffer}.\n+ * This does not consume heap memory, the operating system loads pages the file into memory as they are requested.\n+ * Unfortunately, unmapping a {@link MappedByteBuffer} can only be done by letting it be garbage collected.\n+ * </p>\n+ */\n+public class JfrParser implements Recyclable {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(JfrParser.class);\n+\n+    private static final byte[] MAGIC_BYTES = new byte[]{'F', 'L', 'R', '\\0'};\n+    private static final Set<String> JAVA_FRAME_TYPES = new HashSet<>(Arrays.asList(\"Interpreted\", \"JIT compiled\", \"Inlined\"));\n+\n+    @Nullable\n+    private MappedByteBuffer buffer;\n+    private int eventsOffset;\n+    private int metadataOffset;\n+    @Nullable\n+    private boolean[] isJavaFrameType;\n+    private final Int2IntHashMap classIdToClassNameSymbolId = new Int2IntHashMap(-1);\n+    private final Int2ObjectHashMap<Symbol> symbols = new Int2ObjectHashMap<>();\n+    private final Int2IntHashMap stackTraceIdToFilePositions = new Int2IntHashMap(-1);\n+    private final Long2ObjectHashMap<LazyStackFrame> framesByFrameId = new Long2ObjectHashMap<>();\n+    // used to resolve a symbol with minimal allocations\n+    private final StringBuilder symbolBuilder = new StringBuilder();\n+    @Nullable\n+    private List<WildcardMatcher> excludedClasses;\n+    @Nullable\n+    private List<WildcardMatcher> includedClasses;\n+\n+    /**\n+     * Initializes the parser to make it ready for {@link #getStackTrace(long, boolean, List)} to be called.\n+     *\n+     * @param file            the JFR file to parse\n+     * @param excludedClasses Class names to exclude in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @param includedClasses Class names to include in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void parse(File file, List<WildcardMatcher> excludedClasses, List<WildcardMatcher> includedClasses) throws IOException {\n+        this.excludedClasses = excludedClasses;\n+        this.includedClasses = includedClasses;\n+        try (RandomAccessFile raf = new RandomAccessFile(file, \"r\")) {\n+            FileChannel channel = raf.getChannel();\n+            logger.info(\"Parsing {} ({} bytes)\", file, channel.size());\n+            if (channel.size() > Integer.MAX_VALUE) {\n+                // mapping a file into memory is only possible for chunks of the file which fall into the Integer range (2GB)\n+                // that is because MappedByteBuffers are ByteBuffers which only accept ints in position(int pos)\n+                throw new IllegalArgumentException(\"Input file too large\");\n+            }\n+            this.buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, channel.size());\n+        }\n+        for (byte magicByte : MAGIC_BYTES) {\n+            if (buffer.get() != magicByte) {\n+                throw new IllegalArgumentException(\"Not a JFR file\");\n+            }\n+        }\n+        short major = buffer.getShort();\n+        short minor = buffer.getShort();\n+        if (major != 0 && minor != 9) {\n+            throw new IllegalArgumentException(String.format(\"Can only parse version 0.9. Was %d.%d\", major, minor));\n+        }\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        metadataOffset = (int) buffer.getLong();\n+        eventsOffset = buffer.position();\n+\n+        setPosition(buffer, metadataOffset);\n+        int checkpointOffset = parseMetadata(buffer);\n+        setPosition(buffer, checkpointOffset);\n+        parseCheckpoint(buffer);\n+    }\n+\n+    private int parseMetadata(MappedByteBuffer buffer) throws IOException {\n+        int size = buffer.getInt();\n+        expectEventType(buffer, EventTypeId.EVENT_METADATA);\n+        int checkpointOffsetPosition = size - 16;\n+        setPosition(buffer, buffer.position() + checkpointOffsetPosition);\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        return (int) buffer.getLong();\n+    }\n+\n+    private void expectEventType(MappedByteBuffer buffer, int expectedEventType) throws IOException {\n+        int eventType = buffer.getInt();\n+        if (eventType != expectedEventType) {\n+            throw new IOException(\"Expected \" + expectedEventType + \" but got \" + eventType);\n+        }\n+    }\n+\n+    private void parseCheckpoint(MappedByteBuffer buffer) throws IOException {\n+        buffer.getInt(); // size\n+        expectEventType(buffer, EventTypeId.EVENT_CHECKPOINT);\n+        buffer.getLong(); // stop timestamp\n+        buffer.getLong(); // previous checkpoint - always 0 in async-profiler\n+        while (buffer.position() < metadataOffset) {\n+            parseContentType(buffer);\n+        }\n+    }\n+\n+    private void parseContentType(MappedByteBuffer buffer) throws IOException {\n+        int contentTypeId = buffer.getInt();\n+        logger.debug(\"Parsing content type {}\", contentTypeId);\n+        int count = buffer.getInt();\n+        switch (contentTypeId) {\n+            case ContentTypeId.CONTENT_THREAD:\n+                // currently no thread info\n+                break;\n+            case ContentTypeId.CONTENT_STACKTRACE:\n+                for (int i = 0; i < count; i++) {\n+                    int pos = buffer.position();\n+                    // always an integer\n+                    // see profiler.h\n+                    // MAX_CALLTRACES = 65536\n+                    int stackTraceKey = (int) buffer.getLong();\n+                    this.stackTraceIdToFilePositions.put(stackTraceKey, pos);\n+                    buffer.get(); // truncated\n+                    int numFrames = buffer.getInt();\n+                    int sizeOfFrame = 13;\n+                    setPosition(buffer, buffer.position() + numFrames * sizeOfFrame);\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_CLASS:\n+                for (int i = 0; i < count; i++) {\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    buffer.getLong(); // loader class\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int classNameSymbolId = (int) buffer.getLong();\n+                    classIdToClassNameSymbolId.put(classId, classNameSymbolId); // class name\n+                    buffer.getShort(); // access flags\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_METHOD:\n+                for (int i = 1; i <= count; i++) {\n+                    long id = buffer.getLong();\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int methodNameSymbolId = (int) buffer.getLong();\n+                    framesByFrameId.put(id, new LazyStackFrame(classId, methodNameSymbolId));\n+                    buffer.getLong(); // signature\n+                    buffer.getShort(); // modifiers\n+                    buffer.get(); // hidden\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_SYMBOL:\n+                for (int i = 0; i < count; i++) {\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int symbolId = (int) buffer.getLong();\n+                    int pos = buffer.position();\n+                    symbols.put(symbolId, new Symbol(pos));\n+                    skipString();\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_STATE:\n+                // we're not really interested in the thread states (async-profiler hard-codes state RUNNABLE) anyways\n+                // but we sill have to consume the bytes\n+                for (int i = 1; i <= count; i++) {\n+                    buffer.getShort();\n+                    skipString();\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_FRAME_TYPE:\n+                isJavaFrameType = new boolean[count + 1];\n+                for (int i = 1 ; i <= count; i++) {\n+                    int id = buffer.get();\n+                    if (i != id) {\n+                        throw new IllegalStateException(\"Expecting ids to be incrementing\");\n+                    }\n+                    isJavaFrameType[id] = JAVA_FRAME_TYPES.contains(readUtf8String().toString());\n+                }\n+                break;\n+            default:\n+                throw new IOException(\"Unknown content type \" + contentTypeId);\n+        }\n+    }\n+\n+    private void skipString() {\n+        short stringLength = buffer.getShort();\n+        setPosition(buffer, buffer.position() + stringLength);\n+    }\n+\n+    /**\n+     * Invokes the callback for each stack trace event in the JFR file.\n+     *\n+     * @param callback called for each stack trace event\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void consumeStackTraces(StackTraceConsumer callback) throws IOException {\n+        if (buffer == null) {\n+            throw new IllegalStateException(\"consumeStackTraces was called before parse\");\n+        }\n+        setPosition(buffer, eventsOffset);\n+        while (buffer.position() < metadataOffset) {\n+            int size = buffer.getInt();\n+            int eventType = buffer.getInt();\n+            if (eventType == EventTypeId.EVENT_RECORDING) {\n+                return;\n+            }\n+            if (eventType != EventTypeId.EVENT_EXECUTION_SAMPLE){\n+                throw new IOException(\"Expected \" + EventTypeId.EVENT_EXECUTION_SAMPLE + \" but got \" + eventType);\n+            }\n+            long nanoTime = buffer.getLong();\n+            int tid = buffer.getInt();\n+            long stackTraceId = buffer.getLong();\n+            short threadState = buffer.getShort();\n+            callback.onCallTree(tid, stackTraceId, nanoTime);\n+        }\n+    }\n+\n+    public interface StackTraceConsumer {\n+\n+        /**\n+         * @param threadId     The native thread id for with the event was recorded.\n+         *                     Note that this is not the same as {@link Thread#getId()}.\n+         * @param stackTraceId The id of the stack trace event.\n+         *                     Can be used to resolve the stack trace via {@link #getStackTrace(long, boolean, List)}\n+         * @param nanoTime     The timestamp of the event which can be correlated with {@link System#nanoTime()}\n+         */\n+        void onCallTree(int threadId, long stackTraceId, long nanoTime);\n+    }\n+\n+    /**\n+     * Resolves the stack trace with the given {@code stackTraceId}.\n+     * <p>\n+     * Note that his allocates strings for {@link Symbol#resolved} in case a stack frame has not already been resolved for the current JFR file yet.\n+     * These strings are currently not cached so this can create some GC pressure.\n+     * </p>\n+     *\n+     * @param stackTraceId   The id of the stack traced.\n+     *                       Used to look up the position of the file in which the given stack trace is stored via {@link #stackTraceIdToFilePositions}.\n+     * @param onlyJavaFrames If {@code true}, will only resolve {@code Interpreted}, {@code JIT compiled} and {@code Inlined} frames.\n+     *                       If {@code false}, will also resolve {@code Native}, {@code Kernel} and {@code C++} frames.\n+     * @param stackFrames    The mutable list where the stack frames are written to.\n+     *                       Don't forget to {@link List#clear()} the list before calling this method if the list is reused.\n+     */\n+    public void getStackTrace(long stackTraceId, boolean onlyJavaFrames, List<StackFrame> stackFrames) {\n+        if (buffer == null) {\n+            throw new IllegalStateException(\"getStackTrace was called before parse\");\n+        }\n+        MappedByteBuffer buffer = this.buffer;\n+        int position = buffer.position();\n+        setPosition(buffer, stackTraceIdToFilePositions.get((int) stackTraceId));\n+        long stackTraceIdFromFile = buffer.getLong();\n+        assert stackTraceId == stackTraceIdFromFile;\n+        buffer.get(); // truncated\n+        int numFrames = buffer.getInt();\n+        for (int i = 0; i < numFrames; i++) {\n+            long method = buffer.getLong();\n+            buffer.getInt(); // bci (always set to 0 by async-profiler)\n+            byte frameType = buffer.get();\n+            if (!onlyJavaFrames || isJavaFrameType(frameType)) {\n+                LazyStackFrame lazyStackFrame = framesByFrameId.get(method);\n+                if (lazyStackFrame.isIncluded(this)) {\n+                    StackFrame stackFrame = lazyStackFrame.resolve(this);\n+                    stackFrames.add(stackFrame);\n+                }\n+            }\n+        }\n+        setPosition(buffer, position);\n+    }\n+\n+    private boolean isJavaFrameType(byte frameType) {\n+        return isJavaFrameType[frameType];\n+    }\n+\n+    private StringBuilder resolveSymbol(int pos, boolean replaceSlashWithDot) {\n+        int currentPos = buffer.position();\n+        setPosition(buffer, pos);\n+        try {\n+            return readUtf8String(replaceSlashWithDot);\n+        } finally {\n+            setPosition(buffer, currentPos);\n+        }\n+    }\n+\n+    private boolean isClassIncluded(CharSequence className) {\n+        return WildcardMatcher.isAnyMatch(includedClasses, className) && WildcardMatcher.isNoneMatch(excludedClasses, className);\n+    }\n+\n+    private static void setPosition(MappedByteBuffer buffer, int pos) {\n+        // weird hack because of binary incompatibility introduced in Java 9\n+        // the return type was changed from Buffer to MappedByteBuffer\n+        // linking a method also incorporates the exact return type\n+        ((Buffer) buffer).position(pos);\n+    }\n+\n+    private StackFrame resolveStackFrame(int classId, int methodName) {\n+        Symbol classNameSymbol = symbols.get(classIdToClassNameSymbolId.get(classId));\n+        if (classNameSymbol.isClassNameIncluded(this)) {\n+            String className = classNameSymbol.resolveClassName(this);\n+            String method = symbols.get(methodName).resolve(this);\n+            return new StackFrame(className, Objects.requireNonNull(method));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 347}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQzNTA4Mw==", "bodyText": "and use them with StringBuilders instead of Strings for class and method names, into which you can directly resolve from the file.\n\nThat's probably going to use more memory as the majority of symbols is likely to be unresolved. But pooling the strings and the frames separately could be a nice improvement.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367435083", "createdAt": "2020-01-16T14:06:38Z", "author": {"login": "felixbarny"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "diffHunk": "@@ -0,0 +1,518 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+import co.elastic.apm.agent.profiler.collections.Int2IntHashMap;\n+import co.elastic.apm.agent.profiler.collections.Int2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * Parses the binary JFR file created by async-profiler.\n+ * May not work with JFR files created by an actual flight recorder.\n+ * <p>\n+ * The implementation is tuned with to minimize allocations when parsing a JFR file.\n+ * Most data structures can be reused by first {@linkplain #resetState() resetting the state} and then {@linkplain #parse(File, List, List) parsing}\n+ * another file.\n+ * </p>\n+ * <p>\n+ * The JFR file itself is mapped into memory via a {@link MappedByteBuffer}.\n+ * This does not consume heap memory, the operating system loads pages the file into memory as they are requested.\n+ * Unfortunately, unmapping a {@link MappedByteBuffer} can only be done by letting it be garbage collected.\n+ * </p>\n+ */\n+public class JfrParser implements Recyclable {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(JfrParser.class);\n+\n+    private static final byte[] MAGIC_BYTES = new byte[]{'F', 'L', 'R', '\\0'};\n+    private static final Set<String> JAVA_FRAME_TYPES = new HashSet<>(Arrays.asList(\"Interpreted\", \"JIT compiled\", \"Inlined\"));\n+\n+    @Nullable\n+    private MappedByteBuffer buffer;\n+    private int eventsOffset;\n+    private int metadataOffset;\n+    @Nullable\n+    private boolean[] isJavaFrameType;\n+    private final Int2IntHashMap classIdToClassNameSymbolId = new Int2IntHashMap(-1);\n+    private final Int2ObjectHashMap<Symbol> symbols = new Int2ObjectHashMap<>();\n+    private final Int2IntHashMap stackTraceIdToFilePositions = new Int2IntHashMap(-1);\n+    private final Long2ObjectHashMap<LazyStackFrame> framesByFrameId = new Long2ObjectHashMap<>();\n+    // used to resolve a symbol with minimal allocations\n+    private final StringBuilder symbolBuilder = new StringBuilder();\n+    @Nullable\n+    private List<WildcardMatcher> excludedClasses;\n+    @Nullable\n+    private List<WildcardMatcher> includedClasses;\n+\n+    /**\n+     * Initializes the parser to make it ready for {@link #getStackTrace(long, boolean, List)} to be called.\n+     *\n+     * @param file            the JFR file to parse\n+     * @param excludedClasses Class names to exclude in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @param includedClasses Class names to include in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void parse(File file, List<WildcardMatcher> excludedClasses, List<WildcardMatcher> includedClasses) throws IOException {\n+        this.excludedClasses = excludedClasses;\n+        this.includedClasses = includedClasses;\n+        try (RandomAccessFile raf = new RandomAccessFile(file, \"r\")) {\n+            FileChannel channel = raf.getChannel();\n+            logger.info(\"Parsing {} ({} bytes)\", file, channel.size());\n+            if (channel.size() > Integer.MAX_VALUE) {\n+                // mapping a file into memory is only possible for chunks of the file which fall into the Integer range (2GB)\n+                // that is because MappedByteBuffers are ByteBuffers which only accept ints in position(int pos)\n+                throw new IllegalArgumentException(\"Input file too large\");\n+            }\n+            this.buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, channel.size());\n+        }\n+        for (byte magicByte : MAGIC_BYTES) {\n+            if (buffer.get() != magicByte) {\n+                throw new IllegalArgumentException(\"Not a JFR file\");\n+            }\n+        }\n+        short major = buffer.getShort();\n+        short minor = buffer.getShort();\n+        if (major != 0 && minor != 9) {\n+            throw new IllegalArgumentException(String.format(\"Can only parse version 0.9. Was %d.%d\", major, minor));\n+        }\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        metadataOffset = (int) buffer.getLong();\n+        eventsOffset = buffer.position();\n+\n+        setPosition(buffer, metadataOffset);\n+        int checkpointOffset = parseMetadata(buffer);\n+        setPosition(buffer, checkpointOffset);\n+        parseCheckpoint(buffer);\n+    }\n+\n+    private int parseMetadata(MappedByteBuffer buffer) throws IOException {\n+        int size = buffer.getInt();\n+        expectEventType(buffer, EventTypeId.EVENT_METADATA);\n+        int checkpointOffsetPosition = size - 16;\n+        setPosition(buffer, buffer.position() + checkpointOffsetPosition);\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        return (int) buffer.getLong();\n+    }\n+\n+    private void expectEventType(MappedByteBuffer buffer, int expectedEventType) throws IOException {\n+        int eventType = buffer.getInt();\n+        if (eventType != expectedEventType) {\n+            throw new IOException(\"Expected \" + expectedEventType + \" but got \" + eventType);\n+        }\n+    }\n+\n+    private void parseCheckpoint(MappedByteBuffer buffer) throws IOException {\n+        buffer.getInt(); // size\n+        expectEventType(buffer, EventTypeId.EVENT_CHECKPOINT);\n+        buffer.getLong(); // stop timestamp\n+        buffer.getLong(); // previous checkpoint - always 0 in async-profiler\n+        while (buffer.position() < metadataOffset) {\n+            parseContentType(buffer);\n+        }\n+    }\n+\n+    private void parseContentType(MappedByteBuffer buffer) throws IOException {\n+        int contentTypeId = buffer.getInt();\n+        logger.debug(\"Parsing content type {}\", contentTypeId);\n+        int count = buffer.getInt();\n+        switch (contentTypeId) {\n+            case ContentTypeId.CONTENT_THREAD:\n+                // currently no thread info\n+                break;\n+            case ContentTypeId.CONTENT_STACKTRACE:\n+                for (int i = 0; i < count; i++) {\n+                    int pos = buffer.position();\n+                    // always an integer\n+                    // see profiler.h\n+                    // MAX_CALLTRACES = 65536\n+                    int stackTraceKey = (int) buffer.getLong();\n+                    this.stackTraceIdToFilePositions.put(stackTraceKey, pos);\n+                    buffer.get(); // truncated\n+                    int numFrames = buffer.getInt();\n+                    int sizeOfFrame = 13;\n+                    setPosition(buffer, buffer.position() + numFrames * sizeOfFrame);\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_CLASS:\n+                for (int i = 0; i < count; i++) {\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    buffer.getLong(); // loader class\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int classNameSymbolId = (int) buffer.getLong();\n+                    classIdToClassNameSymbolId.put(classId, classNameSymbolId); // class name\n+                    buffer.getShort(); // access flags\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_METHOD:\n+                for (int i = 1; i <= count; i++) {\n+                    long id = buffer.getLong();\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int methodNameSymbolId = (int) buffer.getLong();\n+                    framesByFrameId.put(id, new LazyStackFrame(classId, methodNameSymbolId));\n+                    buffer.getLong(); // signature\n+                    buffer.getShort(); // modifiers\n+                    buffer.get(); // hidden\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_SYMBOL:\n+                for (int i = 0; i < count; i++) {\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int symbolId = (int) buffer.getLong();\n+                    int pos = buffer.position();\n+                    symbols.put(symbolId, new Symbol(pos));\n+                    skipString();\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_STATE:\n+                // we're not really interested in the thread states (async-profiler hard-codes state RUNNABLE) anyways\n+                // but we sill have to consume the bytes\n+                for (int i = 1; i <= count; i++) {\n+                    buffer.getShort();\n+                    skipString();\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_FRAME_TYPE:\n+                isJavaFrameType = new boolean[count + 1];\n+                for (int i = 1 ; i <= count; i++) {\n+                    int id = buffer.get();\n+                    if (i != id) {\n+                        throw new IllegalStateException(\"Expecting ids to be incrementing\");\n+                    }\n+                    isJavaFrameType[id] = JAVA_FRAME_TYPES.contains(readUtf8String().toString());\n+                }\n+                break;\n+            default:\n+                throw new IOException(\"Unknown content type \" + contentTypeId);\n+        }\n+    }\n+\n+    private void skipString() {\n+        short stringLength = buffer.getShort();\n+        setPosition(buffer, buffer.position() + stringLength);\n+    }\n+\n+    /**\n+     * Invokes the callback for each stack trace event in the JFR file.\n+     *\n+     * @param callback called for each stack trace event\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void consumeStackTraces(StackTraceConsumer callback) throws IOException {\n+        if (buffer == null) {\n+            throw new IllegalStateException(\"consumeStackTraces was called before parse\");\n+        }\n+        setPosition(buffer, eventsOffset);\n+        while (buffer.position() < metadataOffset) {\n+            int size = buffer.getInt();\n+            int eventType = buffer.getInt();\n+            if (eventType == EventTypeId.EVENT_RECORDING) {\n+                return;\n+            }\n+            if (eventType != EventTypeId.EVENT_EXECUTION_SAMPLE){\n+                throw new IOException(\"Expected \" + EventTypeId.EVENT_EXECUTION_SAMPLE + \" but got \" + eventType);\n+            }\n+            long nanoTime = buffer.getLong();\n+            int tid = buffer.getInt();\n+            long stackTraceId = buffer.getLong();\n+            short threadState = buffer.getShort();\n+            callback.onCallTree(tid, stackTraceId, nanoTime);\n+        }\n+    }\n+\n+    public interface StackTraceConsumer {\n+\n+        /**\n+         * @param threadId     The native thread id for with the event was recorded.\n+         *                     Note that this is not the same as {@link Thread#getId()}.\n+         * @param stackTraceId The id of the stack trace event.\n+         *                     Can be used to resolve the stack trace via {@link #getStackTrace(long, boolean, List)}\n+         * @param nanoTime     The timestamp of the event which can be correlated with {@link System#nanoTime()}\n+         */\n+        void onCallTree(int threadId, long stackTraceId, long nanoTime);\n+    }\n+\n+    /**\n+     * Resolves the stack trace with the given {@code stackTraceId}.\n+     * <p>\n+     * Note that his allocates strings for {@link Symbol#resolved} in case a stack frame has not already been resolved for the current JFR file yet.\n+     * These strings are currently not cached so this can create some GC pressure.\n+     * </p>\n+     *\n+     * @param stackTraceId   The id of the stack traced.\n+     *                       Used to look up the position of the file in which the given stack trace is stored via {@link #stackTraceIdToFilePositions}.\n+     * @param onlyJavaFrames If {@code true}, will only resolve {@code Interpreted}, {@code JIT compiled} and {@code Inlined} frames.\n+     *                       If {@code false}, will also resolve {@code Native}, {@code Kernel} and {@code C++} frames.\n+     * @param stackFrames    The mutable list where the stack frames are written to.\n+     *                       Don't forget to {@link List#clear()} the list before calling this method if the list is reused.\n+     */\n+    public void getStackTrace(long stackTraceId, boolean onlyJavaFrames, List<StackFrame> stackFrames) {\n+        if (buffer == null) {\n+            throw new IllegalStateException(\"getStackTrace was called before parse\");\n+        }\n+        MappedByteBuffer buffer = this.buffer;\n+        int position = buffer.position();\n+        setPosition(buffer, stackTraceIdToFilePositions.get((int) stackTraceId));\n+        long stackTraceIdFromFile = buffer.getLong();\n+        assert stackTraceId == stackTraceIdFromFile;\n+        buffer.get(); // truncated\n+        int numFrames = buffer.getInt();\n+        for (int i = 0; i < numFrames; i++) {\n+            long method = buffer.getLong();\n+            buffer.getInt(); // bci (always set to 0 by async-profiler)\n+            byte frameType = buffer.get();\n+            if (!onlyJavaFrames || isJavaFrameType(frameType)) {\n+                LazyStackFrame lazyStackFrame = framesByFrameId.get(method);\n+                if (lazyStackFrame.isIncluded(this)) {\n+                    StackFrame stackFrame = lazyStackFrame.resolve(this);\n+                    stackFrames.add(stackFrame);\n+                }\n+            }\n+        }\n+        setPosition(buffer, position);\n+    }\n+\n+    private boolean isJavaFrameType(byte frameType) {\n+        return isJavaFrameType[frameType];\n+    }\n+\n+    private StringBuilder resolveSymbol(int pos, boolean replaceSlashWithDot) {\n+        int currentPos = buffer.position();\n+        setPosition(buffer, pos);\n+        try {\n+            return readUtf8String(replaceSlashWithDot);\n+        } finally {\n+            setPosition(buffer, currentPos);\n+        }\n+    }\n+\n+    private boolean isClassIncluded(CharSequence className) {\n+        return WildcardMatcher.isAnyMatch(includedClasses, className) && WildcardMatcher.isNoneMatch(excludedClasses, className);\n+    }\n+\n+    private static void setPosition(MappedByteBuffer buffer, int pos) {\n+        // weird hack because of binary incompatibility introduced in Java 9\n+        // the return type was changed from Buffer to MappedByteBuffer\n+        // linking a method also incorporates the exact return type\n+        ((Buffer) buffer).position(pos);\n+    }\n+\n+    private StackFrame resolveStackFrame(int classId, int methodName) {\n+        Symbol classNameSymbol = symbols.get(classIdToClassNameSymbolId.get(classId));\n+        if (classNameSymbol.isClassNameIncluded(this)) {\n+            String className = classNameSymbol.resolveClassName(this);\n+            String method = symbols.get(methodName).resolve(this);\n+            return new StackFrame(className, Objects.requireNonNull(method));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMxNDQ0Mg=="}, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 347}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ1MTEyNA==", "bodyText": "Or pool those StringBuilders, as suggested in #981 (comment) \ud83d\ude1c", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367451124", "createdAt": "2020-01-16T14:35:32Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "diffHunk": "@@ -0,0 +1,518 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+import co.elastic.apm.agent.profiler.collections.Int2IntHashMap;\n+import co.elastic.apm.agent.profiler.collections.Int2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * Parses the binary JFR file created by async-profiler.\n+ * May not work with JFR files created by an actual flight recorder.\n+ * <p>\n+ * The implementation is tuned with to minimize allocations when parsing a JFR file.\n+ * Most data structures can be reused by first {@linkplain #resetState() resetting the state} and then {@linkplain #parse(File, List, List) parsing}\n+ * another file.\n+ * </p>\n+ * <p>\n+ * The JFR file itself is mapped into memory via a {@link MappedByteBuffer}.\n+ * This does not consume heap memory, the operating system loads pages the file into memory as they are requested.\n+ * Unfortunately, unmapping a {@link MappedByteBuffer} can only be done by letting it be garbage collected.\n+ * </p>\n+ */\n+public class JfrParser implements Recyclable {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(JfrParser.class);\n+\n+    private static final byte[] MAGIC_BYTES = new byte[]{'F', 'L', 'R', '\\0'};\n+    private static final Set<String> JAVA_FRAME_TYPES = new HashSet<>(Arrays.asList(\"Interpreted\", \"JIT compiled\", \"Inlined\"));\n+\n+    @Nullable\n+    private MappedByteBuffer buffer;\n+    private int eventsOffset;\n+    private int metadataOffset;\n+    @Nullable\n+    private boolean[] isJavaFrameType;\n+    private final Int2IntHashMap classIdToClassNameSymbolId = new Int2IntHashMap(-1);\n+    private final Int2ObjectHashMap<Symbol> symbols = new Int2ObjectHashMap<>();\n+    private final Int2IntHashMap stackTraceIdToFilePositions = new Int2IntHashMap(-1);\n+    private final Long2ObjectHashMap<LazyStackFrame> framesByFrameId = new Long2ObjectHashMap<>();\n+    // used to resolve a symbol with minimal allocations\n+    private final StringBuilder symbolBuilder = new StringBuilder();\n+    @Nullable\n+    private List<WildcardMatcher> excludedClasses;\n+    @Nullable\n+    private List<WildcardMatcher> includedClasses;\n+\n+    /**\n+     * Initializes the parser to make it ready for {@link #getStackTrace(long, boolean, List)} to be called.\n+     *\n+     * @param file            the JFR file to parse\n+     * @param excludedClasses Class names to exclude in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @param includedClasses Class names to include in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void parse(File file, List<WildcardMatcher> excludedClasses, List<WildcardMatcher> includedClasses) throws IOException {\n+        this.excludedClasses = excludedClasses;\n+        this.includedClasses = includedClasses;\n+        try (RandomAccessFile raf = new RandomAccessFile(file, \"r\")) {\n+            FileChannel channel = raf.getChannel();\n+            logger.info(\"Parsing {} ({} bytes)\", file, channel.size());\n+            if (channel.size() > Integer.MAX_VALUE) {\n+                // mapping a file into memory is only possible for chunks of the file which fall into the Integer range (2GB)\n+                // that is because MappedByteBuffers are ByteBuffers which only accept ints in position(int pos)\n+                throw new IllegalArgumentException(\"Input file too large\");\n+            }\n+            this.buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, channel.size());\n+        }\n+        for (byte magicByte : MAGIC_BYTES) {\n+            if (buffer.get() != magicByte) {\n+                throw new IllegalArgumentException(\"Not a JFR file\");\n+            }\n+        }\n+        short major = buffer.getShort();\n+        short minor = buffer.getShort();\n+        if (major != 0 && minor != 9) {\n+            throw new IllegalArgumentException(String.format(\"Can only parse version 0.9. Was %d.%d\", major, minor));\n+        }\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        metadataOffset = (int) buffer.getLong();\n+        eventsOffset = buffer.position();\n+\n+        setPosition(buffer, metadataOffset);\n+        int checkpointOffset = parseMetadata(buffer);\n+        setPosition(buffer, checkpointOffset);\n+        parseCheckpoint(buffer);\n+    }\n+\n+    private int parseMetadata(MappedByteBuffer buffer) throws IOException {\n+        int size = buffer.getInt();\n+        expectEventType(buffer, EventTypeId.EVENT_METADATA);\n+        int checkpointOffsetPosition = size - 16;\n+        setPosition(buffer, buffer.position() + checkpointOffsetPosition);\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        return (int) buffer.getLong();\n+    }\n+\n+    private void expectEventType(MappedByteBuffer buffer, int expectedEventType) throws IOException {\n+        int eventType = buffer.getInt();\n+        if (eventType != expectedEventType) {\n+            throw new IOException(\"Expected \" + expectedEventType + \" but got \" + eventType);\n+        }\n+    }\n+\n+    private void parseCheckpoint(MappedByteBuffer buffer) throws IOException {\n+        buffer.getInt(); // size\n+        expectEventType(buffer, EventTypeId.EVENT_CHECKPOINT);\n+        buffer.getLong(); // stop timestamp\n+        buffer.getLong(); // previous checkpoint - always 0 in async-profiler\n+        while (buffer.position() < metadataOffset) {\n+            parseContentType(buffer);\n+        }\n+    }\n+\n+    private void parseContentType(MappedByteBuffer buffer) throws IOException {\n+        int contentTypeId = buffer.getInt();\n+        logger.debug(\"Parsing content type {}\", contentTypeId);\n+        int count = buffer.getInt();\n+        switch (contentTypeId) {\n+            case ContentTypeId.CONTENT_THREAD:\n+                // currently no thread info\n+                break;\n+            case ContentTypeId.CONTENT_STACKTRACE:\n+                for (int i = 0; i < count; i++) {\n+                    int pos = buffer.position();\n+                    // always an integer\n+                    // see profiler.h\n+                    // MAX_CALLTRACES = 65536\n+                    int stackTraceKey = (int) buffer.getLong();\n+                    this.stackTraceIdToFilePositions.put(stackTraceKey, pos);\n+                    buffer.get(); // truncated\n+                    int numFrames = buffer.getInt();\n+                    int sizeOfFrame = 13;\n+                    setPosition(buffer, buffer.position() + numFrames * sizeOfFrame);\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_CLASS:\n+                for (int i = 0; i < count; i++) {\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    buffer.getLong(); // loader class\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int classNameSymbolId = (int) buffer.getLong();\n+                    classIdToClassNameSymbolId.put(classId, classNameSymbolId); // class name\n+                    buffer.getShort(); // access flags\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_METHOD:\n+                for (int i = 1; i <= count; i++) {\n+                    long id = buffer.getLong();\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int methodNameSymbolId = (int) buffer.getLong();\n+                    framesByFrameId.put(id, new LazyStackFrame(classId, methodNameSymbolId));\n+                    buffer.getLong(); // signature\n+                    buffer.getShort(); // modifiers\n+                    buffer.get(); // hidden\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_SYMBOL:\n+                for (int i = 0; i < count; i++) {\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int symbolId = (int) buffer.getLong();\n+                    int pos = buffer.position();\n+                    symbols.put(symbolId, new Symbol(pos));\n+                    skipString();\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_STATE:\n+                // we're not really interested in the thread states (async-profiler hard-codes state RUNNABLE) anyways\n+                // but we sill have to consume the bytes\n+                for (int i = 1; i <= count; i++) {\n+                    buffer.getShort();\n+                    skipString();\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_FRAME_TYPE:\n+                isJavaFrameType = new boolean[count + 1];\n+                for (int i = 1 ; i <= count; i++) {\n+                    int id = buffer.get();\n+                    if (i != id) {\n+                        throw new IllegalStateException(\"Expecting ids to be incrementing\");\n+                    }\n+                    isJavaFrameType[id] = JAVA_FRAME_TYPES.contains(readUtf8String().toString());\n+                }\n+                break;\n+            default:\n+                throw new IOException(\"Unknown content type \" + contentTypeId);\n+        }\n+    }\n+\n+    private void skipString() {\n+        short stringLength = buffer.getShort();\n+        setPosition(buffer, buffer.position() + stringLength);\n+    }\n+\n+    /**\n+     * Invokes the callback for each stack trace event in the JFR file.\n+     *\n+     * @param callback called for each stack trace event\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void consumeStackTraces(StackTraceConsumer callback) throws IOException {\n+        if (buffer == null) {\n+            throw new IllegalStateException(\"consumeStackTraces was called before parse\");\n+        }\n+        setPosition(buffer, eventsOffset);\n+        while (buffer.position() < metadataOffset) {\n+            int size = buffer.getInt();\n+            int eventType = buffer.getInt();\n+            if (eventType == EventTypeId.EVENT_RECORDING) {\n+                return;\n+            }\n+            if (eventType != EventTypeId.EVENT_EXECUTION_SAMPLE){\n+                throw new IOException(\"Expected \" + EventTypeId.EVENT_EXECUTION_SAMPLE + \" but got \" + eventType);\n+            }\n+            long nanoTime = buffer.getLong();\n+            int tid = buffer.getInt();\n+            long stackTraceId = buffer.getLong();\n+            short threadState = buffer.getShort();\n+            callback.onCallTree(tid, stackTraceId, nanoTime);\n+        }\n+    }\n+\n+    public interface StackTraceConsumer {\n+\n+        /**\n+         * @param threadId     The native thread id for with the event was recorded.\n+         *                     Note that this is not the same as {@link Thread#getId()}.\n+         * @param stackTraceId The id of the stack trace event.\n+         *                     Can be used to resolve the stack trace via {@link #getStackTrace(long, boolean, List)}\n+         * @param nanoTime     The timestamp of the event which can be correlated with {@link System#nanoTime()}\n+         */\n+        void onCallTree(int threadId, long stackTraceId, long nanoTime);\n+    }\n+\n+    /**\n+     * Resolves the stack trace with the given {@code stackTraceId}.\n+     * <p>\n+     * Note that his allocates strings for {@link Symbol#resolved} in case a stack frame has not already been resolved for the current JFR file yet.\n+     * These strings are currently not cached so this can create some GC pressure.\n+     * </p>\n+     *\n+     * @param stackTraceId   The id of the stack traced.\n+     *                       Used to look up the position of the file in which the given stack trace is stored via {@link #stackTraceIdToFilePositions}.\n+     * @param onlyJavaFrames If {@code true}, will only resolve {@code Interpreted}, {@code JIT compiled} and {@code Inlined} frames.\n+     *                       If {@code false}, will also resolve {@code Native}, {@code Kernel} and {@code C++} frames.\n+     * @param stackFrames    The mutable list where the stack frames are written to.\n+     *                       Don't forget to {@link List#clear()} the list before calling this method if the list is reused.\n+     */\n+    public void getStackTrace(long stackTraceId, boolean onlyJavaFrames, List<StackFrame> stackFrames) {\n+        if (buffer == null) {\n+            throw new IllegalStateException(\"getStackTrace was called before parse\");\n+        }\n+        MappedByteBuffer buffer = this.buffer;\n+        int position = buffer.position();\n+        setPosition(buffer, stackTraceIdToFilePositions.get((int) stackTraceId));\n+        long stackTraceIdFromFile = buffer.getLong();\n+        assert stackTraceId == stackTraceIdFromFile;\n+        buffer.get(); // truncated\n+        int numFrames = buffer.getInt();\n+        for (int i = 0; i < numFrames; i++) {\n+            long method = buffer.getLong();\n+            buffer.getInt(); // bci (always set to 0 by async-profiler)\n+            byte frameType = buffer.get();\n+            if (!onlyJavaFrames || isJavaFrameType(frameType)) {\n+                LazyStackFrame lazyStackFrame = framesByFrameId.get(method);\n+                if (lazyStackFrame.isIncluded(this)) {\n+                    StackFrame stackFrame = lazyStackFrame.resolve(this);\n+                    stackFrames.add(stackFrame);\n+                }\n+            }\n+        }\n+        setPosition(buffer, position);\n+    }\n+\n+    private boolean isJavaFrameType(byte frameType) {\n+        return isJavaFrameType[frameType];\n+    }\n+\n+    private StringBuilder resolveSymbol(int pos, boolean replaceSlashWithDot) {\n+        int currentPos = buffer.position();\n+        setPosition(buffer, pos);\n+        try {\n+            return readUtf8String(replaceSlashWithDot);\n+        } finally {\n+            setPosition(buffer, currentPos);\n+        }\n+    }\n+\n+    private boolean isClassIncluded(CharSequence className) {\n+        return WildcardMatcher.isAnyMatch(includedClasses, className) && WildcardMatcher.isNoneMatch(excludedClasses, className);\n+    }\n+\n+    private static void setPosition(MappedByteBuffer buffer, int pos) {\n+        // weird hack because of binary incompatibility introduced in Java 9\n+        // the return type was changed from Buffer to MappedByteBuffer\n+        // linking a method also incorporates the exact return type\n+        ((Buffer) buffer).position(pos);\n+    }\n+\n+    private StackFrame resolveStackFrame(int classId, int methodName) {\n+        Symbol classNameSymbol = symbols.get(classIdToClassNameSymbolId.get(classId));\n+        if (classNameSymbol.isClassNameIncluded(this)) {\n+            String className = classNameSymbol.resolveClassName(this);\n+            String method = symbols.get(methodName).resolve(this);\n+            return new StackFrame(className, Objects.requireNonNull(method));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMxNDQ0Mg=="}, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 347}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MzE4MDQxOnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxMjo0MDo0N1rOFdWIQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxMjo0MDo0N1rOFdWIQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMxNTU4Nw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public void getStackTrace(long stackTraceId, boolean onlyJavaFrames, List<StackFrame> stackFrames) {\n          \n          \n            \n                public void resolveStackTrace(long stackTraceId, boolean onlyJavaFrames, List<StackFrame> stackFrames) {", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366315587", "createdAt": "2020-01-14T12:40:47Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "diffHunk": "@@ -0,0 +1,518 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+import co.elastic.apm.agent.profiler.collections.Int2IntHashMap;\n+import co.elastic.apm.agent.profiler.collections.Int2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * Parses the binary JFR file created by async-profiler.\n+ * May not work with JFR files created by an actual flight recorder.\n+ * <p>\n+ * The implementation is tuned with to minimize allocations when parsing a JFR file.\n+ * Most data structures can be reused by first {@linkplain #resetState() resetting the state} and then {@linkplain #parse(File, List, List) parsing}\n+ * another file.\n+ * </p>\n+ * <p>\n+ * The JFR file itself is mapped into memory via a {@link MappedByteBuffer}.\n+ * This does not consume heap memory, the operating system loads pages the file into memory as they are requested.\n+ * Unfortunately, unmapping a {@link MappedByteBuffer} can only be done by letting it be garbage collected.\n+ * </p>\n+ */\n+public class JfrParser implements Recyclable {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(JfrParser.class);\n+\n+    private static final byte[] MAGIC_BYTES = new byte[]{'F', 'L', 'R', '\\0'};\n+    private static final Set<String> JAVA_FRAME_TYPES = new HashSet<>(Arrays.asList(\"Interpreted\", \"JIT compiled\", \"Inlined\"));\n+\n+    @Nullable\n+    private MappedByteBuffer buffer;\n+    private int eventsOffset;\n+    private int metadataOffset;\n+    @Nullable\n+    private boolean[] isJavaFrameType;\n+    private final Int2IntHashMap classIdToClassNameSymbolId = new Int2IntHashMap(-1);\n+    private final Int2ObjectHashMap<Symbol> symbols = new Int2ObjectHashMap<>();\n+    private final Int2IntHashMap stackTraceIdToFilePositions = new Int2IntHashMap(-1);\n+    private final Long2ObjectHashMap<LazyStackFrame> framesByFrameId = new Long2ObjectHashMap<>();\n+    // used to resolve a symbol with minimal allocations\n+    private final StringBuilder symbolBuilder = new StringBuilder();\n+    @Nullable\n+    private List<WildcardMatcher> excludedClasses;\n+    @Nullable\n+    private List<WildcardMatcher> includedClasses;\n+\n+    /**\n+     * Initializes the parser to make it ready for {@link #getStackTrace(long, boolean, List)} to be called.\n+     *\n+     * @param file            the JFR file to parse\n+     * @param excludedClasses Class names to exclude in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @param includedClasses Class names to include in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void parse(File file, List<WildcardMatcher> excludedClasses, List<WildcardMatcher> includedClasses) throws IOException {\n+        this.excludedClasses = excludedClasses;\n+        this.includedClasses = includedClasses;\n+        try (RandomAccessFile raf = new RandomAccessFile(file, \"r\")) {\n+            FileChannel channel = raf.getChannel();\n+            logger.info(\"Parsing {} ({} bytes)\", file, channel.size());\n+            if (channel.size() > Integer.MAX_VALUE) {\n+                // mapping a file into memory is only possible for chunks of the file which fall into the Integer range (2GB)\n+                // that is because MappedByteBuffers are ByteBuffers which only accept ints in position(int pos)\n+                throw new IllegalArgumentException(\"Input file too large\");\n+            }\n+            this.buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, channel.size());\n+        }\n+        for (byte magicByte : MAGIC_BYTES) {\n+            if (buffer.get() != magicByte) {\n+                throw new IllegalArgumentException(\"Not a JFR file\");\n+            }\n+        }\n+        short major = buffer.getShort();\n+        short minor = buffer.getShort();\n+        if (major != 0 && minor != 9) {\n+            throw new IllegalArgumentException(String.format(\"Can only parse version 0.9. Was %d.%d\", major, minor));\n+        }\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        metadataOffset = (int) buffer.getLong();\n+        eventsOffset = buffer.position();\n+\n+        setPosition(buffer, metadataOffset);\n+        int checkpointOffset = parseMetadata(buffer);\n+        setPosition(buffer, checkpointOffset);\n+        parseCheckpoint(buffer);\n+    }\n+\n+    private int parseMetadata(MappedByteBuffer buffer) throws IOException {\n+        int size = buffer.getInt();\n+        expectEventType(buffer, EventTypeId.EVENT_METADATA);\n+        int checkpointOffsetPosition = size - 16;\n+        setPosition(buffer, buffer.position() + checkpointOffsetPosition);\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        return (int) buffer.getLong();\n+    }\n+\n+    private void expectEventType(MappedByteBuffer buffer, int expectedEventType) throws IOException {\n+        int eventType = buffer.getInt();\n+        if (eventType != expectedEventType) {\n+            throw new IOException(\"Expected \" + expectedEventType + \" but got \" + eventType);\n+        }\n+    }\n+\n+    private void parseCheckpoint(MappedByteBuffer buffer) throws IOException {\n+        buffer.getInt(); // size\n+        expectEventType(buffer, EventTypeId.EVENT_CHECKPOINT);\n+        buffer.getLong(); // stop timestamp\n+        buffer.getLong(); // previous checkpoint - always 0 in async-profiler\n+        while (buffer.position() < metadataOffset) {\n+            parseContentType(buffer);\n+        }\n+    }\n+\n+    private void parseContentType(MappedByteBuffer buffer) throws IOException {\n+        int contentTypeId = buffer.getInt();\n+        logger.debug(\"Parsing content type {}\", contentTypeId);\n+        int count = buffer.getInt();\n+        switch (contentTypeId) {\n+            case ContentTypeId.CONTENT_THREAD:\n+                // currently no thread info\n+                break;\n+            case ContentTypeId.CONTENT_STACKTRACE:\n+                for (int i = 0; i < count; i++) {\n+                    int pos = buffer.position();\n+                    // always an integer\n+                    // see profiler.h\n+                    // MAX_CALLTRACES = 65536\n+                    int stackTraceKey = (int) buffer.getLong();\n+                    this.stackTraceIdToFilePositions.put(stackTraceKey, pos);\n+                    buffer.get(); // truncated\n+                    int numFrames = buffer.getInt();\n+                    int sizeOfFrame = 13;\n+                    setPosition(buffer, buffer.position() + numFrames * sizeOfFrame);\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_CLASS:\n+                for (int i = 0; i < count; i++) {\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    buffer.getLong(); // loader class\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int classNameSymbolId = (int) buffer.getLong();\n+                    classIdToClassNameSymbolId.put(classId, classNameSymbolId); // class name\n+                    buffer.getShort(); // access flags\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_METHOD:\n+                for (int i = 1; i <= count; i++) {\n+                    long id = buffer.getLong();\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int methodNameSymbolId = (int) buffer.getLong();\n+                    framesByFrameId.put(id, new LazyStackFrame(classId, methodNameSymbolId));\n+                    buffer.getLong(); // signature\n+                    buffer.getShort(); // modifiers\n+                    buffer.get(); // hidden\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_SYMBOL:\n+                for (int i = 0; i < count; i++) {\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int symbolId = (int) buffer.getLong();\n+                    int pos = buffer.position();\n+                    symbols.put(symbolId, new Symbol(pos));\n+                    skipString();\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_STATE:\n+                // we're not really interested in the thread states (async-profiler hard-codes state RUNNABLE) anyways\n+                // but we sill have to consume the bytes\n+                for (int i = 1; i <= count; i++) {\n+                    buffer.getShort();\n+                    skipString();\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_FRAME_TYPE:\n+                isJavaFrameType = new boolean[count + 1];\n+                for (int i = 1 ; i <= count; i++) {\n+                    int id = buffer.get();\n+                    if (i != id) {\n+                        throw new IllegalStateException(\"Expecting ids to be incrementing\");\n+                    }\n+                    isJavaFrameType[id] = JAVA_FRAME_TYPES.contains(readUtf8String().toString());\n+                }\n+                break;\n+            default:\n+                throw new IOException(\"Unknown content type \" + contentTypeId);\n+        }\n+    }\n+\n+    private void skipString() {\n+        short stringLength = buffer.getShort();\n+        setPosition(buffer, buffer.position() + stringLength);\n+    }\n+\n+    /**\n+     * Invokes the callback for each stack trace event in the JFR file.\n+     *\n+     * @param callback called for each stack trace event\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void consumeStackTraces(StackTraceConsumer callback) throws IOException {\n+        if (buffer == null) {\n+            throw new IllegalStateException(\"consumeStackTraces was called before parse\");\n+        }\n+        setPosition(buffer, eventsOffset);\n+        while (buffer.position() < metadataOffset) {\n+            int size = buffer.getInt();\n+            int eventType = buffer.getInt();\n+            if (eventType == EventTypeId.EVENT_RECORDING) {\n+                return;\n+            }\n+            if (eventType != EventTypeId.EVENT_EXECUTION_SAMPLE){\n+                throw new IOException(\"Expected \" + EventTypeId.EVENT_EXECUTION_SAMPLE + \" but got \" + eventType);\n+            }\n+            long nanoTime = buffer.getLong();\n+            int tid = buffer.getInt();\n+            long stackTraceId = buffer.getLong();\n+            short threadState = buffer.getShort();\n+            callback.onCallTree(tid, stackTraceId, nanoTime);\n+        }\n+    }\n+\n+    public interface StackTraceConsumer {\n+\n+        /**\n+         * @param threadId     The native thread id for with the event was recorded.\n+         *                     Note that this is not the same as {@link Thread#getId()}.\n+         * @param stackTraceId The id of the stack trace event.\n+         *                     Can be used to resolve the stack trace via {@link #getStackTrace(long, boolean, List)}\n+         * @param nanoTime     The timestamp of the event which can be correlated with {@link System#nanoTime()}\n+         */\n+        void onCallTree(int threadId, long stackTraceId, long nanoTime);\n+    }\n+\n+    /**\n+     * Resolves the stack trace with the given {@code stackTraceId}.\n+     * <p>\n+     * Note that his allocates strings for {@link Symbol#resolved} in case a stack frame has not already been resolved for the current JFR file yet.\n+     * These strings are currently not cached so this can create some GC pressure.\n+     * </p>\n+     *\n+     * @param stackTraceId   The id of the stack traced.\n+     *                       Used to look up the position of the file in which the given stack trace is stored via {@link #stackTraceIdToFilePositions}.\n+     * @param onlyJavaFrames If {@code true}, will only resolve {@code Interpreted}, {@code JIT compiled} and {@code Inlined} frames.\n+     *                       If {@code false}, will also resolve {@code Native}, {@code Kernel} and {@code C++} frames.\n+     * @param stackFrames    The mutable list where the stack frames are written to.\n+     *                       Don't forget to {@link List#clear()} the list before calling this method if the list is reused.\n+     */\n+    public void getStackTrace(long stackTraceId, boolean onlyJavaFrames, List<StackFrame> stackFrames) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 291}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MzI2NjQxOnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxMzoxMjozMVrOFdW9QQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxMzoxMjozMVrOFdW9QQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMyOTE1Mw==", "bodyText": "This makes it dynamic only when starting with true. If you remove this check it will be completely dynamic, as you check at the beginning of each run invocation.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366329153", "createdAt": "2020-01-14T13:12:31Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#getStackTrace(long, boolean, List) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 100_000;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final AsyncProfiler asyncProfiler = AsyncProfiler.getInstance();\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"apm-sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+        }\n+    }\n+\n+    private RingBuffer<ActivationEvent> createRingBuffer() {\n+        return RingBuffer.<ActivationEvent>createMultiProducer(\n+            new EventFactory<ActivationEvent>() {\n+                @Override\n+                public ActivationEvent newInstance() {\n+                    return new ActivationEvent();\n+                }\n+            },\n+            RING_BUFFER_SIZE,\n+            new NoWaitStrategy());\n+    }\n+\n+    /**\n+     * Called whenever a span is activated.\n+     * <p>\n+     * This and {@link #onDeactivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onActivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(ACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * Called whenever a span is deactivated.\n+     * <p>\n+     * This and {@link #onActivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onDeactivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(DEACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public void run() {\n+        profilingSessions++;\n+        if (config.isProfilingDisabled()) {\n+            scheduler.schedule(this, config.getProfilingInterval().getMillis(), TimeUnit.MILLISECONDS);\n+            return;\n+        }\n+\n+        TimeDuration sampleRate = config.getSamplingInterval();\n+        TimeDuration profilingDuration = config.getProfilingDuration();\n+\n+        setProfilingSessionOngoing(true);\n+\n+        logger.debug(\"Start profiling session\");\n+        try {\n+            profile(sampleRate, profilingDuration);\n+        } catch (Exception e) {\n+            logger.error(\"Stopping profiler\", e);\n+            return;\n+        }\n+        logger.debug(\"End profiling session\");\n+\n+        boolean interrupted = Thread.currentThread().isInterrupted();\n+        boolean continueProfilingSession = config.isNonStopProfiling() && !interrupted && config.isProfilingEnabled();\n+        setProfilingSessionOngoing(continueProfilingSession);\n+\n+        if (!interrupted) {\n+            long delay = config.getProfilingInterval().getMillis() - profilingDuration.getMillis();\n+            scheduler.schedule(this, delay, TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private void profile(TimeDuration sampleRate, TimeDuration profilingDuration) throws Exception {\n+        try {\n+            String startMessage = asyncProfiler.execute(\"start,jfr,event=wall,interval=\" + sampleRate.getMillis() + \"ms,alluser,file=\" + jfrFile);\n+            logger.info(startMessage);\n+\n+            consumeActivationEventsFromRingBufferAndWriteToFile(profilingDuration);\n+\n+            String stopMessage = asyncProfiler.execute(\"stop\");\n+            logger.info(stopMessage);\n+\n+            processTraces(jfrFile);\n+        } catch (InterruptedException e) {\n+            asyncProfiler.stop();\n+            Thread.currentThread().interrupt();\n+        }\n+    }\n+\n+    private void consumeActivationEventsFromRingBufferAndWriteToFile(TimeDuration profilingDuration) throws Exception {\n+        resetActivationEventBuffer();\n+        long threshold = System.currentTimeMillis() + profilingDuration.getMillis();\n+        long initialSleep = 100_000;\n+        long maxSleep = 10_000_000;\n+        long sleep = initialSleep;\n+        while (System.currentTimeMillis() < threshold) {\n+            if (activationEventBuffer.hasRemaining()) {\n+                EventPoller.PollState poll = consumeActivationEventsFromRingBufferAndWriteToFile();\n+                if (poll == EventPoller.PollState.PROCESSING) {\n+                    sleep = initialSleep;\n+                } else {\n+                    if (sleep < maxSleep) {\n+                        sleep *= 2;\n+                    }\n+                }\n+                LockSupport.parkNanos(sleep);\n+            } else {\n+                // the file is full, sleep the rest of the profilingDuration\n+                Thread.sleep(Math.max(0, threshold - System.currentTimeMillis()));\n+            }\n+        }\n+    }\n+\n+    private void resetActivationEventBuffer() {\n+        ((Buffer) activationEventBuffer).clear();\n+    }\n+\n+    EventPoller.PollState consumeActivationEventsFromRingBufferAndWriteToFile() throws Exception {\n+        return poller.poll(writeActivationEventToFileHandler);\n+    }\n+\n+    private void processTraces(File file) throws IOException {\n+        if (activationEventBuffer.position() == 0) {\n+            logger.debug(\"No activation events during this period. Skip processing stack traces.\");\n+            return;\n+        }\n+        List<WildcardMatcher> excludedClasses = config.getExcludedClasses();\n+        List<WildcardMatcher> includedClasses = config.getIncludedClasses();\n+        try {\n+            jfrParser.parse(file, excludedClasses, includedClasses);\n+            startProcessingActivationEventsFile();\n+            final SortedSet<StackTraceEvent> stackTraceEvents = getStackTraceEvents(jfrParser);\n+            if (logger.isDebugEnabled()) {\n+                logger.debug(\"Processing {} stack traces\", stackTraceEvents.size());\n+            }\n+            List<StackFrame> stackFrames = new ArrayList<>();\n+            ElasticApmTracer tracer = this.tracer;\n+            ActivationEvent event = new ActivationEvent();\n+            for (StackTraceEvent stackTrace : stackTraceEvents) {\n+                processActivationEventsUpTo(stackTrace.nanoTime, event);\n+                CallTree.Root root = profiledThreads.get(stackTrace.threadId);\n+                if (root != null) {\n+                    jfrParser.getStackTrace(stackTrace.stackTraceId, true, stackFrames);\n+                    root.addStackTrace(tracer, stackFrames, stackTrace.nanoTime);\n+                }\n+                stackFrames.clear();\n+            }\n+        } finally {\n+            jfrParser.resetState();\n+        }\n+    }\n+\n+    /**\n+     * Returns stack trace events of relevant threads sorted by timestamp.\n+     * The events in the JFR file are not in order.\n+     * Even for the same thread, a more recent event might come before an older event.\n+     * In order to be able to correlate stack trace events and activation events, both need to be in order.\n+     *\n+     * Returns only events for threads where at least one activation happened\n+     */\n+    private SortedSet<StackTraceEvent> getStackTraceEvents(JfrParser jfrParser) throws IOException {\n+        final LongHashSet nativeThreadIds = threadMapper.getNativeThreadIds();\n+        final SortedSet<StackTraceEvent> stackTraceEvents = new TreeSet<>();\n+        jfrParser.consumeStackTraces(new JfrParser.StackTraceConsumer() {\n+            @Override\n+            public void onCallTree(int threadId, long stackTraceId, long nanoTime) {\n+                if (nativeThreadIds.contains(threadId)) {\n+                    stackTraceEvents.add(new StackTraceEvent(nanoTime, stackTraceId, threadId));\n+                }\n+            }\n+        });\n+        return stackTraceEvents;\n+    }\n+\n+    void processActivationEventsUpTo(long timestamp) {\n+        processActivationEventsUpTo(timestamp, new ActivationEvent());\n+    }\n+\n+    public void processActivationEventsUpTo(long timestamp, ActivationEvent event) {\n+        MappedByteBuffer buf = this.activationEventBuffer;\n+        while (buf.hasRemaining()) {\n+            long eventTimestamp = peekLong(buf);\n+            if (eventTimestamp <= timestamp) {\n+                event.deserialize(buf);\n+                event.handle(this);\n+            } else {\n+                return;\n+            }\n+        }\n+    }\n+\n+    private static long peekLong(ByteBuffer buf) {\n+        int pos = buf.position();\n+        try {\n+            return buf.getLong();\n+        } finally {\n+            ((Buffer) buf).position(pos);\n+        }\n+    }\n+\n+    @Override\n+    public void start(ElasticApmTracer tracer) {\n+        if (config.isProfilingEnabled()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 401}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MzI4NTU5OnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxMzoxOTowN1rOFdXJDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzo0ODo1MlrOFeZ5CQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMzMjE3NA==", "bodyText": "Is this required? If you always parse activation events in the right order, then the state of the profiledThreads map should always indicate whether an activation event for a thread is a root or not- if there is one for the thread, it is not a root, otherwise it is. Am I missing something?", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366332174", "createdAt": "2020-01-14T13:19:07Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#getStackTrace(long, boolean, List) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 100_000;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final AsyncProfiler asyncProfiler = AsyncProfiler.getInstance();\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"apm-sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+        }\n+    }\n+\n+    private RingBuffer<ActivationEvent> createRingBuffer() {\n+        return RingBuffer.<ActivationEvent>createMultiProducer(\n+            new EventFactory<ActivationEvent>() {\n+                @Override\n+                public ActivationEvent newInstance() {\n+                    return new ActivationEvent();\n+                }\n+            },\n+            RING_BUFFER_SIZE,\n+            new NoWaitStrategy());\n+    }\n+\n+    /**\n+     * Called whenever a span is activated.\n+     * <p>\n+     * This and {@link #onDeactivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onActivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(ACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * Called whenever a span is deactivated.\n+     * <p>\n+     * This and {@link #onActivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onDeactivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(DEACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public void run() {\n+        profilingSessions++;\n+        if (config.isProfilingDisabled()) {\n+            scheduler.schedule(this, config.getProfilingInterval().getMillis(), TimeUnit.MILLISECONDS);\n+            return;\n+        }\n+\n+        TimeDuration sampleRate = config.getSamplingInterval();\n+        TimeDuration profilingDuration = config.getProfilingDuration();\n+\n+        setProfilingSessionOngoing(true);\n+\n+        logger.debug(\"Start profiling session\");\n+        try {\n+            profile(sampleRate, profilingDuration);\n+        } catch (Exception e) {\n+            logger.error(\"Stopping profiler\", e);\n+            return;\n+        }\n+        logger.debug(\"End profiling session\");\n+\n+        boolean interrupted = Thread.currentThread().isInterrupted();\n+        boolean continueProfilingSession = config.isNonStopProfiling() && !interrupted && config.isProfilingEnabled();\n+        setProfilingSessionOngoing(continueProfilingSession);\n+\n+        if (!interrupted) {\n+            long delay = config.getProfilingInterval().getMillis() - profilingDuration.getMillis();\n+            scheduler.schedule(this, delay, TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private void profile(TimeDuration sampleRate, TimeDuration profilingDuration) throws Exception {\n+        try {\n+            String startMessage = asyncProfiler.execute(\"start,jfr,event=wall,interval=\" + sampleRate.getMillis() + \"ms,alluser,file=\" + jfrFile);\n+            logger.info(startMessage);\n+\n+            consumeActivationEventsFromRingBufferAndWriteToFile(profilingDuration);\n+\n+            String stopMessage = asyncProfiler.execute(\"stop\");\n+            logger.info(stopMessage);\n+\n+            processTraces(jfrFile);\n+        } catch (InterruptedException e) {\n+            asyncProfiler.stop();\n+            Thread.currentThread().interrupt();\n+        }\n+    }\n+\n+    private void consumeActivationEventsFromRingBufferAndWriteToFile(TimeDuration profilingDuration) throws Exception {\n+        resetActivationEventBuffer();\n+        long threshold = System.currentTimeMillis() + profilingDuration.getMillis();\n+        long initialSleep = 100_000;\n+        long maxSleep = 10_000_000;\n+        long sleep = initialSleep;\n+        while (System.currentTimeMillis() < threshold) {\n+            if (activationEventBuffer.hasRemaining()) {\n+                EventPoller.PollState poll = consumeActivationEventsFromRingBufferAndWriteToFile();\n+                if (poll == EventPoller.PollState.PROCESSING) {\n+                    sleep = initialSleep;\n+                } else {\n+                    if (sleep < maxSleep) {\n+                        sleep *= 2;\n+                    }\n+                }\n+                LockSupport.parkNanos(sleep);\n+            } else {\n+                // the file is full, sleep the rest of the profilingDuration\n+                Thread.sleep(Math.max(0, threshold - System.currentTimeMillis()));\n+            }\n+        }\n+    }\n+\n+    private void resetActivationEventBuffer() {\n+        ((Buffer) activationEventBuffer).clear();\n+    }\n+\n+    EventPoller.PollState consumeActivationEventsFromRingBufferAndWriteToFile() throws Exception {\n+        return poller.poll(writeActivationEventToFileHandler);\n+    }\n+\n+    private void processTraces(File file) throws IOException {\n+        if (activationEventBuffer.position() == 0) {\n+            logger.debug(\"No activation events during this period. Skip processing stack traces.\");\n+            return;\n+        }\n+        List<WildcardMatcher> excludedClasses = config.getExcludedClasses();\n+        List<WildcardMatcher> includedClasses = config.getIncludedClasses();\n+        try {\n+            jfrParser.parse(file, excludedClasses, includedClasses);\n+            startProcessingActivationEventsFile();\n+            final SortedSet<StackTraceEvent> stackTraceEvents = getStackTraceEvents(jfrParser);\n+            if (logger.isDebugEnabled()) {\n+                logger.debug(\"Processing {} stack traces\", stackTraceEvents.size());\n+            }\n+            List<StackFrame> stackFrames = new ArrayList<>();\n+            ElasticApmTracer tracer = this.tracer;\n+            ActivationEvent event = new ActivationEvent();\n+            for (StackTraceEvent stackTrace : stackTraceEvents) {\n+                processActivationEventsUpTo(stackTrace.nanoTime, event);\n+                CallTree.Root root = profiledThreads.get(stackTrace.threadId);\n+                if (root != null) {\n+                    jfrParser.getStackTrace(stackTrace.stackTraceId, true, stackFrames);\n+                    root.addStackTrace(tracer, stackFrames, stackTrace.nanoTime);\n+                }\n+                stackFrames.clear();\n+            }\n+        } finally {\n+            jfrParser.resetState();\n+        }\n+    }\n+\n+    /**\n+     * Returns stack trace events of relevant threads sorted by timestamp.\n+     * The events in the JFR file are not in order.\n+     * Even for the same thread, a more recent event might come before an older event.\n+     * In order to be able to correlate stack trace events and activation events, both need to be in order.\n+     *\n+     * Returns only events for threads where at least one activation happened\n+     */\n+    private SortedSet<StackTraceEvent> getStackTraceEvents(JfrParser jfrParser) throws IOException {\n+        final LongHashSet nativeThreadIds = threadMapper.getNativeThreadIds();\n+        final SortedSet<StackTraceEvent> stackTraceEvents = new TreeSet<>();\n+        jfrParser.consumeStackTraces(new JfrParser.StackTraceConsumer() {\n+            @Override\n+            public void onCallTree(int threadId, long stackTraceId, long nanoTime) {\n+                if (nativeThreadIds.contains(threadId)) {\n+                    stackTraceEvents.add(new StackTraceEvent(nanoTime, stackTraceId, threadId));\n+                }\n+            }\n+        });\n+        return stackTraceEvents;\n+    }\n+\n+    void processActivationEventsUpTo(long timestamp) {\n+        processActivationEventsUpTo(timestamp, new ActivationEvent());\n+    }\n+\n+    public void processActivationEventsUpTo(long timestamp, ActivationEvent event) {\n+        MappedByteBuffer buf = this.activationEventBuffer;\n+        while (buf.hasRemaining()) {\n+            long eventTimestamp = peekLong(buf);\n+            if (eventTimestamp <= timestamp) {\n+                event.deserialize(buf);\n+                event.handle(this);\n+            } else {\n+                return;\n+            }\n+        }\n+    }\n+\n+    private static long peekLong(ByteBuffer buf) {\n+        int pos = buf.position();\n+        try {\n+            return buf.getLong();\n+        } finally {\n+            ((Buffer) buf).position(pos);\n+        }\n+    }\n+\n+    @Override\n+    public void start(ElasticApmTracer tracer) {\n+        if (config.isProfilingEnabled()) {\n+            scheduler.submit(this);\n+        }\n+    }\n+\n+    @Override\n+    public void stop() throws Exception {\n+        // cancels/interrupts the profiling thread\n+        scheduler.shutdownNow();\n+        if (!jfrFile.delete()) {\n+            jfrFile.deleteOnExit();\n+        }\n+        if (!activationEventsFile.delete()) {\n+            activationEventsFile.deleteOnExit();\n+        }\n+    }\n+\n+    void setProfilingSessionOngoing(boolean profilingSessionOngoing) {\n+        this.profilingSessionOngoing = profilingSessionOngoing;\n+        if (!profilingSessionOngoing) {\n+            profiledThreads.clear();\n+        }\n+    }\n+\n+    void startProcessingActivationEventsFile() {\n+        ((Buffer) activationEventBuffer).flip();\n+    }\n+\n+    // for testing\n+    CallTree.Root getRoot() {\n+        return profiledThreads.get(threadMapper.getNativeThreadId());\n+    }\n+\n+    void clear() {\n+        profiledThreads.clear();\n+        // consume all remaining events from the ring buffer\n+        try {\n+            poller.poll(new EventPoller.Handler<ActivationEvent>() {\n+                @Override\n+                public boolean onEvent(ActivationEvent event, long sequence, boolean endOfBatch) {\n+                    SamplingProfiler.this.sequence.set(sequence);\n+                    return true;\n+                }\n+            });\n+        } catch (Exception e) {\n+            throw new RuntimeException(e);\n+        }\n+        resetActivationEventBuffer();\n+    }\n+\n+    int getProfilingSessions() {\n+        return profilingSessions;\n+    }\n+    // --\n+\n+    private static class StackTraceEvent implements Comparable<StackTraceEvent> {\n+        private final long nanoTime;\n+        private final long stackTraceId;\n+        private final int threadId;\n+\n+        private StackTraceEvent(long nanoTime, long stackTraceId, int threadId) {\n+            this.nanoTime = nanoTime;\n+            this.stackTraceId = stackTraceId;\n+            this.threadId = threadId;\n+        }\n+\n+        @Override\n+        public int compareTo(StackTraceEvent o) {\n+            return Long.compare(nanoTime, o.nanoTime);\n+        }\n+    }\n+\n+    private static class ActivationEvent {\n+        public static final int SERIALIZED_SIZE =\n+            Long.SIZE / Byte.SIZE + // timestamp\n+                Short.SIZE / Byte.SIZE + // serviceName index\n+                TraceContext.SERIALIZED_LENGTH + // traceContextBuffer\n+                TraceContext.SERIALIZED_LENGTH + // previousContextBuffer\n+                1 + // rootContext\n+                Long.SIZE / Byte.SIZE + // threadId\n+                1; // activation\n+\n+        private static final Map<String, Short> serviceNameMap = new HashMap<>();\n+        private static final Map<Short, String> serviceNameBackMap = new HashMap<>();\n+\n+        private long timestamp;\n+        @Nullable\n+        private String serviceName;\n+        private byte[] traceContextBuffer = new byte[TraceContext.SERIALIZED_LENGTH];\n+        private byte[] previousContextBuffer = new byte[TraceContext.SERIALIZED_LENGTH];\n+        private boolean rootContext;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 491}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQyNTgwMQ==", "bodyText": "There is a chance that we lose events in case the ring buffer is full.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367425801", "createdAt": "2020-01-16T13:48:52Z", "author": {"login": "felixbarny"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#getStackTrace(long, boolean, List) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 100_000;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final AsyncProfiler asyncProfiler = AsyncProfiler.getInstance();\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"apm-sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+        }\n+    }\n+\n+    private RingBuffer<ActivationEvent> createRingBuffer() {\n+        return RingBuffer.<ActivationEvent>createMultiProducer(\n+            new EventFactory<ActivationEvent>() {\n+                @Override\n+                public ActivationEvent newInstance() {\n+                    return new ActivationEvent();\n+                }\n+            },\n+            RING_BUFFER_SIZE,\n+            new NoWaitStrategy());\n+    }\n+\n+    /**\n+     * Called whenever a span is activated.\n+     * <p>\n+     * This and {@link #onDeactivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onActivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(ACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * Called whenever a span is deactivated.\n+     * <p>\n+     * This and {@link #onActivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onDeactivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(DEACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public void run() {\n+        profilingSessions++;\n+        if (config.isProfilingDisabled()) {\n+            scheduler.schedule(this, config.getProfilingInterval().getMillis(), TimeUnit.MILLISECONDS);\n+            return;\n+        }\n+\n+        TimeDuration sampleRate = config.getSamplingInterval();\n+        TimeDuration profilingDuration = config.getProfilingDuration();\n+\n+        setProfilingSessionOngoing(true);\n+\n+        logger.debug(\"Start profiling session\");\n+        try {\n+            profile(sampleRate, profilingDuration);\n+        } catch (Exception e) {\n+            logger.error(\"Stopping profiler\", e);\n+            return;\n+        }\n+        logger.debug(\"End profiling session\");\n+\n+        boolean interrupted = Thread.currentThread().isInterrupted();\n+        boolean continueProfilingSession = config.isNonStopProfiling() && !interrupted && config.isProfilingEnabled();\n+        setProfilingSessionOngoing(continueProfilingSession);\n+\n+        if (!interrupted) {\n+            long delay = config.getProfilingInterval().getMillis() - profilingDuration.getMillis();\n+            scheduler.schedule(this, delay, TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private void profile(TimeDuration sampleRate, TimeDuration profilingDuration) throws Exception {\n+        try {\n+            String startMessage = asyncProfiler.execute(\"start,jfr,event=wall,interval=\" + sampleRate.getMillis() + \"ms,alluser,file=\" + jfrFile);\n+            logger.info(startMessage);\n+\n+            consumeActivationEventsFromRingBufferAndWriteToFile(profilingDuration);\n+\n+            String stopMessage = asyncProfiler.execute(\"stop\");\n+            logger.info(stopMessage);\n+\n+            processTraces(jfrFile);\n+        } catch (InterruptedException e) {\n+            asyncProfiler.stop();\n+            Thread.currentThread().interrupt();\n+        }\n+    }\n+\n+    private void consumeActivationEventsFromRingBufferAndWriteToFile(TimeDuration profilingDuration) throws Exception {\n+        resetActivationEventBuffer();\n+        long threshold = System.currentTimeMillis() + profilingDuration.getMillis();\n+        long initialSleep = 100_000;\n+        long maxSleep = 10_000_000;\n+        long sleep = initialSleep;\n+        while (System.currentTimeMillis() < threshold) {\n+            if (activationEventBuffer.hasRemaining()) {\n+                EventPoller.PollState poll = consumeActivationEventsFromRingBufferAndWriteToFile();\n+                if (poll == EventPoller.PollState.PROCESSING) {\n+                    sleep = initialSleep;\n+                } else {\n+                    if (sleep < maxSleep) {\n+                        sleep *= 2;\n+                    }\n+                }\n+                LockSupport.parkNanos(sleep);\n+            } else {\n+                // the file is full, sleep the rest of the profilingDuration\n+                Thread.sleep(Math.max(0, threshold - System.currentTimeMillis()));\n+            }\n+        }\n+    }\n+\n+    private void resetActivationEventBuffer() {\n+        ((Buffer) activationEventBuffer).clear();\n+    }\n+\n+    EventPoller.PollState consumeActivationEventsFromRingBufferAndWriteToFile() throws Exception {\n+        return poller.poll(writeActivationEventToFileHandler);\n+    }\n+\n+    private void processTraces(File file) throws IOException {\n+        if (activationEventBuffer.position() == 0) {\n+            logger.debug(\"No activation events during this period. Skip processing stack traces.\");\n+            return;\n+        }\n+        List<WildcardMatcher> excludedClasses = config.getExcludedClasses();\n+        List<WildcardMatcher> includedClasses = config.getIncludedClasses();\n+        try {\n+            jfrParser.parse(file, excludedClasses, includedClasses);\n+            startProcessingActivationEventsFile();\n+            final SortedSet<StackTraceEvent> stackTraceEvents = getStackTraceEvents(jfrParser);\n+            if (logger.isDebugEnabled()) {\n+                logger.debug(\"Processing {} stack traces\", stackTraceEvents.size());\n+            }\n+            List<StackFrame> stackFrames = new ArrayList<>();\n+            ElasticApmTracer tracer = this.tracer;\n+            ActivationEvent event = new ActivationEvent();\n+            for (StackTraceEvent stackTrace : stackTraceEvents) {\n+                processActivationEventsUpTo(stackTrace.nanoTime, event);\n+                CallTree.Root root = profiledThreads.get(stackTrace.threadId);\n+                if (root != null) {\n+                    jfrParser.getStackTrace(stackTrace.stackTraceId, true, stackFrames);\n+                    root.addStackTrace(tracer, stackFrames, stackTrace.nanoTime);\n+                }\n+                stackFrames.clear();\n+            }\n+        } finally {\n+            jfrParser.resetState();\n+        }\n+    }\n+\n+    /**\n+     * Returns stack trace events of relevant threads sorted by timestamp.\n+     * The events in the JFR file are not in order.\n+     * Even for the same thread, a more recent event might come before an older event.\n+     * In order to be able to correlate stack trace events and activation events, both need to be in order.\n+     *\n+     * Returns only events for threads where at least one activation happened\n+     */\n+    private SortedSet<StackTraceEvent> getStackTraceEvents(JfrParser jfrParser) throws IOException {\n+        final LongHashSet nativeThreadIds = threadMapper.getNativeThreadIds();\n+        final SortedSet<StackTraceEvent> stackTraceEvents = new TreeSet<>();\n+        jfrParser.consumeStackTraces(new JfrParser.StackTraceConsumer() {\n+            @Override\n+            public void onCallTree(int threadId, long stackTraceId, long nanoTime) {\n+                if (nativeThreadIds.contains(threadId)) {\n+                    stackTraceEvents.add(new StackTraceEvent(nanoTime, stackTraceId, threadId));\n+                }\n+            }\n+        });\n+        return stackTraceEvents;\n+    }\n+\n+    void processActivationEventsUpTo(long timestamp) {\n+        processActivationEventsUpTo(timestamp, new ActivationEvent());\n+    }\n+\n+    public void processActivationEventsUpTo(long timestamp, ActivationEvent event) {\n+        MappedByteBuffer buf = this.activationEventBuffer;\n+        while (buf.hasRemaining()) {\n+            long eventTimestamp = peekLong(buf);\n+            if (eventTimestamp <= timestamp) {\n+                event.deserialize(buf);\n+                event.handle(this);\n+            } else {\n+                return;\n+            }\n+        }\n+    }\n+\n+    private static long peekLong(ByteBuffer buf) {\n+        int pos = buf.position();\n+        try {\n+            return buf.getLong();\n+        } finally {\n+            ((Buffer) buf).position(pos);\n+        }\n+    }\n+\n+    @Override\n+    public void start(ElasticApmTracer tracer) {\n+        if (config.isProfilingEnabled()) {\n+            scheduler.submit(this);\n+        }\n+    }\n+\n+    @Override\n+    public void stop() throws Exception {\n+        // cancels/interrupts the profiling thread\n+        scheduler.shutdownNow();\n+        if (!jfrFile.delete()) {\n+            jfrFile.deleteOnExit();\n+        }\n+        if (!activationEventsFile.delete()) {\n+            activationEventsFile.deleteOnExit();\n+        }\n+    }\n+\n+    void setProfilingSessionOngoing(boolean profilingSessionOngoing) {\n+        this.profilingSessionOngoing = profilingSessionOngoing;\n+        if (!profilingSessionOngoing) {\n+            profiledThreads.clear();\n+        }\n+    }\n+\n+    void startProcessingActivationEventsFile() {\n+        ((Buffer) activationEventBuffer).flip();\n+    }\n+\n+    // for testing\n+    CallTree.Root getRoot() {\n+        return profiledThreads.get(threadMapper.getNativeThreadId());\n+    }\n+\n+    void clear() {\n+        profiledThreads.clear();\n+        // consume all remaining events from the ring buffer\n+        try {\n+            poller.poll(new EventPoller.Handler<ActivationEvent>() {\n+                @Override\n+                public boolean onEvent(ActivationEvent event, long sequence, boolean endOfBatch) {\n+                    SamplingProfiler.this.sequence.set(sequence);\n+                    return true;\n+                }\n+            });\n+        } catch (Exception e) {\n+            throw new RuntimeException(e);\n+        }\n+        resetActivationEventBuffer();\n+    }\n+\n+    int getProfilingSessions() {\n+        return profilingSessions;\n+    }\n+    // --\n+\n+    private static class StackTraceEvent implements Comparable<StackTraceEvent> {\n+        private final long nanoTime;\n+        private final long stackTraceId;\n+        private final int threadId;\n+\n+        private StackTraceEvent(long nanoTime, long stackTraceId, int threadId) {\n+            this.nanoTime = nanoTime;\n+            this.stackTraceId = stackTraceId;\n+            this.threadId = threadId;\n+        }\n+\n+        @Override\n+        public int compareTo(StackTraceEvent o) {\n+            return Long.compare(nanoTime, o.nanoTime);\n+        }\n+    }\n+\n+    private static class ActivationEvent {\n+        public static final int SERIALIZED_SIZE =\n+            Long.SIZE / Byte.SIZE + // timestamp\n+                Short.SIZE / Byte.SIZE + // serviceName index\n+                TraceContext.SERIALIZED_LENGTH + // traceContextBuffer\n+                TraceContext.SERIALIZED_LENGTH + // previousContextBuffer\n+                1 + // rootContext\n+                Long.SIZE / Byte.SIZE + // threadId\n+                1; // activation\n+\n+        private static final Map<String, Short> serviceNameMap = new HashMap<>();\n+        private static final Map<Short, String> serviceNameBackMap = new HashMap<>();\n+\n+        private long timestamp;\n+        @Nullable\n+        private String serviceName;\n+        private byte[] traceContextBuffer = new byte[TraceContext.SERIALIZED_LENGTH];\n+        private byte[] previousContextBuffer = new byte[TraceContext.SERIALIZED_LENGTH];\n+        private boolean rootContext;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMzMjE3NA=="}, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 491}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MzMzNTI2OnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/CallTree.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxMzozNTozNVrOFdXnhw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxMzozNTozNVrOFdXnhw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMzOTk3NQ==", "bodyText": "Consider pooling CallTree objects.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366339975", "createdAt": "2020-01-14T13:35:35Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/CallTree.java", "diffHunk": "@@ -0,0 +1,422 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.Objects;\n+\n+/**\n+ * Converts a sequence of stack traces into a tree structure of method calls.\n+ * <pre>\n+ *             count\n+ *  b b     a      4\n+ * aaaa ->  \u251c\u2500b    1\n+ *          \u2514\u2500b    1\n+ * </pre>\n+ * <p>\n+ * It also stores information about which span is the parent of a particular call tree node,\n+ * based on which span has been {@linkplain ElasticApmTracer#getActive() active} at that time.\n+ * </p>\n+ * <p>\n+ * This allows to {@linkplain Root#spanify() infer spans from the call tree} which have the correct parent/child relationships\n+ * with the regular spans.\n+ * </p>\n+ */\n+public class CallTree implements Recyclable {\n+\n+    @Nullable\n+    private CallTree parent;\n+    protected int count;\n+    private List<CallTree> children = new ArrayList<>();\n+    @Nullable\n+    private StackFrame frame;\n+    protected long start;\n+    private long lastSeen;\n+    private boolean ended;\n+    private long activationTimestamp = -1;\n+    @Nullable\n+    private TraceContext activeContext;\n+    private long deactivationTimestamp = -1;\n+    private boolean isSpan;\n+\n+    public CallTree() {\n+    }\n+\n+    public void set(@Nullable CallTree parent, StackFrame frame, long nanoTime) {\n+        this.parent = parent;\n+        this.frame = frame;\n+        this.start = nanoTime;\n+    }\n+\n+    public void activation(TraceContext traceContext, long activationTimestamp) {\n+        this.activeContext = traceContext;\n+        this.activationTimestamp = activationTimestamp;\n+    }\n+\n+    protected void handleDeactivation(TraceContext deactivatedSpan, long timestamp) {\n+        if (deactivatedSpan.equals(activeContext)) {\n+            deactivationTimestamp = timestamp;\n+        } else {\n+            CallTree lastChild = getLastChild();\n+            if (lastChild != null && !lastChild.isEnded()) {\n+                lastChild.handleDeactivation(deactivatedSpan, timestamp);\n+            }\n+        }\n+    }\n+\n+    public static CallTree.Root createRoot(ObjectPool<CallTree.Root> rootPool, byte[] traceContext, @Nullable String serviceName, long nanoTime) {\n+        CallTree.Root root = rootPool.createInstance();\n+        root.set(traceContext, serviceName, nanoTime);\n+        return root;\n+    }\n+\n+    protected void addFrame(ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        count++;\n+        lastSeen = nanoTime;\n+        //     c ee   <- traceContext not set - they are not a child of the active span but the frame below them\n+        //   bbb dd   <- traceContext set\n+        //   ------   <- all new CallTree during this period should have the traceContext set\n+        // a aaaaaa a\n+        //  |      |\n+        // active  deactive\n+\n+        // this branch is already aware of the activation\n+        if (Objects.equals(this.activeContext, traceContext)) {\n+            traceContext = null;\n+        }\n+\n+        CallTree lastChild = getLastChild();\n+        // if the frame corresponding to the last child is not in the stack trace\n+        // it's assumed to have ended one tick ago\n+        boolean endChild = true;\n+        if (iterator.hasPrevious()) {\n+            final StackFrame frame = iterator.previous();\n+            if (lastChild != null) {\n+                if (!lastChild.isEnded() && frame.equals(lastChild.frame)) {\n+                    lastChild.addFrame(iterator, traceContext, activationTimestamp, nanoTime);\n+                    endChild = false;\n+                } else {\n+                    addChild(frame, iterator, traceContext, activationTimestamp, nanoTime);\n+                }\n+            } else {\n+                addChild(frame, iterator, traceContext, activationTimestamp, nanoTime);\n+            }\n+        }\n+        if (lastChild != null && !lastChild.isEnded() && endChild) {\n+            lastChild.end();\n+        }\n+    }\n+\n+    void addChild(StackFrame frame, ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        CallTree callTree = new CallTree();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 145}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2NTk5NTQ3OnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/CallTree.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQwOTowMDo1OVrOFdxIYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzo0MzowOFrOFeZuNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Njc1Nzk4NQ==", "bodyText": "Log if it IS null", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366757985", "createdAt": "2020-01-15T09:00:59Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/CallTree.java", "diffHunk": "@@ -0,0 +1,422 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.Objects;\n+\n+/**\n+ * Converts a sequence of stack traces into a tree structure of method calls.\n+ * <pre>\n+ *             count\n+ *  b b     a      4\n+ * aaaa ->  \u251c\u2500b    1\n+ *          \u2514\u2500b    1\n+ * </pre>\n+ * <p>\n+ * It also stores information about which span is the parent of a particular call tree node,\n+ * based on which span has been {@linkplain ElasticApmTracer#getActive() active} at that time.\n+ * </p>\n+ * <p>\n+ * This allows to {@linkplain Root#spanify() infer spans from the call tree} which have the correct parent/child relationships\n+ * with the regular spans.\n+ * </p>\n+ */\n+public class CallTree implements Recyclable {\n+\n+    @Nullable\n+    private CallTree parent;\n+    protected int count;\n+    private List<CallTree> children = new ArrayList<>();\n+    @Nullable\n+    private StackFrame frame;\n+    protected long start;\n+    private long lastSeen;\n+    private boolean ended;\n+    private long activationTimestamp = -1;\n+    @Nullable\n+    private TraceContext activeContext;\n+    private long deactivationTimestamp = -1;\n+    private boolean isSpan;\n+\n+    public CallTree() {\n+    }\n+\n+    public void set(@Nullable CallTree parent, StackFrame frame, long nanoTime) {\n+        this.parent = parent;\n+        this.frame = frame;\n+        this.start = nanoTime;\n+    }\n+\n+    public void activation(TraceContext traceContext, long activationTimestamp) {\n+        this.activeContext = traceContext;\n+        this.activationTimestamp = activationTimestamp;\n+    }\n+\n+    protected void handleDeactivation(TraceContext deactivatedSpan, long timestamp) {\n+        if (deactivatedSpan.equals(activeContext)) {\n+            deactivationTimestamp = timestamp;\n+        } else {\n+            CallTree lastChild = getLastChild();\n+            if (lastChild != null && !lastChild.isEnded()) {\n+                lastChild.handleDeactivation(deactivatedSpan, timestamp);\n+            }\n+        }\n+    }\n+\n+    public static CallTree.Root createRoot(ObjectPool<CallTree.Root> rootPool, byte[] traceContext, @Nullable String serviceName, long nanoTime) {\n+        CallTree.Root root = rootPool.createInstance();\n+        root.set(traceContext, serviceName, nanoTime);\n+        return root;\n+    }\n+\n+    protected void addFrame(ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        count++;\n+        lastSeen = nanoTime;\n+        //     c ee   <- traceContext not set - they are not a child of the active span but the frame below them\n+        //   bbb dd   <- traceContext set\n+        //   ------   <- all new CallTree during this period should have the traceContext set\n+        // a aaaaaa a\n+        //  |      |\n+        // active  deactive\n+\n+        // this branch is already aware of the activation\n+        if (Objects.equals(this.activeContext, traceContext)) {\n+            traceContext = null;\n+        }\n+\n+        CallTree lastChild = getLastChild();\n+        // if the frame corresponding to the last child is not in the stack trace\n+        // it's assumed to have ended one tick ago\n+        boolean endChild = true;\n+        if (iterator.hasPrevious()) {\n+            final StackFrame frame = iterator.previous();\n+            if (lastChild != null) {\n+                if (!lastChild.isEnded() && frame.equals(lastChild.frame)) {\n+                    lastChild.addFrame(iterator, traceContext, activationTimestamp, nanoTime);\n+                    endChild = false;\n+                } else {\n+                    addChild(frame, iterator, traceContext, activationTimestamp, nanoTime);\n+                }\n+            } else {\n+                addChild(frame, iterator, traceContext, activationTimestamp, nanoTime);\n+            }\n+        }\n+        if (lastChild != null && !lastChild.isEnded() && endChild) {\n+            lastChild.end();\n+        }\n+    }\n+\n+    void addChild(StackFrame frame, ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        CallTree callTree = new CallTree();\n+        callTree.set(this, frame, nanoTime);\n+        if (traceContext != null) {\n+            callTree.activation(traceContext, activationTimestamp);\n+        }\n+        children.add(callTree);\n+        callTree.addFrame(iterator, null, activationTimestamp, nanoTime);\n+    }\n+\n+    long getDurationUs() {\n+        return (lastSeen - start) / 1000;\n+    }\n+\n+    public int getCount() {\n+        return count;\n+    }\n+\n+    public StackFrame getFrame() {\n+        return frame;\n+    }\n+\n+    public List<CallTree> getChildren() {\n+        return children;\n+    }\n+\n+    void end() {\n+        ended = true;\n+        // if the parent span has already been deactivated before this call tree node has ended\n+        // it means that this node is actually the parent of the already deactivated span\n+        //                     make b parent of a and pre-date the start of b to the activation of a\n+        // [c        ]    \u2500\u2500\u2510  [a(inferred) ]\n+        // \u2514[a(inferred)]   \u2502  [b(inferred)]\n+        //  [b(infer.) ]    \u2514\u25ba [c        ]\n+        //  \u2514\u2500[d(i.)]          \u2514\u2500\u2500[d(i.)]\n+        // see also profiler.CallTreeTest::testDectivationBeforeEnd\n+        if (deactivationHappenedBeforeEnd()) {\n+            start = Math.min(activationTimestamp, start);\n+            List<CallTree> callTrees = getChildren();\n+            for (int i = 0, size = callTrees.size(); i < size; i++) {\n+                CallTree child = callTrees.get(i);\n+                child.activation(activeContext, activationTimestamp);\n+                child.deactivationTimestamp = deactivationTimestamp;\n+                // re-run this logic for all children, even if they have already ended\n+                child.end();\n+            }\n+            activeContext = null;\n+            activationTimestamp = -1;\n+            deactivationTimestamp = -1;\n+        }\n+        CallTree lastChild = getLastChild();\n+        if (lastChild != null && !lastChild.isEnded()) {\n+            lastChild.end();\n+        }\n+    }\n+\n+    private boolean deactivationHappenedBeforeEnd() {\n+        return activeContext != null && deactivationTimestamp > -1 && lastSeen > deactivationTimestamp;\n+    }\n+\n+    public boolean isLeaf() {\n+        return children.isEmpty();\n+    }\n+\n+    /**\n+     * Returns {@code true} if this node has just one child and no self time.\n+     *\n+     * <pre>\n+     *  c\n+     *  b  <- b is a pillar\n+     * aaa\n+     * </pre>\n+     */\n+    private boolean isPillar() {\n+        return children.size() == 1 && children.get(0).count == count;\n+    }\n+\n+    @Nullable\n+    public CallTree getLastChild() {\n+        return children.size() > 0 ? children.get(children.size() - 1) : null;\n+    }\n+\n+    public boolean isEnded() {\n+        return ended;\n+    }\n+\n+    @Override\n+    public String toString() {\n+        StringBuilder sb = new StringBuilder();\n+        try {\n+            toString(sb);\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+        return sb.toString();\n+    }\n+\n+    public void toString(Appendable out) throws IOException {\n+        toString(out, 0);\n+    }\n+\n+    private void toString(Appendable out, int level) throws IOException {\n+        for (int i = 0; i < level; i++) {\n+            out.append(\"  \");\n+        }\n+        out.append(frame.getClassName())\n+            .append('.')\n+            .append(frame.getMethodName())\n+            .append(' ').append(Integer.toString(count))\n+            .append('\\n');\n+        for (CallTree node : children) {\n+            node.toString(out, level + 1);\n+        }\n+    }\n+\n+    void spanify(CallTree.Root root, TraceContext parentContext) {\n+        if (activeContext != null) {\n+            parentContext = activeContext;\n+        }\n+        Span span = null;\n+        if (!isPillar() || isLeaf()) {\n+            span = asSpan(root, parentContext);\n+            this.isSpan = true;\n+        }\n+        for (CallTree child : getChildren()) {\n+            child.spanify(root, span != null ? span.getTraceContext() : parentContext);\n+        }\n+        if (span != null) {\n+            span.end(span.getTimestamp() + getDurationUs());\n+        }\n+    }\n+\n+    protected Span asSpan(Root root, TraceContext parentContext) {\n+        Span span = parentContext.createSpan(root.getEpochMicros(this.start))\n+            .withType(\"app\")\n+            .withSubtype(\"inferred\");\n+\n+        frame.appendSimpleClassName(span.getNameForSerialization());\n+        span.appendToName(\"#\");\n+        span.appendToName(frame.getMethodName());\n+\n+        // we're not interested in the very bottom of the stack which contains things like accepting and handling connections\n+        if (!root.traceContext.equals(parentContext)) {\n+            // we're never spanifying the root\n+            assert this.parent != null;\n+            List<StackFrame> stackTrace = new ArrayList<>();\n+            this.parent.fillStackTrace(stackTrace);\n+            span.setStackTrace(stackTrace);\n+        } else {\n+            span.setStackTrace(Collections.<StackFrame>emptyList());\n+        }\n+        return span;\n+    }\n+\n+    /**\n+     * Fill in the stack trace up to the parent span\n+     */\n+    private void fillStackTrace(List<StackFrame> stackTrace) {\n+        if (parent != null && !this.isSpan) {\n+            stackTrace.add(frame);\n+            parent.fillStackTrace(stackTrace);\n+        }\n+    }\n+\n+    public void removeNodesFasterThan(float percent, int minCount) {\n+        int ticks = (int) (count * percent);\n+        removeNodesFasterThan(Math.max(ticks, minCount));\n+    }\n+\n+    public void removeNodesFasterThan(int minCount) {\n+        List<CallTree> callTrees = getChildren();\n+        for (int i = 0; i < callTrees.size(); i++) {\n+            CallTree child = callTrees.get(i);\n+            if (child.count < minCount) {\n+                callTrees.remove(i--);\n+            } else {\n+                child.removeNodesFasterThan(minCount);\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public void resetState() {\n+        parent = null;\n+        count = 0;\n+        frame = null;\n+        start = 0;\n+        lastSeen = 0;\n+        ended = false;\n+        activationTimestamp = -1;\n+        activeContext = null;\n+        deactivationTimestamp = -1;\n+        isSpan = false;\n+        children.clear();\n+    }\n+\n+    /**\n+     * A special kind of a {@link CallTree} node which represents the root of the call tree.\n+     * This acts as the interface to the outside to add new nodes to the tree or to update existing ones by\n+     * {@linkplain #addStackTrace(ElasticApmTracer, List, long) adding stack traces}.\n+     */\n+    public static class Root extends CallTree implements Recyclable {\n+        private static final StackFrame ROOT_FRAME = new StackFrame(\"root\", \"root\");\n+        protected TraceContext traceContext;\n+        private long activationTimestamp;\n+        @Nullable\n+        private TraceContext activeSpan;\n+        private byte[] activeSpanSerialized = new byte[TraceContext.SERIALIZED_LENGTH];\n+\n+        public Root(ElasticApmTracer tracer) {\n+            this.traceContext = TraceContext.with64BitId(tracer);\n+        }\n+\n+        private void set(byte[] traceContext, @Nullable String serviceName, long nanoTime) {\n+            super.set(null, ROOT_FRAME, nanoTime);\n+            this.traceContext.deserialize(traceContext, serviceName);\n+            setActiveSpan(traceContext, nanoTime);\n+        }\n+\n+        public void setActiveSpan(byte[] activeSpanSerialized, long timestamp) {\n+            activationTimestamp = timestamp;\n+            System.arraycopy(activeSpanSerialized, 0, this.activeSpanSerialized, 0, activeSpanSerialized.length);\n+            this.activeSpan = null;\n+        }\n+\n+        public void onActivation(byte[] active, long timestamp) {\n+            setActiveSpan(active, timestamp);\n+        }\n+\n+        public void onDeactivation(byte[] active, long timestamp) {\n+            if (activeSpan != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 374}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQyMzAzMQ==", "bodyText": "That could happen if the ring buffer gets overwhelmed and we miss the activation event. Not sure if logging that helps, but otoh, probably not a big harm either when logged on debug.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367423031", "createdAt": "2020-01-16T13:43:08Z", "author": {"login": "felixbarny"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/CallTree.java", "diffHunk": "@@ -0,0 +1,422 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.Objects;\n+\n+/**\n+ * Converts a sequence of stack traces into a tree structure of method calls.\n+ * <pre>\n+ *             count\n+ *  b b     a      4\n+ * aaaa ->  \u251c\u2500b    1\n+ *          \u2514\u2500b    1\n+ * </pre>\n+ * <p>\n+ * It also stores information about which span is the parent of a particular call tree node,\n+ * based on which span has been {@linkplain ElasticApmTracer#getActive() active} at that time.\n+ * </p>\n+ * <p>\n+ * This allows to {@linkplain Root#spanify() infer spans from the call tree} which have the correct parent/child relationships\n+ * with the regular spans.\n+ * </p>\n+ */\n+public class CallTree implements Recyclable {\n+\n+    @Nullable\n+    private CallTree parent;\n+    protected int count;\n+    private List<CallTree> children = new ArrayList<>();\n+    @Nullable\n+    private StackFrame frame;\n+    protected long start;\n+    private long lastSeen;\n+    private boolean ended;\n+    private long activationTimestamp = -1;\n+    @Nullable\n+    private TraceContext activeContext;\n+    private long deactivationTimestamp = -1;\n+    private boolean isSpan;\n+\n+    public CallTree() {\n+    }\n+\n+    public void set(@Nullable CallTree parent, StackFrame frame, long nanoTime) {\n+        this.parent = parent;\n+        this.frame = frame;\n+        this.start = nanoTime;\n+    }\n+\n+    public void activation(TraceContext traceContext, long activationTimestamp) {\n+        this.activeContext = traceContext;\n+        this.activationTimestamp = activationTimestamp;\n+    }\n+\n+    protected void handleDeactivation(TraceContext deactivatedSpan, long timestamp) {\n+        if (deactivatedSpan.equals(activeContext)) {\n+            deactivationTimestamp = timestamp;\n+        } else {\n+            CallTree lastChild = getLastChild();\n+            if (lastChild != null && !lastChild.isEnded()) {\n+                lastChild.handleDeactivation(deactivatedSpan, timestamp);\n+            }\n+        }\n+    }\n+\n+    public static CallTree.Root createRoot(ObjectPool<CallTree.Root> rootPool, byte[] traceContext, @Nullable String serviceName, long nanoTime) {\n+        CallTree.Root root = rootPool.createInstance();\n+        root.set(traceContext, serviceName, nanoTime);\n+        return root;\n+    }\n+\n+    protected void addFrame(ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        count++;\n+        lastSeen = nanoTime;\n+        //     c ee   <- traceContext not set - they are not a child of the active span but the frame below them\n+        //   bbb dd   <- traceContext set\n+        //   ------   <- all new CallTree during this period should have the traceContext set\n+        // a aaaaaa a\n+        //  |      |\n+        // active  deactive\n+\n+        // this branch is already aware of the activation\n+        if (Objects.equals(this.activeContext, traceContext)) {\n+            traceContext = null;\n+        }\n+\n+        CallTree lastChild = getLastChild();\n+        // if the frame corresponding to the last child is not in the stack trace\n+        // it's assumed to have ended one tick ago\n+        boolean endChild = true;\n+        if (iterator.hasPrevious()) {\n+            final StackFrame frame = iterator.previous();\n+            if (lastChild != null) {\n+                if (!lastChild.isEnded() && frame.equals(lastChild.frame)) {\n+                    lastChild.addFrame(iterator, traceContext, activationTimestamp, nanoTime);\n+                    endChild = false;\n+                } else {\n+                    addChild(frame, iterator, traceContext, activationTimestamp, nanoTime);\n+                }\n+            } else {\n+                addChild(frame, iterator, traceContext, activationTimestamp, nanoTime);\n+            }\n+        }\n+        if (lastChild != null && !lastChild.isEnded() && endChild) {\n+            lastChild.end();\n+        }\n+    }\n+\n+    void addChild(StackFrame frame, ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        CallTree callTree = new CallTree();\n+        callTree.set(this, frame, nanoTime);\n+        if (traceContext != null) {\n+            callTree.activation(traceContext, activationTimestamp);\n+        }\n+        children.add(callTree);\n+        callTree.addFrame(iterator, null, activationTimestamp, nanoTime);\n+    }\n+\n+    long getDurationUs() {\n+        return (lastSeen - start) / 1000;\n+    }\n+\n+    public int getCount() {\n+        return count;\n+    }\n+\n+    public StackFrame getFrame() {\n+        return frame;\n+    }\n+\n+    public List<CallTree> getChildren() {\n+        return children;\n+    }\n+\n+    void end() {\n+        ended = true;\n+        // if the parent span has already been deactivated before this call tree node has ended\n+        // it means that this node is actually the parent of the already deactivated span\n+        //                     make b parent of a and pre-date the start of b to the activation of a\n+        // [c        ]    \u2500\u2500\u2510  [a(inferred) ]\n+        // \u2514[a(inferred)]   \u2502  [b(inferred)]\n+        //  [b(infer.) ]    \u2514\u25ba [c        ]\n+        //  \u2514\u2500[d(i.)]          \u2514\u2500\u2500[d(i.)]\n+        // see also profiler.CallTreeTest::testDectivationBeforeEnd\n+        if (deactivationHappenedBeforeEnd()) {\n+            start = Math.min(activationTimestamp, start);\n+            List<CallTree> callTrees = getChildren();\n+            for (int i = 0, size = callTrees.size(); i < size; i++) {\n+                CallTree child = callTrees.get(i);\n+                child.activation(activeContext, activationTimestamp);\n+                child.deactivationTimestamp = deactivationTimestamp;\n+                // re-run this logic for all children, even if they have already ended\n+                child.end();\n+            }\n+            activeContext = null;\n+            activationTimestamp = -1;\n+            deactivationTimestamp = -1;\n+        }\n+        CallTree lastChild = getLastChild();\n+        if (lastChild != null && !lastChild.isEnded()) {\n+            lastChild.end();\n+        }\n+    }\n+\n+    private boolean deactivationHappenedBeforeEnd() {\n+        return activeContext != null && deactivationTimestamp > -1 && lastSeen > deactivationTimestamp;\n+    }\n+\n+    public boolean isLeaf() {\n+        return children.isEmpty();\n+    }\n+\n+    /**\n+     * Returns {@code true} if this node has just one child and no self time.\n+     *\n+     * <pre>\n+     *  c\n+     *  b  <- b is a pillar\n+     * aaa\n+     * </pre>\n+     */\n+    private boolean isPillar() {\n+        return children.size() == 1 && children.get(0).count == count;\n+    }\n+\n+    @Nullable\n+    public CallTree getLastChild() {\n+        return children.size() > 0 ? children.get(children.size() - 1) : null;\n+    }\n+\n+    public boolean isEnded() {\n+        return ended;\n+    }\n+\n+    @Override\n+    public String toString() {\n+        StringBuilder sb = new StringBuilder();\n+        try {\n+            toString(sb);\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+        return sb.toString();\n+    }\n+\n+    public void toString(Appendable out) throws IOException {\n+        toString(out, 0);\n+    }\n+\n+    private void toString(Appendable out, int level) throws IOException {\n+        for (int i = 0; i < level; i++) {\n+            out.append(\"  \");\n+        }\n+        out.append(frame.getClassName())\n+            .append('.')\n+            .append(frame.getMethodName())\n+            .append(' ').append(Integer.toString(count))\n+            .append('\\n');\n+        for (CallTree node : children) {\n+            node.toString(out, level + 1);\n+        }\n+    }\n+\n+    void spanify(CallTree.Root root, TraceContext parentContext) {\n+        if (activeContext != null) {\n+            parentContext = activeContext;\n+        }\n+        Span span = null;\n+        if (!isPillar() || isLeaf()) {\n+            span = asSpan(root, parentContext);\n+            this.isSpan = true;\n+        }\n+        for (CallTree child : getChildren()) {\n+            child.spanify(root, span != null ? span.getTraceContext() : parentContext);\n+        }\n+        if (span != null) {\n+            span.end(span.getTimestamp() + getDurationUs());\n+        }\n+    }\n+\n+    protected Span asSpan(Root root, TraceContext parentContext) {\n+        Span span = parentContext.createSpan(root.getEpochMicros(this.start))\n+            .withType(\"app\")\n+            .withSubtype(\"inferred\");\n+\n+        frame.appendSimpleClassName(span.getNameForSerialization());\n+        span.appendToName(\"#\");\n+        span.appendToName(frame.getMethodName());\n+\n+        // we're not interested in the very bottom of the stack which contains things like accepting and handling connections\n+        if (!root.traceContext.equals(parentContext)) {\n+            // we're never spanifying the root\n+            assert this.parent != null;\n+            List<StackFrame> stackTrace = new ArrayList<>();\n+            this.parent.fillStackTrace(stackTrace);\n+            span.setStackTrace(stackTrace);\n+        } else {\n+            span.setStackTrace(Collections.<StackFrame>emptyList());\n+        }\n+        return span;\n+    }\n+\n+    /**\n+     * Fill in the stack trace up to the parent span\n+     */\n+    private void fillStackTrace(List<StackFrame> stackTrace) {\n+        if (parent != null && !this.isSpan) {\n+            stackTrace.add(frame);\n+            parent.fillStackTrace(stackTrace);\n+        }\n+    }\n+\n+    public void removeNodesFasterThan(float percent, int minCount) {\n+        int ticks = (int) (count * percent);\n+        removeNodesFasterThan(Math.max(ticks, minCount));\n+    }\n+\n+    public void removeNodesFasterThan(int minCount) {\n+        List<CallTree> callTrees = getChildren();\n+        for (int i = 0; i < callTrees.size(); i++) {\n+            CallTree child = callTrees.get(i);\n+            if (child.count < minCount) {\n+                callTrees.remove(i--);\n+            } else {\n+                child.removeNodesFasterThan(minCount);\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public void resetState() {\n+        parent = null;\n+        count = 0;\n+        frame = null;\n+        start = 0;\n+        lastSeen = 0;\n+        ended = false;\n+        activationTimestamp = -1;\n+        activeContext = null;\n+        deactivationTimestamp = -1;\n+        isSpan = false;\n+        children.clear();\n+    }\n+\n+    /**\n+     * A special kind of a {@link CallTree} node which represents the root of the call tree.\n+     * This acts as the interface to the outside to add new nodes to the tree or to update existing ones by\n+     * {@linkplain #addStackTrace(ElasticApmTracer, List, long) adding stack traces}.\n+     */\n+    public static class Root extends CallTree implements Recyclable {\n+        private static final StackFrame ROOT_FRAME = new StackFrame(\"root\", \"root\");\n+        protected TraceContext traceContext;\n+        private long activationTimestamp;\n+        @Nullable\n+        private TraceContext activeSpan;\n+        private byte[] activeSpanSerialized = new byte[TraceContext.SERIALIZED_LENGTH];\n+\n+        public Root(ElasticApmTracer tracer) {\n+            this.traceContext = TraceContext.with64BitId(tracer);\n+        }\n+\n+        private void set(byte[] traceContext, @Nullable String serviceName, long nanoTime) {\n+            super.set(null, ROOT_FRAME, nanoTime);\n+            this.traceContext.deserialize(traceContext, serviceName);\n+            setActiveSpan(traceContext, nanoTime);\n+        }\n+\n+        public void setActiveSpan(byte[] activeSpanSerialized, long timestamp) {\n+            activationTimestamp = timestamp;\n+            System.arraycopy(activeSpanSerialized, 0, this.activeSpanSerialized, 0, activeSpanSerialized.length);\n+            this.activeSpan = null;\n+        }\n+\n+        public void onActivation(byte[] active, long timestamp) {\n+            setActiveSpan(active, timestamp);\n+        }\n+\n+        public void onDeactivation(byte[] active, long timestamp) {\n+            if (activeSpan != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Njc1Nzk4NQ=="}, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 374}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2NjA3NDY5OnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/CallTree.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQwOToyNzo1M1rOFdx47w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQwOToyNzo1M1rOFdx47w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Njc3MDQxNQ==", "bodyText": "Add a few words on each, at least traceContext, activeSpan and activeSpanSerialized. It will make it easier to understand.\nCan you reuse CallTree#activeContext instead of using activeSpan, or is it used to reflect a special root state (where activeContext is never set)?\nWouldn't traceContext better be called rootContext?", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366770415", "createdAt": "2020-01-15T09:27:53Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/CallTree.java", "diffHunk": "@@ -0,0 +1,422 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.Objects;\n+\n+/**\n+ * Converts a sequence of stack traces into a tree structure of method calls.\n+ * <pre>\n+ *             count\n+ *  b b     a      4\n+ * aaaa ->  \u251c\u2500b    1\n+ *          \u2514\u2500b    1\n+ * </pre>\n+ * <p>\n+ * It also stores information about which span is the parent of a particular call tree node,\n+ * based on which span has been {@linkplain ElasticApmTracer#getActive() active} at that time.\n+ * </p>\n+ * <p>\n+ * This allows to {@linkplain Root#spanify() infer spans from the call tree} which have the correct parent/child relationships\n+ * with the regular spans.\n+ * </p>\n+ */\n+public class CallTree implements Recyclable {\n+\n+    @Nullable\n+    private CallTree parent;\n+    protected int count;\n+    private List<CallTree> children = new ArrayList<>();\n+    @Nullable\n+    private StackFrame frame;\n+    protected long start;\n+    private long lastSeen;\n+    private boolean ended;\n+    private long activationTimestamp = -1;\n+    @Nullable\n+    private TraceContext activeContext;\n+    private long deactivationTimestamp = -1;\n+    private boolean isSpan;\n+\n+    public CallTree() {\n+    }\n+\n+    public void set(@Nullable CallTree parent, StackFrame frame, long nanoTime) {\n+        this.parent = parent;\n+        this.frame = frame;\n+        this.start = nanoTime;\n+    }\n+\n+    public void activation(TraceContext traceContext, long activationTimestamp) {\n+        this.activeContext = traceContext;\n+        this.activationTimestamp = activationTimestamp;\n+    }\n+\n+    protected void handleDeactivation(TraceContext deactivatedSpan, long timestamp) {\n+        if (deactivatedSpan.equals(activeContext)) {\n+            deactivationTimestamp = timestamp;\n+        } else {\n+            CallTree lastChild = getLastChild();\n+            if (lastChild != null && !lastChild.isEnded()) {\n+                lastChild.handleDeactivation(deactivatedSpan, timestamp);\n+            }\n+        }\n+    }\n+\n+    public static CallTree.Root createRoot(ObjectPool<CallTree.Root> rootPool, byte[] traceContext, @Nullable String serviceName, long nanoTime) {\n+        CallTree.Root root = rootPool.createInstance();\n+        root.set(traceContext, serviceName, nanoTime);\n+        return root;\n+    }\n+\n+    protected void addFrame(ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        count++;\n+        lastSeen = nanoTime;\n+        //     c ee   <- traceContext not set - they are not a child of the active span but the frame below them\n+        //   bbb dd   <- traceContext set\n+        //   ------   <- all new CallTree during this period should have the traceContext set\n+        // a aaaaaa a\n+        //  |      |\n+        // active  deactive\n+\n+        // this branch is already aware of the activation\n+        if (Objects.equals(this.activeContext, traceContext)) {\n+            traceContext = null;\n+        }\n+\n+        CallTree lastChild = getLastChild();\n+        // if the frame corresponding to the last child is not in the stack trace\n+        // it's assumed to have ended one tick ago\n+        boolean endChild = true;\n+        if (iterator.hasPrevious()) {\n+            final StackFrame frame = iterator.previous();\n+            if (lastChild != null) {\n+                if (!lastChild.isEnded() && frame.equals(lastChild.frame)) {\n+                    lastChild.addFrame(iterator, traceContext, activationTimestamp, nanoTime);\n+                    endChild = false;\n+                } else {\n+                    addChild(frame, iterator, traceContext, activationTimestamp, nanoTime);\n+                }\n+            } else {\n+                addChild(frame, iterator, traceContext, activationTimestamp, nanoTime);\n+            }\n+        }\n+        if (lastChild != null && !lastChild.isEnded() && endChild) {\n+            lastChild.end();\n+        }\n+    }\n+\n+    void addChild(StackFrame frame, ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        CallTree callTree = new CallTree();\n+        callTree.set(this, frame, nanoTime);\n+        if (traceContext != null) {\n+            callTree.activation(traceContext, activationTimestamp);\n+        }\n+        children.add(callTree);\n+        callTree.addFrame(iterator, null, activationTimestamp, nanoTime);\n+    }\n+\n+    long getDurationUs() {\n+        return (lastSeen - start) / 1000;\n+    }\n+\n+    public int getCount() {\n+        return count;\n+    }\n+\n+    public StackFrame getFrame() {\n+        return frame;\n+    }\n+\n+    public List<CallTree> getChildren() {\n+        return children;\n+    }\n+\n+    void end() {\n+        ended = true;\n+        // if the parent span has already been deactivated before this call tree node has ended\n+        // it means that this node is actually the parent of the already deactivated span\n+        //                     make b parent of a and pre-date the start of b to the activation of a\n+        // [c        ]    \u2500\u2500\u2510  [a(inferred) ]\n+        // \u2514[a(inferred)]   \u2502  [b(inferred)]\n+        //  [b(infer.) ]    \u2514\u25ba [c        ]\n+        //  \u2514\u2500[d(i.)]          \u2514\u2500\u2500[d(i.)]\n+        // see also profiler.CallTreeTest::testDectivationBeforeEnd\n+        if (deactivationHappenedBeforeEnd()) {\n+            start = Math.min(activationTimestamp, start);\n+            List<CallTree> callTrees = getChildren();\n+            for (int i = 0, size = callTrees.size(); i < size; i++) {\n+                CallTree child = callTrees.get(i);\n+                child.activation(activeContext, activationTimestamp);\n+                child.deactivationTimestamp = deactivationTimestamp;\n+                // re-run this logic for all children, even if they have already ended\n+                child.end();\n+            }\n+            activeContext = null;\n+            activationTimestamp = -1;\n+            deactivationTimestamp = -1;\n+        }\n+        CallTree lastChild = getLastChild();\n+        if (lastChild != null && !lastChild.isEnded()) {\n+            lastChild.end();\n+        }\n+    }\n+\n+    private boolean deactivationHappenedBeforeEnd() {\n+        return activeContext != null && deactivationTimestamp > -1 && lastSeen > deactivationTimestamp;\n+    }\n+\n+    public boolean isLeaf() {\n+        return children.isEmpty();\n+    }\n+\n+    /**\n+     * Returns {@code true} if this node has just one child and no self time.\n+     *\n+     * <pre>\n+     *  c\n+     *  b  <- b is a pillar\n+     * aaa\n+     * </pre>\n+     */\n+    private boolean isPillar() {\n+        return children.size() == 1 && children.get(0).count == count;\n+    }\n+\n+    @Nullable\n+    public CallTree getLastChild() {\n+        return children.size() > 0 ? children.get(children.size() - 1) : null;\n+    }\n+\n+    public boolean isEnded() {\n+        return ended;\n+    }\n+\n+    @Override\n+    public String toString() {\n+        StringBuilder sb = new StringBuilder();\n+        try {\n+            toString(sb);\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+        return sb.toString();\n+    }\n+\n+    public void toString(Appendable out) throws IOException {\n+        toString(out, 0);\n+    }\n+\n+    private void toString(Appendable out, int level) throws IOException {\n+        for (int i = 0; i < level; i++) {\n+            out.append(\"  \");\n+        }\n+        out.append(frame.getClassName())\n+            .append('.')\n+            .append(frame.getMethodName())\n+            .append(' ').append(Integer.toString(count))\n+            .append('\\n');\n+        for (CallTree node : children) {\n+            node.toString(out, level + 1);\n+        }\n+    }\n+\n+    void spanify(CallTree.Root root, TraceContext parentContext) {\n+        if (activeContext != null) {\n+            parentContext = activeContext;\n+        }\n+        Span span = null;\n+        if (!isPillar() || isLeaf()) {\n+            span = asSpan(root, parentContext);\n+            this.isSpan = true;\n+        }\n+        for (CallTree child : getChildren()) {\n+            child.spanify(root, span != null ? span.getTraceContext() : parentContext);\n+        }\n+        if (span != null) {\n+            span.end(span.getTimestamp() + getDurationUs());\n+        }\n+    }\n+\n+    protected Span asSpan(Root root, TraceContext parentContext) {\n+        Span span = parentContext.createSpan(root.getEpochMicros(this.start))\n+            .withType(\"app\")\n+            .withSubtype(\"inferred\");\n+\n+        frame.appendSimpleClassName(span.getNameForSerialization());\n+        span.appendToName(\"#\");\n+        span.appendToName(frame.getMethodName());\n+\n+        // we're not interested in the very bottom of the stack which contains things like accepting and handling connections\n+        if (!root.traceContext.equals(parentContext)) {\n+            // we're never spanifying the root\n+            assert this.parent != null;\n+            List<StackFrame> stackTrace = new ArrayList<>();\n+            this.parent.fillStackTrace(stackTrace);\n+            span.setStackTrace(stackTrace);\n+        } else {\n+            span.setStackTrace(Collections.<StackFrame>emptyList());\n+        }\n+        return span;\n+    }\n+\n+    /**\n+     * Fill in the stack trace up to the parent span\n+     */\n+    private void fillStackTrace(List<StackFrame> stackTrace) {\n+        if (parent != null && !this.isSpan) {\n+            stackTrace.add(frame);\n+            parent.fillStackTrace(stackTrace);\n+        }\n+    }\n+\n+    public void removeNodesFasterThan(float percent, int minCount) {\n+        int ticks = (int) (count * percent);\n+        removeNodesFasterThan(Math.max(ticks, minCount));\n+    }\n+\n+    public void removeNodesFasterThan(int minCount) {\n+        List<CallTree> callTrees = getChildren();\n+        for (int i = 0; i < callTrees.size(); i++) {\n+            CallTree child = callTrees.get(i);\n+            if (child.count < minCount) {\n+                callTrees.remove(i--);\n+            } else {\n+                child.removeNodesFasterThan(minCount);\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public void resetState() {\n+        parent = null;\n+        count = 0;\n+        frame = null;\n+        start = 0;\n+        lastSeen = 0;\n+        ended = false;\n+        activationTimestamp = -1;\n+        activeContext = null;\n+        deactivationTimestamp = -1;\n+        isSpan = false;\n+        children.clear();\n+    }\n+\n+    /**\n+     * A special kind of a {@link CallTree} node which represents the root of the call tree.\n+     * This acts as the interface to the outside to add new nodes to the tree or to update existing ones by\n+     * {@linkplain #addStackTrace(ElasticApmTracer, List, long) adding stack traces}.\n+     */\n+    public static class Root extends CallTree implements Recyclable {\n+        private static final StackFrame ROOT_FRAME = new StackFrame(\"root\", \"root\");\n+        protected TraceContext traceContext;\n+        private long activationTimestamp;\n+        @Nullable\n+        private TraceContext activeSpan;\n+        private byte[] activeSpanSerialized = new byte[TraceContext.SERIALIZED_LENGTH];", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 351}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2NjA5NzQ5OnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/CallTree.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQwOTozNTozOFrOFdyG_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxNToxNjo1OVrOFec8vA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Njc3NDAxMg==", "bodyText": "It would very useful if you add a detailed explanation about the algorithm as a javadoc of this method. Not all corner-cases handled, but the general concept.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366774012", "createdAt": "2020-01-15T09:35:38Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/CallTree.java", "diffHunk": "@@ -0,0 +1,422 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.Objects;\n+\n+/**\n+ * Converts a sequence of stack traces into a tree structure of method calls.\n+ * <pre>\n+ *             count\n+ *  b b     a      4\n+ * aaaa ->  \u251c\u2500b    1\n+ *          \u2514\u2500b    1\n+ * </pre>\n+ * <p>\n+ * It also stores information about which span is the parent of a particular call tree node,\n+ * based on which span has been {@linkplain ElasticApmTracer#getActive() active} at that time.\n+ * </p>\n+ * <p>\n+ * This allows to {@linkplain Root#spanify() infer spans from the call tree} which have the correct parent/child relationships\n+ * with the regular spans.\n+ * </p>\n+ */\n+public class CallTree implements Recyclable {\n+\n+    @Nullable\n+    private CallTree parent;\n+    protected int count;\n+    private List<CallTree> children = new ArrayList<>();\n+    @Nullable\n+    private StackFrame frame;\n+    protected long start;\n+    private long lastSeen;\n+    private boolean ended;\n+    private long activationTimestamp = -1;\n+    @Nullable\n+    private TraceContext activeContext;\n+    private long deactivationTimestamp = -1;\n+    private boolean isSpan;\n+\n+    public CallTree() {\n+    }\n+\n+    public void set(@Nullable CallTree parent, StackFrame frame, long nanoTime) {\n+        this.parent = parent;\n+        this.frame = frame;\n+        this.start = nanoTime;\n+    }\n+\n+    public void activation(TraceContext traceContext, long activationTimestamp) {\n+        this.activeContext = traceContext;\n+        this.activationTimestamp = activationTimestamp;\n+    }\n+\n+    protected void handleDeactivation(TraceContext deactivatedSpan, long timestamp) {\n+        if (deactivatedSpan.equals(activeContext)) {\n+            deactivationTimestamp = timestamp;\n+        } else {\n+            CallTree lastChild = getLastChild();\n+            if (lastChild != null && !lastChild.isEnded()) {\n+                lastChild.handleDeactivation(deactivatedSpan, timestamp);\n+            }\n+        }\n+    }\n+\n+    public static CallTree.Root createRoot(ObjectPool<CallTree.Root> rootPool, byte[] traceContext, @Nullable String serviceName, long nanoTime) {\n+        CallTree.Root root = rootPool.createInstance();\n+        root.set(traceContext, serviceName, nanoTime);\n+        return root;\n+    }\n+\n+    protected void addFrame(ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ3NTkwMA==", "bodyText": "Added some comments but did not go into details. Do you like it now? Any suggestions what/how to explain specifically?", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367475900", "createdAt": "2020-01-16T15:16:59Z", "author": {"login": "felixbarny"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/CallTree.java", "diffHunk": "@@ -0,0 +1,422 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.Objects;\n+\n+/**\n+ * Converts a sequence of stack traces into a tree structure of method calls.\n+ * <pre>\n+ *             count\n+ *  b b     a      4\n+ * aaaa ->  \u251c\u2500b    1\n+ *          \u2514\u2500b    1\n+ * </pre>\n+ * <p>\n+ * It also stores information about which span is the parent of a particular call tree node,\n+ * based on which span has been {@linkplain ElasticApmTracer#getActive() active} at that time.\n+ * </p>\n+ * <p>\n+ * This allows to {@linkplain Root#spanify() infer spans from the call tree} which have the correct parent/child relationships\n+ * with the regular spans.\n+ * </p>\n+ */\n+public class CallTree implements Recyclable {\n+\n+    @Nullable\n+    private CallTree parent;\n+    protected int count;\n+    private List<CallTree> children = new ArrayList<>();\n+    @Nullable\n+    private StackFrame frame;\n+    protected long start;\n+    private long lastSeen;\n+    private boolean ended;\n+    private long activationTimestamp = -1;\n+    @Nullable\n+    private TraceContext activeContext;\n+    private long deactivationTimestamp = -1;\n+    private boolean isSpan;\n+\n+    public CallTree() {\n+    }\n+\n+    public void set(@Nullable CallTree parent, StackFrame frame, long nanoTime) {\n+        this.parent = parent;\n+        this.frame = frame;\n+        this.start = nanoTime;\n+    }\n+\n+    public void activation(TraceContext traceContext, long activationTimestamp) {\n+        this.activeContext = traceContext;\n+        this.activationTimestamp = activationTimestamp;\n+    }\n+\n+    protected void handleDeactivation(TraceContext deactivatedSpan, long timestamp) {\n+        if (deactivatedSpan.equals(activeContext)) {\n+            deactivationTimestamp = timestamp;\n+        } else {\n+            CallTree lastChild = getLastChild();\n+            if (lastChild != null && !lastChild.isEnded()) {\n+                lastChild.handleDeactivation(deactivatedSpan, timestamp);\n+            }\n+        }\n+    }\n+\n+    public static CallTree.Root createRoot(ObjectPool<CallTree.Root> rootPool, byte[] traceContext, @Nullable String serviceName, long nanoTime) {\n+        CallTree.Root root = rootPool.createInstance();\n+        root.set(traceContext, serviceName, nanoTime);\n+        return root;\n+    }\n+\n+    protected void addFrame(ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Njc3NDAxMg=="}, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 107}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2Njk4NTUzOnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/CallTree.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQxNDo0MjoyNFrOFd6jFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxNDo0MDowNFrOFebl7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjkxMjI3OQ==", "bodyText": "I think we should also avoid creating spans when count < 2. If we take snapshots every 20 ms in a 2-second transaction, we may get 100 non-informative spans. More importantly, when someone will compare traces to one another they will seem as there are many arbitrary areas with random spans.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366912279", "createdAt": "2020-01-15T14:42:24Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/CallTree.java", "diffHunk": "@@ -0,0 +1,422 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.Objects;\n+\n+/**\n+ * Converts a sequence of stack traces into a tree structure of method calls.\n+ * <pre>\n+ *             count\n+ *  b b     a      4\n+ * aaaa ->  \u251c\u2500b    1\n+ *          \u2514\u2500b    1\n+ * </pre>\n+ * <p>\n+ * It also stores information about which span is the parent of a particular call tree node,\n+ * based on which span has been {@linkplain ElasticApmTracer#getActive() active} at that time.\n+ * </p>\n+ * <p>\n+ * This allows to {@linkplain Root#spanify() infer spans from the call tree} which have the correct parent/child relationships\n+ * with the regular spans.\n+ * </p>\n+ */\n+public class CallTree implements Recyclable {\n+\n+    @Nullable\n+    private CallTree parent;\n+    protected int count;\n+    private List<CallTree> children = new ArrayList<>();\n+    @Nullable\n+    private StackFrame frame;\n+    protected long start;\n+    private long lastSeen;\n+    private boolean ended;\n+    private long activationTimestamp = -1;\n+    @Nullable\n+    private TraceContext activeContext;\n+    private long deactivationTimestamp = -1;\n+    private boolean isSpan;\n+\n+    public CallTree() {\n+    }\n+\n+    public void set(@Nullable CallTree parent, StackFrame frame, long nanoTime) {\n+        this.parent = parent;\n+        this.frame = frame;\n+        this.start = nanoTime;\n+    }\n+\n+    public void activation(TraceContext traceContext, long activationTimestamp) {\n+        this.activeContext = traceContext;\n+        this.activationTimestamp = activationTimestamp;\n+    }\n+\n+    protected void handleDeactivation(TraceContext deactivatedSpan, long timestamp) {\n+        if (deactivatedSpan.equals(activeContext)) {\n+            deactivationTimestamp = timestamp;\n+        } else {\n+            CallTree lastChild = getLastChild();\n+            if (lastChild != null && !lastChild.isEnded()) {\n+                lastChild.handleDeactivation(deactivatedSpan, timestamp);\n+            }\n+        }\n+    }\n+\n+    public static CallTree.Root createRoot(ObjectPool<CallTree.Root> rootPool, byte[] traceContext, @Nullable String serviceName, long nanoTime) {\n+        CallTree.Root root = rootPool.createInstance();\n+        root.set(traceContext, serviceName, nanoTime);\n+        return root;\n+    }\n+\n+    protected void addFrame(ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        count++;\n+        lastSeen = nanoTime;\n+        //     c ee   <- traceContext not set - they are not a child of the active span but the frame below them\n+        //   bbb dd   <- traceContext set\n+        //   ------   <- all new CallTree during this period should have the traceContext set\n+        // a aaaaaa a\n+        //  |      |\n+        // active  deactive\n+\n+        // this branch is already aware of the activation\n+        if (Objects.equals(this.activeContext, traceContext)) {\n+            traceContext = null;\n+        }\n+\n+        CallTree lastChild = getLastChild();\n+        // if the frame corresponding to the last child is not in the stack trace\n+        // it's assumed to have ended one tick ago\n+        boolean endChild = true;\n+        if (iterator.hasPrevious()) {\n+            final StackFrame frame = iterator.previous();\n+            if (lastChild != null) {\n+                if (!lastChild.isEnded() && frame.equals(lastChild.frame)) {\n+                    lastChild.addFrame(iterator, traceContext, activationTimestamp, nanoTime);\n+                    endChild = false;\n+                } else {\n+                    addChild(frame, iterator, traceContext, activationTimestamp, nanoTime);\n+                }\n+            } else {\n+                addChild(frame, iterator, traceContext, activationTimestamp, nanoTime);\n+            }\n+        }\n+        if (lastChild != null && !lastChild.isEnded() && endChild) {\n+            lastChild.end();\n+        }\n+    }\n+\n+    void addChild(StackFrame frame, ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        CallTree callTree = new CallTree();\n+        callTree.set(this, frame, nanoTime);\n+        if (traceContext != null) {\n+            callTree.activation(traceContext, activationTimestamp);\n+        }\n+        children.add(callTree);\n+        callTree.addFrame(iterator, null, activationTimestamp, nanoTime);\n+    }\n+\n+    long getDurationUs() {\n+        return (lastSeen - start) / 1000;\n+    }\n+\n+    public int getCount() {\n+        return count;\n+    }\n+\n+    public StackFrame getFrame() {\n+        return frame;\n+    }\n+\n+    public List<CallTree> getChildren() {\n+        return children;\n+    }\n+\n+    void end() {\n+        ended = true;\n+        // if the parent span has already been deactivated before this call tree node has ended\n+        // it means that this node is actually the parent of the already deactivated span\n+        //                     make b parent of a and pre-date the start of b to the activation of a\n+        // [c        ]    \u2500\u2500\u2510  [a(inferred) ]\n+        // \u2514[a(inferred)]   \u2502  [b(inferred)]\n+        //  [b(infer.) ]    \u2514\u25ba [c        ]\n+        //  \u2514\u2500[d(i.)]          \u2514\u2500\u2500[d(i.)]\n+        // see also profiler.CallTreeTest::testDectivationBeforeEnd\n+        if (deactivationHappenedBeforeEnd()) {\n+            start = Math.min(activationTimestamp, start);\n+            List<CallTree> callTrees = getChildren();\n+            for (int i = 0, size = callTrees.size(); i < size; i++) {\n+                CallTree child = callTrees.get(i);\n+                child.activation(activeContext, activationTimestamp);\n+                child.deactivationTimestamp = deactivationTimestamp;\n+                // re-run this logic for all children, even if they have already ended\n+                child.end();\n+            }\n+            activeContext = null;\n+            activationTimestamp = -1;\n+            deactivationTimestamp = -1;\n+        }\n+        CallTree lastChild = getLastChild();\n+        if (lastChild != null && !lastChild.isEnded()) {\n+            lastChild.end();\n+        }\n+    }\n+\n+    private boolean deactivationHappenedBeforeEnd() {\n+        return activeContext != null && deactivationTimestamp > -1 && lastSeen > deactivationTimestamp;\n+    }\n+\n+    public boolean isLeaf() {\n+        return children.isEmpty();\n+    }\n+\n+    /**\n+     * Returns {@code true} if this node has just one child and no self time.\n+     *\n+     * <pre>\n+     *  c\n+     *  b  <- b is a pillar\n+     * aaa\n+     * </pre>\n+     */\n+    private boolean isPillar() {\n+        return children.size() == 1 && children.get(0).count == count;\n+    }\n+\n+    @Nullable\n+    public CallTree getLastChild() {\n+        return children.size() > 0 ? children.get(children.size() - 1) : null;\n+    }\n+\n+    public boolean isEnded() {\n+        return ended;\n+    }\n+\n+    @Override\n+    public String toString() {\n+        StringBuilder sb = new StringBuilder();\n+        try {\n+            toString(sb);\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+        return sb.toString();\n+    }\n+\n+    public void toString(Appendable out) throws IOException {\n+        toString(out, 0);\n+    }\n+\n+    private void toString(Appendable out, int level) throws IOException {\n+        for (int i = 0; i < level; i++) {\n+            out.append(\"  \");\n+        }\n+        out.append(frame.getClassName())\n+            .append('.')\n+            .append(frame.getMethodName())\n+            .append(' ').append(Integer.toString(count))\n+            .append('\\n');\n+        for (CallTree node : children) {\n+            node.toString(out, level + 1);\n+        }\n+    }\n+\n+    void spanify(CallTree.Root root, TraceContext parentContext) {\n+        if (activeContext != null) {\n+            parentContext = activeContext;\n+        }\n+        Span span = null;\n+        if (!isPillar() || isLeaf()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 264}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxNjAxNA==", "bodyText": "Those are filtered out in a separate step in co.elastic.apm.agent.profiler.CallTree#removeNodesFasterThan(float, int)", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367416014", "createdAt": "2020-01-16T13:28:40Z", "author": {"login": "felixbarny"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/CallTree.java", "diffHunk": "@@ -0,0 +1,422 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.Objects;\n+\n+/**\n+ * Converts a sequence of stack traces into a tree structure of method calls.\n+ * <pre>\n+ *             count\n+ *  b b     a      4\n+ * aaaa ->  \u251c\u2500b    1\n+ *          \u2514\u2500b    1\n+ * </pre>\n+ * <p>\n+ * It also stores information about which span is the parent of a particular call tree node,\n+ * based on which span has been {@linkplain ElasticApmTracer#getActive() active} at that time.\n+ * </p>\n+ * <p>\n+ * This allows to {@linkplain Root#spanify() infer spans from the call tree} which have the correct parent/child relationships\n+ * with the regular spans.\n+ * </p>\n+ */\n+public class CallTree implements Recyclable {\n+\n+    @Nullable\n+    private CallTree parent;\n+    protected int count;\n+    private List<CallTree> children = new ArrayList<>();\n+    @Nullable\n+    private StackFrame frame;\n+    protected long start;\n+    private long lastSeen;\n+    private boolean ended;\n+    private long activationTimestamp = -1;\n+    @Nullable\n+    private TraceContext activeContext;\n+    private long deactivationTimestamp = -1;\n+    private boolean isSpan;\n+\n+    public CallTree() {\n+    }\n+\n+    public void set(@Nullable CallTree parent, StackFrame frame, long nanoTime) {\n+        this.parent = parent;\n+        this.frame = frame;\n+        this.start = nanoTime;\n+    }\n+\n+    public void activation(TraceContext traceContext, long activationTimestamp) {\n+        this.activeContext = traceContext;\n+        this.activationTimestamp = activationTimestamp;\n+    }\n+\n+    protected void handleDeactivation(TraceContext deactivatedSpan, long timestamp) {\n+        if (deactivatedSpan.equals(activeContext)) {\n+            deactivationTimestamp = timestamp;\n+        } else {\n+            CallTree lastChild = getLastChild();\n+            if (lastChild != null && !lastChild.isEnded()) {\n+                lastChild.handleDeactivation(deactivatedSpan, timestamp);\n+            }\n+        }\n+    }\n+\n+    public static CallTree.Root createRoot(ObjectPool<CallTree.Root> rootPool, byte[] traceContext, @Nullable String serviceName, long nanoTime) {\n+        CallTree.Root root = rootPool.createInstance();\n+        root.set(traceContext, serviceName, nanoTime);\n+        return root;\n+    }\n+\n+    protected void addFrame(ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        count++;\n+        lastSeen = nanoTime;\n+        //     c ee   <- traceContext not set - they are not a child of the active span but the frame below them\n+        //   bbb dd   <- traceContext set\n+        //   ------   <- all new CallTree during this period should have the traceContext set\n+        // a aaaaaa a\n+        //  |      |\n+        // active  deactive\n+\n+        // this branch is already aware of the activation\n+        if (Objects.equals(this.activeContext, traceContext)) {\n+            traceContext = null;\n+        }\n+\n+        CallTree lastChild = getLastChild();\n+        // if the frame corresponding to the last child is not in the stack trace\n+        // it's assumed to have ended one tick ago\n+        boolean endChild = true;\n+        if (iterator.hasPrevious()) {\n+            final StackFrame frame = iterator.previous();\n+            if (lastChild != null) {\n+                if (!lastChild.isEnded() && frame.equals(lastChild.frame)) {\n+                    lastChild.addFrame(iterator, traceContext, activationTimestamp, nanoTime);\n+                    endChild = false;\n+                } else {\n+                    addChild(frame, iterator, traceContext, activationTimestamp, nanoTime);\n+                }\n+            } else {\n+                addChild(frame, iterator, traceContext, activationTimestamp, nanoTime);\n+            }\n+        }\n+        if (lastChild != null && !lastChild.isEnded() && endChild) {\n+            lastChild.end();\n+        }\n+    }\n+\n+    void addChild(StackFrame frame, ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        CallTree callTree = new CallTree();\n+        callTree.set(this, frame, nanoTime);\n+        if (traceContext != null) {\n+            callTree.activation(traceContext, activationTimestamp);\n+        }\n+        children.add(callTree);\n+        callTree.addFrame(iterator, null, activationTimestamp, nanoTime);\n+    }\n+\n+    long getDurationUs() {\n+        return (lastSeen - start) / 1000;\n+    }\n+\n+    public int getCount() {\n+        return count;\n+    }\n+\n+    public StackFrame getFrame() {\n+        return frame;\n+    }\n+\n+    public List<CallTree> getChildren() {\n+        return children;\n+    }\n+\n+    void end() {\n+        ended = true;\n+        // if the parent span has already been deactivated before this call tree node has ended\n+        // it means that this node is actually the parent of the already deactivated span\n+        //                     make b parent of a and pre-date the start of b to the activation of a\n+        // [c        ]    \u2500\u2500\u2510  [a(inferred) ]\n+        // \u2514[a(inferred)]   \u2502  [b(inferred)]\n+        //  [b(infer.) ]    \u2514\u25ba [c        ]\n+        //  \u2514\u2500[d(i.)]          \u2514\u2500\u2500[d(i.)]\n+        // see also profiler.CallTreeTest::testDectivationBeforeEnd\n+        if (deactivationHappenedBeforeEnd()) {\n+            start = Math.min(activationTimestamp, start);\n+            List<CallTree> callTrees = getChildren();\n+            for (int i = 0, size = callTrees.size(); i < size; i++) {\n+                CallTree child = callTrees.get(i);\n+                child.activation(activeContext, activationTimestamp);\n+                child.deactivationTimestamp = deactivationTimestamp;\n+                // re-run this logic for all children, even if they have already ended\n+                child.end();\n+            }\n+            activeContext = null;\n+            activationTimestamp = -1;\n+            deactivationTimestamp = -1;\n+        }\n+        CallTree lastChild = getLastChild();\n+        if (lastChild != null && !lastChild.isEnded()) {\n+            lastChild.end();\n+        }\n+    }\n+\n+    private boolean deactivationHappenedBeforeEnd() {\n+        return activeContext != null && deactivationTimestamp > -1 && lastSeen > deactivationTimestamp;\n+    }\n+\n+    public boolean isLeaf() {\n+        return children.isEmpty();\n+    }\n+\n+    /**\n+     * Returns {@code true} if this node has just one child and no self time.\n+     *\n+     * <pre>\n+     *  c\n+     *  b  <- b is a pillar\n+     * aaa\n+     * </pre>\n+     */\n+    private boolean isPillar() {\n+        return children.size() == 1 && children.get(0).count == count;\n+    }\n+\n+    @Nullable\n+    public CallTree getLastChild() {\n+        return children.size() > 0 ? children.get(children.size() - 1) : null;\n+    }\n+\n+    public boolean isEnded() {\n+        return ended;\n+    }\n+\n+    @Override\n+    public String toString() {\n+        StringBuilder sb = new StringBuilder();\n+        try {\n+            toString(sb);\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+        return sb.toString();\n+    }\n+\n+    public void toString(Appendable out) throws IOException {\n+        toString(out, 0);\n+    }\n+\n+    private void toString(Appendable out, int level) throws IOException {\n+        for (int i = 0; i < level; i++) {\n+            out.append(\"  \");\n+        }\n+        out.append(frame.getClassName())\n+            .append('.')\n+            .append(frame.getMethodName())\n+            .append(' ').append(Integer.toString(count))\n+            .append('\\n');\n+        for (CallTree node : children) {\n+            node.toString(out, level + 1);\n+        }\n+    }\n+\n+    void spanify(CallTree.Root root, TraceContext parentContext) {\n+        if (activeContext != null) {\n+            parentContext = activeContext;\n+        }\n+        Span span = null;\n+        if (!isPillar() || isLeaf()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjkxMjI3OQ=="}, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 264}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ1MzY3OA==", "bodyText": "In the spirit of runtime-call-tree-trimming, you can remove entire branches with count < 2 during the recursive end. If it doesn't complicate stuff too much, maybe worth considering.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367453678", "createdAt": "2020-01-16T14:40:04Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/CallTree.java", "diffHunk": "@@ -0,0 +1,422 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.Objects;\n+\n+/**\n+ * Converts a sequence of stack traces into a tree structure of method calls.\n+ * <pre>\n+ *             count\n+ *  b b     a      4\n+ * aaaa ->  \u251c\u2500b    1\n+ *          \u2514\u2500b    1\n+ * </pre>\n+ * <p>\n+ * It also stores information about which span is the parent of a particular call tree node,\n+ * based on which span has been {@linkplain ElasticApmTracer#getActive() active} at that time.\n+ * </p>\n+ * <p>\n+ * This allows to {@linkplain Root#spanify() infer spans from the call tree} which have the correct parent/child relationships\n+ * with the regular spans.\n+ * </p>\n+ */\n+public class CallTree implements Recyclable {\n+\n+    @Nullable\n+    private CallTree parent;\n+    protected int count;\n+    private List<CallTree> children = new ArrayList<>();\n+    @Nullable\n+    private StackFrame frame;\n+    protected long start;\n+    private long lastSeen;\n+    private boolean ended;\n+    private long activationTimestamp = -1;\n+    @Nullable\n+    private TraceContext activeContext;\n+    private long deactivationTimestamp = -1;\n+    private boolean isSpan;\n+\n+    public CallTree() {\n+    }\n+\n+    public void set(@Nullable CallTree parent, StackFrame frame, long nanoTime) {\n+        this.parent = parent;\n+        this.frame = frame;\n+        this.start = nanoTime;\n+    }\n+\n+    public void activation(TraceContext traceContext, long activationTimestamp) {\n+        this.activeContext = traceContext;\n+        this.activationTimestamp = activationTimestamp;\n+    }\n+\n+    protected void handleDeactivation(TraceContext deactivatedSpan, long timestamp) {\n+        if (deactivatedSpan.equals(activeContext)) {\n+            deactivationTimestamp = timestamp;\n+        } else {\n+            CallTree lastChild = getLastChild();\n+            if (lastChild != null && !lastChild.isEnded()) {\n+                lastChild.handleDeactivation(deactivatedSpan, timestamp);\n+            }\n+        }\n+    }\n+\n+    public static CallTree.Root createRoot(ObjectPool<CallTree.Root> rootPool, byte[] traceContext, @Nullable String serviceName, long nanoTime) {\n+        CallTree.Root root = rootPool.createInstance();\n+        root.set(traceContext, serviceName, nanoTime);\n+        return root;\n+    }\n+\n+    protected void addFrame(ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        count++;\n+        lastSeen = nanoTime;\n+        //     c ee   <- traceContext not set - they are not a child of the active span but the frame below them\n+        //   bbb dd   <- traceContext set\n+        //   ------   <- all new CallTree during this period should have the traceContext set\n+        // a aaaaaa a\n+        //  |      |\n+        // active  deactive\n+\n+        // this branch is already aware of the activation\n+        if (Objects.equals(this.activeContext, traceContext)) {\n+            traceContext = null;\n+        }\n+\n+        CallTree lastChild = getLastChild();\n+        // if the frame corresponding to the last child is not in the stack trace\n+        // it's assumed to have ended one tick ago\n+        boolean endChild = true;\n+        if (iterator.hasPrevious()) {\n+            final StackFrame frame = iterator.previous();\n+            if (lastChild != null) {\n+                if (!lastChild.isEnded() && frame.equals(lastChild.frame)) {\n+                    lastChild.addFrame(iterator, traceContext, activationTimestamp, nanoTime);\n+                    endChild = false;\n+                } else {\n+                    addChild(frame, iterator, traceContext, activationTimestamp, nanoTime);\n+                }\n+            } else {\n+                addChild(frame, iterator, traceContext, activationTimestamp, nanoTime);\n+            }\n+        }\n+        if (lastChild != null && !lastChild.isEnded() && endChild) {\n+            lastChild.end();\n+        }\n+    }\n+\n+    void addChild(StackFrame frame, ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        CallTree callTree = new CallTree();\n+        callTree.set(this, frame, nanoTime);\n+        if (traceContext != null) {\n+            callTree.activation(traceContext, activationTimestamp);\n+        }\n+        children.add(callTree);\n+        callTree.addFrame(iterator, null, activationTimestamp, nanoTime);\n+    }\n+\n+    long getDurationUs() {\n+        return (lastSeen - start) / 1000;\n+    }\n+\n+    public int getCount() {\n+        return count;\n+    }\n+\n+    public StackFrame getFrame() {\n+        return frame;\n+    }\n+\n+    public List<CallTree> getChildren() {\n+        return children;\n+    }\n+\n+    void end() {\n+        ended = true;\n+        // if the parent span has already been deactivated before this call tree node has ended\n+        // it means that this node is actually the parent of the already deactivated span\n+        //                     make b parent of a and pre-date the start of b to the activation of a\n+        // [c        ]    \u2500\u2500\u2510  [a(inferred) ]\n+        // \u2514[a(inferred)]   \u2502  [b(inferred)]\n+        //  [b(infer.) ]    \u2514\u25ba [c        ]\n+        //  \u2514\u2500[d(i.)]          \u2514\u2500\u2500[d(i.)]\n+        // see also profiler.CallTreeTest::testDectivationBeforeEnd\n+        if (deactivationHappenedBeforeEnd()) {\n+            start = Math.min(activationTimestamp, start);\n+            List<CallTree> callTrees = getChildren();\n+            for (int i = 0, size = callTrees.size(); i < size; i++) {\n+                CallTree child = callTrees.get(i);\n+                child.activation(activeContext, activationTimestamp);\n+                child.deactivationTimestamp = deactivationTimestamp;\n+                // re-run this logic for all children, even if they have already ended\n+                child.end();\n+            }\n+            activeContext = null;\n+            activationTimestamp = -1;\n+            deactivationTimestamp = -1;\n+        }\n+        CallTree lastChild = getLastChild();\n+        if (lastChild != null && !lastChild.isEnded()) {\n+            lastChild.end();\n+        }\n+    }\n+\n+    private boolean deactivationHappenedBeforeEnd() {\n+        return activeContext != null && deactivationTimestamp > -1 && lastSeen > deactivationTimestamp;\n+    }\n+\n+    public boolean isLeaf() {\n+        return children.isEmpty();\n+    }\n+\n+    /**\n+     * Returns {@code true} if this node has just one child and no self time.\n+     *\n+     * <pre>\n+     *  c\n+     *  b  <- b is a pillar\n+     * aaa\n+     * </pre>\n+     */\n+    private boolean isPillar() {\n+        return children.size() == 1 && children.get(0).count == count;\n+    }\n+\n+    @Nullable\n+    public CallTree getLastChild() {\n+        return children.size() > 0 ? children.get(children.size() - 1) : null;\n+    }\n+\n+    public boolean isEnded() {\n+        return ended;\n+    }\n+\n+    @Override\n+    public String toString() {\n+        StringBuilder sb = new StringBuilder();\n+        try {\n+            toString(sb);\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+        return sb.toString();\n+    }\n+\n+    public void toString(Appendable out) throws IOException {\n+        toString(out, 0);\n+    }\n+\n+    private void toString(Appendable out, int level) throws IOException {\n+        for (int i = 0; i < level; i++) {\n+            out.append(\"  \");\n+        }\n+        out.append(frame.getClassName())\n+            .append('.')\n+            .append(frame.getMethodName())\n+            .append(' ').append(Integer.toString(count))\n+            .append('\\n');\n+        for (CallTree node : children) {\n+            node.toString(out, level + 1);\n+        }\n+    }\n+\n+    void spanify(CallTree.Root root, TraceContext parentContext) {\n+        if (activeContext != null) {\n+            parentContext = activeContext;\n+        }\n+        Span span = null;\n+        if (!isPillar() || isLeaf()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjkxMjI3OQ=="}, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 264}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2NzQwMDAyOnYy", "diffSide": "RIGHT", "path": "apm-agent-core/src/main/java/co/elastic/apm/agent/objectpool/impl/ListBasedObjectPool.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQxNjozMzowMFrOFd-k_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQwOTo0NzozOVrOFeTgvw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Njk3ODMwMg==", "bodyText": "What's the benefit over the queue-based pool?", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366978302", "createdAt": "2020-01-15T16:33:00Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-core/src/main/java/co/elastic/apm/agent/objectpool/impl/ListBasedObjectPool.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * \n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.objectpool.impl;\n+\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.List;\n+\n+public class ListBasedObjectPool<T> extends AbstractObjectPool<T> {\n+\n+    private final List<T> pool;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzMyMTI3OQ==", "bodyText": "Mainly that it can be used with a plain ArrayList, useful in single-threaded scenarios. Adding Javadoc.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367321279", "createdAt": "2020-01-16T09:47:39Z", "author": {"login": "felixbarny"}, "path": "apm-agent-core/src/main/java/co/elastic/apm/agent/objectpool/impl/ListBasedObjectPool.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * \n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.objectpool.impl;\n+\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.List;\n+\n+public class ListBasedObjectPool<T> extends AbstractObjectPool<T> {\n+\n+    private final List<T> pool;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Njk3ODMwMg=="}, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2NzQ0MzYzOnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/CallTree.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQxNjo0NToxN1rOFd_AAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxNToxMTozMlrOFecv_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Njk4NTIxOQ==", "bodyText": "If you find an easy and cheap way (i.e. without getting the full stack trace) to get Transaction's frame in the root, you can cut all the unnecessary call tree \"trunk\".", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366985219", "createdAt": "2020-01-15T16:45:17Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/CallTree.java", "diffHunk": "@@ -0,0 +1,422 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.Objects;\n+\n+/**\n+ * Converts a sequence of stack traces into a tree structure of method calls.\n+ * <pre>\n+ *             count\n+ *  b b     a      4\n+ * aaaa ->  \u251c\u2500b    1\n+ *          \u2514\u2500b    1\n+ * </pre>\n+ * <p>\n+ * It also stores information about which span is the parent of a particular call tree node,\n+ * based on which span has been {@linkplain ElasticApmTracer#getActive() active} at that time.\n+ * </p>\n+ * <p>\n+ * This allows to {@linkplain Root#spanify() infer spans from the call tree} which have the correct parent/child relationships\n+ * with the regular spans.\n+ * </p>\n+ */\n+public class CallTree implements Recyclable {\n+\n+    @Nullable\n+    private CallTree parent;\n+    protected int count;\n+    private List<CallTree> children = new ArrayList<>();\n+    @Nullable\n+    private StackFrame frame;\n+    protected long start;\n+    private long lastSeen;\n+    private boolean ended;\n+    private long activationTimestamp = -1;\n+    @Nullable\n+    private TraceContext activeContext;\n+    private long deactivationTimestamp = -1;\n+    private boolean isSpan;\n+\n+    public CallTree() {\n+    }\n+\n+    public void set(@Nullable CallTree parent, StackFrame frame, long nanoTime) {\n+        this.parent = parent;\n+        this.frame = frame;\n+        this.start = nanoTime;\n+    }\n+\n+    public void activation(TraceContext traceContext, long activationTimestamp) {\n+        this.activeContext = traceContext;\n+        this.activationTimestamp = activationTimestamp;\n+    }\n+\n+    protected void handleDeactivation(TraceContext deactivatedSpan, long timestamp) {\n+        if (deactivatedSpan.equals(activeContext)) {\n+            deactivationTimestamp = timestamp;\n+        } else {\n+            CallTree lastChild = getLastChild();\n+            if (lastChild != null && !lastChild.isEnded()) {\n+                lastChild.handleDeactivation(deactivatedSpan, timestamp);\n+            }\n+        }\n+    }\n+\n+    public static CallTree.Root createRoot(ObjectPool<CallTree.Root> rootPool, byte[] traceContext, @Nullable String serviceName, long nanoTime) {\n+        CallTree.Root root = rootPool.createInstance();\n+        root.set(traceContext, serviceName, nanoTime);\n+        return root;\n+    }\n+\n+    protected void addFrame(ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        count++;\n+        lastSeen = nanoTime;\n+        //     c ee   <- traceContext not set - they are not a child of the active span but the frame below them\n+        //   bbb dd   <- traceContext set\n+        //   ------   <- all new CallTree during this period should have the traceContext set\n+        // a aaaaaa a\n+        //  |      |\n+        // active  deactive\n+\n+        // this branch is already aware of the activation\n+        if (Objects.equals(this.activeContext, traceContext)) {\n+            traceContext = null;\n+        }\n+\n+        CallTree lastChild = getLastChild();\n+        // if the frame corresponding to the last child is not in the stack trace\n+        // it's assumed to have ended one tick ago\n+        boolean endChild = true;\n+        if (iterator.hasPrevious()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 126}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzMzNTk0Mg==", "bodyText": "It would probably be relatively easy to provide the option to set the class and method name when creating a transaction. But we can't require that as it wouldn't work with bridges. I don't see a generic solution that does not create overhead and allocations.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367335942", "createdAt": "2020-01-16T10:17:08Z", "author": {"login": "felixbarny"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/CallTree.java", "diffHunk": "@@ -0,0 +1,422 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.Objects;\n+\n+/**\n+ * Converts a sequence of stack traces into a tree structure of method calls.\n+ * <pre>\n+ *             count\n+ *  b b     a      4\n+ * aaaa ->  \u251c\u2500b    1\n+ *          \u2514\u2500b    1\n+ * </pre>\n+ * <p>\n+ * It also stores information about which span is the parent of a particular call tree node,\n+ * based on which span has been {@linkplain ElasticApmTracer#getActive() active} at that time.\n+ * </p>\n+ * <p>\n+ * This allows to {@linkplain Root#spanify() infer spans from the call tree} which have the correct parent/child relationships\n+ * with the regular spans.\n+ * </p>\n+ */\n+public class CallTree implements Recyclable {\n+\n+    @Nullable\n+    private CallTree parent;\n+    protected int count;\n+    private List<CallTree> children = new ArrayList<>();\n+    @Nullable\n+    private StackFrame frame;\n+    protected long start;\n+    private long lastSeen;\n+    private boolean ended;\n+    private long activationTimestamp = -1;\n+    @Nullable\n+    private TraceContext activeContext;\n+    private long deactivationTimestamp = -1;\n+    private boolean isSpan;\n+\n+    public CallTree() {\n+    }\n+\n+    public void set(@Nullable CallTree parent, StackFrame frame, long nanoTime) {\n+        this.parent = parent;\n+        this.frame = frame;\n+        this.start = nanoTime;\n+    }\n+\n+    public void activation(TraceContext traceContext, long activationTimestamp) {\n+        this.activeContext = traceContext;\n+        this.activationTimestamp = activationTimestamp;\n+    }\n+\n+    protected void handleDeactivation(TraceContext deactivatedSpan, long timestamp) {\n+        if (deactivatedSpan.equals(activeContext)) {\n+            deactivationTimestamp = timestamp;\n+        } else {\n+            CallTree lastChild = getLastChild();\n+            if (lastChild != null && !lastChild.isEnded()) {\n+                lastChild.handleDeactivation(deactivatedSpan, timestamp);\n+            }\n+        }\n+    }\n+\n+    public static CallTree.Root createRoot(ObjectPool<CallTree.Root> rootPool, byte[] traceContext, @Nullable String serviceName, long nanoTime) {\n+        CallTree.Root root = rootPool.createInstance();\n+        root.set(traceContext, serviceName, nanoTime);\n+        return root;\n+    }\n+\n+    protected void addFrame(ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        count++;\n+        lastSeen = nanoTime;\n+        //     c ee   <- traceContext not set - they are not a child of the active span but the frame below them\n+        //   bbb dd   <- traceContext set\n+        //   ------   <- all new CallTree during this period should have the traceContext set\n+        // a aaaaaa a\n+        //  |      |\n+        // active  deactive\n+\n+        // this branch is already aware of the activation\n+        if (Objects.equals(this.activeContext, traceContext)) {\n+            traceContext = null;\n+        }\n+\n+        CallTree lastChild = getLastChild();\n+        // if the frame corresponding to the last child is not in the stack trace\n+        // it's assumed to have ended one tick ago\n+        boolean endChild = true;\n+        if (iterator.hasPrevious()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Njk4NTIxOQ=="}, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 126}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ3MjYzOQ==", "bodyText": "Right, this is not for now. Would make sense within this PR only if it is simple enough to do without overhead. We can consider as future enhancement if the need arises.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367472639", "createdAt": "2020-01-16T15:11:32Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/CallTree.java", "diffHunk": "@@ -0,0 +1,422 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.Objects;\n+\n+/**\n+ * Converts a sequence of stack traces into a tree structure of method calls.\n+ * <pre>\n+ *             count\n+ *  b b     a      4\n+ * aaaa ->  \u251c\u2500b    1\n+ *          \u2514\u2500b    1\n+ * </pre>\n+ * <p>\n+ * It also stores information about which span is the parent of a particular call tree node,\n+ * based on which span has been {@linkplain ElasticApmTracer#getActive() active} at that time.\n+ * </p>\n+ * <p>\n+ * This allows to {@linkplain Root#spanify() infer spans from the call tree} which have the correct parent/child relationships\n+ * with the regular spans.\n+ * </p>\n+ */\n+public class CallTree implements Recyclable {\n+\n+    @Nullable\n+    private CallTree parent;\n+    protected int count;\n+    private List<CallTree> children = new ArrayList<>();\n+    @Nullable\n+    private StackFrame frame;\n+    protected long start;\n+    private long lastSeen;\n+    private boolean ended;\n+    private long activationTimestamp = -1;\n+    @Nullable\n+    private TraceContext activeContext;\n+    private long deactivationTimestamp = -1;\n+    private boolean isSpan;\n+\n+    public CallTree() {\n+    }\n+\n+    public void set(@Nullable CallTree parent, StackFrame frame, long nanoTime) {\n+        this.parent = parent;\n+        this.frame = frame;\n+        this.start = nanoTime;\n+    }\n+\n+    public void activation(TraceContext traceContext, long activationTimestamp) {\n+        this.activeContext = traceContext;\n+        this.activationTimestamp = activationTimestamp;\n+    }\n+\n+    protected void handleDeactivation(TraceContext deactivatedSpan, long timestamp) {\n+        if (deactivatedSpan.equals(activeContext)) {\n+            deactivationTimestamp = timestamp;\n+        } else {\n+            CallTree lastChild = getLastChild();\n+            if (lastChild != null && !lastChild.isEnded()) {\n+                lastChild.handleDeactivation(deactivatedSpan, timestamp);\n+            }\n+        }\n+    }\n+\n+    public static CallTree.Root createRoot(ObjectPool<CallTree.Root> rootPool, byte[] traceContext, @Nullable String serviceName, long nanoTime) {\n+        CallTree.Root root = rootPool.createInstance();\n+        root.set(traceContext, serviceName, nanoTime);\n+        return root;\n+    }\n+\n+    protected void addFrame(ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        count++;\n+        lastSeen = nanoTime;\n+        //     c ee   <- traceContext not set - they are not a child of the active span but the frame below them\n+        //   bbb dd   <- traceContext set\n+        //   ------   <- all new CallTree during this period should have the traceContext set\n+        // a aaaaaa a\n+        //  |      |\n+        // active  deactive\n+\n+        // this branch is already aware of the activation\n+        if (Objects.equals(this.activeContext, traceContext)) {\n+            traceContext = null;\n+        }\n+\n+        CallTree lastChild = getLastChild();\n+        // if the frame corresponding to the last child is not in the stack trace\n+        // it's assumed to have ended one tick ago\n+        boolean endChild = true;\n+        if (iterator.hasPrevious()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Njk4NTIxOQ=="}, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 126}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2NzQ2MTgzOnYy", "diffSide": "RIGHT", "path": "docs/supported-technologies.asciidoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQxNjo1MDoyOFrOFd_LOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQxNjo1MDoyOFrOFd_LOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Njk4ODA4OQ==", "bodyText": "Let's not call it profiler, we already know how people can misuse this...", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366988089", "createdAt": "2020-01-15T16:50:28Z", "author": {"login": "eyalkoren"}, "path": "docs/supported-technologies.asciidoc", "diffHunk": "@@ -378,13 +378,29 @@ If you are seeing gaps in the span timeline and want to include certain methods,\n |Less flexible on it's own but can be combined with the API.\n  Just get the <<api-current-span, current span>> on an annotated method and customize the span to your liking.\n \n-|Configuration\n+|Sampling-based profiler (incubating) added[1.13.0]\n+|Leverages https://github.com/jvm-profiling-tools/async-profiler[async-profiler]\n+ to periodically record which methods are running (stack traces).\n+ Enable by setting <<config-profiling-spans-enabled, `profiling_spans_enabled`>> to `true`.\n+|Very low overhead, no code changes required.\n+ Great to find out which parts of the code make your application slow,\n+ without having to apply application-specific configuration.\n+|Does not work on Windows.\n+ Only creates spans while a profiling session is ongoing.\n+ This can be controlled via <<config-profiling-duration, `profiling_duration`>> and <<config-profiling-interval, `profiling_interval`>>.\n+ The duration of profiler-inferred spans are not exact measurements, only estimates.\n+ The accuracy depends on <<config-profiling-sampling-interval, `profiling_sampling_interval`>>.\n+\n+|Instrumentation-based profiler", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2NzgyMjkwOnYy", "diffSide": "RIGHT", "path": "CHANGELOG.asciidoc", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQxODo1MDozOFrOFeCvCQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQwOToyODoyN1rOFeS8dg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0NjQwOQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * Instrument log4j Logger#error(String, Throwable) (#919)\n          \n          \n            \n            * Instrument log4j Logger#error(String, Throwable) ({pull}919[#919])", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367046409", "createdAt": "2020-01-15T18:50:38Z", "author": {"login": "bmorelli25"}, "path": "CHANGELOG.asciidoc", "diffHunk": "@@ -31,6 +31,11 @@ endif::[]\n * Instrument log4j Logger#error(String, Throwable) ({pull}919[#919]) Automatically captures exceptions when calling `logger.error(\"message\", exception)`\n * Add instrumentation for external process execution through `java.lang.Process` and Apache `commons-exec` - {pull}903[#903]\n * Add `destination` fields to exit span contexts - {pull}976[#976]\n+* Instrument log4j Logger#error(String, Throwable) (#919)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0NjU4MA==", "bodyText": "Actually, looks like this is already in the changelog on L31. Might just wanna remove L34-35", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367046580", "createdAt": "2020-01-15T18:51:00Z", "author": {"login": "bmorelli25"}, "path": "CHANGELOG.asciidoc", "diffHunk": "@@ -31,6 +31,11 @@ endif::[]\n * Instrument log4j Logger#error(String, Throwable) ({pull}919[#919]) Automatically captures exceptions when calling `logger.error(\"message\", exception)`\n * Add instrumentation for external process execution through `java.lang.Process` and Apache `commons-exec` - {pull}903[#903]\n * Add `destination` fields to exit span contexts - {pull}976[#976]\n+* Instrument log4j Logger#error(String, Throwable) (#919)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0NjQwOQ=="}, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzMxMTk5MA==", "bodyText": "Hm, not sure how it got there must have been some error on while rebasing \ud83e\udd37\u200d\u2642\nGood catch!", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367311990", "createdAt": "2020-01-16T09:28:27Z", "author": {"login": "felixbarny"}, "path": "CHANGELOG.asciidoc", "diffHunk": "@@ -31,6 +31,11 @@ endif::[]\n * Instrument log4j Logger#error(String, Throwable) ({pull}919[#919]) Automatically captures exceptions when calling `logger.error(\"message\", exception)`\n * Add instrumentation for external process execution through `java.lang.Process` and Apache `commons-exec` - {pull}903[#903]\n * Add `destination` fields to exit span contexts - {pull}976[#976]\n+* Instrument log4j Logger#error(String, Throwable) (#919)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0NjQwOQ=="}, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2Nzg1Nzk2OnYy", "diffSide": "RIGHT", "path": "docs/configuration.asciidoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQxOTowMjo1M1rOFeDFdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQxOTowMjo1M1rOFeDFdA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA1MjE0OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The default unit for this option is `ms`\n          \n          \n            \n            The default unit for this option is `ms`.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367052148", "createdAt": "2020-01-15T19:02:53Z", "author": {"login": "bmorelli25"}, "path": "docs/configuration.asciidoc", "diffHunk": "@@ -1204,6 +1218,173 @@ Prepending an element with `(?-i)` makes the matching case sensitive.\n | `elastic.apm.ignore_message_queues` | `ignore_message_queues` | `ELASTIC_APM_IGNORE_MESSAGE_QUEUES`\n |============\n \n+[[config-profiling]]\n+=== Profiling configuration options\n+// This file is auto generated. Please make your changes in *Configuration.java (for example CoreConfiguration.java) and execute ConfigurationExporter\n+[float]\n+[[config-profiling-spans-enabled]]\n+==== `profiling_spans_enabled` (added[1.13.0])\n+\n+Set to `true` to make the agent create spans for method executions based on\n+https://github.com/jvm-profiling-tools/async-profiler[async-profiler], a sampling aka statistical profiler.\n+\n+If this is enabled, the agent will start a profiling session every\n+<<config-profiling-interval, `profiling_interval`>> which lasts for <<config-profiling-duration, `profiling_duration`>>.\n+If a transaction happens within a profiling session,\n+the agent creates spans for slow methods.\n+\n+Note that due to the nature of how sampling profilers work,\n+the duration of the inferred spans are not exact, but only estimations.\n+The <<config-profiling-sampling-interval, `profiling_sampling_interval`>> lets you fine tune the trade-off between accuracy and overhead.\n+\n+NOTE: This feature is not available on Windows\n+\n+\n+[options=\"header\"]\n+|============\n+| Default                          | Type                | Dynamic\n+| `false` | Boolean | true\n+|============\n+\n+\n+[options=\"header\"]\n+|============\n+| Java System Properties      | Property file   | Environment\n+| `elastic.apm.profiling_spans_enabled` | `profiling_spans_enabled` | `ELASTIC_APM_PROFILING_SPANS_ENABLED`\n+|============\n+\n+// This file is auto generated. Please make your changes in *Configuration.java (for example CoreConfiguration.java) and execute ConfigurationExporter\n+[float]\n+[[config-profiling-sampling-interval]]\n+==== `profiling_sampling_interval` (added[1.13.0])\n+\n+The frequency at which stack traces are gathered within a profiling session.\n+The lower you set it, the more accurate the durations will be.\n+This comes at the expense of higher overhead and more spans for potentially irrelevant operations.\n+The minimal duration of a profiling-inferred span is the same as the value of this setting.\n+\n+Supports the duration suffixes `ms`, `s` and `m`.\n+Example: `20ms`.\n+The default unit for this option is `ms`", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 79}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2Nzg2MTUzOnYy", "diffSide": "RIGHT", "path": "docs/configuration.asciidoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQxOTowNDowOVrOFeDHqQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQxOTowNDowOVrOFeDHqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA1MjcxMw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The default unit for this option is `s`\n          \n          \n            \n            The default unit for this option is `s`.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367052713", "createdAt": "2020-01-15T19:04:09Z", "author": {"login": "bmorelli25"}, "path": "docs/configuration.asciidoc", "diffHunk": "@@ -1204,6 +1218,173 @@ Prepending an element with `(?-i)` makes the matching case sensitive.\n | `elastic.apm.ignore_message_queues` | `ignore_message_queues` | `ELASTIC_APM_IGNORE_MESSAGE_QUEUES`\n |============\n \n+[[config-profiling]]\n+=== Profiling configuration options\n+// This file is auto generated. Please make your changes in *Configuration.java (for example CoreConfiguration.java) and execute ConfigurationExporter\n+[float]\n+[[config-profiling-spans-enabled]]\n+==== `profiling_spans_enabled` (added[1.13.0])\n+\n+Set to `true` to make the agent create spans for method executions based on\n+https://github.com/jvm-profiling-tools/async-profiler[async-profiler], a sampling aka statistical profiler.\n+\n+If this is enabled, the agent will start a profiling session every\n+<<config-profiling-interval, `profiling_interval`>> which lasts for <<config-profiling-duration, `profiling_duration`>>.\n+If a transaction happens within a profiling session,\n+the agent creates spans for slow methods.\n+\n+Note that due to the nature of how sampling profilers work,\n+the duration of the inferred spans are not exact, but only estimations.\n+The <<config-profiling-sampling-interval, `profiling_sampling_interval`>> lets you fine tune the trade-off between accuracy and overhead.\n+\n+NOTE: This feature is not available on Windows\n+\n+\n+[options=\"header\"]\n+|============\n+| Default                          | Type                | Dynamic\n+| `false` | Boolean | true\n+|============\n+\n+\n+[options=\"header\"]\n+|============\n+| Java System Properties      | Property file   | Environment\n+| `elastic.apm.profiling_spans_enabled` | `profiling_spans_enabled` | `ELASTIC_APM_PROFILING_SPANS_ENABLED`\n+|============\n+\n+// This file is auto generated. Please make your changes in *Configuration.java (for example CoreConfiguration.java) and execute ConfigurationExporter\n+[float]\n+[[config-profiling-sampling-interval]]\n+==== `profiling_sampling_interval` (added[1.13.0])\n+\n+The frequency at which stack traces are gathered within a profiling session.\n+The lower you set it, the more accurate the durations will be.\n+This comes at the expense of higher overhead and more spans for potentially irrelevant operations.\n+The minimal duration of a profiling-inferred span is the same as the value of this setting.\n+\n+Supports the duration suffixes `ms`, `s` and `m`.\n+Example: `20ms`.\n+The default unit for this option is `ms`\n+\n+[options=\"header\"]\n+|============\n+| Default                          | Type                | Dynamic\n+| `20ms` | TimeDuration | true\n+|============\n+\n+\n+[options=\"header\"]\n+|============\n+| Java System Properties      | Property file   | Environment\n+| `elastic.apm.profiling_sampling_interval` | `profiling_sampling_interval` | `ELASTIC_APM_PROFILING_SAMPLING_INTERVAL`\n+|============\n+\n+// This file is auto generated. Please make your changes in *Configuration.java (for example CoreConfiguration.java) and execute ConfigurationExporter\n+[float]\n+[[config-profiling-included-classes]]\n+==== `profiling_included_classes` (added[1.13.0])\n+\n+If set, the agent will only create inferred spans for methods which match this list.\n+Setting a value may slightly increase performance and can reduce clutter by only creating spans for the classes you are interested in.\n+Example: `org.example.myapp.*`\n+\n+This option supports the wildcard `*`, which matches zero or more characters.\n+Examples: `/foo/*/bar/*/baz*`, `*foo*`.\n+Matching is case insensitive by default.\n+Prepending an element with `(?-i)` makes the matching case sensitive.\n+\n+\n+[options=\"header\"]\n+|============\n+| Default                          | Type                | Dynamic\n+| `*` | List | true\n+|============\n+\n+\n+[options=\"header\"]\n+|============\n+| Java System Properties      | Property file   | Environment\n+| `elastic.apm.profiling_included_classes` | `profiling_included_classes` | `ELASTIC_APM_PROFILING_INCLUDED_CLASSES`\n+|============\n+\n+// This file is auto generated. Please make your changes in *Configuration.java (for example CoreConfiguration.java) and execute ConfigurationExporter\n+[float]\n+[[config-profiling-excluded-classes]]\n+==== `profiling_excluded_classes` (added[1.13.0])\n+\n+Excludes classes for which no profiler-inferred spans should be created.\n+\n+This option supports the wildcard `*`, which matches zero or more characters.\n+Examples: `/foo/*/bar/*/baz*`, `*foo*`.\n+Matching is case insensitive by default.\n+Prepending an element with `(?-i)` makes the matching case sensitive.\n+\n+\n+[options=\"header\"]\n+|============\n+| Default                          | Type                | Dynamic\n+| `(?-i)java.*, (?-i)javax.*, (?-i)sun.*, (?-i)com.sun.*, (?-i)jdk.*` | List | true\n+|============\n+\n+\n+[options=\"header\"]\n+|============\n+| Java System Properties      | Property file   | Environment\n+| `elastic.apm.profiling_excluded_classes` | `profiling_excluded_classes` | `ELASTIC_APM_PROFILING_EXCLUDED_CLASSES`\n+|============\n+\n+// This file is auto generated. Please make your changes in *Configuration.java (for example CoreConfiguration.java) and execute ConfigurationExporter\n+[float]\n+[[config-profiling-interval]]\n+==== `profiling_interval` (added[1.13.0])\n+\n+The interval at which profiling sessions should be started.\n+\n+Supports the duration suffixes `ms`, `s` and `m`.\n+Example: `61s`.\n+The default unit for this option is `s`", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 157}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2Nzg2MTc5OnYy", "diffSide": "RIGHT", "path": "docs/configuration.asciidoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQxOTowNDoxNlrOFeDH3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQxOTowNDoxNlrOFeDH3g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA1Mjc2Ng==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The default unit for this option is `s`\n          \n          \n            \n            The default unit for this option is `s`.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367052766", "createdAt": "2020-01-15T19:04:16Z", "author": {"login": "bmorelli25"}, "path": "docs/configuration.asciidoc", "diffHunk": "@@ -1204,6 +1218,173 @@ Prepending an element with `(?-i)` makes the matching case sensitive.\n | `elastic.apm.ignore_message_queues` | `ignore_message_queues` | `ELASTIC_APM_IGNORE_MESSAGE_QUEUES`\n |============\n \n+[[config-profiling]]\n+=== Profiling configuration options\n+// This file is auto generated. Please make your changes in *Configuration.java (for example CoreConfiguration.java) and execute ConfigurationExporter\n+[float]\n+[[config-profiling-spans-enabled]]\n+==== `profiling_spans_enabled` (added[1.13.0])\n+\n+Set to `true` to make the agent create spans for method executions based on\n+https://github.com/jvm-profiling-tools/async-profiler[async-profiler], a sampling aka statistical profiler.\n+\n+If this is enabled, the agent will start a profiling session every\n+<<config-profiling-interval, `profiling_interval`>> which lasts for <<config-profiling-duration, `profiling_duration`>>.\n+If a transaction happens within a profiling session,\n+the agent creates spans for slow methods.\n+\n+Note that due to the nature of how sampling profilers work,\n+the duration of the inferred spans are not exact, but only estimations.\n+The <<config-profiling-sampling-interval, `profiling_sampling_interval`>> lets you fine tune the trade-off between accuracy and overhead.\n+\n+NOTE: This feature is not available on Windows\n+\n+\n+[options=\"header\"]\n+|============\n+| Default                          | Type                | Dynamic\n+| `false` | Boolean | true\n+|============\n+\n+\n+[options=\"header\"]\n+|============\n+| Java System Properties      | Property file   | Environment\n+| `elastic.apm.profiling_spans_enabled` | `profiling_spans_enabled` | `ELASTIC_APM_PROFILING_SPANS_ENABLED`\n+|============\n+\n+// This file is auto generated. Please make your changes in *Configuration.java (for example CoreConfiguration.java) and execute ConfigurationExporter\n+[float]\n+[[config-profiling-sampling-interval]]\n+==== `profiling_sampling_interval` (added[1.13.0])\n+\n+The frequency at which stack traces are gathered within a profiling session.\n+The lower you set it, the more accurate the durations will be.\n+This comes at the expense of higher overhead and more spans for potentially irrelevant operations.\n+The minimal duration of a profiling-inferred span is the same as the value of this setting.\n+\n+Supports the duration suffixes `ms`, `s` and `m`.\n+Example: `20ms`.\n+The default unit for this option is `ms`\n+\n+[options=\"header\"]\n+|============\n+| Default                          | Type                | Dynamic\n+| `20ms` | TimeDuration | true\n+|============\n+\n+\n+[options=\"header\"]\n+|============\n+| Java System Properties      | Property file   | Environment\n+| `elastic.apm.profiling_sampling_interval` | `profiling_sampling_interval` | `ELASTIC_APM_PROFILING_SAMPLING_INTERVAL`\n+|============\n+\n+// This file is auto generated. Please make your changes in *Configuration.java (for example CoreConfiguration.java) and execute ConfigurationExporter\n+[float]\n+[[config-profiling-included-classes]]\n+==== `profiling_included_classes` (added[1.13.0])\n+\n+If set, the agent will only create inferred spans for methods which match this list.\n+Setting a value may slightly increase performance and can reduce clutter by only creating spans for the classes you are interested in.\n+Example: `org.example.myapp.*`\n+\n+This option supports the wildcard `*`, which matches zero or more characters.\n+Examples: `/foo/*/bar/*/baz*`, `*foo*`.\n+Matching is case insensitive by default.\n+Prepending an element with `(?-i)` makes the matching case sensitive.\n+\n+\n+[options=\"header\"]\n+|============\n+| Default                          | Type                | Dynamic\n+| `*` | List | true\n+|============\n+\n+\n+[options=\"header\"]\n+|============\n+| Java System Properties      | Property file   | Environment\n+| `elastic.apm.profiling_included_classes` | `profiling_included_classes` | `ELASTIC_APM_PROFILING_INCLUDED_CLASSES`\n+|============\n+\n+// This file is auto generated. Please make your changes in *Configuration.java (for example CoreConfiguration.java) and execute ConfigurationExporter\n+[float]\n+[[config-profiling-excluded-classes]]\n+==== `profiling_excluded_classes` (added[1.13.0])\n+\n+Excludes classes for which no profiler-inferred spans should be created.\n+\n+This option supports the wildcard `*`, which matches zero or more characters.\n+Examples: `/foo/*/bar/*/baz*`, `*foo*`.\n+Matching is case insensitive by default.\n+Prepending an element with `(?-i)` makes the matching case sensitive.\n+\n+\n+[options=\"header\"]\n+|============\n+| Default                          | Type                | Dynamic\n+| `(?-i)java.*, (?-i)javax.*, (?-i)sun.*, (?-i)com.sun.*, (?-i)jdk.*` | List | true\n+|============\n+\n+\n+[options=\"header\"]\n+|============\n+| Java System Properties      | Property file   | Environment\n+| `elastic.apm.profiling_excluded_classes` | `profiling_excluded_classes` | `ELASTIC_APM_PROFILING_EXCLUDED_CLASSES`\n+|============\n+\n+// This file is auto generated. Please make your changes in *Configuration.java (for example CoreConfiguration.java) and execute ConfigurationExporter\n+[float]\n+[[config-profiling-interval]]\n+==== `profiling_interval` (added[1.13.0])\n+\n+The interval at which profiling sessions should be started.\n+\n+Supports the duration suffixes `ms`, `s` and `m`.\n+Example: `61s`.\n+The default unit for this option is `s`\n+\n+[options=\"header\"]\n+|============\n+| Default                          | Type                | Dynamic\n+| `61s` | TimeDuration | true\n+|============\n+\n+\n+[options=\"header\"]\n+|============\n+| Java System Properties      | Property file   | Environment\n+| `elastic.apm.profiling_interval` | `profiling_interval` | `ELASTIC_APM_PROFILING_INTERVAL`\n+|============\n+\n+// This file is auto generated. Please make your changes in *Configuration.java (for example CoreConfiguration.java) and execute ConfigurationExporter\n+[float]\n+[[config-profiling-duration]]\n+==== `profiling_duration` (added[1.13.0])\n+\n+The duration of a profiling session.\n+For sampled transactions which fall within a profiling session (they start after and end before the session),\n+so-called inferred spans will be created.\n+They appear in the trace waterfall view like regular spans.\n+\n+Supports the duration suffixes `ms`, `s` and `m`.\n+Example: `10s`.\n+The default unit for this option is `s`", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d"}, "originalPosition": 184}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMwNTk1MTg1OnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/ProfilingConfiguration.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMFQxMzoyNjo0OFrOFjqxqw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNjo1MzoxMVrOFk4cqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mjk0NTMyMw==", "bodyText": "Isn't it the other way round? Smaller interval => higher accuracy", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r372945323", "createdAt": "2020-01-30T13:26:48Z", "author": {"login": "apangin"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/ProfilingConfiguration.java", "diffHunk": "@@ -0,0 +1,182 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.ListValueConverter;\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.configuration.converter.TimeDurationValueConverter;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.matcher.WildcardMatcherValueConverter;\n+import org.stagemonitor.configuration.ConfigurationOption;\n+import org.stagemonitor.configuration.ConfigurationOptionProvider;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static co.elastic.apm.agent.configuration.validation.RangeValidator.isInRange;\n+import static co.elastic.apm.agent.configuration.validation.RangeValidator.min;\n+\n+public class ProfilingConfiguration extends ConfigurationOptionProvider {\n+\n+    private static final String PROFILING_CATEGORY = \"Profiling\";\n+\n+    private final ConfigurationOption<Boolean> profilingEnabled = ConfigurationOption.<Boolean>booleanOption()\n+        .key(\"profiling_spans_enabled\")\n+        .configurationCategory(PROFILING_CATEGORY)\n+        .description(\"Set to `true` to make the agent create spans for method executions based on\\n\" +\n+            \"https://github.com/jvm-profiling-tools/async-profiler[async-profiler], a sampling aka statistical profiler.\\n\" +\n+            \"\\n\" +\n+            \"If this is enabled, the agent will start a profiling session every\\n\" +\n+            \"<<config-profiling-interval, `profiling_interval`>> which lasts for <<config-profiling-duration, `profiling_duration`>>.\\n\" +\n+            \"If a transaction happens within a profiling session,\\n\" +\n+            \"the agent creates spans for slow methods.\\n\" +\n+            \"\\n\" +\n+            \"Due to the nature of how sampling profilers work,\\n\" +\n+            \"the duration of the inferred spans are not exact, but only estimations.\\n\" +\n+            \"The <<config-profiling-sampling-interval, `profiling_sampling_interval`>> lets you fine tune the trade-off between accuracy and overhead.\\n\" +\n+            \"\\n\" +\n+            \"The inferred spans are created after a profiling session has ended.\\n\" +\n+            \"This means there is a delay between the regular and the inferred spans being visible in the UI.\\n\" +\n+            \"\\n\" +\n+            \"NOTE: This feature is not available on Windows\")\n+        .tags(\"experimental\")\n+        .dynamic(true)\n+        .tags(\"added[1.13.0]\")\n+        .buildWithDefault(false);\n+\n+    private final ConfigurationOption<TimeDuration> samplingInterval = TimeDurationValueConverter.durationOption(\"ms\")\n+        .key(\"profiling_sampling_interval\")\n+        .configurationCategory(PROFILING_CATEGORY)\n+        .dynamic(true)\n+        .description(\"The frequency at which stack traces are gathered within a profiling session.\\n\" +\n+            \"The lower you set it, the more accurate the durations will be.\\n\" +\n+            \"This comes at the expense of higher overhead and more spans for potentially irrelevant operations.\\n\" +\n+            \"The minimal duration of a profiling-inferred span is the same as the value of this setting.\")\n+        .addValidator(isInRange(TimeDuration.of(\"1ms\"), TimeDuration.of(\"1s\")))\n+        .tags(\"added[1.13.0]\")\n+        .buildWithDefault(TimeDuration.of(\"20ms\"));\n+\n+    private final ConfigurationOption<TimeDuration> inferredSpansMinDuration = TimeDurationValueConverter.durationOption(\"ms\")\n+        .key(\"profiling_spans_min_duration\")\n+        .configurationCategory(PROFILING_CATEGORY)\n+        .dynamic(true)\n+        .description(\"The minimum duration of an inferred span.\\n\" +\n+            \"Note that the min duration is also implicitly set by the sampling interval.\\n\" +\n+            \"However, decreasing the sampling interval also decreases the accuracy of the duration of inferred spans.\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIxNzg5OA==", "bodyText": "Good catch \ud83d\udc4d", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r374217898", "createdAt": "2020-02-03T16:53:11Z", "author": {"login": "felixbarny"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/ProfilingConfiguration.java", "diffHunk": "@@ -0,0 +1,182 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.ListValueConverter;\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.configuration.converter.TimeDurationValueConverter;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.matcher.WildcardMatcherValueConverter;\n+import org.stagemonitor.configuration.ConfigurationOption;\n+import org.stagemonitor.configuration.ConfigurationOptionProvider;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static co.elastic.apm.agent.configuration.validation.RangeValidator.isInRange;\n+import static co.elastic.apm.agent.configuration.validation.RangeValidator.min;\n+\n+public class ProfilingConfiguration extends ConfigurationOptionProvider {\n+\n+    private static final String PROFILING_CATEGORY = \"Profiling\";\n+\n+    private final ConfigurationOption<Boolean> profilingEnabled = ConfigurationOption.<Boolean>booleanOption()\n+        .key(\"profiling_spans_enabled\")\n+        .configurationCategory(PROFILING_CATEGORY)\n+        .description(\"Set to `true` to make the agent create spans for method executions based on\\n\" +\n+            \"https://github.com/jvm-profiling-tools/async-profiler[async-profiler], a sampling aka statistical profiler.\\n\" +\n+            \"\\n\" +\n+            \"If this is enabled, the agent will start a profiling session every\\n\" +\n+            \"<<config-profiling-interval, `profiling_interval`>> which lasts for <<config-profiling-duration, `profiling_duration`>>.\\n\" +\n+            \"If a transaction happens within a profiling session,\\n\" +\n+            \"the agent creates spans for slow methods.\\n\" +\n+            \"\\n\" +\n+            \"Due to the nature of how sampling profilers work,\\n\" +\n+            \"the duration of the inferred spans are not exact, but only estimations.\\n\" +\n+            \"The <<config-profiling-sampling-interval, `profiling_sampling_interval`>> lets you fine tune the trade-off between accuracy and overhead.\\n\" +\n+            \"\\n\" +\n+            \"The inferred spans are created after a profiling session has ended.\\n\" +\n+            \"This means there is a delay between the regular and the inferred spans being visible in the UI.\\n\" +\n+            \"\\n\" +\n+            \"NOTE: This feature is not available on Windows\")\n+        .tags(\"experimental\")\n+        .dynamic(true)\n+        .tags(\"added[1.13.0]\")\n+        .buildWithDefault(false);\n+\n+    private final ConfigurationOption<TimeDuration> samplingInterval = TimeDurationValueConverter.durationOption(\"ms\")\n+        .key(\"profiling_sampling_interval\")\n+        .configurationCategory(PROFILING_CATEGORY)\n+        .dynamic(true)\n+        .description(\"The frequency at which stack traces are gathered within a profiling session.\\n\" +\n+            \"The lower you set it, the more accurate the durations will be.\\n\" +\n+            \"This comes at the expense of higher overhead and more spans for potentially irrelevant operations.\\n\" +\n+            \"The minimal duration of a profiling-inferred span is the same as the value of this setting.\")\n+        .addValidator(isInRange(TimeDuration.of(\"1ms\"), TimeDuration.of(\"1s\")))\n+        .tags(\"added[1.13.0]\")\n+        .buildWithDefault(TimeDuration.of(\"20ms\"));\n+\n+    private final ConfigurationOption<TimeDuration> inferredSpansMinDuration = TimeDurationValueConverter.durationOption(\"ms\")\n+        .key(\"profiling_spans_min_duration\")\n+        .configurationCategory(PROFILING_CATEGORY)\n+        .dynamic(true)\n+        .description(\"The minimum duration of an inferred span.\\n\" +\n+            \"Note that the min duration is also implicitly set by the sampling interval.\\n\" +\n+            \"However, decreasing the sampling interval also decreases the accuracy of the duration of inferred spans.\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mjk0NTMyMw=="}, "originalCommit": {"oid": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489"}, "originalPosition": 87}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMwNjE0MjY0OnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/AsyncProfiler.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMFQxNDoyMDo0MFrOFjsksg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMFQxNDoyMDo0MFrOFjsksg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mjk3NDc3MA==", "bodyText": "I'm going to re-implement the way how native methods are bound, so that no fancy layers will be needed. It's possible to make it work without instrumentation or dynamic class generation.\nFurthermore, the number of native methods will be likely reduced to the minimum required. E.g. all dumpXXX stuff can be implemented on top of execute0.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r372974770", "createdAt": "2020-01-30T14:20:40Z", "author": {"login": "apangin"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/AsyncProfiler.java", "diffHunk": "@@ -0,0 +1,278 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+/*\n+ * Copyright 2018 Andrei Pangin\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.util.IOUtils;\n+import net.bytebuddy.ByteBuddy;\n+import net.bytebuddy.dynamic.ClassFileLocator;\n+import net.bytebuddy.dynamic.loading.ClassLoadingStrategy;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+\n+/**\n+ * Java API for in-process profiling. Serves as a wrapper around\n+ * async-profiler native library. This class is a singleton.\n+ * The first call to {@link #getInstance()} initiates loading of\n+ * libasyncProfiler.so.\n+ * <p>\n+ * This is based on https://github.com/jvm-profiling-tools/async-profiler/blob/master/src/java/one/profiler/AsyncProfiler.java,\n+ * under Apache License 2.0.\n+ * It is modified to allow it to be shaded into the {@code co.elastic.apm} namespace\n+ * </p>\n+ */\n+public abstract class AsyncProfiler {\n+\n+    @Nullable\n+    private static volatile AsyncProfiler instance;\n+\n+    private final String version;\n+\n+    public AsyncProfiler() {\n+        this.version = version0();\n+    }\n+\n+    public static AsyncProfiler getInstance() {\n+        AsyncProfiler result = AsyncProfiler.instance;\n+        if (result != null) {\n+            return result;\n+        }\n+        synchronized (AsyncProfiler.class) {\n+            if (instance == null) {\n+                instance = newInstance();\n+            }\n+            return instance;\n+        }\n+    }\n+\n+    /*\n+     * Allows AsyncProfiler to be shaded. JNI mapping works for a specific package so shading normally doesn't work.\n+     */\n+    private static AsyncProfiler newInstance() {\n+        try {\n+            return new ByteBuddy()\n+                // ClassFileLocator.ForClassLoader.ofBootLoader() can't resolve resources added via Instrumentation.appendToBootstrapClassLoaderSearch\n+                // see also https://stackoverflow.com/questions/51347432/why-cant-i-load-resources-which-are-appended-to-the-bootstrap-class-loader-sear\n+                .redefine(DirectNativeBinding.class, ClassFileLocator.ForClassLoader.ofSystemLoader())\n+                .name(\"one.profiler.AsyncProfiler\")\n+                .make()\n+                .load(AsyncProfiler.class.getClassLoader(), ClassLoadingStrategy.Default.CHILD_FIRST)\n+                .getLoaded()\n+                .getConstructor()\n+                .newInstance();\n+        } catch (Exception e) {\n+            throw new IllegalStateException(e);\n+        }\n+    }\n+\n+    /**\n+     * Start profiling\n+     *\n+     * @param event Profiling event, see {@link Events}\n+     * @param interval Sampling interval, e.g. nanoseconds for Events.CPU\n+     * @throws IllegalStateException If profiler is already running\n+     */\n+    public void start(String event, long interval) throws IllegalStateException {\n+        start0(event, interval, true);\n+    }\n+\n+    /**\n+     * Start or resume profiling without resetting collected data.\n+     * Note that event and interval may change since the previous profiling session.\n+     *\n+     * @param event Profiling event, see {@link Events}\n+     * @param interval Sampling interval, e.g. nanoseconds for Events.CPU\n+     * @throws IllegalStateException If profiler is already running\n+     */\n+    public void resume(String event, long interval) throws IllegalStateException {\n+        start0(event, interval, false);\n+    }\n+\n+    /**\n+     * Stop profiling (without dumping results)\n+     *\n+     * @throws IllegalStateException If profiler is not running\n+     */\n+    public void stop() throws IllegalStateException {\n+        stop0();\n+    }\n+\n+    /**\n+     * Get the number of samples collected during the profiling session\n+     *\n+     * @return Number of samples\n+     */\n+    public native long getSamples();\n+\n+    /**\n+     * Get profiler agent version, e.g. \"1.0\"\n+     *\n+     * @return Version string\n+     */\n+    public String getVersion() {\n+        return version;\n+    }\n+\n+    /**\n+     * Execute an agent-compatible profiling command -\n+     * the comma-separated list of arguments described in arguments.cpp\n+     *\n+     * @param command Profiling command\n+     * @return The command result\n+     * @throws IllegalArgumentException If failed to parse the command\n+     * @throws java.io.IOException If failed to create output file\n+     */\n+    public String execute(String command) throws IllegalArgumentException, java.io.IOException {\n+        return execute0(command);\n+    }\n+\n+    /**\n+     * Dump profile in 'collapsed stacktraces' format\n+     *\n+     * @param counter Which counter to display in the output\n+     * @return Textual representation of the profile\n+     */\n+    public String dumpCollapsed(Counter counter) {\n+        return dumpCollapsed0(counter.ordinal());\n+    }\n+\n+    /**\n+     * Dump collected stack traces\n+     *\n+     * @param maxTraces Maximum number of stack traces to dump. 0 means no limit\n+     * @return Textual representation of the profile\n+     */\n+    public String dumpTraces(int maxTraces) {\n+        return dumpTraces0(maxTraces);\n+    }\n+\n+    /**\n+     * Dump flat profile, i.e. the histogram of the hottest methods\n+     *\n+     * @param maxMethods Maximum number of methods to dump. 0 means no limit\n+     * @return Textual representation of the profile\n+     */\n+    public String dumpFlat(int maxMethods) {\n+        return dumpFlat0(maxMethods);\n+    }\n+\n+    /**\n+     * Get OS thread ID of the current Java thread. On Linux, this is the same number\n+     * as gettid() returns. The result ID matches 'tid' in the profiler output.\n+     *\n+     * @return 64-bit integer that matches native (OS level) thread ID\n+     */\n+    public long getNativeThreadId() {\n+        return getNativeThreadId0();\n+    }\n+\n+    public abstract void start0(String event, long interval, boolean reset) throws IllegalStateException;\n+    public abstract void stop0() throws IllegalStateException;\n+    public abstract String execute0(String command) throws IllegalArgumentException, java.io.IOException;\n+    public abstract String dumpCollapsed0(int counter);\n+    public abstract String dumpTraces0(int maxTraces);\n+    public abstract String dumpFlat0(int maxMethods);\n+    public abstract String version0();\n+    public abstract long getNativeThreadId0();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489"}, "originalPosition": 213}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMwNjIyODUyOnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/AsyncProfiler.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMFQxNDo0Mjo0M1rOFjtZKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNjo1OToxOFrOFk4qFg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mjk4ODIwMQ==", "bodyText": "There are definitely more platforms where async-profiler works, e.g. x64-musl and AArch64. Probably, more platforms in future - there is already a PR for PPC port, for example. Not sure if packing all binaries into a single .jar is a good idea.\nAlso, it's not enough to look only at these two properties to distinguish glibc from musl libc.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r372988201", "createdAt": "2020-01-30T14:42:43Z", "author": {"login": "apangin"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/AsyncProfiler.java", "diffHunk": "@@ -0,0 +1,278 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+/*\n+ * Copyright 2018 Andrei Pangin\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.util.IOUtils;\n+import net.bytebuddy.ByteBuddy;\n+import net.bytebuddy.dynamic.ClassFileLocator;\n+import net.bytebuddy.dynamic.loading.ClassLoadingStrategy;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+\n+/**\n+ * Java API for in-process profiling. Serves as a wrapper around\n+ * async-profiler native library. This class is a singleton.\n+ * The first call to {@link #getInstance()} initiates loading of\n+ * libasyncProfiler.so.\n+ * <p>\n+ * This is based on https://github.com/jvm-profiling-tools/async-profiler/blob/master/src/java/one/profiler/AsyncProfiler.java,\n+ * under Apache License 2.0.\n+ * It is modified to allow it to be shaded into the {@code co.elastic.apm} namespace\n+ * </p>\n+ */\n+public abstract class AsyncProfiler {\n+\n+    @Nullable\n+    private static volatile AsyncProfiler instance;\n+\n+    private final String version;\n+\n+    public AsyncProfiler() {\n+        this.version = version0();\n+    }\n+\n+    public static AsyncProfiler getInstance() {\n+        AsyncProfiler result = AsyncProfiler.instance;\n+        if (result != null) {\n+            return result;\n+        }\n+        synchronized (AsyncProfiler.class) {\n+            if (instance == null) {\n+                instance = newInstance();\n+            }\n+            return instance;\n+        }\n+    }\n+\n+    /*\n+     * Allows AsyncProfiler to be shaded. JNI mapping works for a specific package so shading normally doesn't work.\n+     */\n+    private static AsyncProfiler newInstance() {\n+        try {\n+            return new ByteBuddy()\n+                // ClassFileLocator.ForClassLoader.ofBootLoader() can't resolve resources added via Instrumentation.appendToBootstrapClassLoaderSearch\n+                // see also https://stackoverflow.com/questions/51347432/why-cant-i-load-resources-which-are-appended-to-the-bootstrap-class-loader-sear\n+                .redefine(DirectNativeBinding.class, ClassFileLocator.ForClassLoader.ofSystemLoader())\n+                .name(\"one.profiler.AsyncProfiler\")\n+                .make()\n+                .load(AsyncProfiler.class.getClassLoader(), ClassLoadingStrategy.Default.CHILD_FIRST)\n+                .getLoaded()\n+                .getConstructor()\n+                .newInstance();\n+        } catch (Exception e) {\n+            throw new IllegalStateException(e);\n+        }\n+    }\n+\n+    /**\n+     * Start profiling\n+     *\n+     * @param event Profiling event, see {@link Events}\n+     * @param interval Sampling interval, e.g. nanoseconds for Events.CPU\n+     * @throws IllegalStateException If profiler is already running\n+     */\n+    public void start(String event, long interval) throws IllegalStateException {\n+        start0(event, interval, true);\n+    }\n+\n+    /**\n+     * Start or resume profiling without resetting collected data.\n+     * Note that event and interval may change since the previous profiling session.\n+     *\n+     * @param event Profiling event, see {@link Events}\n+     * @param interval Sampling interval, e.g. nanoseconds for Events.CPU\n+     * @throws IllegalStateException If profiler is already running\n+     */\n+    public void resume(String event, long interval) throws IllegalStateException {\n+        start0(event, interval, false);\n+    }\n+\n+    /**\n+     * Stop profiling (without dumping results)\n+     *\n+     * @throws IllegalStateException If profiler is not running\n+     */\n+    public void stop() throws IllegalStateException {\n+        stop0();\n+    }\n+\n+    /**\n+     * Get the number of samples collected during the profiling session\n+     *\n+     * @return Number of samples\n+     */\n+    public native long getSamples();\n+\n+    /**\n+     * Get profiler agent version, e.g. \"1.0\"\n+     *\n+     * @return Version string\n+     */\n+    public String getVersion() {\n+        return version;\n+    }\n+\n+    /**\n+     * Execute an agent-compatible profiling command -\n+     * the comma-separated list of arguments described in arguments.cpp\n+     *\n+     * @param command Profiling command\n+     * @return The command result\n+     * @throws IllegalArgumentException If failed to parse the command\n+     * @throws java.io.IOException If failed to create output file\n+     */\n+    public String execute(String command) throws IllegalArgumentException, java.io.IOException {\n+        return execute0(command);\n+    }\n+\n+    /**\n+     * Dump profile in 'collapsed stacktraces' format\n+     *\n+     * @param counter Which counter to display in the output\n+     * @return Textual representation of the profile\n+     */\n+    public String dumpCollapsed(Counter counter) {\n+        return dumpCollapsed0(counter.ordinal());\n+    }\n+\n+    /**\n+     * Dump collected stack traces\n+     *\n+     * @param maxTraces Maximum number of stack traces to dump. 0 means no limit\n+     * @return Textual representation of the profile\n+     */\n+    public String dumpTraces(int maxTraces) {\n+        return dumpTraces0(maxTraces);\n+    }\n+\n+    /**\n+     * Dump flat profile, i.e. the histogram of the hottest methods\n+     *\n+     * @param maxMethods Maximum number of methods to dump. 0 means no limit\n+     * @return Textual representation of the profile\n+     */\n+    public String dumpFlat(int maxMethods) {\n+        return dumpFlat0(maxMethods);\n+    }\n+\n+    /**\n+     * Get OS thread ID of the current Java thread. On Linux, this is the same number\n+     * as gettid() returns. The result ID matches 'tid' in the profiler output.\n+     *\n+     * @return 64-bit integer that matches native (OS level) thread ID\n+     */\n+    public long getNativeThreadId() {\n+        return getNativeThreadId0();\n+    }\n+\n+    public abstract void start0(String event, long interval, boolean reset) throws IllegalStateException;\n+    public abstract void stop0() throws IllegalStateException;\n+    public abstract String execute0(String command) throws IllegalArgumentException, java.io.IOException;\n+    public abstract String dumpCollapsed0(int counter);\n+    public abstract String dumpTraces0(int maxTraces);\n+    public abstract String dumpFlat0(int maxMethods);\n+    public abstract String version0();\n+    public abstract long getNativeThreadId0();\n+\n+    /**\n+     * Inspired by https://gist.github.com/raphw/be0994259e75652f057c9e1d3ee5f567\n+     */\n+    public static class DirectNativeBinding extends AsyncProfiler {\n+\n+        static {\n+            loadNativeLibrary();\n+        }\n+\n+        private static void loadNativeLibrary() {\n+            String libraryName = getLibraryFileName();\n+            File file = IOUtils.exportResourceToTemp(\"asyncprofiler/\" + libraryName + \".so\", libraryName, \".so\");\n+            System.load(file.getAbsolutePath());\n+        }\n+\n+        private static String getLibraryFileName() {\n+            String os = System.getProperty(\"os.name\").toLowerCase();\n+            String arch = System.getProperty(\"os.arch\").toLowerCase();\n+            if (os.contains(\"linux\")) {\n+                if (arch.contains(\"arm\") || arch.contains(\"aarch\")) {\n+                    return \"libasyncProfiler-linux-arm\";\n+                } else if (arch.contains(\"64\")) {\n+                    return \"libasyncProfiler-linux-x64\";\n+                } else if (arch.contains(\"86\")) {\n+                    return \"libasyncProfiler-linux-x86\";\n+                } else {\n+                    throw new IllegalStateException(\"Async-profiler does not work on Linux \" + arch);\n+                }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489"}, "originalPosition": 242}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyMTMzNA==", "bodyText": "Let's start with just the 4 platforms.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r374221334", "createdAt": "2020-02-03T16:59:18Z", "author": {"login": "felixbarny"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/AsyncProfiler.java", "diffHunk": "@@ -0,0 +1,278 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+/*\n+ * Copyright 2018 Andrei Pangin\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.util.IOUtils;\n+import net.bytebuddy.ByteBuddy;\n+import net.bytebuddy.dynamic.ClassFileLocator;\n+import net.bytebuddy.dynamic.loading.ClassLoadingStrategy;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+\n+/**\n+ * Java API for in-process profiling. Serves as a wrapper around\n+ * async-profiler native library. This class is a singleton.\n+ * The first call to {@link #getInstance()} initiates loading of\n+ * libasyncProfiler.so.\n+ * <p>\n+ * This is based on https://github.com/jvm-profiling-tools/async-profiler/blob/master/src/java/one/profiler/AsyncProfiler.java,\n+ * under Apache License 2.0.\n+ * It is modified to allow it to be shaded into the {@code co.elastic.apm} namespace\n+ * </p>\n+ */\n+public abstract class AsyncProfiler {\n+\n+    @Nullable\n+    private static volatile AsyncProfiler instance;\n+\n+    private final String version;\n+\n+    public AsyncProfiler() {\n+        this.version = version0();\n+    }\n+\n+    public static AsyncProfiler getInstance() {\n+        AsyncProfiler result = AsyncProfiler.instance;\n+        if (result != null) {\n+            return result;\n+        }\n+        synchronized (AsyncProfiler.class) {\n+            if (instance == null) {\n+                instance = newInstance();\n+            }\n+            return instance;\n+        }\n+    }\n+\n+    /*\n+     * Allows AsyncProfiler to be shaded. JNI mapping works for a specific package so shading normally doesn't work.\n+     */\n+    private static AsyncProfiler newInstance() {\n+        try {\n+            return new ByteBuddy()\n+                // ClassFileLocator.ForClassLoader.ofBootLoader() can't resolve resources added via Instrumentation.appendToBootstrapClassLoaderSearch\n+                // see also https://stackoverflow.com/questions/51347432/why-cant-i-load-resources-which-are-appended-to-the-bootstrap-class-loader-sear\n+                .redefine(DirectNativeBinding.class, ClassFileLocator.ForClassLoader.ofSystemLoader())\n+                .name(\"one.profiler.AsyncProfiler\")\n+                .make()\n+                .load(AsyncProfiler.class.getClassLoader(), ClassLoadingStrategy.Default.CHILD_FIRST)\n+                .getLoaded()\n+                .getConstructor()\n+                .newInstance();\n+        } catch (Exception e) {\n+            throw new IllegalStateException(e);\n+        }\n+    }\n+\n+    /**\n+     * Start profiling\n+     *\n+     * @param event Profiling event, see {@link Events}\n+     * @param interval Sampling interval, e.g. nanoseconds for Events.CPU\n+     * @throws IllegalStateException If profiler is already running\n+     */\n+    public void start(String event, long interval) throws IllegalStateException {\n+        start0(event, interval, true);\n+    }\n+\n+    /**\n+     * Start or resume profiling without resetting collected data.\n+     * Note that event and interval may change since the previous profiling session.\n+     *\n+     * @param event Profiling event, see {@link Events}\n+     * @param interval Sampling interval, e.g. nanoseconds for Events.CPU\n+     * @throws IllegalStateException If profiler is already running\n+     */\n+    public void resume(String event, long interval) throws IllegalStateException {\n+        start0(event, interval, false);\n+    }\n+\n+    /**\n+     * Stop profiling (without dumping results)\n+     *\n+     * @throws IllegalStateException If profiler is not running\n+     */\n+    public void stop() throws IllegalStateException {\n+        stop0();\n+    }\n+\n+    /**\n+     * Get the number of samples collected during the profiling session\n+     *\n+     * @return Number of samples\n+     */\n+    public native long getSamples();\n+\n+    /**\n+     * Get profiler agent version, e.g. \"1.0\"\n+     *\n+     * @return Version string\n+     */\n+    public String getVersion() {\n+        return version;\n+    }\n+\n+    /**\n+     * Execute an agent-compatible profiling command -\n+     * the comma-separated list of arguments described in arguments.cpp\n+     *\n+     * @param command Profiling command\n+     * @return The command result\n+     * @throws IllegalArgumentException If failed to parse the command\n+     * @throws java.io.IOException If failed to create output file\n+     */\n+    public String execute(String command) throws IllegalArgumentException, java.io.IOException {\n+        return execute0(command);\n+    }\n+\n+    /**\n+     * Dump profile in 'collapsed stacktraces' format\n+     *\n+     * @param counter Which counter to display in the output\n+     * @return Textual representation of the profile\n+     */\n+    public String dumpCollapsed(Counter counter) {\n+        return dumpCollapsed0(counter.ordinal());\n+    }\n+\n+    /**\n+     * Dump collected stack traces\n+     *\n+     * @param maxTraces Maximum number of stack traces to dump. 0 means no limit\n+     * @return Textual representation of the profile\n+     */\n+    public String dumpTraces(int maxTraces) {\n+        return dumpTraces0(maxTraces);\n+    }\n+\n+    /**\n+     * Dump flat profile, i.e. the histogram of the hottest methods\n+     *\n+     * @param maxMethods Maximum number of methods to dump. 0 means no limit\n+     * @return Textual representation of the profile\n+     */\n+    public String dumpFlat(int maxMethods) {\n+        return dumpFlat0(maxMethods);\n+    }\n+\n+    /**\n+     * Get OS thread ID of the current Java thread. On Linux, this is the same number\n+     * as gettid() returns. The result ID matches 'tid' in the profiler output.\n+     *\n+     * @return 64-bit integer that matches native (OS level) thread ID\n+     */\n+    public long getNativeThreadId() {\n+        return getNativeThreadId0();\n+    }\n+\n+    public abstract void start0(String event, long interval, boolean reset) throws IllegalStateException;\n+    public abstract void stop0() throws IllegalStateException;\n+    public abstract String execute0(String command) throws IllegalArgumentException, java.io.IOException;\n+    public abstract String dumpCollapsed0(int counter);\n+    public abstract String dumpTraces0(int maxTraces);\n+    public abstract String dumpFlat0(int maxMethods);\n+    public abstract String version0();\n+    public abstract long getNativeThreadId0();\n+\n+    /**\n+     * Inspired by https://gist.github.com/raphw/be0994259e75652f057c9e1d3ee5f567\n+     */\n+    public static class DirectNativeBinding extends AsyncProfiler {\n+\n+        static {\n+            loadNativeLibrary();\n+        }\n+\n+        private static void loadNativeLibrary() {\n+            String libraryName = getLibraryFileName();\n+            File file = IOUtils.exportResourceToTemp(\"asyncprofiler/\" + libraryName + \".so\", libraryName, \".so\");\n+            System.load(file.getAbsolutePath());\n+        }\n+\n+        private static String getLibraryFileName() {\n+            String os = System.getProperty(\"os.name\").toLowerCase();\n+            String arch = System.getProperty(\"os.arch\").toLowerCase();\n+            if (os.contains(\"linux\")) {\n+                if (arch.contains(\"arm\") || arch.contains(\"aarch\")) {\n+                    return \"libasyncProfiler-linux-arm\";\n+                } else if (arch.contains(\"64\")) {\n+                    return \"libasyncProfiler-linux-x64\";\n+                } else if (arch.contains(\"86\")) {\n+                    return \"libasyncProfiler-linux-x86\";\n+                } else {\n+                    throw new IllegalStateException(\"Async-profiler does not work on Linux \" + arch);\n+                }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mjk4ODIwMQ=="}, "originalCommit": {"oid": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489"}, "originalPosition": 242}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMwNjMxMjEyOnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMFQxNTowMzoxMFrOFjuMhA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNzowMDozNlrOFk4syA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzAwMTM0OA==", "bodyText": "Although async-profiler currently writes everything within a single checkpoint, JFR format can possibly have many checkpoints. In order to support continuous profiling, both JFR reader and writer should consider multiple checkpoints.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r373001348", "createdAt": "2020-01-30T15:03:10Z", "author": {"login": "apangin"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "diffHunk": "@@ -0,0 +1,531 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+import co.elastic.apm.agent.profiler.collections.Int2IntHashMap;\n+import co.elastic.apm.agent.profiler.collections.Int2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * Parses the binary JFR file created by async-profiler.\n+ * May not work with JFR files created by an actual flight recorder.\n+ * <p>\n+ * The implementation is tuned with to minimize allocations when parsing a JFR file.\n+ * Most data structures can be reused by first {@linkplain #resetState() resetting the state} and then {@linkplain #parse(File, List, List) parsing}\n+ * another file.\n+ * </p>\n+ * <p>\n+ * The JFR file itself is mapped into memory via a {@link MappedByteBuffer}.\n+ * This does not consume heap memory, the operating system loads pages the file into memory as they are requested.\n+ * Unfortunately, unmapping a {@link MappedByteBuffer} can only be done by letting it be garbage collected.\n+ * </p>\n+ */\n+public class JfrParser implements Recyclable {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(JfrParser.class);\n+\n+    private static final byte[] MAGIC_BYTES = new byte[]{'F', 'L', 'R', '\\0'};\n+    private static final Set<String> JAVA_FRAME_TYPES = new HashSet<>(Arrays.asList(\"Interpreted\", \"JIT compiled\", \"Inlined\"));\n+\n+    @Nullable\n+    private MappedByteBuffer buffer;\n+    private int eventsOffset;\n+    private int metadataOffset;\n+    @Nullable\n+    private boolean[] isJavaFrameType;\n+    private final Int2IntHashMap classIdToClassNameSymbolId = new Int2IntHashMap(-1);\n+    private final Int2ObjectHashMap<Symbol> symbols = new Int2ObjectHashMap<>();\n+    private final Int2IntHashMap stackTraceIdToFilePositions = new Int2IntHashMap(-1);\n+    private final Long2ObjectHashMap<LazyStackFrame> framesByFrameId = new Long2ObjectHashMap<>();\n+    // used to resolve a symbol with minimal allocations\n+    private final StringBuilder symbolBuilder = new StringBuilder();\n+    @Nullable\n+    private List<WildcardMatcher> excludedClasses;\n+    @Nullable\n+    private List<WildcardMatcher> includedClasses;\n+\n+    /**\n+     * Initializes the parser to make it ready for {@link #resolveStackTrace(long, boolean, List, int)} to be called.\n+     *\n+     * @param file            the JFR file to parse\n+     * @param excludedClasses Class names to exclude in stack traces (has an effect on {@link #resolveStackTrace(long, boolean, List, int)})\n+     * @param includedClasses Class names to include in stack traces (has an effect on {@link #resolveStackTrace(long, boolean, List, int)})\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void parse(File file, List<WildcardMatcher> excludedClasses, List<WildcardMatcher> includedClasses) throws IOException {\n+        this.excludedClasses = excludedClasses;\n+        this.includedClasses = includedClasses;\n+        try (RandomAccessFile raf = new RandomAccessFile(file, \"r\")) {\n+            FileChannel channel = raf.getChannel();\n+            logger.debug(\"Parsing {} ({} bytes)\", file, channel.size());\n+            if (channel.size() > Integer.MAX_VALUE) {\n+                // mapping a file into memory is only possible for chunks of the file which fall into the Integer range (2GB)\n+                // that is because MappedByteBuffers are ByteBuffers which only accept ints in position(int pos)\n+                throw new IllegalArgumentException(\"Input file too large\");\n+            }\n+            this.buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, channel.size());\n+        }\n+        for (byte magicByte : MAGIC_BYTES) {\n+            if (buffer.get() != magicByte) {\n+                throw new IllegalArgumentException(\"Not a JFR file\");\n+            }\n+        }\n+        short major = buffer.getShort();\n+        short minor = buffer.getShort();\n+        if (major != 0 || minor != 9) {\n+            throw new IllegalArgumentException(String.format(\"Can only parse version 0.9. Was %d.%d\", major, minor));\n+        }\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        metadataOffset = (int) buffer.getLong();\n+        eventsOffset = buffer.position();\n+\n+        setPosition(buffer, metadataOffset);\n+        int checkpointOffset = parseMetadata(buffer);\n+        setPosition(buffer, checkpointOffset);\n+        parseCheckpoint(buffer);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489"}, "originalPosition": 125}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyMjAyNA==", "bodyText": "I'm aware that this class makes quite a few assumptions about how the JFR file is written. But as we always ship with a specific version of async-profiler I think this is fine and allows for some optimizations.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r374222024", "createdAt": "2020-02-03T17:00:36Z", "author": {"login": "felixbarny"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "diffHunk": "@@ -0,0 +1,531 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+import co.elastic.apm.agent.profiler.collections.Int2IntHashMap;\n+import co.elastic.apm.agent.profiler.collections.Int2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * Parses the binary JFR file created by async-profiler.\n+ * May not work with JFR files created by an actual flight recorder.\n+ * <p>\n+ * The implementation is tuned with to minimize allocations when parsing a JFR file.\n+ * Most data structures can be reused by first {@linkplain #resetState() resetting the state} and then {@linkplain #parse(File, List, List) parsing}\n+ * another file.\n+ * </p>\n+ * <p>\n+ * The JFR file itself is mapped into memory via a {@link MappedByteBuffer}.\n+ * This does not consume heap memory, the operating system loads pages the file into memory as they are requested.\n+ * Unfortunately, unmapping a {@link MappedByteBuffer} can only be done by letting it be garbage collected.\n+ * </p>\n+ */\n+public class JfrParser implements Recyclable {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(JfrParser.class);\n+\n+    private static final byte[] MAGIC_BYTES = new byte[]{'F', 'L', 'R', '\\0'};\n+    private static final Set<String> JAVA_FRAME_TYPES = new HashSet<>(Arrays.asList(\"Interpreted\", \"JIT compiled\", \"Inlined\"));\n+\n+    @Nullable\n+    private MappedByteBuffer buffer;\n+    private int eventsOffset;\n+    private int metadataOffset;\n+    @Nullable\n+    private boolean[] isJavaFrameType;\n+    private final Int2IntHashMap classIdToClassNameSymbolId = new Int2IntHashMap(-1);\n+    private final Int2ObjectHashMap<Symbol> symbols = new Int2ObjectHashMap<>();\n+    private final Int2IntHashMap stackTraceIdToFilePositions = new Int2IntHashMap(-1);\n+    private final Long2ObjectHashMap<LazyStackFrame> framesByFrameId = new Long2ObjectHashMap<>();\n+    // used to resolve a symbol with minimal allocations\n+    private final StringBuilder symbolBuilder = new StringBuilder();\n+    @Nullable\n+    private List<WildcardMatcher> excludedClasses;\n+    @Nullable\n+    private List<WildcardMatcher> includedClasses;\n+\n+    /**\n+     * Initializes the parser to make it ready for {@link #resolveStackTrace(long, boolean, List, int)} to be called.\n+     *\n+     * @param file            the JFR file to parse\n+     * @param excludedClasses Class names to exclude in stack traces (has an effect on {@link #resolveStackTrace(long, boolean, List, int)})\n+     * @param includedClasses Class names to include in stack traces (has an effect on {@link #resolveStackTrace(long, boolean, List, int)})\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void parse(File file, List<WildcardMatcher> excludedClasses, List<WildcardMatcher> includedClasses) throws IOException {\n+        this.excludedClasses = excludedClasses;\n+        this.includedClasses = includedClasses;\n+        try (RandomAccessFile raf = new RandomAccessFile(file, \"r\")) {\n+            FileChannel channel = raf.getChannel();\n+            logger.debug(\"Parsing {} ({} bytes)\", file, channel.size());\n+            if (channel.size() > Integer.MAX_VALUE) {\n+                // mapping a file into memory is only possible for chunks of the file which fall into the Integer range (2GB)\n+                // that is because MappedByteBuffers are ByteBuffers which only accept ints in position(int pos)\n+                throw new IllegalArgumentException(\"Input file too large\");\n+            }\n+            this.buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, channel.size());\n+        }\n+        for (byte magicByte : MAGIC_BYTES) {\n+            if (buffer.get() != magicByte) {\n+                throw new IllegalArgumentException(\"Not a JFR file\");\n+            }\n+        }\n+        short major = buffer.getShort();\n+        short minor = buffer.getShort();\n+        if (major != 0 || minor != 9) {\n+            throw new IllegalArgumentException(String.format(\"Can only parse version 0.9. Was %d.%d\", major, minor));\n+        }\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        metadataOffset = (int) buffer.getLong();\n+        eventsOffset = buffer.position();\n+\n+        setPosition(buffer, metadataOffset);\n+        int checkpointOffset = parseMetadata(buffer);\n+        setPosition(buffer, checkpointOffset);\n+        parseCheckpoint(buffer);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzAwMTM0OA=="}, "originalCommit": {"oid": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489"}, "originalPosition": 125}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMwNjM1ODc5OnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMFQxNToxNTowOFrOFjupnQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNzowMToxM1rOFk4uCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzAwODc5Nw==", "bodyText": "There are plans to support at least two states: RUNNABLE and SLEEPING, depending on whether the thread is currently on cpu or not.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r373008797", "createdAt": "2020-01-30T15:15:08Z", "author": {"login": "apangin"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "diffHunk": "@@ -0,0 +1,531 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+import co.elastic.apm.agent.profiler.collections.Int2IntHashMap;\n+import co.elastic.apm.agent.profiler.collections.Int2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * Parses the binary JFR file created by async-profiler.\n+ * May not work with JFR files created by an actual flight recorder.\n+ * <p>\n+ * The implementation is tuned with to minimize allocations when parsing a JFR file.\n+ * Most data structures can be reused by first {@linkplain #resetState() resetting the state} and then {@linkplain #parse(File, List, List) parsing}\n+ * another file.\n+ * </p>\n+ * <p>\n+ * The JFR file itself is mapped into memory via a {@link MappedByteBuffer}.\n+ * This does not consume heap memory, the operating system loads pages the file into memory as they are requested.\n+ * Unfortunately, unmapping a {@link MappedByteBuffer} can only be done by letting it be garbage collected.\n+ * </p>\n+ */\n+public class JfrParser implements Recyclable {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(JfrParser.class);\n+\n+    private static final byte[] MAGIC_BYTES = new byte[]{'F', 'L', 'R', '\\0'};\n+    private static final Set<String> JAVA_FRAME_TYPES = new HashSet<>(Arrays.asList(\"Interpreted\", \"JIT compiled\", \"Inlined\"));\n+\n+    @Nullable\n+    private MappedByteBuffer buffer;\n+    private int eventsOffset;\n+    private int metadataOffset;\n+    @Nullable\n+    private boolean[] isJavaFrameType;\n+    private final Int2IntHashMap classIdToClassNameSymbolId = new Int2IntHashMap(-1);\n+    private final Int2ObjectHashMap<Symbol> symbols = new Int2ObjectHashMap<>();\n+    private final Int2IntHashMap stackTraceIdToFilePositions = new Int2IntHashMap(-1);\n+    private final Long2ObjectHashMap<LazyStackFrame> framesByFrameId = new Long2ObjectHashMap<>();\n+    // used to resolve a symbol with minimal allocations\n+    private final StringBuilder symbolBuilder = new StringBuilder();\n+    @Nullable\n+    private List<WildcardMatcher> excludedClasses;\n+    @Nullable\n+    private List<WildcardMatcher> includedClasses;\n+\n+    /**\n+     * Initializes the parser to make it ready for {@link #resolveStackTrace(long, boolean, List, int)} to be called.\n+     *\n+     * @param file            the JFR file to parse\n+     * @param excludedClasses Class names to exclude in stack traces (has an effect on {@link #resolveStackTrace(long, boolean, List, int)})\n+     * @param includedClasses Class names to include in stack traces (has an effect on {@link #resolveStackTrace(long, boolean, List, int)})\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void parse(File file, List<WildcardMatcher> excludedClasses, List<WildcardMatcher> includedClasses) throws IOException {\n+        this.excludedClasses = excludedClasses;\n+        this.includedClasses = includedClasses;\n+        try (RandomAccessFile raf = new RandomAccessFile(file, \"r\")) {\n+            FileChannel channel = raf.getChannel();\n+            logger.debug(\"Parsing {} ({} bytes)\", file, channel.size());\n+            if (channel.size() > Integer.MAX_VALUE) {\n+                // mapping a file into memory is only possible for chunks of the file which fall into the Integer range (2GB)\n+                // that is because MappedByteBuffers are ByteBuffers which only accept ints in position(int pos)\n+                throw new IllegalArgumentException(\"Input file too large\");\n+            }\n+            this.buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, channel.size());\n+        }\n+        for (byte magicByte : MAGIC_BYTES) {\n+            if (buffer.get() != magicByte) {\n+                throw new IllegalArgumentException(\"Not a JFR file\");\n+            }\n+        }\n+        short major = buffer.getShort();\n+        short minor = buffer.getShort();\n+        if (major != 0 || minor != 9) {\n+            throw new IllegalArgumentException(String.format(\"Can only parse version 0.9. Was %d.%d\", major, minor));\n+        }\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        metadataOffset = (int) buffer.getLong();\n+        eventsOffset = buffer.position();\n+\n+        setPosition(buffer, metadataOffset);\n+        int checkpointOffset = parseMetadata(buffer);\n+        setPosition(buffer, checkpointOffset);\n+        parseCheckpoint(buffer);\n+    }\n+\n+    private int parseMetadata(MappedByteBuffer buffer) throws IOException {\n+        int size = buffer.getInt();\n+        expectEventType(buffer, EventTypeId.EVENT_METADATA);\n+        int checkpointOffsetPosition = size - 16;\n+        setPosition(buffer, buffer.position() + checkpointOffsetPosition);\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        return (int) buffer.getLong();\n+    }\n+\n+    private void expectEventType(MappedByteBuffer buffer, int expectedEventType) throws IOException {\n+        int eventType = buffer.getInt();\n+        if (eventType != expectedEventType) {\n+            throw new IOException(\"Expected \" + expectedEventType + \" but got \" + eventType);\n+        }\n+    }\n+\n+    private void parseCheckpoint(MappedByteBuffer buffer) throws IOException {\n+        buffer.getInt(); // size\n+        expectEventType(buffer, EventTypeId.EVENT_CHECKPOINT);\n+        buffer.getLong(); // stop timestamp\n+        buffer.getLong(); // previous checkpoint - always 0 in async-profiler\n+        while (buffer.position() < metadataOffset) {\n+            parseContentType(buffer);\n+        }\n+    }\n+\n+    private void parseContentType(MappedByteBuffer buffer) throws IOException {\n+        int contentTypeId = buffer.getInt();\n+        logger.debug(\"Parsing content type {}\", contentTypeId);\n+        int count = buffer.getInt();\n+        switch (contentTypeId) {\n+            case ContentTypeId.CONTENT_THREAD:\n+                // currently no thread info\n+                break;\n+            case ContentTypeId.CONTENT_STACKTRACE:\n+                for (int i = 0; i < count; i++) {\n+                    int pos = buffer.position();\n+                    // always an integer\n+                    // see profiler.h\n+                    // MAX_CALLTRACES = 65536\n+                    int stackTraceKey = (int) buffer.getLong();\n+                    this.stackTraceIdToFilePositions.put(stackTraceKey, pos);\n+                    buffer.get(); // truncated\n+                    int numFrames = buffer.getInt();\n+                    int sizeOfFrame = 13;\n+                    setPosition(buffer, buffer.position() + numFrames * sizeOfFrame);\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_CLASS:\n+                for (int i = 0; i < count; i++) {\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    buffer.getLong(); // loader class\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int classNameSymbolId = (int) buffer.getLong();\n+                    classIdToClassNameSymbolId.put(classId, classNameSymbolId); // class name\n+                    buffer.getShort(); // access flags\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_METHOD:\n+                for (int i = 1; i <= count; i++) {\n+                    long id = buffer.getLong();\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int methodNameSymbolId = (int) buffer.getLong();\n+                    framesByFrameId.put(id, new LazyStackFrame(classId, methodNameSymbolId));\n+                    buffer.getLong(); // signature\n+                    buffer.getShort(); // modifiers\n+                    buffer.get(); // hidden\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_SYMBOL:\n+                for (int i = 0; i < count; i++) {\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int symbolId = (int) buffer.getLong();\n+                    int pos = buffer.position();\n+                    symbols.put(symbolId, new Symbol(pos));\n+                    skipString();\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_STATE:\n+                // we're not really interested in the thread states (async-profiler hard-codes state RUNNABLE) anyways\n+                // but we sill have to consume the bytes", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489"}, "originalPosition": 211}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyMjM0Nw==", "bodyText": "That's great news. I'll implement that once it's available in async-profiler.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r374222347", "createdAt": "2020-02-03T17:01:13Z", "author": {"login": "felixbarny"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "diffHunk": "@@ -0,0 +1,531 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+import co.elastic.apm.agent.profiler.collections.Int2IntHashMap;\n+import co.elastic.apm.agent.profiler.collections.Int2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * Parses the binary JFR file created by async-profiler.\n+ * May not work with JFR files created by an actual flight recorder.\n+ * <p>\n+ * The implementation is tuned with to minimize allocations when parsing a JFR file.\n+ * Most data structures can be reused by first {@linkplain #resetState() resetting the state} and then {@linkplain #parse(File, List, List) parsing}\n+ * another file.\n+ * </p>\n+ * <p>\n+ * The JFR file itself is mapped into memory via a {@link MappedByteBuffer}.\n+ * This does not consume heap memory, the operating system loads pages the file into memory as they are requested.\n+ * Unfortunately, unmapping a {@link MappedByteBuffer} can only be done by letting it be garbage collected.\n+ * </p>\n+ */\n+public class JfrParser implements Recyclable {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(JfrParser.class);\n+\n+    private static final byte[] MAGIC_BYTES = new byte[]{'F', 'L', 'R', '\\0'};\n+    private static final Set<String> JAVA_FRAME_TYPES = new HashSet<>(Arrays.asList(\"Interpreted\", \"JIT compiled\", \"Inlined\"));\n+\n+    @Nullable\n+    private MappedByteBuffer buffer;\n+    private int eventsOffset;\n+    private int metadataOffset;\n+    @Nullable\n+    private boolean[] isJavaFrameType;\n+    private final Int2IntHashMap classIdToClassNameSymbolId = new Int2IntHashMap(-1);\n+    private final Int2ObjectHashMap<Symbol> symbols = new Int2ObjectHashMap<>();\n+    private final Int2IntHashMap stackTraceIdToFilePositions = new Int2IntHashMap(-1);\n+    private final Long2ObjectHashMap<LazyStackFrame> framesByFrameId = new Long2ObjectHashMap<>();\n+    // used to resolve a symbol with minimal allocations\n+    private final StringBuilder symbolBuilder = new StringBuilder();\n+    @Nullable\n+    private List<WildcardMatcher> excludedClasses;\n+    @Nullable\n+    private List<WildcardMatcher> includedClasses;\n+\n+    /**\n+     * Initializes the parser to make it ready for {@link #resolveStackTrace(long, boolean, List, int)} to be called.\n+     *\n+     * @param file            the JFR file to parse\n+     * @param excludedClasses Class names to exclude in stack traces (has an effect on {@link #resolveStackTrace(long, boolean, List, int)})\n+     * @param includedClasses Class names to include in stack traces (has an effect on {@link #resolveStackTrace(long, boolean, List, int)})\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void parse(File file, List<WildcardMatcher> excludedClasses, List<WildcardMatcher> includedClasses) throws IOException {\n+        this.excludedClasses = excludedClasses;\n+        this.includedClasses = includedClasses;\n+        try (RandomAccessFile raf = new RandomAccessFile(file, \"r\")) {\n+            FileChannel channel = raf.getChannel();\n+            logger.debug(\"Parsing {} ({} bytes)\", file, channel.size());\n+            if (channel.size() > Integer.MAX_VALUE) {\n+                // mapping a file into memory is only possible for chunks of the file which fall into the Integer range (2GB)\n+                // that is because MappedByteBuffers are ByteBuffers which only accept ints in position(int pos)\n+                throw new IllegalArgumentException(\"Input file too large\");\n+            }\n+            this.buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, channel.size());\n+        }\n+        for (byte magicByte : MAGIC_BYTES) {\n+            if (buffer.get() != magicByte) {\n+                throw new IllegalArgumentException(\"Not a JFR file\");\n+            }\n+        }\n+        short major = buffer.getShort();\n+        short minor = buffer.getShort();\n+        if (major != 0 || minor != 9) {\n+            throw new IllegalArgumentException(String.format(\"Can only parse version 0.9. Was %d.%d\", major, minor));\n+        }\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        metadataOffset = (int) buffer.getLong();\n+        eventsOffset = buffer.position();\n+\n+        setPosition(buffer, metadataOffset);\n+        int checkpointOffset = parseMetadata(buffer);\n+        setPosition(buffer, checkpointOffset);\n+        parseCheckpoint(buffer);\n+    }\n+\n+    private int parseMetadata(MappedByteBuffer buffer) throws IOException {\n+        int size = buffer.getInt();\n+        expectEventType(buffer, EventTypeId.EVENT_METADATA);\n+        int checkpointOffsetPosition = size - 16;\n+        setPosition(buffer, buffer.position() + checkpointOffsetPosition);\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        return (int) buffer.getLong();\n+    }\n+\n+    private void expectEventType(MappedByteBuffer buffer, int expectedEventType) throws IOException {\n+        int eventType = buffer.getInt();\n+        if (eventType != expectedEventType) {\n+            throw new IOException(\"Expected \" + expectedEventType + \" but got \" + eventType);\n+        }\n+    }\n+\n+    private void parseCheckpoint(MappedByteBuffer buffer) throws IOException {\n+        buffer.getInt(); // size\n+        expectEventType(buffer, EventTypeId.EVENT_CHECKPOINT);\n+        buffer.getLong(); // stop timestamp\n+        buffer.getLong(); // previous checkpoint - always 0 in async-profiler\n+        while (buffer.position() < metadataOffset) {\n+            parseContentType(buffer);\n+        }\n+    }\n+\n+    private void parseContentType(MappedByteBuffer buffer) throws IOException {\n+        int contentTypeId = buffer.getInt();\n+        logger.debug(\"Parsing content type {}\", contentTypeId);\n+        int count = buffer.getInt();\n+        switch (contentTypeId) {\n+            case ContentTypeId.CONTENT_THREAD:\n+                // currently no thread info\n+                break;\n+            case ContentTypeId.CONTENT_STACKTRACE:\n+                for (int i = 0; i < count; i++) {\n+                    int pos = buffer.position();\n+                    // always an integer\n+                    // see profiler.h\n+                    // MAX_CALLTRACES = 65536\n+                    int stackTraceKey = (int) buffer.getLong();\n+                    this.stackTraceIdToFilePositions.put(stackTraceKey, pos);\n+                    buffer.get(); // truncated\n+                    int numFrames = buffer.getInt();\n+                    int sizeOfFrame = 13;\n+                    setPosition(buffer, buffer.position() + numFrames * sizeOfFrame);\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_CLASS:\n+                for (int i = 0; i < count; i++) {\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    buffer.getLong(); // loader class\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int classNameSymbolId = (int) buffer.getLong();\n+                    classIdToClassNameSymbolId.put(classId, classNameSymbolId); // class name\n+                    buffer.getShort(); // access flags\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_METHOD:\n+                for (int i = 1; i <= count; i++) {\n+                    long id = buffer.getLong();\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int methodNameSymbolId = (int) buffer.getLong();\n+                    framesByFrameId.put(id, new LazyStackFrame(classId, methodNameSymbolId));\n+                    buffer.getLong(); // signature\n+                    buffer.getShort(); // modifiers\n+                    buffer.get(); // hidden\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_SYMBOL:\n+                for (int i = 0; i < count; i++) {\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int symbolId = (int) buffer.getLong();\n+                    int pos = buffer.position();\n+                    symbols.put(symbolId, new Symbol(pos));\n+                    skipString();\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_STATE:\n+                // we're not really interested in the thread states (async-profiler hard-codes state RUNNABLE) anyways\n+                // but we sill have to consume the bytes", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzAwODc5Nw=="}, "originalCommit": {"oid": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489"}, "originalPosition": 211}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMwNjY5MzgxOnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMFQxNjo0MjozMlrOFjx9Gg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QyMzo0MjowMlrOFlD0rQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA2MjkzOA==", "bodyText": "Writing to a (large) MappedByteBuffer is somewhat guileful. Any put() operation may potentially get stuck, and not only in writing thread, but also cause long global time-to-safepoint pause.\nIn this sense, writing to a temporary direct ByteBuffer and then flushing with a regular write() call is safer.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r373062938", "createdAt": "2020-01-30T16:42:32Z", "author": {"login": "apangin"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,657 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#resolveStackTrace(long, boolean, List, int) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 1_000_000;\n+    private static final int MAX_STACK_DEPTH = 256;\n+    private static final int PRE_ALLOCATE_ACTIVATION_EVENTS_FILE_MB = 10;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+            preAllocate(activationEventBuffer, PRE_ALLOCATE_ACTIVATION_EVENTS_FILE_MB);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489"}, "originalPosition": 189}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIxODM5NA==", "bodyText": "Thx for the tip!\nDo similar problems occur when reading?", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r374218394", "createdAt": "2020-02-03T16:54:06Z", "author": {"login": "felixbarny"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,657 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#resolveStackTrace(long, boolean, List, int) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 1_000_000;\n+    private static final int MAX_STACK_DEPTH = 256;\n+    private static final int PRE_ALLOCATE_ACTIVATION_EVENTS_FILE_MB = 10;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+            preAllocate(activationEventBuffer, PRE_ALLOCATE_ACTIVATION_EVENTS_FILE_MB);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA2MjkzOA=="}, "originalCommit": {"oid": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489"}, "originalPosition": 189}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQwNDI2OQ==", "bodyText": "Yes, reading can be even worse. When writing to a MappedByteBuffer, dirty pages are flushed in background as long as it is possible; but when reading, page faults are synchronous.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r374404269", "createdAt": "2020-02-03T23:42:02Z", "author": {"login": "apangin"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,657 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#resolveStackTrace(long, boolean, List, int) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 1_000_000;\n+    private static final int MAX_STACK_DEPTH = 256;\n+    private static final int PRE_ALLOCATE_ACTIVATION_EVENTS_FILE_MB = 10;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+            preAllocate(activationEventBuffer, PRE_ALLOCATE_ACTIVATION_EVENTS_FILE_MB);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA2MjkzOA=="}, "originalCommit": {"oid": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489"}, "originalPosition": 189}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMwNjY5ODA3OnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMFQxNjo0Mzo0N1rOFjx_4A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNjo1NDo1NVrOFk4gdg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA2MzY0OA==", "bodyText": "Sleeping even if there is more data to process - is it intentional?", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r373063648", "createdAt": "2020-01-30T16:43:47Z", "author": {"login": "apangin"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,657 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#resolveStackTrace(long, boolean, List, int) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 1_000_000;\n+    private static final int MAX_STACK_DEPTH = 256;\n+    private static final int PRE_ALLOCATE_ACTIVATION_EVENTS_FILE_MB = 10;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+            preAllocate(activationEventBuffer, PRE_ALLOCATE_ACTIVATION_EVENTS_FILE_MB);\n+        }\n+    }\n+\n+    /**\n+     * Makes sure that the first blocks of the file are contiguous to provide fast sequential access\n+     */\n+    private static void preAllocate(MappedByteBuffer activationEventBuffer, int mb) {\n+        byte[] oneKb = new byte[1024];\n+        for (int i = 0; i < mb * 1024; i++) {\n+            activationEventBuffer.put(oneKb);\n+        }\n+        ((Buffer) activationEventBuffer).clear();\n+    }\n+\n+    private RingBuffer<ActivationEvent> createRingBuffer() {\n+        return RingBuffer.<ActivationEvent>createMultiProducer(\n+            new EventFactory<ActivationEvent>() {\n+                @Override\n+                public ActivationEvent newInstance() {\n+                    return new ActivationEvent();\n+                }\n+            },\n+            RING_BUFFER_SIZE,\n+            new NoWaitStrategy());\n+    }\n+\n+    /**\n+     * Called whenever a span is activated.\n+     * <p>\n+     * This and {@link #onDeactivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onActivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            boolean success = eventBuffer.tryPublishEvent(ACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+            if (!success && logger.isDebugEnabled()) {\n+                logger.debug(\"Could not add activation event to ring buffer as no slots are available\");\n+            }\n+            return success;\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * Called whenever a span is deactivated.\n+     * <p>\n+     * This and {@link #onActivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onDeactivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            boolean success = eventBuffer.tryPublishEvent(DEACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+            if (!success && logger.isDebugEnabled()) {\n+                logger.debug(\"Could not add deactivation event to ring buffer as no slots are available\");\n+            }\n+            return success;\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public void run() {\n+        profilingSessions++;\n+        if (config.isProfilingDisabled()) {\n+            scheduler.schedule(this, config.getProfilingInterval().getMillis(), TimeUnit.MILLISECONDS);\n+            return;\n+        }\n+\n+        TimeDuration sampleRate = config.getSamplingInterval();\n+        TimeDuration profilingDuration = config.getProfilingDuration();\n+\n+        setProfilingSessionOngoing(true);\n+\n+        logger.debug(\"Start profiling session\");\n+        try {\n+            profile(sampleRate, profilingDuration);\n+        } catch (Throwable t) {\n+            setProfilingSessionOngoing(false);\n+            logger.error(\"Stopping profiler\", t);\n+            return;\n+        }\n+        logger.debug(\"End profiling session\");\n+\n+        boolean interrupted = Thread.currentThread().isInterrupted();\n+        boolean continueProfilingSession = config.isNonStopProfiling() && !interrupted && config.isProfilingEnabled();\n+        setProfilingSessionOngoing(continueProfilingSession);\n+\n+        if (!interrupted) {\n+            long delay = config.getProfilingInterval().getMillis() - profilingDuration.getMillis();\n+            scheduler.schedule(this, delay, TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private void profile(TimeDuration sampleRate, TimeDuration profilingDuration) throws Exception {\n+        AsyncProfiler asyncProfiler = AsyncProfiler.getInstance();\n+        try {\n+            String startMessage = asyncProfiler.execute(\"start,jfr,event=wall,interval=\" + sampleRate.getMillis() + \"ms,alluser,file=\" + jfrFile);\n+            logger.debug(startMessage);\n+\n+            consumeActivationEventsFromRingBufferAndWriteToFile(profilingDuration);\n+\n+            String stopMessage = asyncProfiler.execute(\"stop\");\n+            logger.debug(stopMessage);\n+\n+            processTraces(jfrFile);\n+        } catch (InterruptedException e) {\n+            asyncProfiler.stop();\n+            Thread.currentThread().interrupt();\n+        }\n+    }\n+\n+    private void consumeActivationEventsFromRingBufferAndWriteToFile(TimeDuration profilingDuration) throws Exception {\n+        resetActivationEventBuffer();\n+        long threshold = System.currentTimeMillis() + profilingDuration.getMillis();\n+        long initialSleep = 100_000;\n+        long maxSleep = 10_000_000;\n+        long sleep = initialSleep;\n+        while (System.currentTimeMillis() < threshold) {\n+            if (activationEventBuffer.hasRemaining()) {\n+                EventPoller.PollState poll = consumeActivationEventsFromRingBufferAndWriteToFile();\n+                if (poll == EventPoller.PollState.PROCESSING) {\n+                    sleep = initialSleep;\n+                } else {\n+                    if (sleep < maxSleep) {\n+                        sleep *= 2;\n+                    }\n+                }\n+                LockSupport.parkNanos(sleep);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489"}, "originalPosition": 327}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIxODg3MA==", "bodyText": "Good catch, there might be new data after poll returns.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r374218870", "createdAt": "2020-02-03T16:54:55Z", "author": {"login": "felixbarny"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,657 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#resolveStackTrace(long, boolean, List, int) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 1_000_000;\n+    private static final int MAX_STACK_DEPTH = 256;\n+    private static final int PRE_ALLOCATE_ACTIVATION_EVENTS_FILE_MB = 10;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+            preAllocate(activationEventBuffer, PRE_ALLOCATE_ACTIVATION_EVENTS_FILE_MB);\n+        }\n+    }\n+\n+    /**\n+     * Makes sure that the first blocks of the file are contiguous to provide fast sequential access\n+     */\n+    private static void preAllocate(MappedByteBuffer activationEventBuffer, int mb) {\n+        byte[] oneKb = new byte[1024];\n+        for (int i = 0; i < mb * 1024; i++) {\n+            activationEventBuffer.put(oneKb);\n+        }\n+        ((Buffer) activationEventBuffer).clear();\n+    }\n+\n+    private RingBuffer<ActivationEvent> createRingBuffer() {\n+        return RingBuffer.<ActivationEvent>createMultiProducer(\n+            new EventFactory<ActivationEvent>() {\n+                @Override\n+                public ActivationEvent newInstance() {\n+                    return new ActivationEvent();\n+                }\n+            },\n+            RING_BUFFER_SIZE,\n+            new NoWaitStrategy());\n+    }\n+\n+    /**\n+     * Called whenever a span is activated.\n+     * <p>\n+     * This and {@link #onDeactivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onActivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            boolean success = eventBuffer.tryPublishEvent(ACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+            if (!success && logger.isDebugEnabled()) {\n+                logger.debug(\"Could not add activation event to ring buffer as no slots are available\");\n+            }\n+            return success;\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * Called whenever a span is deactivated.\n+     * <p>\n+     * This and {@link #onActivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onDeactivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            boolean success = eventBuffer.tryPublishEvent(DEACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+            if (!success && logger.isDebugEnabled()) {\n+                logger.debug(\"Could not add deactivation event to ring buffer as no slots are available\");\n+            }\n+            return success;\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public void run() {\n+        profilingSessions++;\n+        if (config.isProfilingDisabled()) {\n+            scheduler.schedule(this, config.getProfilingInterval().getMillis(), TimeUnit.MILLISECONDS);\n+            return;\n+        }\n+\n+        TimeDuration sampleRate = config.getSamplingInterval();\n+        TimeDuration profilingDuration = config.getProfilingDuration();\n+\n+        setProfilingSessionOngoing(true);\n+\n+        logger.debug(\"Start profiling session\");\n+        try {\n+            profile(sampleRate, profilingDuration);\n+        } catch (Throwable t) {\n+            setProfilingSessionOngoing(false);\n+            logger.error(\"Stopping profiler\", t);\n+            return;\n+        }\n+        logger.debug(\"End profiling session\");\n+\n+        boolean interrupted = Thread.currentThread().isInterrupted();\n+        boolean continueProfilingSession = config.isNonStopProfiling() && !interrupted && config.isProfilingEnabled();\n+        setProfilingSessionOngoing(continueProfilingSession);\n+\n+        if (!interrupted) {\n+            long delay = config.getProfilingInterval().getMillis() - profilingDuration.getMillis();\n+            scheduler.schedule(this, delay, TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private void profile(TimeDuration sampleRate, TimeDuration profilingDuration) throws Exception {\n+        AsyncProfiler asyncProfiler = AsyncProfiler.getInstance();\n+        try {\n+            String startMessage = asyncProfiler.execute(\"start,jfr,event=wall,interval=\" + sampleRate.getMillis() + \"ms,alluser,file=\" + jfrFile);\n+            logger.debug(startMessage);\n+\n+            consumeActivationEventsFromRingBufferAndWriteToFile(profilingDuration);\n+\n+            String stopMessage = asyncProfiler.execute(\"stop\");\n+            logger.debug(stopMessage);\n+\n+            processTraces(jfrFile);\n+        } catch (InterruptedException e) {\n+            asyncProfiler.stop();\n+            Thread.currentThread().interrupt();\n+        }\n+    }\n+\n+    private void consumeActivationEventsFromRingBufferAndWriteToFile(TimeDuration profilingDuration) throws Exception {\n+        resetActivationEventBuffer();\n+        long threshold = System.currentTimeMillis() + profilingDuration.getMillis();\n+        long initialSleep = 100_000;\n+        long maxSleep = 10_000_000;\n+        long sleep = initialSleep;\n+        while (System.currentTimeMillis() < threshold) {\n+            if (activationEventBuffer.hasRemaining()) {\n+                EventPoller.PollState poll = consumeActivationEventsFromRingBufferAndWriteToFile();\n+                if (poll == EventPoller.PollState.PROCESSING) {\n+                    sleep = initialSleep;\n+                } else {\n+                    if (sleep < maxSleep) {\n+                        sleep *= 2;\n+                    }\n+                }\n+                LockSupport.parkNanos(sleep);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA2MzY0OA=="}, "originalCommit": {"oid": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489"}, "originalPosition": 327}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMwNjc4NTc3OnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMFQxNzowODo0N1rOFjy3uA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMFQxNzowODo0N1rOFjy3uA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA3Nzk0NA==", "bodyText": "IMO, a regular List, sorted afterwards, will be more space-efficient, and will preserve StackTraceEvents with duplicate timestamps (although they are unlikely).", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r373077944", "createdAt": "2020-01-30T17:08:47Z", "author": {"login": "apangin"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,657 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#resolveStackTrace(long, boolean, List, int) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 1_000_000;\n+    private static final int MAX_STACK_DEPTH = 256;\n+    private static final int PRE_ALLOCATE_ACTIVATION_EVENTS_FILE_MB = 10;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+            preAllocate(activationEventBuffer, PRE_ALLOCATE_ACTIVATION_EVENTS_FILE_MB);\n+        }\n+    }\n+\n+    /**\n+     * Makes sure that the first blocks of the file are contiguous to provide fast sequential access\n+     */\n+    private static void preAllocate(MappedByteBuffer activationEventBuffer, int mb) {\n+        byte[] oneKb = new byte[1024];\n+        for (int i = 0; i < mb * 1024; i++) {\n+            activationEventBuffer.put(oneKb);\n+        }\n+        ((Buffer) activationEventBuffer).clear();\n+    }\n+\n+    private RingBuffer<ActivationEvent> createRingBuffer() {\n+        return RingBuffer.<ActivationEvent>createMultiProducer(\n+            new EventFactory<ActivationEvent>() {\n+                @Override\n+                public ActivationEvent newInstance() {\n+                    return new ActivationEvent();\n+                }\n+            },\n+            RING_BUFFER_SIZE,\n+            new NoWaitStrategy());\n+    }\n+\n+    /**\n+     * Called whenever a span is activated.\n+     * <p>\n+     * This and {@link #onDeactivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onActivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            boolean success = eventBuffer.tryPublishEvent(ACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+            if (!success && logger.isDebugEnabled()) {\n+                logger.debug(\"Could not add activation event to ring buffer as no slots are available\");\n+            }\n+            return success;\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * Called whenever a span is deactivated.\n+     * <p>\n+     * This and {@link #onActivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onDeactivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            boolean success = eventBuffer.tryPublishEvent(DEACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+            if (!success && logger.isDebugEnabled()) {\n+                logger.debug(\"Could not add deactivation event to ring buffer as no slots are available\");\n+            }\n+            return success;\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public void run() {\n+        profilingSessions++;\n+        if (config.isProfilingDisabled()) {\n+            scheduler.schedule(this, config.getProfilingInterval().getMillis(), TimeUnit.MILLISECONDS);\n+            return;\n+        }\n+\n+        TimeDuration sampleRate = config.getSamplingInterval();\n+        TimeDuration profilingDuration = config.getProfilingDuration();\n+\n+        setProfilingSessionOngoing(true);\n+\n+        logger.debug(\"Start profiling session\");\n+        try {\n+            profile(sampleRate, profilingDuration);\n+        } catch (Throwable t) {\n+            setProfilingSessionOngoing(false);\n+            logger.error(\"Stopping profiler\", t);\n+            return;\n+        }\n+        logger.debug(\"End profiling session\");\n+\n+        boolean interrupted = Thread.currentThread().isInterrupted();\n+        boolean continueProfilingSession = config.isNonStopProfiling() && !interrupted && config.isProfilingEnabled();\n+        setProfilingSessionOngoing(continueProfilingSession);\n+\n+        if (!interrupted) {\n+            long delay = config.getProfilingInterval().getMillis() - profilingDuration.getMillis();\n+            scheduler.schedule(this, delay, TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private void profile(TimeDuration sampleRate, TimeDuration profilingDuration) throws Exception {\n+        AsyncProfiler asyncProfiler = AsyncProfiler.getInstance();\n+        try {\n+            String startMessage = asyncProfiler.execute(\"start,jfr,event=wall,interval=\" + sampleRate.getMillis() + \"ms,alluser,file=\" + jfrFile);\n+            logger.debug(startMessage);\n+\n+            consumeActivationEventsFromRingBufferAndWriteToFile(profilingDuration);\n+\n+            String stopMessage = asyncProfiler.execute(\"stop\");\n+            logger.debug(stopMessage);\n+\n+            processTraces(jfrFile);\n+        } catch (InterruptedException e) {\n+            asyncProfiler.stop();\n+            Thread.currentThread().interrupt();\n+        }\n+    }\n+\n+    private void consumeActivationEventsFromRingBufferAndWriteToFile(TimeDuration profilingDuration) throws Exception {\n+        resetActivationEventBuffer();\n+        long threshold = System.currentTimeMillis() + profilingDuration.getMillis();\n+        long initialSleep = 100_000;\n+        long maxSleep = 10_000_000;\n+        long sleep = initialSleep;\n+        while (System.currentTimeMillis() < threshold) {\n+            if (activationEventBuffer.hasRemaining()) {\n+                EventPoller.PollState poll = consumeActivationEventsFromRingBufferAndWriteToFile();\n+                if (poll == EventPoller.PollState.PROCESSING) {\n+                    sleep = initialSleep;\n+                } else {\n+                    if (sleep < maxSleep) {\n+                        sleep *= 2;\n+                    }\n+                }\n+                LockSupport.parkNanos(sleep);\n+            } else {\n+                logger.warn(\"The activation events file is full. Try lowering the profiling_duration.\");\n+                // the file is full, sleep the rest of the profilingDuration\n+                Thread.sleep(Math.max(0, threshold - System.currentTimeMillis()));\n+            }\n+        }\n+    }\n+\n+    private void resetActivationEventBuffer() {\n+        ((Buffer) activationEventBuffer).clear();\n+    }\n+\n+    EventPoller.PollState consumeActivationEventsFromRingBufferAndWriteToFile() throws Exception {\n+        return poller.poll(writeActivationEventToFileHandler);\n+    }\n+\n+    private void processTraces(File file) throws IOException {\n+        if (activationEventBuffer.position() == 0) {\n+            logger.debug(\"No activation events during this period. Skip processing stack traces.\");\n+            return;\n+        }\n+        long start = System.nanoTime();\n+        List<WildcardMatcher> excludedClasses = config.getExcludedClasses();\n+        List<WildcardMatcher> includedClasses = config.getIncludedClasses();\n+        try {\n+            jfrParser.parse(file, excludedClasses, includedClasses);\n+            startProcessingActivationEventsFile();\n+            final SortedSet<StackTraceEvent> stackTraceEvents = getStackTraceEvents(jfrParser);\n+            if (logger.isDebugEnabled()) {\n+                logger.debug(\"Processing {} stack traces\", stackTraceEvents.size());\n+            }\n+            List<StackFrame> stackFrames = new ArrayList<>();\n+            ElasticApmTracer tracer = this.tracer;\n+            ActivationEvent event = new ActivationEvent();\n+            for (StackTraceEvent stackTrace : stackTraceEvents) {\n+                processActivationEventsUpTo(stackTrace.nanoTime, event);\n+                CallTree.Root root = profiledThreads.get(stackTrace.threadId);\n+                if (root != null) {\n+                    jfrParser.resolveStackTrace(stackTrace.stackTraceId, true, stackFrames, MAX_STACK_DEPTH);\n+                    if (stackFrames.size() == MAX_STACK_DEPTH) {\n+                        logger.debug(\"Max stack depth reached. Set profiling_included_classes or profiling_excluded_classes.\");\n+                    }\n+                    root.addStackTrace(tracer, stackFrames, stackTrace.nanoTime);\n+                }\n+                stackFrames.clear();\n+            }\n+        } finally {\n+            if (logger.isDebugEnabled()) {\n+                logger.debug(\"Processing traces took {}\u00b5s\", (System.nanoTime() - start) / 1000);\n+            }\n+            jfrParser.resetState();\n+        }\n+    }\n+\n+    /**\n+     * Returns stack trace events of relevant threads sorted by timestamp.\n+     * The events in the JFR file are not in order.\n+     * Even for the same thread, a more recent event might come before an older event.\n+     * In order to be able to correlate stack trace events and activation events, both need to be in order.\n+     *\n+     * Returns only events for threads where at least one activation happened\n+     */\n+    private SortedSet<StackTraceEvent> getStackTraceEvents(JfrParser jfrParser) throws IOException {\n+        final LongHashSet nativeThreadIds = threadMapper.getNativeThreadIds();\n+        final SortedSet<StackTraceEvent> stackTraceEvents = new TreeSet<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489"}, "originalPosition": 392}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMwNjkxMzM0OnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/NativeThreadIdToJavaThreadMapper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMFQxNzo0ODo0NlrOFj0HqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNjo1MjoxMlrOFk4alg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA5ODQwOA==", "bodyText": "Matching Java threads by native id looks a bit hacky. It probably makes sense for async-profiler to record Java thread id, too.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r373098408", "createdAt": "2020-01-30T17:48:46Z", "author": {"login": "apangin"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/NativeThreadIdToJavaThreadMapper.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import com.blogspot.mydailyjava.weaklockfree.DetachedThreadLocal;\n+import com.blogspot.mydailyjava.weaklockfree.WeakConcurrentMap;\n+\n+import java.util.Map;\n+\n+public class NativeThreadIdToJavaThreadMapper {\n+\n+    private final DetachedThreadLocal<Long> threadToNativeThread = new DetachedThreadLocal<>(DetachedThreadLocal.Cleaner.INLINE);\n+\n+    /**\n+     * Returns the native thread id of the current thread\n+     */\n+    public long getNativeThreadId() {\n+        Long nativeThreadId = threadToNativeThread.get();\n+        if (nativeThreadId == null) {\n+            nativeThreadId = AsyncProfiler.getInstance().getNativeThreadId();\n+            threadToNativeThread.set(nativeThreadId);\n+        }\n+        return nativeThreadId;\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIxNzM2Ng==", "bodyText": "Agree. See also jvm-profiling-tools/async-profiler#277 (comment)", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r374217366", "createdAt": "2020-02-03T16:52:12Z", "author": {"login": "felixbarny"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/NativeThreadIdToJavaThreadMapper.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import com.blogspot.mydailyjava.weaklockfree.DetachedThreadLocal;\n+import com.blogspot.mydailyjava.weaklockfree.WeakConcurrentMap;\n+\n+import java.util.Map;\n+\n+public class NativeThreadIdToJavaThreadMapper {\n+\n+    private final DetachedThreadLocal<Long> threadToNativeThread = new DetachedThreadLocal<>(DetachedThreadLocal.Cleaner.INLINE);\n+\n+    /**\n+     * Returns the native thread id of the current thread\n+     */\n+    public long getNativeThreadId() {\n+        Long nativeThreadId = threadToNativeThread.get();\n+        if (nativeThreadId == null) {\n+            nativeThreadId = AsyncProfiler.getInstance().getNativeThreadId();\n+            threadToNativeThread.set(nativeThreadId);\n+        }\n+        return nativeThreadId;\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA5ODQwOA=="}, "originalCommit": {"oid": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNTk3MjQ3OnYy", "diffSide": "RIGHT", "path": "apm-agent-core/src/main/java/co/elastic/apm/agent/impl/transaction/TraceContext.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQwNjoyMjo0N1rOFlJL3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQwNjoyMjo0N1rOFlJL3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQ5MjEyNA==", "bodyText": "Maybe switch to using the binary header functionalities for serialization (fillOutgoingTraceParentBinaryHeader) and deserialization (asChildOf(byte[])), with an extended byte array where you separately serialize/deserialize the clock and service name? Just so we don't need to maintain both", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r374492124", "createdAt": "2020-02-04T06:22:47Z", "author": {"login": "eyalkoren"}, "path": "apm-agent-core/src/main/java/co/elastic/apm/agent/impl/transaction/TraceContext.java", "diffHunk": "@@ -559,6 +575,51 @@ public ClassLoader getApplicationClassLoader() {\n         }\n     }\n \n+    public byte[] serialize() {\n+        byte[] result = new byte[SERIALIZED_LENGTH];\n+        serialize(result);\n+        return result;\n+    }\n+\n+    public void serialize(byte[] buffer) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b14253690f5eb1256bdd189eced6930ee683a7bf"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMzMzY0NDQxOnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/BufferedFile.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMFQxODowODowMVrOFnwLDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QxMjo1NzoyN1rOFpSwAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzIyODA0Ng==", "bodyText": "Seems like we read redundant 4MB at the beginning, since after getting metadata offset, we immediately seek to the end of the file. Probably, read can accept another parameter - the maximum number of bytes to read.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r377228046", "createdAt": "2020-02-10T18:08:01Z", "author": {"login": "apangin"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/BufferedFile.java", "diffHunk": "@@ -0,0 +1,244 @@\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+\n+/**\n+ * An abstraction similar to {@link MappedByteBuffer} that allows to read the content of a file with an API that is similar to\n+ * {@link ByteBuffer}.\n+ * <p>\n+ * Instances of this class hold a reusable buffer that contains a subset of the file,\n+ * or the whole file if the buffer's capacity is greater or equal to the file's size.\n+ * </p>\n+ * <p>\n+ * Whenever calling a method like {@link #getLong()} or {@link #position(long)} would exceed the currently buffered range\n+ * the same buffer is filled with a different range of the file.\n+ * </p>\n+ * <p>\n+ * The downside of {@link MappedByteBuffer} (and the reason for implementing this abstraction)\n+ * is that calling methods like {@link MappedByteBuffer#get()} can increase time-to-safepoint.\n+ * This is because these methods are implemented as JVM intrinsics.\n+ * When the JVM executes an intrinsic, it does not switch to the native execution context which means that it's not ready to enter a safepoint\n+ * whenever a intrinsic runs.\n+ * As reading a file from disk can get stuck (for example when the disk is busy) calling {@link MappedByteBuffer#get()} may take a while to execute.\n+ * While it's executing other threads have to wait for it to finish if the JVM wants to reach a safe point.\n+ * </p>\n+ */\n+class BufferedFile implements Recyclable {\n+\n+    private static final int SIZE_OF_BYTE = 1;\n+    private static final int SIZE_OF_SHORT = 2;\n+    private static final int SIZE_OF_INT = 4;\n+    private static final int SIZE_OF_LONG = 8;\n+    private final ByteBuffer buffer;\n+    private final int capacity;\n+    private long offset;\n+    private long limit;\n+    private boolean wholeFileInBuffer;\n+    @Nullable\n+    private RandomAccessFile randomAccessFile;\n+    @Nullable\n+    private FileChannel fileChannel;\n+\n+    public BufferedFile(ByteBuffer buffer) {\n+        this.buffer = buffer;\n+        capacity = buffer.capacity();\n+    }\n+\n+    /**\n+     * Starts reading the file into the {@linkplain #buffer buffer}\n+     *\n+     * @param file the file to read from\n+     * @throws IOException If some I/O error occurs\n+     */\n+    public void setFile(File file) throws IOException {\n+        randomAccessFile = new RandomAccessFile(file, \"r\");\n+        fileChannel = randomAccessFile.getChannel();\n+        read(0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cfa4e6f3c152f65add494e01f9f0bc566bfd6069"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODg0MzEzOA==", "bodyText": "good catch! done.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r378843138", "createdAt": "2020-02-13T12:57:27Z", "author": {"login": "felixbarny"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/BufferedFile.java", "diffHunk": "@@ -0,0 +1,244 @@\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+\n+/**\n+ * An abstraction similar to {@link MappedByteBuffer} that allows to read the content of a file with an API that is similar to\n+ * {@link ByteBuffer}.\n+ * <p>\n+ * Instances of this class hold a reusable buffer that contains a subset of the file,\n+ * or the whole file if the buffer's capacity is greater or equal to the file's size.\n+ * </p>\n+ * <p>\n+ * Whenever calling a method like {@link #getLong()} or {@link #position(long)} would exceed the currently buffered range\n+ * the same buffer is filled with a different range of the file.\n+ * </p>\n+ * <p>\n+ * The downside of {@link MappedByteBuffer} (and the reason for implementing this abstraction)\n+ * is that calling methods like {@link MappedByteBuffer#get()} can increase time-to-safepoint.\n+ * This is because these methods are implemented as JVM intrinsics.\n+ * When the JVM executes an intrinsic, it does not switch to the native execution context which means that it's not ready to enter a safepoint\n+ * whenever a intrinsic runs.\n+ * As reading a file from disk can get stuck (for example when the disk is busy) calling {@link MappedByteBuffer#get()} may take a while to execute.\n+ * While it's executing other threads have to wait for it to finish if the JVM wants to reach a safe point.\n+ * </p>\n+ */\n+class BufferedFile implements Recyclable {\n+\n+    private static final int SIZE_OF_BYTE = 1;\n+    private static final int SIZE_OF_SHORT = 2;\n+    private static final int SIZE_OF_INT = 4;\n+    private static final int SIZE_OF_LONG = 8;\n+    private final ByteBuffer buffer;\n+    private final int capacity;\n+    private long offset;\n+    private long limit;\n+    private boolean wholeFileInBuffer;\n+    @Nullable\n+    private RandomAccessFile randomAccessFile;\n+    @Nullable\n+    private FileChannel fileChannel;\n+\n+    public BufferedFile(ByteBuffer buffer) {\n+        this.buffer = buffer;\n+        capacity = buffer.capacity();\n+    }\n+\n+    /**\n+     * Starts reading the file into the {@linkplain #buffer buffer}\n+     *\n+     * @param file the file to read from\n+     * @throws IOException If some I/O error occurs\n+     */\n+    public void setFile(File file) throws IOException {\n+        randomAccessFile = new RandomAccessFile(file, \"r\");\n+        fileChannel = randomAccessFile.getChannel();\n+        read(0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzIyODA0Ng=="}, "originalCommit": {"oid": "cfa4e6f3c152f65add494e01f9f0bc566bfd6069"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMzMzY1NjQ5OnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/BufferedFile.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMFQxODoxMTozNVrOFnwSQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMFQxODoxMTozNVrOFnwSQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzIyOTg5MA==", "bodyText": "A small note: RandomAccessFile is redundant, when it is used only to get FileChannel. You may directly call FileChannel.open instead.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r377229890", "createdAt": "2020-02-10T18:11:35Z", "author": {"login": "apangin"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/BufferedFile.java", "diffHunk": "@@ -0,0 +1,244 @@\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+\n+/**\n+ * An abstraction similar to {@link MappedByteBuffer} that allows to read the content of a file with an API that is similar to\n+ * {@link ByteBuffer}.\n+ * <p>\n+ * Instances of this class hold a reusable buffer that contains a subset of the file,\n+ * or the whole file if the buffer's capacity is greater or equal to the file's size.\n+ * </p>\n+ * <p>\n+ * Whenever calling a method like {@link #getLong()} or {@link #position(long)} would exceed the currently buffered range\n+ * the same buffer is filled with a different range of the file.\n+ * </p>\n+ * <p>\n+ * The downside of {@link MappedByteBuffer} (and the reason for implementing this abstraction)\n+ * is that calling methods like {@link MappedByteBuffer#get()} can increase time-to-safepoint.\n+ * This is because these methods are implemented as JVM intrinsics.\n+ * When the JVM executes an intrinsic, it does not switch to the native execution context which means that it's not ready to enter a safepoint\n+ * whenever a intrinsic runs.\n+ * As reading a file from disk can get stuck (for example when the disk is busy) calling {@link MappedByteBuffer#get()} may take a while to execute.\n+ * While it's executing other threads have to wait for it to finish if the JVM wants to reach a safe point.\n+ * </p>\n+ */\n+class BufferedFile implements Recyclable {\n+\n+    private static final int SIZE_OF_BYTE = 1;\n+    private static final int SIZE_OF_SHORT = 2;\n+    private static final int SIZE_OF_INT = 4;\n+    private static final int SIZE_OF_LONG = 8;\n+    private final ByteBuffer buffer;\n+    private final int capacity;\n+    private long offset;\n+    private long limit;\n+    private boolean wholeFileInBuffer;\n+    @Nullable\n+    private RandomAccessFile randomAccessFile;\n+    @Nullable\n+    private FileChannel fileChannel;\n+\n+    public BufferedFile(ByteBuffer buffer) {\n+        this.buffer = buffer;\n+        capacity = buffer.capacity();\n+    }\n+\n+    /**\n+     * Starts reading the file into the {@linkplain #buffer buffer}\n+     *\n+     * @param file the file to read from\n+     * @throws IOException If some I/O error occurs\n+     */\n+    public void setFile(File file) throws IOException {\n+        randomAccessFile = new RandomAccessFile(file, \"r\");\n+        fileChannel = randomAccessFile.getChannel();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cfa4e6f3c152f65add494e01f9f0bc566bfd6069"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMzMzY2ODA2OnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMFQxODoxNToyN1rOFnwZgQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMFQxODoxNToyN1rOFnwZgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzIzMTc0NQ==", "bodyText": "I'd add & 0xffff to convert this to an unsigned short.\nThere hardly be a string larger than 32K, but just in case.\nThe same in skipString.", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r377231745", "createdAt": "2020-02-10T18:15:27Z", "author": {"login": "apangin"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "diffHunk": "@@ -363,16 +339,17 @@ private StackFrame resolveStackFrame(int classId, int methodName) {\n         }\n     }\n \n-    private StringBuilder readUtf8String() {\n+    private StringBuilder readUtf8String() throws IOException {\n         return readUtf8String(false);\n     }\n \n-    private StringBuilder readUtf8String(boolean replaceSlashWithDot) {\n-        int size = buffer.getShort();\n+    private StringBuilder readUtf8String(boolean replaceSlashWithDot) throws IOException {\n+        int size = bufferedFile.getShort();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cfa4e6f3c152f65add494e01f9f0bc566bfd6069"}, "originalPosition": 400}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM0ODM0Mzg0OnYy", "diffSide": "RIGHT", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/BufferedFile.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQxNjo1NzoyMVrOFp9TDQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQxNjo1NzoyMVrOFp9TDQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTU0MDIzNw==", "bodyText": "0xffff", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r379540237", "createdAt": "2020-02-14T16:57:21Z", "author": {"login": "apangin"}, "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/BufferedFile.java", "diffHunk": "@@ -0,0 +1,278 @@\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.StandardOpenOption;\n+\n+/**\n+ * An abstraction similar to {@link MappedByteBuffer} that allows to read the content of a file with an API that is similar to\n+ * {@link ByteBuffer}.\n+ * <p>\n+ * Instances of this class hold a reusable buffer that contains a subset of the file,\n+ * or the whole file if the buffer's capacity is greater or equal to the file's size.\n+ * </p>\n+ * <p>\n+ * Whenever calling a method like {@link #getLong()} or {@link #position(long)} would exceed the currently buffered range\n+ * the same buffer is filled with a different range of the file.\n+ * </p>\n+ * <p>\n+ * The downside of {@link MappedByteBuffer} (and the reason for implementing this abstraction)\n+ * is that calling methods like {@link MappedByteBuffer#get()} can increase time-to-safepoint.\n+ * This is because these methods are implemented as JVM intrinsics.\n+ * When the JVM executes an intrinsic, it does not switch to the native execution context which means that it's not ready to enter a safepoint\n+ * whenever a intrinsic runs.\n+ * As reading a file from disk can get stuck (for example when the disk is busy) calling {@link MappedByteBuffer#get()} may take a while to execute.\n+ * While it's executing other threads have to wait for it to finish if the JVM wants to reach a safe point.\n+ * </p>\n+ */\n+class BufferedFile implements Recyclable {\n+\n+    private static final int SIZE_OF_BYTE = 1;\n+    private static final int SIZE_OF_SHORT = 2;\n+    private static final int SIZE_OF_INT = 4;\n+    private static final int SIZE_OF_LONG = 8;\n+    private final ByteBuffer buffer;\n+    private final int capacity;\n+    /**\n+     * The offset of the file from where the {@link #buffer} starts\n+     */\n+    private long offset;\n+    private boolean wholeFileInBuffer;\n+    @Nullable\n+    private FileChannel fileChannel;\n+\n+    public BufferedFile(ByteBuffer buffer) {\n+        this.buffer = buffer;\n+        capacity = buffer.capacity();\n+    }\n+\n+    /**\n+     * Starts reading the file into the {@linkplain #buffer buffer}\n+     *\n+     * @param file the file to read from\n+     * @throws IOException If some I/O error occurs\n+     */\n+    public void setFile(File file) throws IOException {\n+        fileChannel = FileChannel.open(file.toPath(), StandardOpenOption.READ);\n+        if (fileChannel.size() <= capacity) {\n+            read(0, capacity);\n+            wholeFileInBuffer = true;\n+        } else {\n+            buffer.flip();\n+        }\n+    }\n+\n+    /**\n+     * Returns the position of the file\n+     *\n+     * @return the position of the file\n+     */\n+    public long position() {\n+        return offset + buffer.position();\n+    }\n+\n+    /**\n+     * Skips the provided number of bytes in the file without reading new data.\n+     *\n+     * @param bytesToSkip the number of bytes to skip\n+     */\n+    public void skip(int bytesToSkip) {\n+        position(position() + bytesToSkip);\n+    }\n+\n+    /**\n+     * Sets the position of the file without reading new data.\n+     *\n+     * @param pos the new position\n+     */\n+    public void position(long pos) {\n+        long bufferDelta = pos - (offset + buffer.position());\n+        long newBufferPos = buffer.position() + bufferDelta;\n+        if (0 <= newBufferPos && newBufferPos <= buffer.capacity()) {\n+            buffer.position((int) newBufferPos);\n+        } else {\n+            // makes sure that the next ensureRemaining will load from file\n+            buffer.position(0);\n+            buffer.limit(0);\n+            offset = pos;\n+        }\n+    }\n+\n+    /**\n+     * Ensures that the provided number of bytes are available in the {@linkplain #buffer buffer}\n+     *\n+     * @param minRemaining the number of bytes which are guaranteed to be available in the {@linkplain #buffer buffer}\n+     * @throws IOException           If some I/O error occurs\n+     * @throws IllegalStateException If the provided number of bytes is greater thatn the buffer's capacity\n+     */\n+    public void ensureRemaining(int minRemaining) throws IOException {\n+        ensureRemaining(minRemaining, capacity);\n+    }\n+\n+    public void ensureRemaining(int minRemaining, int maxRead) throws IOException {\n+        if (wholeFileInBuffer) {\n+            return;\n+        }\n+        if (minRemaining > capacity) {\n+            throw new IllegalStateException(String.format(\"Length (%d) greater than buffer capacity (%d)\", minRemaining, capacity));\n+        }\n+        if (buffer.remaining() < minRemaining) {\n+            read(position(), maxRead);\n+        }\n+    }\n+\n+    /**\n+     * Gets a byte from the current {@linkplain #position() position} of this file.\n+     * If the {@linkplain #buffer buffer} does not fully contain this byte, loads another slice of the file into the buffer.\n+     *\n+     * @return The byte at the file's current position\n+     * @throws IOException If some I/O error occurs\n+     */\n+    public short get() throws IOException {\n+        ensureRemaining(SIZE_OF_BYTE);\n+        return buffer.get();\n+    }\n+\n+    /**\n+     * Gets a short from the current {@linkplain #position() position} of this file.\n+     * If the {@linkplain #buffer buffer} does not fully contain this short, loads another slice of the file into the buffer.\n+     *\n+     * @return The short at the file's current position\n+     * @throws IOException If some I/O error occurs\n+     */\n+    public short getShort() throws IOException {\n+        ensureRemaining(SIZE_OF_SHORT);\n+        return buffer.getShort();\n+    }\n+\n+    /**\n+     * Gets a short from the current {@linkplain #position() position} of this file.\n+     * If the {@linkplain #buffer buffer} does not fully contain this short, loads another slice of the file into the buffer.\n+     *\n+     * @return The short at the file's current position\n+     * @throws IOException If some I/O error occurs\n+     */\n+    public int getUnsignedShort() throws IOException {\n+        return getShort() & 0xff;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "96c0f80211cc5d30e9db759845f07c30b7095c0c"}, "originalPosition": 162}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 370, "cost": 1, "resetAt": "2021-11-12T18:49:56Z"}}}