{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDAyODg3MDIw", "number": 1135, "reviewThreads": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwNzoyNjozMlrODxg8Mw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQxNDoxOTozNVrODyGBHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzMjQ2NTE1OnYy", "diffSide": "RIGHT", "path": "docs/method-monitoring.asciidoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwNzoyNjozMlrOGFBhmA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwNzoyNjozMlrOGFBhmA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzkyMTA0OA==", "bodyText": "Could be misunderstood that people have to install async-profiler, which is not the case. The agent ships with async-profiler and configures it automatically.", "url": "https://github.com/elastic/apm-agent-java/pull/1135#discussion_r407921048", "createdAt": "2020-04-14T07:26:32Z", "author": {"login": "felixbarny"}, "path": "docs/method-monitoring.asciidoc", "diffHunk": "@@ -0,0 +1,282 @@\n+[[java-method-monitoring]]\n+== How to find slow methods\n+\n+Identifying a problematic service is only half of the battle when diagnosing application slowdowns.\n+Luckily, the Elastic APM Java Agent provides multiple ways to get method-level insights into your code.\n+This can help you diagnose slow requests due to heavy computations, inefficient algorithms,\n+or similar problems not related to interactions between services.\n+\n+[float]\n+==== _If you don't know which methods you want to monitor..._\n+\n+[float]\n+===== Sampling-based profiler\n+\n+Find out which part of your code is making your application slow;\n+periodically record running methods with a sampling-based profiler.\n+\n+image:./images/green-check.svg[] Very low overhead. +\n+image:./images/green-check.svg[] No code changes required. +\n+image:./images/red-x.svg[] Does not work on Windows. +\n+image:./images/red-x.svg[] The duration of profiler-inferred spans are not exact measurements, only estimates.\n+\n+<<method-sampling-based,Learn more>>\n+\n+[float]\n+==== _If you know which methods you want to monitor..._\n+\n+[float]\n+===== API/Code\n+\n+Use the API or OpenTracing bridge to manually create spans for methods of interest.\n+\n+image:./images/green-check.svg[] Most flexible. +\n+image:./images/red-x.svg[] Incorrect API usage may lead to invalid traces (scope leaks).\n+\n+<<method-api,Learn more>>\n+\n+[float]\n+===== Annotations\n+\n+Annotations can be placed on top of methods to automatically create spans for them.\n+\n+image:./images/green-check.svg[]Easier and more robust than the API. +\n+image:./images/red-x.svg[]Less flexible on its own, but can be combined with the API\n+\n+<<method-annotations,Learn more>>\n+\n+[float]\n+===== Configuration-based\n+\n+Use a configuration option to specify additional methods to instrument.\n+\n+image:./images/green-check.svg[]  No need to modify source code. +\n+image:./images/green-check.svg[] Possible to monitor code in third-party libraries +\n+image:./images/green-check.svg[] Match methods via wildcards +\n+image:./images/red-x.svg[] Easy to overuse which hurts runtime and startup performance.\n+\n+<<method-config-based,Learn more>>\n+\n+//********************************************\n+[[method-sampling-based]]\n+=== Sampling-based profiler\n+\n+experimental::[]\n+added::[1.14.0]\n+\n+Instead of recording every event, leverage https://github.com/jvm-profiling-tools/async-profiler[async-profiler]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6134df2505237285b6b805583632a0fb85b7290c"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzMjU0NDU0OnYy", "diffSide": "RIGHT", "path": "docs/method-monitoring.asciidoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwNzo0ODoxNFrOGFCQ7g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwNzo0ODoxNFrOGFCQ7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzkzMzE2Ng==", "bodyText": "A value lower than the sampling interval wouldn't have an effect as there can't be inferred spans that are faster than the sampling interval.\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            profiling_inferred_spans_min_duration=25ms\n          \n          \n            \n            profiling_inferred_spans_min_duration=250ms", "url": "https://github.com/elastic/apm-agent-java/pull/1135#discussion_r407933166", "createdAt": "2020-04-14T07:48:14Z", "author": {"login": "felixbarny"}, "path": "docs/method-monitoring.asciidoc", "diffHunk": "@@ -0,0 +1,282 @@\n+[[java-method-monitoring]]\n+== How to find slow methods\n+\n+Identifying a problematic service is only half of the battle when diagnosing application slowdowns.\n+Luckily, the Elastic APM Java Agent provides multiple ways to get method-level insights into your code.\n+This can help you diagnose slow requests due to heavy computations, inefficient algorithms,\n+or similar problems not related to interactions between services.\n+\n+[float]\n+==== _If you don't know which methods you want to monitor..._\n+\n+[float]\n+===== Sampling-based profiler\n+\n+Find out which part of your code is making your application slow;\n+periodically record running methods with a sampling-based profiler.\n+\n+image:./images/green-check.svg[] Very low overhead. +\n+image:./images/green-check.svg[] No code changes required. +\n+image:./images/red-x.svg[] Does not work on Windows. +\n+image:./images/red-x.svg[] The duration of profiler-inferred spans are not exact measurements, only estimates.\n+\n+<<method-sampling-based,Learn more>>\n+\n+[float]\n+==== _If you know which methods you want to monitor..._\n+\n+[float]\n+===== API/Code\n+\n+Use the API or OpenTracing bridge to manually create spans for methods of interest.\n+\n+image:./images/green-check.svg[] Most flexible. +\n+image:./images/red-x.svg[] Incorrect API usage may lead to invalid traces (scope leaks).\n+\n+<<method-api,Learn more>>\n+\n+[float]\n+===== Annotations\n+\n+Annotations can be placed on top of methods to automatically create spans for them.\n+\n+image:./images/green-check.svg[]Easier and more robust than the API. +\n+image:./images/red-x.svg[]Less flexible on its own, but can be combined with the API\n+\n+<<method-annotations,Learn more>>\n+\n+[float]\n+===== Configuration-based\n+\n+Use a configuration option to specify additional methods to instrument.\n+\n+image:./images/green-check.svg[]  No need to modify source code. +\n+image:./images/green-check.svg[] Possible to monitor code in third-party libraries +\n+image:./images/green-check.svg[] Match methods via wildcards +\n+image:./images/red-x.svg[] Easy to overuse which hurts runtime and startup performance.\n+\n+<<method-config-based,Learn more>>\n+\n+//********************************************\n+[[method-sampling-based]]\n+=== Sampling-based profiler\n+\n+experimental::[]\n+added::[1.14.0]\n+\n+Instead of recording every event, leverage https://github.com/jvm-profiling-tools/async-profiler[async-profiler]\n+to periodically request the stack trace from all actively running threads.\n+This means measurements do not need to be inserted into all methods, which keeps the overhead of this approach extremely low.\n+Stack traces are then correlated with span activation events, and profiler-inferred spans for slow methods are created.\n+Just like that, we've detected exactly what is executing between current transactions and spans.\n+\n+// Show simple example from Blog?\n+// BEFORE:: WelcomeController#welcome\n+// AFTER:: WelcomeController#think\n+// https://www.elastic.co/blog/from-distributed-tracing-to-distributed-profiling-with-elastic-apm\n+\n+[float]\n+==== Use cases\n+\n+* **Development**:\n+When trying to find out why the request you just made was slow.\n+* **Load testing / Production**:\n+When analyzing why some requests are slower than others.\n+* **Customer support**:\n+When a user complains that a particular request they made at noon was slow,\n+especially if you can't reproduce that slowness in your development or staging environment.\n+\n+[float]\n+==== Advantages\n+\n+* **No need to know what methods to monitor**:\n+Find slow methods without specifying specific method names up front.\n+The profiler automatically bubbles up slow methods as spans in the APM app.\n+* **Low overhead. Production ready**:\n+The profiler-based approach is designed to be low-overhead enough to run in production;\n+Continuously run it to provide insights into slow methods.\n+\n+[float]\n+==== How to enable inferred spans with async-profiler\n+\n+Enable inferred spans by setting <<config-profiling-inferred-spans-enabled,`profiling_inferred_spans_enabled`>> to `true`.\n+\n+**Tune stack trace frequency**\n+\n+Tune the frequency at which stack traces are gathered within a profiling session by adjusting\n+<<config-profiling-inferred-spans-sampling-interval,`profiling_inferred_spans_sampling_interval`>>.\n+The lower the sampling interval, the higher the accuracy and the level of detail of the inferred spans.\n+Of course, the higher the level of detail, the higher the profiler overhead and the Elasticsearch index sizes.\n+As most of the processing is done in the background, the impact on the response time of user requests is negligible.\n+\n+**Clean up clutter in the APM app**\n+\n+Filter out inferred spans that are faster than the configured threshold,\n+and avoid cluttering the APM app with fast-executing methods by setting\n+<<config-profiling-inferred-spans-min-duration,`profiling_inferred_spans_min_duration`>>.\n+\n+**Include and exclude specific classes**\n+\n+Include and exclude specific classes explicitly with\n+<<config-profiling-inferred-spans-included-classes,`profiling_inferred_spans_included_classes`>> and\n+<<config-profiling-inferred-spans-excluded-classes,`profiling_inferred_spans_excluded_classes`>>.\n+Generally, the fewer classes that are included, the faster and the more memory efficient the processing is.\n+\n+By default, the classes from the JDK and from most application servers are excluded. This reduces the number of uninteresting inferred spans.\n+\n+**Example `elasticapm.properties` file with inferred spans enabled**\n+\n+[source,properties]\n+----\n+profiling_inferred_spans_enabled=true\n+profiling_inferred_spans_sampling_interval=50ms\n+profiling_inferred_spans_min_duration=25ms", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6134df2505237285b6b805583632a0fb85b7290c"}, "originalPosition": 133}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzMjU2MjI0OnYy", "diffSide": "RIGHT", "path": "docs/method-monitoring.asciidoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwNzo1MzowOVrOGFCbtQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwNzo1MzowOVrOGFCbtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzkzNTkyNQ==", "bodyText": "If included classes are set, you can only exclude classes within that set of classes. Other classes like java.* are excluded implicitly.\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            profiling_inferred_spans_excluded_classes=(?-i)java.*\n          \n          \n            \n            profiling_inferred_spans_excluded_classes=org.example.myapp.ignoreme.*", "url": "https://github.com/elastic/apm-agent-java/pull/1135#discussion_r407935925", "createdAt": "2020-04-14T07:53:09Z", "author": {"login": "felixbarny"}, "path": "docs/method-monitoring.asciidoc", "diffHunk": "@@ -0,0 +1,282 @@\n+[[java-method-monitoring]]\n+== How to find slow methods\n+\n+Identifying a problematic service is only half of the battle when diagnosing application slowdowns.\n+Luckily, the Elastic APM Java Agent provides multiple ways to get method-level insights into your code.\n+This can help you diagnose slow requests due to heavy computations, inefficient algorithms,\n+or similar problems not related to interactions between services.\n+\n+[float]\n+==== _If you don't know which methods you want to monitor..._\n+\n+[float]\n+===== Sampling-based profiler\n+\n+Find out which part of your code is making your application slow;\n+periodically record running methods with a sampling-based profiler.\n+\n+image:./images/green-check.svg[] Very low overhead. +\n+image:./images/green-check.svg[] No code changes required. +\n+image:./images/red-x.svg[] Does not work on Windows. +\n+image:./images/red-x.svg[] The duration of profiler-inferred spans are not exact measurements, only estimates.\n+\n+<<method-sampling-based,Learn more>>\n+\n+[float]\n+==== _If you know which methods you want to monitor..._\n+\n+[float]\n+===== API/Code\n+\n+Use the API or OpenTracing bridge to manually create spans for methods of interest.\n+\n+image:./images/green-check.svg[] Most flexible. +\n+image:./images/red-x.svg[] Incorrect API usage may lead to invalid traces (scope leaks).\n+\n+<<method-api,Learn more>>\n+\n+[float]\n+===== Annotations\n+\n+Annotations can be placed on top of methods to automatically create spans for them.\n+\n+image:./images/green-check.svg[]Easier and more robust than the API. +\n+image:./images/red-x.svg[]Less flexible on its own, but can be combined with the API\n+\n+<<method-annotations,Learn more>>\n+\n+[float]\n+===== Configuration-based\n+\n+Use a configuration option to specify additional methods to instrument.\n+\n+image:./images/green-check.svg[]  No need to modify source code. +\n+image:./images/green-check.svg[] Possible to monitor code in third-party libraries +\n+image:./images/green-check.svg[] Match methods via wildcards +\n+image:./images/red-x.svg[] Easy to overuse which hurts runtime and startup performance.\n+\n+<<method-config-based,Learn more>>\n+\n+//********************************************\n+[[method-sampling-based]]\n+=== Sampling-based profiler\n+\n+experimental::[]\n+added::[1.14.0]\n+\n+Instead of recording every event, leverage https://github.com/jvm-profiling-tools/async-profiler[async-profiler]\n+to periodically request the stack trace from all actively running threads.\n+This means measurements do not need to be inserted into all methods, which keeps the overhead of this approach extremely low.\n+Stack traces are then correlated with span activation events, and profiler-inferred spans for slow methods are created.\n+Just like that, we've detected exactly what is executing between current transactions and spans.\n+\n+// Show simple example from Blog?\n+// BEFORE:: WelcomeController#welcome\n+// AFTER:: WelcomeController#think\n+// https://www.elastic.co/blog/from-distributed-tracing-to-distributed-profiling-with-elastic-apm\n+\n+[float]\n+==== Use cases\n+\n+* **Development**:\n+When trying to find out why the request you just made was slow.\n+* **Load testing / Production**:\n+When analyzing why some requests are slower than others.\n+* **Customer support**:\n+When a user complains that a particular request they made at noon was slow,\n+especially if you can't reproduce that slowness in your development or staging environment.\n+\n+[float]\n+==== Advantages\n+\n+* **No need to know what methods to monitor**:\n+Find slow methods without specifying specific method names up front.\n+The profiler automatically bubbles up slow methods as spans in the APM app.\n+* **Low overhead. Production ready**:\n+The profiler-based approach is designed to be low-overhead enough to run in production;\n+Continuously run it to provide insights into slow methods.\n+\n+[float]\n+==== How to enable inferred spans with async-profiler\n+\n+Enable inferred spans by setting <<config-profiling-inferred-spans-enabled,`profiling_inferred_spans_enabled`>> to `true`.\n+\n+**Tune stack trace frequency**\n+\n+Tune the frequency at which stack traces are gathered within a profiling session by adjusting\n+<<config-profiling-inferred-spans-sampling-interval,`profiling_inferred_spans_sampling_interval`>>.\n+The lower the sampling interval, the higher the accuracy and the level of detail of the inferred spans.\n+Of course, the higher the level of detail, the higher the profiler overhead and the Elasticsearch index sizes.\n+As most of the processing is done in the background, the impact on the response time of user requests is negligible.\n+\n+**Clean up clutter in the APM app**\n+\n+Filter out inferred spans that are faster than the configured threshold,\n+and avoid cluttering the APM app with fast-executing methods by setting\n+<<config-profiling-inferred-spans-min-duration,`profiling_inferred_spans_min_duration`>>.\n+\n+**Include and exclude specific classes**\n+\n+Include and exclude specific classes explicitly with\n+<<config-profiling-inferred-spans-included-classes,`profiling_inferred_spans_included_classes`>> and\n+<<config-profiling-inferred-spans-excluded-classes,`profiling_inferred_spans_excluded_classes`>>.\n+Generally, the fewer classes that are included, the faster and the more memory efficient the processing is.\n+\n+By default, the classes from the JDK and from most application servers are excluded. This reduces the number of uninteresting inferred spans.\n+\n+**Example `elasticapm.properties` file with inferred spans enabled**\n+\n+[source,properties]\n+----\n+profiling_inferred_spans_enabled=true\n+profiling_inferred_spans_sampling_interval=50ms\n+profiling_inferred_spans_min_duration=25ms\n+profiling_inferred_spans_included_classes=org.example.myapp.*\n+profiling_inferred_spans_excluded_classes=(?-i)java.*", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6134df2505237285b6b805583632a0fb85b7290c"}, "originalPosition": 135}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzMjY2NjA1OnYy", "diffSide": "RIGHT", "path": "docs/method-monitoring.asciidoc", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwODoyMDowNlrOGFDbVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxOTo0MTozMFrOGFeFvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk1MjIxMw==", "bodyText": "Activating the span is important. See also #1127", "url": "https://github.com/elastic/apm-agent-java/pull/1135#discussion_r407952213", "createdAt": "2020-04-14T08:20:06Z", "author": {"login": "felixbarny"}, "path": "docs/method-monitoring.asciidoc", "diffHunk": "@@ -0,0 +1,282 @@\n+[[java-method-monitoring]]\n+== How to find slow methods\n+\n+Identifying a problematic service is only half of the battle when diagnosing application slowdowns.\n+Luckily, the Elastic APM Java Agent provides multiple ways to get method-level insights into your code.\n+This can help you diagnose slow requests due to heavy computations, inefficient algorithms,\n+or similar problems not related to interactions between services.\n+\n+[float]\n+==== _If you don't know which methods you want to monitor..._\n+\n+[float]\n+===== Sampling-based profiler\n+\n+Find out which part of your code is making your application slow;\n+periodically record running methods with a sampling-based profiler.\n+\n+image:./images/green-check.svg[] Very low overhead. +\n+image:./images/green-check.svg[] No code changes required. +\n+image:./images/red-x.svg[] Does not work on Windows. +\n+image:./images/red-x.svg[] The duration of profiler-inferred spans are not exact measurements, only estimates.\n+\n+<<method-sampling-based,Learn more>>\n+\n+[float]\n+==== _If you know which methods you want to monitor..._\n+\n+[float]\n+===== API/Code\n+\n+Use the API or OpenTracing bridge to manually create spans for methods of interest.\n+\n+image:./images/green-check.svg[] Most flexible. +\n+image:./images/red-x.svg[] Incorrect API usage may lead to invalid traces (scope leaks).\n+\n+<<method-api,Learn more>>\n+\n+[float]\n+===== Annotations\n+\n+Annotations can be placed on top of methods to automatically create spans for them.\n+\n+image:./images/green-check.svg[]Easier and more robust than the API. +\n+image:./images/red-x.svg[]Less flexible on its own, but can be combined with the API\n+\n+<<method-annotations,Learn more>>\n+\n+[float]\n+===== Configuration-based\n+\n+Use a configuration option to specify additional methods to instrument.\n+\n+image:./images/green-check.svg[]  No need to modify source code. +\n+image:./images/green-check.svg[] Possible to monitor code in third-party libraries +\n+image:./images/green-check.svg[] Match methods via wildcards +\n+image:./images/red-x.svg[] Easy to overuse which hurts runtime and startup performance.\n+\n+<<method-config-based,Learn more>>\n+\n+//********************************************\n+[[method-sampling-based]]\n+=== Sampling-based profiler\n+\n+experimental::[]\n+added::[1.14.0]\n+\n+Instead of recording every event, leverage https://github.com/jvm-profiling-tools/async-profiler[async-profiler]\n+to periodically request the stack trace from all actively running threads.\n+This means measurements do not need to be inserted into all methods, which keeps the overhead of this approach extremely low.\n+Stack traces are then correlated with span activation events, and profiler-inferred spans for slow methods are created.\n+Just like that, we've detected exactly what is executing between current transactions and spans.\n+\n+// Show simple example from Blog?\n+// BEFORE:: WelcomeController#welcome\n+// AFTER:: WelcomeController#think\n+// https://www.elastic.co/blog/from-distributed-tracing-to-distributed-profiling-with-elastic-apm\n+\n+[float]\n+==== Use cases\n+\n+* **Development**:\n+When trying to find out why the request you just made was slow.\n+* **Load testing / Production**:\n+When analyzing why some requests are slower than others.\n+* **Customer support**:\n+When a user complains that a particular request they made at noon was slow,\n+especially if you can't reproduce that slowness in your development or staging environment.\n+\n+[float]\n+==== Advantages\n+\n+* **No need to know what methods to monitor**:\n+Find slow methods without specifying specific method names up front.\n+The profiler automatically bubbles up slow methods as spans in the APM app.\n+* **Low overhead. Production ready**:\n+The profiler-based approach is designed to be low-overhead enough to run in production;\n+Continuously run it to provide insights into slow methods.\n+\n+[float]\n+==== How to enable inferred spans with async-profiler\n+\n+Enable inferred spans by setting <<config-profiling-inferred-spans-enabled,`profiling_inferred_spans_enabled`>> to `true`.\n+\n+**Tune stack trace frequency**\n+\n+Tune the frequency at which stack traces are gathered within a profiling session by adjusting\n+<<config-profiling-inferred-spans-sampling-interval,`profiling_inferred_spans_sampling_interval`>>.\n+The lower the sampling interval, the higher the accuracy and the level of detail of the inferred spans.\n+Of course, the higher the level of detail, the higher the profiler overhead and the Elasticsearch index sizes.\n+As most of the processing is done in the background, the impact on the response time of user requests is negligible.\n+\n+**Clean up clutter in the APM app**\n+\n+Filter out inferred spans that are faster than the configured threshold,\n+and avoid cluttering the APM app with fast-executing methods by setting\n+<<config-profiling-inferred-spans-min-duration,`profiling_inferred_spans_min_duration`>>.\n+\n+**Include and exclude specific classes**\n+\n+Include and exclude specific classes explicitly with\n+<<config-profiling-inferred-spans-included-classes,`profiling_inferred_spans_included_classes`>> and\n+<<config-profiling-inferred-spans-excluded-classes,`profiling_inferred_spans_excluded_classes`>>.\n+Generally, the fewer classes that are included, the faster and the more memory efficient the processing is.\n+\n+By default, the classes from the JDK and from most application servers are excluded. This reduces the number of uninteresting inferred spans.\n+\n+**Example `elasticapm.properties` file with inferred spans enabled**\n+\n+[source,properties]\n+----\n+profiling_inferred_spans_enabled=true\n+profiling_inferred_spans_sampling_interval=50ms\n+profiling_inferred_spans_min_duration=25ms\n+profiling_inferred_spans_included_classes=org.example.myapp.*\n+profiling_inferred_spans_excluded_classes=(?-i)java.*\n+----\n+\n+[float]\n+==== Caveats\n+\n+Inferred spans are estimations, not exact measurements.\n+They may start after the method actually started, and end before the method actually ended.\n+This can lead to inconsistencies, all of which are documented in the\n+https://github.com/elastic/apm-agent-java/tree/master/apm-agent-plugins/apm-profiling-plugin[apm-profiling-plugin readme].\n+\n+// Inferred spans are created after the profiling session ends and therefor may appear later in the APM app's span timeline than regular spans.\n+// Because of this, a regular span cannot be the child of an inferred span.\n+\n+//********************************************\n+[[method-api]]\n+=== API/Code\n+\n+Use the <<api-span,span API>> to manually create spans for methods of interest.\n+The API is extremely flexible, and offers the ability to customize your spans,\n+by adding labels to them, or by changing the type, name, or timestamp.\n+\n+TIP: OpenTracing fan? You can use the <<opentracing-bridge,OpenTracing API>>, instead of the Agent API,\n+to manually create spans.\n+\n+[float]\n+==== How to create spans with the span API\n+\n+. Get the current span with <<api-current-span,`currentSpan()`>>,\n+which may or may not have been created with auto-instrumentation.\n+. Create a child span with <<api-span-start-span,`startSpan()`>>.\n+. Customize the span with the <<api-span,span API>>.\n+\n+[source,java]\n+----\n+import co.elastic.apm.api.ElasticApm;\n+import co.elastic.apm.api.Span;\n+\n+Span parent = ElasticApm.currentSpan(); <1>\n+Span span = parent.startSpan(); <2>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6134df2505237285b6b805583632a0fb85b7290c"}, "originalPosition": 174}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODM4OTA1Mw==", "bodyText": "Good to know. I added a callout to the code example to point this out.", "url": "https://github.com/elastic/apm-agent-java/pull/1135#discussion_r408389053", "createdAt": "2020-04-14T19:41:30Z", "author": {"login": "bmorelli25"}, "path": "docs/method-monitoring.asciidoc", "diffHunk": "@@ -0,0 +1,282 @@\n+[[java-method-monitoring]]\n+== How to find slow methods\n+\n+Identifying a problematic service is only half of the battle when diagnosing application slowdowns.\n+Luckily, the Elastic APM Java Agent provides multiple ways to get method-level insights into your code.\n+This can help you diagnose slow requests due to heavy computations, inefficient algorithms,\n+or similar problems not related to interactions between services.\n+\n+[float]\n+==== _If you don't know which methods you want to monitor..._\n+\n+[float]\n+===== Sampling-based profiler\n+\n+Find out which part of your code is making your application slow;\n+periodically record running methods with a sampling-based profiler.\n+\n+image:./images/green-check.svg[] Very low overhead. +\n+image:./images/green-check.svg[] No code changes required. +\n+image:./images/red-x.svg[] Does not work on Windows. +\n+image:./images/red-x.svg[] The duration of profiler-inferred spans are not exact measurements, only estimates.\n+\n+<<method-sampling-based,Learn more>>\n+\n+[float]\n+==== _If you know which methods you want to monitor..._\n+\n+[float]\n+===== API/Code\n+\n+Use the API or OpenTracing bridge to manually create spans for methods of interest.\n+\n+image:./images/green-check.svg[] Most flexible. +\n+image:./images/red-x.svg[] Incorrect API usage may lead to invalid traces (scope leaks).\n+\n+<<method-api,Learn more>>\n+\n+[float]\n+===== Annotations\n+\n+Annotations can be placed on top of methods to automatically create spans for them.\n+\n+image:./images/green-check.svg[]Easier and more robust than the API. +\n+image:./images/red-x.svg[]Less flexible on its own, but can be combined with the API\n+\n+<<method-annotations,Learn more>>\n+\n+[float]\n+===== Configuration-based\n+\n+Use a configuration option to specify additional methods to instrument.\n+\n+image:./images/green-check.svg[]  No need to modify source code. +\n+image:./images/green-check.svg[] Possible to monitor code in third-party libraries +\n+image:./images/green-check.svg[] Match methods via wildcards +\n+image:./images/red-x.svg[] Easy to overuse which hurts runtime and startup performance.\n+\n+<<method-config-based,Learn more>>\n+\n+//********************************************\n+[[method-sampling-based]]\n+=== Sampling-based profiler\n+\n+experimental::[]\n+added::[1.14.0]\n+\n+Instead of recording every event, leverage https://github.com/jvm-profiling-tools/async-profiler[async-profiler]\n+to periodically request the stack trace from all actively running threads.\n+This means measurements do not need to be inserted into all methods, which keeps the overhead of this approach extremely low.\n+Stack traces are then correlated with span activation events, and profiler-inferred spans for slow methods are created.\n+Just like that, we've detected exactly what is executing between current transactions and spans.\n+\n+// Show simple example from Blog?\n+// BEFORE:: WelcomeController#welcome\n+// AFTER:: WelcomeController#think\n+// https://www.elastic.co/blog/from-distributed-tracing-to-distributed-profiling-with-elastic-apm\n+\n+[float]\n+==== Use cases\n+\n+* **Development**:\n+When trying to find out why the request you just made was slow.\n+* **Load testing / Production**:\n+When analyzing why some requests are slower than others.\n+* **Customer support**:\n+When a user complains that a particular request they made at noon was slow,\n+especially if you can't reproduce that slowness in your development or staging environment.\n+\n+[float]\n+==== Advantages\n+\n+* **No need to know what methods to monitor**:\n+Find slow methods without specifying specific method names up front.\n+The profiler automatically bubbles up slow methods as spans in the APM app.\n+* **Low overhead. Production ready**:\n+The profiler-based approach is designed to be low-overhead enough to run in production;\n+Continuously run it to provide insights into slow methods.\n+\n+[float]\n+==== How to enable inferred spans with async-profiler\n+\n+Enable inferred spans by setting <<config-profiling-inferred-spans-enabled,`profiling_inferred_spans_enabled`>> to `true`.\n+\n+**Tune stack trace frequency**\n+\n+Tune the frequency at which stack traces are gathered within a profiling session by adjusting\n+<<config-profiling-inferred-spans-sampling-interval,`profiling_inferred_spans_sampling_interval`>>.\n+The lower the sampling interval, the higher the accuracy and the level of detail of the inferred spans.\n+Of course, the higher the level of detail, the higher the profiler overhead and the Elasticsearch index sizes.\n+As most of the processing is done in the background, the impact on the response time of user requests is negligible.\n+\n+**Clean up clutter in the APM app**\n+\n+Filter out inferred spans that are faster than the configured threshold,\n+and avoid cluttering the APM app with fast-executing methods by setting\n+<<config-profiling-inferred-spans-min-duration,`profiling_inferred_spans_min_duration`>>.\n+\n+**Include and exclude specific classes**\n+\n+Include and exclude specific classes explicitly with\n+<<config-profiling-inferred-spans-included-classes,`profiling_inferred_spans_included_classes`>> and\n+<<config-profiling-inferred-spans-excluded-classes,`profiling_inferred_spans_excluded_classes`>>.\n+Generally, the fewer classes that are included, the faster and the more memory efficient the processing is.\n+\n+By default, the classes from the JDK and from most application servers are excluded. This reduces the number of uninteresting inferred spans.\n+\n+**Example `elasticapm.properties` file with inferred spans enabled**\n+\n+[source,properties]\n+----\n+profiling_inferred_spans_enabled=true\n+profiling_inferred_spans_sampling_interval=50ms\n+profiling_inferred_spans_min_duration=25ms\n+profiling_inferred_spans_included_classes=org.example.myapp.*\n+profiling_inferred_spans_excluded_classes=(?-i)java.*\n+----\n+\n+[float]\n+==== Caveats\n+\n+Inferred spans are estimations, not exact measurements.\n+They may start after the method actually started, and end before the method actually ended.\n+This can lead to inconsistencies, all of which are documented in the\n+https://github.com/elastic/apm-agent-java/tree/master/apm-agent-plugins/apm-profiling-plugin[apm-profiling-plugin readme].\n+\n+// Inferred spans are created after the profiling session ends and therefor may appear later in the APM app's span timeline than regular spans.\n+// Because of this, a regular span cannot be the child of an inferred span.\n+\n+//********************************************\n+[[method-api]]\n+=== API/Code\n+\n+Use the <<api-span,span API>> to manually create spans for methods of interest.\n+The API is extremely flexible, and offers the ability to customize your spans,\n+by adding labels to them, or by changing the type, name, or timestamp.\n+\n+TIP: OpenTracing fan? You can use the <<opentracing-bridge,OpenTracing API>>, instead of the Agent API,\n+to manually create spans.\n+\n+[float]\n+==== How to create spans with the span API\n+\n+. Get the current span with <<api-current-span,`currentSpan()`>>,\n+which may or may not have been created with auto-instrumentation.\n+. Create a child span with <<api-span-start-span,`startSpan()`>>.\n+. Customize the span with the <<api-span,span API>>.\n+\n+[source,java]\n+----\n+import co.elastic.apm.api.ElasticApm;\n+import co.elastic.apm.api.Span;\n+\n+Span parent = ElasticApm.currentSpan(); <1>\n+Span span = parent.startSpan(); <2>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk1MjIxMw=="}, "originalCommit": {"oid": "6134df2505237285b6b805583632a0fb85b7290c"}, "originalPosition": 174}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzMjcyODU4OnYy", "diffSide": "RIGHT", "path": "docs/method-monitoring.asciidoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwODozNjoxOFrOGFEBdQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwODozNjoxOFrOGFEBdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk2MTk3Mw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            try {\n          \n          \n            \n            try (Scope scope = span.activate()) {", "url": "https://github.com/elastic/apm-agent-java/pull/1135#discussion_r407961973", "createdAt": "2020-04-14T08:36:18Z", "author": {"login": "felixbarny"}, "path": "docs/method-monitoring.asciidoc", "diffHunk": "@@ -0,0 +1,282 @@\n+[[java-method-monitoring]]\n+== How to find slow methods\n+\n+Identifying a problematic service is only half of the battle when diagnosing application slowdowns.\n+Luckily, the Elastic APM Java Agent provides multiple ways to get method-level insights into your code.\n+This can help you diagnose slow requests due to heavy computations, inefficient algorithms,\n+or similar problems not related to interactions between services.\n+\n+[float]\n+==== _If you don't know which methods you want to monitor..._\n+\n+[float]\n+===== Sampling-based profiler\n+\n+Find out which part of your code is making your application slow;\n+periodically record running methods with a sampling-based profiler.\n+\n+image:./images/green-check.svg[] Very low overhead. +\n+image:./images/green-check.svg[] No code changes required. +\n+image:./images/red-x.svg[] Does not work on Windows. +\n+image:./images/red-x.svg[] The duration of profiler-inferred spans are not exact measurements, only estimates.\n+\n+<<method-sampling-based,Learn more>>\n+\n+[float]\n+==== _If you know which methods you want to monitor..._\n+\n+[float]\n+===== API/Code\n+\n+Use the API or OpenTracing bridge to manually create spans for methods of interest.\n+\n+image:./images/green-check.svg[] Most flexible. +\n+image:./images/red-x.svg[] Incorrect API usage may lead to invalid traces (scope leaks).\n+\n+<<method-api,Learn more>>\n+\n+[float]\n+===== Annotations\n+\n+Annotations can be placed on top of methods to automatically create spans for them.\n+\n+image:./images/green-check.svg[]Easier and more robust than the API. +\n+image:./images/red-x.svg[]Less flexible on its own, but can be combined with the API\n+\n+<<method-annotations,Learn more>>\n+\n+[float]\n+===== Configuration-based\n+\n+Use a configuration option to specify additional methods to instrument.\n+\n+image:./images/green-check.svg[]  No need to modify source code. +\n+image:./images/green-check.svg[] Possible to monitor code in third-party libraries +\n+image:./images/green-check.svg[] Match methods via wildcards +\n+image:./images/red-x.svg[] Easy to overuse which hurts runtime and startup performance.\n+\n+<<method-config-based,Learn more>>\n+\n+//********************************************\n+[[method-sampling-based]]\n+=== Sampling-based profiler\n+\n+experimental::[]\n+added::[1.14.0]\n+\n+Instead of recording every event, leverage https://github.com/jvm-profiling-tools/async-profiler[async-profiler]\n+to periodically request the stack trace from all actively running threads.\n+This means measurements do not need to be inserted into all methods, which keeps the overhead of this approach extremely low.\n+Stack traces are then correlated with span activation events, and profiler-inferred spans for slow methods are created.\n+Just like that, we've detected exactly what is executing between current transactions and spans.\n+\n+// Show simple example from Blog?\n+// BEFORE:: WelcomeController#welcome\n+// AFTER:: WelcomeController#think\n+// https://www.elastic.co/blog/from-distributed-tracing-to-distributed-profiling-with-elastic-apm\n+\n+[float]\n+==== Use cases\n+\n+* **Development**:\n+When trying to find out why the request you just made was slow.\n+* **Load testing / Production**:\n+When analyzing why some requests are slower than others.\n+* **Customer support**:\n+When a user complains that a particular request they made at noon was slow,\n+especially if you can't reproduce that slowness in your development or staging environment.\n+\n+[float]\n+==== Advantages\n+\n+* **No need to know what methods to monitor**:\n+Find slow methods without specifying specific method names up front.\n+The profiler automatically bubbles up slow methods as spans in the APM app.\n+* **Low overhead. Production ready**:\n+The profiler-based approach is designed to be low-overhead enough to run in production;\n+Continuously run it to provide insights into slow methods.\n+\n+[float]\n+==== How to enable inferred spans with async-profiler\n+\n+Enable inferred spans by setting <<config-profiling-inferred-spans-enabled,`profiling_inferred_spans_enabled`>> to `true`.\n+\n+**Tune stack trace frequency**\n+\n+Tune the frequency at which stack traces are gathered within a profiling session by adjusting\n+<<config-profiling-inferred-spans-sampling-interval,`profiling_inferred_spans_sampling_interval`>>.\n+The lower the sampling interval, the higher the accuracy and the level of detail of the inferred spans.\n+Of course, the higher the level of detail, the higher the profiler overhead and the Elasticsearch index sizes.\n+As most of the processing is done in the background, the impact on the response time of user requests is negligible.\n+\n+**Clean up clutter in the APM app**\n+\n+Filter out inferred spans that are faster than the configured threshold,\n+and avoid cluttering the APM app with fast-executing methods by setting\n+<<config-profiling-inferred-spans-min-duration,`profiling_inferred_spans_min_duration`>>.\n+\n+**Include and exclude specific classes**\n+\n+Include and exclude specific classes explicitly with\n+<<config-profiling-inferred-spans-included-classes,`profiling_inferred_spans_included_classes`>> and\n+<<config-profiling-inferred-spans-excluded-classes,`profiling_inferred_spans_excluded_classes`>>.\n+Generally, the fewer classes that are included, the faster and the more memory efficient the processing is.\n+\n+By default, the classes from the JDK and from most application servers are excluded. This reduces the number of uninteresting inferred spans.\n+\n+**Example `elasticapm.properties` file with inferred spans enabled**\n+\n+[source,properties]\n+----\n+profiling_inferred_spans_enabled=true\n+profiling_inferred_spans_sampling_interval=50ms\n+profiling_inferred_spans_min_duration=25ms\n+profiling_inferred_spans_included_classes=org.example.myapp.*\n+profiling_inferred_spans_excluded_classes=(?-i)java.*\n+----\n+\n+[float]\n+==== Caveats\n+\n+Inferred spans are estimations, not exact measurements.\n+They may start after the method actually started, and end before the method actually ended.\n+This can lead to inconsistencies, all of which are documented in the\n+https://github.com/elastic/apm-agent-java/tree/master/apm-agent-plugins/apm-profiling-plugin[apm-profiling-plugin readme].\n+\n+// Inferred spans are created after the profiling session ends and therefor may appear later in the APM app's span timeline than regular spans.\n+// Because of this, a regular span cannot be the child of an inferred span.\n+\n+//********************************************\n+[[method-api]]\n+=== API/Code\n+\n+Use the <<api-span,span API>> to manually create spans for methods of interest.\n+The API is extremely flexible, and offers the ability to customize your spans,\n+by adding labels to them, or by changing the type, name, or timestamp.\n+\n+TIP: OpenTracing fan? You can use the <<opentracing-bridge,OpenTracing API>>, instead of the Agent API,\n+to manually create spans.\n+\n+[float]\n+==== How to create spans with the span API\n+\n+. Get the current span with <<api-current-span,`currentSpan()`>>,\n+which may or may not have been created with auto-instrumentation.\n+. Create a child span with <<api-span-start-span,`startSpan()`>>.\n+. Customize the span with the <<api-span,span API>>.\n+\n+[source,java]\n+----\n+import co.elastic.apm.api.ElasticApm;\n+import co.elastic.apm.api.Span;\n+\n+Span parent = ElasticApm.currentSpan(); <1>\n+Span span = parent.startSpan(); <2>\n+try {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6134df2505237285b6b805583632a0fb85b7290c"}, "originalPosition": 175}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzMjc3Nzk4OnYy", "diffSide": "RIGHT", "path": "docs/method-monitoring.asciidoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwODo0ODozNVrOGFEffQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwODo0ODozNVrOGFEffQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk2OTY2MQ==", "bodyText": "Let's keep this simple.\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            @CaptureSpan(value = \"spanName\", type = \"ext\", subtype = \"http\") <1>\n          \n          \n            \n            @CaptureSpan <1>", "url": "https://github.com/elastic/apm-agent-java/pull/1135#discussion_r407969661", "createdAt": "2020-04-14T08:48:35Z", "author": {"login": "felixbarny"}, "path": "docs/method-monitoring.asciidoc", "diffHunk": "@@ -0,0 +1,282 @@\n+[[java-method-monitoring]]\n+== How to find slow methods\n+\n+Identifying a problematic service is only half of the battle when diagnosing application slowdowns.\n+Luckily, the Elastic APM Java Agent provides multiple ways to get method-level insights into your code.\n+This can help you diagnose slow requests due to heavy computations, inefficient algorithms,\n+or similar problems not related to interactions between services.\n+\n+[float]\n+==== _If you don't know which methods you want to monitor..._\n+\n+[float]\n+===== Sampling-based profiler\n+\n+Find out which part of your code is making your application slow;\n+periodically record running methods with a sampling-based profiler.\n+\n+image:./images/green-check.svg[] Very low overhead. +\n+image:./images/green-check.svg[] No code changes required. +\n+image:./images/red-x.svg[] Does not work on Windows. +\n+image:./images/red-x.svg[] The duration of profiler-inferred spans are not exact measurements, only estimates.\n+\n+<<method-sampling-based,Learn more>>\n+\n+[float]\n+==== _If you know which methods you want to monitor..._\n+\n+[float]\n+===== API/Code\n+\n+Use the API or OpenTracing bridge to manually create spans for methods of interest.\n+\n+image:./images/green-check.svg[] Most flexible. +\n+image:./images/red-x.svg[] Incorrect API usage may lead to invalid traces (scope leaks).\n+\n+<<method-api,Learn more>>\n+\n+[float]\n+===== Annotations\n+\n+Annotations can be placed on top of methods to automatically create spans for them.\n+\n+image:./images/green-check.svg[]Easier and more robust than the API. +\n+image:./images/red-x.svg[]Less flexible on its own, but can be combined with the API\n+\n+<<method-annotations,Learn more>>\n+\n+[float]\n+===== Configuration-based\n+\n+Use a configuration option to specify additional methods to instrument.\n+\n+image:./images/green-check.svg[]  No need to modify source code. +\n+image:./images/green-check.svg[] Possible to monitor code in third-party libraries +\n+image:./images/green-check.svg[] Match methods via wildcards +\n+image:./images/red-x.svg[] Easy to overuse which hurts runtime and startup performance.\n+\n+<<method-config-based,Learn more>>\n+\n+//********************************************\n+[[method-sampling-based]]\n+=== Sampling-based profiler\n+\n+experimental::[]\n+added::[1.14.0]\n+\n+Instead of recording every event, leverage https://github.com/jvm-profiling-tools/async-profiler[async-profiler]\n+to periodically request the stack trace from all actively running threads.\n+This means measurements do not need to be inserted into all methods, which keeps the overhead of this approach extremely low.\n+Stack traces are then correlated with span activation events, and profiler-inferred spans for slow methods are created.\n+Just like that, we've detected exactly what is executing between current transactions and spans.\n+\n+// Show simple example from Blog?\n+// BEFORE:: WelcomeController#welcome\n+// AFTER:: WelcomeController#think\n+// https://www.elastic.co/blog/from-distributed-tracing-to-distributed-profiling-with-elastic-apm\n+\n+[float]\n+==== Use cases\n+\n+* **Development**:\n+When trying to find out why the request you just made was slow.\n+* **Load testing / Production**:\n+When analyzing why some requests are slower than others.\n+* **Customer support**:\n+When a user complains that a particular request they made at noon was slow,\n+especially if you can't reproduce that slowness in your development or staging environment.\n+\n+[float]\n+==== Advantages\n+\n+* **No need to know what methods to monitor**:\n+Find slow methods without specifying specific method names up front.\n+The profiler automatically bubbles up slow methods as spans in the APM app.\n+* **Low overhead. Production ready**:\n+The profiler-based approach is designed to be low-overhead enough to run in production;\n+Continuously run it to provide insights into slow methods.\n+\n+[float]\n+==== How to enable inferred spans with async-profiler\n+\n+Enable inferred spans by setting <<config-profiling-inferred-spans-enabled,`profiling_inferred_spans_enabled`>> to `true`.\n+\n+**Tune stack trace frequency**\n+\n+Tune the frequency at which stack traces are gathered within a profiling session by adjusting\n+<<config-profiling-inferred-spans-sampling-interval,`profiling_inferred_spans_sampling_interval`>>.\n+The lower the sampling interval, the higher the accuracy and the level of detail of the inferred spans.\n+Of course, the higher the level of detail, the higher the profiler overhead and the Elasticsearch index sizes.\n+As most of the processing is done in the background, the impact on the response time of user requests is negligible.\n+\n+**Clean up clutter in the APM app**\n+\n+Filter out inferred spans that are faster than the configured threshold,\n+and avoid cluttering the APM app with fast-executing methods by setting\n+<<config-profiling-inferred-spans-min-duration,`profiling_inferred_spans_min_duration`>>.\n+\n+**Include and exclude specific classes**\n+\n+Include and exclude specific classes explicitly with\n+<<config-profiling-inferred-spans-included-classes,`profiling_inferred_spans_included_classes`>> and\n+<<config-profiling-inferred-spans-excluded-classes,`profiling_inferred_spans_excluded_classes`>>.\n+Generally, the fewer classes that are included, the faster and the more memory efficient the processing is.\n+\n+By default, the classes from the JDK and from most application servers are excluded. This reduces the number of uninteresting inferred spans.\n+\n+**Example `elasticapm.properties` file with inferred spans enabled**\n+\n+[source,properties]\n+----\n+profiling_inferred_spans_enabled=true\n+profiling_inferred_spans_sampling_interval=50ms\n+profiling_inferred_spans_min_duration=25ms\n+profiling_inferred_spans_included_classes=org.example.myapp.*\n+profiling_inferred_spans_excluded_classes=(?-i)java.*\n+----\n+\n+[float]\n+==== Caveats\n+\n+Inferred spans are estimations, not exact measurements.\n+They may start after the method actually started, and end before the method actually ended.\n+This can lead to inconsistencies, all of which are documented in the\n+https://github.com/elastic/apm-agent-java/tree/master/apm-agent-plugins/apm-profiling-plugin[apm-profiling-plugin readme].\n+\n+// Inferred spans are created after the profiling session ends and therefor may appear later in the APM app's span timeline than regular spans.\n+// Because of this, a regular span cannot be the child of an inferred span.\n+\n+//********************************************\n+[[method-api]]\n+=== API/Code\n+\n+Use the <<api-span,span API>> to manually create spans for methods of interest.\n+The API is extremely flexible, and offers the ability to customize your spans,\n+by adding labels to them, or by changing the type, name, or timestamp.\n+\n+TIP: OpenTracing fan? You can use the <<opentracing-bridge,OpenTracing API>>, instead of the Agent API,\n+to manually create spans.\n+\n+[float]\n+==== How to create spans with the span API\n+\n+. Get the current span with <<api-current-span,`currentSpan()`>>,\n+which may or may not have been created with auto-instrumentation.\n+. Create a child span with <<api-span-start-span,`startSpan()`>>.\n+. Customize the span with the <<api-span,span API>>.\n+\n+[source,java]\n+----\n+import co.elastic.apm.api.ElasticApm;\n+import co.elastic.apm.api.Span;\n+\n+Span parent = ElasticApm.currentSpan(); <1>\n+Span span = parent.startSpan(); <2>\n+try {\n+    span.setName(\"SELECT FROM customer\"); <3>\n+    span.addLabel(\"foo\", \"bar\"); <4>\n+    // do your thing...\n+} catch (Exception e) {\n+    span.captureException(e);\n+    throw e;\n+} finally {\n+    span.end();\n+}\n+----\n+<1> Get current span\n+<2> Create a child span\n+<3> Override the default span name\n+<4> Add labels to the span\n+\n+[float]\n+==== Combine with annotations\n+\n+// This section is copied from the <<method-annotations>> documentation\n+include::method-monitoring.asciidoc[tag=combine-api-annotations]\n+\n+//********************************************\n+[[method-annotations]]\n+=== Annotations\n+\n+The <<api-annotation,annotation API>> allows you to place annotations on top of methods to automatically create spans for them.\n+This method of creating spans is easier, more robust, and typically more performant than using the API;\n+there\u2019s nothing you can do wrong like forgetting to end a span or close a scope.\n+\n+Annotations are less flexible when used on their own, but can be combined with the span API for added flexibility.\n+\n+[float]\n+==== How-to create spans with the annotations API\n+\n+Here's an example that uses the <<api-capture-span,`@CaptureSpan`>> annotation to create a span for the `spanWithAnnotation()` method.\n+The span is named `spanName`, is of type `ext`, and subtype `http`.\n+\n+[source,java]\n+----\n+@CaptureSpan(value = \"spanName\", type = \"ext\", subtype = \"http\")\n+private static void spanWithAnnotation() {\n+    // do your thing...\n+}\n+----\n+\n+[float]\n+==== Combine with the span API\n+\n+// This content is also used in the `method-api` documentation\n+// Ensure any changes made here can also apply there.\n+// tag::combine-api-annotations[]\n+You can combine annotations with the span API to increase their flexibility.\n+Just get the current span on an annotated method and customize the span to your liking.\n+\n+[source,java]\n+----\n+@CaptureSpan(value = \"spanName\", type = \"ext\", subtype = \"http\") <1>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6134df2505237285b6b805583632a0fb85b7290c"}, "originalPosition": 232}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzMjc5NDUwOnYy", "diffSide": "RIGHT", "path": "docs/method-monitoring.asciidoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwODo1MjozNlrOGFEpng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwODo1MjozNlrOGFEpng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk3MjI1NA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            private static void spanWithAnnotation() {\n          \n          \n            \n                Span parent = ElasticApm.currentSpan(); <2>\n          \n          \n            \n                Span span = parent.startSpan(); <3>\n          \n          \n            \n                try {\n          \n          \n            \n                    // do your thing...\n          \n          \n            \n                } catch (Exception e) {\n          \n          \n            \n                    span.captureException(e);\n          \n          \n            \n                    throw e;\n          \n          \n            \n                } finally {\n          \n          \n            \n                    span.end();\n          \n          \n            \n                }\n          \n          \n            \n            }\n          \n          \n            \n            private static void spanWithAnnotation(String foo) {\n          \n          \n            \n                Span span = ElasticApm.currentSpan(); <2>\n          \n          \n            \n                span.setTag(\"foo\", foo); <3>\n          \n          \n            \n            }", "url": "https://github.com/elastic/apm-agent-java/pull/1135#discussion_r407972254", "createdAt": "2020-04-14T08:52:36Z", "author": {"login": "felixbarny"}, "path": "docs/method-monitoring.asciidoc", "diffHunk": "@@ -0,0 +1,282 @@\n+[[java-method-monitoring]]\n+== How to find slow methods\n+\n+Identifying a problematic service is only half of the battle when diagnosing application slowdowns.\n+Luckily, the Elastic APM Java Agent provides multiple ways to get method-level insights into your code.\n+This can help you diagnose slow requests due to heavy computations, inefficient algorithms,\n+or similar problems not related to interactions between services.\n+\n+[float]\n+==== _If you don't know which methods you want to monitor..._\n+\n+[float]\n+===== Sampling-based profiler\n+\n+Find out which part of your code is making your application slow;\n+periodically record running methods with a sampling-based profiler.\n+\n+image:./images/green-check.svg[] Very low overhead. +\n+image:./images/green-check.svg[] No code changes required. +\n+image:./images/red-x.svg[] Does not work on Windows. +\n+image:./images/red-x.svg[] The duration of profiler-inferred spans are not exact measurements, only estimates.\n+\n+<<method-sampling-based,Learn more>>\n+\n+[float]\n+==== _If you know which methods you want to monitor..._\n+\n+[float]\n+===== API/Code\n+\n+Use the API or OpenTracing bridge to manually create spans for methods of interest.\n+\n+image:./images/green-check.svg[] Most flexible. +\n+image:./images/red-x.svg[] Incorrect API usage may lead to invalid traces (scope leaks).\n+\n+<<method-api,Learn more>>\n+\n+[float]\n+===== Annotations\n+\n+Annotations can be placed on top of methods to automatically create spans for them.\n+\n+image:./images/green-check.svg[]Easier and more robust than the API. +\n+image:./images/red-x.svg[]Less flexible on its own, but can be combined with the API\n+\n+<<method-annotations,Learn more>>\n+\n+[float]\n+===== Configuration-based\n+\n+Use a configuration option to specify additional methods to instrument.\n+\n+image:./images/green-check.svg[]  No need to modify source code. +\n+image:./images/green-check.svg[] Possible to monitor code in third-party libraries +\n+image:./images/green-check.svg[] Match methods via wildcards +\n+image:./images/red-x.svg[] Easy to overuse which hurts runtime and startup performance.\n+\n+<<method-config-based,Learn more>>\n+\n+//********************************************\n+[[method-sampling-based]]\n+=== Sampling-based profiler\n+\n+experimental::[]\n+added::[1.14.0]\n+\n+Instead of recording every event, leverage https://github.com/jvm-profiling-tools/async-profiler[async-profiler]\n+to periodically request the stack trace from all actively running threads.\n+This means measurements do not need to be inserted into all methods, which keeps the overhead of this approach extremely low.\n+Stack traces are then correlated with span activation events, and profiler-inferred spans for slow methods are created.\n+Just like that, we've detected exactly what is executing between current transactions and spans.\n+\n+// Show simple example from Blog?\n+// BEFORE:: WelcomeController#welcome\n+// AFTER:: WelcomeController#think\n+// https://www.elastic.co/blog/from-distributed-tracing-to-distributed-profiling-with-elastic-apm\n+\n+[float]\n+==== Use cases\n+\n+* **Development**:\n+When trying to find out why the request you just made was slow.\n+* **Load testing / Production**:\n+When analyzing why some requests are slower than others.\n+* **Customer support**:\n+When a user complains that a particular request they made at noon was slow,\n+especially if you can't reproduce that slowness in your development or staging environment.\n+\n+[float]\n+==== Advantages\n+\n+* **No need to know what methods to monitor**:\n+Find slow methods without specifying specific method names up front.\n+The profiler automatically bubbles up slow methods as spans in the APM app.\n+* **Low overhead. Production ready**:\n+The profiler-based approach is designed to be low-overhead enough to run in production;\n+Continuously run it to provide insights into slow methods.\n+\n+[float]\n+==== How to enable inferred spans with async-profiler\n+\n+Enable inferred spans by setting <<config-profiling-inferred-spans-enabled,`profiling_inferred_spans_enabled`>> to `true`.\n+\n+**Tune stack trace frequency**\n+\n+Tune the frequency at which stack traces are gathered within a profiling session by adjusting\n+<<config-profiling-inferred-spans-sampling-interval,`profiling_inferred_spans_sampling_interval`>>.\n+The lower the sampling interval, the higher the accuracy and the level of detail of the inferred spans.\n+Of course, the higher the level of detail, the higher the profiler overhead and the Elasticsearch index sizes.\n+As most of the processing is done in the background, the impact on the response time of user requests is negligible.\n+\n+**Clean up clutter in the APM app**\n+\n+Filter out inferred spans that are faster than the configured threshold,\n+and avoid cluttering the APM app with fast-executing methods by setting\n+<<config-profiling-inferred-spans-min-duration,`profiling_inferred_spans_min_duration`>>.\n+\n+**Include and exclude specific classes**\n+\n+Include and exclude specific classes explicitly with\n+<<config-profiling-inferred-spans-included-classes,`profiling_inferred_spans_included_classes`>> and\n+<<config-profiling-inferred-spans-excluded-classes,`profiling_inferred_spans_excluded_classes`>>.\n+Generally, the fewer classes that are included, the faster and the more memory efficient the processing is.\n+\n+By default, the classes from the JDK and from most application servers are excluded. This reduces the number of uninteresting inferred spans.\n+\n+**Example `elasticapm.properties` file with inferred spans enabled**\n+\n+[source,properties]\n+----\n+profiling_inferred_spans_enabled=true\n+profiling_inferred_spans_sampling_interval=50ms\n+profiling_inferred_spans_min_duration=25ms\n+profiling_inferred_spans_included_classes=org.example.myapp.*\n+profiling_inferred_spans_excluded_classes=(?-i)java.*\n+----\n+\n+[float]\n+==== Caveats\n+\n+Inferred spans are estimations, not exact measurements.\n+They may start after the method actually started, and end before the method actually ended.\n+This can lead to inconsistencies, all of which are documented in the\n+https://github.com/elastic/apm-agent-java/tree/master/apm-agent-plugins/apm-profiling-plugin[apm-profiling-plugin readme].\n+\n+// Inferred spans are created after the profiling session ends and therefor may appear later in the APM app's span timeline than regular spans.\n+// Because of this, a regular span cannot be the child of an inferred span.\n+\n+//********************************************\n+[[method-api]]\n+=== API/Code\n+\n+Use the <<api-span,span API>> to manually create spans for methods of interest.\n+The API is extremely flexible, and offers the ability to customize your spans,\n+by adding labels to them, or by changing the type, name, or timestamp.\n+\n+TIP: OpenTracing fan? You can use the <<opentracing-bridge,OpenTracing API>>, instead of the Agent API,\n+to manually create spans.\n+\n+[float]\n+==== How to create spans with the span API\n+\n+. Get the current span with <<api-current-span,`currentSpan()`>>,\n+which may or may not have been created with auto-instrumentation.\n+. Create a child span with <<api-span-start-span,`startSpan()`>>.\n+. Customize the span with the <<api-span,span API>>.\n+\n+[source,java]\n+----\n+import co.elastic.apm.api.ElasticApm;\n+import co.elastic.apm.api.Span;\n+\n+Span parent = ElasticApm.currentSpan(); <1>\n+Span span = parent.startSpan(); <2>\n+try {\n+    span.setName(\"SELECT FROM customer\"); <3>\n+    span.addLabel(\"foo\", \"bar\"); <4>\n+    // do your thing...\n+} catch (Exception e) {\n+    span.captureException(e);\n+    throw e;\n+} finally {\n+    span.end();\n+}\n+----\n+<1> Get current span\n+<2> Create a child span\n+<3> Override the default span name\n+<4> Add labels to the span\n+\n+[float]\n+==== Combine with annotations\n+\n+// This section is copied from the <<method-annotations>> documentation\n+include::method-monitoring.asciidoc[tag=combine-api-annotations]\n+\n+//********************************************\n+[[method-annotations]]\n+=== Annotations\n+\n+The <<api-annotation,annotation API>> allows you to place annotations on top of methods to automatically create spans for them.\n+This method of creating spans is easier, more robust, and typically more performant than using the API;\n+there\u2019s nothing you can do wrong like forgetting to end a span or close a scope.\n+\n+Annotations are less flexible when used on their own, but can be combined with the span API for added flexibility.\n+\n+[float]\n+==== How-to create spans with the annotations API\n+\n+Here's an example that uses the <<api-capture-span,`@CaptureSpan`>> annotation to create a span for the `spanWithAnnotation()` method.\n+The span is named `spanName`, is of type `ext`, and subtype `http`.\n+\n+[source,java]\n+----\n+@CaptureSpan(value = \"spanName\", type = \"ext\", subtype = \"http\")\n+private static void spanWithAnnotation() {\n+    // do your thing...\n+}\n+----\n+\n+[float]\n+==== Combine with the span API\n+\n+// This content is also used in the `method-api` documentation\n+// Ensure any changes made here can also apply there.\n+// tag::combine-api-annotations[]\n+You can combine annotations with the span API to increase their flexibility.\n+Just get the current span on an annotated method and customize the span to your liking.\n+\n+[source,java]\n+----\n+@CaptureSpan(value = \"spanName\", type = \"ext\", subtype = \"http\") <1>\n+private static void spanWithAnnotation() {\n+    Span parent = ElasticApm.currentSpan(); <2>\n+    Span span = parent.startSpan(); <3>\n+    try {\n+        // do your thing...\n+    } catch (Exception e) {\n+        span.captureException(e);\n+        throw e;\n+    } finally {\n+        span.end();\n+    }\n+}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6134df2505237285b6b805583632a0fb85b7290c"}, "originalPosition": 244}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzMjc5NzA2OnYy", "diffSide": "RIGHT", "path": "docs/method-monitoring.asciidoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwODo1MzoxOFrOGFErSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwODo1MzoxOFrOGFErSQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk3MjY4MQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            <2> Get the current span\n          \n          \n            \n            <2> Get the current span (the one created via the `@CaptureSpan` annotation)", "url": "https://github.com/elastic/apm-agent-java/pull/1135#discussion_r407972681", "createdAt": "2020-04-14T08:53:18Z", "author": {"login": "felixbarny"}, "path": "docs/method-monitoring.asciidoc", "diffHunk": "@@ -0,0 +1,282 @@\n+[[java-method-monitoring]]\n+== How to find slow methods\n+\n+Identifying a problematic service is only half of the battle when diagnosing application slowdowns.\n+Luckily, the Elastic APM Java Agent provides multiple ways to get method-level insights into your code.\n+This can help you diagnose slow requests due to heavy computations, inefficient algorithms,\n+or similar problems not related to interactions between services.\n+\n+[float]\n+==== _If you don't know which methods you want to monitor..._\n+\n+[float]\n+===== Sampling-based profiler\n+\n+Find out which part of your code is making your application slow;\n+periodically record running methods with a sampling-based profiler.\n+\n+image:./images/green-check.svg[] Very low overhead. +\n+image:./images/green-check.svg[] No code changes required. +\n+image:./images/red-x.svg[] Does not work on Windows. +\n+image:./images/red-x.svg[] The duration of profiler-inferred spans are not exact measurements, only estimates.\n+\n+<<method-sampling-based,Learn more>>\n+\n+[float]\n+==== _If you know which methods you want to monitor..._\n+\n+[float]\n+===== API/Code\n+\n+Use the API or OpenTracing bridge to manually create spans for methods of interest.\n+\n+image:./images/green-check.svg[] Most flexible. +\n+image:./images/red-x.svg[] Incorrect API usage may lead to invalid traces (scope leaks).\n+\n+<<method-api,Learn more>>\n+\n+[float]\n+===== Annotations\n+\n+Annotations can be placed on top of methods to automatically create spans for them.\n+\n+image:./images/green-check.svg[]Easier and more robust than the API. +\n+image:./images/red-x.svg[]Less flexible on its own, but can be combined with the API\n+\n+<<method-annotations,Learn more>>\n+\n+[float]\n+===== Configuration-based\n+\n+Use a configuration option to specify additional methods to instrument.\n+\n+image:./images/green-check.svg[]  No need to modify source code. +\n+image:./images/green-check.svg[] Possible to monitor code in third-party libraries +\n+image:./images/green-check.svg[] Match methods via wildcards +\n+image:./images/red-x.svg[] Easy to overuse which hurts runtime and startup performance.\n+\n+<<method-config-based,Learn more>>\n+\n+//********************************************\n+[[method-sampling-based]]\n+=== Sampling-based profiler\n+\n+experimental::[]\n+added::[1.14.0]\n+\n+Instead of recording every event, leverage https://github.com/jvm-profiling-tools/async-profiler[async-profiler]\n+to periodically request the stack trace from all actively running threads.\n+This means measurements do not need to be inserted into all methods, which keeps the overhead of this approach extremely low.\n+Stack traces are then correlated with span activation events, and profiler-inferred spans for slow methods are created.\n+Just like that, we've detected exactly what is executing between current transactions and spans.\n+\n+// Show simple example from Blog?\n+// BEFORE:: WelcomeController#welcome\n+// AFTER:: WelcomeController#think\n+// https://www.elastic.co/blog/from-distributed-tracing-to-distributed-profiling-with-elastic-apm\n+\n+[float]\n+==== Use cases\n+\n+* **Development**:\n+When trying to find out why the request you just made was slow.\n+* **Load testing / Production**:\n+When analyzing why some requests are slower than others.\n+* **Customer support**:\n+When a user complains that a particular request they made at noon was slow,\n+especially if you can't reproduce that slowness in your development or staging environment.\n+\n+[float]\n+==== Advantages\n+\n+* **No need to know what methods to monitor**:\n+Find slow methods without specifying specific method names up front.\n+The profiler automatically bubbles up slow methods as spans in the APM app.\n+* **Low overhead. Production ready**:\n+The profiler-based approach is designed to be low-overhead enough to run in production;\n+Continuously run it to provide insights into slow methods.\n+\n+[float]\n+==== How to enable inferred spans with async-profiler\n+\n+Enable inferred spans by setting <<config-profiling-inferred-spans-enabled,`profiling_inferred_spans_enabled`>> to `true`.\n+\n+**Tune stack trace frequency**\n+\n+Tune the frequency at which stack traces are gathered within a profiling session by adjusting\n+<<config-profiling-inferred-spans-sampling-interval,`profiling_inferred_spans_sampling_interval`>>.\n+The lower the sampling interval, the higher the accuracy and the level of detail of the inferred spans.\n+Of course, the higher the level of detail, the higher the profiler overhead and the Elasticsearch index sizes.\n+As most of the processing is done in the background, the impact on the response time of user requests is negligible.\n+\n+**Clean up clutter in the APM app**\n+\n+Filter out inferred spans that are faster than the configured threshold,\n+and avoid cluttering the APM app with fast-executing methods by setting\n+<<config-profiling-inferred-spans-min-duration,`profiling_inferred_spans_min_duration`>>.\n+\n+**Include and exclude specific classes**\n+\n+Include and exclude specific classes explicitly with\n+<<config-profiling-inferred-spans-included-classes,`profiling_inferred_spans_included_classes`>> and\n+<<config-profiling-inferred-spans-excluded-classes,`profiling_inferred_spans_excluded_classes`>>.\n+Generally, the fewer classes that are included, the faster and the more memory efficient the processing is.\n+\n+By default, the classes from the JDK and from most application servers are excluded. This reduces the number of uninteresting inferred spans.\n+\n+**Example `elasticapm.properties` file with inferred spans enabled**\n+\n+[source,properties]\n+----\n+profiling_inferred_spans_enabled=true\n+profiling_inferred_spans_sampling_interval=50ms\n+profiling_inferred_spans_min_duration=25ms\n+profiling_inferred_spans_included_classes=org.example.myapp.*\n+profiling_inferred_spans_excluded_classes=(?-i)java.*\n+----\n+\n+[float]\n+==== Caveats\n+\n+Inferred spans are estimations, not exact measurements.\n+They may start after the method actually started, and end before the method actually ended.\n+This can lead to inconsistencies, all of which are documented in the\n+https://github.com/elastic/apm-agent-java/tree/master/apm-agent-plugins/apm-profiling-plugin[apm-profiling-plugin readme].\n+\n+// Inferred spans are created after the profiling session ends and therefor may appear later in the APM app's span timeline than regular spans.\n+// Because of this, a regular span cannot be the child of an inferred span.\n+\n+//********************************************\n+[[method-api]]\n+=== API/Code\n+\n+Use the <<api-span,span API>> to manually create spans for methods of interest.\n+The API is extremely flexible, and offers the ability to customize your spans,\n+by adding labels to them, or by changing the type, name, or timestamp.\n+\n+TIP: OpenTracing fan? You can use the <<opentracing-bridge,OpenTracing API>>, instead of the Agent API,\n+to manually create spans.\n+\n+[float]\n+==== How to create spans with the span API\n+\n+. Get the current span with <<api-current-span,`currentSpan()`>>,\n+which may or may not have been created with auto-instrumentation.\n+. Create a child span with <<api-span-start-span,`startSpan()`>>.\n+. Customize the span with the <<api-span,span API>>.\n+\n+[source,java]\n+----\n+import co.elastic.apm.api.ElasticApm;\n+import co.elastic.apm.api.Span;\n+\n+Span parent = ElasticApm.currentSpan(); <1>\n+Span span = parent.startSpan(); <2>\n+try {\n+    span.setName(\"SELECT FROM customer\"); <3>\n+    span.addLabel(\"foo\", \"bar\"); <4>\n+    // do your thing...\n+} catch (Exception e) {\n+    span.captureException(e);\n+    throw e;\n+} finally {\n+    span.end();\n+}\n+----\n+<1> Get current span\n+<2> Create a child span\n+<3> Override the default span name\n+<4> Add labels to the span\n+\n+[float]\n+==== Combine with annotations\n+\n+// This section is copied from the <<method-annotations>> documentation\n+include::method-monitoring.asciidoc[tag=combine-api-annotations]\n+\n+//********************************************\n+[[method-annotations]]\n+=== Annotations\n+\n+The <<api-annotation,annotation API>> allows you to place annotations on top of methods to automatically create spans for them.\n+This method of creating spans is easier, more robust, and typically more performant than using the API;\n+there\u2019s nothing you can do wrong like forgetting to end a span or close a scope.\n+\n+Annotations are less flexible when used on their own, but can be combined with the span API for added flexibility.\n+\n+[float]\n+==== How-to create spans with the annotations API\n+\n+Here's an example that uses the <<api-capture-span,`@CaptureSpan`>> annotation to create a span for the `spanWithAnnotation()` method.\n+The span is named `spanName`, is of type `ext`, and subtype `http`.\n+\n+[source,java]\n+----\n+@CaptureSpan(value = \"spanName\", type = \"ext\", subtype = \"http\")\n+private static void spanWithAnnotation() {\n+    // do your thing...\n+}\n+----\n+\n+[float]\n+==== Combine with the span API\n+\n+// This content is also used in the `method-api` documentation\n+// Ensure any changes made here can also apply there.\n+// tag::combine-api-annotations[]\n+You can combine annotations with the span API to increase their flexibility.\n+Just get the current span on an annotated method and customize the span to your liking.\n+\n+[source,java]\n+----\n+@CaptureSpan(value = \"spanName\", type = \"ext\", subtype = \"http\") <1>\n+private static void spanWithAnnotation() {\n+    Span parent = ElasticApm.currentSpan(); <2>\n+    Span span = parent.startSpan(); <3>\n+    try {\n+        // do your thing...\n+    } catch (Exception e) {\n+        span.captureException(e);\n+        throw e;\n+    } finally {\n+        span.end();\n+    }\n+}\n+----\n+<1> Use `@CaptureSpan` annotation to create a span\n+<2> Get the current span", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6134df2505237285b6b805583632a0fb85b7290c"}, "originalPosition": 247}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzMjc5ODgzOnYy", "diffSide": "RIGHT", "path": "docs/method-monitoring.asciidoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwODo1Mzo0NlrOGFEsXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwODo1Mzo0NlrOGFEsXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk3Mjk1Nw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            <3> Start a child span\n          \n          \n            \n            <3> Customize the span", "url": "https://github.com/elastic/apm-agent-java/pull/1135#discussion_r407972957", "createdAt": "2020-04-14T08:53:46Z", "author": {"login": "felixbarny"}, "path": "docs/method-monitoring.asciidoc", "diffHunk": "@@ -0,0 +1,282 @@\n+[[java-method-monitoring]]\n+== How to find slow methods\n+\n+Identifying a problematic service is only half of the battle when diagnosing application slowdowns.\n+Luckily, the Elastic APM Java Agent provides multiple ways to get method-level insights into your code.\n+This can help you diagnose slow requests due to heavy computations, inefficient algorithms,\n+or similar problems not related to interactions between services.\n+\n+[float]\n+==== _If you don't know which methods you want to monitor..._\n+\n+[float]\n+===== Sampling-based profiler\n+\n+Find out which part of your code is making your application slow;\n+periodically record running methods with a sampling-based profiler.\n+\n+image:./images/green-check.svg[] Very low overhead. +\n+image:./images/green-check.svg[] No code changes required. +\n+image:./images/red-x.svg[] Does not work on Windows. +\n+image:./images/red-x.svg[] The duration of profiler-inferred spans are not exact measurements, only estimates.\n+\n+<<method-sampling-based,Learn more>>\n+\n+[float]\n+==== _If you know which methods you want to monitor..._\n+\n+[float]\n+===== API/Code\n+\n+Use the API or OpenTracing bridge to manually create spans for methods of interest.\n+\n+image:./images/green-check.svg[] Most flexible. +\n+image:./images/red-x.svg[] Incorrect API usage may lead to invalid traces (scope leaks).\n+\n+<<method-api,Learn more>>\n+\n+[float]\n+===== Annotations\n+\n+Annotations can be placed on top of methods to automatically create spans for them.\n+\n+image:./images/green-check.svg[]Easier and more robust than the API. +\n+image:./images/red-x.svg[]Less flexible on its own, but can be combined with the API\n+\n+<<method-annotations,Learn more>>\n+\n+[float]\n+===== Configuration-based\n+\n+Use a configuration option to specify additional methods to instrument.\n+\n+image:./images/green-check.svg[]  No need to modify source code. +\n+image:./images/green-check.svg[] Possible to monitor code in third-party libraries +\n+image:./images/green-check.svg[] Match methods via wildcards +\n+image:./images/red-x.svg[] Easy to overuse which hurts runtime and startup performance.\n+\n+<<method-config-based,Learn more>>\n+\n+//********************************************\n+[[method-sampling-based]]\n+=== Sampling-based profiler\n+\n+experimental::[]\n+added::[1.14.0]\n+\n+Instead of recording every event, leverage https://github.com/jvm-profiling-tools/async-profiler[async-profiler]\n+to periodically request the stack trace from all actively running threads.\n+This means measurements do not need to be inserted into all methods, which keeps the overhead of this approach extremely low.\n+Stack traces are then correlated with span activation events, and profiler-inferred spans for slow methods are created.\n+Just like that, we've detected exactly what is executing between current transactions and spans.\n+\n+// Show simple example from Blog?\n+// BEFORE:: WelcomeController#welcome\n+// AFTER:: WelcomeController#think\n+// https://www.elastic.co/blog/from-distributed-tracing-to-distributed-profiling-with-elastic-apm\n+\n+[float]\n+==== Use cases\n+\n+* **Development**:\n+When trying to find out why the request you just made was slow.\n+* **Load testing / Production**:\n+When analyzing why some requests are slower than others.\n+* **Customer support**:\n+When a user complains that a particular request they made at noon was slow,\n+especially if you can't reproduce that slowness in your development or staging environment.\n+\n+[float]\n+==== Advantages\n+\n+* **No need to know what methods to monitor**:\n+Find slow methods without specifying specific method names up front.\n+The profiler automatically bubbles up slow methods as spans in the APM app.\n+* **Low overhead. Production ready**:\n+The profiler-based approach is designed to be low-overhead enough to run in production;\n+Continuously run it to provide insights into slow methods.\n+\n+[float]\n+==== How to enable inferred spans with async-profiler\n+\n+Enable inferred spans by setting <<config-profiling-inferred-spans-enabled,`profiling_inferred_spans_enabled`>> to `true`.\n+\n+**Tune stack trace frequency**\n+\n+Tune the frequency at which stack traces are gathered within a profiling session by adjusting\n+<<config-profiling-inferred-spans-sampling-interval,`profiling_inferred_spans_sampling_interval`>>.\n+The lower the sampling interval, the higher the accuracy and the level of detail of the inferred spans.\n+Of course, the higher the level of detail, the higher the profiler overhead and the Elasticsearch index sizes.\n+As most of the processing is done in the background, the impact on the response time of user requests is negligible.\n+\n+**Clean up clutter in the APM app**\n+\n+Filter out inferred spans that are faster than the configured threshold,\n+and avoid cluttering the APM app with fast-executing methods by setting\n+<<config-profiling-inferred-spans-min-duration,`profiling_inferred_spans_min_duration`>>.\n+\n+**Include and exclude specific classes**\n+\n+Include and exclude specific classes explicitly with\n+<<config-profiling-inferred-spans-included-classes,`profiling_inferred_spans_included_classes`>> and\n+<<config-profiling-inferred-spans-excluded-classes,`profiling_inferred_spans_excluded_classes`>>.\n+Generally, the fewer classes that are included, the faster and the more memory efficient the processing is.\n+\n+By default, the classes from the JDK and from most application servers are excluded. This reduces the number of uninteresting inferred spans.\n+\n+**Example `elasticapm.properties` file with inferred spans enabled**\n+\n+[source,properties]\n+----\n+profiling_inferred_spans_enabled=true\n+profiling_inferred_spans_sampling_interval=50ms\n+profiling_inferred_spans_min_duration=25ms\n+profiling_inferred_spans_included_classes=org.example.myapp.*\n+profiling_inferred_spans_excluded_classes=(?-i)java.*\n+----\n+\n+[float]\n+==== Caveats\n+\n+Inferred spans are estimations, not exact measurements.\n+They may start after the method actually started, and end before the method actually ended.\n+This can lead to inconsistencies, all of which are documented in the\n+https://github.com/elastic/apm-agent-java/tree/master/apm-agent-plugins/apm-profiling-plugin[apm-profiling-plugin readme].\n+\n+// Inferred spans are created after the profiling session ends and therefor may appear later in the APM app's span timeline than regular spans.\n+// Because of this, a regular span cannot be the child of an inferred span.\n+\n+//********************************************\n+[[method-api]]\n+=== API/Code\n+\n+Use the <<api-span,span API>> to manually create spans for methods of interest.\n+The API is extremely flexible, and offers the ability to customize your spans,\n+by adding labels to them, or by changing the type, name, or timestamp.\n+\n+TIP: OpenTracing fan? You can use the <<opentracing-bridge,OpenTracing API>>, instead of the Agent API,\n+to manually create spans.\n+\n+[float]\n+==== How to create spans with the span API\n+\n+. Get the current span with <<api-current-span,`currentSpan()`>>,\n+which may or may not have been created with auto-instrumentation.\n+. Create a child span with <<api-span-start-span,`startSpan()`>>.\n+. Customize the span with the <<api-span,span API>>.\n+\n+[source,java]\n+----\n+import co.elastic.apm.api.ElasticApm;\n+import co.elastic.apm.api.Span;\n+\n+Span parent = ElasticApm.currentSpan(); <1>\n+Span span = parent.startSpan(); <2>\n+try {\n+    span.setName(\"SELECT FROM customer\"); <3>\n+    span.addLabel(\"foo\", \"bar\"); <4>\n+    // do your thing...\n+} catch (Exception e) {\n+    span.captureException(e);\n+    throw e;\n+} finally {\n+    span.end();\n+}\n+----\n+<1> Get current span\n+<2> Create a child span\n+<3> Override the default span name\n+<4> Add labels to the span\n+\n+[float]\n+==== Combine with annotations\n+\n+// This section is copied from the <<method-annotations>> documentation\n+include::method-monitoring.asciidoc[tag=combine-api-annotations]\n+\n+//********************************************\n+[[method-annotations]]\n+=== Annotations\n+\n+The <<api-annotation,annotation API>> allows you to place annotations on top of methods to automatically create spans for them.\n+This method of creating spans is easier, more robust, and typically more performant than using the API;\n+there\u2019s nothing you can do wrong like forgetting to end a span or close a scope.\n+\n+Annotations are less flexible when used on their own, but can be combined with the span API for added flexibility.\n+\n+[float]\n+==== How-to create spans with the annotations API\n+\n+Here's an example that uses the <<api-capture-span,`@CaptureSpan`>> annotation to create a span for the `spanWithAnnotation()` method.\n+The span is named `spanName`, is of type `ext`, and subtype `http`.\n+\n+[source,java]\n+----\n+@CaptureSpan(value = \"spanName\", type = \"ext\", subtype = \"http\")\n+private static void spanWithAnnotation() {\n+    // do your thing...\n+}\n+----\n+\n+[float]\n+==== Combine with the span API\n+\n+// This content is also used in the `method-api` documentation\n+// Ensure any changes made here can also apply there.\n+// tag::combine-api-annotations[]\n+You can combine annotations with the span API to increase their flexibility.\n+Just get the current span on an annotated method and customize the span to your liking.\n+\n+[source,java]\n+----\n+@CaptureSpan(value = \"spanName\", type = \"ext\", subtype = \"http\") <1>\n+private static void spanWithAnnotation() {\n+    Span parent = ElasticApm.currentSpan(); <2>\n+    Span span = parent.startSpan(); <3>\n+    try {\n+        // do your thing...\n+    } catch (Exception e) {\n+        span.captureException(e);\n+        throw e;\n+    } finally {\n+        span.end();\n+    }\n+}\n+----\n+<1> Use `@CaptureSpan` annotation to create a span\n+<2> Get the current span\n+<3> Start a child span", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6134df2505237285b6b805583632a0fb85b7290c"}, "originalPosition": 248}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzMjgwMzA2OnYy", "diffSide": "RIGHT", "path": "docs/method-monitoring.asciidoc", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwODo1NDozN1rOGFEuyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxOTozNzoyNlrOGFd9WQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk3MzU3Ng==", "bodyText": "Maybe just link to docs?", "url": "https://github.com/elastic/apm-agent-java/pull/1135#discussion_r407973576", "createdAt": "2020-04-14T08:54:37Z", "author": {"login": "felixbarny"}, "path": "docs/method-monitoring.asciidoc", "diffHunk": "@@ -0,0 +1,282 @@\n+[[java-method-monitoring]]\n+== How to find slow methods\n+\n+Identifying a problematic service is only half of the battle when diagnosing application slowdowns.\n+Luckily, the Elastic APM Java Agent provides multiple ways to get method-level insights into your code.\n+This can help you diagnose slow requests due to heavy computations, inefficient algorithms,\n+or similar problems not related to interactions between services.\n+\n+[float]\n+==== _If you don't know which methods you want to monitor..._\n+\n+[float]\n+===== Sampling-based profiler\n+\n+Find out which part of your code is making your application slow;\n+periodically record running methods with a sampling-based profiler.\n+\n+image:./images/green-check.svg[] Very low overhead. +\n+image:./images/green-check.svg[] No code changes required. +\n+image:./images/red-x.svg[] Does not work on Windows. +\n+image:./images/red-x.svg[] The duration of profiler-inferred spans are not exact measurements, only estimates.\n+\n+<<method-sampling-based,Learn more>>\n+\n+[float]\n+==== _If you know which methods you want to monitor..._\n+\n+[float]\n+===== API/Code\n+\n+Use the API or OpenTracing bridge to manually create spans for methods of interest.\n+\n+image:./images/green-check.svg[] Most flexible. +\n+image:./images/red-x.svg[] Incorrect API usage may lead to invalid traces (scope leaks).\n+\n+<<method-api,Learn more>>\n+\n+[float]\n+===== Annotations\n+\n+Annotations can be placed on top of methods to automatically create spans for them.\n+\n+image:./images/green-check.svg[]Easier and more robust than the API. +\n+image:./images/red-x.svg[]Less flexible on its own, but can be combined with the API\n+\n+<<method-annotations,Learn more>>\n+\n+[float]\n+===== Configuration-based\n+\n+Use a configuration option to specify additional methods to instrument.\n+\n+image:./images/green-check.svg[]  No need to modify source code. +\n+image:./images/green-check.svg[] Possible to monitor code in third-party libraries +\n+image:./images/green-check.svg[] Match methods via wildcards +\n+image:./images/red-x.svg[] Easy to overuse which hurts runtime and startup performance.\n+\n+<<method-config-based,Learn more>>\n+\n+//********************************************\n+[[method-sampling-based]]\n+=== Sampling-based profiler\n+\n+experimental::[]\n+added::[1.14.0]\n+\n+Instead of recording every event, leverage https://github.com/jvm-profiling-tools/async-profiler[async-profiler]\n+to periodically request the stack trace from all actively running threads.\n+This means measurements do not need to be inserted into all methods, which keeps the overhead of this approach extremely low.\n+Stack traces are then correlated with span activation events, and profiler-inferred spans for slow methods are created.\n+Just like that, we've detected exactly what is executing between current transactions and spans.\n+\n+// Show simple example from Blog?\n+// BEFORE:: WelcomeController#welcome\n+// AFTER:: WelcomeController#think\n+// https://www.elastic.co/blog/from-distributed-tracing-to-distributed-profiling-with-elastic-apm\n+\n+[float]\n+==== Use cases\n+\n+* **Development**:\n+When trying to find out why the request you just made was slow.\n+* **Load testing / Production**:\n+When analyzing why some requests are slower than others.\n+* **Customer support**:\n+When a user complains that a particular request they made at noon was slow,\n+especially if you can't reproduce that slowness in your development or staging environment.\n+\n+[float]\n+==== Advantages\n+\n+* **No need to know what methods to monitor**:\n+Find slow methods without specifying specific method names up front.\n+The profiler automatically bubbles up slow methods as spans in the APM app.\n+* **Low overhead. Production ready**:\n+The profiler-based approach is designed to be low-overhead enough to run in production;\n+Continuously run it to provide insights into slow methods.\n+\n+[float]\n+==== How to enable inferred spans with async-profiler\n+\n+Enable inferred spans by setting <<config-profiling-inferred-spans-enabled,`profiling_inferred_spans_enabled`>> to `true`.\n+\n+**Tune stack trace frequency**\n+\n+Tune the frequency at which stack traces are gathered within a profiling session by adjusting\n+<<config-profiling-inferred-spans-sampling-interval,`profiling_inferred_spans_sampling_interval`>>.\n+The lower the sampling interval, the higher the accuracy and the level of detail of the inferred spans.\n+Of course, the higher the level of detail, the higher the profiler overhead and the Elasticsearch index sizes.\n+As most of the processing is done in the background, the impact on the response time of user requests is negligible.\n+\n+**Clean up clutter in the APM app**\n+\n+Filter out inferred spans that are faster than the configured threshold,\n+and avoid cluttering the APM app with fast-executing methods by setting\n+<<config-profiling-inferred-spans-min-duration,`profiling_inferred_spans_min_duration`>>.\n+\n+**Include and exclude specific classes**\n+\n+Include and exclude specific classes explicitly with\n+<<config-profiling-inferred-spans-included-classes,`profiling_inferred_spans_included_classes`>> and\n+<<config-profiling-inferred-spans-excluded-classes,`profiling_inferred_spans_excluded_classes`>>.\n+Generally, the fewer classes that are included, the faster and the more memory efficient the processing is.\n+\n+By default, the classes from the JDK and from most application servers are excluded. This reduces the number of uninteresting inferred spans.\n+\n+**Example `elasticapm.properties` file with inferred spans enabled**\n+\n+[source,properties]\n+----\n+profiling_inferred_spans_enabled=true\n+profiling_inferred_spans_sampling_interval=50ms\n+profiling_inferred_spans_min_duration=25ms\n+profiling_inferred_spans_included_classes=org.example.myapp.*\n+profiling_inferred_spans_excluded_classes=(?-i)java.*\n+----\n+\n+[float]\n+==== Caveats\n+\n+Inferred spans are estimations, not exact measurements.\n+They may start after the method actually started, and end before the method actually ended.\n+This can lead to inconsistencies, all of which are documented in the\n+https://github.com/elastic/apm-agent-java/tree/master/apm-agent-plugins/apm-profiling-plugin[apm-profiling-plugin readme].\n+\n+// Inferred spans are created after the profiling session ends and therefor may appear later in the APM app's span timeline than regular spans.\n+// Because of this, a regular span cannot be the child of an inferred span.\n+\n+//********************************************\n+[[method-api]]\n+=== API/Code\n+\n+Use the <<api-span,span API>> to manually create spans for methods of interest.\n+The API is extremely flexible, and offers the ability to customize your spans,\n+by adding labels to them, or by changing the type, name, or timestamp.\n+\n+TIP: OpenTracing fan? You can use the <<opentracing-bridge,OpenTracing API>>, instead of the Agent API,\n+to manually create spans.\n+\n+[float]\n+==== How to create spans with the span API\n+\n+. Get the current span with <<api-current-span,`currentSpan()`>>,\n+which may or may not have been created with auto-instrumentation.\n+. Create a child span with <<api-span-start-span,`startSpan()`>>.\n+. Customize the span with the <<api-span,span API>>.\n+\n+[source,java]\n+----\n+import co.elastic.apm.api.ElasticApm;\n+import co.elastic.apm.api.Span;\n+\n+Span parent = ElasticApm.currentSpan(); <1>\n+Span span = parent.startSpan(); <2>\n+try {\n+    span.setName(\"SELECT FROM customer\"); <3>\n+    span.addLabel(\"foo\", \"bar\"); <4>\n+    // do your thing...\n+} catch (Exception e) {\n+    span.captureException(e);\n+    throw e;\n+} finally {\n+    span.end();\n+}\n+----\n+<1> Get current span\n+<2> Create a child span\n+<3> Override the default span name\n+<4> Add labels to the span\n+\n+[float]\n+==== Combine with annotations\n+\n+// This section is copied from the <<method-annotations>> documentation\n+include::method-monitoring.asciidoc[tag=combine-api-annotations]\n+\n+//********************************************\n+[[method-annotations]]\n+=== Annotations\n+\n+The <<api-annotation,annotation API>> allows you to place annotations on top of methods to automatically create spans for them.\n+This method of creating spans is easier, more robust, and typically more performant than using the API;\n+there\u2019s nothing you can do wrong like forgetting to end a span or close a scope.\n+\n+Annotations are less flexible when used on their own, but can be combined with the span API for added flexibility.\n+\n+[float]\n+==== How-to create spans with the annotations API\n+\n+Here's an example that uses the <<api-capture-span,`@CaptureSpan`>> annotation to create a span for the `spanWithAnnotation()` method.\n+The span is named `spanName`, is of type `ext`, and subtype `http`.\n+\n+[source,java]\n+----\n+@CaptureSpan(value = \"spanName\", type = \"ext\", subtype = \"http\")\n+private static void spanWithAnnotation() {\n+    // do your thing...\n+}\n+----\n+\n+[float]\n+==== Combine with the span API\n+\n+// This content is also used in the `method-api` documentation\n+// Ensure any changes made here can also apply there.\n+// tag::combine-api-annotations[]\n+You can combine annotations with the span API to increase their flexibility.\n+Just get the current span on an annotated method and customize the span to your liking.\n+\n+[source,java]\n+----\n+@CaptureSpan(value = \"spanName\", type = \"ext\", subtype = \"http\") <1>\n+private static void spanWithAnnotation() {\n+    Span parent = ElasticApm.currentSpan(); <2>\n+    Span span = parent.startSpan(); <3>\n+    try {\n+        // do your thing...\n+    } catch (Exception e) {\n+        span.captureException(e);\n+        throw e;\n+    } finally {\n+        span.end();\n+    }\n+}\n+----\n+<1> Use `@CaptureSpan` annotation to create a span\n+<2> Get the current span\n+<3> Start a child span\n+// end::combine-api-annotations[]\n+\n+//********************************************\n+[[method-config-based]]\n+=== Configuration-based\n+\n+Use the <<config-trace-methods,`trace_methods`>> configuration option to specify additional methods to instrument.\n+You can match methods via wildcards in the package, class or method name, by their modifier (like public),\n+by a particular annotation, and more.\n+Because you don\u2019t need to modify your source code, this makes it possible to monitor code in 3rd party libraries.\n+\n+Be careful, it's easy to overuse `trace_methods` by matching too many methods--hurting both runtime and startup performance.\n+Use in conjunction with <<config-trace-methods-duration-threshold,`trace_methods_duration_threshold`>> when setting for entire packages\n+in order to reduce overhead and avoid having too many spans in the APM app.\n+\n+[float]\n+==== How-to create spans with `trace_methods`\n+\n+// I don't really understand this.\n+// Just gonna put some dance emojis here for now \ud83d\udc83\ud83d\udd7a\ud83d\udc83\ud83d\udd7a\ud83d\udc83\ud83d\udd7a\n+// Move from configuration to here?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6134df2505237285b6b805583632a0fb85b7290c"}, "originalPosition": 269}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODM4NjkwNQ==", "bodyText": "Yeah, that's probably the best solution for config-based. I don't want to duplicate the content, and we can't easily share content from the configuration reference.", "url": "https://github.com/elastic/apm-agent-java/pull/1135#discussion_r408386905", "createdAt": "2020-04-14T19:37:26Z", "author": {"login": "bmorelli25"}, "path": "docs/method-monitoring.asciidoc", "diffHunk": "@@ -0,0 +1,282 @@\n+[[java-method-monitoring]]\n+== How to find slow methods\n+\n+Identifying a problematic service is only half of the battle when diagnosing application slowdowns.\n+Luckily, the Elastic APM Java Agent provides multiple ways to get method-level insights into your code.\n+This can help you diagnose slow requests due to heavy computations, inefficient algorithms,\n+or similar problems not related to interactions between services.\n+\n+[float]\n+==== _If you don't know which methods you want to monitor..._\n+\n+[float]\n+===== Sampling-based profiler\n+\n+Find out which part of your code is making your application slow;\n+periodically record running methods with a sampling-based profiler.\n+\n+image:./images/green-check.svg[] Very low overhead. +\n+image:./images/green-check.svg[] No code changes required. +\n+image:./images/red-x.svg[] Does not work on Windows. +\n+image:./images/red-x.svg[] The duration of profiler-inferred spans are not exact measurements, only estimates.\n+\n+<<method-sampling-based,Learn more>>\n+\n+[float]\n+==== _If you know which methods you want to monitor..._\n+\n+[float]\n+===== API/Code\n+\n+Use the API or OpenTracing bridge to manually create spans for methods of interest.\n+\n+image:./images/green-check.svg[] Most flexible. +\n+image:./images/red-x.svg[] Incorrect API usage may lead to invalid traces (scope leaks).\n+\n+<<method-api,Learn more>>\n+\n+[float]\n+===== Annotations\n+\n+Annotations can be placed on top of methods to automatically create spans for them.\n+\n+image:./images/green-check.svg[]Easier and more robust than the API. +\n+image:./images/red-x.svg[]Less flexible on its own, but can be combined with the API\n+\n+<<method-annotations,Learn more>>\n+\n+[float]\n+===== Configuration-based\n+\n+Use a configuration option to specify additional methods to instrument.\n+\n+image:./images/green-check.svg[]  No need to modify source code. +\n+image:./images/green-check.svg[] Possible to monitor code in third-party libraries +\n+image:./images/green-check.svg[] Match methods via wildcards +\n+image:./images/red-x.svg[] Easy to overuse which hurts runtime and startup performance.\n+\n+<<method-config-based,Learn more>>\n+\n+//********************************************\n+[[method-sampling-based]]\n+=== Sampling-based profiler\n+\n+experimental::[]\n+added::[1.14.0]\n+\n+Instead of recording every event, leverage https://github.com/jvm-profiling-tools/async-profiler[async-profiler]\n+to periodically request the stack trace from all actively running threads.\n+This means measurements do not need to be inserted into all methods, which keeps the overhead of this approach extremely low.\n+Stack traces are then correlated with span activation events, and profiler-inferred spans for slow methods are created.\n+Just like that, we've detected exactly what is executing between current transactions and spans.\n+\n+// Show simple example from Blog?\n+// BEFORE:: WelcomeController#welcome\n+// AFTER:: WelcomeController#think\n+// https://www.elastic.co/blog/from-distributed-tracing-to-distributed-profiling-with-elastic-apm\n+\n+[float]\n+==== Use cases\n+\n+* **Development**:\n+When trying to find out why the request you just made was slow.\n+* **Load testing / Production**:\n+When analyzing why some requests are slower than others.\n+* **Customer support**:\n+When a user complains that a particular request they made at noon was slow,\n+especially if you can't reproduce that slowness in your development or staging environment.\n+\n+[float]\n+==== Advantages\n+\n+* **No need to know what methods to monitor**:\n+Find slow methods without specifying specific method names up front.\n+The profiler automatically bubbles up slow methods as spans in the APM app.\n+* **Low overhead. Production ready**:\n+The profiler-based approach is designed to be low-overhead enough to run in production;\n+Continuously run it to provide insights into slow methods.\n+\n+[float]\n+==== How to enable inferred spans with async-profiler\n+\n+Enable inferred spans by setting <<config-profiling-inferred-spans-enabled,`profiling_inferred_spans_enabled`>> to `true`.\n+\n+**Tune stack trace frequency**\n+\n+Tune the frequency at which stack traces are gathered within a profiling session by adjusting\n+<<config-profiling-inferred-spans-sampling-interval,`profiling_inferred_spans_sampling_interval`>>.\n+The lower the sampling interval, the higher the accuracy and the level of detail of the inferred spans.\n+Of course, the higher the level of detail, the higher the profiler overhead and the Elasticsearch index sizes.\n+As most of the processing is done in the background, the impact on the response time of user requests is negligible.\n+\n+**Clean up clutter in the APM app**\n+\n+Filter out inferred spans that are faster than the configured threshold,\n+and avoid cluttering the APM app with fast-executing methods by setting\n+<<config-profiling-inferred-spans-min-duration,`profiling_inferred_spans_min_duration`>>.\n+\n+**Include and exclude specific classes**\n+\n+Include and exclude specific classes explicitly with\n+<<config-profiling-inferred-spans-included-classes,`profiling_inferred_spans_included_classes`>> and\n+<<config-profiling-inferred-spans-excluded-classes,`profiling_inferred_spans_excluded_classes`>>.\n+Generally, the fewer classes that are included, the faster and the more memory efficient the processing is.\n+\n+By default, the classes from the JDK and from most application servers are excluded. This reduces the number of uninteresting inferred spans.\n+\n+**Example `elasticapm.properties` file with inferred spans enabled**\n+\n+[source,properties]\n+----\n+profiling_inferred_spans_enabled=true\n+profiling_inferred_spans_sampling_interval=50ms\n+profiling_inferred_spans_min_duration=25ms\n+profiling_inferred_spans_included_classes=org.example.myapp.*\n+profiling_inferred_spans_excluded_classes=(?-i)java.*\n+----\n+\n+[float]\n+==== Caveats\n+\n+Inferred spans are estimations, not exact measurements.\n+They may start after the method actually started, and end before the method actually ended.\n+This can lead to inconsistencies, all of which are documented in the\n+https://github.com/elastic/apm-agent-java/tree/master/apm-agent-plugins/apm-profiling-plugin[apm-profiling-plugin readme].\n+\n+// Inferred spans are created after the profiling session ends and therefor may appear later in the APM app's span timeline than regular spans.\n+// Because of this, a regular span cannot be the child of an inferred span.\n+\n+//********************************************\n+[[method-api]]\n+=== API/Code\n+\n+Use the <<api-span,span API>> to manually create spans for methods of interest.\n+The API is extremely flexible, and offers the ability to customize your spans,\n+by adding labels to them, or by changing the type, name, or timestamp.\n+\n+TIP: OpenTracing fan? You can use the <<opentracing-bridge,OpenTracing API>>, instead of the Agent API,\n+to manually create spans.\n+\n+[float]\n+==== How to create spans with the span API\n+\n+. Get the current span with <<api-current-span,`currentSpan()`>>,\n+which may or may not have been created with auto-instrumentation.\n+. Create a child span with <<api-span-start-span,`startSpan()`>>.\n+. Customize the span with the <<api-span,span API>>.\n+\n+[source,java]\n+----\n+import co.elastic.apm.api.ElasticApm;\n+import co.elastic.apm.api.Span;\n+\n+Span parent = ElasticApm.currentSpan(); <1>\n+Span span = parent.startSpan(); <2>\n+try {\n+    span.setName(\"SELECT FROM customer\"); <3>\n+    span.addLabel(\"foo\", \"bar\"); <4>\n+    // do your thing...\n+} catch (Exception e) {\n+    span.captureException(e);\n+    throw e;\n+} finally {\n+    span.end();\n+}\n+----\n+<1> Get current span\n+<2> Create a child span\n+<3> Override the default span name\n+<4> Add labels to the span\n+\n+[float]\n+==== Combine with annotations\n+\n+// This section is copied from the <<method-annotations>> documentation\n+include::method-monitoring.asciidoc[tag=combine-api-annotations]\n+\n+//********************************************\n+[[method-annotations]]\n+=== Annotations\n+\n+The <<api-annotation,annotation API>> allows you to place annotations on top of methods to automatically create spans for them.\n+This method of creating spans is easier, more robust, and typically more performant than using the API;\n+there\u2019s nothing you can do wrong like forgetting to end a span or close a scope.\n+\n+Annotations are less flexible when used on their own, but can be combined with the span API for added flexibility.\n+\n+[float]\n+==== How-to create spans with the annotations API\n+\n+Here's an example that uses the <<api-capture-span,`@CaptureSpan`>> annotation to create a span for the `spanWithAnnotation()` method.\n+The span is named `spanName`, is of type `ext`, and subtype `http`.\n+\n+[source,java]\n+----\n+@CaptureSpan(value = \"spanName\", type = \"ext\", subtype = \"http\")\n+private static void spanWithAnnotation() {\n+    // do your thing...\n+}\n+----\n+\n+[float]\n+==== Combine with the span API\n+\n+// This content is also used in the `method-api` documentation\n+// Ensure any changes made here can also apply there.\n+// tag::combine-api-annotations[]\n+You can combine annotations with the span API to increase their flexibility.\n+Just get the current span on an annotated method and customize the span to your liking.\n+\n+[source,java]\n+----\n+@CaptureSpan(value = \"spanName\", type = \"ext\", subtype = \"http\") <1>\n+private static void spanWithAnnotation() {\n+    Span parent = ElasticApm.currentSpan(); <2>\n+    Span span = parent.startSpan(); <3>\n+    try {\n+        // do your thing...\n+    } catch (Exception e) {\n+        span.captureException(e);\n+        throw e;\n+    } finally {\n+        span.end();\n+    }\n+}\n+----\n+<1> Use `@CaptureSpan` annotation to create a span\n+<2> Get the current span\n+<3> Start a child span\n+// end::combine-api-annotations[]\n+\n+//********************************************\n+[[method-config-based]]\n+=== Configuration-based\n+\n+Use the <<config-trace-methods,`trace_methods`>> configuration option to specify additional methods to instrument.\n+You can match methods via wildcards in the package, class or method name, by their modifier (like public),\n+by a particular annotation, and more.\n+Because you don\u2019t need to modify your source code, this makes it possible to monitor code in 3rd party libraries.\n+\n+Be careful, it's easy to overuse `trace_methods` by matching too many methods--hurting both runtime and startup performance.\n+Use in conjunction with <<config-trace-methods-duration-threshold,`trace_methods_duration_threshold`>> when setting for entire packages\n+in order to reduce overhead and avoid having too many spans in the APM app.\n+\n+[float]\n+==== How-to create spans with `trace_methods`\n+\n+// I don't really understand this.\n+// Just gonna put some dance emojis here for now \ud83d\udc83\ud83d\udd7a\ud83d\udc83\ud83d\udd7a\ud83d\udc83\ud83d\udd7a\n+// Move from configuration to here?", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk3MzU3Ng=="}, "originalCommit": {"oid": "6134df2505237285b6b805583632a0fb85b7290c"}, "originalPosition": 269}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzMjgwNDYyOnYy", "diffSide": "RIGHT", "path": "docs/method-monitoring.asciidoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwODo1NDo1NVrOGFEvtQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwODo1NDo1NVrOGFEvtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk3MzgxMw==", "bodyText": "\ud83d\ude04", "url": "https://github.com/elastic/apm-agent-java/pull/1135#discussion_r407973813", "createdAt": "2020-04-14T08:54:55Z", "author": {"login": "felixbarny"}, "path": "docs/method-monitoring.asciidoc", "diffHunk": "@@ -0,0 +1,282 @@\n+[[java-method-monitoring]]\n+== How to find slow methods\n+\n+Identifying a problematic service is only half of the battle when diagnosing application slowdowns.\n+Luckily, the Elastic APM Java Agent provides multiple ways to get method-level insights into your code.\n+This can help you diagnose slow requests due to heavy computations, inefficient algorithms,\n+or similar problems not related to interactions between services.\n+\n+[float]\n+==== _If you don't know which methods you want to monitor..._\n+\n+[float]\n+===== Sampling-based profiler\n+\n+Find out which part of your code is making your application slow;\n+periodically record running methods with a sampling-based profiler.\n+\n+image:./images/green-check.svg[] Very low overhead. +\n+image:./images/green-check.svg[] No code changes required. +\n+image:./images/red-x.svg[] Does not work on Windows. +\n+image:./images/red-x.svg[] The duration of profiler-inferred spans are not exact measurements, only estimates.\n+\n+<<method-sampling-based,Learn more>>\n+\n+[float]\n+==== _If you know which methods you want to monitor..._\n+\n+[float]\n+===== API/Code\n+\n+Use the API or OpenTracing bridge to manually create spans for methods of interest.\n+\n+image:./images/green-check.svg[] Most flexible. +\n+image:./images/red-x.svg[] Incorrect API usage may lead to invalid traces (scope leaks).\n+\n+<<method-api,Learn more>>\n+\n+[float]\n+===== Annotations\n+\n+Annotations can be placed on top of methods to automatically create spans for them.\n+\n+image:./images/green-check.svg[]Easier and more robust than the API. +\n+image:./images/red-x.svg[]Less flexible on its own, but can be combined with the API\n+\n+<<method-annotations,Learn more>>\n+\n+[float]\n+===== Configuration-based\n+\n+Use a configuration option to specify additional methods to instrument.\n+\n+image:./images/green-check.svg[]  No need to modify source code. +\n+image:./images/green-check.svg[] Possible to monitor code in third-party libraries +\n+image:./images/green-check.svg[] Match methods via wildcards +\n+image:./images/red-x.svg[] Easy to overuse which hurts runtime and startup performance.\n+\n+<<method-config-based,Learn more>>\n+\n+//********************************************\n+[[method-sampling-based]]\n+=== Sampling-based profiler\n+\n+experimental::[]\n+added::[1.14.0]\n+\n+Instead of recording every event, leverage https://github.com/jvm-profiling-tools/async-profiler[async-profiler]\n+to periodically request the stack trace from all actively running threads.\n+This means measurements do not need to be inserted into all methods, which keeps the overhead of this approach extremely low.\n+Stack traces are then correlated with span activation events, and profiler-inferred spans for slow methods are created.\n+Just like that, we've detected exactly what is executing between current transactions and spans.\n+\n+// Show simple example from Blog?\n+// BEFORE:: WelcomeController#welcome\n+// AFTER:: WelcomeController#think\n+// https://www.elastic.co/blog/from-distributed-tracing-to-distributed-profiling-with-elastic-apm\n+\n+[float]\n+==== Use cases\n+\n+* **Development**:\n+When trying to find out why the request you just made was slow.\n+* **Load testing / Production**:\n+When analyzing why some requests are slower than others.\n+* **Customer support**:\n+When a user complains that a particular request they made at noon was slow,\n+especially if you can't reproduce that slowness in your development or staging environment.\n+\n+[float]\n+==== Advantages\n+\n+* **No need to know what methods to monitor**:\n+Find slow methods without specifying specific method names up front.\n+The profiler automatically bubbles up slow methods as spans in the APM app.\n+* **Low overhead. Production ready**:\n+The profiler-based approach is designed to be low-overhead enough to run in production;\n+Continuously run it to provide insights into slow methods.\n+\n+[float]\n+==== How to enable inferred spans with async-profiler\n+\n+Enable inferred spans by setting <<config-profiling-inferred-spans-enabled,`profiling_inferred_spans_enabled`>> to `true`.\n+\n+**Tune stack trace frequency**\n+\n+Tune the frequency at which stack traces are gathered within a profiling session by adjusting\n+<<config-profiling-inferred-spans-sampling-interval,`profiling_inferred_spans_sampling_interval`>>.\n+The lower the sampling interval, the higher the accuracy and the level of detail of the inferred spans.\n+Of course, the higher the level of detail, the higher the profiler overhead and the Elasticsearch index sizes.\n+As most of the processing is done in the background, the impact on the response time of user requests is negligible.\n+\n+**Clean up clutter in the APM app**\n+\n+Filter out inferred spans that are faster than the configured threshold,\n+and avoid cluttering the APM app with fast-executing methods by setting\n+<<config-profiling-inferred-spans-min-duration,`profiling_inferred_spans_min_duration`>>.\n+\n+**Include and exclude specific classes**\n+\n+Include and exclude specific classes explicitly with\n+<<config-profiling-inferred-spans-included-classes,`profiling_inferred_spans_included_classes`>> and\n+<<config-profiling-inferred-spans-excluded-classes,`profiling_inferred_spans_excluded_classes`>>.\n+Generally, the fewer classes that are included, the faster and the more memory efficient the processing is.\n+\n+By default, the classes from the JDK and from most application servers are excluded. This reduces the number of uninteresting inferred spans.\n+\n+**Example `elasticapm.properties` file with inferred spans enabled**\n+\n+[source,properties]\n+----\n+profiling_inferred_spans_enabled=true\n+profiling_inferred_spans_sampling_interval=50ms\n+profiling_inferred_spans_min_duration=25ms\n+profiling_inferred_spans_included_classes=org.example.myapp.*\n+profiling_inferred_spans_excluded_classes=(?-i)java.*\n+----\n+\n+[float]\n+==== Caveats\n+\n+Inferred spans are estimations, not exact measurements.\n+They may start after the method actually started, and end before the method actually ended.\n+This can lead to inconsistencies, all of which are documented in the\n+https://github.com/elastic/apm-agent-java/tree/master/apm-agent-plugins/apm-profiling-plugin[apm-profiling-plugin readme].\n+\n+// Inferred spans are created after the profiling session ends and therefor may appear later in the APM app's span timeline than regular spans.\n+// Because of this, a regular span cannot be the child of an inferred span.\n+\n+//********************************************\n+[[method-api]]\n+=== API/Code\n+\n+Use the <<api-span,span API>> to manually create spans for methods of interest.\n+The API is extremely flexible, and offers the ability to customize your spans,\n+by adding labels to them, or by changing the type, name, or timestamp.\n+\n+TIP: OpenTracing fan? You can use the <<opentracing-bridge,OpenTracing API>>, instead of the Agent API,\n+to manually create spans.\n+\n+[float]\n+==== How to create spans with the span API\n+\n+. Get the current span with <<api-current-span,`currentSpan()`>>,\n+which may or may not have been created with auto-instrumentation.\n+. Create a child span with <<api-span-start-span,`startSpan()`>>.\n+. Customize the span with the <<api-span,span API>>.\n+\n+[source,java]\n+----\n+import co.elastic.apm.api.ElasticApm;\n+import co.elastic.apm.api.Span;\n+\n+Span parent = ElasticApm.currentSpan(); <1>\n+Span span = parent.startSpan(); <2>\n+try {\n+    span.setName(\"SELECT FROM customer\"); <3>\n+    span.addLabel(\"foo\", \"bar\"); <4>\n+    // do your thing...\n+} catch (Exception e) {\n+    span.captureException(e);\n+    throw e;\n+} finally {\n+    span.end();\n+}\n+----\n+<1> Get current span\n+<2> Create a child span\n+<3> Override the default span name\n+<4> Add labels to the span\n+\n+[float]\n+==== Combine with annotations\n+\n+// This section is copied from the <<method-annotations>> documentation\n+include::method-monitoring.asciidoc[tag=combine-api-annotations]\n+\n+//********************************************\n+[[method-annotations]]\n+=== Annotations\n+\n+The <<api-annotation,annotation API>> allows you to place annotations on top of methods to automatically create spans for them.\n+This method of creating spans is easier, more robust, and typically more performant than using the API;\n+there\u2019s nothing you can do wrong like forgetting to end a span or close a scope.\n+\n+Annotations are less flexible when used on their own, but can be combined with the span API for added flexibility.\n+\n+[float]\n+==== How-to create spans with the annotations API\n+\n+Here's an example that uses the <<api-capture-span,`@CaptureSpan`>> annotation to create a span for the `spanWithAnnotation()` method.\n+The span is named `spanName`, is of type `ext`, and subtype `http`.\n+\n+[source,java]\n+----\n+@CaptureSpan(value = \"spanName\", type = \"ext\", subtype = \"http\")\n+private static void spanWithAnnotation() {\n+    // do your thing...\n+}\n+----\n+\n+[float]\n+==== Combine with the span API\n+\n+// This content is also used in the `method-api` documentation\n+// Ensure any changes made here can also apply there.\n+// tag::combine-api-annotations[]\n+You can combine annotations with the span API to increase their flexibility.\n+Just get the current span on an annotated method and customize the span to your liking.\n+\n+[source,java]\n+----\n+@CaptureSpan(value = \"spanName\", type = \"ext\", subtype = \"http\") <1>\n+private static void spanWithAnnotation() {\n+    Span parent = ElasticApm.currentSpan(); <2>\n+    Span span = parent.startSpan(); <3>\n+    try {\n+        // do your thing...\n+    } catch (Exception e) {\n+        span.captureException(e);\n+        throw e;\n+    } finally {\n+        span.end();\n+    }\n+}\n+----\n+<1> Use `@CaptureSpan` annotation to create a span\n+<2> Get the current span\n+<3> Start a child span\n+// end::combine-api-annotations[]\n+\n+//********************************************\n+[[method-config-based]]\n+=== Configuration-based\n+\n+Use the <<config-trace-methods,`trace_methods`>> configuration option to specify additional methods to instrument.\n+You can match methods via wildcards in the package, class or method name, by their modifier (like public),\n+by a particular annotation, and more.\n+Because you don\u2019t need to modify your source code, this makes it possible to monitor code in 3rd party libraries.\n+\n+Be careful, it's easy to overuse `trace_methods` by matching too many methods--hurting both runtime and startup performance.\n+Use in conjunction with <<config-trace-methods-duration-threshold,`trace_methods_duration_threshold`>> when setting for entire packages\n+in order to reduce overhead and avoid having too many spans in the APM app.\n+\n+[float]\n+==== How-to create spans with `trace_methods`\n+\n+// I don't really understand this.\n+// Just gonna put some dance emojis here for now \ud83d\udc83\ud83d\udd7a\ud83d\udc83\ud83d\udd7a\ud83d\udc83\ud83d\udd7a", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6134df2505237285b6b805583632a0fb85b7290c"}, "originalPosition": 268}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzMjg1MjQ0OnYy", "diffSide": "RIGHT", "path": "docs/method-monitoring.asciidoc", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwOTowNjo0NFrOGFFNRw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxOTozMTo0N1rOGFdxSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk4MTM4Mw==", "bodyText": "Be consistent with the usage of dots", "url": "https://github.com/elastic/apm-agent-java/pull/1135#discussion_r407981383", "createdAt": "2020-04-14T09:06:44Z", "author": {"login": "felixbarny"}, "path": "docs/method-monitoring.asciidoc", "diffHunk": "@@ -0,0 +1,282 @@\n+[[java-method-monitoring]]\n+== How to find slow methods\n+\n+Identifying a problematic service is only half of the battle when diagnosing application slowdowns.\n+Luckily, the Elastic APM Java Agent provides multiple ways to get method-level insights into your code.\n+This can help you diagnose slow requests due to heavy computations, inefficient algorithms,\n+or similar problems not related to interactions between services.\n+\n+[float]\n+==== _If you don't know which methods you want to monitor..._\n+\n+[float]\n+===== Sampling-based profiler\n+\n+Find out which part of your code is making your application slow;\n+periodically record running methods with a sampling-based profiler.\n+\n+image:./images/green-check.svg[] Very low overhead. +\n+image:./images/green-check.svg[] No code changes required. +\n+image:./images/red-x.svg[] Does not work on Windows. +\n+image:./images/red-x.svg[] The duration of profiler-inferred spans are not exact measurements, only estimates.\n+\n+<<method-sampling-based,Learn more>>\n+\n+[float]\n+==== _If you know which methods you want to monitor..._\n+\n+[float]\n+===== API/Code\n+\n+Use the API or OpenTracing bridge to manually create spans for methods of interest.\n+\n+image:./images/green-check.svg[] Most flexible. +\n+image:./images/red-x.svg[] Incorrect API usage may lead to invalid traces (scope leaks).\n+\n+<<method-api,Learn more>>\n+\n+[float]\n+===== Annotations\n+\n+Annotations can be placed on top of methods to automatically create spans for them.\n+\n+image:./images/green-check.svg[]Easier and more robust than the API. +\n+image:./images/red-x.svg[]Less flexible on its own, but can be combined with the API", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6134df2505237285b6b805583632a0fb85b7290c"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODM4MzgxOA==", "bodyText": "\ud83d\ude28", "url": "https://github.com/elastic/apm-agent-java/pull/1135#discussion_r408383818", "createdAt": "2020-04-14T19:31:47Z", "author": {"login": "bmorelli25"}, "path": "docs/method-monitoring.asciidoc", "diffHunk": "@@ -0,0 +1,282 @@\n+[[java-method-monitoring]]\n+== How to find slow methods\n+\n+Identifying a problematic service is only half of the battle when diagnosing application slowdowns.\n+Luckily, the Elastic APM Java Agent provides multiple ways to get method-level insights into your code.\n+This can help you diagnose slow requests due to heavy computations, inefficient algorithms,\n+or similar problems not related to interactions between services.\n+\n+[float]\n+==== _If you don't know which methods you want to monitor..._\n+\n+[float]\n+===== Sampling-based profiler\n+\n+Find out which part of your code is making your application slow;\n+periodically record running methods with a sampling-based profiler.\n+\n+image:./images/green-check.svg[] Very low overhead. +\n+image:./images/green-check.svg[] No code changes required. +\n+image:./images/red-x.svg[] Does not work on Windows. +\n+image:./images/red-x.svg[] The duration of profiler-inferred spans are not exact measurements, only estimates.\n+\n+<<method-sampling-based,Learn more>>\n+\n+[float]\n+==== _If you know which methods you want to monitor..._\n+\n+[float]\n+===== API/Code\n+\n+Use the API or OpenTracing bridge to manually create spans for methods of interest.\n+\n+image:./images/green-check.svg[] Most flexible. +\n+image:./images/red-x.svg[] Incorrect API usage may lead to invalid traces (scope leaks).\n+\n+<<method-api,Learn more>>\n+\n+[float]\n+===== Annotations\n+\n+Annotations can be placed on top of methods to automatically create spans for them.\n+\n+image:./images/green-check.svg[]Easier and more robust than the API. +\n+image:./images/red-x.svg[]Less flexible on its own, but can be combined with the API", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk4MTM4Mw=="}, "originalCommit": {"oid": "6134df2505237285b6b805583632a0fb85b7290c"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzODUwOTM5OnYy", "diffSide": "RIGHT", "path": "docs/index.asciidoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQxNDoxMzowN1rOGF7s4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQxNDoxMzowN1rOGF7s4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODg3NDIxMQ==", "bodyText": "neat!", "url": "https://github.com/elastic/apm-agent-java/pull/1135#discussion_r408874211", "createdAt": "2020-04-15T14:13:07Z", "author": {"login": "felixbarny"}, "path": "docs/index.asciidoc", "diffHunk": "@@ -6,6 +6,9 @@ NOTE: For the best reading experience,\n please view this documentation at https://www.elastic.co/guide/en/apm/agent/java[elastic.co]\n endif::[]\n \n+:y: image:./images/green-check.svg[]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6a648a739b8ed92972154a1ef86223b345b41491"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzODUzOTgxOnYy", "diffSide": "RIGHT", "path": "docs/method-monitoring.asciidoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQxNDoxOTozNVrOGF7_xQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQxNDoxOTozNVrOGF7_xQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODg3OTA0NQ==", "bodyText": "It doesn't improve performance a lot so better not mention it to not give a false sense of security\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            in order to reduce overhead and avoid having too many spans in the APM app.\n          \n          \n            \n            in order to avoid having too many spans in the APM app.", "url": "https://github.com/elastic/apm-agent-java/pull/1135#discussion_r408879045", "createdAt": "2020-04-15T14:19:35Z", "author": {"login": "felixbarny"}, "path": "docs/method-monitoring.asciidoc", "diffHunk": "@@ -0,0 +1,258 @@\n+[[java-method-monitoring]]\n+== How to find slow methods\n+\n+Identifying a problematic service is only half of the battle when diagnosing application slowdowns.\n+Luckily, the Elastic APM Java Agent provides multiple ways to get method-level insights into your code.\n+This can help you diagnose slow requests due to heavy computations, inefficient algorithms,\n+or similar problems not related to interactions between services.\n+\n+[float]\n+==== _If you don't know which methods you want to monitor..._\n+\n+[float]\n+===== Sampling-based profiler\n+\n+Find out which part of your code is making your application slow by\n+periodically recording running methods with a sampling-based profiler.\n+\n+{y} Very low overhead. +\n+{y} No code changes required. +\n+{n} Does not work on Windows. +\n+{n} The duration of profiler-inferred spans are not exact measurements, only estimates.\n+\n+<<method-sampling-based,Learn more>>\n+\n+[float]\n+==== _If you know which methods you want to monitor..._\n+\n+[float]\n+===== API/Code\n+\n+Use the API or OpenTracing bridge to manually create spans for methods of interest.\n+\n+{y} Most flexible. +\n+{n} Incorrect API usage may lead to invalid traces (scope leaks).\n+\n+<<method-api,Learn more>>\n+\n+[float]\n+===== Annotations\n+\n+Annotations can be placed on top of methods to automatically create spans for them.\n+\n+{y} Easier and more robust than the API. +\n+{n} Less flexible on its own, but can be combined with the API.\n+\n+<<method-annotations,Learn more>>\n+\n+[float]\n+===== Configuration-based\n+\n+Use a configuration option to specify additional methods to instrument.\n+\n+{y} No need to modify source code. +\n+{y} Possible to monitor code in third-party libraries. +\n+{y} Match methods via wildcards. +\n+{n} Easy to overuse which hurts runtime and startup performance.\n+\n+<<method-config-based,Learn more>>\n+\n+//********************************************\n+[[method-sampling-based]]\n+=== Sampling-based profiler\n+\n+experimental::[]\n+added::[1.14.0]\n+\n+Instead of recording every event, leverage the agent's built-in integration with\n+https://github.com/jvm-profiling-tools/async-profiler[async-profiler]\n+to periodically request the stack trace from all actively running threads.\n+This means measurements do not need to be inserted into all methods, which keeps the overhead of this approach extremely low.\n+Stack traces are then correlated with span activation events, and profiler-inferred spans for slow methods are created.\n+Just like that, we've detected exactly what is executing between current transactions and spans.\n+\n+// Show simple example from Blog?\n+// BEFORE:: WelcomeController#welcome\n+// AFTER:: WelcomeController#think\n+// https://www.elastic.co/blog/from-distributed-tracing-to-distributed-profiling-with-elastic-apm\n+\n+[float]\n+==== Use cases\n+\n+* **Development**:\n+When trying to find out why the request you just made was slow.\n+* **Load testing / Production**:\n+When analyzing why some requests are slower than others.\n+* **Customer support**:\n+When a user complains that a particular request they made at noon was slow,\n+especially if you can't reproduce that slowness in your development or staging environment.\n+\n+[float]\n+==== Advantages\n+\n+* **No need to know what methods to monitor**:\n+Find slow methods without specifying specific method names up front.\n+The profiler automatically bubbles up slow methods as spans in the APM app.\n+* **Low overhead. Production ready**:\n+The profiler-based approach is designed to be low-overhead enough to run in production;\n+Continuously run it to provide insights into slow methods.\n+\n+[float]\n+==== How to enable inferred spans with async-profiler\n+\n+Enable inferred spans by setting <<config-profiling-inferred-spans-enabled,`profiling_inferred_spans_enabled`>> to `true`.\n+\n+**Tune stack trace frequency**\n+\n+Tune the frequency at which stack traces are gathered within a profiling session by adjusting\n+<<config-profiling-inferred-spans-sampling-interval,`profiling_inferred_spans_sampling_interval`>>.\n+The lower the sampling interval, the higher the accuracy and the level of detail of the inferred spans.\n+Of course, the higher the level of detail, the higher the profiler overhead and the Elasticsearch index sizes.\n+As most of the processing is done in the background, the impact on the response time of user requests is negligible.\n+\n+**Clean up clutter in the APM app**\n+\n+Filter out inferred spans that are faster than the configured threshold,\n+and avoid cluttering the APM app with fast-executing methods by setting\n+<<config-profiling-inferred-spans-min-duration,`profiling_inferred_spans_min_duration`>>.\n+\n+**Include and exclude specific classes**\n+\n+Include classes explicitly with <<config-profiling-inferred-spans-included-classes,`profiling_inferred_spans_included_classes`>>;\n+exclude with <<config-profiling-inferred-spans-excluded-classes,`profiling_inferred_spans_excluded_classes`>>.\n+Generally, the fewer classes that are included, the faster and the more memory efficient the processing is.\n+\n+By default, the classes from the JDK and from most application servers are excluded. This reduces the number of uninteresting inferred spans.\n+\n+**Example `elasticapm.properties` file with inferred spans enabled**\n+\n+[source,properties]\n+----\n+profiling_inferred_spans_enabled=true\n+profiling_inferred_spans_sampling_interval=50ms\n+profiling_inferred_spans_min_duration=250ms\n+profiling_inferred_spans_included_classes=org.example.myapp.*\n+profiling_inferred_spans_excluded_classes=org.example.myapp.ignoreme.*\n+----\n+\n+[float]\n+==== Caveats\n+\n+Inferred spans are estimations, not exact measurements.\n+They may start after the method actually started, and end before the method actually ended.\n+This can lead to inconsistencies, all of which are documented in the\n+https://github.com/elastic/apm-agent-java/tree/master/apm-agent-plugins/apm-profiling-plugin[apm-profiling-plugin readme].\n+\n+// Inferred spans are created after the profiling session ends and therefor may appear later in the APM app's span timeline than regular spans.\n+// Because of this, a regular span cannot be the child of an inferred span.\n+\n+//********************************************\n+[[method-api]]\n+=== API/Code\n+\n+Use the <<api-span,span API>> to manually create spans for methods of interest.\n+The API is extremely flexible, and offers the ability to customize your spans,\n+by adding labels to them, or by changing the type, name, or timestamp.\n+\n+TIP: OpenTracing fan? You can use the <<opentracing-bridge,OpenTracing API>>, instead of the Agent API,\n+to manually create spans.\n+\n+[float]\n+==== How to create spans with the span API\n+\n+. Get the current span with <<api-current-span,`currentSpan()`>>,\n+which may or may not have been created with auto-instrumentation.\n+. Create a child span with <<api-span-start-span,`startSpan()`>>.\n+. Activate the span with <<api-span-activate,`activate()`>>.\n+. Customize the span with the <<api-span,span API>>.\n+\n+[source,java]\n+----\n+import co.elastic.apm.api.ElasticApm;\n+import co.elastic.apm.api.Span;\n+\n+Span parent = ElasticApm.currentSpan(); <1>\n+Span span = parent.startSpan(); <2>\n+try (Scope scope = span.activate()) { <3>\n+    span.setName(\"SELECT FROM customer\"); <4>\n+    span.addLabel(\"foo\", \"bar\"); <5>\n+    // do your thing...\n+} catch (Exception e) {\n+    span.captureException(e);\n+    throw e;\n+} finally {\n+    span.end();\n+}\n+----\n+<1> Get current span\n+<2> Create a child span\n+<3> Make this span the active span on the current thread\n+<4> Override the default span name\n+<5> Add labels to the span\n+\n+[float]\n+==== Combine with annotations\n+\n+// This section is sourced from the <<method-annotations>> documentation\n+include::method-monitoring.asciidoc[tag=combine-api-annotations]\n+\n+//********************************************\n+[[method-annotations]]\n+=== Annotations\n+\n+The <<api-annotation,annotation API>> allows you to place annotations on top of methods to automatically create spans for them.\n+This method of creating spans is easier, more robust, and typically more performant than using the API;\n+there\u2019s nothing you can do wrong like forgetting to end a span or close a scope.\n+\n+Annotations are less flexible when used on their own, but can be combined with the span API for added flexibility.\n+\n+[float]\n+==== How-to create spans with the annotations API\n+\n+Here's an example that uses the <<api-capture-span,`@CaptureSpan`>> annotation to create a span for the `spanWithAnnotation()` method.\n+The span is named `spanName`, is of type `ext`, and subtype `http`.\n+\n+[source,java]\n+----\n+@CaptureSpan(value = \"spanName\", type = \"ext\", subtype = \"http\")\n+private static void spanWithAnnotation() {\n+    // do your thing...\n+}\n+----\n+\n+[float]\n+==== Combine with the span API\n+\n+// This content is also used in the `method-api` documentation\n+// Ensure any changes made here can also apply there.\n+// tag::combine-api-annotations[]\n+You can combine annotations with the span API to increase their flexibility.\n+Just get the current span on an annotated method and customize the span to your liking.\n+\n+[source,java]\n+----\n+@CaptureSpan <1>\n+private static void spanWithAnnotation(String foo) {\n+    Span span = ElasticApm.currentSpan(); <2>\n+    span.setTag(\"foo\", foo); <3>\n+}\n+----\n+<1> Use `@CaptureSpan` annotation to create a span\n+<2> Get the current span (the one created via the `@CaptureSpan` annotation)\n+<3> Customize the span\n+// end::combine-api-annotations[]\n+\n+//********************************************\n+[[method-config-based]]\n+=== Configuration-based\n+\n+Use the <<config-trace-methods,`trace_methods`>> configuration option to specify additional methods to instrument.\n+You can match methods via wildcards in the package, class or method name, by their modifier (like public),\n+by a particular annotation, and more.\n+Because you don\u2019t need to modify your source code, this makes it possible to monitor code in 3rd party libraries.\n+\n+Be careful, it's easy to overuse `trace_methods` by matching too many methods--hurting both runtime and startup performance.\n+Use in conjunction with <<config-trace-methods-duration-threshold,`trace_methods_duration_threshold`>> when setting for entire packages\n+in order to reduce overhead and avoid having too many spans in the APM app.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6a648a739b8ed92972154a1ef86223b345b41491"}, "originalPosition": 256}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 272, "cost": 1, "resetAt": "2021-11-12T18:49:56Z"}}}