{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQxNjcxMjcy", "number": 76, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxNjoxOTowMVrOEKLKng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxOTo0MTowN1rOEKQBbg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5MTA0MTU4OnYy", "diffSide": "RIGHT", "path": "tools/unsupervised_dataset/sql_crawler/extraction_modules/generic_extraction_module.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxNjoxOTowMVrOGrEM4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxOTo0MToyMFrOGrLxBA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzgxMDc4Ng==", "bodyText": "Maybe define this as a separate const string. I think this can be longer in the future when you cover insert, update, merge, etc.", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/76#discussion_r447810786", "createdAt": "2020-06-30T16:19:01Z", "author": {"login": "yzhvictor"}, "path": "tools/unsupervised_dataset/sql_crawler/extraction_modules/generic_extraction_module.py", "diffHunk": "@@ -1,8 +1,32 @@\n-class GenericExtractionModule(object):\n+\"\"\" Collects SQL queries from any website \"\"\"\n+import html\n+import re\n+\n+class GenericExtractionModule():\n     \"\"\" A module to extract SQL queries from any website without knowing the HTML\n         format of a site.\n     \"\"\"\n \n-    def find_queries(html):\n-        #TODO(Noah): Implement generic module\n-        return []\n+    def find_queries(html_response):\n+        \"\"\" Finds queries and extracts them from any website, without using HTML\n+        tags to locate them.\n+\n+        Args:\n+            html: HTML response which contains HTML text\n+\n+        Returns\n+            A list of queries in the form of strings.\n+        \"\"\"\n+        # Remove HTML tags and special characters\n+        content = html_response.text\n+        converted = html.unescape(content)\n+        tags_removed = re.sub('<[^<]+?>', '', converted)\n+\n+        # Look for text that matches common SQL queries\n+        matches = re.findall(r\"(?:SELECT|WITH|CREATE)[^;]*;\", tags_removed)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dba354ec2fd8ba2df8caa1cae3bd6d9009cc2dfd"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzkzNDcyNA==", "bodyText": "+1", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/76#discussion_r447934724", "createdAt": "2020-06-30T19:41:20Z", "author": {"login": "kikkyo"}, "path": "tools/unsupervised_dataset/sql_crawler/extraction_modules/generic_extraction_module.py", "diffHunk": "@@ -1,8 +1,32 @@\n-class GenericExtractionModule(object):\n+\"\"\" Collects SQL queries from any website \"\"\"\n+import html\n+import re\n+\n+class GenericExtractionModule():\n     \"\"\" A module to extract SQL queries from any website without knowing the HTML\n         format of a site.\n     \"\"\"\n \n-    def find_queries(html):\n-        #TODO(Noah): Implement generic module\n-        return []\n+    def find_queries(html_response):\n+        \"\"\" Finds queries and extracts them from any website, without using HTML\n+        tags to locate them.\n+\n+        Args:\n+            html: HTML response which contains HTML text\n+\n+        Returns\n+            A list of queries in the form of strings.\n+        \"\"\"\n+        # Remove HTML tags and special characters\n+        content = html_response.text\n+        converted = html.unescape(content)\n+        tags_removed = re.sub('<[^<]+?>', '', converted)\n+\n+        # Look for text that matches common SQL queries\n+        matches = re.findall(r\"(?:SELECT|WITH|CREATE)[^;]*;\", tags_removed)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzgxMDc4Ng=="}, "originalCommit": {"oid": "dba354ec2fd8ba2df8caa1cae3bd6d9009cc2dfd"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5MTA0NDQzOnYy", "diffSide": "RIGHT", "path": "tools/unsupervised_dataset/sql_crawler/extraction_modules/generic_extraction_module.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxNjoxOTo0NVrOGrEOsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxNjoxOTo0NVrOGrEOsA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzgxMTI0OA==", "bodyText": "Let's always have some test coverage for new code added, thanks.", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/76#discussion_r447811248", "createdAt": "2020-06-30T16:19:45Z", "author": {"login": "yzhvictor"}, "path": "tools/unsupervised_dataset/sql_crawler/extraction_modules/generic_extraction_module.py", "diffHunk": "@@ -1,8 +1,32 @@\n-class GenericExtractionModule(object):\n+\"\"\" Collects SQL queries from any website \"\"\"\n+import html\n+import re\n+\n+class GenericExtractionModule():\n     \"\"\" A module to extract SQL queries from any website without knowing the HTML\n         format of a site.\n     \"\"\"\n \n-    def find_queries(html):\n-        #TODO(Noah): Implement generic module\n-        return []\n+    def find_queries(html_response):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dba354ec2fd8ba2df8caa1cae3bd6d9009cc2dfd"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5MTgzNzI2OnYy", "diffSide": "RIGHT", "path": "tools/unsupervised_dataset/sql_crawler/extractor.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxOTo0MTowN1rOGrLwiw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxOTo0MTowN1rOGrLwiw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzkzNDYwMw==", "bodyText": "Use const string too?", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/76#discussion_r447934603", "createdAt": "2020-06-30T19:41:07Z", "author": {"login": "kikkyo"}, "path": "tools/unsupervised_dataset/sql_crawler/extractor.py", "diffHunk": "@@ -64,5 +64,4 @@ def retrieve_module(url):\n     if \"cloud.google.com\" in url:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dba354ec2fd8ba2df8caa1cae3bd6d9009cc2dfd"}, "originalPosition": 1}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2966, "cost": 1, "resetAt": "2021-11-12T19:05:54Z"}}}