{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU0Nzk1ODA1", "number": 113, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMDo0Njo1OVrOEQ2PJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwNTowNzo0MFrOEQ5ApQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2MTAxMjg2OnYy", "diffSide": "RIGHT", "path": "tools/query_verification/src/main/java/com/google/bigquery/Main.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMDo0Njo1OVrOG1OwGw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMDo0Njo1OVrOG1OwGw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ2OTQwMw==", "bodyText": "Maybe we should log that the file is being skipped.", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/113#discussion_r458469403", "createdAt": "2020-07-22T00:46:59Z", "author": {"login": "Luminarys"}, "path": "tools/query_verification/src/main/java/com/google/bigquery/Main.java", "diffHunk": "@@ -82,9 +89,22 @@ public static void main(String[] args) {\n \n         // Data input handling\n         if (command.hasOption(\"d\")) {\n-            // TODO Data input for data aware verification\n+            String[] dataOptionValues = command.getOptionValues(\"d\");\n+\n+            for (String dataFilePath : dataOptionValues) {\n+                String dataFileName = new File(dataFilePath).getName();\n+                String dataContents = getContentsOfFile(dataFilePath);\n+\n+                // Check file format\n+                if (dataFileName.substring(dataFileName.lastIndexOf(\".\") + 1).toLowerCase().equals(\"csv\")) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a02071e61075470959c0faec496fe2bb2f487902"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2MTA1NDEyOnYy", "diffSide": "RIGHT", "path": "tools/query_verification/src/main/java/com/google/bigquery/QueryVerifier.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMToxMDowMFrOG1PH6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwMToxMDowMFrOG1PH6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ3NTQ5OA==", "bodyText": "Can we get more context from this than just the fact it was interrupted", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/113#discussion_r458475498", "createdAt": "2020-07-22T01:10:00Z", "author": {"login": "Luminarys"}, "path": "tools/query_verification/src/main/java/com/google/bigquery/QueryVerifier.java", "diffHunk": "@@ -113,11 +93,122 @@ public void verifyDataFree() {\n      * Verifies migrated query by sending query jobs to BQ and TD to check for differences in the query results.\n      */\n     public void verifyDataAware() {\n-        boolean verificationResult = false;\n+        List<Table> tables = getBigQueryTablesFromSchema();\n+        populateBigQueryTablesFromData(tables);\n+\n+        // Create query jobs\n+        List<JobInfo> jobInfos = getJobInfosFromQuery(migratedQuery, false);\n+\n+        // Store results from every job\n+        List<QueryJobResults<TableResult>> bigQueryJobResults = new ArrayList<QueryJobResults<TableResult>>();\n+\n+        for (int i = 0; i < jobInfos.size(); i++) {\n+            JobInfo jobInfo = jobInfos.get(i);\n+\n+            // Retrieve query\n+            QueryJobConfiguration queryJobConfiguration = jobInfo.getConfiguration();\n+            String query = queryJobConfiguration.getQuery();\n+\n+            QueryJobResults results = null;\n+            try {\n+                // Run query job\n+                Job queryJob = bigQuery.create(jobInfo);\n+\n+                results = QueryJobResults.create(query, queryJob.getQueryResults());\n+            } catch (BigQueryException | InterruptedException e) {\n+                // Print out syntax/semantic errors returned from BQ\n+                System.out.printf(\"Error in Query #%d from %s\\n%s\\n\\n\", i, migratedQuery.path(), e.getMessage());\n+            } finally {\n+                // Store results\n+                bigQueryJobResults.add(results);\n+            }\n+        }\n+\n+        // Clear tables created\n+        tables.forEach(table -> BigQueryOptions.getDefaultInstance().getService().delete(table.getTableId()));\n+\n+        // TODO Run queries in TD\n \n-        // TODO Implement data aware verification\n+        // TODO Compare results\n \n-        System.out.printf(\"Data-Aware Verification %s\\n\", verificationResult ? \"Succeeded\" : \"Failed\");\n+        bigQueryJobResults.removeIf(Objects::isNull);\n+\n+        System.out.println();\n+        System.out.printf(\"%d/%d (%.2f%%) Queries Verified\\n\", bigQueryJobResults.size(), jobInfos.size(), bigQueryJobResults.size() * 100.0f / jobInfos.size());\n+        System.out.printf(\"Data-Aware Verification %s\\n\", bigQueryJobResults.size() == jobInfos.size() ? \"Succeeded\" : \"Failed\");\n+    }\n+\n+    /**\n+     * Creates BQ tables based on the provided schema\n+     * @return List of newly created tables\n+     */\n+    public List<Table> getBigQueryTablesFromSchema() {\n+        List<Table> tables = new ArrayList<Table>();\n+\n+        if (migratedSchema != null) {\n+            if (migratedSchema.isInJsonFormat()) {\n+                // Schema is JSON\n+                List<TableInfo> tableInfos = QueryVerifier.getTableInfoFromJsonSchema(migratedSchema);\n+                if (tableInfos != null) {\n+                    tableInfos.forEach(tableInfo -> tables.add(bigQuery.create(tableInfo)));\n+                }\n+            } else {\n+                // Schema is DDL\n+                JobInfo jobInfo = configureJob(migratedSchema.schema(), false);\n+                Job schemaJob = bigQuery.create(jobInfo);\n+                try {\n+                    schemaJob.waitFor();\n+                } catch (InterruptedException e) {\n+                    System.out.println(e.getMessage());\n+                }\n+\n+                List<TableId> tableIds = QueryVerifier.getTableIdsFromDdlSchema(migratedSchema);\n+                tableIds.forEach(tableId -> tables.add(bigQuery.getTable(tableId)));\n+            }\n+\n+            if (tables.isEmpty()) {\n+                System.out.println(migratedSchema.path() + \" is not correctly formatted.\");\n+            }\n+        }\n+\n+        return tables;\n+    }\n+\n+    /**\n+     * Populates BQ tables based on the provided table data\n+     * @param tables\n+     */\n+    public void populateBigQueryTablesFromData(List<Table> tables) {\n+        for (QueryVerificationData queryVerificationData : data) {\n+            Table table = bigQuery.getTable(queryVerificationData.datasetName(), queryVerificationData.tableName());\n+\n+            // Check if no schema was provided for this table\n+            if (table == null) {\n+                System.out.println(queryVerificationData.tableName() + \" has no provided schema.\");\n+\n+                // Try to continue verification\n+                continue;\n+            }\n+\n+            TableId tableId = table.getTableId();\n+\n+            // Copy contents of CSV file\n+            WriteChannelConfiguration writeChannelConfiguration = WriteChannelConfiguration.newBuilder(tableId).setFormatOptions(FormatOptions.csv()).build();\n+            TableDataWriteChannel writer = bigQuery.writer(writeChannelConfiguration);\n+            try {\n+                writer.write(ByteBuffer.wrap(queryVerificationData.contents().getBytes()));\n+                writer.close();\n+            } catch (IOException e) {\n+                System.out.println(\"I/O Exception: \" + e.getMessage());\n+            }\n+\n+            // Run table data writing job\n+            try {\n+                writer.getJob().waitFor();\n+            } catch (InterruptedException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a02071e61075470959c0faec496fe2bb2f487902"}, "originalPosition": 202}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2MTQ2MzgyOnYy", "diffSide": "RIGHT", "path": "tools/query_verification/src/main/java/com/google/bigquery/Main.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwNTowNTozNVrOG1S16A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwNTowNTozNVrOG1S16A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODUzNjQyNA==", "bodyText": "Do we really want to check the extension. I feel sometimes although the files are csv format, they don't necessary have .csv extension. I think maybe we can just assume people are providing valid files?", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/113#discussion_r458536424", "createdAt": "2020-07-22T05:05:35Z", "author": {"login": "yzhvictor"}, "path": "tools/query_verification/src/main/java/com/google/bigquery/Main.java", "diffHunk": "@@ -82,9 +89,22 @@ public static void main(String[] args) {\n \n         // Data input handling\n         if (command.hasOption(\"d\")) {\n-            // TODO Data input for data aware verification\n+            String[] dataOptionValues = command.getOptionValues(\"d\");\n+\n+            for (String dataFilePath : dataOptionValues) {\n+                String dataFileName = new File(dataFilePath).getName();\n+                String dataContents = getContentsOfFile(dataFilePath);\n+\n+                // Check file format\n+                if (dataFileName.substring(dataFileName.lastIndexOf(\".\") + 1).toLowerCase().equals(\"csv\")) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a02071e61075470959c0faec496fe2bb2f487902"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2MTQ2NzI1OnYy", "diffSide": "RIGHT", "path": "tools/query_verification/src/main/java/com/google/bigquery/QueryVerifier.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwNTowNzo0MFrOG1S4Cg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxNjozMjowMFrOG2Sctw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODUzNjk3MA==", "bodyText": "consider using logger library instead of system.out", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/113#discussion_r458536970", "createdAt": "2020-07-22T05:07:40Z", "author": {"login": "yzhvictor"}, "path": "tools/query_verification/src/main/java/com/google/bigquery/QueryVerifier.java", "diffHunk": "@@ -113,11 +93,122 @@ public void verifyDataFree() {\n      * Verifies migrated query by sending query jobs to BQ and TD to check for differences in the query results.\n      */\n     public void verifyDataAware() {\n-        boolean verificationResult = false;\n+        List<Table> tables = getBigQueryTablesFromSchema();\n+        populateBigQueryTablesFromData(tables);\n+\n+        // Create query jobs\n+        List<JobInfo> jobInfos = getJobInfosFromQuery(migratedQuery, false);\n+\n+        // Store results from every job\n+        List<QueryJobResults<TableResult>> bigQueryJobResults = new ArrayList<QueryJobResults<TableResult>>();\n+\n+        for (int i = 0; i < jobInfos.size(); i++) {\n+            JobInfo jobInfo = jobInfos.get(i);\n+\n+            // Retrieve query\n+            QueryJobConfiguration queryJobConfiguration = jobInfo.getConfiguration();\n+            String query = queryJobConfiguration.getQuery();\n+\n+            QueryJobResults results = null;\n+            try {\n+                // Run query job\n+                Job queryJob = bigQuery.create(jobInfo);\n+\n+                results = QueryJobResults.create(query, queryJob.getQueryResults());\n+            } catch (BigQueryException | InterruptedException e) {\n+                // Print out syntax/semantic errors returned from BQ\n+                System.out.printf(\"Error in Query #%d from %s\\n%s\\n\\n\", i, migratedQuery.path(), e.getMessage());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a02071e61075470959c0faec496fe2bb2f487902"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU3ODU1MQ==", "bodyText": "As discussed, we'll have a follow up pr to handle logging.", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/113#discussion_r459578551", "createdAt": "2020-07-23T16:32:00Z", "author": {"login": "yzhvictor"}, "path": "tools/query_verification/src/main/java/com/google/bigquery/QueryVerifier.java", "diffHunk": "@@ -113,11 +93,122 @@ public void verifyDataFree() {\n      * Verifies migrated query by sending query jobs to BQ and TD to check for differences in the query results.\n      */\n     public void verifyDataAware() {\n-        boolean verificationResult = false;\n+        List<Table> tables = getBigQueryTablesFromSchema();\n+        populateBigQueryTablesFromData(tables);\n+\n+        // Create query jobs\n+        List<JobInfo> jobInfos = getJobInfosFromQuery(migratedQuery, false);\n+\n+        // Store results from every job\n+        List<QueryJobResults<TableResult>> bigQueryJobResults = new ArrayList<QueryJobResults<TableResult>>();\n+\n+        for (int i = 0; i < jobInfos.size(); i++) {\n+            JobInfo jobInfo = jobInfos.get(i);\n+\n+            // Retrieve query\n+            QueryJobConfiguration queryJobConfiguration = jobInfo.getConfiguration();\n+            String query = queryJobConfiguration.getQuery();\n+\n+            QueryJobResults results = null;\n+            try {\n+                // Run query job\n+                Job queryJob = bigQuery.create(jobInfo);\n+\n+                results = QueryJobResults.create(query, queryJob.getQueryResults());\n+            } catch (BigQueryException | InterruptedException e) {\n+                // Print out syntax/semantic errors returned from BQ\n+                System.out.printf(\"Error in Query #%d from %s\\n%s\\n\\n\", i, migratedQuery.path(), e.getMessage());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODUzNjk3MA=="}, "originalCommit": {"oid": "a02071e61075470959c0faec496fe2bb2f487902"}, "originalPosition": 112}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3052, "cost": 1, "resetAt": "2021-11-12T19:05:54Z"}}}