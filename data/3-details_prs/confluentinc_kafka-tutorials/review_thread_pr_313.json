{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk3ODA4MTk5", "number": 313, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxNzo0NjozOFrODufdDQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QxNzowNjozOFrOEmsmBA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwMDc2NDI5OnYy", "diffSide": "RIGHT", "path": "_includes/tutorials/generate-test-data-streams/kafka/markup/dev/consume-topic-02b.adoc", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxNzo0NjozOFrOGAgqRQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQwOTozOToyOVrOGBPolg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzE4ODI5Mw==", "bodyText": "This file has duplicate content to consume-topic-02a.adoc.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313#discussion_r403188293", "createdAt": "2020-04-03T17:46:38Z", "author": {"login": "bbejeck"}, "path": "_includes/tutorials/generate-test-data-streams/kafka/markup/dev/consume-topic-02b.adoc", "diffHunk": "@@ -0,0 +1,10 @@\n+We now have two Kafka topics being written to. The first (`devices`) is keyed on the MAC address, as can be seen from the data: ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "47c380a1e31e6246e75b4a7022fd0b3da47c0c13"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzk1NzkxMA==", "bodyText": "Good catch, thanks @bbejeck. Fixed.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313#discussion_r403957910", "createdAt": "2020-04-06T09:39:29Z", "author": {"login": "rmoff"}, "path": "_includes/tutorials/generate-test-data-streams/kafka/markup/dev/consume-topic-02b.adoc", "diffHunk": "@@ -0,0 +1,10 @@\n+We now have two Kafka topics being written to. The first (`devices`) is keyed on the MAC address, as can be seen from the data: ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzE4ODI5Mw=="}, "originalCommit": {"oid": "47c380a1e31e6246e75b4a7022fd0b3da47c0c13"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5MDExNzU5OnYy", "diffSide": "RIGHT", "path": "_data/harnesses/generate-test-data-streams/ksql.yml", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QxNzowNjowMFrOHW4Prg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQxMjo0MToxNlrOHXYuVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc1MjIzOA==", "bodyText": "Can you add the CCloud section like the other tutorials?", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313#discussion_r493752238", "createdAt": "2020-09-23T17:06:00Z", "author": {"login": "ybyzek"}, "path": "_data/harnesses/generate-test-data-streams/ksql.yml", "diffHunk": "@@ -0,0 +1,198 @@\n+dev:\n+  steps:\n+    - title: Initialize the project\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/init.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/init.adoc\n+        - action: execute\n+          file: tutorial-steps/dev/make-dirs.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/make-dirs.adoc\n+          stdout: tutorial-steps/dev/outputs/make-dirs.out\n+            \n+    - title: Get Confluent Platform\n+      content:\n+        - action: make_file\n+          file: docker-compose.yml\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/make-docker-compose.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/start-compose.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/wait-for-containers.adoc\n+          stdout: tutorial-steps/dev/outputs/wait-for-containers.out\n+\n+        - action: execute\n+          file: tutorial-steps/dev/check-plugin.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/check-plugin.adoc\n+          stdout: tutorial-steps/dev/outputs/check-plugin.out\n+            \n+    - title: Create a standalone stream of test data\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/create-connector-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/create-connector-01.adoc\n+\n+        - action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/check-connector-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/check-connector-01.adoc\n+            - file: tutorial-steps/dev/describe-connector-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/describe-connector-01.adoc\n+            \n+    - title: Consume events from the test topic\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/consume-topic.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/consume-topic.adoc\n+\n+    - title: Declare the topic as a ksqlDB stream\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 255\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/create-stream-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/create-stream-01.adoc\n+            - file: tutorial-steps/dev/describe-stream-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/describe-stream-01.adoc\n+            - file: tutorial-steps/dev/query-stream-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/query-stream-01.adoc\n+\n+    - title: Create two related streams of test data\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/create-connector-02.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/create-connector-02.adoc\n+\n+        - action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+            \n+    - title: Join the test data streams in ksqlDB\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 255\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/check-connector-02.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/check-connector-02.adoc\n+            - file: tutorial-steps/dev/join-streams-declare.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/join-streams-declare.adoc\n+            - file: tutorial-steps/dev/join-streams-do.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/join-streams-do.adoc\n+\n+    - title: Clean up\n+      content:\n+      - action: execute\n+        file: tutorial-steps/dev/clean-up.sh\n+        render:\n+          file: tutorials/generate-test-data-streams/ksql/markup/dev/clean-up.adoc\n+\n+\n+prod:\n+  steps:\n+    - title: Write your statements to a file\n+      content:\n+        - action: make_file\n+          file: src/statements.sql\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/make-src-file.adoc\n+\n+    - title: Send the statements to the REST endpoint\n+      content:\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            skip: true\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            skip: true\n+\n+        - action: execute\n+          file: tutorial-steps/prod/send-to-api.sh\n+          stdout: tutorial-steps/prod/outputs/send-to-api.out\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/prod/submit-to-api.adoc\n+\n+    - title: Validate the deployment\n+      content:\n+        - action: execute\n+          file: tutorial-steps/prod/check-deploy.sh\n+          stdout: tutorial-steps/prod/outputs/check-deploy.out\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/prod/check-deploy.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/clean-up.sh\n+          render:\n+            skip: true", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dab8d58a03dcbc5f363e62795baac539f57fcc2b"}, "originalPosition": 198}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDE0OTQwNg==", "bodyText": "Voluble isn't available on CCloud", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313#discussion_r494149406", "createdAt": "2020-09-24T08:53:42Z", "author": {"login": "rmoff"}, "path": "_data/harnesses/generate-test-data-streams/ksql.yml", "diffHunk": "@@ -0,0 +1,198 @@\n+dev:\n+  steps:\n+    - title: Initialize the project\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/init.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/init.adoc\n+        - action: execute\n+          file: tutorial-steps/dev/make-dirs.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/make-dirs.adoc\n+          stdout: tutorial-steps/dev/outputs/make-dirs.out\n+            \n+    - title: Get Confluent Platform\n+      content:\n+        - action: make_file\n+          file: docker-compose.yml\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/make-docker-compose.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/start-compose.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/wait-for-containers.adoc\n+          stdout: tutorial-steps/dev/outputs/wait-for-containers.out\n+\n+        - action: execute\n+          file: tutorial-steps/dev/check-plugin.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/check-plugin.adoc\n+          stdout: tutorial-steps/dev/outputs/check-plugin.out\n+            \n+    - title: Create a standalone stream of test data\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/create-connector-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/create-connector-01.adoc\n+\n+        - action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/check-connector-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/check-connector-01.adoc\n+            - file: tutorial-steps/dev/describe-connector-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/describe-connector-01.adoc\n+            \n+    - title: Consume events from the test topic\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/consume-topic.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/consume-topic.adoc\n+\n+    - title: Declare the topic as a ksqlDB stream\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 255\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/create-stream-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/create-stream-01.adoc\n+            - file: tutorial-steps/dev/describe-stream-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/describe-stream-01.adoc\n+            - file: tutorial-steps/dev/query-stream-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/query-stream-01.adoc\n+\n+    - title: Create two related streams of test data\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/create-connector-02.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/create-connector-02.adoc\n+\n+        - action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+            \n+    - title: Join the test data streams in ksqlDB\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 255\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/check-connector-02.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/check-connector-02.adoc\n+            - file: tutorial-steps/dev/join-streams-declare.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/join-streams-declare.adoc\n+            - file: tutorial-steps/dev/join-streams-do.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/join-streams-do.adoc\n+\n+    - title: Clean up\n+      content:\n+      - action: execute\n+        file: tutorial-steps/dev/clean-up.sh\n+        render:\n+          file: tutorials/generate-test-data-streams/ksql/markup/dev/clean-up.adoc\n+\n+\n+prod:\n+  steps:\n+    - title: Write your statements to a file\n+      content:\n+        - action: make_file\n+          file: src/statements.sql\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/make-src-file.adoc\n+\n+    - title: Send the statements to the REST endpoint\n+      content:\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            skip: true\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            skip: true\n+\n+        - action: execute\n+          file: tutorial-steps/prod/send-to-api.sh\n+          stdout: tutorial-steps/prod/outputs/send-to-api.out\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/prod/submit-to-api.adoc\n+\n+    - title: Validate the deployment\n+      content:\n+        - action: execute\n+          file: tutorial-steps/prod/check-deploy.sh\n+          stdout: tutorial-steps/prod/outputs/check-deploy.out\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/prod/check-deploy.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/clean-up.sh\n+          render:\n+            skip: true", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc1MjIzOA=="}, "originalCommit": {"oid": "dab8d58a03dcbc5f363e62795baac539f57fcc2b"}, "originalPosition": 198}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDI0MTM4OQ==", "bodyText": "It doesn't mean we can't run connector locally connected to cloud.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313#discussion_r494241389", "createdAt": "2020-09-24T11:34:26Z", "author": {"login": "gAmUssA"}, "path": "_data/harnesses/generate-test-data-streams/ksql.yml", "diffHunk": "@@ -0,0 +1,198 @@\n+dev:\n+  steps:\n+    - title: Initialize the project\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/init.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/init.adoc\n+        - action: execute\n+          file: tutorial-steps/dev/make-dirs.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/make-dirs.adoc\n+          stdout: tutorial-steps/dev/outputs/make-dirs.out\n+            \n+    - title: Get Confluent Platform\n+      content:\n+        - action: make_file\n+          file: docker-compose.yml\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/make-docker-compose.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/start-compose.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/wait-for-containers.adoc\n+          stdout: tutorial-steps/dev/outputs/wait-for-containers.out\n+\n+        - action: execute\n+          file: tutorial-steps/dev/check-plugin.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/check-plugin.adoc\n+          stdout: tutorial-steps/dev/outputs/check-plugin.out\n+            \n+    - title: Create a standalone stream of test data\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/create-connector-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/create-connector-01.adoc\n+\n+        - action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/check-connector-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/check-connector-01.adoc\n+            - file: tutorial-steps/dev/describe-connector-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/describe-connector-01.adoc\n+            \n+    - title: Consume events from the test topic\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/consume-topic.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/consume-topic.adoc\n+\n+    - title: Declare the topic as a ksqlDB stream\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 255\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/create-stream-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/create-stream-01.adoc\n+            - file: tutorial-steps/dev/describe-stream-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/describe-stream-01.adoc\n+            - file: tutorial-steps/dev/query-stream-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/query-stream-01.adoc\n+\n+    - title: Create two related streams of test data\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/create-connector-02.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/create-connector-02.adoc\n+\n+        - action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+            \n+    - title: Join the test data streams in ksqlDB\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 255\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/check-connector-02.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/check-connector-02.adoc\n+            - file: tutorial-steps/dev/join-streams-declare.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/join-streams-declare.adoc\n+            - file: tutorial-steps/dev/join-streams-do.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/join-streams-do.adoc\n+\n+    - title: Clean up\n+      content:\n+      - action: execute\n+        file: tutorial-steps/dev/clean-up.sh\n+        render:\n+          file: tutorials/generate-test-data-streams/ksql/markup/dev/clean-up.adoc\n+\n+\n+prod:\n+  steps:\n+    - title: Write your statements to a file\n+      content:\n+        - action: make_file\n+          file: src/statements.sql\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/make-src-file.adoc\n+\n+    - title: Send the statements to the REST endpoint\n+      content:\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            skip: true\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            skip: true\n+\n+        - action: execute\n+          file: tutorial-steps/prod/send-to-api.sh\n+          stdout: tutorial-steps/prod/outputs/send-to-api.out\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/prod/submit-to-api.adoc\n+\n+    - title: Validate the deployment\n+      content:\n+        - action: execute\n+          file: tutorial-steps/prod/check-deploy.sh\n+          stdout: tutorial-steps/prod/outputs/check-deploy.out\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/prod/check-deploy.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/clean-up.sh\n+          render:\n+            skip: true", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc1MjIzOA=="}, "originalCommit": {"oid": "dab8d58a03dcbc5f363e62795baac539f57fcc2b"}, "originalPosition": 198}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDI3MDM0Mw==", "bodyText": "@rmoff Voluble is a connector, so it can be run in a self-managed connect cluster to CCloud.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313#discussion_r494270343", "createdAt": "2020-09-24T12:23:07Z", "author": {"login": "ybyzek"}, "path": "_data/harnesses/generate-test-data-streams/ksql.yml", "diffHunk": "@@ -0,0 +1,198 @@\n+dev:\n+  steps:\n+    - title: Initialize the project\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/init.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/init.adoc\n+        - action: execute\n+          file: tutorial-steps/dev/make-dirs.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/make-dirs.adoc\n+          stdout: tutorial-steps/dev/outputs/make-dirs.out\n+            \n+    - title: Get Confluent Platform\n+      content:\n+        - action: make_file\n+          file: docker-compose.yml\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/make-docker-compose.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/start-compose.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/wait-for-containers.adoc\n+          stdout: tutorial-steps/dev/outputs/wait-for-containers.out\n+\n+        - action: execute\n+          file: tutorial-steps/dev/check-plugin.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/check-plugin.adoc\n+          stdout: tutorial-steps/dev/outputs/check-plugin.out\n+            \n+    - title: Create a standalone stream of test data\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/create-connector-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/create-connector-01.adoc\n+\n+        - action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/check-connector-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/check-connector-01.adoc\n+            - file: tutorial-steps/dev/describe-connector-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/describe-connector-01.adoc\n+            \n+    - title: Consume events from the test topic\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/consume-topic.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/consume-topic.adoc\n+\n+    - title: Declare the topic as a ksqlDB stream\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 255\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/create-stream-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/create-stream-01.adoc\n+            - file: tutorial-steps/dev/describe-stream-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/describe-stream-01.adoc\n+            - file: tutorial-steps/dev/query-stream-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/query-stream-01.adoc\n+\n+    - title: Create two related streams of test data\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/create-connector-02.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/create-connector-02.adoc\n+\n+        - action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+            \n+    - title: Join the test data streams in ksqlDB\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 255\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/check-connector-02.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/check-connector-02.adoc\n+            - file: tutorial-steps/dev/join-streams-declare.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/join-streams-declare.adoc\n+            - file: tutorial-steps/dev/join-streams-do.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/join-streams-do.adoc\n+\n+    - title: Clean up\n+      content:\n+      - action: execute\n+        file: tutorial-steps/dev/clean-up.sh\n+        render:\n+          file: tutorials/generate-test-data-streams/ksql/markup/dev/clean-up.adoc\n+\n+\n+prod:\n+  steps:\n+    - title: Write your statements to a file\n+      content:\n+        - action: make_file\n+          file: src/statements.sql\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/make-src-file.adoc\n+\n+    - title: Send the statements to the REST endpoint\n+      content:\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            skip: true\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            skip: true\n+\n+        - action: execute\n+          file: tutorial-steps/prod/send-to-api.sh\n+          stdout: tutorial-steps/prod/outputs/send-to-api.out\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/prod/submit-to-api.adoc\n+\n+    - title: Validate the deployment\n+      content:\n+        - action: execute\n+          file: tutorial-steps/prod/check-deploy.sh\n+          stdout: tutorial-steps/prod/outputs/check-deploy.out\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/prod/check-deploy.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/clean-up.sh\n+          render:\n+            skip: true", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc1MjIzOA=="}, "originalCommit": {"oid": "dab8d58a03dcbc5f363e62795baac539f57fcc2b"}, "originalPosition": 198}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDI4NDM3Mg==", "bodyText": "\u00af_(\u30c4)_/\u00af I don't think it makes sense to crowbar in Cloud to every single Connector tutorial. It's a tutorial on how to use a connector, not run it end-to-end. Consider, we also don't include how to run it outside of Docker, because that's left to the user to figure out.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313#discussion_r494284372", "createdAt": "2020-09-24T12:41:16Z", "author": {"login": "rmoff"}, "path": "_data/harnesses/generate-test-data-streams/ksql.yml", "diffHunk": "@@ -0,0 +1,198 @@\n+dev:\n+  steps:\n+    - title: Initialize the project\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/init.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/init.adoc\n+        - action: execute\n+          file: tutorial-steps/dev/make-dirs.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/make-dirs.adoc\n+          stdout: tutorial-steps/dev/outputs/make-dirs.out\n+            \n+    - title: Get Confluent Platform\n+      content:\n+        - action: make_file\n+          file: docker-compose.yml\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/make-docker-compose.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/start-compose.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/wait-for-containers.adoc\n+          stdout: tutorial-steps/dev/outputs/wait-for-containers.out\n+\n+        - action: execute\n+          file: tutorial-steps/dev/check-plugin.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/check-plugin.adoc\n+          stdout: tutorial-steps/dev/outputs/check-plugin.out\n+            \n+    - title: Create a standalone stream of test data\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/create-connector-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/create-connector-01.adoc\n+\n+        - action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/check-connector-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/check-connector-01.adoc\n+            - file: tutorial-steps/dev/describe-connector-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/describe-connector-01.adoc\n+            \n+    - title: Consume events from the test topic\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/consume-topic.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/consume-topic.adoc\n+\n+    - title: Declare the topic as a ksqlDB stream\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 255\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/create-stream-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/create-stream-01.adoc\n+            - file: tutorial-steps/dev/describe-stream-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/describe-stream-01.adoc\n+            - file: tutorial-steps/dev/query-stream-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/query-stream-01.adoc\n+\n+    - title: Create two related streams of test data\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/create-connector-02.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/create-connector-02.adoc\n+\n+        - action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+            \n+    - title: Join the test data streams in ksqlDB\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 255\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/check-connector-02.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/check-connector-02.adoc\n+            - file: tutorial-steps/dev/join-streams-declare.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/join-streams-declare.adoc\n+            - file: tutorial-steps/dev/join-streams-do.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/join-streams-do.adoc\n+\n+    - title: Clean up\n+      content:\n+      - action: execute\n+        file: tutorial-steps/dev/clean-up.sh\n+        render:\n+          file: tutorials/generate-test-data-streams/ksql/markup/dev/clean-up.adoc\n+\n+\n+prod:\n+  steps:\n+    - title: Write your statements to a file\n+      content:\n+        - action: make_file\n+          file: src/statements.sql\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/make-src-file.adoc\n+\n+    - title: Send the statements to the REST endpoint\n+      content:\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            skip: true\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            skip: true\n+\n+        - action: execute\n+          file: tutorial-steps/prod/send-to-api.sh\n+          stdout: tutorial-steps/prod/outputs/send-to-api.out\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/prod/submit-to-api.adoc\n+\n+    - title: Validate the deployment\n+      content:\n+        - action: execute\n+          file: tutorial-steps/prod/check-deploy.sh\n+          stdout: tutorial-steps/prod/outputs/check-deploy.out\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/prod/check-deploy.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/clean-up.sh\n+          render:\n+            skip: true", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc1MjIzOA=="}, "originalCommit": {"oid": "dab8d58a03dcbc5f363e62795baac539f57fcc2b"}, "originalPosition": 198}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5MDExOTcyOnYy", "diffSide": "RIGHT", "path": "_data/tutorials.yaml", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QxNzowNjozOFrOHW4RCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQwODo1ODowN1rOHXQqYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc1MjU4Ng==", "bodyText": "problem no longer exists", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313#discussion_r493752586", "createdAt": "2020-09-23T17:06:38Z", "author": {"login": "ybyzek"}, "path": "_data/tutorials.yaml", "diffHunk": "@@ -226,6 +226,17 @@ flatten-nested-data:\n     kstreams: disabled\n     kafka: disabled\n \n+generate-test-data-streams:\n+  title: \"Generate streams of test data\"\n+  meta-description: \"Generate streams of test data\"\n+  slug: \"/generate-streams-of-test-data\"\n+  problem: \"you are working in the Kafka ecosystem and as part of learning and developing applications and pipelines need a stream of test data\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dab8d58a03dcbc5f363e62795baac539f57fcc2b"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDE1MjI4OQ==", "bodyText": "fixed", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313#discussion_r494152289", "createdAt": "2020-09-24T08:58:07Z", "author": {"login": "rmoff"}, "path": "_data/tutorials.yaml", "diffHunk": "@@ -226,6 +226,17 @@ flatten-nested-data:\n     kstreams: disabled\n     kafka: disabled\n \n+generate-test-data-streams:\n+  title: \"Generate streams of test data\"\n+  meta-description: \"Generate streams of test data\"\n+  slug: \"/generate-streams-of-test-data\"\n+  problem: \"you are working in the Kafka ecosystem and as part of learning and developing applications and pipelines need a stream of test data\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc1MjU4Ng=="}, "originalCommit": {"oid": "dab8d58a03dcbc5f363e62795baac539f57fcc2b"}, "originalPosition": 8}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4080, "cost": 1, "resetAt": "2021-11-12T19:05:54Z"}}}