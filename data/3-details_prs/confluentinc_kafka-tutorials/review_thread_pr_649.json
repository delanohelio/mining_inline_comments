{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTMwNjQwMzM3", "number": 649, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQwMzo0OTozOVrOE_cFUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxODo1ODoyNFrOFAaV3g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0OTU1ODU3OnYy", "diffSide": "RIGHT", "path": "_data/tutorials.yaml", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQwMzo0OTozOVrOH9JWbA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNjoyNjoxOVrOH9jTpQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzg3ODM4MA==", "bodyText": "@awalther28 awesome touch to augment meta-description as well, since that text may sometimes be surfaced in Google search results, which in turn impacts SEO and CTR.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/649#discussion_r533878380", "createdAt": "2020-12-02T03:49:39Z", "author": {"login": "ybyzek"}, "path": "_data/tutorials.yaml", "diffHunk": "@@ -43,10 +43,10 @@ merging:\n     kafka: enabled\n \n joining-stream-table:\n-  title: \"How to join a stream and a table together\"\n-  meta-description: \"Learn to join a stream and a table together\"\n+  title: \"How to join a stream and a lookup table together\"\n+  meta-description: \"Learn to join a stream and a lookup table together\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8281cee2c7939cc539bd76fd393d897cc474217f"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDI5NDQxOQ==", "bodyText": "@ybyzek Do you think I need to go further into detail throughout the KT about databases+lookups OR do you think these modifications are enough?", "url": "https://github.com/confluentinc/kafka-tutorials/pull/649#discussion_r534294419", "createdAt": "2020-12-02T16:14:36Z", "author": {"login": "awalther28"}, "path": "_data/tutorials.yaml", "diffHunk": "@@ -43,10 +43,10 @@ merging:\n     kafka: enabled\n \n joining-stream-table:\n-  title: \"How to join a stream and a table together\"\n-  meta-description: \"Learn to join a stream and a table together\"\n+  title: \"How to join a stream and a lookup table together\"\n+  meta-description: \"Learn to join a stream and a lookup table together\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzg3ODM4MA=="}, "originalCommit": {"oid": "8281cee2c7939cc539bd76fd393d897cc474217f"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDMwMzY1Mw==", "bodyText": "LGTM!", "url": "https://github.com/confluentinc/kafka-tutorials/pull/649#discussion_r534303653", "createdAt": "2020-12-02T16:26:19Z", "author": {"login": "ybyzek"}, "path": "_data/tutorials.yaml", "diffHunk": "@@ -43,10 +43,10 @@ merging:\n     kafka: enabled\n \n joining-stream-table:\n-  title: \"How to join a stream and a table together\"\n-  meta-description: \"Learn to join a stream and a table together\"\n+  title: \"How to join a stream and a lookup table together\"\n+  meta-description: \"Learn to join a stream and a lookup table together\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzg3ODM4MA=="}, "originalCommit": {"oid": "8281cee2c7939cc539bd76fd393d897cc474217f"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1MzM5ODkzOnYy", "diffSide": "RIGHT", "path": "index.html", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQyMDo1MzoyM1rOH9ttCQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQyMDo1OTo1MVrOH9t7iA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDQ3Mzk5Mw==", "bodyText": "@awalther28 for symmetry to the other KTs listed below this one, what do you think about removing lookup from here?  (Leaving lookup in the KT itself)", "url": "https://github.com/confluentinc/kafka-tutorials/pull/649#discussion_r534473993", "createdAt": "2020-12-02T20:53:23Z", "author": {"login": "ybyzek"}, "path": "index.html", "diffHunk": "@@ -101,7 +101,7 @@ <h2 class=\"subtitle\">Apache Kafka is a powerful, scalable, fault-tolerant distri\n             <div>Join data.</div>\n           </div>\n           <ul>\n-            <li><a href=\"join-a-stream-to-a-table/ksql.html\">Join a stream and a table</a></li>\n+            <li><a href=\"join-a-stream-to-a-table/ksql.html\">Join a stream and a lookup table</a></li>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "079b265b475c0da0cdb72f319b64ccc1fa365ba7"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDQ3NzcwNA==", "bodyText": "It did low key break my heart to ruin to the symmetry of:\nJoin a stream and a table\nJoin a stream and a stream\nJoin a table and a table\nIf this KT was going through the \"how to's\" of the connector, I'd feel strongly about keeping the word lookup there but it doesn't \ud83d\ude42  thus it has been removed.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/649#discussion_r534477704", "createdAt": "2020-12-02T20:59:51Z", "author": {"login": "awalther28"}, "path": "index.html", "diffHunk": "@@ -101,7 +101,7 @@ <h2 class=\"subtitle\">Apache Kafka is a powerful, scalable, fault-tolerant distri\n             <div>Join data.</div>\n           </div>\n           <ul>\n-            <li><a href=\"join-a-stream-to-a-table/ksql.html\">Join a stream and a table</a></li>\n+            <li><a href=\"join-a-stream-to-a-table/ksql.html\">Join a stream and a lookup table</a></li>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDQ3Mzk5Mw=="}, "originalCommit": {"oid": "079b265b475c0da0cdb72f319b64ccc1fa365ba7"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1MzQwNTY4OnYy", "diffSide": "RIGHT", "path": "_includes/tutorials/joining-stream-table/ksql/markup/dev/create-inputs.adoc", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQyMDo1NTowNlrOH9txEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQyMjowNDo1NFrOH9wEww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDQ3NTAyNA==", "bodyText": "@awalther28 awesome text.  Given that there's also a kstreams KT (for both this KT and the JDBC KT), maybe this text should also be added to _includes/tutorials/joining-stream-table/kstreams?  (with slight modification :%s/ksqlDB/Kafka Streams/)", "url": "https://github.com/confluentinc/kafka-tutorials/pull/649#discussion_r534475024", "createdAt": "2020-12-02T20:55:06Z", "author": {"login": "ybyzek"}, "path": "_includes/tutorials/joining-stream-table/ksql/markup/dev/create-inputs.adoc", "diffHunk": "@@ -2,4 +2,6 @@ First, you'll need to create a Kafka topic and table to represent the movie refe\n \n +++++\n <pre class=\"snippet\"><code class=\"sql\">{% include_raw tutorials/joining-stream-table/ksql/code/tutorial-steps/dev/create-movies-table.sql %}</code></pre>\n-+++++\n\\ No newline at end of file\n++++++\n+\n+In this case the lookup data originates from a Kafka topic but this doesn't always have to be the case. You can use Kafka Connect to stream data from a source system (such as a database) into a Kafka topic, which could then be the foundation for your ksqlDB lookup table. For further reading checkout this tutorial on link:https://kafka-tutorials.confluent.io/connect-add-key-to-source/ksql.html[creating a ksqlDB table from PostgresSQL data using Kafka Connect].", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "079b265b475c0da0cdb72f319b64ccc1fa365ba7"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDUxMjgzNQ==", "bodyText": "@ybyzek I added a similar blurb in the kstreams example in commit 84cad85.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/649#discussion_r534512835", "createdAt": "2020-12-02T22:04:54Z", "author": {"login": "awalther28"}, "path": "_includes/tutorials/joining-stream-table/ksql/markup/dev/create-inputs.adoc", "diffHunk": "@@ -2,4 +2,6 @@ First, you'll need to create a Kafka topic and table to represent the movie refe\n \n +++++\n <pre class=\"snippet\"><code class=\"sql\">{% include_raw tutorials/joining-stream-table/ksql/code/tutorial-steps/dev/create-movies-table.sql %}</code></pre>\n-+++++\n\\ No newline at end of file\n++++++\n+\n+In this case the lookup data originates from a Kafka topic but this doesn't always have to be the case. You can use Kafka Connect to stream data from a source system (such as a database) into a Kafka topic, which could then be the foundation for your ksqlDB lookup table. For further reading checkout this tutorial on link:https://kafka-tutorials.confluent.io/connect-add-key-to-source/ksql.html[creating a ksqlDB table from PostgresSQL data using Kafka Connect].", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDQ3NTAyNA=="}, "originalCommit": {"oid": "079b265b475c0da0cdb72f319b64ccc1fa365ba7"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1OTc1OTAyOnYy", "diffSide": "RIGHT", "path": "_includes/tutorials/joining-stream-table/ksql/markup/dev/populate-ratings.adoc", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxODo1ODoyNFrOH-sTWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxOToyMDoxMlrOH-tK5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQ5OTYwOQ==", "bodyText": "@awalther28 FYC, feel free to ignore if you intentionally chose the console producer\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            This tutorial uses ksqlDB `INSERT INTO VALUES` syntax. For an example on how to use the Apache Kafka\u00ae clients to write data to the underlying topics, see link:https://kafka-tutorials.confluent.io/kafka-console-consumer-producer-basics/kafka.html[*Kafka console producer basics*] and for an example on how to use connectors to source data from external systems, see link:https://kafka-tutorials.confluent.io/connect-add-key-to-source/ksql.html[*creating a ksqlDB table from PostgresSQL data using Kafka Connect*].\n          \n          \n            \n            This tutorial uses ksqlDB `INSERT INTO VALUES` syntax. For an example on how to use the Apache Kafka\u00ae clients to write data to the underlying topics, see link:https://kafka-tutorials.confluent.io/creating-first-apache-kafka-producer-application/kafka.html[*building your first Kafka producer application*] and for an example on how to use connectors to source data from external systems, see link:https://kafka-tutorials.confluent.io/connect-add-key-to-source/ksql.html[*creating a ksqlDB table from PostgresSQL data using Kafka Connect*].", "url": "https://github.com/confluentinc/kafka-tutorials/pull/649#discussion_r535499609", "createdAt": "2020-12-03T18:58:24Z", "author": {"login": "ybyzek"}, "path": "_includes/tutorials/joining-stream-table/ksql/markup/dev/populate-ratings.adoc", "diffHunk": "@@ -2,4 +2,16 @@ In a similar manner, populate the ratings stream:\n \n +++++\n <pre class=\"snippet\"><code class=\"sql\">{% include_raw tutorials/joining-stream-table/ksql/code/tutorial-steps/dev/populate-ratings.sql %}</code></pre>\n-+++++\n\\ No newline at end of file\n++++++\n+\n+[NOTE]\n+.Populating Data\n+====\n+One fundamental operation for working with tables is populating them with data. There are a number of ways to do this:\n+\n+ * Use ksqlDB's `INSERT INTO VALUES` syntax.\n+ * Use the Apache Kafka\u00ae clients to write data to the underlying topics.\n+ * Use connectors to source data from external systems.\n+\n+This tutorial uses ksqlDB `INSERT INTO VALUES` syntax. For an example on how to use the Apache Kafka\u00ae clients to write data to the underlying topics, see link:https://kafka-tutorials.confluent.io/kafka-console-consumer-producer-basics/kafka.html[*Kafka console producer basics*] and for an example on how to use connectors to source data from external systems, see link:https://kafka-tutorials.confluent.io/connect-add-key-to-source/ksql.html[*creating a ksqlDB table from PostgresSQL data using Kafka Connect*].", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eab31e885c476e85d03ac3b0c2efc9a7773884f5"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTUxMzgyOQ==", "bodyText": "I did but this looks like a better fit given it is specifically talking about Apache Kafka\u00ae client applications", "url": "https://github.com/confluentinc/kafka-tutorials/pull/649#discussion_r535513829", "createdAt": "2020-12-03T19:20:12Z", "author": {"login": "awalther28"}, "path": "_includes/tutorials/joining-stream-table/ksql/markup/dev/populate-ratings.adoc", "diffHunk": "@@ -2,4 +2,16 @@ In a similar manner, populate the ratings stream:\n \n +++++\n <pre class=\"snippet\"><code class=\"sql\">{% include_raw tutorials/joining-stream-table/ksql/code/tutorial-steps/dev/populate-ratings.sql %}</code></pre>\n-+++++\n\\ No newline at end of file\n++++++\n+\n+[NOTE]\n+.Populating Data\n+====\n+One fundamental operation for working with tables is populating them with data. There are a number of ways to do this:\n+\n+ * Use ksqlDB's `INSERT INTO VALUES` syntax.\n+ * Use the Apache Kafka\u00ae clients to write data to the underlying topics.\n+ * Use connectors to source data from external systems.\n+\n+This tutorial uses ksqlDB `INSERT INTO VALUES` syntax. For an example on how to use the Apache Kafka\u00ae clients to write data to the underlying topics, see link:https://kafka-tutorials.confluent.io/kafka-console-consumer-producer-basics/kafka.html[*Kafka console producer basics*] and for an example on how to use connectors to source data from external systems, see link:https://kafka-tutorials.confluent.io/connect-add-key-to-source/ksql.html[*creating a ksqlDB table from PostgresSQL data using Kafka Connect*].", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQ5OTYwOQ=="}, "originalCommit": {"oid": "eab31e885c476e85d03ac3b0c2efc9a7773884f5"}, "originalPosition": 17}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3863, "cost": 1, "resetAt": "2021-11-12T19:05:54Z"}}}