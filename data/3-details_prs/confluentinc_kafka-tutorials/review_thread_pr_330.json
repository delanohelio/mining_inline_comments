{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA4MTU4MDI1", "number": 330, "reviewThreads": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQyMjozMzo0N1rOD301Jg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNDoyODo0MFrOD5A8cQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5ODYzODQ2OnYy", "diffSide": "RIGHT", "path": "_includes/tutorials/cogrouping-streams/kstreams/code/src/main/java/io/confluent/developer/CogroupingStreams.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQyMjozMzo0N1rOGOTb7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQyMjozNDoxNFrOGOTcnQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY1MTY5Mg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    props.put(AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG, envProps.getProperty(\"schema.registry.url\"));\n          \n          \n            \n                    props.put(AbstractKafkaSchemaSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG, envProps.getProperty(\"schema.registry.url\"));", "url": "https://github.com/confluentinc/kafka-tutorials/pull/330#discussion_r417651692", "createdAt": "2020-04-29T22:33:47Z", "author": {"login": "gAmUssA"}, "path": "_includes/tutorials/cogrouping-streams/kstreams/code/src/main/java/io/confluent/developer/CogroupingStreams.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package io.confluent.developer;\n+\n+\n+import io.confluent.common.utils.TestUtils;\n+import io.confluent.developer.avro.LoginEvent;\n+import io.confluent.developer.avro.LoginRollup;\n+import io.confluent.kafka.serializers.AbstractKafkaAvroSerDeConfig;\n+import io.confluent.kafka.serializers.AbstractKafkaSchemaSerDeConfig;\n+import io.confluent.kafka.serializers.KafkaAvroDeserializer;\n+import io.confluent.kafka.serializers.KafkaAvroSerializer;\n+import io.confluent.kafka.streams.serdes.avro.PrimitiveAvroSerde;\n+import io.confluent.kafka.streams.serdes.avro.SpecificAvroSerde;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import org.apache.avro.specific.SpecificRecord;\n+import org.apache.kafka.clients.admin.AdminClient;\n+import org.apache.kafka.clients.admin.NewTopic;\n+import org.apache.kafka.common.serialization.Serde;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.kstream.Aggregator;\n+import org.apache.kafka.streams.kstream.Consumed;\n+import org.apache.kafka.streams.kstream.KGroupedStream;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Materialized;\n+import org.apache.kafka.streams.kstream.Produced;\n+\n+public class CogroupingStreams {\n+\n+\n+\tpublic Properties buildStreamsProperties(Properties envProps) {\n+        Properties props = new Properties();\n+\n+        props.put(StreamsConfig.APPLICATION_ID_CONFIG, envProps.getProperty(\"application.id\"));\n+        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, envProps.getProperty(\"bootstrap.servers\"));\n+        props.put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n+        props.put(AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG, envProps.getProperty(\"schema.registry.url\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f0fd6f1732dab41bca4e09aca88798fb1717b43"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY1MTg2OQ==", "bodyText": "AbstractKafkaAvroSerDeConfig is deprecated in 5.5", "url": "https://github.com/confluentinc/kafka-tutorials/pull/330#discussion_r417651869", "createdAt": "2020-04-29T22:34:14Z", "author": {"login": "gAmUssA"}, "path": "_includes/tutorials/cogrouping-streams/kstreams/code/src/main/java/io/confluent/developer/CogroupingStreams.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package io.confluent.developer;\n+\n+\n+import io.confluent.common.utils.TestUtils;\n+import io.confluent.developer.avro.LoginEvent;\n+import io.confluent.developer.avro.LoginRollup;\n+import io.confluent.kafka.serializers.AbstractKafkaAvroSerDeConfig;\n+import io.confluent.kafka.serializers.AbstractKafkaSchemaSerDeConfig;\n+import io.confluent.kafka.serializers.KafkaAvroDeserializer;\n+import io.confluent.kafka.serializers.KafkaAvroSerializer;\n+import io.confluent.kafka.streams.serdes.avro.PrimitiveAvroSerde;\n+import io.confluent.kafka.streams.serdes.avro.SpecificAvroSerde;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import org.apache.avro.specific.SpecificRecord;\n+import org.apache.kafka.clients.admin.AdminClient;\n+import org.apache.kafka.clients.admin.NewTopic;\n+import org.apache.kafka.common.serialization.Serde;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.kstream.Aggregator;\n+import org.apache.kafka.streams.kstream.Consumed;\n+import org.apache.kafka.streams.kstream.KGroupedStream;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Materialized;\n+import org.apache.kafka.streams.kstream.Produced;\n+\n+public class CogroupingStreams {\n+\n+\n+\tpublic Properties buildStreamsProperties(Properties envProps) {\n+        Properties props = new Properties();\n+\n+        props.put(StreamsConfig.APPLICATION_ID_CONFIG, envProps.getProperty(\"application.id\"));\n+        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, envProps.getProperty(\"bootstrap.servers\"));\n+        props.put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n+        props.put(AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG, envProps.getProperty(\"schema.registry.url\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY1MTY5Mg=="}, "originalCommit": {"oid": "4f0fd6f1732dab41bca4e09aca88798fb1717b43"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5ODY0MzY2OnYy", "diffSide": "RIGHT", "path": "_includes/tutorials/cogrouping-streams/kstreams/code/src/main/java/io/confluent/developer/CogroupingStreams.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQyMjozNTo1MVrOGOTfBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQyMjozNTo1MVrOGOTfBA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY1MjQ4NA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            import io.confluent.kafka.serializers.AbstractKafkaAvroSerDeConfig;", "url": "https://github.com/confluentinc/kafka-tutorials/pull/330#discussion_r417652484", "createdAt": "2020-04-29T22:35:51Z", "author": {"login": "gAmUssA"}, "path": "_includes/tutorials/cogrouping-streams/kstreams/code/src/main/java/io/confluent/developer/CogroupingStreams.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package io.confluent.developer;\n+\n+\n+import io.confluent.common.utils.TestUtils;\n+import io.confluent.developer.avro.LoginEvent;\n+import io.confluent.developer.avro.LoginRollup;\n+import io.confluent.kafka.serializers.AbstractKafkaAvroSerDeConfig;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f0fd6f1732dab41bca4e09aca88798fb1717b43"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5ODY0NDYyOnYy", "diffSide": "RIGHT", "path": "_includes/tutorials/cogrouping-streams/kstreams/code/src/main/java/io/confluent/developer/CogroupingStreams.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQyMjozNjoxMlrOGOTflA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQyMjozNjoxMlrOGOTflA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY1MjYyOA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            import io.confluent.kafka.streams.serdes.avro.PrimitiveAvroSerde;", "url": "https://github.com/confluentinc/kafka-tutorials/pull/330#discussion_r417652628", "createdAt": "2020-04-29T22:36:12Z", "author": {"login": "gAmUssA"}, "path": "_includes/tutorials/cogrouping-streams/kstreams/code/src/main/java/io/confluent/developer/CogroupingStreams.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package io.confluent.developer;\n+\n+\n+import io.confluent.common.utils.TestUtils;\n+import io.confluent.developer.avro.LoginEvent;\n+import io.confluent.developer.avro.LoginRollup;\n+import io.confluent.kafka.serializers.AbstractKafkaAvroSerDeConfig;\n+import io.confluent.kafka.serializers.AbstractKafkaSchemaSerDeConfig;\n+import io.confluent.kafka.serializers.KafkaAvroDeserializer;\n+import io.confluent.kafka.serializers.KafkaAvroSerializer;\n+import io.confluent.kafka.streams.serdes.avro.PrimitiveAvroSerde;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f0fd6f1732dab41bca4e09aca88798fb1717b43"}, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDk1NDY5OnYy", "diffSide": "RIGHT", "path": ".gitignore", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMzo1NTozOFrOGQBe1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNjozNToyMVrOGQIcgw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ1NDY3OQ==", "bodyText": "Many tutorials reference output files in this directory pattern via adoc includes. We have #217 tracking some consistency/clarification of this behavior. It seems like it would create confusion to ignore them across the repo now. For this specific tutorial, you could consider adding a .gitignore to the tutorial's respective subdirectory.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/330#discussion_r419454679", "createdAt": "2020-05-04T13:55:38Z", "author": {"login": "colinhicks"}, "path": ".gitignore", "diffHunk": "@@ -9,7 +9,7 @@ build/\n .jekyll-metadata\n node_modules/\n out/\n-*/outputs/*\n+**/tutorial-steps/dev/outputs/", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ad1d7afa2f9a6e50607ab49f651712bc8aa27496"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTU2ODc3MQ==", "bodyText": "That's a good point, I'll add a separate .gitignore file for the tutorial.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/330#discussion_r419568771", "createdAt": "2020-05-04T16:35:21Z", "author": {"login": "bbejeck"}, "path": ".gitignore", "diffHunk": "@@ -9,7 +9,7 @@ build/\n .jekyll-metadata\n node_modules/\n out/\n-*/outputs/*\n+**/tutorial-steps/dev/outputs/", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ1NDY3OQ=="}, "originalCommit": {"oid": "ad1d7afa2f9a6e50607ab49f651712bc8aa27496"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDk4ODExOnYy", "diffSide": "RIGHT", "path": "_includes/tutorials/cogrouping-streams/kstreams/markup/dev/make-aggregator.adoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNDowMjo0MlrOGQBzAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNDowMjo0MlrOGQBzAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ1OTg0Mg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The `Aggregator` you saw in the previous step, constructs a map keeping a count of user logins per user, per application, so a map of maps.  Here you'll see the core logic of the `LoginAggregator`, and the code is straightforward, as you can see below.\n          \n          \n            \n            The `Aggregator` you saw in the previous step constructs a map of maps: the count of logins per user, per application.  Below is the core logic of the `LoginAggregator`.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/330#discussion_r419459842", "createdAt": "2020-05-04T14:02:42Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/cogrouping-streams/kstreams/markup/dev/make-aggregator.adoc", "diffHunk": "@@ -0,0 +1,27 @@\n+////\n+In this file you describe the Kafka streams topology, and should cover the main points of the tutorial.\n+The text assumes a method buildTopology exists and constructs the Kafka Streams application.  Feel free to modify the text below to suit your needs.\n+////\n+\n+The `Aggregator` you saw in the previous step, constructs a map keeping a count of user logins per user, per application, so a map of maps.  Here you'll see the core logic of the `LoginAggregator`, and the code is straightforward, as you can see below.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ad1d7afa2f9a6e50607ab49f651712bc8aa27496"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDk4OTc2OnYy", "diffSide": "RIGHT", "path": "_includes/tutorials/cogrouping-streams/kstreams/markup/dev/make-aggregator.adoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNDowMzowOFrOGQB0Dw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNDowMzowOFrOGQB0Dw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ2MDExMQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Each call to `Aggregator.apply` retrieves the user login map for the given application id (or creating one if it doesn't exist).  From there, the `Aggregator` increments the login count for the given user.\n          \n          \n            \n            Each call to `Aggregator.apply` retrieves the user login map for the given application id (or creates one if it doesn't exist).  From there, the `Aggregator` increments the login count for the given user.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/330#discussion_r419460111", "createdAt": "2020-05-04T14:03:08Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/cogrouping-streams/kstreams/markup/dev/make-aggregator.adoc", "diffHunk": "@@ -0,0 +1,27 @@\n+////\n+In this file you describe the Kafka streams topology, and should cover the main points of the tutorial.\n+The text assumes a method buildTopology exists and constructs the Kafka Streams application.  Feel free to modify the text below to suit your needs.\n+////\n+\n+The `Aggregator` you saw in the previous step, constructs a map keeping a count of user logins per user, per application, so a map of maps.  Here you'll see the core logic of the `LoginAggregator`, and the code is straightforward, as you can see below.\n+\n+Each call to `Aggregator.apply` retrieves the user login map for the given application id (or creating one if it doesn't exist).  From there, the `Aggregator` increments the login count for the given user.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ad1d7afa2f9a6e50607ab49f651712bc8aa27496"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDk5Mjg5OnYy", "diffSide": "RIGHT", "path": "_includes/tutorials/cogrouping-streams/kstreams/markup/dev/make-avro-dir.adoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNDowMzo0OVrOGQB16A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNDowMzo0OVrOGQB16A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ2MDU4NA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            This tutorial uses 4 streams.  The three input streams have a record type of `LoginEvent` used to represent a user logging into an application.  The fourth stream is an ouput stream that writes a `LoginRollup` object out to a topic.  In the next steps you'll create the avro schemas for these objects.\n          \n          \n            \n            This tutorial uses 4 streams.  The three input streams have a record type of `LoginEvent` used to represent a user logging into an application.  The fourth stream is an output stream that writes a `LoginRollup` object out to a topic.  In the next steps you'll create the Avro schemas for these objects.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/330#discussion_r419460584", "createdAt": "2020-05-04T14:03:49Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/cogrouping-streams/kstreams/markup/dev/make-avro-dir.adoc", "diffHunk": "@@ -0,0 +1,8 @@\n+\n+This tutorial uses 4 streams.  The three input streams have a record type of `LoginEvent` used to represent a user logging into an application.  The fourth stream is an ouput stream that writes a `LoginRollup` object out to a topic.  In the next steps you'll create the avro schemas for these objects.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ad1d7afa2f9a6e50607ab49f651712bc8aa27496"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMTAxNTY1OnYy", "diffSide": "RIGHT", "path": "_includes/tutorials/cogrouping-streams/kstreams/markup/dev/make-topology.adoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNDowODoxM1rOGQCDSA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNDowODoxM1rOGQCDSA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ2NDAwOA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Next, you have three input streams (`appOneStream`, `appTwoStream`, and `appThreeStream`).  You need the intermediate object `KGroupedStream`  so you execute the\n          \n          \n            \n            `groupByKey()` method on each stream.  For this tutorial, we have assumed the incoming records already have keys.  Otherwise, you'll need to use a key selecting method (`selectKey()`, `map()`), or `groupBy()` to successfully group by key.\n          \n          \n            \n            Next, you have three input streams: `appOneStream`, `appTwoStream`, and `appThreeStream`.  You need the intermediate object `KGroupedStream`, so you execute the `groupByKey()` method on each stream.  For this tutorial, we have assumed the incoming records already have keys.  In cases where records lack keys, you need to use a key-selecting method (`selectKey()`, `map()`, or `groupBy()`) to successfully group by key.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/330#discussion_r419464008", "createdAt": "2020-05-04T14:08:13Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/cogrouping-streams/kstreams/markup/dev/make-topology.adoc", "diffHunk": "@@ -0,0 +1,39 @@\n+////\n+In this file you describe the Kafka streams topology, and should cover the main points of the tutorial.\n+The text assumes a method buildTopology exists and constructs the Kafka Streams application.  Feel free to modify the text below to suit your needs.\n+////\n+\n+Before you create the Java class to run the `Cogrouping` example, let's dive into the main point of this tutorial, how we use cogrouping:\n+\n+++++\n+<pre class=\"snippet\">\n+    <code class=\"java\">\n+        final Aggregator&lt;String, LoginEvent, LoginRollup&gt; loginAggregator = new LoginAggregator();\n+\n+        final KGroupedStream&lt;String, LoginEvent&gt; appOneGrouped = appOneStream.groupByKey();\n+        final KGroupedStream&lt;String, LoginEvent&gt; appTwoGrouped = appTwoStream.groupByKey();\n+        final KGroupedStream&lt;String, LoginEvent&gt; appThreeGrouped = appThreeStream.groupByKey();\n+\n+        appOneGrouped.cogroup(loginAggregator)\n+            .cogroup(appTwoGrouped, loginAggregator)\n+            .cogroup(appThreeGrouped, loginAggregator)\n+            .aggregate(() -&gt; new LoginRollup(new HashMap&lt;>()), Materialized.with(Serdes.String(), loginRollupSerde))\n+            .toStream().to(totalResultOutputTopic, Produced.with(stringSerde, loginRollupSerde));\n+    </code>\n+</pre>\n+++++\n+\n+You're using the cogrouping functionality here to get an overall grouping of logins per application.  Kafka Streams creates this total grouping by using an `Aggregator` who knows how to extract records from each grouped stream.  Your `Aggregator` instance here knows how to correctly combine each `LoginEvent` into the larger `LoginRollup` object.  You'll learn more about `Aggregator` in the next step.\n+\n+Next, you have three input streams (`appOneStream`, `appTwoStream`, and `appThreeStream`).  You need the intermediate object `KGroupedStream`  so you execute the\n+`groupByKey()` method on each stream.  For this tutorial, we have assumed the incoming records already have keys.  Otherwise, you'll need to use a key selecting method (`selectKey()`, `map()`), or `groupBy()` to successfully group by key.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ad1d7afa2f9a6e50607ab49f651712bc8aa27496"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMTAyMTMxOnYy", "diffSide": "RIGHT", "path": "_includes/tutorials/cogrouping-streams/kstreams/markup/dev/make-topology.adoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNDowOToyOFrOGQCG1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNDowOToyOFrOGQCG1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ2NDkxOA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            For more background on cogrouping functionality in stream you can https://cwiki.apache.org/confluence/display/KAFKA/KIP-150+-+Kafka-Streams+Cogroup[read the KIP proposal].\n          \n          \n            \n            For more background on cogrouping functionality in stream you can https://cwiki.apache.org/confluence/display/KAFKA/KIP-150+-+Kafka-Streams+Cogroup[read the KIP-150 proposal].", "url": "https://github.com/confluentinc/kafka-tutorials/pull/330#discussion_r419464918", "createdAt": "2020-05-04T14:09:28Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/cogrouping-streams/kstreams/markup/dev/make-topology.adoc", "diffHunk": "@@ -0,0 +1,39 @@\n+////\n+In this file you describe the Kafka streams topology, and should cover the main points of the tutorial.\n+The text assumes a method buildTopology exists and constructs the Kafka Streams application.  Feel free to modify the text below to suit your needs.\n+////\n+\n+Before you create the Java class to run the `Cogrouping` example, let's dive into the main point of this tutorial, how we use cogrouping:\n+\n+++++\n+<pre class=\"snippet\">\n+    <code class=\"java\">\n+        final Aggregator&lt;String, LoginEvent, LoginRollup&gt; loginAggregator = new LoginAggregator();\n+\n+        final KGroupedStream&lt;String, LoginEvent&gt; appOneGrouped = appOneStream.groupByKey();\n+        final KGroupedStream&lt;String, LoginEvent&gt; appTwoGrouped = appTwoStream.groupByKey();\n+        final KGroupedStream&lt;String, LoginEvent&gt; appThreeGrouped = appThreeStream.groupByKey();\n+\n+        appOneGrouped.cogroup(loginAggregator)\n+            .cogroup(appTwoGrouped, loginAggregator)\n+            .cogroup(appThreeGrouped, loginAggregator)\n+            .aggregate(() -&gt; new LoginRollup(new HashMap&lt;>()), Materialized.with(Serdes.String(), loginRollupSerde))\n+            .toStream().to(totalResultOutputTopic, Produced.with(stringSerde, loginRollupSerde));\n+    </code>\n+</pre>\n+++++\n+\n+You're using the cogrouping functionality here to get an overall grouping of logins per application.  Kafka Streams creates this total grouping by using an `Aggregator` who knows how to extract records from each grouped stream.  Your `Aggregator` instance here knows how to correctly combine each `LoginEvent` into the larger `LoginRollup` object.  You'll learn more about `Aggregator` in the next step.\n+\n+Next, you have three input streams (`appOneStream`, `appTwoStream`, and `appThreeStream`).  You need the intermediate object `KGroupedStream`  so you execute the\n+`groupByKey()` method on each stream.  For this tutorial, we have assumed the incoming records already have keys.  Otherwise, you'll need to use a key selecting method (`selectKey()`, `map()`), or `groupBy()` to successfully group by key.\n+\n+Now with your `KGroupedStream` objects, you start creating your larger aggregate by calling `KGroupedStream.cogroup()` on the first stream, using your `Aggregator`.  This first step returns a `CogroupedKStream` instance.  Then for each remaining `KGroupedStream`, you execute `CogroupedKSteam.cogroup()` using one of the `KGroupedStream` instances and the `Aggregator` you created previously.  You repeat this sequence of calls for all of the `KGroupedStream` objects you want to combine into an overall aggregate.\n+\n+For more background on cogrouping functionality in stream you can https://cwiki.apache.org/confluence/display/KAFKA/KIP-150+-+Kafka-Streams+Cogroup[read the KIP proposal].", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ad1d7afa2f9a6e50607ab49f651712bc8aa27496"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMTA1NTQ5OnYy", "diffSide": "RIGHT", "path": "_data/tutorials.yaml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNDoxNzowOVrOGQCcFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNDoxNzowOVrOGQCcFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ3MDM1Nw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              problem: \"you have multiple streams with an aggregate value that you want to combine into a single object\"\n          \n          \n            \n              problem: \"you have multiple streams, each with an aggregate value like `count`,  that you want to combine into a single result\"", "url": "https://github.com/confluentinc/kafka-tutorials/pull/330#discussion_r419470357", "createdAt": "2020-05-04T14:17:09Z", "author": {"login": "colinhicks"}, "path": "_data/tutorials.yaml", "diffHunk": "@@ -257,3 +257,14 @@ naming-changelog-repartition-topics:\n     ksql: disabled\n     kstreams: enabled\n     kafka: disabled\n+\n+cogrouping-streams:\n+  title: \"How to combine stream aggregates together in a single larger object\"\n+  meta-description: \"How to combine stream aggregates together in a single larger object\"\n+  slug: \"/cogrouping-streams\"\n+  problem: \"you have multiple streams with an aggregate value that you want to combine into a single object\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ad1d7afa2f9a6e50607ab49f651712bc8aa27496"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMTEwODk3OnYy", "diffSide": "RIGHT", "path": "_data/tutorials.yaml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNDoyODo0MFrOGQC9kg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNDoyODo0MFrOGQC9kg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ3ODkzMA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              introduction: \"You have mulitple streams with an aggregate value but you want to group them all together - cogrouping.  In this tutorial we'll cover how to use the KStreams CoGrouping functionality to merge mulitple aggregates into a single aggregate object\"\n          \n          \n            \n              introduction: \"You want to compute the count of user login events per application in your system, grouping the individual result from each source stream into one aggregated object.  In this tutorial we'll cover how to use the Kafka Streams Cogrouping functionality to accomplish this task with clear, performant code\"", "url": "https://github.com/confluentinc/kafka-tutorials/pull/330#discussion_r419478930", "createdAt": "2020-05-04T14:28:40Z", "author": {"login": "colinhicks"}, "path": "_data/tutorials.yaml", "diffHunk": "@@ -257,3 +257,14 @@ naming-changelog-repartition-topics:\n     ksql: disabled\n     kstreams: enabled\n     kafka: disabled\n+\n+cogrouping-streams:\n+  title: \"How to combine stream aggregates together in a single larger object\"\n+  meta-description: \"How to combine stream aggregates together in a single larger object\"\n+  slug: \"/cogrouping-streams\"\n+  problem: \"you have multiple streams with an aggregate value that you want to combine into a single object\"\n+  introduction: \"You have mulitple streams with an aggregate value but you want to group them all together - cogrouping.  In this tutorial we'll cover how to use the KStreams CoGrouping functionality to merge mulitple aggregates into a single aggregate object\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ad1d7afa2f9a6e50607ab49f651712bc8aa27496"}, "originalPosition": 19}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4098, "cost": 1, "resetAt": "2021-11-12T19:05:54Z"}}}