{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk3ODA4MTk5", "number": 313, "title": "New tutorials: generated test streams of data with ksqlDB and Kafka Connect", "bodyText": "/cc @MichaelDrogalis", "createdAt": "2020-04-02T21:11:31Z", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313", "merged": true, "mergeCommit": {"oid": "7543c92125436e537257e472ccf89139c7f3aacd"}, "closed": true, "closedAt": "2020-09-24T13:47:21Z", "author": {"login": "rmoff"}, "timelineItems": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcTDvhgAH2gAyMzk3ODA4MTk5OmFjM2Q4OTQyNzU2ODQ0ZTJkOGFlMjVlZDkyYWFhMjg1NzNhMGY5MDI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdL_RQOAH2gAyMzk3ODA4MTk5OjU0ZGQ0M2ZiZjAxMTAyOTgyMDdlZTZiN2U4Mzg3NmFkZDU5ZjAyZjU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "ac3d8942756844e2d8ae25ed92aaa28573a0f902", "author": {"user": {"login": "rmoff", "name": "Robin Moffatt"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/ac3d8942756844e2d8ae25ed92aaa28573a0f902", "committedDate": "2020-03-31T14:12:16Z", "message": "new tutorial"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6e0da3fb7068f5d715cc495801b8b183d3f12ff9", "author": {"user": {"login": "rmoff", "name": "Robin Moffatt"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/6e0da3fb7068f5d715cc495801b8b183d3f12ff9", "committedDate": "2020-03-31T14:13:28Z", "message": "Merge branch 'master' into 290-voluble"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a5cea09c5fe59ad47fa26ffe9ce39a358902f75f", "author": {"user": {"login": "rmoff", "name": "Robin Moffatt"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/a5cea09c5fe59ad47fa26ffe9ce39a358902f75f", "committedDate": "2020-04-02T09:31:57Z", "message": "ksqlDB tutorial WIP"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1b207ac86183dee5f465c130a0011048920ec79f", "author": {"user": {"login": "rmoff", "name": "Robin Moffatt"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/1b207ac86183dee5f465c130a0011048920ec79f", "committedDate": "2020-04-02T14:23:01Z", "message": "New tutorial: ksqlDB : generate streams of test data"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "49caa9837b0ccfdc862f8424bfd9cf44974fedcd", "author": {"user": {"login": "rmoff", "name": "Robin Moffatt"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/49caa9837b0ccfdc862f8424bfd9cf44974fedcd", "committedDate": "2020-04-02T14:23:26Z", "message": "Merge branch 'master' into 290-voluble"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "656d1b095990d79853dc9393bbd5704b70208c8c", "author": {"user": {"login": "rmoff", "name": "Robin Moffatt"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/656d1b095990d79853dc9393bbd5704b70208c8c", "committedDate": "2020-04-02T20:25:05Z", "message": "ksqlDB tutorial tweaks"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "149bd6f5183c0198fb62335922441c288a38b64f", "author": {"user": {"login": "rmoff", "name": "Robin Moffatt"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/149bd6f5183c0198fb62335922441c288a38b64f", "committedDate": "2020-04-02T20:25:34Z", "message": "New tutorial: Kafka Connect generate test streams"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "47c380a1e31e6246e75b4a7022fd0b3da47c0c13", "author": {"user": {"login": "rmoff", "name": "Robin Moffatt"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/47c380a1e31e6246e75b4a7022fd0b3da47c0c13", "committedDate": "2020-04-02T21:08:35Z", "message": "Tweaks"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg3NDU5OTA3", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313#pullrequestreview-387459907", "createdAt": "2020-04-03T17:46:38Z", "commit": {"oid": "47c380a1e31e6246e75b4a7022fd0b3da47c0c13"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxNzo0NjozOFrOGAgqRQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxNzo0NjozOFrOGAgqRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzE4ODI5Mw==", "bodyText": "This file has duplicate content to consume-topic-02a.adoc.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313#discussion_r403188293", "createdAt": "2020-04-03T17:46:38Z", "author": {"login": "bbejeck"}, "path": "_includes/tutorials/generate-test-data-streams/kafka/markup/dev/consume-topic-02b.adoc", "diffHunk": "@@ -0,0 +1,10 @@\n+We now have two Kafka topics being written to. The first (`devices`) is keyed on the MAC address, as can be seen from the data: ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "47c380a1e31e6246e75b4a7022fd0b3da47c0c13"}, "originalPosition": 1}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2f73ce3f7762ae3598ff4837863264643c031124", "author": {"user": {"login": "rmoff", "name": "Robin Moffatt"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/2f73ce3f7762ae3598ff4837863264643c031124", "committedDate": "2020-04-06T09:39:05Z", "message": "Fix duplicate content"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg4MzY1MTg5", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313#pullrequestreview-388365189", "createdAt": "2020-04-06T15:29:01Z", "commit": {"oid": "2f73ce3f7762ae3598ff4837863264643c031124"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dab8d58a03dcbc5f363e62795baac539f57fcc2b", "author": {"user": {"login": "rmoff", "name": "Robin Moffatt"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/dab8d58a03dcbc5f363e62795baac539f57fcc2b", "committedDate": "2020-09-21T14:34:26Z", "message": "Merge branch 'master' into 290-voluble"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk0ODcwMTkx", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313#pullrequestreview-494870191", "createdAt": "2020-09-23T17:05:22Z", "commit": {"oid": "dab8d58a03dcbc5f363e62795baac539f57fcc2b"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk0ODcwNjkw", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313#pullrequestreview-494870690", "createdAt": "2020-09-23T17:06:00Z", "commit": {"oid": "dab8d58a03dcbc5f363e62795baac539f57fcc2b"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QxNzowNjowMFrOHW4Prg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QxNzowNjozOFrOHW4RCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc1MjIzOA==", "bodyText": "Can you add the CCloud section like the other tutorials?", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313#discussion_r493752238", "createdAt": "2020-09-23T17:06:00Z", "author": {"login": "ybyzek"}, "path": "_data/harnesses/generate-test-data-streams/ksql.yml", "diffHunk": "@@ -0,0 +1,198 @@\n+dev:\n+  steps:\n+    - title: Initialize the project\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/init.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/init.adoc\n+        - action: execute\n+          file: tutorial-steps/dev/make-dirs.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/make-dirs.adoc\n+          stdout: tutorial-steps/dev/outputs/make-dirs.out\n+            \n+    - title: Get Confluent Platform\n+      content:\n+        - action: make_file\n+          file: docker-compose.yml\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/make-docker-compose.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/start-compose.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/wait-for-containers.adoc\n+          stdout: tutorial-steps/dev/outputs/wait-for-containers.out\n+\n+        - action: execute\n+          file: tutorial-steps/dev/check-plugin.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/check-plugin.adoc\n+          stdout: tutorial-steps/dev/outputs/check-plugin.out\n+            \n+    - title: Create a standalone stream of test data\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/create-connector-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/create-connector-01.adoc\n+\n+        - action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/check-connector-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/check-connector-01.adoc\n+            - file: tutorial-steps/dev/describe-connector-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/describe-connector-01.adoc\n+            \n+    - title: Consume events from the test topic\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/consume-topic.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/consume-topic.adoc\n+\n+    - title: Declare the topic as a ksqlDB stream\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 255\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/create-stream-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/create-stream-01.adoc\n+            - file: tutorial-steps/dev/describe-stream-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/describe-stream-01.adoc\n+            - file: tutorial-steps/dev/query-stream-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/query-stream-01.adoc\n+\n+    - title: Create two related streams of test data\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/create-connector-02.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/create-connector-02.adoc\n+\n+        - action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+            \n+    - title: Join the test data streams in ksqlDB\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 255\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/check-connector-02.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/check-connector-02.adoc\n+            - file: tutorial-steps/dev/join-streams-declare.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/join-streams-declare.adoc\n+            - file: tutorial-steps/dev/join-streams-do.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/join-streams-do.adoc\n+\n+    - title: Clean up\n+      content:\n+      - action: execute\n+        file: tutorial-steps/dev/clean-up.sh\n+        render:\n+          file: tutorials/generate-test-data-streams/ksql/markup/dev/clean-up.adoc\n+\n+\n+prod:\n+  steps:\n+    - title: Write your statements to a file\n+      content:\n+        - action: make_file\n+          file: src/statements.sql\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/make-src-file.adoc\n+\n+    - title: Send the statements to the REST endpoint\n+      content:\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            skip: true\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            skip: true\n+\n+        - action: execute\n+          file: tutorial-steps/prod/send-to-api.sh\n+          stdout: tutorial-steps/prod/outputs/send-to-api.out\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/prod/submit-to-api.adoc\n+\n+    - title: Validate the deployment\n+      content:\n+        - action: execute\n+          file: tutorial-steps/prod/check-deploy.sh\n+          stdout: tutorial-steps/prod/outputs/check-deploy.out\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/prod/check-deploy.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/clean-up.sh\n+          render:\n+            skip: true", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dab8d58a03dcbc5f363e62795baac539f57fcc2b"}, "originalPosition": 198}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc1MjU4Ng==", "bodyText": "problem no longer exists", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313#discussion_r493752586", "createdAt": "2020-09-23T17:06:38Z", "author": {"login": "ybyzek"}, "path": "_data/tutorials.yaml", "diffHunk": "@@ -226,6 +226,17 @@ flatten-nested-data:\n     kstreams: disabled\n     kafka: disabled\n \n+generate-test-data-streams:\n+  title: \"Generate streams of test data\"\n+  meta-description: \"Generate streams of test data\"\n+  slug: \"/generate-streams-of-test-data\"\n+  problem: \"you are working in the Kafka ecosystem and as part of learning and developing applications and pipelines need a stream of test data\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dab8d58a03dcbc5f363e62795baac539f57fcc2b"}, "originalPosition": 8}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bbeacdce9cdb5bc39340e30d2ef6fc8e775f5262", "author": {"user": {"login": "rmoff", "name": "Robin Moffatt"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/bbeacdce9cdb5bc39340e30d2ef6fc8e775f5262", "committedDate": "2020-09-24T08:57:58Z", "message": "Remove `problem:`"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5aa3e979edb6793de35aadfec97d01e4ac874d85", "author": {"user": {"login": "rmoff", "name": "Robin Moffatt"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/5aa3e979edb6793de35aadfec97d01e4ac874d85", "committedDate": "2020-09-24T11:12:26Z", "message": "Merge in master, rename tutorial"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "54dd43fbf0110298207ee6b7e83876add59f02f5", "author": {"user": {"login": "rmoff", "name": "Robin Moffatt"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/54dd43fbf0110298207ee6b7e83876add59f02f5", "committedDate": "2020-09-24T11:13:16Z", "message": "Merge branch '290-voluble' of github.com:confluentinc/kafka-tutorials into 290-voluble"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 294, "cost": 1, "resetAt": "2021-11-01T13:07:16Z"}}}