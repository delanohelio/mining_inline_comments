{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI5NjgzNTk1", "number": 647, "title": "DEVX-2183: Convert \"Event Time Processing\" recipe to KT", "bodyText": "Description\nhttps://confluentinc.atlassian.net/browse/DEVX-2183\n#265\nStaging Docs\nhttp://kafka-tutorials-staging.s3-website-us-west-2.amazonaws.com/DEVX-2183/\nhttp://kafka-tutorials-staging.s3-website-us-west-2.amazonaws.com/DEVX-2183/time-concepts/ksql.html", "createdAt": "2020-11-30T17:01:33Z", "url": "https://github.com/confluentinc/kafka-tutorials/pull/647", "merged": true, "mergeCommit": {"oid": "494030ef00d478da5e037b40912bee3179e4a478"}, "closed": true, "closedAt": "2020-12-01T17:18:05Z", "author": {"login": "ybyzek"}, "timelineItems": {"totalCount": 45, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABddj3_CAH2gAyNTI5NjgzNTk1OjJjZjE0MDhlMGY1OWRjMmYzZDdiYzc5YmY3ZGI0ODBjNDYxZjc3ZGQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdh8BYegFqTU0MjA0MTQ4Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "2cf1408e0f59dc2f3d7bc79bf7db480c461f77dd", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/2cf1408e0f59dc2f3d7bc79bf7db480c461f77dd", "committedDate": "2020-11-18T01:28:52Z", "message": "DEVX-2183/GH-265: Time concepts: event time, ingestion time"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "89339028d4e6c30703635d13b163897e3976237f", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/89339028d4e6c30703635d13b163897e3976237f", "committedDate": "2020-11-18T01:49:52Z", "message": "Checkpoint"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "01dcfae7c19b502536f6345d659d57b488f202a8", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/01dcfae7c19b502536f6345d659d57b488f202a8", "committedDate": "2020-11-18T02:03:05Z", "message": "Add new steps"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8f07dc82bc8f3c49736e6386e1ac491a11f63158", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/8f07dc82bc8f3c49736e6386e1ac491a11f63158", "committedDate": "2020-11-23T14:31:58Z", "message": "Create avsc schema files and build"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cc2b92ae1848b2a21c1888351d3fb0f708009679", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/cc2b92ae1848b2a21c1888351d3fb0f708009679", "committedDate": "2020-11-23T14:55:32Z", "message": "Checkpoint"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fb01b726b0847d988f9c888b40ed29d647214f4f", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/fb01b726b0847d988f9c888b40ed29d647214f4f", "committedDate": "2020-11-23T17:27:40Z", "message": "Print timestamps"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6776933aeefe4ecba092cd673a96a5f3b63de87f", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/6776933aeefe4ecba092cd673a96a5f3b63de87f", "committedDate": "2020-11-23T19:48:48Z", "message": "Checkpoint 2"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6967d6402d7f2c354a367369ad900a55fb17f075", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/6967d6402d7f2c354a367369ad900a55fb17f075", "committedDate": "2020-11-23T19:52:43Z", "message": "Remove extraneous files"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "158bfa5bc9ca743d9b4fd25526ee0748a93b7998", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/158bfa5bc9ca743d9b4fd25526ee0748a93b7998", "committedDate": "2020-11-30T15:48:57Z", "message": "DEVX-2183: cleanup"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "08080b6e82c4e793e4bad4221334ef7a9c3f312c", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/08080b6e82c4e793e4bad4221334ef7a9c3f312c", "committedDate": "2020-11-30T17:42:19Z", "message": "Prettier format; tweak"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6dff1eec918ec1da995ca854d1c3d7d18fd00247", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/6dff1eec918ec1da995ca854d1c3d7d18fd00247", "committedDate": "2020-11-30T19:25:20Z", "message": "Updated Makefile"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dd530c96f92218c1a2c2e4934e8584011550f61b", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/dd530c96f92218c1a2c2e4934e8584011550f61b", "committedDate": "2020-11-30T19:28:00Z", "message": "Update short answer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1b09c0ffeff30a99853e1180ca75d0debcc211bc", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/1b09c0ffeff30a99853e1180ca75d0debcc211bc", "committedDate": "2020-11-30T19:30:28Z", "message": "Merge branch 'master' into DEVX-2183"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "55c96d9a1f3767adb0068f194c879cdb3dcf76b2", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/55c96d9a1f3767adb0068f194c879cdb3dcf76b2", "committedDate": "2020-11-30T19:33:37Z", "message": "Update introduction"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "546d72d8aa2f4e4cd5207ec00cf3f7ffc9af17db", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/546d72d8aa2f4e4cd5207ec00cf3f7ffc9af17db", "committedDate": "2020-11-30T19:38:50Z", "message": "Add missing status"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "825d42a0ce9364c76db6f07a7fb8d604eccab7f4", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/825d42a0ce9364c76db6f07a7fb8d604eccab7f4", "committedDate": "2020-11-30T19:40:02Z", "message": "Tweak short answer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "faec12b5b2a7a1da6e73e21bb394a21c408352b7", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/faec12b5b2a7a1da6e73e21bb394a21c408352b7", "committedDate": "2020-11-30T19:48:10Z", "message": "Add link to ksqlDB documentation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4b293edf686402061cac1edac5f06d2fe604d33a", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/4b293edf686402061cac1edac5f06d2fe604d33a", "committedDate": "2020-11-30T20:04:10Z", "message": "Tweak"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9934a76c9b9aa8a7f8954c82078cdcbfe473a785", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/9934a76c9b9aa8a7f8954c82078cdcbfe473a785", "committedDate": "2020-11-30T20:59:02Z", "message": "Add explanation for Kafka producer"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQxMzIzMzE2", "url": "https://github.com/confluentinc/kafka-tutorials/pull/647#pullrequestreview-541323316", "createdAt": "2020-11-30T21:50:33Z", "commit": {"oid": "9934a76c9b9aa8a7f8954c82078cdcbfe473a785"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQyMTo1MDozM1rOH8PPlg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQyMjowNjo1M1rOH8Pv9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjkyNjM1OA==", "bodyText": "I know you generally stick to and point out \"event driven language\" any reason why you \"data record\" here instead of \"event\"?", "url": "https://github.com/confluentinc/kafka-tutorials/pull/647#discussion_r532926358", "createdAt": "2020-11-30T21:50:33Z", "author": {"login": "awalther28"}, "path": "_includes/tutorials/time-concepts/ksql/markup/dev/make-application.adoc", "diffHunk": "@@ -0,0 +1,15 @@\n+Achieving event-time semantics typically requires embedding timestamps into the data record at the time it is produced.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9934a76c9b9aa8a7f8954c82078cdcbfe473a785"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjkyNzUwMA==", "bodyText": "I appreciate that you use the same terminology throughout this article. One thing I did notice is that sometimes you put wall-clock in quotes and sometimes you don't. Maybe this is for a specific reason that I didn't pick up on..? If there isn't a reasoning, would you mind making sure that either all mentions of wall-clock are in quotes or not in quotes?", "url": "https://github.com/confluentinc/kafka-tutorials/pull/647#discussion_r532927500", "createdAt": "2020-11-30T21:52:41Z", "author": {"login": "awalther28"}, "path": "_includes/tutorials/time-concepts/ksql/markup/dev/make-event-schema.adoc", "diffHunk": "@@ -0,0 +1,6 @@\n+Then create the following Avro schema file at `src/main/avro/DeviceEvent.avsc` for the event.\n+This schema has two fields, one of which is called `eventTime` that represents the event time, or wall-clock time.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9934a76c9b9aa8a7f8954c82078cdcbfe473a785"}, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjkyODgzNQ==", "bodyText": "I'm not sure this should be committed, should it?", "url": "https://github.com/confluentinc/kafka-tutorials/pull/647#discussion_r532928835", "createdAt": "2020-11-30T21:55:17Z", "author": {"login": "awalther28"}, "path": "_includes/tutorials/kafka-producer-application/kafka/code/gradlew.bat", "diffHunk": "@@ -1,100 +1,104 @@\n-@rem\n-@rem Copyright 2015 the original author or authors.\n-@rem\n-@rem Licensed under the Apache License, Version 2.0 (the \"License\");\n-@rem you may not use this file except in compliance with the License.\n-@rem You may obtain a copy of the License at\n-@rem\n-@rem      https://www.apache.org/licenses/LICENSE-2.0\n-@rem\n-@rem Unless required by applicable law or agreed to in writing, software\n-@rem distributed under the License is distributed on an \"AS IS\" BASIS,\n-@rem WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-@rem See the License for the specific language governing permissions and\n-@rem limitations under the License.\n-@rem\n-\n-@if \"%DEBUG%\" == \"\" @echo off\n-@rem ##########################################################################\n-@rem\n-@rem  Gradle startup script for Windows\n-@rem\n-@rem ##########################################################################\n-\n-@rem Set local scope for the variables with windows NT shell\n-if \"%OS%\"==\"Windows_NT\" setlocal\n-\n-set DIRNAME=%~dp0\n-if \"%DIRNAME%\" == \"\" set DIRNAME=.\n-set APP_BASE_NAME=%~n0\n-set APP_HOME=%DIRNAME%\n-\n-@rem Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script.\n-set DEFAULT_JVM_OPTS=\"-Xmx64m\" \"-Xms64m\"\n-\n-@rem Find java.exe\n-if defined JAVA_HOME goto findJavaFromJavaHome\n-\n-set JAVA_EXE=java.exe\n-%JAVA_EXE% -version >NUL 2>&1\n-if \"%ERRORLEVEL%\" == \"0\" goto init\n-\n-echo.\n-echo ERROR: JAVA_HOME is not set and no 'java' command could be found in your PATH.\n-echo.\n-echo Please set the JAVA_HOME variable in your environment to match the\n-echo location of your Java installation.\n-\n-goto fail\n-\n-:findJavaFromJavaHome\n-set JAVA_HOME=%JAVA_HOME:\"=%\n-set JAVA_EXE=%JAVA_HOME%/bin/java.exe\n-\n-if exist \"%JAVA_EXE%\" goto init\n-\n-echo.\n-echo ERROR: JAVA_HOME is set to an invalid directory: %JAVA_HOME%\n-echo.\n-echo Please set the JAVA_HOME variable in your environment to match the\n-echo location of your Java installation.\n-\n-goto fail\n-\n-:init\n-@rem Get command-line arguments, handling Windows variants\n-\n-if not \"%OS%\" == \"Windows_NT\" goto win9xME_args\n-\n-:win9xME_args\n-@rem Slurp the command line arguments.\n-set CMD_LINE_ARGS=\n-set _SKIP=2\n-\n-:win9xME_args_slurp\n-if \"x%~1\" == \"x\" goto execute\n-\n-set CMD_LINE_ARGS=%*\n-\n-:execute\n-@rem Setup the command line\n-\n-set CLASSPATH=%APP_HOME%\\gradle\\wrapper\\gradle-wrapper.jar\n-\n-@rem Execute Gradle\n-\"%JAVA_EXE%\" %DEFAULT_JVM_OPTS% %JAVA_OPTS% %GRADLE_OPTS% \"-Dorg.gradle.appname=%APP_BASE_NAME%\" -classpath \"%CLASSPATH%\" org.gradle.wrapper.GradleWrapperMain %CMD_LINE_ARGS%\n-\n-:end\n-@rem End local scope for the variables with windows NT shell\n-if \"%ERRORLEVEL%\"==\"0\" goto mainEnd\n-\n-:fail\n-rem Set variable GRADLE_EXIT_CONSOLE if you need the _script_ return code instead of\n-rem the _cmd.exe /c_ return code!\n-if  not \"\" == \"%GRADLE_EXIT_CONSOLE%\" exit 1\n-exit /b 1\n-\n-:mainEnd\n-if \"%OS%\"==\"Windows_NT\" endlocal\n-\n-:omega\n+@rem\r\n+@rem Copyright 2015 the original author or authors.\r\n+@rem\r\n+@rem Licensed under the Apache License, Version 2.0 (the \"License\");\r\n+@rem you may not use this file except in compliance with the License.\r\n+@rem You may obtain a copy of the License at\r\n+@rem\r\n+@rem      https://www.apache.org/licenses/LICENSE-2.0\r\n+@rem\r\n+@rem Unless required by applicable law or agreed to in writing, software\r\n+@rem distributed under the License is distributed on an \"AS IS\" BASIS,\r\n+@rem WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n+@rem See the License for the specific language governing permissions and\r\n+@rem limitations under the License.\r\n+@rem\r\n+\r\n+@if \"%DEBUG%\" == \"\" @echo off\r\n+@rem ##########################################################################\r\n+@rem\r\n+@rem  Gradle startup script for Windows\r\n+@rem\r\n+@rem ##########################################################################\r\n+\r\n+@rem Set local scope for the variables with windows NT shell\r\n+if \"%OS%\"==\"Windows_NT\" setlocal\r\n+\r\n+set DIRNAME=%~dp0\r\n+if \"%DIRNAME%\" == \"\" set DIRNAME=.\r\n+set APP_BASE_NAME=%~n0\r\n+set APP_HOME=%DIRNAME%\r\n+\r\n+@rem Resolve any \".\" and \"..\" in APP_HOME to make it shorter.\r\n+for %%i in (\"%APP_HOME%\") do set APP_HOME=%%~fi\r\n+\r\n+@rem Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script.\r\n+set DEFAULT_JVM_OPTS=\"-Xmx64m\" \"-Xms64m\"\r\n+\r\n+@rem Find java.exe\r\n+if defined JAVA_HOME goto findJavaFromJavaHome\r\n+\r\n+set JAVA_EXE=java.exe\r\n+%JAVA_EXE% -version >NUL 2>&1\r\n+if \"%ERRORLEVEL%\" == \"0\" goto init\r\n+\r\n+echo.\r\n+echo ERROR: JAVA_HOME is not set and no 'java' command could be found in your PATH.\r\n+echo.\r\n+echo Please set the JAVA_HOME variable in your environment to match the\r\n+echo location of your Java installation.\r\n+\r\n+goto fail\r\n+\r\n+:findJavaFromJavaHome\r\n+set JAVA_HOME=%JAVA_HOME:\"=%\r\n+set JAVA_EXE=%JAVA_HOME%/bin/java.exe\r\n+\r\n+if exist \"%JAVA_EXE%\" goto init\r\n+\r\n+echo.\r\n+echo ERROR: JAVA_HOME is set to an invalid directory: %JAVA_HOME%\r\n+echo.\r\n+echo Please set the JAVA_HOME variable in your environment to match the\r\n+echo location of your Java installation.\r\n+\r\n+goto fail\r\n+\r\n+:init\r\n+@rem Get command-line arguments, handling Windows variants\r\n+\r\n+if not \"%OS%\" == \"Windows_NT\" goto win9xME_args\r\n+\r\n+:win9xME_args\r\n+@rem Slurp the command line arguments.\r\n+set CMD_LINE_ARGS=\r\n+set _SKIP=2\r\n+\r\n+:win9xME_args_slurp\r\n+if \"x%~1\" == \"x\" goto execute\r\n+\r\n+set CMD_LINE_ARGS=%*\r\n+\r\n+:execute\r\n+@rem Setup the command line\r\n+\r\n+set CLASSPATH=%APP_HOME%\\gradle\\wrapper\\gradle-wrapper.jar\r\n+\r\n+\r\n+@rem Execute Gradle\r\n+\"%JAVA_EXE%\" %DEFAULT_JVM_OPTS% %JAVA_OPTS% %GRADLE_OPTS% \"-Dorg.gradle.appname=%APP_BASE_NAME%\" -classpath \"%CLASSPATH%\" org.gradle.wrapper.GradleWrapperMain %CMD_LINE_ARGS%\r\n+\r\n+:end\r\n+@rem End local scope for the variables with windows NT shell\r\n+if \"%ERRORLEVEL%\"==\"0\" goto mainEnd\r\n+\r\n+:fail\r\n+rem Set variable GRADLE_EXIT_CONSOLE if you need the _script_ return code instead of\r\n+rem the _cmd.exe /c_ return code!\r\n+if  not \"\" == \"%GRADLE_EXIT_CONSOLE%\" exit 1\r\n+exit /b 1\r\n+\r\n+:mainEnd\r\n+if \"%OS%\"==\"Windows_NT\" endlocal\r\n+\r\n+:omega\r", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9934a76c9b9aa8a7f8954c82078cdcbfe473a785"}, "originalPosition": 204}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjkzMjUyNA==", "bodyText": "This file isn't used in the harness yaml for time-concepts. Can we remove this?", "url": "https://github.com/confluentinc/kafka-tutorials/pull/647#discussion_r532932524", "createdAt": "2020-11-30T22:02:32Z", "author": {"login": "awalther28"}, "path": "_includes/tutorials/time-concepts/ksql/markup/dev/persistent-query.adoc", "diffHunk": "@@ -0,0 +1,5 @@\n+Since the output looks right, the next step is to make the query persistent. This looks exactly like the push query, except we have added a `CREATE TABLE AS` statement to the beginning of it. This statement returns to the CLI prompt right away, having created a persistent stream processing program running in the ksqlDB engine, continuously processing input records and updating the resulting `MOVIE_TICKETS_SOLD` table. Moreover, we don\u2019t see the results of the query displayed in the CLI, because they are updating the newly-created table itself. That table is available to other ksqlDB queries for further processing, and by default all its records are produced to a topic having the same name (MOVIE_TICKETS_SOLD).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9934a76c9b9aa8a7f8954c82078cdcbfe473a785"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjkzMzAzMQ==", "bodyText": "We don't use this either. Can we remove it?", "url": "https://github.com/confluentinc/kafka-tutorials/pull/647#discussion_r532933031", "createdAt": "2020-11-30T22:03:40Z", "author": {"login": "awalther28"}, "path": "_includes/tutorials/time-concepts/ksql/markup/test/make-test-input.adoc", "diffHunk": "@@ -0,0 +1,5 @@\n+The Confluent ksqlDB CLI Docker image contains a program called the `ksql-test-runner`. We can pass this program a JSON file describing our desired input data, a JSON file containing the intended output results, and a file of ksqlDB queries to run, and it will tell us whether our queries successfully turn the input into the output. To get started, create a file at `test/input.json` with the inputs for testing", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9934a76c9b9aa8a7f8954c82078cdcbfe473a785"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjkzMzA3Mg==", "bodyText": "We don't use this either. Can we remove it?", "url": "https://github.com/confluentinc/kafka-tutorials/pull/647#discussion_r532933072", "createdAt": "2020-11-30T22:03:46Z", "author": {"login": "awalther28"}, "path": "_includes/tutorials/time-concepts/ksql/markup/test/make-test-output.adoc", "diffHunk": "@@ -0,0 +1,5 @@\n+Next, create a file at `test/output.json` with the expected outputs:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9934a76c9b9aa8a7f8954c82078cdcbfe473a785"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjkzMzE0MA==", "bodyText": "We don't use this either. Can we remove it?", "url": "https://github.com/confluentinc/kafka-tutorials/pull/647#discussion_r532933140", "createdAt": "2020-11-30T22:03:52Z", "author": {"login": "awalther28"}, "path": "_includes/tutorials/time-concepts/ksql/markup/test/run-tests.adoc", "diffHunk": "@@ -0,0 +1,11 @@\n+Finally, invoke the tests using the test runner and the statements file that you created earlier:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9934a76c9b9aa8a7f8954c82078cdcbfe473a785"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjkzMzI3Ng==", "bodyText": "We don't use this either. Can we remove it?", "url": "https://github.com/confluentinc/kafka-tutorials/pull/647#discussion_r532933276", "createdAt": "2020-11-30T22:04:10Z", "author": {"login": "awalther28"}, "path": "_includes/tutorials/time-concepts/ksql/markup/prod/submit-to-api.adoc", "diffHunk": "@@ -0,0 +1,5 @@\n+Launch your statements into production by sending them to the ksqlDB server REST endpoint with the following command:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9934a76c9b9aa8a7f8954c82078cdcbfe473a785"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjkzNDY0Nw==", "bodyText": "This file isn't used in the harness yaml for time-concepts. Can we remove this?", "url": "https://github.com/confluentinc/kafka-tutorials/pull/647#discussion_r532934647", "createdAt": "2020-11-30T22:06:53Z", "author": {"login": "awalther28"}, "path": "_includes/tutorials/time-concepts/ksql/markup/dev/make-src-file.adoc", "diffHunk": "@@ -0,0 +1,5 @@\n+Now that you have a series of statements that's doing the right thing, the last step is to put them into a file so that they can be used outside the CLI session. Create a file at `src/statements.sql` with the following content:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9934a76c9b9aa8a7f8954c82078cdcbfe473a785"}, "originalPosition": 1}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8869c84846a5b5ada02ac00810fc683c41cb2a2c", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/8869c84846a5b5ada02ac00810fc683c41cb2a2c", "committedDate": "2020-11-30T23:04:32Z", "message": "Remove wall-clock time from KT"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQxMzU4NDc0", "url": "https://github.com/confluentinc/kafka-tutorials/pull/647#pullrequestreview-541358474", "createdAt": "2020-11-30T22:50:50Z", "commit": {"oid": "9934a76c9b9aa8a7f8954c82078cdcbfe473a785"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQyMjo1MDo1MFrOH8Q_fg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQyMzowNjozOVrOH8RZPw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjk1NTAwNg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              introduction: \"Ingestion time is the time at which the Kafka broker appends the record to its log file, versus event time which is the time at which the source creates the record. By default, time-based aggregations in Kafka Streams and ksqlDB operate on the ingestion timestamp, but there may be use cases where they need to operate on the actual time at which the event occurred, in which case the event time should be carried in the message payload . This tutorial will show you how to extract and use the ingestion timestamp and the event timestamp.\"\n          \n          \n            \n              introduction: \"By default, time-based aggregations in Kafka Streams and ksqlDB operate on the record's timestamp, which could be either https://docs.ksqldb.io/en/latest/concepts/time-and-windows-in-ksqldb-queries/#time-semantics[CreateTime or LogAppendTime] depending on the configuration of the topic. But there may be use cases where you need to operate on a timestamp contained inside the message payload. This tutorial will show you how to extract and use either the record's timestamp or the timestamp from a field in the record's value. \"", "url": "https://github.com/confluentinc/kafka-tutorials/pull/647#discussion_r532955006", "createdAt": "2020-11-30T22:50:50Z", "author": {"login": "bbejeck"}, "path": "_data/tutorials.yaml", "diffHunk": "@@ -526,6 +526,17 @@ anomaly-detection:\n     scala: disabled\n     swift: disabled\n \n+time-concepts:\n+  title: \"Ingestion time and event time\"\n+  meta-description: \"Ingestion time and event time\"\n+  slug: \"/time-concepts\"\n+  question: \"What is the difference between ingestion time and event time, and how can I choose which one to use for stream processing?\"\n+  introduction: \"Ingestion time is the time at which the Kafka broker appends the record to its log file, versus event time which is the time at which the source creates the record. By default, time-based aggregations in Kafka Streams and ksqlDB operate on the ingestion timestamp, but there may be use cases where they need to operate on the actual time at which the event occurred, in which case the event time should be carried in the message payload . This tutorial will show you how to extract and use the ingestion timestamp and the event timestamp.\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9934a76c9b9aa8a7f8954c82078cdcbfe473a785"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjk1OTYyMw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            To process data based on *ingestion time*, also known as *log time*, which uses the Kafka record timestamp:\n          \n          \n            \n            To process data based on the Kafka record timestamp, `ROWTIME` :", "url": "https://github.com/confluentinc/kafka-tutorials/pull/647#discussion_r532959623", "createdAt": "2020-11-30T23:01:37Z", "author": {"login": "bbejeck"}, "path": "_includes/tutorials/time-concepts/ksql/markup/answer/short-answer.adoc", "diffHunk": "@@ -0,0 +1,11 @@\n+To process data based on *ingestion time*, also known as *log time*, which uses the Kafka record timestamp:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9934a76c9b9aa8a7f8954c82078cdcbfe473a785"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjk2MTU5OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            To process data based on *event time*, also known as *wall-clock time*, which uses a timestamp from within the record payload:\n          \n          \n            \n            To process data using a timestamp from a field within the record payload:", "url": "https://github.com/confluentinc/kafka-tutorials/pull/647#discussion_r532961599", "createdAt": "2020-11-30T23:06:39Z", "author": {"login": "bbejeck"}, "path": "_includes/tutorials/time-concepts/ksql/markup/answer/short-answer.adoc", "diffHunk": "@@ -0,0 +1,11 @@\n+To process data based on *ingestion time*, also known as *log time*, which uses the Kafka record timestamp:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"groovy\">{% include_raw tutorials/time-concepts/ksql/code/tutorial-steps/dev/create-stream-logtime.sql  %}</code></pre>\n++++++\n+\n+To process data based on *event time*, also known as *wall-clock time*, which uses a timestamp from within the record payload:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9934a76c9b9aa8a7f8954c82078cdcbfe473a785"}, "originalPosition": 7}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b8b0fb8e010749564c83dba906bd13dd6bfb9dd3", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/b8b0fb8e010749564c83dba906bd13dd6bfb9dd3", "committedDate": "2020-11-30T23:12:20Z", "message": "Remove ./ksql/markup/dev/persistent-query.adoc"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQxMzczNjYy", "url": "https://github.com/confluentinc/kafka-tutorials/pull/647#pullrequestreview-541373662", "createdAt": "2020-11-30T23:22:37Z", "commit": {"oid": "b8b0fb8e010749564c83dba906bd13dd6bfb9dd3"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQyMzoyMjozN1rOH8Ry1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQyMzoyMzo1OVrOH8R07Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjk2ODE0OQ==", "bodyText": "Might be good to mention here that ROWTIME is a pseudo column and is the Kafka record timestamp", "url": "https://github.com/confluentinc/kafka-tutorials/pull/647#discussion_r532968149", "createdAt": "2020-11-30T23:22:37Z", "author": {"login": "bbejeck"}, "path": "_includes/tutorials/time-concepts/ksql/markup/dev/transient-query-logtime.adoc", "diffHunk": "@@ -0,0 +1,19 @@\n+Let\u2019s inspect the events in this newly created `TEMPERATURE_READINGS_LOGTIME` stream by running a `SELECT` statement with an `EMIT CHANGES` clause, limited to 10.\n+It shows the payload fields `TEMPERATURE` and `EVENTTIME`, plus the `ROWTIME`.\n+\n++++++\n+<pre class=\"snippet\"><code class=\"sql\">{% include_raw tutorials/time-concepts/ksql/code/tutorial-steps/dev/transient-query-logtime.sql %}</code></pre>\n++++++\n+\n+This should yield the following output:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/time-concepts/ksql/code/tutorial-steps/dev/expected-transient-query-logtime.log %}</code></pre>\n++++++\n+\n+Notice that for each row:\n+\n+- The `EVENTTIME` value in ksqlDB corresponds exactly to the `payload eventTime` set by the producer\n+- The `ROWTIME` value in ksqlDB corresponds exactly to the `log timestamp` printed by the producer's callback (i.e., ingestion time, when the record was written into the broker's log file)\n+\n+All processing on this stream is based on `ROWTIME`, consequently this results in processing based on ingestion time.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8b0fb8e010749564c83dba906bd13dd6bfb9dd3"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjk2ODY4NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            All processing on this stream is based on `ROWTIME`, consequently this results in processing based on ingestion time.\n          \n          \n            \n            All processing on this stream is based on `ROWTIME`, consequently this results in processing based on the timestamp of the Kafka record\n          \n      \n    \n    \n  \n\nor something similar", "url": "https://github.com/confluentinc/kafka-tutorials/pull/647#discussion_r532968685", "createdAt": "2020-11-30T23:23:59Z", "author": {"login": "bbejeck"}, "path": "_includes/tutorials/time-concepts/ksql/markup/dev/transient-query-logtime.adoc", "diffHunk": "@@ -0,0 +1,19 @@\n+Let\u2019s inspect the events in this newly created `TEMPERATURE_READINGS_LOGTIME` stream by running a `SELECT` statement with an `EMIT CHANGES` clause, limited to 10.\n+It shows the payload fields `TEMPERATURE` and `EVENTTIME`, plus the `ROWTIME`.\n+\n++++++\n+<pre class=\"snippet\"><code class=\"sql\">{% include_raw tutorials/time-concepts/ksql/code/tutorial-steps/dev/transient-query-logtime.sql %}</code></pre>\n++++++\n+\n+This should yield the following output:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/time-concepts/ksql/code/tutorial-steps/dev/expected-transient-query-logtime.log %}</code></pre>\n++++++\n+\n+Notice that for each row:\n+\n+- The `EVENTTIME` value in ksqlDB corresponds exactly to the `payload eventTime` set by the producer\n+- The `ROWTIME` value in ksqlDB corresponds exactly to the `log timestamp` printed by the producer's callback (i.e., ingestion time, when the record was written into the broker's log file)\n+\n+All processing on this stream is based on `ROWTIME`, consequently this results in processing based on ingestion time.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8b0fb8e010749564c83dba906bd13dd6bfb9dd3"}, "originalPosition": 19}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7cdd2f6e83f5b6463f134e1e0d2b9701e4c24619", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/7cdd2f6e83f5b6463f134e1e0d2b9701e4c24619", "committedDate": "2020-11-30T23:32:56Z", "message": "Removed unused files (copied via clone)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "17b45677b5948ccb74cb3c7a1b70adead94f33b8", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/17b45677b5948ccb74cb3c7a1b70adead94f33b8", "committedDate": "2020-11-30T23:37:51Z", "message": "Merge branch 'master' into DEVX-2183"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f975ce345ea7fc8df039a6339cca86f5a5229973", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/f975ce345ea7fc8df039a6339cca86f5a5229973", "committedDate": "2020-12-01T00:08:20Z", "message": "Update introduction"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "623bcbee8ce6af37b033bc0ca999c64775fdd4b2", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/623bcbee8ce6af37b033bc0ca999c64775fdd4b2", "committedDate": "2020-12-01T00:13:16Z", "message": "Update  _includes/tutorials/kafka-producer-application/kafka/code/gradlew.bat from master"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a441422f7943aeedc4823f22138460d6a3e7d47f", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/a441422f7943aeedc4823f22138460d6a3e7d47f", "committedDate": "2020-12-01T00:27:23Z", "message": "Update short answer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4899bb349eaf995a5da4743719c2ac67c1136e5e", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/4899bb349eaf995a5da4743719c2ac67c1136e5e", "committedDate": "2020-12-01T00:31:55Z", "message": "Tweak based on feedback from Bill"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "44f4d674dd905583898cada704380db35361a134", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/44f4d674dd905583898cada704380db35361a134", "committedDate": "2020-12-01T00:57:11Z", "message": "Make language consistent"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dab9f2c79bd49a6070bbdaeea82447f19afa9486", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/dab9f2c79bd49a6070bbdaeea82447f19afa9486", "committedDate": "2020-12-01T00:59:59Z", "message": "Tweak"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5f21343fe247b5ace2bb47b1dca65415594d36be", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/5f21343fe247b5ace2bb47b1dca65415594d36be", "committedDate": "2020-12-01T01:24:35Z", "message": "Move sleeps to exaggerate time difference"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f0b413330f984c68efe014a7310c94afe99fe6c4", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/f0b413330f984c68efe014a7310c94afe99fe6c4", "committedDate": "2020-12-01T01:27:53Z", "message": "Update .semaphore/semaphore.yml"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "64b0576efd0f82a9c95b862996dbd2abab8a5217", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/64b0576efd0f82a9c95b862996dbd2abab8a5217", "committedDate": "2020-12-01T01:29:19Z", "message": "Update .semaphore/semaphore.yml"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7e2846c3df65a5a09f5a2e4e7708377b84e7ad15", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/7e2846c3df65a5a09f5a2e4e7708377b84e7ad15", "committedDate": "2020-12-01T01:40:17Z", "message": "Checkout kafka-producer-application files from master"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ce4ba22a1e148d10473ea2b52274f18a3f1f7392", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/ce4ba22a1e148d10473ea2b52274f18a3f1f7392", "committedDate": "2020-12-01T01:46:36Z", "message": "Modify Makefile"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e65048d1bd8c8ad54cca86a6a5f0151f47d86b19", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/e65048d1bd8c8ad54cca86a6a5f0151f47d86b19", "committedDate": "2020-12-01T01:50:37Z", "message": "Move KT to different card"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "56c41ff0aed7abf7f90f23bd65cc2f412a6f2b9a", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/56c41ff0aed7abf7f90f23bd65cc2f412a6f2b9a", "committedDate": "2020-12-01T01:52:14Z", "message": "Simplify KT title"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "86109da971fc3280a9ba541cd3627f0c90cac33f", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/86109da971fc3280a9ba541cd3627f0c90cac33f", "committedDate": "2020-12-01T14:38:01Z", "message": "Simplify answer; simplify stream creation without fields; tweak introduction"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "694d83447304cac3fec8bb44c699b7f807caf93a", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/694d83447304cac3fec8bb44c699b7f807caf93a", "committedDate": "2020-12-01T14:45:48Z", "message": "Change pseudo to system; tweak short answer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2b946119c49ca4ff633bce7512438291152609cf", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/2b946119c49ca4ff633bce7512438291152609cf", "committedDate": "2020-12-01T14:48:50Z", "message": "Tweak short answer"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQxOTg1NDY5", "url": "https://github.com/confluentinc/kafka-tutorials/pull/647#pullrequestreview-541985469", "createdAt": "2020-12-01T14:59:22Z", "commit": {"oid": "2b946119c49ca4ff633bce7512438291152609cf"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2f71abe20630641743df5df8deb7d032594fed05", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/2f71abe20630641743df5df8deb7d032594fed05", "committedDate": "2020-12-01T15:09:55Z", "message": "Spelling"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyMDQxNDgy", "url": "https://github.com/confluentinc/kafka-tutorials/pull/647#pullrequestreview-542041482", "createdAt": "2020-12-01T15:52:33Z", "commit": {"oid": "2f71abe20630641743df5df8deb7d032594fed05"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 112, "cost": 1, "resetAt": "2021-11-01T13:07:16Z"}}}