{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQzODA0ODg1", "number": 675, "title": "Typo fixes for Kafka 101 tutorials", "bodyText": "Description\nFixes for typos I encountered while doing the Kafka 101 tutorials.\nThis PR also removes the mkdir schema step in the kafka-console-consumer-producer tutorial. The directory is actually created by the docker-compose.yml file, so that step is redundant.", "createdAt": "2020-12-22T00:55:37Z", "url": "https://github.com/confluentinc/kafka-tutorials/pull/675", "merged": true, "mergeCommit": {"oid": "7b496343c34763789db942d45281c18c5ad6c6a1"}, "closed": true, "closedAt": "2021-01-04T20:03:45Z", "author": {"login": "brianstrauch"}, "timelineItems": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdoeYOUgH2gAyNTQzODA0ODg1OjZiNzU3MjdjN2FkOWNlMDFjZmMwYzY0MjRmNmJlMzZkOTg2ZWRkNjc=", "endCursor": "Y3Vyc29yOnYyOpPPAAABds73V4gH2gAyNTQzODA0ODg1OjM3OTIwZDQyOGZkYjMwYzUxODA2NWVhOTA0NmI3Yzc4MmQxNDRiNjU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "6b75727c7ad9ce01cfc0c6424f6be36d986edd67", "author": {"user": {"login": "brianstrauch", "name": "Brian Strauch"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/6b75727c7ad9ce01cfc0c6424f6be36d986edd67", "committedDate": "2020-12-21T23:17:49Z", "message": "typo fixes for Kafka 101 tutorials"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3MTE3ODMy", "url": "https://github.com/confluentinc/kafka-tutorials/pull/675#pullrequestreview-557117832", "createdAt": "2020-12-22T14:28:30Z", "commit": {"oid": "6b75727c7ad9ce01cfc0c6424f6be36d986edd67"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxNDoyODozMFrOIJ9CGg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxNDoyODozMFrOIJ9CGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzMwODA1OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            - `acks=all`: highest data durability guarantee, the leader broker persisted the record to its log and received acknowledgment of replication from all in-sync replicas. When using `aks=all`, it's strongly recommended to update https://kafka.apache.org/documentation/#min.insync.replicas[min.insync.replicas] as well.\n          \n          \n            \n            - `acks=all`: highest data durability guarantee, the leader broker persisted the record to its log and received acknowledgment of replication from all in-sync replicas. When using `acks=all`, it's strongly recommended to update https://kafka.apache.org/documentation/#min.insync.replicas[min.insync.replicas] as well.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/675#discussion_r547308058", "createdAt": "2020-12-22T14:28:30Z", "author": {"login": "ybyzek"}, "path": "_includes/tutorials/kafka-producer-application-callback/kafka/markup/dev/make-dev-file.adoc", "diffHunk": "@@ -15,7 +15,7 @@ https://kafka.apache.org/documentation/#acks[acks] - The `KafkaProducer` uses th\n \n - `acks=0`: \"fire and forget\", once the producer sends the record batch it is considered successful\n - `acks=1`: leader broker added the records to its local log but didn't wait for any acknowledgment from the followers\n-- `acks=all`: highest data durability guarantee, the leader broker persisted the record to its log and received acknowledgment of replication from all in-sync replicas When using `aks=all`, it's strongly recommended to update https://kafka.apache.org/documentation/#min.insync.replicas[min.insync.replicas] as well.\n+- `acks=all`: highest data durability guarantee, the leader broker persisted the record to its log and received acknowledgment of replication from all in-sync replicas. When using `aks=all`, it's strongly recommended to update https://kafka.apache.org/documentation/#min.insync.replicas[min.insync.replicas] as well.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b75727c7ad9ce01cfc0c6424f6be36d986edd67"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3MTE3OTcz", "url": "https://github.com/confluentinc/kafka-tutorials/pull/675#pullrequestreview-557117973", "createdAt": "2020-12-22T14:28:42Z", "commit": {"oid": "6b75727c7ad9ce01cfc0c6424f6be36d986edd67"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxNDoyODo0MlrOIJ9Cgw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxNDoyODo0MlrOIJ9Cgw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzMwODE2Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            - `acks=all`: highest data durability guarantee, the leader broker persisted the record to its log and received acknowledgment of replication from all in-sync replicas. When using `aks=all`, it's strongly recommended to update https://kafka.apache.org/documentation/#min.insync.replicas[min.insync.replicas] as well.\n          \n          \n            \n            - `acks=all`: highest data durability guarantee, the leader broker persisted the record to its log and received acknowledgment of replication from all in-sync replicas. When using `acks=all`, it's strongly recommended to update https://kafka.apache.org/documentation/#min.insync.replicas[min.insync.replicas] as well.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/675#discussion_r547308163", "createdAt": "2020-12-22T14:28:42Z", "author": {"login": "ybyzek"}, "path": "_includes/tutorials/kafka-producer-application/kafka/markup/dev/make-dev-file.adoc", "diffHunk": "@@ -15,7 +15,7 @@ https://kafka.apache.org/documentation/#acks[acks] - The `KafkaProducer` uses th\n \n - `acks=0`: \"fire and forget\", once the producer sends the record batch it is considered successful\n - `acks=1`: leader broker added the records to its local log but didn't wait for any acknowledgment from the followers\n-- `acks=all`: highest data durability guarantee, the leader broker persisted the record to its log and received acknowledgment of replication from all in-sync replicas When using `aks=all`, it's strongly recommended to update https://kafka.apache.org/documentation/#min.insync.replicas[min.insync.replicas] as well.\n+- `acks=all`: highest data durability guarantee, the leader broker persisted the record to its log and received acknowledgment of replication from all in-sync replicas. When using `aks=all`, it's strongly recommended to update https://kafka.apache.org/documentation/#min.insync.replicas[min.insync.replicas] as well.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b75727c7ad9ce01cfc0c6424f6be36d986edd67"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3MTE4NjM0", "url": "https://github.com/confluentinc/kafka-tutorials/pull/675#pullrequestreview-557118634", "createdAt": "2020-12-22T14:29:38Z", "commit": {"oid": "6b75727c7ad9ce01cfc0c6424f6be36d986edd67"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxNDoyOTozOFrOIJ9Eag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxNDoyOTozOFrOIJ9Eag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzMwODY1MA==", "bodyText": "\"You're all down now!\" is pretty hip, no? ;)", "url": "https://github.com/confluentinc/kafka-tutorials/pull/675#discussion_r547308650", "createdAt": "2020-12-22T14:29:38Z", "author": {"login": "ybyzek"}, "path": "_includes/tutorials/streams-to-table/kstreams/markup/dev/clean-up.adoc", "diffHunk": "@@ -1,4 +1,4 @@\n-You're all down now!\n+You're all done now!", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b75727c7ad9ce01cfc0c6424f6be36d986edd67"}, "originalPosition": 2}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3MTE5MzI1", "url": "https://github.com/confluentinc/kafka-tutorials/pull/675#pullrequestreview-557119325", "createdAt": "2020-12-22T14:30:36Z", "commit": {"oid": "6b75727c7ad9ce01cfc0c6424f6be36d986edd67"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxNDozMDozNlrOIJ9Gaw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxNDozMDozNlrOIJ9Gaw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzMwOTE2Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              introduction: \"You want to inspect/debug records written to a topic.  The keys and values are longs and doubles, respectively.  In this tutorial you'll learn how to specify key and value deserializers with the console consumer.\"\n          \n          \n            \n              introduction: \"You want to inspect/debug records written to a topic.  Each record key and value is a long and double, respectively.  In this tutorial you'll learn how to specify key and value deserializers with the console consumer.\"", "url": "https://github.com/confluentinc/kafka-tutorials/pull/675#discussion_r547309163", "createdAt": "2020-12-22T14:30:36Z", "author": {"login": "ybyzek"}, "path": "_data/tutorials.yaml", "diffHunk": "@@ -293,11 +293,11 @@ console-consumer-producer-basic:\n     kafka: enabled\n \n console-consumer-primitive-keys-values:\n-  title: \"How to use the console consumer to read non-string primitive keys values\"\n+  title: \"How to use the console consumer to read non-string primitive keys and values\"\n   meta-description: \"How to use the console consumer to read non-string primitive keys and values\"\n   slug: \"/console-consumer-primitive-values\"\n   question: \"How do I specify key and value deserializers when running the Kafka console consumer?\"\n-  introduction: \"You want to inspect/debug records written to a topic.  The keys and values are long and doubles, repsectively.  In this tutorial you'll learn how to specify key and value deserializers with the console consumer\"\n+  introduction: \"You want to inspect/debug records written to a topic.  The keys and values are longs and doubles, respectively.  In this tutorial you'll learn how to specify key and value deserializers with the console consumer.\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b75727c7ad9ce01cfc0c6424f6be36d986edd67"}, "originalPosition": 19}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3MTE5OTIw", "url": "https://github.com/confluentinc/kafka-tutorials/pull/675#pullrequestreview-557119920", "createdAt": "2020-12-22T14:31:24Z", "commit": {"oid": "6b75727c7ad9ce01cfc0c6424f6be36d986edd67"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxNDozMToyNFrOIJ9ICg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxNDozMToyNFrOIJ9ICg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzMwOTU3OA==", "bodyText": "@brianstrauch great catch", "url": "https://github.com/confluentinc/kafka-tutorials/pull/675#discussion_r547309578", "createdAt": "2020-12-22T14:31:24Z", "author": {"login": "ybyzek"}, "path": "_includes/tutorials/console-consumer-producer-avro/kafka/markup/dev/produce-topic-keys-values.adoc", "diffHunk": "@@ -1,7 +1,7 @@\n Kafka works with key-value pairs, but so far you've only sent records with values only.  Well to be fair you've sent key-value pairs, but the keys are `null`.\n Sometimes you'll need to send a valid key in addition to the value from the command line.\n \n-To enable sending full key-value pairs from the command line you add two properties to your console producer, `parse.keys` and `key.separtor`\n+To enable sending full key-value pairs from the command line you add two properties to your console producer, `parse.key` and `key.separator`", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b75727c7ad9ce01cfc0c6424f6be36d986edd67"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3MTIwODIx", "url": "https://github.com/confluentinc/kafka-tutorials/pull/675#pullrequestreview-557120821", "createdAt": "2020-12-22T14:32:42Z", "commit": {"oid": "6b75727c7ad9ce01cfc0c6424f6be36d986edd67"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxNDozMjo0MlrOIJ9KuQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxNDozMjo0MlrOIJ9KuQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzMxMDI2NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            <1> Iterate over all of the records and store the `value`s in a `List`\n          \n          \n            \n            <1> Iterate over all of the records and store each record's `value` in a `List`", "url": "https://github.com/confluentinc/kafka-tutorials/pull/675#discussion_r547310265", "createdAt": "2020-12-22T14:32:42Z", "author": {"login": "ybyzek"}, "path": "_includes/tutorials/kafka-consumer-application/kafka/markup/dev/make-supporting-classes.adoc", "diffHunk": "@@ -31,13 +31,13 @@ The `FileWritingRecordsHandler` is a simple class that writes values of consumed\n       try {\n         Files.write(path, valueList, StandardOpenOption.CREATE, StandardOpenOption.WRITE, StandardOpenOption.APPEND);  //<3>\n       } catch (IOException e) {\n-          throw new RuntimeException(e);\n+        throw new RuntimeException(e);\n       }\n     }\n   }\n ----\n-<1> Iterate over all of the records and store the `value` in a `List`\n-<2> If the isn't empty let's do something!\n+<1> Iterate over all of the records and store the `value`s in a `List`", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b75727c7ad9ce01cfc0c6424f6be36d986edd67"}, "originalPosition": 12}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3MTIwOTQ4", "url": "https://github.com/confluentinc/kafka-tutorials/pull/675#pullrequestreview-557120948", "createdAt": "2020-12-22T14:32:53Z", "commit": {"oid": "6b75727c7ad9ce01cfc0c6424f6be36d986edd67"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxNDozMjo1M1rOIJ9LEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxNDozMjo1M1rOIJ9LEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzMxMDM1Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            <2> If the `List` isn't empty let's do something!\n          \n          \n            \n            <2> If the `List` isn't empty, let's do something!", "url": "https://github.com/confluentinc/kafka-tutorials/pull/675#discussion_r547310352", "createdAt": "2020-12-22T14:32:53Z", "author": {"login": "ybyzek"}, "path": "_includes/tutorials/kafka-consumer-application/kafka/markup/dev/make-supporting-classes.adoc", "diffHunk": "@@ -31,13 +31,13 @@ The `FileWritingRecordsHandler` is a simple class that writes values of consumed\n       try {\n         Files.write(path, valueList, StandardOpenOption.CREATE, StandardOpenOption.WRITE, StandardOpenOption.APPEND);  //<3>\n       } catch (IOException e) {\n-          throw new RuntimeException(e);\n+        throw new RuntimeException(e);\n       }\n     }\n   }\n ----\n-<1> Iterate over all of the records and store the `value` in a `List`\n-<2> If the isn't empty let's do something!\n+<1> Iterate over all of the records and store the `value`s in a `List`\n+<2> If the `List` isn't empty let's do something!", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b75727c7ad9ce01cfc0c6424f6be36d986edd67"}, "originalPosition": 13}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3MTIyMDEx", "url": "https://github.com/confluentinc/kafka-tutorials/pull/675#pullrequestreview-557122011", "createdAt": "2020-12-22T14:34:21Z", "commit": {"oid": "6b75727c7ad9ce01cfc0c6424f6be36d986edd67"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "76d17b9bd297644dd5b50c53a854c0061a493163", "author": {"user": {"login": "brianstrauch", "name": "Brian Strauch"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/76d17b9bd297644dd5b50c53a854c0061a493163", "committedDate": "2020-12-22T21:24:57Z", "message": "Update _includes/tutorials/kafka-producer-application-callback/kafka/markup/dev/make-dev-file.adoc\n\nCo-authored-by: Yeva Byzek <ybyzek@users.noreply.github.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "54edf21e06ec5cd628a86d45d89928ba67214f7c", "author": {"user": {"login": "brianstrauch", "name": "Brian Strauch"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/54edf21e06ec5cd628a86d45d89928ba67214f7c", "committedDate": "2020-12-22T21:25:09Z", "message": "Update _includes/tutorials/kafka-producer-application/kafka/markup/dev/make-dev-file.adoc\n\nCo-authored-by: Yeva Byzek <ybyzek@users.noreply.github.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ab27da888a967fbaa3e83a52a7f1e9621d2f5a1d", "author": {"user": {"login": "brianstrauch", "name": "Brian Strauch"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/ab27da888a967fbaa3e83a52a7f1e9621d2f5a1d", "committedDate": "2020-12-22T21:25:52Z", "message": "Update _data/tutorials.yaml\n\nCo-authored-by: Yeva Byzek <ybyzek@users.noreply.github.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0c0ce1576514666e9711431b5c2f3ed9dd63c433", "author": {"user": {"login": "brianstrauch", "name": "Brian Strauch"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/0c0ce1576514666e9711431b5c2f3ed9dd63c433", "committedDate": "2020-12-22T21:26:07Z", "message": "Update _includes/tutorials/kafka-consumer-application/kafka/markup/dev/make-supporting-classes.adoc\n\nCo-authored-by: Yeva Byzek <ybyzek@users.noreply.github.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bce3109a7422d9ec453b45dad40ad1093b6df986", "author": {"user": {"login": "brianstrauch", "name": "Brian Strauch"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/bce3109a7422d9ec453b45dad40ad1093b6df986", "committedDate": "2020-12-22T21:26:14Z", "message": "Update _includes/tutorials/kafka-consumer-application/kafka/markup/dev/make-supporting-classes.adoc\n\nCo-authored-by: Yeva Byzek <ybyzek@users.noreply.github.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3Mzc3NjM4", "url": "https://github.com/confluentinc/kafka-tutorials/pull/675#pullrequestreview-557377638", "createdAt": "2020-12-22T21:29:55Z", "commit": {"oid": "bce3109a7422d9ec453b45dad40ad1093b6df986"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYxMTc2MDcw", "url": "https://github.com/confluentinc/kafka-tutorials/pull/675#pullrequestreview-561176070", "createdAt": "2021-01-04T16:45:21Z", "commit": {"oid": "bce3109a7422d9ec453b45dad40ad1093b6df986"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNFQxNjo0NToyMVrOIN43Ww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNFQxNjo0NToyMVrOIN43Ww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTQzNDA3NQ==", "bodyText": "Removing these two lines causes the test-harness to fail as the actual output produces 7 records instead of 5.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/675#discussion_r551434075", "createdAt": "2021-01-04T16:45:21Z", "author": {"login": "bbejeck"}, "path": "_includes/tutorials/console-consumer-producer-avro/kafka/code/tutorial-steps/dev/expected-output-step-two.txt", "diffHunk": "@@ -3,5 +3,3 @@\n {\"number\":2343436,\"date\":1596491687,\"shipping_address\":\"89 Addison St, Palo Alto, 94302 CA, USA\",\"subtotal\":10.0,\"shipping_cost\":0.0,\"tax\":1.0,\"grand_total\":11.0}\n {\"number\":2343437,\"date\":1596490492,\"shipping_address\":\"456 Charles St, Beverly Hills, 90209 CA, USA\",\"subtotal\":450.0,\"shipping_cost\":10.0,\"tax\":28.91,\"grand_total\":488.91}\n {\"number\":2343438,\"date\":1596490692,\"shipping_address\":\"456 Preston St, Brooklyn, 11212 NY, USA\",\"subtotal\":34.0,\"shipping_cost\":2.0,\"tax\":3.0,\"grand_total\":39.0}\n-{\"number\":2343439,\"date\":1596501510,\"shipping_address\":\"1600 Pennsylvania Avenue NW, Washington, DC 20500, USA\",\"subtotal\":1000.0,\"shipping_cost\":20.0,\"tax\":0.0,\"grand_total\":1020.0}\n-{\"number\":2343440,\"date\":1596501510,\"shipping_address\":\"55 Music Concourse Dr, San Francisco, CA 94118, USA\",\"subtotal\":345.0,\"shipping_cost\":10.0,\"tax\":10.0,\"grand_total\":365.0}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bce3109a7422d9ec453b45dad40ad1093b6df986"}, "originalPosition": 5}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "37920d428fdb30c518065ea9046b7c782d144b65", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/37920d428fdb30c518065ea9046b7c782d144b65", "committedDate": "2021-01-04T19:54:45Z", "message": "Add back two records to the expected results file"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 137, "cost": 1, "resetAt": "2021-11-01T13:07:16Z"}}}