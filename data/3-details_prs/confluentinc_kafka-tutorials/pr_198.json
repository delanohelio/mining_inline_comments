{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzcyNjEzOTgz", "number": 198, "title": "Kafka-Tutorials: KTable Foreign Key Joins Tutorial", "bodyText": "This PR is my first attempt at a Kafka Tutorial (issue #193) and contains mostly all-new content.\nThe only existing files changed are:\n\nindex.html\n.semaphore/semaphore.yml\n_data/tutorials.yml\n\nI validated the tutorial by running all the steps locally.", "createdAt": "2020-02-07T21:43:10Z", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198", "merged": true, "mergeCommit": {"oid": "d2ea91b184bf70eb4375cae9d0ad02b1afe56d73"}, "closed": true, "closedAt": "2020-03-06T21:44:05Z", "author": {"login": "bbejeck"}, "timelineItems": {"totalCount": 27, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcBZBSDAH2gAyMzcyNjEzOTgzOmNmN2I4YTJlN2Q4NWIyZDlmMzEwOGY2ZDI1NWE4ZTYxOTYxZTBjZDM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcF3KmyAFqTM2MTE0MDI4Mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "cf7b8a2e7d85b2d9f3108f6d255a8e61961e0cd3", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/cf7b8a2e7d85b2d9f3108f6d255a8e61961e0cd3", "committedDate": "2020-02-05T16:49:02Z", "message": "Initial commit of tutorial code"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a042d8ca062b8006c793d1f157d3e52040cc043c", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/a042d8ca062b8006c793d1f157d3e52040cc043c", "committedDate": "2020-02-05T18:07:34Z", "message": "added all tutorial-steps, updated build.gradle file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "66d6a1e8317aaccee9eabe8874811f3be0338a96", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/66d6a1e8317aaccee9eabe8874811f3be0338a96", "committedDate": "2020-02-05T21:52:13Z", "message": "added markup files"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7bee539bbe588bfc45fbe7f8108d847c024ca9e4", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/7bee539bbe588bfc45fbe7f8108d847c024ca9e4", "committedDate": "2020-02-05T21:55:15Z", "message": "More changes for re-named files"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "560600b9ba8245a25c6df6c40114653bb8c38552", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/560600b9ba8245a25c6df6c40114653bb8c38552", "committedDate": "2020-02-06T15:34:51Z", "message": "clean-up"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2cdd4eb964a8164c4f9aa98475c167aa3f496bbf", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/2cdd4eb964a8164c4f9aa98475c167aa3f496bbf", "committedDate": "2020-02-06T17:13:23Z", "message": "added harness, joiner test and last parts to complete tutorial"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3fd8ebe6d98f277c44f2becfd94adc6f5dc753d6", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/3fd8ebe6d98f277c44f2becfd94adc6f5dc753d6", "committedDate": "2020-02-07T17:06:23Z", "message": "add tutorial to index page, fix bugs found from running tutorial, updates for avro console producer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1802eedfe159ea2ab754e248d67593414d1cc6c2", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/1802eedfe159ea2ab754e248d67593414d1cc6c2", "committedDate": "2020-02-07T21:31:56Z", "message": "Code clean up, another round of fixes from running tutorial"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU1NDU2OTM5", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#pullrequestreview-355456939", "createdAt": "2020-02-07T21:47:39Z", "commit": {"oid": "1802eedfe159ea2ab754e248d67593414d1cc6c2"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QyMTo0Nzo0MFrOFnLQIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QyMTo0OToxOVrOFnLSew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYyMzEzNw==", "bodyText": "as of the 5.4 release, the kafka-avro-console-producer accepts a key-schema parameter.  I've validated this works locally.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r376623137", "createdAt": "2020-02-07T21:47:40Z", "author": {"login": "bbejeck"}, "path": "_includes/tutorials/fk-joins/kstreams/code/tutorial-steps/dev/console-producer-albums.sh", "diffHunk": "@@ -0,0 +1,5 @@\n+docker exec -i schema-registry /usr/bin/kafka-avro-console-producer --topic albums --broker-list broker:9092\\\n+  --property \"parse.key=true\"\\", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1802eedfe159ea2ab754e248d67593414d1cc6c2"}, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYyMzYyOQ==", "bodyText": "This is the correct format, it allows for passing in keys to kafka-avro-console-producer", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r376623629", "createdAt": "2020-02-07T21:49:01Z", "author": {"login": "bbejeck"}, "path": "_includes/tutorials/fk-joins/kstreams/code/tutorial-steps/dev/track-purchases.json", "diffHunk": "@@ -0,0 +1,7 @@\n+100:{\"id\": 100, \"album_id\": 5, \"song_title\": \"Houses Of The Holy\", \"price\": 0.99}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1802eedfe159ea2ab754e248d67593414d1cc6c2"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYyMzczOQ==", "bodyText": "This is the correct format, it allows for passing in keys to kafka-avro-console-producer", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r376623739", "createdAt": "2020-02-07T21:49:19Z", "author": {"login": "bbejeck"}, "path": "_includes/tutorials/fk-joins/kstreams/code/tutorial-steps/dev/albums.json", "diffHunk": "@@ -0,0 +1,4 @@\n+5:{\"id\": 5, \"title\": \"Physical Graffiti\", \"artist\": \"Led Zeppelin\", \"genre\": \"Rock\"}\n+6:{\"id\": 6, \"title\": \"Highway to Hell\",   \"artist\": \"AC/DC\", \"genre\": \"Rock\"}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1802eedfe159ea2ab754e248d67593414d1cc6c2"}, "originalPosition": 2}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e6470a5f2ffe802e384aea69cb3273b37c5ebdcc", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/e6470a5f2ffe802e384aea69cb3273b37c5ebdcc", "committedDate": "2020-02-07T22:14:16Z", "message": "Fixed bad directory in Makefile"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU1NDcyOTk2", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#pullrequestreview-355472996", "createdAt": "2020-02-07T22:23:56Z", "commit": {"oid": "e6470a5f2ffe802e384aea69cb3273b37c5ebdcc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QyMjoyMzo1N1rOFnMCUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QyMjoyMzo1N1rOFnMCUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYzNTk4NA==", "bodyText": "There is a built in bash function (until) for this if you're interested...\nuntil readiness_probe\ndo\n  sleep 5\ndone", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r376635984", "createdAt": "2020-02-07T22:23:57Z", "author": {"login": "rspurgeon"}, "path": "_includes/tutorials/fk-joins/kstreams/code/tutorial-steps/dev/wait-for-containers.sh", "diffHunk": "@@ -0,0 +1,14 @@\n+#!/bin/bash\n+\n+function readiness_probe {\n+    nc -z -w 2 0.0.0.0 29092\n+}\n+\n+echo \"Waiting for the broker to become available ...\"\n+\n+readiness_probe\n+\n+while [[ $? != 0 ]]; do\n+    sleep 5\n+    readiness_probe\n+done", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e6470a5f2ffe802e384aea69cb3273b37c5ebdcc"}, "originalPosition": 14}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU1NDc1NjE0", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#pullrequestreview-355475614", "createdAt": "2020-02-07T22:30:25Z", "commit": {"oid": "e6470a5f2ffe802e384aea69cb3273b37c5ebdcc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QyMjozMDoyNVrOFnMKaA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QyMjozMDoyNVrOFnMKaA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYzODA1Ng==", "bodyText": "copy and paste monster...  filtering should be fk-joins", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r376638056", "createdAt": "2020-02-07T22:30:25Z", "author": {"login": "rspurgeon"}, "path": "_includes/tutorials/fk-joins/kstreams/markup/dev/start-compose.adoc", "diffHunk": "@@ -0,0 +1,5 @@\n+And launch it by running:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/filtering/kstreams/code/tutorial-steps/dev/docker-compose-up.sh %}</code></pre>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e6470a5f2ffe802e384aea69cb3273b37c5ebdcc"}, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU1NDc5ODg2", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#pullrequestreview-355479886", "createdAt": "2020-02-07T22:41:56Z", "commit": {"oid": "e6470a5f2ffe802e384aea69cb3273b37c5ebdcc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QyMjo0MTo1NlrOFnMX5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QyMjo0MTo1NlrOFnMX5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY0MTUxMQ==", "bodyText": "typo in trackPurcases", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r376641511", "createdAt": "2020-02-07T22:41:56Z", "author": {"login": "rspurgeon"}, "path": "_includes/tutorials/fk-joins/kstreams/markup/dev/make-avro-dir.adoc", "diffHunk": "@@ -0,0 +1,9 @@\n+This tutorial uses three streams: one called `albums` that holds album reference data, one called `trackPurchases` that holds an update-stream of inbound music track purchases, and one called `musicInterestTable` that holds the result of a foreign-key join between purchases and albums.  In the case the inbound keys are different, but the `trackPurcases` stream has the id of the album in its value, so we can use the `KTable` foreign-key join funcitionality to extract the album id and perform the join.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e6470a5f2ffe802e384aea69cb3273b37c5ebdcc"}, "originalPosition": 1}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU1NDgyMzI2", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#pullrequestreview-355482326", "createdAt": "2020-02-07T22:48:43Z", "commit": {"oid": "e6470a5f2ffe802e384aea69cb3273b37c5ebdcc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QyMjo0ODo0NFrOFnMfsg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QyMjo0ODo0NFrOFnMfsg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY0MzUwNg==", "bodyText": "When you join two tables in a relational database, by default you get a new table containing all of the columns of the left table plus all of the columns of the right table. When you join a table and a table, you get a new table, but you must be explicit about the value of that table\u2014the combination between the value in the table and the assocaited value in the table.\n\nThis was difficult to follow, maybe try a revision?", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r376643506", "createdAt": "2020-02-07T22:48:44Z", "author": {"login": "rspurgeon"}, "path": "_includes/tutorials/fk-joins/kstreams/markup/dev/make-joiner.adoc", "diffHunk": "@@ -0,0 +1,9 @@\n+For the ValueJoiner class, create the following file at `src/main/java/io/confluent/developer/MusicInterestJoiner.java`.\n+\n+When you join two tables in a relational database, by default you get a new table containing all of the columns of the left table plus all of the columns of the right table. When you join a table and a table, you get a new table, but you must be explicit about the value of that table\u2014the combination between the value in the table and the assocaited value in the table. The `https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/kstream/ValueJoiner.html[ValueJoiner]` interface in the Streams API does this work. The single `apply()` method takes the \"left\" table and the \"right\" table values as parameters, and returns the value of the joined table as output. (Their keys are not a part of the equation, because they are equal by definition and do not change in the result.) As you can see here, this is just a matter of creating a `MusicInterest` object and populating it with the relevant fields of the input album and track purchase.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e6470a5f2ffe802e384aea69cb3273b37c5ebdcc"}, "originalPosition": 3}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d4a677bc66b4b8faae46dfa7a36003ed27bcf925", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/d4a677bc66b4b8faae46dfa7a36003ed27bcf925", "committedDate": "2020-02-10T15:40:40Z", "message": "Fix name of test file in harness yml"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "db0cbf4811a4e1cdbeb17a81923027734f04fa88", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/db0cbf4811a4e1cdbeb17a81923027734f04fa88", "committedDate": "2020-02-10T19:54:55Z", "message": "Use TestUtils to create state dir"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7fae29b41f44a4606243a3946fdaedbd05157aa3", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/7fae29b41f44a4606243a3946fdaedbd05157aa3", "committedDate": "2020-02-10T21:29:52Z", "message": "Fixed Makefile for ci build, other changes per review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8721f5a9f3fd1f53f44befc65e00ace55a1f8825", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/8721f5a9f3fd1f53f44befc65e00ace55a1f8825", "committedDate": "2020-02-10T21:36:58Z", "message": "Add newlines to output files"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "424c65e4ca88513e5f79d02ccac90d6f7cae8457", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/424c65e4ca88513e5f79d02ccac90d6f7cae8457", "committedDate": "2020-02-10T22:11:56Z", "message": "Increase pause to harness for results, add close timeout back to streams, remove spaces from expected output results"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU3Nzg0Njkw", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#pullrequestreview-357784690", "createdAt": "2020-02-12T21:02:41Z", "commit": {"oid": "424c65e4ca88513e5f79d02ccac90d6f7cae8457"}, "state": "COMMENTED", "comments": {"totalCount": 20, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMlQyMTowMjo0MVrOFo-czQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMlQyMTo1Nzo1MFrOFpACPw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUxMDU0MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              title: \"How to join a table and a table with a foriegn key\"\n          \n          \n            \n              title: \"How to join a table and a table with a foreign key\"", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r378510541", "createdAt": "2020-02-12T21:02:41Z", "author": {"login": "colinhicks"}, "path": "_data/tutorials.yaml", "diffHunk": "@@ -72,6 +72,15 @@ joining-stream-stream:\n     ksql: enabled\n     kstreams: enabled\n \n+fk-joins:\n+  title: \"How to join a table and a table with a foriegn key\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "424c65e4ca88513e5f79d02ccac90d6f7cae8457"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUxMTM3MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              meta-description: \"Learn how to use the KTable foriegn key join functionality\"\n          \n          \n            \n              meta-description: \"Learn how to join two tables with different primary keys\"", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r378511371", "createdAt": "2020-02-12T21:04:38Z", "author": {"login": "colinhicks"}, "path": "_data/tutorials.yaml", "diffHunk": "@@ -72,6 +72,15 @@ joining-stream-stream:\n     ksql: enabled\n     kstreams: enabled\n \n+fk-joins:\n+  title: \"How to join a table and a table with a foriegn key\"\n+  meta-description: \"Learn how to use the KTable foriegn key join functionality\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "424c65e4ca88513e5f79d02ccac90d6f7cae8457"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUxMTg4OA==", "bodyText": "Changing this here, so that it matches the shortened path segment in the url.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              slug: \"/table-table-foreign-key-joins\"\n          \n          \n            \n              slug: \"/foreign-key-joins\"", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r378511888", "createdAt": "2020-02-12T21:05:50Z", "author": {"login": "colinhicks"}, "path": "_data/tutorials.yaml", "diffHunk": "@@ -72,6 +72,15 @@ joining-stream-stream:\n     ksql: enabled\n     kstreams: enabled\n \n+fk-joins:\n+  title: \"How to join a table and a table with a foriegn key\"\n+  meta-description: \"Learn how to use the KTable foriegn key join functionality\"\n+  slug: \"/table-table-foreign-key-joins\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "424c65e4ca88513e5f79d02ccac90d6f7cae8457"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUxMjUyMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              problem: \"you need to join two tables, but the primary keys are different so you need to use a foriegn key to complete the join\"\n          \n          \n            \n              problem: \"you need to join two tables, but they have different primary keys\"", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r378512522", "createdAt": "2020-02-12T21:07:07Z", "author": {"login": "colinhicks"}, "path": "_data/tutorials.yaml", "diffHunk": "@@ -72,6 +72,15 @@ joining-stream-stream:\n     ksql: enabled\n     kstreams: enabled\n \n+fk-joins:\n+  title: \"How to join a table and a table with a foriegn key\"\n+  meta-description: \"Learn how to use the KTable foriegn key join functionality\"\n+  slug: \"/table-table-foreign-key-joins\"\n+  problem: \"you need to join two tables, but the primary keys are different so you need to use a foriegn key to complete the join\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "424c65e4ca88513e5f79d02ccac90d6f7cae8457"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUxNDc2OQ==", "bodyText": "Slight rewording to combine and shorten last two sentences.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              introduction: \"Suppose you are running an internet streaming music service where you offer albums or individual music tracks for sale.  You'd like to track trends in listener preference by joining the track purchases against the table of albums.  The issue is that the track purchase key doesn't align with the primary key for the album table.  But the value of the track purchase contains the id of the album.  Using the KTable-KTable foreign key join functionality, you can extract the album id from the track purchase and complete the join against the album table.\"\n          \n          \n            \n              introduction: \"Suppose you are running an internet streaming music service where you offer albums or individual music tracks for sale.  You'd like to track trends in listener preference by joining the track purchases against the table of albums.  The issue is that the track purchase key doesn't align with the primary key for the album table.  However, since the value of the track purchase contains the id of the album, you can extract the album id from the track purchase and complete a foreign key join against the album table.\"", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r378514769", "createdAt": "2020-02-12T21:12:02Z", "author": {"login": "colinhicks"}, "path": "_data/tutorials.yaml", "diffHunk": "@@ -72,6 +72,15 @@ joining-stream-stream:\n     ksql: enabled\n     kstreams: enabled\n \n+fk-joins:\n+  title: \"How to join a table and a table with a foriegn key\"\n+  meta-description: \"Learn how to use the KTable foriegn key join functionality\"\n+  slug: \"/table-table-foreign-key-joins\"\n+  problem: \"you need to join two tables, but the primary keys are different so you need to use a foriegn key to complete the join\"\n+  introduction: \"Suppose you are running an internet streaming music service where you offer albums or individual music tracks for sale.  You'd like to track trends in listener preference by joining the track purchases against the table of albums.  The issue is that the track purchase key doesn't align with the primary key for the album table.  But the value of the track purchase contains the id of the album.  Using the KTable-KTable foreign key join functionality, you can extract the album id from the track purchase and complete the join against the album table.\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "424c65e4ca88513e5f79d02ccac90d6f7cae8457"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUxNzMxNQ==", "bodyText": "It would be nice to link to the Confluent docs for FK joins. But this is the only thing docs searched returned: https://docs.confluent.io/current/streams/upgrade-guide.html#foreign-key-ktable-ktable-joins\n\nForeign key KTable-KTable joins\nTODO: KIP-213\n\nMaybe there's something else?", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r378517315", "createdAt": "2020-02-12T21:17:24Z", "author": {"login": "colinhicks"}, "path": "_data/tutorials.yaml", "diffHunk": "@@ -72,6 +72,15 @@ joining-stream-stream:\n     ksql: enabled\n     kstreams: enabled\n \n+fk-joins:\n+  title: \"How to join a table and a table with a foriegn key\"\n+  meta-description: \"Learn how to use the KTable foriegn key join functionality\"\n+  slug: \"/table-table-foreign-key-joins\"\n+  problem: \"you need to join two tables, but the primary keys are different so you need to use a foriegn key to complete the join\"\n+  introduction: \"Suppose you are running an internet streaming music service where you offer albums or individual music tracks for sale.  You'd like to track trends in listener preference by joining the track purchases against the table of albums.  The issue is that the track purchase key doesn't align with the primary key for the album table.  But the value of the track purchase contains the id of the album.  Using the KTable-KTable foreign key join functionality, you can extract the album id from the track purchase and complete the join against the album table.\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUxNDc2OQ=="}, "originalCommit": {"oid": "424c65e4ca88513e5f79d02ccac90d6f7cae8457"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUxOTIyOA==", "bodyText": "Is the first hyphen intentional, here? It's also in test.properties, but not in prod.properties", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r378519228", "createdAt": "2020-02-12T21:21:28Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/fk-joins/kstreams/code/configuration/dev.properties", "diffHunk": "@@ -0,0 +1,16 @@\n+application.id=-fk-joining-app", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "424c65e4ca88513e5f79d02ccac90d6f7cae8457"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUyMTM1NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            This tutorial uses three streams: one called `albums` that holds album reference data, one called `trackPurchases` that holds an update-stream of inbound music track purchases, and one called `musicInterestTable` that holds the result of a foreign-key join between trackPurchases and albums.  In the case the inbound keys are different, but the `trackPurchases` stream has the id of the album in its value, so we can use the `KTable` foreign-key join funcitionality to extract the album id and perform the join.\n          \n          \n            \n            This tutorial uses three streams: one called `albums` that holds album reference data, one called `trackPurchases` that holds an update-stream of inbound music track purchases, and one called `musicInterestTable` that holds the result of a foreign-key join between `trackPurchases` and `albums`.\n          \n          \n            \n            \n          \n          \n            \n            In this case the inbound keys are different, but the `trackPurchases` stream has the id of the album in its value. We will use the `KTable` foreign-key join functionality to extract the album id and perform the join.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r378521354", "createdAt": "2020-02-12T21:25:54Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/fk-joins/kstreams/markup/dev/make-avro-dir.adoc", "diffHunk": "@@ -0,0 +1,9 @@\n+This tutorial uses three streams: one called `albums` that holds album reference data, one called `trackPurchases` that holds an update-stream of inbound music track purchases, and one called `musicInterestTable` that holds the result of a foreign-key join between trackPurchases and albums.  In the case the inbound keys are different, but the `trackPurchases` stream has the id of the album in its value, so we can use the `KTable` foreign-key join funcitionality to extract the album id and perform the join.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "424c65e4ca88513e5f79d02ccac90d6f7cae8457"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUyNTE2NA==", "bodyText": "Suggesting a few wording tweaks and a paragraph break:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Now that we have our table of albums, we'll move on to the tracks available for purchase stream.  While it may seem that purchasing music tracks would end up in a `KStream`, there are a couple of circumstances that allow us to represent the track purchases as a table instead.  First each track purchase has a simple `Long` as the key, representing a increasing sequence number for each purchase.  So each purchase is unique and we don't need to worry about later sales replacing earlier purchases by the same customer.  Secondly, we need to join the track purchase with an existing album so we can create trend of which artists and genre seem to be either gaining or losing poplularity.\n          \n          \n            \n            Now that we have our table of albums, we'll move on to the tracks available for purchase stream.  While it may seem that purchasing music tracks would end up in a `KStream`, there are a couple of circumstances that allow us to represent the track purchases as a table instead.\n          \n          \n            \n            \n          \n          \n            \n            First, each track purchase has a simple `Long` key, representing a increasing sequence number for each purchase.  This means each purchase is unique, and we don't need to worry about later sales replacing earlier purchases by the same customer.  Second, we need to join each track purchase with an existing album so we can create a trend of artists and genres gaining or losing popularity.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r378525164", "createdAt": "2020-02-12T21:33:50Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/fk-joins/kstreams/markup/dev/make-topology.adoc", "diffHunk": "@@ -0,0 +1,21 @@\n+Then create the following file at `src/main/java/io/confluent/developer/FkJoinTableToTable.java`. Let's take a close look at the `buildTopology()` method, which uses the Kafka Streams DSL.\n+\n+The first thing the method does is create an instance of `https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/StreamsBuilder.html[StreamsBuilder]`, which is the helper object that lets us build our topology. With our builder in hand, there are three things we need to do. First, we call the `table()` method to create a `https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/kstream/KTable.html[KStream]<Long, Album>` object.  In this case, we can use a `KTable` as each we know the topic is keyed by the album id and each album-id is unique.\n+\n+Now that we have our table of albums, we'll move on to the tracks available for purchase stream.  While it may seem that purchasing music tracks would end up in a `KStream`, there are a couple of circumstances that allow us to represent the track purchases as a table instead.  First each track purchase has a simple `Long` as the key, representing a increasing sequence number for each purchase.  So each purchase is unique and we don't need to worry about later sales replacing earlier purchases by the same customer.  Secondly, we need to join the track purchase with an existing album so we can create trend of which artists and genre seem to be either gaining or losing poplularity.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "424c65e4ca88513e5f79d02ccac90d6f7cae8457"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUyODg3Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            But if the key is a monatomically increasing number, how can we join against the album table?  The track-purchase table has the album-id as part of its value payload, so we can use the new overaloaded `KTable.join` method that accepts a `ForiegnKeyExtractor` parameter that allows us to pull the primary-key of the value of one table to enable a join with another table.\n          \n          \n            \n            But if the key is a monotonically increasing number, how can we join against the `album` table?  The `trackPurchases` table has the album id as part of its value payload, so we can use the `KTable.join` method with a `ForeignKeyExtractor` parameter to extract the album id for the join comparison.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r378528877", "createdAt": "2020-02-12T21:41:32Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/fk-joins/kstreams/markup/dev/make-topology.adoc", "diffHunk": "@@ -0,0 +1,21 @@\n+Then create the following file at `src/main/java/io/confluent/developer/FkJoinTableToTable.java`. Let's take a close look at the `buildTopology()` method, which uses the Kafka Streams DSL.\n+\n+The first thing the method does is create an instance of `https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/StreamsBuilder.html[StreamsBuilder]`, which is the helper object that lets us build our topology. With our builder in hand, there are three things we need to do. First, we call the `table()` method to create a `https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/kstream/KTable.html[KStream]<Long, Album>` object.  In this case, we can use a `KTable` as each we know the topic is keyed by the album id and each album-id is unique.\n+\n+Now that we have our table of albums, we'll move on to the tracks available for purchase stream.  While it may seem that purchasing music tracks would end up in a `KStream`, there are a couple of circumstances that allow us to represent the track purchases as a table instead.  First each track purchase has a simple `Long` as the key, representing a increasing sequence number for each purchase.  So each purchase is unique and we don't need to worry about later sales replacing earlier purchases by the same customer.  Secondly, we need to join the track purchase with an existing album so we can create trend of which artists and genre seem to be either gaining or losing poplularity.\n+\n+But if the key is a monatomically increasing number, how can we join against the album table?  The track-purchase table has the album-id as part of its value payload, so we can use the new overaloaded `KTable.join` method that accepts a `ForiegnKeyExtractor` parameter that allows us to pull the primary-key of the value of one table to enable a join with another table.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "424c65e4ca88513e5f79d02ccac90d6f7cae8457"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUzMDg3OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Creating the `https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/kstream/KTable.html[KTable]<Long,TrackPurchase>` of track purchases looks just like our first step with the albums: we create a table from the topic. Note that we must choose the same key\u2014album ID\u2014for our join to work.  You accomplish this by providing a Java 8 method handle `TrackPurchase::getAlbumId` to extact the correct id for sucessful completion of the join.\n          \n          \n            \n            Creating the `https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/kstream/KTable.html[KTable]<Long,TrackPurchase>` of track purchases looks just like our first step with the albums: we create a table from the topic. Note that we must choose the same key\u2014the album id\u2014for our join to work.  You can accomplish this by providing a Java 8 method handle `TrackPurchase::getAlbumId` to extract the id.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r378530879", "createdAt": "2020-02-12T21:45:51Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/fk-joins/kstreams/markup/dev/make-topology.adoc", "diffHunk": "@@ -0,0 +1,21 @@\n+Then create the following file at `src/main/java/io/confluent/developer/FkJoinTableToTable.java`. Let's take a close look at the `buildTopology()` method, which uses the Kafka Streams DSL.\n+\n+The first thing the method does is create an instance of `https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/StreamsBuilder.html[StreamsBuilder]`, which is the helper object that lets us build our topology. With our builder in hand, there are three things we need to do. First, we call the `table()` method to create a `https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/kstream/KTable.html[KStream]<Long, Album>` object.  In this case, we can use a `KTable` as each we know the topic is keyed by the album id and each album-id is unique.\n+\n+Now that we have our table of albums, we'll move on to the tracks available for purchase stream.  While it may seem that purchasing music tracks would end up in a `KStream`, there are a couple of circumstances that allow us to represent the track purchases as a table instead.  First each track purchase has a simple `Long` as the key, representing a increasing sequence number for each purchase.  So each purchase is unique and we don't need to worry about later sales replacing earlier purchases by the same customer.  Secondly, we need to join the track purchase with an existing album so we can create trend of which artists and genre seem to be either gaining or losing poplularity.\n+\n+But if the key is a monatomically increasing number, how can we join against the album table?  The track-purchase table has the album-id as part of its value payload, so we can use the new overaloaded `KTable.join` method that accepts a `ForiegnKeyExtractor` parameter that allows us to pull the primary-key of the value of one table to enable a join with another table.\n+\n+Creating the `https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/kstream/KTable.html[KTable]<Long,TrackPurchase>` of track purchases looks just like our first step with the albums: we create a table from the topic. Note that we must choose the same key\u2014album ID\u2014for our join to work.  You accomplish this by providing a Java 8 method handle `TrackPurchase::getAlbumId` to extact the correct id for sucessful completion of the join.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "424c65e4ca88513e5f79d02ccac90d6f7cae8457"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUzMTcxMw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            At this point we should discuss the importance of the order in which we use the `KTable` parameters in the `join()`.  The `trackPurchases` table is the *_calling_* or *_left-side-table_* and is the table where the primary-key is embedded in its value.  So the *_left-side-table_*  always provides the `ForiegnKeyExtractor` function.\n          \n          \n            \n            At this point we should discuss the importance of the order in which we use the `KTable` parameters in the `join()`.  The `trackPurchases` table is the *_calling_* or *_left-side-table_*, and it is the table where the primary key is embedded in its value.  The *_left-side-table_*  always provides the `ForeignKeyExtractor` function.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r378531713", "createdAt": "2020-02-12T21:47:34Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/fk-joins/kstreams/markup/dev/make-topology.adoc", "diffHunk": "@@ -0,0 +1,21 @@\n+Then create the following file at `src/main/java/io/confluent/developer/FkJoinTableToTable.java`. Let's take a close look at the `buildTopology()` method, which uses the Kafka Streams DSL.\n+\n+The first thing the method does is create an instance of `https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/StreamsBuilder.html[StreamsBuilder]`, which is the helper object that lets us build our topology. With our builder in hand, there are three things we need to do. First, we call the `table()` method to create a `https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/kstream/KTable.html[KStream]<Long, Album>` object.  In this case, we can use a `KTable` as each we know the topic is keyed by the album id and each album-id is unique.\n+\n+Now that we have our table of albums, we'll move on to the tracks available for purchase stream.  While it may seem that purchasing music tracks would end up in a `KStream`, there are a couple of circumstances that allow us to represent the track purchases as a table instead.  First each track purchase has a simple `Long` as the key, representing a increasing sequence number for each purchase.  So each purchase is unique and we don't need to worry about later sales replacing earlier purchases by the same customer.  Secondly, we need to join the track purchase with an existing album so we can create trend of which artists and genre seem to be either gaining or losing poplularity.\n+\n+But if the key is a monatomically increasing number, how can we join against the album table?  The track-purchase table has the album-id as part of its value payload, so we can use the new overaloaded `KTable.join` method that accepts a `ForiegnKeyExtractor` parameter that allows us to pull the primary-key of the value of one table to enable a join with another table.\n+\n+Creating the `https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/kstream/KTable.html[KTable]<Long,TrackPurchase>` of track purchases looks just like our first step with the albums: we create a table from the topic. Note that we must choose the same key\u2014album ID\u2014for our join to work.  You accomplish this by providing a Java 8 method handle `TrackPurchase::getAlbumId` to extact the correct id for sucessful completion of the join.\n+\n+At this point we should discuss the importance of the order in which we use the `KTable` parameters in the `join()`.  The `trackPurchases` table is the *_calling_* or *_left-side-table_* and is the table where the primary-key is embedded in its value.  So the *_left-side-table_*  always provides the `ForiegnKeyExtractor` function.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "424c65e4ca88513e5f79d02ccac90d6f7cae8457"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUzMjU0Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The `albums` table is the *_right-side-table_* and always has the `primary-key` for the join. So, if you tried `albums.join(trackPurchases..)` the join would never work as the `albums` table has no knowlege of the `trackPurchases` table details.\n          \n          \n            \n            The `albums` table is the *_right-side-table_* and always has the primary key for the join. This is where order matters, for example: if you tried `albums.join(trackPurchases..)` the join would never work as the `albums` table has no knowledge of the `trackPurchases` table details.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r378532546", "createdAt": "2020-02-12T21:49:20Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/fk-joins/kstreams/markup/dev/make-topology.adoc", "diffHunk": "@@ -0,0 +1,21 @@\n+Then create the following file at `src/main/java/io/confluent/developer/FkJoinTableToTable.java`. Let's take a close look at the `buildTopology()` method, which uses the Kafka Streams DSL.\n+\n+The first thing the method does is create an instance of `https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/StreamsBuilder.html[StreamsBuilder]`, which is the helper object that lets us build our topology. With our builder in hand, there are three things we need to do. First, we call the `table()` method to create a `https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/kstream/KTable.html[KStream]<Long, Album>` object.  In this case, we can use a `KTable` as each we know the topic is keyed by the album id and each album-id is unique.\n+\n+Now that we have our table of albums, we'll move on to the tracks available for purchase stream.  While it may seem that purchasing music tracks would end up in a `KStream`, there are a couple of circumstances that allow us to represent the track purchases as a table instead.  First each track purchase has a simple `Long` as the key, representing a increasing sequence number for each purchase.  So each purchase is unique and we don't need to worry about later sales replacing earlier purchases by the same customer.  Secondly, we need to join the track purchase with an existing album so we can create trend of which artists and genre seem to be either gaining or losing poplularity.\n+\n+But if the key is a monatomically increasing number, how can we join against the album table?  The track-purchase table has the album-id as part of its value payload, so we can use the new overaloaded `KTable.join` method that accepts a `ForiegnKeyExtractor` parameter that allows us to pull the primary-key of the value of one table to enable a join with another table.\n+\n+Creating the `https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/kstream/KTable.html[KTable]<Long,TrackPurchase>` of track purchases looks just like our first step with the albums: we create a table from the topic. Note that we must choose the same key\u2014album ID\u2014for our join to work.  You accomplish this by providing a Java 8 method handle `TrackPurchase::getAlbumId` to extact the correct id for sucessful completion of the join.\n+\n+At this point we should discuss the importance of the order in which we use the `KTable` parameters in the `join()`.  The `trackPurchases` table is the *_calling_* or *_left-side-table_* and is the table where the primary-key is embedded in its value.  So the *_left-side-table_*  always provides the `ForiegnKeyExtractor` function.\n+\n+The `albums` table is the *_right-side-table_* and always has the `primary-key` for the join. So, if you tried `albums.join(trackPurchases..)` the join would never work as the `albums` table has no knowlege of the `trackPurchases` table details.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "424c65e4ca88513e5f79d02ccac90d6f7cae8457"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUzMzM4MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            If you have a situation where you have two tables where the primary-keys don't match, but *_each_* table has reference to each other's primary key, the the order of the tables in the join method won't matter.  But that scenario seems unlikely in practice.\n          \n          \n            \n            If you have a situation where you have two tables for which the primary keys don't match, yet *_each_* table has a reference to the other's primary key, then the order of the tables in the join method won't matter.  This scenario is probably unlikely in practice.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r378533381", "createdAt": "2020-02-12T21:51:10Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/fk-joins/kstreams/markup/dev/make-topology.adoc", "diffHunk": "@@ -0,0 +1,21 @@\n+Then create the following file at `src/main/java/io/confluent/developer/FkJoinTableToTable.java`. Let's take a close look at the `buildTopology()` method, which uses the Kafka Streams DSL.\n+\n+The first thing the method does is create an instance of `https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/StreamsBuilder.html[StreamsBuilder]`, which is the helper object that lets us build our topology. With our builder in hand, there are three things we need to do. First, we call the `table()` method to create a `https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/kstream/KTable.html[KStream]<Long, Album>` object.  In this case, we can use a `KTable` as each we know the topic is keyed by the album id and each album-id is unique.\n+\n+Now that we have our table of albums, we'll move on to the tracks available for purchase stream.  While it may seem that purchasing music tracks would end up in a `KStream`, there are a couple of circumstances that allow us to represent the track purchases as a table instead.  First each track purchase has a simple `Long` as the key, representing a increasing sequence number for each purchase.  So each purchase is unique and we don't need to worry about later sales replacing earlier purchases by the same customer.  Secondly, we need to join the track purchase with an existing album so we can create trend of which artists and genre seem to be either gaining or losing poplularity.\n+\n+But if the key is a monatomically increasing number, how can we join against the album table?  The track-purchase table has the album-id as part of its value payload, so we can use the new overaloaded `KTable.join` method that accepts a `ForiegnKeyExtractor` parameter that allows us to pull the primary-key of the value of one table to enable a join with another table.\n+\n+Creating the `https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/kstream/KTable.html[KTable]<Long,TrackPurchase>` of track purchases looks just like our first step with the albums: we create a table from the topic. Note that we must choose the same key\u2014album ID\u2014for our join to work.  You accomplish this by providing a Java 8 method handle `TrackPurchase::getAlbumId` to extact the correct id for sucessful completion of the join.\n+\n+At this point we should discuss the importance of the order in which we use the `KTable` parameters in the `join()`.  The `trackPurchases` table is the *_calling_* or *_left-side-table_* and is the table where the primary-key is embedded in its value.  So the *_left-side-table_*  always provides the `ForiegnKeyExtractor` function.\n+\n+The `albums` table is the *_right-side-table_* and always has the `primary-key` for the join. So, if you tried `albums.join(trackPurchases..)` the join would never work as the `albums` table has no knowlege of the `trackPurchases` table details.\n+\n+If you have a situation where you have two tables where the primary-keys don't match, but *_each_* table has reference to each other's primary key, the the order of the tables in the join method won't matter.  But that scenario seems unlikely in practice.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "424c65e4ca88513e5f79d02ccac90d6f7cae8457"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUzMzcwOQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            With the track purchases table and the album table in hand, all that remains is to join them using the `join()` method. It's a wonderfully simply one-liner, but we have concealed a bit of complexity in the form of the `MusicInterestJoiner` class. More on that in a moment.\n          \n          \n            \n            With the `trackPurchases` table and the `albums` table in hand, all that remains is to join them using the `join()` method. It's a wonderfully simply one-liner, but we have concealed a bit of complexity in the form of the `MusicInterestJoiner` class. More on that in a moment.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r378533709", "createdAt": "2020-02-12T21:51:48Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/fk-joins/kstreams/markup/dev/make-topology.adoc", "diffHunk": "@@ -0,0 +1,21 @@\n+Then create the following file at `src/main/java/io/confluent/developer/FkJoinTableToTable.java`. Let's take a close look at the `buildTopology()` method, which uses the Kafka Streams DSL.\n+\n+The first thing the method does is create an instance of `https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/StreamsBuilder.html[StreamsBuilder]`, which is the helper object that lets us build our topology. With our builder in hand, there are three things we need to do. First, we call the `table()` method to create a `https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/kstream/KTable.html[KStream]<Long, Album>` object.  In this case, we can use a `KTable` as each we know the topic is keyed by the album id and each album-id is unique.\n+\n+Now that we have our table of albums, we'll move on to the tracks available for purchase stream.  While it may seem that purchasing music tracks would end up in a `KStream`, there are a couple of circumstances that allow us to represent the track purchases as a table instead.  First each track purchase has a simple `Long` as the key, representing a increasing sequence number for each purchase.  So each purchase is unique and we don't need to worry about later sales replacing earlier purchases by the same customer.  Secondly, we need to join the track purchase with an existing album so we can create trend of which artists and genre seem to be either gaining or losing poplularity.\n+\n+But if the key is a monatomically increasing number, how can we join against the album table?  The track-purchase table has the album-id as part of its value payload, so we can use the new overaloaded `KTable.join` method that accepts a `ForiegnKeyExtractor` parameter that allows us to pull the primary-key of the value of one table to enable a join with another table.\n+\n+Creating the `https://kafka.apache.org/{{ site.ak_javadoc_version }}/javadoc/org/apache/kafka/streams/kstream/KTable.html[KTable]<Long,TrackPurchase>` of track purchases looks just like our first step with the albums: we create a table from the topic. Note that we must choose the same key\u2014album ID\u2014for our join to work.  You accomplish this by providing a Java 8 method handle `TrackPurchase::getAlbumId` to extact the correct id for sucessful completion of the join.\n+\n+At this point we should discuss the importance of the order in which we use the `KTable` parameters in the `join()`.  The `trackPurchases` table is the *_calling_* or *_left-side-table_* and is the table where the primary-key is embedded in its value.  So the *_left-side-table_*  always provides the `ForiegnKeyExtractor` function.\n+\n+The `albums` table is the *_right-side-table_* and always has the `primary-key` for the join. So, if you tried `albums.join(trackPurchases..)` the join would never work as the `albums` table has no knowlege of the `trackPurchases` table details.\n+\n+If you have a situation where you have two tables where the primary-keys don't match, but *_each_* table has reference to each other's primary key, the the order of the tables in the join method won't matter.  But that scenario seems unlikely in practice.\n+\n+With the track purchases table and the album table in hand, all that remains is to join them using the `join()` method. It's a wonderfully simply one-liner, but we have concealed a bit of complexity in the form of the `MusicInterestJoiner` class. More on that in a moment.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "424c65e4ca88513e5f79d02ccac90d6f7cae8457"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUzNDQ0Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            You have now joined a table to a table with a foriegn key! Well done.\n          \n          \n            \n            You have now joined a table to a table with a foreign key! Well done.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r378534443", "createdAt": "2020-02-12T21:53:24Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/fk-joins/kstreams/markup/dev/run-track-purchases-producer.adoc", "diffHunk": "@@ -0,0 +1,21 @@\n+Run the following in a new terminal window. This process is the most fun if you can see this and the previous terminal (which is consuming the music interest results) at the same time. If your terminal program lets you do horizontal split panes, try it that way:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/fk-joins/kstreams/code/tutorial-steps/dev/console-producer-track-purchases.sh %}</code></pre>\n++++++\n+\n+When the producer starts up, copy and paste these lines into the terminal. Then you can observe the results in the consumer terminal:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"json\">{% include_raw tutorials/fk-joins/kstreams/code/tutorial-steps/dev/track-purchases.json %}</code></pre>\n++++++\n+\n+Please note that do to the nature of how a `KTable` works,  you won't see results simultaneously.  You need to wait roughly 30 seconds or so after pasting the lines above to see any results in the consumer terminal.\n+\n+Speaking of that consumer terminal, these are the results you should see there if you paste in all the albums and track-purchases as shown in this tutorial:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"json\">{% include_raw tutorials/fk-joins/kstreams/code/tutorial-steps/dev/outputs/music-interest.json %}</code></pre>\n++++++\n+\n+You have now joined a table to a table with a foriegn key! Well done.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "424c65e4ca88513e5f79d02ccac90d6f7cae8457"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUzNTAwMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Create the following file at `src/test/java/io/confluent/developer/MusicInterestJoinerTest.java`. This tests the helper class that merges the value of the album and the track purchase as each purchase is joined to a album. The class has a depenency on the `ValueJoiner` interface, but otherwise does not depend on anything external to our domain; it just needs `Album`, `TrackPurchase`, and `MusicInterest`` domain objects. As such, it's about as testable as code gets:\n          \n          \n            \n            Create the following file at `src/test/java/io/confluent/developer/MusicInterestJoinerTest.java`. This tests the helper class that merges the value of the album and the track purchase as each purchase is joined to an album. The class has a dependency on the `ValueJoiner` interface, but otherwise does not depend on anything external to our domain; it just needs `Album`, `TrackPurchase`, and `MusicInterest`` domain objects. As such, it's about as testable as code gets:", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r378535002", "createdAt": "2020-02-12T21:54:31Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/fk-joins/kstreams/markup/test/make-join-test.adoc", "diffHunk": "@@ -0,0 +1,5 @@\n+Create the following file at `src/test/java/io/confluent/developer/MusicInterestJoinerTest.java`. This tests the helper class that merges the value of the album and the track purchase as each purchase is joined to a album. The class has a depenency on the `ValueJoiner` interface, but otherwise does not depend on anything external to our domain; it just needs `Album`, `TrackPurchase`, and `MusicInterest`` domain objects. As such, it's about as testable as code gets:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "424c65e4ca88513e5f79d02ccac90d6f7cae8457"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUzNTE4MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Now create the following file at `src/test/java/io/confluent/developer/FkJoinTableToTableTest.java`. Testing a Kafka streams application requires a bit of test harness code, but happily the `org.apache.kafka.streams.TopologyTestDriver` class makes this much more pleasant that it would otherwise be.\n          \n          \n            \n            Now create the following file at `src/test/java/io/confluent/developer/FkJoinTableToTableTest.java`. Testing a Kafka streams application requires a bit of test harness code, but happily the `org.apache.kafka.streams.TopologyTestDriver` class makes this much more pleasant than it would otherwise be.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r378535181", "createdAt": "2020-02-12T21:54:55Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/fk-joins/kstreams/markup/test/make-topology-test.adoc", "diffHunk": "@@ -0,0 +1,7 @@\n+Now create the following file at `src/test/java/io/confluent/developer/FkJoinTableToTableTest.java`. Testing a Kafka streams application requires a bit of test harness code, but happily the `org.apache.kafka.streams.TopologyTestDriver` class makes this much more pleasant that it would otherwise be.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "424c65e4ca88513e5f79d02ccac90d6f7cae8457"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUzNTQ4MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        <li><a href=\"table-table-foreign-key-joins/kstreams.html\">Join two tables with a foreign key</a></li>\n          \n          \n            \n                        <li><a href=\"foreign-key-joins/kstreams.html\">Join two tables with a foreign key</a></li>", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r378535481", "createdAt": "2020-02-12T21:55:37Z", "author": {"login": "colinhicks"}, "path": "index.html", "diffHunk": "@@ -70,6 +70,7 @@ <h2 class=\"subtitle\">Apache Kafka is a powerful, scalable, fault-tolerant distri\n             <li><a href=\"join-a-stream-to-a-table/ksql.html\">Join a stream and a table together</a></li>\n             <li><a href=\"join-a-stream-to-a-stream/ksql.html\">Join a stream and a stream together</a></li>\n             <li><a href=\"join-a-table-to-a-table/ksql.html\">Join a table and a table together</a></li>\n+            <li><a href=\"table-table-foreign-key-joins/kstreams.html\">Join two tables with a foreign key</a></li>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "424c65e4ca88513e5f79d02ccac90d6f7cae8457"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUzNjUxMQ==", "bodyText": "Since this determines the rendered url, I've simplified it. A couple other suggestions correspond to this change. If you think table-to-table-foreign-key-joins would be better, go for it.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            permalink: /table-table-foreign-key-joins/kstreams\n          \n          \n            \n            permalink: /foreign-key-joins/kstreams", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r378536511", "createdAt": "2020-02-12T21:57:50Z", "author": {"login": "colinhicks"}, "path": "tutorials/fk-joins/kstreams.html", "diffHunk": "@@ -0,0 +1,6 @@\n+---\n+layout: tutorial\n+permalink: /table-table-foreign-key-joins/kstreams", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "424c65e4ca88513e5f79d02ccac90d6f7cae8457"}, "originalPosition": 3}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "20fc124a66ea90d58e4dc35a227a0c498f0b9602", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/20fc124a66ea90d58e4dc35a227a0c498f0b9602", "committedDate": "2020-02-18T17:03:08Z", "message": "Apply suggestions from code review\n\nCo-Authored-By: Colin Hicks <colin.hicks@confluent.io>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "956e7e7a0b4fa17ded660d8a11c9819f4343f619", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/956e7e7a0b4fa17ded660d8a11c9819f4343f619", "committedDate": "2020-02-18T19:34:05Z", "message": "Update test to use MockSchemaRegistry"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9fd4e8c8d0fa92ea0c6e7998efca39c0fdfc82f3", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/9fd4e8c8d0fa92ea0c6e7998efca39c0fdfc82f3", "committedDate": "2020-02-18T20:16:03Z", "message": "fix application-id config"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9ac9691ac78198b9d9f697b64b3f416bca39d52c", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/9ac9691ac78198b9d9f697b64b3f416bca39d52c", "committedDate": "2020-02-18T20:32:27Z", "message": "updates for using MockSchemaRegistry in unit test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0cb885c56e71c0a3ab50c65315cc499cedb6f5e2", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/0cb885c56e71c0a3ab50c65315cc499cedb6f5e2", "committedDate": "2020-02-18T23:43:16Z", "message": "Add short description about the use of MockSchemaRegistry for unit tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYwNzU2NTU0", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#pullrequestreview-360756554", "createdAt": "2020-02-18T23:51:01Z", "commit": {"oid": "0cb885c56e71c0a3ab50c65315cc499cedb6f5e2"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQyMzo1MTowMVrOFrWn5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQyMzo1MTowMVrOFrWn5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTAwMzc0OQ==", "bodyText": "just added this bit text as it explains the test configuration for schema registry i.e. using MockSchemaRegistry\n\\cc @colinhicks @rspurgeon", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#discussion_r381003749", "createdAt": "2020-02-18T23:51:01Z", "author": {"login": "bbejeck"}, "path": "_includes/tutorials/fk-joins/kstreams/markup/test/make-test-file.adoc", "diffHunk": "@@ -0,0 +1,8 @@\n+First, create a test file at `configuration/test.properties`:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/fk-joins/kstreams/code/configuration/test.properties %}</code></pre>\n++++++\n+\n+You should take note of the `schema.registry.url` configuration.  The config is using a special pseudo-protocol `mock://..` which means our test", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0cb885c56e71c0a3ab50c65315cc499cedb6f5e2"}, "originalPosition": 7}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYxMTQwMjgz", "url": "https://github.com/confluentinc/kafka-tutorials/pull/198#pullrequestreview-361140283", "createdAt": "2020-02-19T14:12:04Z", "commit": {"oid": "0cb885c56e71c0a3ab50c65315cc499cedb6f5e2"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 248, "cost": 1, "resetAt": "2021-11-01T13:07:16Z"}}}