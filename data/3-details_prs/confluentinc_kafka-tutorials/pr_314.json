{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk4MjUzMzQ4", "number": 314, "title": "DEVX-1645:  Naming stateful operations", "bodyText": "For GHI #306\nThis tutorial is a bit of a departure from the regular format in that it uses feature flags to enable different parts of the topology.  The application uses feature flags via properties.", "createdAt": "2020-04-03T15:54:38Z", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314", "merged": true, "mergeCommit": {"oid": "c35d47821949b724ede8d9d7e7fcefb0f41df33f"}, "closed": true, "closedAt": "2020-04-10T17:05:21Z", "author": {"login": "bbejeck"}, "timelineItems": {"totalCount": 21, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcUExogAFqTM4NzQ1NjQwMg==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcWT3JjgBqjMyMjI0MDk2MzQ=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg3NDU2NDAy", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#pullrequestreview-387456402", "createdAt": "2020-04-03T17:41:34Z", "commit": {"oid": "cc2a0d9b7839839721c040eb5fd4ac6c89549070"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxNzo0MTozNFrOGAgZEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxNzo0OToyN1rOGAg0TQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzE4Mzg4OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                compile \"org.apache.avro:avro:1.8.2\"\n          \n          \n            \n                implementation \"org.apache.avro:avro:1.8.2\"", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r403183889", "createdAt": "2020-04-03T17:41:34Z", "author": {"login": "gAmUssA"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/code/build.gradle", "diffHunk": "@@ -0,0 +1,63 @@\n+buildscript {\n+    repositories {\n+        jcenter()\n+    }\n+    dependencies {\n+        classpath \"com.commercehub.gradle.plugin:gradle-avro-plugin:0.15.1\"\n+        classpath \"com.github.jengelman.gradle.plugins:shadow:4.0.2\"\n+    }\n+}\n+\n+plugins {\n+    id \"java\"\n+    id \"com.google.cloud.tools.jib\" version \"1.1.1\"\n+    id \"idea\"\n+    id \"eclipse\"\n+}\n+\n+sourceCompatibility = \"1.8\"\n+targetCompatibility = \"1.8\"\n+version = \"0.0.1\"\n+\n+repositories {\n+    mavenCentral()\n+    jcenter()\n+\n+    maven {\n+        url \"http://packages.confluent.io/maven\"\n+    }\n+}\n+\n+apply plugin: \"com.commercehub.gradle.plugin.avro\"\n+apply plugin: \"com.github.johnrengelman.shadow\"\n+\n+dependencies {\n+    compile \"org.apache.avro:avro:1.8.2\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc2a0d9b7839839721c040eb5fd4ac6c89549070"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzE4NDM0Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                testCompile \"org.apache.kafka:kafka-streams-test-utils:2.4.1\"\n          \n          \n            \n                testImplementation \"org.apache.kafka:kafka-streams-test-utils:2.4.1\"", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r403184342", "createdAt": "2020-04-03T17:42:05Z", "author": {"login": "gAmUssA"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/code/build.gradle", "diffHunk": "@@ -0,0 +1,63 @@\n+buildscript {\n+    repositories {\n+        jcenter()\n+    }\n+    dependencies {\n+        classpath \"com.commercehub.gradle.plugin:gradle-avro-plugin:0.15.1\"\n+        classpath \"com.github.jengelman.gradle.plugins:shadow:4.0.2\"\n+    }\n+}\n+\n+plugins {\n+    id \"java\"\n+    id \"com.google.cloud.tools.jib\" version \"1.1.1\"\n+    id \"idea\"\n+    id \"eclipse\"\n+}\n+\n+sourceCompatibility = \"1.8\"\n+targetCompatibility = \"1.8\"\n+version = \"0.0.1\"\n+\n+repositories {\n+    mavenCentral()\n+    jcenter()\n+\n+    maven {\n+        url \"http://packages.confluent.io/maven\"\n+    }\n+}\n+\n+apply plugin: \"com.commercehub.gradle.plugin.avro\"\n+apply plugin: \"com.github.johnrengelman.shadow\"\n+\n+dependencies {\n+    compile \"org.apache.avro:avro:1.8.2\"\n+    implementation \"org.slf4j:slf4j-simple:1.7.26\"\n+    implementation \"org.apache.kafka:kafka-streams:2.4.1\"\n+    implementation \"io.confluent:kafka-streams-avro-serde:5.4.1\"\n+    testCompile \"org.apache.kafka:kafka-streams-test-utils:2.4.1\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc2a0d9b7839839721c040eb5fd4ac6c89549070"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzE4NDQ2MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                testCompile \"junit:junit:4.12\"\n          \n          \n            \n                testImplementation \"junit:junit:4.12\"", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r403184461", "createdAt": "2020-04-03T17:42:13Z", "author": {"login": "gAmUssA"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/code/build.gradle", "diffHunk": "@@ -0,0 +1,63 @@\n+buildscript {\n+    repositories {\n+        jcenter()\n+    }\n+    dependencies {\n+        classpath \"com.commercehub.gradle.plugin:gradle-avro-plugin:0.15.1\"\n+        classpath \"com.github.jengelman.gradle.plugins:shadow:4.0.2\"\n+    }\n+}\n+\n+plugins {\n+    id \"java\"\n+    id \"com.google.cloud.tools.jib\" version \"1.1.1\"\n+    id \"idea\"\n+    id \"eclipse\"\n+}\n+\n+sourceCompatibility = \"1.8\"\n+targetCompatibility = \"1.8\"\n+version = \"0.0.1\"\n+\n+repositories {\n+    mavenCentral()\n+    jcenter()\n+\n+    maven {\n+        url \"http://packages.confluent.io/maven\"\n+    }\n+}\n+\n+apply plugin: \"com.commercehub.gradle.plugin.avro\"\n+apply plugin: \"com.github.johnrengelman.shadow\"\n+\n+dependencies {\n+    compile \"org.apache.avro:avro:1.8.2\"\n+    implementation \"org.slf4j:slf4j-simple:1.7.26\"\n+    implementation \"org.apache.kafka:kafka-streams:2.4.1\"\n+    implementation \"io.confluent:kafka-streams-avro-serde:5.4.1\"\n+    testCompile \"org.apache.kafka:kafka-streams-test-utils:2.4.1\"\n+    testCompile \"junit:junit:4.12\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc2a0d9b7839839721c040eb5fd4ac6c89549070"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzE4NDg4NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  \"Class-Path\": configurations.compile.collect { it.getName() }.join(\" \"),\n          \n          \n            \n                  \"Class-Path\": configurations.compileClasspath.collect { it.getName() }.join(\" \"),", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r403184884", "createdAt": "2020-04-03T17:42:39Z", "author": {"login": "gAmUssA"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/code/build.gradle", "diffHunk": "@@ -0,0 +1,63 @@\n+buildscript {\n+    repositories {\n+        jcenter()\n+    }\n+    dependencies {\n+        classpath \"com.commercehub.gradle.plugin:gradle-avro-plugin:0.15.1\"\n+        classpath \"com.github.jengelman.gradle.plugins:shadow:4.0.2\"\n+    }\n+}\n+\n+plugins {\n+    id \"java\"\n+    id \"com.google.cloud.tools.jib\" version \"1.1.1\"\n+    id \"idea\"\n+    id \"eclipse\"\n+}\n+\n+sourceCompatibility = \"1.8\"\n+targetCompatibility = \"1.8\"\n+version = \"0.0.1\"\n+\n+repositories {\n+    mavenCentral()\n+    jcenter()\n+\n+    maven {\n+        url \"http://packages.confluent.io/maven\"\n+    }\n+}\n+\n+apply plugin: \"com.commercehub.gradle.plugin.avro\"\n+apply plugin: \"com.github.johnrengelman.shadow\"\n+\n+dependencies {\n+    compile \"org.apache.avro:avro:1.8.2\"\n+    implementation \"org.slf4j:slf4j-simple:1.7.26\"\n+    implementation \"org.apache.kafka:kafka-streams:2.4.1\"\n+    implementation \"io.confluent:kafka-streams-avro-serde:5.4.1\"\n+    testCompile \"org.apache.kafka:kafka-streams-test-utils:2.4.1\"\n+    testCompile \"junit:junit:4.12\"\n+    testImplementation 'org.hamcrest:hamcrest:2.2'\n+}\n+\n+test {\n+    testLogging {\n+        outputs.upToDateWhen { false }\n+        showStandardStreams = true\n+        exceptionFormat = \"full\"\n+    }\n+}\n+\n+jar {\n+  manifest {\n+    attributes(\n+      \"Class-Path\": configurations.compile.collect { it.getName() }.join(\" \"),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc2a0d9b7839839721c040eb5fd4ac6c89549070"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzE4NjMzMA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    url \"http://packages.confluent.io/maven\"\n          \n          \n            \n                    url \"https://packages.confluent.io/maven\"", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r403186330", "createdAt": "2020-04-03T17:44:17Z", "author": {"login": "gAmUssA"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/code/build.gradle", "diffHunk": "@@ -0,0 +1,63 @@\n+buildscript {\n+    repositories {\n+        jcenter()\n+    }\n+    dependencies {\n+        classpath \"com.commercehub.gradle.plugin:gradle-avro-plugin:0.15.1\"\n+        classpath \"com.github.jengelman.gradle.plugins:shadow:4.0.2\"\n+    }\n+}\n+\n+plugins {\n+    id \"java\"\n+    id \"com.google.cloud.tools.jib\" version \"1.1.1\"\n+    id \"idea\"\n+    id \"eclipse\"\n+}\n+\n+sourceCompatibility = \"1.8\"\n+targetCompatibility = \"1.8\"\n+version = \"0.0.1\"\n+\n+repositories {\n+    mavenCentral()\n+    jcenter()\n+\n+    maven {\n+        url \"http://packages.confluent.io/maven\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc2a0d9b7839839721c040eb5fd4ac6c89549070"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzE4NzYyOQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            shadowJar {\n          \n          \n            \n                archiveName = \"naming-changelog-repartition-topics-standalone-${version}.${extension}\"\n          \n          \n            \n            }\n          \n          \n            \n            shadowJar {\n          \n          \n            \n              archiveBaseName = \"naming-changelog-repartition-topics-standalone\"\n          \n          \n            \n              archiveClassifier = ''\n          \n          \n            \n            }", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r403187629", "createdAt": "2020-04-03T17:45:51Z", "author": {"login": "gAmUssA"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/code/build.gradle", "diffHunk": "@@ -0,0 +1,63 @@\n+buildscript {\n+    repositories {\n+        jcenter()\n+    }\n+    dependencies {\n+        classpath \"com.commercehub.gradle.plugin:gradle-avro-plugin:0.15.1\"\n+        classpath \"com.github.jengelman.gradle.plugins:shadow:4.0.2\"\n+    }\n+}\n+\n+plugins {\n+    id \"java\"\n+    id \"com.google.cloud.tools.jib\" version \"1.1.1\"\n+    id \"idea\"\n+    id \"eclipse\"\n+}\n+\n+sourceCompatibility = \"1.8\"\n+targetCompatibility = \"1.8\"\n+version = \"0.0.1\"\n+\n+repositories {\n+    mavenCentral()\n+    jcenter()\n+\n+    maven {\n+        url \"http://packages.confluent.io/maven\"\n+    }\n+}\n+\n+apply plugin: \"com.commercehub.gradle.plugin.avro\"\n+apply plugin: \"com.github.johnrengelman.shadow\"\n+\n+dependencies {\n+    compile \"org.apache.avro:avro:1.8.2\"\n+    implementation \"org.slf4j:slf4j-simple:1.7.26\"\n+    implementation \"org.apache.kafka:kafka-streams:2.4.1\"\n+    implementation \"io.confluent:kafka-streams-avro-serde:5.4.1\"\n+    testCompile \"org.apache.kafka:kafka-streams-test-utils:2.4.1\"\n+    testCompile \"junit:junit:4.12\"\n+    testImplementation 'org.hamcrest:hamcrest:2.2'\n+}\n+\n+test {\n+    testLogging {\n+        outputs.upToDateWhen { false }\n+        showStandardStreams = true\n+        exceptionFormat = \"full\"\n+    }\n+}\n+\n+jar {\n+  manifest {\n+    attributes(\n+      \"Class-Path\": configurations.compile.collect { it.getName() }.join(\" \"),\n+      \"Main-Class\": \"io.confluent.developer.NamingChangelogAndRepartitionTopics\"\n+    )\n+  }\n+}\n+\n+shadowJar {\n+    archiveName = \"naming-changelog-repartition-topics-standalone-${version}.${extension}\"\n+}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc2a0d9b7839839721c040eb5fd4ac6c89549070"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzE4ODM0Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                mavenCentral()", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r403188342", "createdAt": "2020-04-03T17:46:41Z", "author": {"login": "gAmUssA"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/code/build.gradle", "diffHunk": "@@ -0,0 +1,63 @@\n+buildscript {\n+    repositories {\n+        jcenter()\n+    }\n+    dependencies {\n+        classpath \"com.commercehub.gradle.plugin:gradle-avro-plugin:0.15.1\"\n+        classpath \"com.github.jengelman.gradle.plugins:shadow:4.0.2\"\n+    }\n+}\n+\n+plugins {\n+    id \"java\"\n+    id \"com.google.cloud.tools.jib\" version \"1.1.1\"\n+    id \"idea\"\n+    id \"eclipse\"\n+}\n+\n+sourceCompatibility = \"1.8\"\n+targetCompatibility = \"1.8\"\n+version = \"0.0.1\"\n+\n+repositories {\n+    mavenCentral()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc2a0d9b7839839721c040eb5fd4ac6c89549070"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzE4ODYyNw==", "bodyText": "redundant. jcenter() covers everything", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r403188627", "createdAt": "2020-04-03T17:47:00Z", "author": {"login": "gAmUssA"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/code/build.gradle", "diffHunk": "@@ -0,0 +1,63 @@\n+buildscript {\n+    repositories {\n+        jcenter()\n+    }\n+    dependencies {\n+        classpath \"com.commercehub.gradle.plugin:gradle-avro-plugin:0.15.1\"\n+        classpath \"com.github.jengelman.gradle.plugins:shadow:4.0.2\"\n+    }\n+}\n+\n+plugins {\n+    id \"java\"\n+    id \"com.google.cloud.tools.jib\" version \"1.1.1\"\n+    id \"idea\"\n+    id \"eclipse\"\n+}\n+\n+sourceCompatibility = \"1.8\"\n+targetCompatibility = \"1.8\"\n+version = \"0.0.1\"\n+\n+repositories {\n+    mavenCentral()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzE4ODM0Mg=="}, "originalCommit": {"oid": "cc2a0d9b7839839721c040eb5fd4ac6c89549070"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzE5MDg2MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The point of this tutorial is to discuss the importance of naming state stores (hence changelog topics) and repartition topics.  In addition to having a more readable topology description, you can make your Kafka Streams application more robust to topology changes.\n          \n          \n            \n            The point of this tutorial is to discuss the importance of naming state stores (hence `changelog` topics) and repartition topics.  In addition to having a more readable topology description, you can make your Kafka Streams application more robust to topology changes.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r403190861", "createdAt": "2020-04-03T17:49:27Z", "author": {"login": "gAmUssA"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-topology.adoc", "diffHunk": "@@ -0,0 +1,49 @@\n+////\n+In this file you describe the Kafka streams topology, and should cover the main points of the tutorial.\n+The text assumes a method buildTopology exists and constructs the Kafka Streams application.  Feel free to modify the text below to suit your needs.\n+////\n+\n+The point of this tutorial is to discuss the importance of naming state stores (hence changelog topics) and repartition topics.  In addition to having a more readable topology description, you can make your Kafka Streams application more robust to topology changes.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc2a0d9b7839839721c040eb5fd4ac6c89549070"}, "originalPosition": 6}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f67bb639e02277daa4ac800a93ff7441148ef5f0", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/f67bb639e02277daa4ac800a93ff7441148ef5f0", "committedDate": "2020-04-03T20:27:59Z", "message": "update avro version"}, "afterCommit": {"oid": "de6297a305b760ae1e458ead4796b142ec60db89", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/de6297a305b760ae1e458ead4796b142ec60db89", "committedDate": "2020-04-06T22:52:01Z", "message": "updates to get test harness running and tutorial steps to make sense"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkwMjcyODIx", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#pullrequestreview-390272821", "createdAt": "2020-04-08T19:36:56Z", "commit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "state": "COMMENTED", "comments": {"totalCount": 42, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxOTozNjo1N1rOGC-Acw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQyMDozNTozOVrOGC_9Pg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc2NjI1OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              introduction: \"Consider an existing Kafka Streams application and you want to add or remove some operations.  In this tutorial we'll show how to name the changelog and repartition topics so topology updates don't break compatibility with your existing application\"\n          \n          \n            \n              introduction: \"You want to add or remove some operations in your Kafka Streams application.  In this tutorial we'll name the changelog and repartition topics so that the topology updates don't break compatibility.\"", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405766259", "createdAt": "2020-04-08T19:36:57Z", "author": {"login": "colinhicks"}, "path": "_data/tutorials.yaml", "diffHunk": "@@ -226,3 +226,14 @@ aggregating-average:\n     ksql: disabled\n     kstreams: enabled\n     kafka: disabled\n+\n+naming-changelog-repartition-topics:\n+  title: \"How to name stateful operations in Kafka Streams\"\n+  meta-description: \"How to name stateful operations in Kafka Streams\"\n+  slug: \"/naming-stateful-operations\"\n+  problem: \"you have an existing Kafka Streams application and you want to make changes to the topology, but you'd like the new topology to remain compatible with the existing one\"\n+  introduction: \"Consider an existing Kafka Streams application and you want to add or remove some operations.  In this tutorial we'll show how to name the changelog and repartition topics so topology updates don't break compatibility with your existing application\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc2Njc0MQ==", "bodyText": "(extra lines)\n\n  \n    \n      \n        Suggested change", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405766741", "createdAt": "2020-04-08T19:37:48Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/code/configuration/dev.properties", "diffHunk": "@@ -0,0 +1,17 @@\n+application.id=naming-changelog-repartition-topics\n+bootstrap.servers=localhost:29092\n+schema.registry.url=http://localhost:8081\n+\n+input.topic.name=input-topic\n+input.topic.partitions=1\n+input.topic.replication.factor=1\n+\n+output.topic.name=output-topic\n+output.topic.partitions=1\n+output.topic.replication.factor=1\n+\n+join.topic.name=join-topic\n+join.topic.partitions=1\n+join.topic.replication.factor=1\n+\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc2ODE3NA==", "bodyText": "Looks like this is pointing to the wrong docker-compose", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405768174", "createdAt": "2020-04-08T19:40:34Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-docker-compose.adoc", "diffHunk": "@@ -0,0 +1,5 @@\n+Next, create the following `docker-compose.yml` file to obtain Confluent Platform:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"dockerfile\">{% include_raw tutorials/filtering/kstreams/code/docker-compose.yml %}</code></pre>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc2OTY2Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            First look at the code of the Kafka Streams application:\n          \n          \n            \n            Lets look at the core logic of the Kafka Streams application:", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405769662", "createdAt": "2020-04-08T19:43:20Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-topology.adoc", "diffHunk": "@@ -0,0 +1,48 @@\n+////\n+In this file you describe the Kafka streams topology, and should cover the main points of the tutorial.\n+The text assumes a method buildTopology exists and constructs the Kafka Streams application.  Feel free to modify the text below to suit your needs.\n+////\n+\n+The point of this tutorial is to discuss the importance of naming state stores (hence `changelog` topics) and repartition topics.  In addition to having a more readable topology description, you can make your Kafka Streams application more robust to topology changes.\n+\n+First look at the code of the Kafka Streams application:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc3MDEzOA==", "bodyText": "(extra line)\n\n  \n    \n      \n        Suggested change", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405770138", "createdAt": "2020-04-08T19:44:09Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-topology.adoc", "diffHunk": "@@ -0,0 +1,48 @@\n+////\n+In this file you describe the Kafka streams topology, and should cover the main points of the tutorial.\n+The text assumes a method buildTopology exists and constructs the Kafka Streams application.  Feel free to modify the text below to suit your needs.\n+////\n+\n+The point of this tutorial is to discuss the importance of naming state stores (hence `changelog` topics) and repartition topics.  In addition to having a more readable topology description, you can make your Kafka Streams application more robust to topology changes.\n+\n+First look at the code of the Kafka Streams application:\n++++++\n+<pre class=\"snippet\"><code class=\"java\">\n+  KStream&lt;Long, Example&gt; inputStream = builder.stream(inputTopic, Consumed.with(longSerde, exampleSerde))\n+                                                  .selectKey((k, v) -> Long.parseLong(v.getName().substring(0, 1)));\n+\n+  KStream&lt;Long, Long&gt; countStream = inputStream.groupByKey().count().toStream();\n+\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc3MDc0MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Additionally, `count()` is an aggregation so Kafka Streams creates state store and a changelog topic for fault-tolerance of the state store.\n          \n          \n            \n            Additionally, `count()` is an aggregation, so Kafka Streams creates a state store plus a changelog topic for fault-tolerance of the state store.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405770741", "createdAt": "2020-04-08T19:45:23Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-topology.adoc", "diffHunk": "@@ -0,0 +1,48 @@\n+////\n+In this file you describe the Kafka streams topology, and should cover the main points of the tutorial.\n+The text assumes a method buildTopology exists and constructs the Kafka Streams application.  Feel free to modify the text below to suit your needs.\n+////\n+\n+The point of this tutorial is to discuss the importance of naming state stores (hence `changelog` topics) and repartition topics.  In addition to having a more readable topology description, you can make your Kafka Streams application more robust to topology changes.\n+\n+First look at the code of the Kafka Streams application:\n++++++\n+<pre class=\"snippet\"><code class=\"java\">\n+  KStream&lt;Long, Example&gt; inputStream = builder.stream(inputTopic, Consumed.with(longSerde, exampleSerde))\n+                                                  .selectKey((k, v) -> Long.parseLong(v.getName().substring(0, 1)));\n+\n+  KStream&lt;Long, Long&gt; countStream = inputStream.groupByKey().count().toStream();\n+\n+\n+  KStream&lt;Long, String&gt; joinedStream = inputStream.join(exampleCountStream, (v1, v2) -> v1.getName() + v2.toString(),\n+                                                              JoinWindows.of(Duration.ofMillis(100)),\n+                                                              StreamJoined.with(longSerde, exampleSerde, longSerde));\n+</code></pre>\n++++++\n+\n+\n+In the `inputStream` there is a `selectKey()` operation, changing the key of the incoming stream.\n+\n+As a result, executing the `inputStream.groupByKey()` operation forces a repartition to make sure the modified keys end up on the correct partition.\n+\n+Additionally, `count()` is an aggregation so Kafka Streams creates state store and a changelog topic for fault-tolerance of the state store.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc3MTEwOQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            There are additional state stores and another reparition topic in this topology, but we'll focus on the `countStream` to keep things simple.  But the same principles apply to any state store, changelog and repartition topic.\n          \n          \n            \n            There are additional state stores and another repartition topic in this topology, but we'll focus on the `countStream` to keep things simple.  The same principles apply to any state store, changelog and repartition topic.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405771109", "createdAt": "2020-04-08T19:46:06Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-topology.adoc", "diffHunk": "@@ -0,0 +1,48 @@\n+////\n+In this file you describe the Kafka streams topology, and should cover the main points of the tutorial.\n+The text assumes a method buildTopology exists and constructs the Kafka Streams application.  Feel free to modify the text below to suit your needs.\n+////\n+\n+The point of this tutorial is to discuss the importance of naming state stores (hence `changelog` topics) and repartition topics.  In addition to having a more readable topology description, you can make your Kafka Streams application more robust to topology changes.\n+\n+First look at the code of the Kafka Streams application:\n++++++\n+<pre class=\"snippet\"><code class=\"java\">\n+  KStream&lt;Long, Example&gt; inputStream = builder.stream(inputTopic, Consumed.with(longSerde, exampleSerde))\n+                                                  .selectKey((k, v) -> Long.parseLong(v.getName().substring(0, 1)));\n+\n+  KStream&lt;Long, Long&gt; countStream = inputStream.groupByKey().count().toStream();\n+\n+\n+  KStream&lt;Long, String&gt; joinedStream = inputStream.join(exampleCountStream, (v1, v2) -> v1.getName() + v2.toString(),\n+                                                              JoinWindows.of(Duration.ofMillis(100)),\n+                                                              StreamJoined.with(longSerde, exampleSerde, longSerde));\n+</code></pre>\n++++++\n+\n+\n+In the `inputStream` there is a `selectKey()` operation, changing the key of the incoming stream.\n+\n+As a result, executing the `inputStream.groupByKey()` operation forces a repartition to make sure the modified keys end up on the correct partition.\n+\n+Additionally, `count()` is an aggregation so Kafka Streams creates state store and a changelog topic for fault-tolerance of the state store.\n+\n+There are additional state stores and another reparition topic in this topology, but we'll focus on the `countStream` to keep things simple.  But the same principles apply to any state store, changelog and repartition topic.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc3NjM2NA==", "bodyText": "I did some experimenting here. This list should render far better if you apply this patch:\ndiff --git a/_includes/tutorial-content.html b/_includes/tutorial-content.html\nindex d527d24..26943b2 100644\n--- a/_includes/tutorial-content.html\n+++ b/_includes/tutorial-content.html\n@@ -1,4 +1,4 @@\n-<div>\n+<div class=\"content\">\n   <section class=\"section\">\n     <div class=\"container\">\n       <div class=\"columns\">", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405776364", "createdAt": "2020-04-08T19:55:40Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-topology.adoc", "diffHunk": "@@ -0,0 +1,48 @@\n+////\n+In this file you describe the Kafka streams topology, and should cover the main points of the tutorial.\n+The text assumes a method buildTopology exists and constructs the Kafka Streams application.  Feel free to modify the text below to suit your needs.\n+////\n+\n+The point of this tutorial is to discuss the importance of naming state stores (hence `changelog` topics) and repartition topics.  In addition to having a more readable topology description, you can make your Kafka Streams application more robust to topology changes.\n+\n+First look at the code of the Kafka Streams application:\n++++++\n+<pre class=\"snippet\"><code class=\"java\">\n+  KStream&lt;Long, Example&gt; inputStream = builder.stream(inputTopic, Consumed.with(longSerde, exampleSerde))\n+                                                  .selectKey((k, v) -> Long.parseLong(v.getName().substring(0, 1)));\n+\n+  KStream&lt;Long, Long&gt; countStream = inputStream.groupByKey().count().toStream();\n+\n+\n+  KStream&lt;Long, String&gt; joinedStream = inputStream.join(exampleCountStream, (v1, v2) -> v1.getName() + v2.toString(),\n+                                                              JoinWindows.of(Duration.ofMillis(100)),\n+                                                              StreamJoined.with(longSerde, exampleSerde, longSerde));\n+</code></pre>\n++++++\n+\n+\n+In the `inputStream` there is a `selectKey()` operation, changing the key of the incoming stream.\n+\n+As a result, executing the `inputStream.groupByKey()` operation forces a repartition to make sure the modified keys end up on the correct partition.\n+\n+Additionally, `count()` is an aggregation so Kafka Streams creates state store and a changelog topic for fault-tolerance of the state store.\n+\n+There are additional state stores and another reparition topic in this topology, but we'll focus on the `countStream` to keep things simple.  But the same principles apply to any state store, changelog and repartition topic.\n+\n+When using the DSL, Kafka Streams generates the names for each processor, state store, and any required internal topics.  To view a textual representation of your topology, you can run `Topology.describe()`.\n+\n+We won't show a full description here, but describing our topology here results in the following names for the state store, changelog and repartition topic:\n+\n+-  state store - `<application.id>-KSTREAM-AGGREGATE-STATE-STORE-0000000002`\n+-  changelog topic - `<application.id>-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog`\n+-  repartition topic - `<application.id>-KSTREAM-AGGREGATE-STATE-STORE-0000000002-repartition`", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc3NzkyMw==", "bodyText": "IMO, these two paragraphs can be joined.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405777923", "createdAt": "2020-04-08T19:58:31Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-topology.adoc", "diffHunk": "@@ -0,0 +1,48 @@\n+////\n+In this file you describe the Kafka streams topology, and should cover the main points of the tutorial.\n+The text assumes a method buildTopology exists and constructs the Kafka Streams application.  Feel free to modify the text below to suit your needs.\n+////\n+\n+The point of this tutorial is to discuss the importance of naming state stores (hence `changelog` topics) and repartition topics.  In addition to having a more readable topology description, you can make your Kafka Streams application more robust to topology changes.\n+\n+First look at the code of the Kafka Streams application:\n++++++\n+<pre class=\"snippet\"><code class=\"java\">\n+  KStream&lt;Long, Example&gt; inputStream = builder.stream(inputTopic, Consumed.with(longSerde, exampleSerde))\n+                                                  .selectKey((k, v) -> Long.parseLong(v.getName().substring(0, 1)));\n+\n+  KStream&lt;Long, Long&gt; countStream = inputStream.groupByKey().count().toStream();\n+\n+\n+  KStream&lt;Long, String&gt; joinedStream = inputStream.join(exampleCountStream, (v1, v2) -> v1.getName() + v2.toString(),\n+                                                              JoinWindows.of(Duration.ofMillis(100)),\n+                                                              StreamJoined.with(longSerde, exampleSerde, longSerde));\n+</code></pre>\n++++++\n+\n+\n+In the `inputStream` there is a `selectKey()` operation, changing the key of the incoming stream.\n+\n+As a result, executing the `inputStream.groupByKey()` operation forces a repartition to make sure the modified keys end up on the correct partition.\n+\n+Additionally, `count()` is an aggregation so Kafka Streams creates state store and a changelog topic for fault-tolerance of the state store.\n+\n+There are additional state stores and another reparition topic in this topology, but we'll focus on the `countStream` to keep things simple.  But the same principles apply to any state store, changelog and repartition topic.\n+\n+When using the DSL, Kafka Streams generates the names for each processor, state store, and any required internal topics.  To view a textual representation of your topology, you can run `Topology.describe()`.\n+\n+We won't show a full description here, but describing our topology here results in the following names for the state store, changelog and repartition topic:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc3OTM2NA==", "bodyText": "Also, I think you should also consider combining the three single-sentence paragraphs above into one or two paragraphs.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405779364", "createdAt": "2020-04-08T20:01:07Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-topology.adoc", "diffHunk": "@@ -0,0 +1,48 @@\n+////\n+In this file you describe the Kafka streams topology, and should cover the main points of the tutorial.\n+The text assumes a method buildTopology exists and constructs the Kafka Streams application.  Feel free to modify the text below to suit your needs.\n+////\n+\n+The point of this tutorial is to discuss the importance of naming state stores (hence `changelog` topics) and repartition topics.  In addition to having a more readable topology description, you can make your Kafka Streams application more robust to topology changes.\n+\n+First look at the code of the Kafka Streams application:\n++++++\n+<pre class=\"snippet\"><code class=\"java\">\n+  KStream&lt;Long, Example&gt; inputStream = builder.stream(inputTopic, Consumed.with(longSerde, exampleSerde))\n+                                                  .selectKey((k, v) -> Long.parseLong(v.getName().substring(0, 1)));\n+\n+  KStream&lt;Long, Long&gt; countStream = inputStream.groupByKey().count().toStream();\n+\n+\n+  KStream&lt;Long, String&gt; joinedStream = inputStream.join(exampleCountStream, (v1, v2) -> v1.getName() + v2.toString(),\n+                                                              JoinWindows.of(Duration.ofMillis(100)),\n+                                                              StreamJoined.with(longSerde, exampleSerde, longSerde));\n+</code></pre>\n++++++\n+\n+\n+In the `inputStream` there is a `selectKey()` operation, changing the key of the incoming stream.\n+\n+As a result, executing the `inputStream.groupByKey()` operation forces a repartition to make sure the modified keys end up on the correct partition.\n+\n+Additionally, `count()` is an aggregation so Kafka Streams creates state store and a changelog topic for fault-tolerance of the state store.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc3MDc0MQ=="}, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc3OTYwMA==", "bodyText": "viz", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405779600", "createdAt": "2020-04-08T20:01:33Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-topology.adoc", "diffHunk": "@@ -0,0 +1,48 @@\n+////\n+In this file you describe the Kafka streams topology, and should cover the main points of the tutorial.\n+The text assumes a method buildTopology exists and constructs the Kafka Streams application.  Feel free to modify the text below to suit your needs.\n+////\n+\n+The point of this tutorial is to discuss the importance of naming state stores (hence `changelog` topics) and repartition topics.  In addition to having a more readable topology description, you can make your Kafka Streams application more robust to topology changes.\n+\n+First look at the code of the Kafka Streams application:\n++++++\n+<pre class=\"snippet\"><code class=\"java\">\n+  KStream&lt;Long, Example&gt; inputStream = builder.stream(inputTopic, Consumed.with(longSerde, exampleSerde))\n+                                                  .selectKey((k, v) -> Long.parseLong(v.getName().substring(0, 1)));\n+\n+  KStream&lt;Long, Long&gt; countStream = inputStream.groupByKey().count().toStream();\n+\n+\n+  KStream&lt;Long, String&gt; joinedStream = inputStream.join(exampleCountStream, (v1, v2) -> v1.getName() + v2.toString(),\n+                                                              JoinWindows.of(Duration.ofMillis(100)),\n+                                                              StreamJoined.with(longSerde, exampleSerde, longSerde));\n+</code></pre>\n++++++\n+\n+\n+In the `inputStream` there is a `selectKey()` operation, changing the key of the incoming stream.\n+\n+As a result, executing the `inputStream.groupByKey()` operation forces a repartition to make sure the modified keys end up on the correct partition.\n+\n+Additionally, `count()` is an aggregation so Kafka Streams creates state store and a changelog topic for fault-tolerance of the state store.\n+\n+There are additional state stores and another reparition topic in this topology, but we'll focus on the `countStream` to keep things simple.  But the same principles apply to any state store, changelog and repartition topic.\n+\n+When using the DSL, Kafka Streams generates the names for each processor, state store, and any required internal topics.  To view a textual representation of your topology, you can run `Topology.describe()`.\n+\n+We won't show a full description here, but describing our topology here results in the following names for the state store, changelog and repartition topic:\n+\n+-  state store - `<application.id>-KSTREAM-AGGREGATE-STATE-STORE-0000000002`\n+-  changelog topic - `<application.id>-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog`\n+-  repartition topic - `<application.id>-KSTREAM-AGGREGATE-STATE-STORE-0000000002-repartition`", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc3NjM2NA=="}, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc4MDYzOA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            When using the DSL, Kafka Streams generates the names for each processor, state store, and any required internal topics.  To view a textual representation of your topology, you can run `Topology.describe()`.\n          \n          \n            \n            \n          \n          \n            \n            We won't show a full description here, but describing our topology here results in the following names for the state store, changelog and repartition topic:\n          \n          \n            \n            When using the DSL, Kafka Streams generates the names for each processor, state store, and any required internal topics.  To view a textual representation of your topology, you can run `Topology.describe()`.\n          \n          \n            \n            \n          \n          \n            \n            We won't show the full output here, but describing this topology indicates the following names for the state store, changelog and repartition topic:", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405780638", "createdAt": "2020-04-08T20:03:34Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-topology.adoc", "diffHunk": "@@ -0,0 +1,48 @@\n+////\n+In this file you describe the Kafka streams topology, and should cover the main points of the tutorial.\n+The text assumes a method buildTopology exists and constructs the Kafka Streams application.  Feel free to modify the text below to suit your needs.\n+////\n+\n+The point of this tutorial is to discuss the importance of naming state stores (hence `changelog` topics) and repartition topics.  In addition to having a more readable topology description, you can make your Kafka Streams application more robust to topology changes.\n+\n+First look at the code of the Kafka Streams application:\n++++++\n+<pre class=\"snippet\"><code class=\"java\">\n+  KStream&lt;Long, Example&gt; inputStream = builder.stream(inputTopic, Consumed.with(longSerde, exampleSerde))\n+                                                  .selectKey((k, v) -> Long.parseLong(v.getName().substring(0, 1)));\n+\n+  KStream&lt;Long, Long&gt; countStream = inputStream.groupByKey().count().toStream();\n+\n+\n+  KStream&lt;Long, String&gt; joinedStream = inputStream.join(exampleCountStream, (v1, v2) -> v1.getName() + v2.toString(),\n+                                                              JoinWindows.of(Duration.ofMillis(100)),\n+                                                              StreamJoined.with(longSerde, exampleSerde, longSerde));\n+</code></pre>\n++++++\n+\n+\n+In the `inputStream` there is a `selectKey()` operation, changing the key of the incoming stream.\n+\n+As a result, executing the `inputStream.groupByKey()` operation forces a repartition to make sure the modified keys end up on the correct partition.\n+\n+Additionally, `count()` is an aggregation so Kafka Streams creates state store and a changelog topic for fault-tolerance of the state store.\n+\n+There are additional state stores and another reparition topic in this topology, but we'll focus on the `countStream` to keep things simple.  But the same principles apply to any state store, changelog and repartition topic.\n+\n+When using the DSL, Kafka Streams generates the names for each processor, state store, and any required internal topics.  To view a textual representation of your topology, you can run `Topology.describe()`.\n+\n+We won't show a full description here, but describing our topology here results in the following names for the state store, changelog and repartition topic:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc4MjEyMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            You'll notice the number `0000000002` at the end of the names.  Kafka Streams appends an incrementing number as part of the name for each part of the topology.  Here the state store, changelog topic and repartition topic share the same number as by default they re-use the name of the state store for their name.\n          \n          \n            \n            You'll notice the number `0000000002` at the end of the names.  Kafka Streams appends an incrementing number as part of the name for each part of the topology.  Here the state store, changelog topic, and repartition topic share the same number, since by default, they reuse the name of the corresponding state store.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405782122", "createdAt": "2020-04-08T20:06:12Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-topology.adoc", "diffHunk": "@@ -0,0 +1,48 @@\n+////\n+In this file you describe the Kafka streams topology, and should cover the main points of the tutorial.\n+The text assumes a method buildTopology exists and constructs the Kafka Streams application.  Feel free to modify the text below to suit your needs.\n+////\n+\n+The point of this tutorial is to discuss the importance of naming state stores (hence `changelog` topics) and repartition topics.  In addition to having a more readable topology description, you can make your Kafka Streams application more robust to topology changes.\n+\n+First look at the code of the Kafka Streams application:\n++++++\n+<pre class=\"snippet\"><code class=\"java\">\n+  KStream&lt;Long, Example&gt; inputStream = builder.stream(inputTopic, Consumed.with(longSerde, exampleSerde))\n+                                                  .selectKey((k, v) -> Long.parseLong(v.getName().substring(0, 1)));\n+\n+  KStream&lt;Long, Long&gt; countStream = inputStream.groupByKey().count().toStream();\n+\n+\n+  KStream&lt;Long, String&gt; joinedStream = inputStream.join(exampleCountStream, (v1, v2) -> v1.getName() + v2.toString(),\n+                                                              JoinWindows.of(Duration.ofMillis(100)),\n+                                                              StreamJoined.with(longSerde, exampleSerde, longSerde));\n+</code></pre>\n++++++\n+\n+\n+In the `inputStream` there is a `selectKey()` operation, changing the key of the incoming stream.\n+\n+As a result, executing the `inputStream.groupByKey()` operation forces a repartition to make sure the modified keys end up on the correct partition.\n+\n+Additionally, `count()` is an aggregation so Kafka Streams creates state store and a changelog topic for fault-tolerance of the state store.\n+\n+There are additional state stores and another reparition topic in this topology, but we'll focus on the `countStream` to keep things simple.  But the same principles apply to any state store, changelog and repartition topic.\n+\n+When using the DSL, Kafka Streams generates the names for each processor, state store, and any required internal topics.  To view a textual representation of your topology, you can run `Topology.describe()`.\n+\n+We won't show a full description here, but describing our topology here results in the following names for the state store, changelog and repartition topic:\n+\n+-  state store - `<application.id>-KSTREAM-AGGREGATE-STATE-STORE-0000000002`\n+-  changelog topic - `<application.id>-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog`\n+-  repartition topic - `<application.id>-KSTREAM-AGGREGATE-STATE-STORE-0000000002-repartition`\n+\n+\n+You'll notice the number `0000000002` at the end of the names.  Kafka Streams appends an incrementing number as part of the name for each part of the topology.  Here the state store, changelog topic and repartition topic share the same number as by default they re-use the name of the state store for their name.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc4NDQ2Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Now go ahead and create the following file at `src/main/java/io/confluent/developer/NamingChangelogAndRepartitionTopics.java`\n          \n          \n            \n            Now go ahead and create the following file at `src/main/java/io/confluent/developer/NamingChangelogAndRepartitionTopics.java`.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405784463", "createdAt": "2020-04-08T20:10:38Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-topology.adoc", "diffHunk": "@@ -0,0 +1,48 @@\n+////\n+In this file you describe the Kafka streams topology, and should cover the main points of the tutorial.\n+The text assumes a method buildTopology exists and constructs the Kafka Streams application.  Feel free to modify the text below to suit your needs.\n+////\n+\n+The point of this tutorial is to discuss the importance of naming state stores (hence `changelog` topics) and repartition topics.  In addition to having a more readable topology description, you can make your Kafka Streams application more robust to topology changes.\n+\n+First look at the code of the Kafka Streams application:\n++++++\n+<pre class=\"snippet\"><code class=\"java\">\n+  KStream&lt;Long, Example&gt; inputStream = builder.stream(inputTopic, Consumed.with(longSerde, exampleSerde))\n+                                                  .selectKey((k, v) -> Long.parseLong(v.getName().substring(0, 1)));\n+\n+  KStream&lt;Long, Long&gt; countStream = inputStream.groupByKey().count().toStream();\n+\n+\n+  KStream&lt;Long, String&gt; joinedStream = inputStream.join(exampleCountStream, (v1, v2) -> v1.getName() + v2.toString(),\n+                                                              JoinWindows.of(Duration.ofMillis(100)),\n+                                                              StreamJoined.with(longSerde, exampleSerde, longSerde));\n+</code></pre>\n++++++\n+\n+\n+In the `inputStream` there is a `selectKey()` operation, changing the key of the incoming stream.\n+\n+As a result, executing the `inputStream.groupByKey()` operation forces a repartition to make sure the modified keys end up on the correct partition.\n+\n+Additionally, `count()` is an aggregation so Kafka Streams creates state store and a changelog topic for fault-tolerance of the state store.\n+\n+There are additional state stores and another reparition topic in this topology, but we'll focus on the `countStream` to keep things simple.  But the same principles apply to any state store, changelog and repartition topic.\n+\n+When using the DSL, Kafka Streams generates the names for each processor, state store, and any required internal topics.  To view a textual representation of your topology, you can run `Topology.describe()`.\n+\n+We won't show a full description here, but describing our topology here results in the following names for the state store, changelog and repartition topic:\n+\n+-  state store - `<application.id>-KSTREAM-AGGREGATE-STATE-STORE-0000000002`\n+-  changelog topic - `<application.id>-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog`\n+-  repartition topic - `<application.id>-KSTREAM-AGGREGATE-STATE-STORE-0000000002-repartition`\n+\n+\n+You'll notice the number `0000000002` at the end of the names.  Kafka Streams appends an incrementing number as part of the name for each part of the topology.  Here the state store, changelog topic and repartition topic share the same number as by default they re-use the name of the state store for their name.\n+\n+Now go ahead and create the following file at `src/main/java/io/confluent/developer/NamingChangelogAndRepartitionTopics.java`", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc4NTExNg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Now go ahead stop the console-producer with a `CTRL+C` and start the console-consumer.  Take note you're running the consumer with the `--from-beggining` option so you'll get all messages sent to the `output` topic.\n          \n          \n            \n            Stop the console-producer with a `CTRL+C`, and start the console-consumer.  Take note you're running the consumer with the `--from-beginning` option so you'll get all messages sent to the `output` topic.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405785116", "createdAt": "2020-04-08T20:11:48Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-consumer.adoc", "diffHunk": "@@ -0,0 +1,24 @@\n+////\n+  This is a sample content file for how to include a console consumer to the tutorial, probably a good idea so the end user can watch the results\n+  of the tutorial.  Change the text as needed.\n+\n+////\n+\n+Now go ahead stop the console-producer with a `CTRL+C` and start the console-consumer.  Take note you're running the consumer with the `--from-beggining` option so you'll get all messages sent to the `output` topic.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc4NTUyNw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            You should take note that even though this is the output of an aggregation operation, this tutorial configured the streams application to use `StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG = 0`, so you'll see _**every**_ update from `count()` operation.\n          \n          \n            \n            Note that even though this is the output of an aggregation operation, this tutorial configured the streams application to use `StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG = 0`, so you'll see _**every**_ update from the `count()` operation.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405785527", "createdAt": "2020-04-08T20:12:36Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-consumer.adoc", "diffHunk": "@@ -0,0 +1,24 @@\n+////\n+  This is a sample content file for how to include a console consumer to the tutorial, probably a good idea so the end user can watch the results\n+  of the tutorial.  Change the text as needed.\n+\n+////\n+\n+Now go ahead stop the console-producer with a `CTRL+C` and start the console-consumer.  Take note you're running the consumer with the `--from-beggining` option so you'll get all messages sent to the `output` topic.\n+\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/console-consumer.sh %}</code></pre>\n++++++\n+\n+From your first run you should see the following output:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/expected-output.txt %}</code></pre>\n++++++\n+\n+You should take note that even though this is the output of an aggregation operation, this tutorial configured the streams application to use `StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG = 0`, so you'll see _**every**_ update from `count()` operation.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc4NTk4Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Since the streams application takes the first character to use as the key, so the output of 1-1, 1-2, and 1-3 (key-count) is expected.\n          \n          \n            \n            Since the streams application takes the first character to use as the key, the output of `1-1`, `1-2`, and `1-3` (key-count) is expected.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405785986", "createdAt": "2020-04-08T20:13:26Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-consumer.adoc", "diffHunk": "@@ -0,0 +1,24 @@\n+////\n+  This is a sample content file for how to include a console consumer to the tutorial, probably a good idea so the end user can watch the results\n+  of the tutorial.  Change the text as needed.\n+\n+////\n+\n+Now go ahead stop the console-producer with a `CTRL+C` and start the console-consumer.  Take note you're running the consumer with the `--from-beggining` option so you'll get all messages sent to the `output` topic.\n+\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/console-consumer.sh %}</code></pre>\n++++++\n+\n+From your first run you should see the following output:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/expected-output.txt %}</code></pre>\n++++++\n+\n+You should take note that even though this is the output of an aggregation operation, this tutorial configured the streams application to use `StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG = 0`, so you'll see _**every**_ update from `count()` operation.\n+\n+Since the streams application takes the first character to use as the key, so the output of 1-1, 1-2, and 1-3 (key-count) is expected.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc4NjIxNw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            As you may have guessed, adding or subtracting a processor in your topology will change the name of all processors downstram of your change.\n          \n          \n            \n            As you may have guessed, adding or subtracting a processor in your topology will change the name of all processors downstream of your change.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405786217", "createdAt": "2020-04-08T20:13:49Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/add-filter-to-topology.adoc", "diffHunk": "@@ -0,0 +1,30 @@\n+As you may have guessed, adding or subtracting a processor in your topology will change the name of all processors downstram of your change.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc4NzIzMw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            To make things a little easier for you, the code for the tutorial is configured to use feature flags. You'll use the feature flags by passing different parameters in the command to start the Kafka Streams application.\n          \n          \n            \n            To make things a little easier, the code for the tutorial is configured to use feature flags. You'll use the feature flags by passing different parameters in the command to start the Kafka Streams application.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405787233", "createdAt": "2020-04-08T20:15:27Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/add-filter-to-topology.adoc", "diffHunk": "@@ -0,0 +1,30 @@\n+As you may have guessed, adding or subtracting a processor in your topology will change the name of all processors downstram of your change.\n+\n+With that in mind, let's add a `filter()` processor to the `inputStream`:\n+\n+\n++++++\n+<pre class=\"snippet\"><code class=\"java\">\n+  KStream&lt;Long, Example&gt; inputStream = builder.stream(inputTopic, Consumed.with(longSerde, exampleSerde))\n+                                                  .selectKey((k, v) -> Long.parseLong(v.getName().substring(0, 1)))\n+                                                  .filter((k, v) -> k != 1L);\n+</code></pre>\n++++++\n+\n+To make things a little easier for you, the code for the tutorial is configured to use feature flags. You'll use the feature flags by passing different parameters in the command to start the Kafka Streams application.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc4NzY2MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Now go back to the window running the streams application and do a `CTRL+C` then restart the app with the following command:\n          \n          \n            \n            Now, in the terminal running the streams application, do a `CTRL+C`, then restart the app with the following command:", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405787661", "createdAt": "2020-04-08T20:16:11Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/add-filter-to-topology.adoc", "diffHunk": "@@ -0,0 +1,30 @@\n+As you may have guessed, adding or subtracting a processor in your topology will change the name of all processors downstram of your change.\n+\n+With that in mind, let's add a `filter()` processor to the `inputStream`:\n+\n+\n++++++\n+<pre class=\"snippet\"><code class=\"java\">\n+  KStream&lt;Long, Example&gt; inputStream = builder.stream(inputTopic, Consumed.with(longSerde, exampleSerde))\n+                                                  .selectKey((k, v) -> Long.parseLong(v.getName().substring(0, 1)))\n+                                                  .filter((k, v) -> k != 1L);\n+</code></pre>\n++++++\n+\n+To make things a little easier for you, the code for the tutorial is configured to use feature flags. You'll use the feature flags by passing different parameters in the command to start the Kafka Streams application.\n+\n+Since you've added the `filter()` before the aggregation, the name of the state store, changelog topic, and repartition topic will change.\n+\n+In the new names, the number suffix will go from `0000000002` to `0000000003` like so:\n+\n+\n+* state store - `<application.id>-KSTREAM-AGGREGATE-STATE-STORE-0000000003`\n+* changelog topic - `<application.id>-KSTREAM-AGGREGATE-STATE-STORE-0000000003-changelog`\n+* repartition topic - `<application.id>-KSTREAM-AGGREGATE-STATE-STORE-0000000003-repartition`\n+\n+Now go back to the window running the streams application and do a `CTRL+C` then restart the app with the following command:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc4ODExOA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Go back to the producer/consumer terminal and start the console-producer again\n          \n          \n            \n            Go back to the producer/consumer terminal and start the console-producer again.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405788118", "createdAt": "2020-04-08T20:16:57Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-producer-no-names-with-filter.adoc", "diffHunk": "@@ -0,0 +1,25 @@\n+////\n+   Example content file for how to include a console produer(s) in the tutorial.\n+   Usually you'll include a line referencing the script to run the console producer and also include some content\n+   describing how to input data as shown below.\n+\n+   Again modify this file as you need for your tutorial, as this is just sample content.  You also may have more than one\n+   console producer to run depending on how you structure your tutorial\n+\n+////\n+\n+Go back to the producer/consumer terminal and start the console-producer again", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc4ODY1OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            You are going to send the exact same data from before, as we want to update the counts for existing records.\n          \n          \n            \n            \n          \n          \n            \n            Copy and paste the following into the prompt and press enter:\n          \n          \n            \n            We'll send the exact same data from before, as we want to update the counts for existing records. Copy and paste the following into the prompt and press enter:", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405788659", "createdAt": "2020-04-08T20:17:57Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-producer-no-names-with-filter.adoc", "diffHunk": "@@ -0,0 +1,25 @@\n+////\n+   Example content file for how to include a console produer(s) in the tutorial.\n+   Usually you'll include a line referencing the script to run the console producer and also include some content\n+   describing how to input data as shown below.\n+\n+   Again modify this file as you need for your tutorial, as this is just sample content.  You also may have more than one\n+   console producer to run depending on how you structure your tutorial\n+\n+////\n+\n+Go back to the producer/consumer terminal and start the console-producer again\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/console-producer.sh %}</code></pre>\n++++++\n+\n+You are going to send the exact same data from before, as we want to update the counts for existing records.\n+\n+Copy and paste the following into the prompt and press enter:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc4OTMxOA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            If you haven't already stop the console-producer with a `CTRL+C` and re-start the console-consumer.  Remember the consumer is running with the `--from-beggining` option so you'll get all messages sent to the `output-topic` topic.\n          \n          \n            \n            Now, restart the console-consumer.  Remember the consumer is running with the `--from-beginning` option so you'll get all messages sent to the `output-topic` topic.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405789318", "createdAt": "2020-04-08T20:19:09Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-consumer-no-names-filter.adoc", "diffHunk": "@@ -0,0 +1,26 @@\n+////\n+  This is a sample content file for how to include a console consumer to the tutorial, probably a good idea so the end user can watch the results\n+  of the tutorial.  Change the text as needed.\n+\n+////\n+\n+If you haven't already stop the console-producer with a `CTRL+C` and re-start the console-consumer.  Remember the consumer is running with the `--from-beggining` option so you'll get all messages sent to the `output-topic` topic.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc5MDMyOA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Even though the Kafka Streams application counts by key and you sent the same keys, the output is repeated.  Remember streams produced the first 3 records in the previous run.  So why is the output `1-1, 1-2, 1-3` instead of `1-4, 1-5, 1-6`?  Well you added a new operation to the topology, which incremented the counter used to generate the names of every processor, state store, and internal topic downstream of the new operator.\n          \n          \n            \n            Even though the Kafka Streams application counts by key and you sent the same keys, the output is repeated.  The application produced the first 3 records in the previous run.  So why is the output `1-1, 1-2, 1-3` instead of `1-4, 1-5, 1-6`?  Adding the new operation incremented the counter used to generate the names of every processor, state store, and internal topic downstream of the new operator.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405790328", "createdAt": "2020-04-08T20:20:59Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-consumer-no-names-filter.adoc", "diffHunk": "@@ -0,0 +1,26 @@\n+////\n+  This is a sample content file for how to include a console consumer to the tutorial, probably a good idea so the end user can watch the results\n+  of the tutorial.  Change the text as needed.\n+\n+////\n+\n+If you haven't already stop the console-producer with a `CTRL+C` and re-start the console-consumer.  Remember the consumer is running with the `--from-beggining` option so you'll get all messages sent to the `output-topic` topic.\n+\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/console-consumer.sh %}</code></pre>\n++++++\n+\n+In this second run, you should see this output:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/expected-output-no-names-with-filter.txt %}</code></pre>\n++++++\n+\n+Even though the Kafka Streams application counts by key and you sent the same keys, the output is repeated.  Remember streams produced the first 3 records in the previous run.  So why is the output `1-1, 1-2, 1-3` instead of `1-4, 1-5, 1-6`?  Well you added a new operation to the topology, which incremented the counter used to generate the names of every processor, state store, and internal topic downstream of the new operator.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc5MTE4MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            This renaming means the streams application `count()` processor now uses a new state store, vs. the one created when you first started the application.  The situation is the same if you used an in-memory store as the name of the changelog topic has changed as well, so there is nothing to restore once streams builds the in-memory store.\n          \n          \n            \n            This renaming means the streams application `count()` processor now uses a new state store, vs. the one created when you first started the application.  The situation is the same if you used an in-memory store as the name of the changelog topic. When the name changes, there is nothing to restore once streams builds the in-memory store.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405791181", "createdAt": "2020-04-08T20:22:39Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-consumer-no-names-filter.adoc", "diffHunk": "@@ -0,0 +1,26 @@\n+////\n+  This is a sample content file for how to include a console consumer to the tutorial, probably a good idea so the end user can watch the results\n+  of the tutorial.  Change the text as needed.\n+\n+////\n+\n+If you haven't already stop the console-producer with a `CTRL+C` and re-start the console-consumer.  Remember the consumer is running with the `--from-beggining` option so you'll get all messages sent to the `output-topic` topic.\n+\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/console-consumer.sh %}</code></pre>\n++++++\n+\n+In this second run, you should see this output:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/expected-output-no-names-with-filter.txt %}</code></pre>\n++++++\n+\n+Even though the Kafka Streams application counts by key and you sent the same keys, the output is repeated.  Remember streams produced the first 3 records in the previous run.  So why is the output `1-1, 1-2, 1-3` instead of `1-4, 1-5, 1-6`?  Well you added a new operation to the topology, which incremented the counter used to generate the names of every processor, state store, and internal topic downstream of the new operator.\n+\n+This renaming means the streams application `count()` processor now uses a new state store, vs. the one created when you first started the application.  The situation is the same if you used an in-memory store as the name of the changelog topic has changed as well, so there is nothing to restore once streams builds the in-memory store.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc5MTQzNA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Your orginal data is still there, but it's just that streams isn't using the previously created state store and changelog topic.\n          \n          \n            \n            Your original data is still there, but Kafka Streams isn't using the previously created state store and changelog topic.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405791434", "createdAt": "2020-04-08T20:23:09Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-consumer-no-names-filter.adoc", "diffHunk": "@@ -0,0 +1,26 @@\n+////\n+  This is a sample content file for how to include a console consumer to the tutorial, probably a good idea so the end user can watch the results\n+  of the tutorial.  Change the text as needed.\n+\n+////\n+\n+If you haven't already stop the console-producer with a `CTRL+C` and re-start the console-consumer.  Remember the consumer is running with the `--from-beggining` option so you'll get all messages sent to the `output-topic` topic.\n+\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/console-consumer.sh %}</code></pre>\n++++++\n+\n+In this second run, you should see this output:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/expected-output-no-names-with-filter.txt %}</code></pre>\n++++++\n+\n+Even though the Kafka Streams application counts by key and you sent the same keys, the output is repeated.  Remember streams produced the first 3 records in the previous run.  So why is the output `1-1, 1-2, 1-3` instead of `1-4, 1-5, 1-6`?  Well you added a new operation to the topology, which incremented the counter used to generate the names of every processor, state store, and internal topic downstream of the new operator.\n+\n+This renaming means the streams application `count()` processor now uses a new state store, vs. the one created when you first started the application.  The situation is the same if you used an in-memory store as the name of the changelog topic has changed as well, so there is nothing to restore once streams builds the in-memory store.\n+\n+Your orginal data is still there, but it's just that streams isn't using the previously created state store and changelog topic.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc5MjIyNg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Now let's start over but this time you'll update the topology and provide names to all stateful operators:\n          \n          \n            \n            Now let's start over. This time you'll update the topology and provide names to all stateful operators.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405792226", "createdAt": "2020-04-08T20:24:31Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/add-names-to-topology.adoc", "diffHunk": "@@ -0,0 +1,23 @@\n+Now let's start over but this time you'll update the topology and provide names to all stateful operators:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc5MjY0Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Now go back to the window running the streams application and do a `CTRL+C` then restart the streams application with this command:\n          \n          \n            \n            Now go back to the window running the streams application and do a `CTRL+C` then restart the streams application with this command:\n          \n      \n    \n    \n  \n\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Now go back to the window running the streams application and do a `CTRL+C` then restart the streams application with this command:\n          \n          \n            \n            In the terminal running the streams application, do a `CTRL+C`, then restart the streams application with this command:", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405792646", "createdAt": "2020-04-08T20:25:13Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/add-names-to-topology.adoc", "diffHunk": "@@ -0,0 +1,23 @@\n+Now let's start over but this time you'll update the topology and provide names to all stateful operators:\n+\n+\n++++++\n+<pre class=\"snippet\"><code class=\"java\">\n+ countStream = inputStream.groupByKey(Grouped.with(\"count\", longSerde, stringSerde))\n+                                   .count(Materialized.as(\"the-counting-store\"))\n+                                   .toStream();\n+\n+ joinedStream = inputStream.join(countStream, (v1, v2) -> v1 + v2.toString(),\n+                                 JoinWindows.of(Duration.ofMillis(100)),\n+                                 StreamJoined.with(longSerde, stringSerde, longSerde)\n+                                             .withName(\"join\").withStoreName(\"the-join-store\"));\n+</code></pre>\n++++++\n+\n+Just like you've done throughout the tutorial, the changes are made by using feature flags which are enabled by parameters you pass to start the application.\n+\n+Now go back to the window running the streams application and do a `CTRL+C` then restart the streams application with this command:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc5MjkwNw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Back in your procducer/consumer terminal start the console-producer again\n          \n          \n            \n            Back in your producer/consumer terminal, start the console-producer again.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405792907", "createdAt": "2020-04-08T20:25:39Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-producer-names-no-filter.adoc", "diffHunk": "@@ -0,0 +1,22 @@\n+////\n+   Example content file for how to include a console produer(s) in the tutorial.\n+   Usually you'll include a line referencing the script to run the console producer and also include some content\n+   describing how to input data as shown below.\n+\n+   Again modify this file as you need for your tutorial, as this is just sample content.  You also may have more than one\n+   console producer to run depending on how you structure your tutorial\n+\n+////\n+Back in your procducer/consumer terminal start the console-producer again", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc5MzM1MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Since you used data resulting in new keys `2-1, 2-2, 2-3` looks correct.\n          \n          \n            \n            Since you used data resulting in new keys, `2-1, 2-2, 2-3` looks correct.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405793351", "createdAt": "2020-04-08T20:26:25Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-consumer-names-no-filter.adoc", "diffHunk": "@@ -0,0 +1,22 @@\n+////\n+  This is a sample content file for how to include a console consumer to the tutorial, probably a good idea so the end user can watch the results\n+  of the tutorial.  Change the text as needed.\n+\n+////\n+\n+Now let's start up the console consumer again:\n+\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/console-consumer.sh %}</code></pre>\n++++++\n+\n+For this run you should see all six records plus three new records:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/expected-output-names-no-filter.txt %}</code></pre>\n++++++\n+\n+Since you used data resulting in new keys `2-1, 2-2, 2-3` looks correct.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc5MzU0OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                - title: Update named topology\n          \n          \n            \n                - title: Update the named topology", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405793548", "createdAt": "2020-04-08T20:26:48Z", "author": {"login": "colinhicks"}, "path": "_data/harnesses/naming-changelog-repartition-topics/kstreams.yml", "diffHunk": "@@ -0,0 +1,238 @@\n+dev:\n+  steps:\n+    - title: Initialize the project\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/init.sh\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/init.adoc\n+\n+    - title: Get Confluent Platform\n+      content:\n+        - action: make_file\n+          file: docker-compose.yml\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-docker-compose.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/start-compose.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            skip: true\n+\n+    - title: Configure the project\n+      content:\n+        - action: make_file\n+          file: build.gradle\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-build-file.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/gradle-wrapper.sh\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-gradle-wrapper.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/make-configuration-dir.sh\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-config-dir.adoc\n+\n+        - action: make_file\n+          file: configuration/dev.properties\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-dev-file.adoc\n+            \n+    - title: Create an initial Kafka Streams topology\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/make-src-dir.sh\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-src-dir.adoc\n+            \n+        - action: make_file\n+          file: src/main/java/io/confluent/developer/NamingChangelogAndRepartitionTopics.java\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-topology.adoc\n+\n+    - title: Compile and run the Kafka Streams program\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/build-uberjar.sh\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/build-uberjar.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/run-dev-app.sh\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-dev-app.adoc\n+\n+    - title: Produce sample data to the input topic\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/console-producer.sh\n+          stdin: tutorial-steps/dev/input.txt\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-producer.adoc\n+\n+    - title: Consume data from the output topic\n+      content:\n+        - action: execute_async\n+          file: tutorial-steps/dev/console-consumer.sh\n+          stdout: tutorial-steps/dev/outputs/actual-output.txt\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-consumer.adoc\n+\n+        - name: wait for the consumer to read the messages\n+          action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+\n+    - title: Add an operation to the topology\n+      content:    \n+        - action: skip\n+          file: src/main/java/io/confluent/developer/NamingChangelogAndRepartitionTopics.java\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/add-filter-to-topology.adoc \n+\n+        - action: execute\n+          file: tutorial-steps/dev/stop-streams-app.sh\n+          render:\n+            skip: true\n+\n+        - name: wait for streams to stop\n+          action: sleep\n+          ms: 5000\n+          render:\n+            skip: true    \n+     \n+        - action: execute_async\n+          file: tutorial-steps/dev/run-dev-app-no-name-filter.sh\n+          render:\n+            skip: true\n+\n+    - title: Produce some records to the updated topology\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/console-producer.sh\n+          stdin: tutorial-steps/dev/input.txt\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-producer-no-names-with-filter.adoc\n+\n+    - title: Consume the updated records\n+      content:\n+        - action: execute_async\n+          file: tutorial-steps/dev/console-consumer.sh\n+          stdout: tutorial-steps/dev/outputs/actual-output.txt\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-consumer-no-names-filter.adoc\n+\n+        - name: wait for the consumer to read the messages\n+          action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+\n+    - title: Add names to the stateful operators of the topology\n+      content:    \n+        - action: make_file\n+          file: src/main/java/io/confluent/developer/NamingChangelogAndRepartitionTopics.java\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/add-names-to-topology.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/stop-streams-app.sh\n+          render:\n+            skip: true\n+\n+        - name: wait for streams to stop\n+          action: sleep\n+          ms: 5000\n+          render:\n+            skip: true    \n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/run-dev-app-names-no-filter.sh\n+          render:\n+            skip: true\n+\n+    - title: Produce records to the named topology\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/console-producer.sh\n+          stdin: tutorial-steps/dev/named-input.txt\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-producer-names-no-filter.adoc\n+\n+    - title: Consume records from the named topology\n+      content:\n+        - action: execute_async\n+          file: tutorial-steps/dev/console-consumer.sh\n+          stdout: tutorial-steps/dev/outputs/actual-output.txt\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-consumer-names-no-filter.adoc\n+        - name: wait for the consumer to read the messages\n+          action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+\n+    - title: Update named topology", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 184}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc5Mzk3Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                - title: Produce records updated named topology\n          \n          \n            \n                - title: Produce records to the updated, named topology", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405793973", "createdAt": "2020-04-08T20:27:38Z", "author": {"login": "colinhicks"}, "path": "_data/harnesses/naming-changelog-repartition-topics/kstreams.yml", "diffHunk": "@@ -0,0 +1,238 @@\n+dev:\n+  steps:\n+    - title: Initialize the project\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/init.sh\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/init.adoc\n+\n+    - title: Get Confluent Platform\n+      content:\n+        - action: make_file\n+          file: docker-compose.yml\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-docker-compose.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/start-compose.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            skip: true\n+\n+    - title: Configure the project\n+      content:\n+        - action: make_file\n+          file: build.gradle\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-build-file.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/gradle-wrapper.sh\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-gradle-wrapper.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/make-configuration-dir.sh\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-config-dir.adoc\n+\n+        - action: make_file\n+          file: configuration/dev.properties\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-dev-file.adoc\n+            \n+    - title: Create an initial Kafka Streams topology\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/make-src-dir.sh\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-src-dir.adoc\n+            \n+        - action: make_file\n+          file: src/main/java/io/confluent/developer/NamingChangelogAndRepartitionTopics.java\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-topology.adoc\n+\n+    - title: Compile and run the Kafka Streams program\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/build-uberjar.sh\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/build-uberjar.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/run-dev-app.sh\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-dev-app.adoc\n+\n+    - title: Produce sample data to the input topic\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/console-producer.sh\n+          stdin: tutorial-steps/dev/input.txt\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-producer.adoc\n+\n+    - title: Consume data from the output topic\n+      content:\n+        - action: execute_async\n+          file: tutorial-steps/dev/console-consumer.sh\n+          stdout: tutorial-steps/dev/outputs/actual-output.txt\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-consumer.adoc\n+\n+        - name: wait for the consumer to read the messages\n+          action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+\n+    - title: Add an operation to the topology\n+      content:    \n+        - action: skip\n+          file: src/main/java/io/confluent/developer/NamingChangelogAndRepartitionTopics.java\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/add-filter-to-topology.adoc \n+\n+        - action: execute\n+          file: tutorial-steps/dev/stop-streams-app.sh\n+          render:\n+            skip: true\n+\n+        - name: wait for streams to stop\n+          action: sleep\n+          ms: 5000\n+          render:\n+            skip: true    \n+     \n+        - action: execute_async\n+          file: tutorial-steps/dev/run-dev-app-no-name-filter.sh\n+          render:\n+            skip: true\n+\n+    - title: Produce some records to the updated topology\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/console-producer.sh\n+          stdin: tutorial-steps/dev/input.txt\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-producer-no-names-with-filter.adoc\n+\n+    - title: Consume the updated records\n+      content:\n+        - action: execute_async\n+          file: tutorial-steps/dev/console-consumer.sh\n+          stdout: tutorial-steps/dev/outputs/actual-output.txt\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-consumer-no-names-filter.adoc\n+\n+        - name: wait for the consumer to read the messages\n+          action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+\n+    - title: Add names to the stateful operators of the topology\n+      content:    \n+        - action: make_file\n+          file: src/main/java/io/confluent/developer/NamingChangelogAndRepartitionTopics.java\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/add-names-to-topology.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/stop-streams-app.sh\n+          render:\n+            skip: true\n+\n+        - name: wait for streams to stop\n+          action: sleep\n+          ms: 5000\n+          render:\n+            skip: true    \n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/run-dev-app-names-no-filter.sh\n+          render:\n+            skip: true\n+\n+    - title: Produce records to the named topology\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/console-producer.sh\n+          stdin: tutorial-steps/dev/named-input.txt\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-producer-names-no-filter.adoc\n+\n+    - title: Consume records from the named topology\n+      content:\n+        - action: execute_async\n+          file: tutorial-steps/dev/console-consumer.sh\n+          stdout: tutorial-steps/dev/outputs/actual-output.txt\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-consumer-names-no-filter.adoc\n+        - name: wait for the consumer to read the messages\n+          action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+\n+    - title: Update named topology\n+      content:    \n+        - action: make_file\n+          file: src/main/java/io/confluent/developer/NamingChangelogAndRepartitionTopics.java\n+          render:\n+            file: tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/add-filter-to-named-topology.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/stop-streams-app.sh\n+          render:\n+            skip: true\n+\n+        - name: wait for streams to stop\n+          action: sleep\n+          ms: 5000\n+          render:\n+            skip: true         \n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/run-dev-app-names-with-filter.sh\n+          render:\n+            skip: true\n+\n+    - title: Produce records updated named topology", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 207}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc5NDQ2Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Now go back to the window running the streams application and do a `CTRL+C` then restart the streams application with this command:\n          \n          \n            \n            In the terminal running the streams application, do a `CTRL+C`, then restart the streams application with this command:", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405794467", "createdAt": "2020-04-08T20:28:33Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/add-filter-to-named-topology.adoc", "diffHunk": "@@ -0,0 +1,19 @@\n+Now let's add a new operator (`filter()`) to the named topology:\n+\n+\n++++++\n+<pre class=\"snippet\"><code class=\"java\">\n+  KStream&lt;Long, Example&gt; inputStream = builder.stream(inputTopic, Consumed.with(longSerde, exampleSerde))\n+                                                  .selectKey((k, v) -> Long.parseLong(v.getName().substring(0, 1)))\n+                                                  .filter((k, v) -> k != 1L);\n+</code></pre>\n++++++\n+\n+But this time, adding a new processor won't change the name of the stateful parts of your application, as you've explicity named them in the previous step.\n+\n+Now go back to the window running the streams application and do a `CTRL+C` then restart the streams application with this command:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc5NDk1MA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            One last time from your consusmer/producer terminal,  start a console-producer\n          \n          \n            \n            One last time, from your producer/consumer terminal,  start a console-producer", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405794950", "createdAt": "2020-04-08T20:29:22Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-producer-names-with-filter.adoc", "diffHunk": "@@ -0,0 +1,23 @@\n+////\n+   Example content file for how to include a console produer(s) in the tutorial.\n+   Usually you'll include a line referencing the script to run the console producer and also include some content\n+   describing how to input data as shown below.\n+\n+   Again modify this file as you need for your tutorial, as this is just sample content.  You also may have more than one\n+   console producer to run depending on how you structure your tutorial\n+\n+////\n+\n+One last time from your consusmer/producer terminal,  start a console-producer", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc5NTQ0Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Now stop the console-prodcer (if you haven't already) and start a console-consumer (for the last time I promise!)\n          \n          \n            \n            Finally, start a console-consumer.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405795446", "createdAt": "2020-04-08T20:30:22Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-consumer-names-with-filter.adoc", "diffHunk": "@@ -0,0 +1,54 @@\n+////\n+  This is a sample content file for how to include a console consumer to the tutorial, probably a good idea so the end user can watch the results\n+  of the tutorial.  Change the text as needed.\n+\n+////\n+\n+Now stop the console-prodcer (if you haven't already) and start a console-consumer (for the last time I promise!)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc5NTk2Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Looking at the last three records you see `2-4, 2-5, 2-6`.  This output is correct as you produced six records with the same key, so the final count is accurate.\n          \n          \n            \n            The last three records, `2-4, 2-5, 2-6`, show the correct output, as you produced six records with the same key.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405795963", "createdAt": "2020-04-08T20:31:28Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-consumer-names-with-filter.adoc", "diffHunk": "@@ -0,0 +1,54 @@\n+////\n+  This is a sample content file for how to include a console consumer to the tutorial, probably a good idea so the end user can watch the results\n+  of the tutorial.  Change the text as needed.\n+\n+////\n+\n+Now stop the console-prodcer (if you haven't already) and start a console-consumer (for the last time I promise!)\n+\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/console-consumer.sh %}</code></pre>\n++++++\n+\n+You should see the following output:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/expected-output-names-with-filter.txt %}</code></pre>\n++++++\n+\n+Looking at the last three records you see `2-4, 2-5, 2-6`.  This output is correct as you produced six records with the same key, so the final count is accurate.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc5NjI4MA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            You have updated your topology and re-used the existing state stores and internal topics!\n          \n          \n            \n            You have updated your topology and reused the existing state stores and internal topics!", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405796280", "createdAt": "2020-04-08T20:32:03Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-consumer-names-with-filter.adoc", "diffHunk": "@@ -0,0 +1,54 @@\n+////\n+  This is a sample content file for how to include a console consumer to the tutorial, probably a good idea so the end user can watch the results\n+  of the tutorial.  Change the text as needed.\n+\n+////\n+\n+Now stop the console-prodcer (if you haven't already) and start a console-consumer (for the last time I promise!)\n+\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/console-consumer.sh %}</code></pre>\n++++++\n+\n+You should see the following output:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/expected-output-names-with-filter.txt %}</code></pre>\n++++++\n+\n+Looking at the last three records you see `2-4, 2-5, 2-6`.  This output is correct as you produced six records with the same key, so the final count is accurate.\n+\n+You have updated your topology and re-used the existing state stores and internal topics!", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc5NjkwNQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            . Always name sateful operators\n          \n          \n            \n            . Always name stateful operators", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405796905", "createdAt": "2020-04-08T20:33:11Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-consumer-names-with-filter.adoc", "diffHunk": "@@ -0,0 +1,54 @@\n+////\n+  This is a sample content file for how to include a console consumer to the tutorial, probably a good idea so the end user can watch the results\n+  of the tutorial.  Change the text as needed.\n+\n+////\n+\n+Now stop the console-prodcer (if you haven't already) and start a console-consumer (for the last time I promise!)\n+\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/console-consumer.sh %}</code></pre>\n++++++\n+\n+You should see the following output:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/expected-output-names-with-filter.txt %}</code></pre>\n++++++\n+\n+Looking at the last three records you see `2-4, 2-5, 2-6`.  This output is correct as you produced six records with the same key, so the final count is accurate.\n+\n+You have updated your topology and re-used the existing state stores and internal topics!\n+\n+\n+\n+\n+. Always name sateful operators", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc5NzA5NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            . If you haven't named your stateful operators and you need to update your toplogy, use the `https://docs.confluent.io/current/streams/developer-guide/app-reset-tool.html[Application Reset Tool]` to reprocess records (tutorial coming soon!).\n          \n          \n            \n            . If you haven't named your stateful operators and you need to update your topology, use the `https://docs.confluent.io/current/streams/developer-guide/app-reset-tool.html[Application Reset Tool]` to reprocess records.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405797094", "createdAt": "2020-04-08T20:33:35Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-consumer-names-with-filter.adoc", "diffHunk": "@@ -0,0 +1,54 @@\n+////\n+  This is a sample content file for how to include a console consumer to the tutorial, probably a good idea so the end user can watch the results\n+  of the tutorial.  Change the text as needed.\n+\n+////\n+\n+Now stop the console-prodcer (if you haven't already) and start a console-consumer (for the last time I promise!)\n+\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/console-consumer.sh %}</code></pre>\n++++++\n+\n+You should see the following output:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/expected-output-names-with-filter.txt %}</code></pre>\n++++++\n+\n+Looking at the last three records you see `2-4, 2-5, 2-6`.  This output is correct as you produced six records with the same key, so the final count is accurate.\n+\n+You have updated your topology and re-used the existing state stores and internal topics!\n+\n+\n+\n+\n+. Always name sateful operators\n+. If you haven't named your stateful operators and you need to update your toplogy, use the `https://docs.confluent.io/current/streams/developer-guide/app-reset-tool.html[Application Reset Tool]` to reprocess records (tutorial coming soon!).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc5NzY0NA==", "bodyText": "Does it make sense to put these two points under the conclusion header, too?", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405797644", "createdAt": "2020-04-08T20:34:30Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-consumer-names-with-filter.adoc", "diffHunk": "@@ -0,0 +1,54 @@\n+////\n+  This is a sample content file for how to include a console consumer to the tutorial, probably a good idea so the end user can watch the results\n+  of the tutorial.  Change the text as needed.\n+\n+////\n+\n+Now stop the console-prodcer (if you haven't already) and start a console-consumer (for the last time I promise!)\n+\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/console-consumer.sh %}</code></pre>\n++++++\n+\n+You should see the following output:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/expected-output-names-with-filter.txt %}</code></pre>\n++++++\n+\n+Looking at the last three records you see `2-4, 2-5, 2-6`.  This output is correct as you produced six records with the same key, so the final count is accurate.\n+\n+You have updated your topology and re-used the existing state stores and internal topics!\n+\n+\n+\n+\n+. Always name sateful operators\n+. If you haven't named your stateful operators and you need to update your toplogy, use the `https://docs.confluent.io/current/streams/developer-guide/app-reset-tool.html[Application Reset Tool]` to reprocess records (tutorial coming soon!).\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc5Nzg2Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              <div class=\"text\">Conclusion - Some points to remember</div>\n          \n          \n            \n              <div class=\"text\">Some points to remember</div>", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405797862", "createdAt": "2020-04-08T20:34:56Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-consumer-names-with-filter.adoc", "diffHunk": "@@ -0,0 +1,54 @@\n+////\n+  This is a sample content file for how to include a console consumer to the tutorial, probably a good idea so the end user can watch the results\n+  of the tutorial.  Change the text as needed.\n+\n+////\n+\n+Now stop the console-prodcer (if you haven't already) and start a console-consumer (for the last time I promise!)\n+\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/console-consumer.sh %}</code></pre>\n++++++\n+\n+You should see the following output:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/expected-output-names-with-filter.txt %}</code></pre>\n++++++\n+\n+Looking at the last three records you see `2-4, 2-5, 2-6`.  This output is correct as you produced six records with the same key, so the final count is accurate.\n+\n+You have updated your topology and re-used the existing state stores and internal topics!\n+\n+\n+\n+\n+. Always name sateful operators\n+. If you haven't named your stateful operators and you need to update your toplogy, use the `https://docs.confluent.io/current/streams/developer-guide/app-reset-tool.html[Application Reset Tool]` to reprocess records (tutorial coming soon!).\n+\n+++++\n+<br/> <br/>\n+<h4 class=\"subtitle\">\n+  <div class=\"text\">Conclusion - Some points to remember</div>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc5ODIwNg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n               . `StreamJoined.withStoreName()` used to name the state stores associated with the join.\n          \n          \n            \n               . `StreamJoined.withStoreName()` is used to name the state stores associated with the join.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r405798206", "createdAt": "2020-04-08T20:35:39Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/run-consumer-names-with-filter.adoc", "diffHunk": "@@ -0,0 +1,54 @@\n+////\n+  This is a sample content file for how to include a console consumer to the tutorial, probably a good idea so the end user can watch the results\n+  of the tutorial.  Change the text as needed.\n+\n+////\n+\n+Now stop the console-prodcer (if you haven't already) and start a console-consumer (for the last time I promise!)\n+\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/console-consumer.sh %}</code></pre>\n++++++\n+\n+You should see the following output:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/expected-output-names-with-filter.txt %}</code></pre>\n++++++\n+\n+Looking at the last three records you see `2-4, 2-5, 2-6`.  This output is correct as you produced six records with the same key, so the final count is accurate.\n+\n+You have updated your topology and re-used the existing state stores and internal topics!\n+\n+\n+\n+\n+. Always name sateful operators\n+. If you haven't named your stateful operators and you need to update your toplogy, use the `https://docs.confluent.io/current/streams/developer-guide/app-reset-tool.html[Application Reset Tool]` to reprocess records (tutorial coming soon!).\n+\n+++++\n+<br/> <br/>\n+<h4 class=\"subtitle\">\n+  <div class=\"text\">Conclusion - Some points to remember</div>\n+</h4>\n+++++\n+\n+- **Aggregation repartition topics (if needed)**\n+   . Use the `Grouped.as()` method\n+   . Use `Grouped` to provide repartition `Serdes` as well if required\n+   . Kafka Streams appends the text `-repartition` to the provided name\n+   . If no name is provided, the state store name is used with `-repartition` appended\n+\n+- **Joins**\n+   . Use the `StreamJoined` configuration object\n+   . `StreamJoined.name()` names the join processors and provides the base-name of the repartition topic (if needed)\n+   . `StreamJoined.withStoreName()` used to name the state stores associated with the join.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 46}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkwODgyNDIx", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#pullrequestreview-390882421", "createdAt": "2020-04-09T15:09:51Z", "commit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQxNTowOTo1MVrOGDdFtA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQxNTowOTo1MVrOGDdFtA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjI3NTUwOA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            <pre class=\"snippet\"><code class=\"dockerfile\">{% include_raw tutorials/filtering/kstreams/code/docker-compose.yml %}</code></pre>\n          \n          \n            \n            <pre class=\"snippet\"><code class=\"dockerfile\">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/docker-compose.yml %}</code></pre>", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#discussion_r406275508", "createdAt": "2020-04-09T15:09:51Z", "author": {"login": "gAmUssA"}, "path": "_includes/tutorials/naming-changelog-repartition-topics/kstreams/markup/dev/make-docker-compose.adoc", "diffHunk": "@@ -0,0 +1,5 @@\n+Next, create the following `docker-compose.yml` file to obtain Confluent Platform:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"dockerfile\">{% include_raw tutorials/filtering/kstreams/code/docker-compose.yml %}</code></pre>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa3a073ce44d5be84a8125d2a1c16cb12da6dd77"}, "originalPosition": 4}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ef343537d5dd07589bd00e99b71efea3dace2ac7", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/ef343537d5dd07589bd00e99b71efea3dace2ac7", "committedDate": "2020-04-09T18:46:44Z", "message": "Apply suggestions from code review\n\nCo-Authored-By: Colin Hicks <colin.hicks@confluent.io>\nCo-Authored-By: Viktor Gamov <viktor@confluent.io>"}, "afterCommit": {"oid": "e4ee057371f73d76207750e7bd9cee4bec136899", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/e4ee057371f73d76207750e7bd9cee4bec136899", "committedDate": "2020-04-09T21:04:14Z", "message": "updates for adding topology images and links to full topology images"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxMTM4MTQ4", "url": "https://github.com/confluentinc/kafka-tutorials/pull/314#pullrequestreview-391138148", "createdAt": "2020-04-09T21:16:31Z", "commit": {"oid": "e4ee057371f73d76207750e7bd9cee4bec136899"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b109d0ce820fe980a13ac79cac6c23a5def22a5f", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/b109d0ce820fe980a13ac79cac6c23a5def22a5f", "committedDate": "2020-04-10T16:36:00Z", "message": "Initial commit for naming stateful parts of a kafka streams application"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c347b71480158966d82f7f1afbeb567ba66c0630", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/c347b71480158966d82f7f1afbeb567ba66c0630", "committedDate": "2020-04-10T16:36:00Z", "message": "incremental changes for naming stores, changelogs and repartition topics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "410f4f2538501fcf79e222281614eee9a425914c", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/410f4f2538501fcf79e222281614eee9a425914c", "committedDate": "2020-04-10T16:38:19Z", "message": "Initial commit for stateful namiing tutorial"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4e500b7940763ce7c55efe1504f74c292ba14a02", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/4e500b7940763ce7c55efe1504f74c292ba14a02", "committedDate": "2020-04-10T16:38:19Z", "message": "Remove extra file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b3b20abc413912214bbf7677e709ad16b81e6f89", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/b3b20abc413912214bbf7677e709ad16b81e6f89", "committedDate": "2020-04-10T16:38:19Z", "message": "Apply suggestions from code review\r\n\r\nThanks for the review @gAmUssA!\n\nCo-Authored-By: Viktor Gamov <viktor@confluent.io>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a1f949fcdac73e16d11fed4001eecac981c758f1", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/a1f949fcdac73e16d11fed4001eecac981c758f1", "committedDate": "2020-04-10T16:38:19Z", "message": "update avro version"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "74688253920fee27c025a48a407d39544a63a357", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/74688253920fee27c025a48a407d39544a63a357", "committedDate": "2020-04-10T16:38:19Z", "message": "updates to get test harness running and tutorial steps to make sense"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4d7fca7a2d9d524ee2e421b76e119710990133ab", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/4d7fca7a2d9d524ee2e421b76e119710990133ab", "committedDate": "2020-04-10T16:38:19Z", "message": "updated test harness to call docker-compose down, remove outputs from source control"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "324b507ae7244da5adc0ae64e7be3a0bb3e43da7", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/324b507ae7244da5adc0ae64e7be3a0bb3e43da7", "committedDate": "2020-04-10T16:38:19Z", "message": "make sure to close streams before shutting down docker"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "91f7a98cfc5abe397f8f191ec5da26f177d70ec5", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/91f7a98cfc5abe397f8f191ec5da26f177d70ec5", "committedDate": "2020-04-10T16:38:19Z", "message": "update stop stream script to use SIGINT vs TERM (the default)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d516deb4079cb30888ec88e139902c69ea105bb0", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/d516deb4079cb30888ec88e139902c69ea105bb0", "committedDate": "2020-04-10T16:38:19Z", "message": "revert changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6719fdf092b42feaec9186588531f16bdf863fb5", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/6719fdf092b42feaec9186588531f16bdf863fb5", "committedDate": "2020-04-10T16:38:19Z", "message": "Apply suggestions from code review\n\nCo-Authored-By: Colin Hicks <colin.hicks@confluent.io>\nCo-Authored-By: Viktor Gamov <viktor@confluent.io>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "075e7af1598e2a75e8af5df40f8c75a435ac8db9", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/075e7af1598e2a75e8af5df40f8c75a435ac8db9", "committedDate": "2020-04-10T16:38:19Z", "message": "updates for adding topology images and links to full topology images"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4d8039af4c2b82c3aad17d7978198b89cb5e8678", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/4d8039af4c2b82c3aad17d7978198b89cb5e8678", "committedDate": "2020-04-10T16:38:19Z", "message": "Adding command to kill gradle"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "bc4846cb37884680609e6cf0d4b17e862a56d9f7", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/bc4846cb37884680609e6cf0d4b17e862a56d9f7", "committedDate": "2020-04-10T15:02:37Z", "message": "Adding command to kill gradle"}, "afterCommit": {"oid": "4d8039af4c2b82c3aad17d7978198b89cb5e8678", "author": {"user": {"login": "bbejeck", "name": "Bill Bejeck"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/4d8039af4c2b82c3aad17d7978198b89cb5e8678", "committedDate": "2020-04-10T16:38:19Z", "message": "Adding command to kill gradle"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 305, "cost": 1, "resetAt": "2021-11-01T13:07:16Z"}}}