{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkzNjg2NzI2", "number": 304, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxNDozNjowNFrODstAPA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxNDo1Mzo1NlrODstiXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4MjAxMjc2OnYy", "diffSide": "RIGHT", "path": "_data/harnesses/connect-add-key-to-source/kafka.yml", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxNDozNjowNFrOF9s2gQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxMToyMjoyNFrOF-RBzg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDI0MjMwNQ==", "bodyText": "This series of steps relies on waiting for the containers behind the scenes. However, in the tutorial text it's not clear that waiting is necessary.\nFor example if the Create the connector step is executed too quickly, the command returns curl: (52) Empty reply from server. And querying the status returns {\"error_code\":404,\"message\":\"No status found for connector jdbc_source_postgres_01\"}.\nIn the text, I think it would be good to suggest re-running the Create the connector step in this case.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/304#discussion_r400242305", "createdAt": "2020-03-30T14:36:04Z", "author": {"login": "colinhicks"}, "path": "_data/harnesses/connect-add-key-to-source/kafka.yml", "diffHunk": "@@ -0,0 +1,83 @@\n+dev:\n+  steps:\n+    - title: Initialize the project\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/init.sh\n+          render:\n+            file: tutorials/connect-add-key-to-source/kafka/markup/dev/init.adoc\n+            \n+    - title: Prepare the source data\n+      content:\n+        - change_directory: connect-add-key-to-source\n+          action: make_file\n+          file: cities.sql\n+          render:\n+            file: tutorials/connect-add-key-to-source/kafka/markup/dev/make-sql-commandfile.adoc\n+\n+    - title: Get Confluent Platform\n+      content:\n+        - action: make_file\n+          file: docker-compose.yml\n+          render:\n+            file: tutorials/connect-add-key-to-source/kafka/markup/dev/make-docker-compose.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            file: tutorials/connect-add-key-to-source/kafka/markup/dev/start-compose.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            skip: true\n+            \n+    - title: Check the source data\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/query-postgres.sh\n+          stdout: tutorial-steps/dev/outputs/query-postgres.log\n+          render:\n+            file: tutorials/connect-add-key-to-source/kafka/markup/dev/query-postgres.adoc\n+\n+    - title: Create the connector\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/create-connector.sh\n+          stdout: tutorial-steps/dev/outputs/create-connector.log\n+          render:\n+            file: tutorials/connect-add-key-to-source/kafka/markup/dev/create-connector.adoc\n+\n+        - name: give Kafka Connect chance to create the connector\n+          action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+\n+        - action: execute\n+          file: tutorial-steps/dev/check-connector.sh\n+          stdout: tutorial-steps/dev/outputs/check-connector.log\n+          render:\n+            file: tutorials/connect-add-key-to-source/kafka/markup/dev/check-connector.adoc\n+\n+        - name: give Kafka Connect further chance to get the data to the topic\n+          action: sleep\n+          ms: 5000\n+          render:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a68109abc1751064f484184c7aa30ff36815ec3b"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgzNTAyMg==", "bodyText": "Thanks. Done.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/304#discussion_r400835022", "createdAt": "2020-03-31T11:22:24Z", "author": {"login": "rmoff"}, "path": "_data/harnesses/connect-add-key-to-source/kafka.yml", "diffHunk": "@@ -0,0 +1,83 @@\n+dev:\n+  steps:\n+    - title: Initialize the project\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/init.sh\n+          render:\n+            file: tutorials/connect-add-key-to-source/kafka/markup/dev/init.adoc\n+            \n+    - title: Prepare the source data\n+      content:\n+        - change_directory: connect-add-key-to-source\n+          action: make_file\n+          file: cities.sql\n+          render:\n+            file: tutorials/connect-add-key-to-source/kafka/markup/dev/make-sql-commandfile.adoc\n+\n+    - title: Get Confluent Platform\n+      content:\n+        - action: make_file\n+          file: docker-compose.yml\n+          render:\n+            file: tutorials/connect-add-key-to-source/kafka/markup/dev/make-docker-compose.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            file: tutorials/connect-add-key-to-source/kafka/markup/dev/start-compose.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            skip: true\n+            \n+    - title: Check the source data\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/query-postgres.sh\n+          stdout: tutorial-steps/dev/outputs/query-postgres.log\n+          render:\n+            file: tutorials/connect-add-key-to-source/kafka/markup/dev/query-postgres.adoc\n+\n+    - title: Create the connector\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/create-connector.sh\n+          stdout: tutorial-steps/dev/outputs/create-connector.log\n+          render:\n+            file: tutorials/connect-add-key-to-source/kafka/markup/dev/create-connector.adoc\n+\n+        - name: give Kafka Connect chance to create the connector\n+          action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+\n+        - action: execute\n+          file: tutorial-steps/dev/check-connector.sh\n+          stdout: tutorial-steps/dev/outputs/check-connector.log\n+          render:\n+            file: tutorials/connect-add-key-to-source/kafka/markup/dev/check-connector.adoc\n+\n+        - name: give Kafka Connect further chance to get the data to the topic\n+          action: sleep\n+          ms: 5000\n+          render:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDI0MjMwNQ=="}, "originalCommit": {"oid": "a68109abc1751064f484184c7aa30ff36815ec3b"}, "originalPosition": 66}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4MjEwMDE1OnYy", "diffSide": "RIGHT", "path": "_includes/tutorials/connect-add-key-to-source/ksql/code/src/statements.sql", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxNDo1Mzo1NlrOF9ttqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxMzozMDowNVrOF-V3Yg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDI1NjQyNg==", "bodyText": "The statements sent to \"production\" should also include the cities table, too, right?\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            );\n          \n          \n            \n            );\n          \n          \n            \n            \n          \n          \n            \n            CREATE TABLE CITIES (ROWKEY INT KEY) WITH (KAFKA_TOPIC='postgres_cities', VALUE_FORMAT='AVRO');", "url": "https://github.com/confluentinc/kafka-tutorials/pull/304#discussion_r400256426", "createdAt": "2020-03-30T14:53:56Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/connect-add-key-to-source/ksql/code/src/statements.sql", "diffHunk": "@@ -0,0 +1,15 @@\n+CREATE SOURCE CONNECTOR JDBC_SOURCE_POSTGRES_01 WITH (\n+    'connector.class'= 'io.confluent.connect.jdbc.JdbcSourceConnector',\n+    'connection.url'= 'jdbc:postgresql://postgres:5432/postgres',\n+    'connection.user'= 'postgres',\n+    'connection.password'= 'postgres',\n+    'mode'= 'incrementing',\n+    'incrementing.column.name'= 'city_id',\n+    'topic.prefix'= 'postgres_',\n+    'transforms'= 'copyFieldToKey,extractValuefromStruct',\n+    'transforms.copyFieldToKey.type'= 'org.apache.kafka.connect.transforms.ValueToKey',\n+    'transforms.copyFieldToKey.fields'= 'city_id',\n+    'transforms.extractValuefromStruct.type'= 'org.apache.kafka.connect.transforms.ExtractField$Key',\n+    'transforms.extractValuefromStruct.field'= 'city_id',\n+    'key.converter' = 'org.apache.kafka.connect.converters.IntegerConverter'\n+);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a68109abc1751064f484184c7aa30ff36815ec3b"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgzNTM4Ng==", "bodyText": "Debatable - the tutorial is about adding a key to ingested data, and the production step does just that. Happy to add the table declaration in though if you'd prefer?", "url": "https://github.com/confluentinc/kafka-tutorials/pull/304#discussion_r400835386", "createdAt": "2020-03-31T11:23:07Z", "author": {"login": "rmoff"}, "path": "_includes/tutorials/connect-add-key-to-source/ksql/code/src/statements.sql", "diffHunk": "@@ -0,0 +1,15 @@\n+CREATE SOURCE CONNECTOR JDBC_SOURCE_POSTGRES_01 WITH (\n+    'connector.class'= 'io.confluent.connect.jdbc.JdbcSourceConnector',\n+    'connection.url'= 'jdbc:postgresql://postgres:5432/postgres',\n+    'connection.user'= 'postgres',\n+    'connection.password'= 'postgres',\n+    'mode'= 'incrementing',\n+    'incrementing.column.name'= 'city_id',\n+    'topic.prefix'= 'postgres_',\n+    'transforms'= 'copyFieldToKey,extractValuefromStruct',\n+    'transforms.copyFieldToKey.type'= 'org.apache.kafka.connect.transforms.ValueToKey',\n+    'transforms.copyFieldToKey.fields'= 'city_id',\n+    'transforms.extractValuefromStruct.type'= 'org.apache.kafka.connect.transforms.ExtractField$Key',\n+    'transforms.extractValuefromStruct.field'= 'city_id',\n+    'key.converter' = 'org.apache.kafka.connect.converters.IntegerConverter'\n+);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDI1NjQyNg=="}, "originalCommit": {"oid": "a68109abc1751064f484184c7aa30ff36815ec3b"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkxNDI3NA==", "bodyText": "Yeah, as-is, it does what it says on the tin. I'm fine with leaving out the create table statement.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/304#discussion_r400914274", "createdAt": "2020-03-31T13:30:05Z", "author": {"login": "colinhicks"}, "path": "_includes/tutorials/connect-add-key-to-source/ksql/code/src/statements.sql", "diffHunk": "@@ -0,0 +1,15 @@\n+CREATE SOURCE CONNECTOR JDBC_SOURCE_POSTGRES_01 WITH (\n+    'connector.class'= 'io.confluent.connect.jdbc.JdbcSourceConnector',\n+    'connection.url'= 'jdbc:postgresql://postgres:5432/postgres',\n+    'connection.user'= 'postgres',\n+    'connection.password'= 'postgres',\n+    'mode'= 'incrementing',\n+    'incrementing.column.name'= 'city_id',\n+    'topic.prefix'= 'postgres_',\n+    'transforms'= 'copyFieldToKey,extractValuefromStruct',\n+    'transforms.copyFieldToKey.type'= 'org.apache.kafka.connect.transforms.ValueToKey',\n+    'transforms.copyFieldToKey.fields'= 'city_id',\n+    'transforms.extractValuefromStruct.type'= 'org.apache.kafka.connect.transforms.ExtractField$Key',\n+    'transforms.extractValuefromStruct.field'= 'city_id',\n+    'key.converter' = 'org.apache.kafka.connect.converters.IntegerConverter'\n+);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDI1NjQyNg=="}, "originalCommit": {"oid": "a68109abc1751064f484184c7aa30ff36815ec3b"}, "originalPosition": 15}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4078, "cost": 1, "resetAt": "2021-11-12T19:05:54Z"}}}