{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMyNzYzNjM2", "number": 438, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQyMToyNToyMFrOEUNZjw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQyMTo1MToyMVrOEUNuhw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NjI2NTExOnYy", "diffSide": "RIGHT", "path": "_includes/tutorials/streams-to-table/kstreams/code/docker-compose.yml", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQyMToyNToyMFrOG6XZdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQyMjo0MDoxNVrOG6YsKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzg1Mzk0MA==", "bodyText": "qq: I thought we should use cp-kafka or cp-confluent-server because cp-enterprise-kafka will be deprecated", "url": "https://github.com/confluentinc/kafka-tutorials/pull/438#discussion_r463853940", "createdAt": "2020-07-31T21:25:20Z", "author": {"login": "gAmUssA"}, "path": "_includes/tutorials/streams-to-table/kstreams/code/docker-compose.yml", "diffHunk": "@@ -0,0 +1,50 @@\n+---\n+version: '2'\n+\n+services:\n+  zookeeper:\n+    image: confluentinc/cp-zookeeper:5.5.0\n+    hostname: zookeeper\n+    container_name: zookeeper\n+    ports:\n+      - \"2181:2181\"\n+    environment:\n+      ZOOKEEPER_CLIENT_PORT: 2181\n+      ZOOKEEPER_TICK_TIME: 2000\n+\n+  broker:\n+    image: confluentinc/cp-enterprise-kafka:5.5.0", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "119fccf9a44fb71da5e4e10f6f093be0a729568c"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzg3NTExNQ==", "bodyText": "yep, this is a copy/paste error, I'll change it.", "url": "https://github.com/confluentinc/kafka-tutorials/pull/438#discussion_r463875115", "createdAt": "2020-07-31T22:40:15Z", "author": {"login": "bbejeck"}, "path": "_includes/tutorials/streams-to-table/kstreams/code/docker-compose.yml", "diffHunk": "@@ -0,0 +1,50 @@\n+---\n+version: '2'\n+\n+services:\n+  zookeeper:\n+    image: confluentinc/cp-zookeeper:5.5.0\n+    hostname: zookeeper\n+    container_name: zookeeper\n+    ports:\n+      - \"2181:2181\"\n+    environment:\n+      ZOOKEEPER_CLIENT_PORT: 2181\n+      ZOOKEEPER_TICK_TIME: 2000\n+\n+  broker:\n+    image: confluentinc/cp-enterprise-kafka:5.5.0", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzg1Mzk0MA=="}, "originalCommit": {"oid": "119fccf9a44fb71da5e4e10f6f093be0a729568c"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NjMxODc5OnYy", "diffSide": "RIGHT", "path": "_includes/tutorials/streams-to-table/kstreams/code/src/main/java/io/confluent/developer/StreamsToTable.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQyMTo1MToyMVrOG6X5pA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxNjowOTo0NFrOHASeFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzg2MjE4MA==", "bodyText": "shouldn't we avoid leaking test code to production code?", "url": "https://github.com/confluentinc/kafka-tutorials/pull/438#discussion_r463862180", "createdAt": "2020-07-31T21:51:21Z", "author": {"login": "gAmUssA"}, "path": "_includes/tutorials/streams-to-table/kstreams/code/src/main/java/io/confluent/developer/StreamsToTable.java", "diffHunk": "@@ -0,0 +1,132 @@\n+package io.confluent.developer;\n+\n+\n+import io.confluent.common.utils.TestUtils;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import org.apache.kafka.clients.admin.AdminClient;\n+import org.apache.kafka.clients.admin.NewTopic;\n+import org.apache.kafka.common.serialization.Serde;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.kstream.Consumed;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.KTable;\n+import org.apache.kafka.streams.kstream.Materialized;\n+import org.apache.kafka.streams.kstream.Produced;\n+\n+public class StreamsToTable {\n+\n+\n+\tpublic Properties buildStreamsProperties(Properties envProps) {\n+        Properties props = new Properties();\n+\n+        props.put(StreamsConfig.APPLICATION_ID_CONFIG, envProps.getProperty(\"application.id\"));\n+        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, envProps.getProperty(\"bootstrap.servers\"));\n+        props.put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "119fccf9a44fb71da5e4e10f6f093be0a729568c"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDA2NDY2MA==", "bodyText": "ack", "url": "https://github.com/confluentinc/kafka-tutorials/pull/438#discussion_r470064660", "createdAt": "2020-08-13T16:09:44Z", "author": {"login": "bbejeck"}, "path": "_includes/tutorials/streams-to-table/kstreams/code/src/main/java/io/confluent/developer/StreamsToTable.java", "diffHunk": "@@ -0,0 +1,132 @@\n+package io.confluent.developer;\n+\n+\n+import io.confluent.common.utils.TestUtils;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import org.apache.kafka.clients.admin.AdminClient;\n+import org.apache.kafka.clients.admin.NewTopic;\n+import org.apache.kafka.common.serialization.Serde;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.kstream.Consumed;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.KTable;\n+import org.apache.kafka.streams.kstream.Materialized;\n+import org.apache.kafka.streams.kstream.Produced;\n+\n+public class StreamsToTable {\n+\n+\n+\tpublic Properties buildStreamsProperties(Properties envProps) {\n+        Properties props = new Properties();\n+\n+        props.put(StreamsConfig.APPLICATION_ID_CONFIG, envProps.getProperty(\"application.id\"));\n+        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, envProps.getProperty(\"bootstrap.servers\"));\n+        props.put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzg2MjE4MA=="}, "originalCommit": {"oid": "119fccf9a44fb71da5e4e10f6f093be0a729568c"}, "originalPosition": 36}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3915, "cost": 1, "resetAt": "2021-11-12T19:05:54Z"}}}