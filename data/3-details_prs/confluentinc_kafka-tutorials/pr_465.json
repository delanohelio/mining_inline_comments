{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ0OTM4MDA0", "number": 465, "title": "Add new KT for kafka-connect-datagen (local)", "bodyText": "This PR addresses #464\ncc: @bbejeck @rspurgeon", "createdAt": "2020-07-06T18:35:13Z", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465", "merged": true, "mergeCommit": {"oid": "d47a52b6747a1f34084320262d2197e89b6ff8e8"}, "closed": true, "closedAt": "2020-07-21T01:16:53Z", "author": {"login": "ybyzek"}, "timelineItems": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcyTxL8gH2gAyNDQ0OTM4MDA0OjE2OTQ2NDI5ZWE1MmM0ZTE4ODBiY2YxZGZlZmU0MmEzYWZhZTk2ZmM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc27wIlAFqTQ1MjA2MDEwOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "16946429ea52c4e1880bcf1dfefe42a3afae96fc", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/16946429ea52c4e1880bcf1dfefe42a3afae96fc", "committedDate": "2020-07-06T16:24:13Z", "message": "GH-464: groundwork for #464 kafka-connect-datagen for local Kafka topics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a3aa94404cbddfd97641a2522fee0601790821a9", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/a3aa94404cbddfd97641a2522fee0601790821a9", "committedDate": "2020-07-06T17:26:09Z", "message": "Clean up consumer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dcb4558dc6bb525e876e4f866db93385cd247048", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/dcb4558dc6bb525e876e4f866db93385cd247048", "committedDate": "2020-07-06T18:19:36Z", "message": "Pass local build"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c8823713ac0fd002c100b12cb76f28c41ac2ecd2", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/c8823713ac0fd002c100b12cb76f28c41ac2ecd2", "committedDate": "2020-07-06T18:24:49Z", "message": "Rename self-managed to local"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "09d222ec1324837a821bafa82de40fd1537159cc", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/09d222ec1324837a821bafa82de40fd1537159cc", "committedDate": "2020-07-06T18:33:37Z", "message": "Add cleanup to prod"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQzOTIxNDA0", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465#pullrequestreview-443921404", "createdAt": "2020-07-07T14:02:11Z", "commit": {"oid": "09d222ec1324837a821bafa82de40fd1537159cc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxNDowMjoxMVrOGuAByQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxNDowMjoxMVrOGuAByQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDg4ODEzNw==", "bodyText": "Would a link to the datagen repository work here?", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465#discussion_r450888137", "createdAt": "2020-07-07T14:02:11Z", "author": {"login": "rspurgeon"}, "path": "_data/tutorials.yaml", "diffHunk": "@@ -302,3 +302,14 @@ console-consumer-read-specific-offsets-partition:\n     ksql: disabled\n     kstreams: disabled\n     kafka: enabled\n+\n+kafka-connect-datagen-local:\n+  title: \"How to generate mock data to a local Kafka topic using the Kafka Connect Datagen\"\n+  meta-description: \"How to generate mock data to a local Kafka topic using the Kafka Connect Datagen\"\n+  slug: \"/kafka-connect-datagen-local\"\n+  problem: \"you want to test your Kafka applications but need mock data produced to Kafka topics.\"\n+  introduction: \"You will run a local instance of the kafka-connect-datagen connector to produce mock data to a local Kafka cluster\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "09d222ec1324837a821bafa82de40fd1537159cc"}, "originalPosition": 10}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQzOTMxMzkw", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465#pullrequestreview-443931390", "createdAt": "2020-07-07T14:12:35Z", "commit": {"oid": "09d222ec1324837a821bafa82de40fd1537159cc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxNDoxMjozNlrOGuAffg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxNDoxMjozNlrOGuAffg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDg5NTc0Mg==", "bodyText": "FYC Use an explicit version to prevent any unexpected compatibility issues down the line for users", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465#discussion_r450895742", "createdAt": "2020-07-07T14:12:36Z", "author": {"login": "rspurgeon"}, "path": "_includes/tutorials/kafka-connect-datagen-local/kafka/code/Dockerfile", "diffHunk": "@@ -0,0 +1,5 @@\n+FROM confluentinc/cp-kafka-connect-base:5.5.1\n+\n+ENV CONNECT_PLUGIN_PATH=\"/usr/share/java,/usr/share/confluent-hub-components\"\n+\n+RUN confluent-hub install --no-prompt confluentinc/kafka-connect-datagen:latest", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "09d222ec1324837a821bafa82de40fd1537159cc"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQzOTMyODEw", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465#pullrequestreview-443932810", "createdAt": "2020-07-07T14:14:04Z", "commit": {"oid": "09d222ec1324837a821bafa82de40fd1537159cc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxNDoxNDowNFrOGuAjew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxNDoxNDowNFrOGuAjew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDg5Njc2Mw==", "bodyText": "We're using cp-kafka-connect-base:5.5.1 for the connector but 5.5.0 for the services.  Is that intentional?", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465#discussion_r450896763", "createdAt": "2020-07-07T14:14:04Z", "author": {"login": "rspurgeon"}, "path": "_includes/tutorials/kafka-connect-datagen-local/kafka/code/docker-compose.yml", "diffHunk": "@@ -0,0 +1,71 @@\n+---\n+version: '2'\n+\n+services:\n+  zookeeper:\n+    image: confluentinc/cp-zookeeper:5.5.0", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "09d222ec1324837a821bafa82de40fd1537159cc"}, "originalPosition": 6}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQzOTM3ODgw", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465#pullrequestreview-443937880", "createdAt": "2020-07-07T14:19:03Z", "commit": {"oid": "09d222ec1324837a821bafa82de40fd1537159cc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxNDoxOTowNFrOGuAyrw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxNDoxOTowNFrOGuAyrw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDkwMDY1NQ==", "bodyText": "Is it possible to leave the prod steps out entirely as they aren't relevant for this tutorial?   The Cleanup Docker step seems like a \"Dev\" step IMO", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465#discussion_r450900655", "createdAt": "2020-07-07T14:19:04Z", "author": {"login": "rspurgeon"}, "path": "_data/harnesses/kafka-connect-datagen-local/kafka.yml", "diffHunk": "@@ -0,0 +1,79 @@\n+dev:\n+  steps:\n+    - title: Initialize the project\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/init.sh\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/init.adoc\n+\n+    - title: Get Confluent Platform\n+      content:\n+        - action: make_file\n+          file: Dockerfile\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/make-dockerfile.adoc\n+\n+        - action: make_file\n+          file: docker-compose.yml\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/make-docker-compose.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/start-compose.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            skip: true\n+            \n+    - title: Create the connector\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/create-connector.sh\n+          stdout: tutorial-steps/dev/outputs/create-connector.log\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/create-connector.adoc\n+\n+        - name: give Kafka Connect chance to create the connector\n+          action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+\n+        - action: execute\n+          file: tutorial-steps/dev/check-connector.sh\n+          stdout: tutorial-steps/dev/outputs/check-connector.log\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/check-connector.adoc\n+\n+        - name: give Kafka Connect further chance to get the data to the topic\n+          action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+\n+    - title: Consume events from the Kafka topic\n+      content:\n+      - action: execute_async\n+        file: tutorial-steps/dev/harness-console-consumer-keys.sh\n+        stdout: tutorial-steps/dev/outputs/consume-topic.log\n+        render:\n+          file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/consume-topic-key-value.adoc\n+\n+      - name: wait for consumer to read records\n+        action: sleep\n+        ms: 10000\n+        render:\n+          skip: true\n+\n+prod:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "09d222ec1324837a821bafa82de40fd1537159cc"}, "originalPosition": 72}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQzOTQ3MTg5", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465#pullrequestreview-443947189", "createdAt": "2020-07-07T14:28:22Z", "commit": {"oid": "09d222ec1324837a821bafa82de40fd1537159cc"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0e5485221c5687ca64ae1b5a1f1ea827ef607e21", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/0e5485221c5687ca64ae1b5a1f1ea827ef607e21", "committedDate": "2020-07-07T14:31:50Z", "message": "Feedback from Rick"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUxOTc4NTE0", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465#pullrequestreview-451978514", "createdAt": "2020-07-20T21:39:41Z", "commit": {"oid": "0e5485221c5687ca64ae1b5a1f1ea827ef607e21"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQyMTozOTo0MlrOG0gOOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQyMTo0NTo1NFrOG0gY2w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcwNzA2NQ==", "bodyText": "The clean-up step isn't displayed when running through the tutorial.  The skip: true part needs to be replaced with file: <path>\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        skip: true\n          \n          \n            \n                        tutorials/kafka-connect-datagen-local/kafka/markup/dev/clean-up.adoc", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465#discussion_r457707065", "createdAt": "2020-07-20T21:39:42Z", "author": {"login": "bbejeck"}, "path": "_data/harnesses/kafka-connect-datagen-local/kafka.yml", "diffHunk": "@@ -0,0 +1,79 @@\n+dev:\n+  steps:\n+    - title: Initialize the project\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/init.sh\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/init.adoc\n+\n+    - title: Get Confluent Platform\n+      content:\n+        - action: make_file\n+          file: Dockerfile\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/make-dockerfile.adoc\n+\n+        - action: make_file\n+          file: docker-compose.yml\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/make-docker-compose.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/start-compose.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            skip: true\n+            \n+    - title: Create the connector\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/create-connector.sh\n+          stdout: tutorial-steps/dev/outputs/create-connector.log\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/create-connector.adoc\n+\n+        - name: give Kafka Connect chance to create the connector\n+          action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+\n+        - action: execute\n+          file: tutorial-steps/dev/check-connector.sh\n+          stdout: tutorial-steps/dev/outputs/check-connector.log\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/check-connector.adoc\n+\n+        - name: give Kafka Connect further chance to get the data to the topic\n+          action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+\n+    - title: Consume events from the Kafka topic\n+      content:\n+      - action: execute_async\n+        file: tutorial-steps/dev/harness-console-consumer-keys.sh\n+        stdout: tutorial-steps/dev/outputs/consume-topic.log\n+        render:\n+          file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/consume-topic-key-value.adoc\n+\n+      - name: wait for consumer to read records\n+        action: sleep\n+        ms: 10000\n+        render:\n+          skip: true\n+\n+prod:\n+  steps:\n+    - title: Cleanup Docker containers\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/clean-up.sh\n+          render:\n+            skip: true", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0e5485221c5687ca64ae1b5a1f1ea827ef607e21"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcwOTc4Nw==", "bodyText": "FYC add a quick note to clean-up.adoc that the prod step is only for clean-up.  Or maybe we can find a way to have some sort of flag to set that is skipped when running make SEQUENCE=\"dev, test\"", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465#discussion_r457709787", "createdAt": "2020-07-20T21:45:54Z", "author": {"login": "bbejeck"}, "path": "_data/harnesses/kafka-connect-datagen-local/kafka.yml", "diffHunk": "@@ -0,0 +1,79 @@\n+dev:\n+  steps:\n+    - title: Initialize the project\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/init.sh\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/init.adoc\n+\n+    - title: Get Confluent Platform\n+      content:\n+        - action: make_file\n+          file: Dockerfile\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/make-dockerfile.adoc\n+\n+        - action: make_file\n+          file: docker-compose.yml\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/make-docker-compose.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/start-compose.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            skip: true\n+            \n+    - title: Create the connector\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/create-connector.sh\n+          stdout: tutorial-steps/dev/outputs/create-connector.log\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/create-connector.adoc\n+\n+        - name: give Kafka Connect chance to create the connector\n+          action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+\n+        - action: execute\n+          file: tutorial-steps/dev/check-connector.sh\n+          stdout: tutorial-steps/dev/outputs/check-connector.log\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/check-connector.adoc\n+\n+        - name: give Kafka Connect further chance to get the data to the topic\n+          action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+\n+    - title: Consume events from the Kafka topic\n+      content:\n+      - action: execute_async\n+        file: tutorial-steps/dev/harness-console-consumer-keys.sh\n+        stdout: tutorial-steps/dev/outputs/consume-topic.log\n+        render:\n+          file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/consume-topic-key-value.adoc\n+\n+      - name: wait for consumer to read records\n+        action: sleep\n+        ms: 10000\n+        render:\n+          skip: true\n+\n+prod:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDkwMDY1NQ=="}, "originalCommit": {"oid": "09d222ec1324837a821bafa82de40fd1537159cc"}, "originalPosition": 72}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "93676502b18619d12a9867cb8e8717ad30834a40", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/93676502b18619d12a9867cb8e8717ad30834a40", "committedDate": "2020-07-20T22:08:16Z", "message": "Render cleanup step in prod"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c17258a0d044e9a60a7d577b561fb8ca253c62e8", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/c17258a0d044e9a60a7d577b561fb8ca253c62e8", "committedDate": "2020-07-20T22:10:57Z", "message": "Add note to clean-up.adoc"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "04dd82d2a215813dc648d97ffc3fa815997413e3", "author": {"user": {"login": "ybyzek", "name": "Yeva Byzek"}}, "url": "https://github.com/confluentinc/kafka-tutorials/commit/04dd82d2a215813dc648d97ffc3fa815997413e3", "committedDate": "2020-07-21T00:23:08Z", "message": "Add Kafka Test Connect Datagen Local to semaphore.yml"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyMDYwMTA4", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465#pullrequestreview-452060108", "createdAt": "2020-07-21T01:14:58Z", "commit": {"oid": "04dd82d2a215813dc648d97ffc3fa815997413e3"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 194, "cost": 1, "resetAt": "2021-11-01T13:07:16Z"}}}