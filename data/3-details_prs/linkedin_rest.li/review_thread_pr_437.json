{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk3MjQyNzk5", "number": 437, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wM1QxNTo0Njo0M1rOEqBl6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNFQyMjo0NDowM1rOEqINwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNTAxNzM3OnYy", "diffSide": "RIGHT", "path": "build.gradle", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wM1QxNTo0Njo0M1rOHcCOOA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNFQwODowMzoyOVrOHcF13w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTE1ODU4NA==", "bodyText": "We haven't traditionally cared about this, but can we copy the HashedMap implementation from Apache Commons if we need it? This is a 500 KB artifact that will be forced on consumers since pegasus:data is pulled in by anything that uses pegasus.", "url": "https://github.com/linkedin/rest.li/pull/437#discussion_r499158584", "createdAt": "2020-10-03T15:46:43Z", "author": {"login": "tjni"}, "path": "build.gradle", "diffHunk": "@@ -52,6 +52,7 @@ project.ext.externalDependency = [\n   'codemodel': 'com.sun.codemodel:codemodel:2.2',\n   'commonsCli': 'commons-cli:commons-cli:1.0',\n   'commonsCodec': 'commons-codec:commons-codec:1.3',\n+  'commonsCollections4': 'org.apache.commons:commons-collections4:4.0',", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "89f85d43420ad2254928f9cb8a075f371b14f13f"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTIxNzg4Nw==", "bodyText": "Fixed", "url": "https://github.com/linkedin/rest.li/pull/437#discussion_r499217887", "createdAt": "2020-10-04T08:03:29Z", "author": {"login": "karthikrg"}, "path": "build.gradle", "diffHunk": "@@ -52,6 +52,7 @@ project.ext.externalDependency = [\n   'codemodel': 'com.sun.codemodel:codemodel:2.2',\n   'commonsCli': 'commons-cli:commons-cli:1.0',\n   'commonsCodec': 'commons-codec:commons-codec:1.3',\n+  'commonsCollections4': 'org.apache.commons:commons-collections4:4.0',", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTE1ODU4NA=="}, "originalCommit": {"oid": "89f85d43420ad2254928f9cb8a075f371b14f13f"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNjA0NzMxOnYy", "diffSide": "RIGHT", "path": "data/src/main/java/com/linkedin/data/DataComplexIdentitySet.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNFQyMToxNTowOFrOHcKN8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNFQyMjo0NjoxOFrOHcKqaw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTI4OTU4Nw==", "bodyText": "Should be _table[index] = node.next", "url": "https://github.com/linkedin/rest.li/pull/437#discussion_r499289587", "createdAt": "2020-10-04T21:15:08Z", "author": {"login": "karthikbalasub"}, "path": "data/src/main/java/com/linkedin/data/DataComplexIdentitySet.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+   Copyright (c) 2020 LinkedIn Corp.\n+\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\n+   you may not use this file except in compliance with the License.\n+   You may obtain a copy of the License at\n+\n+       http://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing, software\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+   See the License for the specific language governing permissions and\n+   limitations under the License.\n+*/\n+\n+package com.linkedin.data;\n+\n+import java.util.IdentityHashMap;\n+\n+\n+/**\n+ * A space and time efficient {@link IdentityHashMap} equivalent optimized forr checking {@link DataComplex} by\n+ * identity. We don't use {@link IdentityHashMap} as-is since {@link System#identityHashCode(Object)} performs\n+ * significantly worse than {@link DataComplex#dataComplexHashCode()} under multi-threaded conditions.\n+ *\n+ * <p>Instances of this class are typically used for cycle detection.</p>\n+ */\n+class DataComplexIdentitySet\n+{\n+  private static final int CAPACITY = 16;\n+\n+  private final Node[] _table;\n+\n+  /**\n+   * Constructor.\n+   */\n+  DataComplexIdentitySet()\n+  {\n+    _table = new Node[CAPACITY];\n+  }\n+\n+  /**\n+   * Add the given {@link DataComplex} to the set.\n+   *\n+   * @param dataComplex The {@link DataComplex} to add.\n+   *\n+   * @return True if the {@link DataComplex} was already present and not added, false otherwise.\n+   */\n+  boolean add(DataComplex dataComplex)\n+  {\n+    final int index = dataComplex.dataComplexHashCode() & (CAPACITY - 1);\n+    Node node = _table[index];\n+\n+    // No entries in bucket, add and return false.\n+    if (node == null)\n+    {\n+      _table[index] = new Node(dataComplex);\n+      return false;\n+    }\n+\n+    Node previous = null;\n+    while (node != null)\n+    {\n+      if (node._dataComplex == dataComplex)\n+      {\n+        // Entry found, return true and bail!\n+        return true;\n+      }\n+\n+      previous = node;\n+      node = node._next;\n+    }\n+\n+    // No entry found for given data complex. Add it to the end, and return false.\n+    previous._next = new Node(dataComplex);\n+    return false;\n+  }\n+\n+  /**\n+   * Removes the given {@link DataComplex} from the set if it exists.\n+   *\n+   * @param dataComplex The {@link DataComplex} to remove.\n+   */\n+  void remove(DataComplex dataComplex)\n+  {\n+    final int index = dataComplex.dataComplexHashCode() & (CAPACITY - 1);\n+    Node node = _table[index];\n+\n+    // If there is no node at the given index there is nothing to do.\n+    if (node == null)\n+    {\n+      return;\n+    }\n+\n+    Node previous = null;\n+    while (node != null)\n+    {\n+      if (node._dataComplex == dataComplex)\n+      {\n+        // Entry found, remove it.\n+        if (previous == null)\n+        {\n+          // This is the first node, set table index to null.\n+          _table[index] = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71808f5465eaa4f654457a45c88bbb578ec656c7"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTI4OTk1Mw==", "bodyText": "Isn't that the same as setting to null since this is the 1st node?", "url": "https://github.com/linkedin/rest.li/pull/437#discussion_r499289953", "createdAt": "2020-10-04T21:19:40Z", "author": {"login": "karthikrg"}, "path": "data/src/main/java/com/linkedin/data/DataComplexIdentitySet.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+   Copyright (c) 2020 LinkedIn Corp.\n+\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\n+   you may not use this file except in compliance with the License.\n+   You may obtain a copy of the License at\n+\n+       http://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing, software\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+   See the License for the specific language governing permissions and\n+   limitations under the License.\n+*/\n+\n+package com.linkedin.data;\n+\n+import java.util.IdentityHashMap;\n+\n+\n+/**\n+ * A space and time efficient {@link IdentityHashMap} equivalent optimized forr checking {@link DataComplex} by\n+ * identity. We don't use {@link IdentityHashMap} as-is since {@link System#identityHashCode(Object)} performs\n+ * significantly worse than {@link DataComplex#dataComplexHashCode()} under multi-threaded conditions.\n+ *\n+ * <p>Instances of this class are typically used for cycle detection.</p>\n+ */\n+class DataComplexIdentitySet\n+{\n+  private static final int CAPACITY = 16;\n+\n+  private final Node[] _table;\n+\n+  /**\n+   * Constructor.\n+   */\n+  DataComplexIdentitySet()\n+  {\n+    _table = new Node[CAPACITY];\n+  }\n+\n+  /**\n+   * Add the given {@link DataComplex} to the set.\n+   *\n+   * @param dataComplex The {@link DataComplex} to add.\n+   *\n+   * @return True if the {@link DataComplex} was already present and not added, false otherwise.\n+   */\n+  boolean add(DataComplex dataComplex)\n+  {\n+    final int index = dataComplex.dataComplexHashCode() & (CAPACITY - 1);\n+    Node node = _table[index];\n+\n+    // No entries in bucket, add and return false.\n+    if (node == null)\n+    {\n+      _table[index] = new Node(dataComplex);\n+      return false;\n+    }\n+\n+    Node previous = null;\n+    while (node != null)\n+    {\n+      if (node._dataComplex == dataComplex)\n+      {\n+        // Entry found, return true and bail!\n+        return true;\n+      }\n+\n+      previous = node;\n+      node = node._next;\n+    }\n+\n+    // No entry found for given data complex. Add it to the end, and return false.\n+    previous._next = new Node(dataComplex);\n+    return false;\n+  }\n+\n+  /**\n+   * Removes the given {@link DataComplex} from the set if it exists.\n+   *\n+   * @param dataComplex The {@link DataComplex} to remove.\n+   */\n+  void remove(DataComplex dataComplex)\n+  {\n+    final int index = dataComplex.dataComplexHashCode() & (CAPACITY - 1);\n+    Node node = _table[index];\n+\n+    // If there is no node at the given index there is nothing to do.\n+    if (node == null)\n+    {\n+      return;\n+    }\n+\n+    Node previous = null;\n+    while (node != null)\n+    {\n+      if (node._dataComplex == dataComplex)\n+      {\n+        // Entry found, remove it.\n+        if (previous == null)\n+        {\n+          // This is the first node, set table index to null.\n+          _table[index] = null;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTI4OTU4Nw=="}, "originalCommit": {"oid": "71808f5465eaa4f654457a45c88bbb578ec656c7"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTI5Njg3NQ==", "bodyText": "It wouldn't work if the index has more than one element.\n_table[i] = A -> B -> null\nremove A\n_table[i] = null\nit should be\n_table[i] = B -> null", "url": "https://github.com/linkedin/rest.li/pull/437#discussion_r499296875", "createdAt": "2020-10-04T22:46:18Z", "author": {"login": "karthikbalasub"}, "path": "data/src/main/java/com/linkedin/data/DataComplexIdentitySet.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+   Copyright (c) 2020 LinkedIn Corp.\n+\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\n+   you may not use this file except in compliance with the License.\n+   You may obtain a copy of the License at\n+\n+       http://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing, software\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+   See the License for the specific language governing permissions and\n+   limitations under the License.\n+*/\n+\n+package com.linkedin.data;\n+\n+import java.util.IdentityHashMap;\n+\n+\n+/**\n+ * A space and time efficient {@link IdentityHashMap} equivalent optimized forr checking {@link DataComplex} by\n+ * identity. We don't use {@link IdentityHashMap} as-is since {@link System#identityHashCode(Object)} performs\n+ * significantly worse than {@link DataComplex#dataComplexHashCode()} under multi-threaded conditions.\n+ *\n+ * <p>Instances of this class are typically used for cycle detection.</p>\n+ */\n+class DataComplexIdentitySet\n+{\n+  private static final int CAPACITY = 16;\n+\n+  private final Node[] _table;\n+\n+  /**\n+   * Constructor.\n+   */\n+  DataComplexIdentitySet()\n+  {\n+    _table = new Node[CAPACITY];\n+  }\n+\n+  /**\n+   * Add the given {@link DataComplex} to the set.\n+   *\n+   * @param dataComplex The {@link DataComplex} to add.\n+   *\n+   * @return True if the {@link DataComplex} was already present and not added, false otherwise.\n+   */\n+  boolean add(DataComplex dataComplex)\n+  {\n+    final int index = dataComplex.dataComplexHashCode() & (CAPACITY - 1);\n+    Node node = _table[index];\n+\n+    // No entries in bucket, add and return false.\n+    if (node == null)\n+    {\n+      _table[index] = new Node(dataComplex);\n+      return false;\n+    }\n+\n+    Node previous = null;\n+    while (node != null)\n+    {\n+      if (node._dataComplex == dataComplex)\n+      {\n+        // Entry found, return true and bail!\n+        return true;\n+      }\n+\n+      previous = node;\n+      node = node._next;\n+    }\n+\n+    // No entry found for given data complex. Add it to the end, and return false.\n+    previous._next = new Node(dataComplex);\n+    return false;\n+  }\n+\n+  /**\n+   * Removes the given {@link DataComplex} from the set if it exists.\n+   *\n+   * @param dataComplex The {@link DataComplex} to remove.\n+   */\n+  void remove(DataComplex dataComplex)\n+  {\n+    final int index = dataComplex.dataComplexHashCode() & (CAPACITY - 1);\n+    Node node = _table[index];\n+\n+    // If there is no node at the given index there is nothing to do.\n+    if (node == null)\n+    {\n+      return;\n+    }\n+\n+    Node previous = null;\n+    while (node != null)\n+    {\n+      if (node._dataComplex == dataComplex)\n+      {\n+        // Entry found, remove it.\n+        if (previous == null)\n+        {\n+          // This is the first node, set table index to null.\n+          _table[index] = null;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTI4OTU4Nw=="}, "originalCommit": {"oid": "71808f5465eaa4f654457a45c88bbb578ec656c7"}, "originalPosition": 105}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNjA0ODA1OnYy", "diffSide": "RIGHT", "path": "data/src/main/java/com/linkedin/data/DataComplexIdentitySet.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNFQyMToxNjoyMVrOHcKOTQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNFQyMToxNjoyMVrOHcKOTQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTI4OTY3Nw==", "bodyText": "forr -> for", "url": "https://github.com/linkedin/rest.li/pull/437#discussion_r499289677", "createdAt": "2020-10-04T21:16:21Z", "author": {"login": "karthikbalasub"}, "path": "data/src/main/java/com/linkedin/data/DataComplexIdentitySet.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+   Copyright (c) 2020 LinkedIn Corp.\n+\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\n+   you may not use this file except in compliance with the License.\n+   You may obtain a copy of the License at\n+\n+       http://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing, software\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+   See the License for the specific language governing permissions and\n+   limitations under the License.\n+*/\n+\n+package com.linkedin.data;\n+\n+import java.util.IdentityHashMap;\n+\n+\n+/**\n+ * A space and time efficient {@link IdentityHashMap} equivalent optimized forr checking {@link DataComplex} by", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71808f5465eaa4f654457a45c88bbb578ec656c7"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNjA0ODIxOnYy", "diffSide": "RIGHT", "path": "data/src/main/java/com/linkedin/data/DataComplexIdentitySet.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNFQyMToxNjo0MlrOHcKOYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNFQyMTozNDozOVrOHcKUDQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTI4OTY5Nw==", "bodyText": "Please add unittests", "url": "https://github.com/linkedin/rest.li/pull/437#discussion_r499289697", "createdAt": "2020-10-04T21:16:42Z", "author": {"login": "karthikbalasub"}, "path": "data/src/main/java/com/linkedin/data/DataComplexIdentitySet.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+   Copyright (c) 2020 LinkedIn Corp.\n+\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\n+   you may not use this file except in compliance with the License.\n+   You may obtain a copy of the License at\n+\n+       http://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing, software\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+   See the License for the specific language governing permissions and\n+   limitations under the License.\n+*/\n+\n+package com.linkedin.data;\n+\n+import java.util.IdentityHashMap;\n+\n+\n+/**\n+ * A space and time efficient {@link IdentityHashMap} equivalent optimized forr checking {@link DataComplex} by\n+ * identity. We don't use {@link IdentityHashMap} as-is since {@link System#identityHashCode(Object)} performs\n+ * significantly worse than {@link DataComplex#dataComplexHashCode()} under multi-threaded conditions.\n+ *\n+ * <p>Instances of this class are typically used for cycle detection.</p>\n+ */\n+class DataComplexIdentitySet", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71808f5465eaa4f654457a45c88bbb578ec656c7"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTI5MTE0OQ==", "bodyText": "Fixed!", "url": "https://github.com/linkedin/rest.li/pull/437#discussion_r499291149", "createdAt": "2020-10-04T21:34:39Z", "author": {"login": "karthikrg"}, "path": "data/src/main/java/com/linkedin/data/DataComplexIdentitySet.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+   Copyright (c) 2020 LinkedIn Corp.\n+\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\n+   you may not use this file except in compliance with the License.\n+   You may obtain a copy of the License at\n+\n+       http://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing, software\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+   See the License for the specific language governing permissions and\n+   limitations under the License.\n+*/\n+\n+package com.linkedin.data;\n+\n+import java.util.IdentityHashMap;\n+\n+\n+/**\n+ * A space and time efficient {@link IdentityHashMap} equivalent optimized forr checking {@link DataComplex} by\n+ * identity. We don't use {@link IdentityHashMap} as-is since {@link System#identityHashCode(Object)} performs\n+ * significantly worse than {@link DataComplex#dataComplexHashCode()} under multi-threaded conditions.\n+ *\n+ * <p>Instances of this class are typically used for cycle detection.</p>\n+ */\n+class DataComplexIdentitySet", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTI4OTY5Nw=="}, "originalCommit": {"oid": "71808f5465eaa4f654457a45c88bbb578ec656c7"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNjEwMjQxOnYy", "diffSide": "RIGHT", "path": "data/src/test/java/com/linkedin/data/TestDataComplexIdentitySet.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNFQyMjo0NDowM1rOHcKprA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNFQyMzowMzowNFrOHcKvOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTI5NjY4NA==", "bodyText": "Remove dataMap and then add sameHashCodeMap, it should return true, but will return false.", "url": "https://github.com/linkedin/rest.li/pull/437#discussion_r499296684", "createdAt": "2020-10-04T22:44:03Z", "author": {"login": "karthikbalasub"}, "path": "data/src/test/java/com/linkedin/data/TestDataComplexIdentitySet.java", "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+   Copyright (c) 2020 LinkedIn Corp.\n+\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\n+   you may not use this file except in compliance with the License.\n+   You may obtain a copy of the License at\n+\n+       http://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing, software\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+   See the License for the specific language governing permissions and\n+   limitations under the License.\n+ */\n+\n+package com.linkedin.data;\n+\n+import org.testng.Assert;\n+import org.testng.annotations.Test;\n+\n+\n+public class TestDataComplexIdentitySet\n+{\n+  @Test\n+  void testBasicOperations() throws CloneNotSupportedException\n+  {\n+    DataComplexIdentitySet set = new DataComplexIdentitySet();\n+    DataMap dataMap = new DataMap();\n+\n+    // Adding a DataComplex that doesn't exist should return false.\n+    Assert.assertFalse(set.add(dataMap));\n+\n+    // Adding a DataComplex that already exists should return true.\n+    Assert.assertTrue(set.add(dataMap));\n+\n+    DataMap clone = dataMap.clone();\n+\n+    // Adding a clone, ie. equal but not the same instance must return false.\n+    Assert.assertFalse(set.add(clone));\n+\n+    // Remove the original map.\n+    set.remove(dataMap);\n+\n+    // Ensure that the original map got removed by testing that adding it again returns false.\n+    Assert.assertFalse(set.add(dataMap));\n+\n+    // Ensure that the clone still exists in the map by testing that adding it again returns true.\n+    Assert.assertTrue(set.add(clone));\n+\n+    // Create a new map and override its hashcode to be same as the original map.\n+    DataMap sameHashCodeMap = new DataMap();\n+    sameHashCodeMap._dataComplexHashCode = dataMap.dataComplexHashCode();\n+\n+    // Ensure that adding the same hashcode map returns false the first time since it doesn't yet exist.\n+    Assert.assertFalse(set.add(sameHashCodeMap));\n+\n+    // Ensure that adding the same hashcod map again returns true.\n+    Assert.assertTrue(set.add(sameHashCodeMap));\n+\n+    // Ensure that the original and cloned maps still exist.\n+    Assert.assertTrue(set.add(dataMap));\n+    Assert.assertTrue(set.add(clone));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0fc4400aa23f44cfe4023cc7006c040be557cb7"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTI5ODEwNA==", "bodyText": "Got it. Fixed and added this test.", "url": "https://github.com/linkedin/rest.li/pull/437#discussion_r499298104", "createdAt": "2020-10-04T23:03:04Z", "author": {"login": "karthikrg"}, "path": "data/src/test/java/com/linkedin/data/TestDataComplexIdentitySet.java", "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+   Copyright (c) 2020 LinkedIn Corp.\n+\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\n+   you may not use this file except in compliance with the License.\n+   You may obtain a copy of the License at\n+\n+       http://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing, software\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+   See the License for the specific language governing permissions and\n+   limitations under the License.\n+ */\n+\n+package com.linkedin.data;\n+\n+import org.testng.Assert;\n+import org.testng.annotations.Test;\n+\n+\n+public class TestDataComplexIdentitySet\n+{\n+  @Test\n+  void testBasicOperations() throws CloneNotSupportedException\n+  {\n+    DataComplexIdentitySet set = new DataComplexIdentitySet();\n+    DataMap dataMap = new DataMap();\n+\n+    // Adding a DataComplex that doesn't exist should return false.\n+    Assert.assertFalse(set.add(dataMap));\n+\n+    // Adding a DataComplex that already exists should return true.\n+    Assert.assertTrue(set.add(dataMap));\n+\n+    DataMap clone = dataMap.clone();\n+\n+    // Adding a clone, ie. equal but not the same instance must return false.\n+    Assert.assertFalse(set.add(clone));\n+\n+    // Remove the original map.\n+    set.remove(dataMap);\n+\n+    // Ensure that the original map got removed by testing that adding it again returns false.\n+    Assert.assertFalse(set.add(dataMap));\n+\n+    // Ensure that the clone still exists in the map by testing that adding it again returns true.\n+    Assert.assertTrue(set.add(clone));\n+\n+    // Create a new map and override its hashcode to be same as the original map.\n+    DataMap sameHashCodeMap = new DataMap();\n+    sameHashCodeMap._dataComplexHashCode = dataMap.dataComplexHashCode();\n+\n+    // Ensure that adding the same hashcode map returns false the first time since it doesn't yet exist.\n+    Assert.assertFalse(set.add(sameHashCodeMap));\n+\n+    // Ensure that adding the same hashcod map again returns true.\n+    Assert.assertTrue(set.add(sameHashCodeMap));\n+\n+    // Ensure that the original and cloned maps still exist.\n+    Assert.assertTrue(set.add(dataMap));\n+    Assert.assertTrue(set.add(clone));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTI5NjY4NA=="}, "originalCommit": {"oid": "a0fc4400aa23f44cfe4023cc7006c040be557cb7"}, "originalPosition": 63}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 382, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}