{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzc5MjM2NzE0", "number": 185, "title": "AsyncPool Improvements and Fixes", "bodyText": "When a object creation request to the pool is faster than the actual creation itself - the rate limiter queues all the incoming requests and creates the object without considering the fact that the checked out objects would come back to the pool.\nThis change is to make sure that the rate limiter task always check if there is a waiter in the queue or the pool is under the minimum level.", "createdAt": "2020-02-24T21:19:56Z", "url": "https://github.com/linkedin/rest.li/pull/185", "merged": true, "mergeCommit": {"oid": "27a4019c925985f0613c1e61520f1c2bcb30cef2"}, "closed": true, "closedAt": "2020-02-29T01:23:05Z", "author": {"login": "nizarm"}, "timelineItems": {"totalCount": 21, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcH2cEWgBqjMwNzA0OTMwNTY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcI59ZyAH2gAyMzc5MjM2NzE0OjAzNmQzMWJhMDA4NWU1ZWFhYWJkZGQyZDljNjU0MDhjMzgxZGExY2Q=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9dd2252c745dbe1f50034945154ed5de6180e25f", "author": {"user": {"login": "nizarm", "name": "Nizar Mankulangara"}}, "url": "https://github.com/linkedin/rest.li/commit/9dd2252c745dbe1f50034945154ed5de6180e25f", "committedDate": "2020-02-24T21:20:26Z", "message": "Merge branch 'master' into bugfix/asyncpool"}, "afterCommit": {"oid": "f0d1ed5cd84f87f06a8dcc84e9a059038be50971", "author": {"user": {"login": "nizarm", "name": "Nizar Mankulangara"}}, "url": "https://github.com/linkedin/rest.li/commit/f0d1ed5cd84f87f06a8dcc84e9a059038be50971", "committedDate": "2020-02-25T18:02:14Z", "message": "AsyncPool Improvements and Fixes:\n1. Do not submit the object creation request in the rate limiter When there is no waiters for the object and when the pool is above the minimum size. This fix will make sure that only the absolute minimum required objects are created in the pool even when the object creation request rate is higher than the actual object creation rate itself.\n\n2. Currenltly in the chhanel pool, the concurrency control how many parallel channel creation requests are in progress. The netty channel creation returns the channel as soon as the channel is created and before the SSL handshake is completed. This behaviour makes the concurrency settings less efffective.\nFix: Fix the channel pool to return the channl after the ssl handshake (for ssl channels) and make the ssl handshake part of the concurrency\n\n3. When a downstream server is healthy - it will not take so much time for the pool to provide a channel to the waiter. If the waiter is too long in the waiters queue, somethign unhealthy in the downstream and it is always better to fail fast the request.\nFix: A new channel pool level configuration introduced. WaiterTimeout - to fail fast the waiter. These waiters will be re-tried in different downstream due to RetriableException\n\n4. Currently during channel creation - there is no easy way to fine tune the \"connectionTimeout\" and \"sslHandShakeTimeout\". It always use the default values.\nFix: Provide a configuration option to fine tune these to fail fast"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f0d1ed5cd84f87f06a8dcc84e9a059038be50971", "author": {"user": {"login": "nizarm", "name": "Nizar Mankulangara"}}, "url": "https://github.com/linkedin/rest.li/commit/f0d1ed5cd84f87f06a8dcc84e9a059038be50971", "committedDate": "2020-02-25T18:02:14Z", "message": "AsyncPool Improvements and Fixes:\n1. Do not submit the object creation request in the rate limiter When there is no waiters for the object and when the pool is above the minimum size. This fix will make sure that only the absolute minimum required objects are created in the pool even when the object creation request rate is higher than the actual object creation rate itself.\n\n2. Currenltly in the chhanel pool, the concurrency control how many parallel channel creation requests are in progress. The netty channel creation returns the channel as soon as the channel is created and before the SSL handshake is completed. This behaviour makes the concurrency settings less efffective.\nFix: Fix the channel pool to return the channl after the ssl handshake (for ssl channels) and make the ssl handshake part of the concurrency\n\n3. When a downstream server is healthy - it will not take so much time for the pool to provide a channel to the waiter. If the waiter is too long in the waiters queue, somethign unhealthy in the downstream and it is always better to fail fast the request.\nFix: A new channel pool level configuration introduced. WaiterTimeout - to fail fast the waiter. These waiters will be re-tried in different downstream due to RetriableException\n\n4. Currently during channel creation - there is no easy way to fine tune the \"connectionTimeout\" and \"sslHandShakeTimeout\". It always use the default values.\nFix: Provide a configuration option to fine tune these to fail fast"}, "afterCommit": {"oid": "1c6856ecb5453d5166ffa2df74491a70236e2e88", "author": {"user": {"login": "nizarm", "name": "Nizar Mankulangara"}}, "url": "https://github.com/linkedin/rest.li/commit/1c6856ecb5453d5166ffa2df74491a70236e2e88", "committedDate": "2020-02-26T22:55:00Z", "message": "AsyncPool Improvements and Fixes:\n1. Do not submit the object creation request in the rate limiter When there is no waiters for the object and when the pool is above the minimum size. This fix will make sure that only the absolute minimum required objects are created in the pool even when the object creation request rate is higher than the actual object creation rate itself.\n\n2. Currenltly in the chhanel pool, the concurrency control how many parallel channel creation requests are in progress. The netty channel creation returns the channel as soon as the channel is created and before the SSL handshake is completed. This behaviour makes the concurrency settings less efffective.\nFix: Fix the channel pool to return the channl after the ssl handshake (for ssl channels) and make the ssl handshake part of the concurrency\n\n3. When a downstream server is healthy - it will not take so much time for the pool to provide a channel to the waiter. If the waiter is too long in the waiters queue, somethign unhealthy in the downstream and it is always better to fail fast the request.\nFix: A new channel pool level configuration introduced. WaiterTimeout - to fail fast the waiter. These waiters will be re-tried in different downstream due to RetriableException\n\n4. Currently during channel creation - there is no easy way to fine tune the \"connectionTimeout\" and \"sslHandShakeTimeout\". It always use the default values.\nFix: Provide a configuration option to fine tune these to fail fast"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "1c6856ecb5453d5166ffa2df74491a70236e2e88", "author": {"user": {"login": "nizarm", "name": "Nizar Mankulangara"}}, "url": "https://github.com/linkedin/rest.li/commit/1c6856ecb5453d5166ffa2df74491a70236e2e88", "committedDate": "2020-02-26T22:55:00Z", "message": "AsyncPool Improvements and Fixes:\n1. Do not submit the object creation request in the rate limiter When there is no waiters for the object and when the pool is above the minimum size. This fix will make sure that only the absolute minimum required objects are created in the pool even when the object creation request rate is higher than the actual object creation rate itself.\n\n2. Currenltly in the chhanel pool, the concurrency control how many parallel channel creation requests are in progress. The netty channel creation returns the channel as soon as the channel is created and before the SSL handshake is completed. This behaviour makes the concurrency settings less efffective.\nFix: Fix the channel pool to return the channl after the ssl handshake (for ssl channels) and make the ssl handshake part of the concurrency\n\n3. When a downstream server is healthy - it will not take so much time for the pool to provide a channel to the waiter. If the waiter is too long in the waiters queue, somethign unhealthy in the downstream and it is always better to fail fast the request.\nFix: A new channel pool level configuration introduced. WaiterTimeout - to fail fast the waiter. These waiters will be re-tried in different downstream due to RetriableException\n\n4. Currently during channel creation - there is no easy way to fine tune the \"connectionTimeout\" and \"sslHandShakeTimeout\". It always use the default values.\nFix: Provide a configuration option to fine tune these to fail fast"}, "afterCommit": {"oid": "9ffb7476a604e571231c4d9830698470ef153512", "author": {"user": {"login": "nizarm", "name": "Nizar Mankulangara"}}, "url": "https://github.com/linkedin/rest.li/commit/9ffb7476a604e571231c4d9830698470ef153512", "committedDate": "2020-02-26T22:57:47Z", "message": "AsyncPool Improvements and Fixes:\n1. Do not submit the object creation request in the rate limiter When there is no waiters for the object and when the pool is above the minimum size. This fix will make sure that only the absolute minimum required objects are created in the pool even when the object creation request rate is higher than the actual object creation rate itself.\n\n2. Currenltly in the chhanel pool, the concurrency control how many parallel channel creation requests are in progress. The netty channel creation returns the channel as soon as the channel is created and before the SSL handshake is completed. This behaviour makes the concurrency settings less efffective.\nFix: Fix the channel pool to return the channl after the ssl handshake (for ssl channels) and make the ssl handshake part of the concurrency\n\n3. When a downstream server is healthy - it will not take so much time for the pool to provide a channel to the waiter. If the waiter is too long in the waiters queue, somethign unhealthy in the downstream and it is always better to fail fast the request.\nFix: A new channel pool level configuration introduced. WaiterTimeout - to fail fast the waiter. These waiters will be re-tried in different downstream due to RetriableException\n\n4. Currently during channel creation - there is no easy way to fine tune the \"connectionTimeout\" and \"sslHandShakeTimeout\". It always use the default values.\nFix: Provide a configuration option to fine tune these to fail fast"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9ffb7476a604e571231c4d9830698470ef153512", "author": {"user": {"login": "nizarm", "name": "Nizar Mankulangara"}}, "url": "https://github.com/linkedin/rest.li/commit/9ffb7476a604e571231c4d9830698470ef153512", "committedDate": "2020-02-26T22:57:47Z", "message": "AsyncPool Improvements and Fixes:\n1. Do not submit the object creation request in the rate limiter When there is no waiters for the object and when the pool is above the minimum size. This fix will make sure that only the absolute minimum required objects are created in the pool even when the object creation request rate is higher than the actual object creation rate itself.\n\n2. Currenltly in the chhanel pool, the concurrency control how many parallel channel creation requests are in progress. The netty channel creation returns the channel as soon as the channel is created and before the SSL handshake is completed. This behaviour makes the concurrency settings less efffective.\nFix: Fix the channel pool to return the channl after the ssl handshake (for ssl channels) and make the ssl handshake part of the concurrency\n\n3. When a downstream server is healthy - it will not take so much time for the pool to provide a channel to the waiter. If the waiter is too long in the waiters queue, somethign unhealthy in the downstream and it is always better to fail fast the request.\nFix: A new channel pool level configuration introduced. WaiterTimeout - to fail fast the waiter. These waiters will be re-tried in different downstream due to RetriableException\n\n4. Currently during channel creation - there is no easy way to fine tune the \"connectionTimeout\" and \"sslHandShakeTimeout\". It always use the default values.\nFix: Provide a configuration option to fine tune these to fail fast"}, "afterCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "author": {"user": {"login": "nizarm", "name": "Nizar Mankulangara"}}, "url": "https://github.com/linkedin/rest.li/commit/4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "committedDate": "2020-02-26T22:59:11Z", "message": "AsyncPool Improvements and Fixes:\n1. Do not submit the object creation request in the rate limiter When there is no waiters for the object and when the pool is above the minimum size. This fix will make sure that only the absolute minimum required objects are created in the pool even when the object creation request rate is higher than the actual object creation rate itself.\n\n2. Currenltly in the chhanel pool, the concurrency control how many parallel channel creation requests are in progress. The netty channel creation returns the channel as soon as the channel is created and before the SSL handshake is completed. This behaviour makes the concurrency settings less efffective.\nFix: Fix the channel pool to return the channl after the ssl handshake (for ssl channels) and make the ssl handshake part of the concurrency\n\n3. When a downstream server is healthy - it will not take so much time for the pool to provide a channel to the waiter. If the waiter is too long in the waiters queue, somethign unhealthy in the downstream and it is always better to fail fast the request.\nFix: A new channel pool level configuration introduced. WaiterTimeout - to fail fast the waiter. These waiters will be re-tried in different downstream due to RetriableException\n\n4. Currently during channel creation - there is no easy way to fine tune the \"connectionTimeout\" and \"sslHandShakeTimeout\". It always use the default values.\nFix: Provide a configuration option to fine tune these to fail fast"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1Mzc5OTYz", "url": "https://github.com/linkedin/rest.li/pull/185#pullrequestreview-365379963", "createdAt": "2020-02-27T02:35:31Z", "commit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QwMjozNTozMVrOFvDaVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QwMjozNTozMVrOFvDaVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg4MzI4NQ==", "bodyText": "CHANNELPOOL_SSL_CALLBACK_HANDLER?", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384883285", "createdAt": "2020-02-27T02:35:31Z", "author": {"login": "FreCap"}, "path": "r2-netty/src/main/java/com/linkedin/r2/transport/http/client/common/ChannelPoolLifecycle.java", "diffHunk": "@@ -86,33 +92,56 @@ public ChannelPoolLifecycle(SocketAddress address, Bootstrap bootstrap, ChannelG\n   public void create(final Callback<Channel> channelCallback)\n   {\n     _bootstrap.connect(_remoteAddress).addListener((ChannelFutureListener) channelFuture -> {\n-      if (channelFuture.isSuccess())\n+      if (!channelFuture.isSuccess())\n+      {\n+        onError(channelCallback, channelFuture);\n+        return;\n+      }\n+\n+      Channel c = channelFuture.channel();\n+      c.attr(CHANNEL_CREATION_TIME_KEY).set(_clock.currentTimeMillis());\n+\n+      if (_tcpNoDelay)\n+      {\n+        c.config().setOption(ChannelOption.TCP_NODELAY, true);\n+      }\n+      _channelGroup.add(c);\n+\n+      if (c.pipeline().get(SslHandlerUtil.PIPELINE_SSL_HANDLER) == null)\n       {\n-        Channel c = channelFuture.channel();\n-        c.attr(CHANNEL_CREATION_TIME_KEY).set(_clock.currentTimeMillis());\n-        if (_tcpNoDelay)\n-        {\n-          c.config().setOption(ChannelOption.TCP_NODELAY, true);\n-        }\n-        _channelGroup.add(c);\n         channelCallback.onSuccess(c);\n+        return;\n       }\n-      else\n+\n+      c.pipeline().addAfter(SslHandlerUtil.PIPELINE_SSL_HANDLER, CHANNELPOOL_CALLBACK_HANDLER, new ChannelDuplexHandler()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 65}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1MzgxOTgy", "url": "https://github.com/linkedin/rest.li/pull/185#pullrequestreview-365381982", "createdAt": "2020-02-27T02:42:59Z", "commit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 26, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QwMjo0Mjo1OVrOFvDheg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QwMzo1Njo0NlrOFvEgxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg4NTExNA==", "bodyText": "sslSessionTimeout -> sslHandshakeTimeout?", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384885114", "createdAt": "2020-02-27T02:42:59Z", "author": {"login": "FreCap"}, "path": "r2-netty/src/main/java/com/linkedin/r2/transport/http/client/rest/HttpNettyChannelPoolFactory.java", "diffHunk": "@@ -54,19 +55,24 @@\n   private final ChannelGroup _allChannels;\n   private final ScheduledExecutorService _scheduler;\n   private final int _maxConcurrentConnectionInitializations;\n+  private final int _channelPoolWaiterTimeout;\n \n   public HttpNettyChannelPoolFactory(int maxPoolSize, long idleTimeout, int maxPoolWaiterSize, AsyncPoolImpl.Strategy strategy,\n                                      int minPoolSize, EventLoopGroup eventLoopGroup, SSLContext sslContext, SSLParameters sslParameters, int maxHeaderSize,\n                                      int maxChunkSize, int maxResponseSize, ScheduledExecutorService scheduler, int maxConcurrentConnectionInitializations,\n-                                     boolean enableSSLSessionResumption, ChannelGroup allChannels)\n+                                     boolean enableSSLSessionResumption, ChannelGroup allChannels, int channelPoolWaiterTimeout,\n+                                     int connectTimeout, int sslSessionTimeout)\n   {\n \n     _allChannels = allChannels;\n     _scheduler = scheduler;\n     _maxConcurrentConnectionInitializations = maxConcurrentConnectionInitializations;\n+    _channelPoolWaiterTimeout = channelPoolWaiterTimeout;\n     Bootstrap bootstrap = new Bootstrap().group(eventLoopGroup)\n       .channel(NioSocketChannel.class)\n-      .handler(new HttpClientPipelineInitializer(sslContext, sslParameters, maxHeaderSize, maxChunkSize, maxResponseSize, enableSSLSessionResumption));\n+      .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, connectTimeout)\n+      .handler(new HttpClientPipelineInitializer(sslContext, sslParameters, maxHeaderSize, maxChunkSize, maxResponseSize,\n+          enableSSLSessionResumption, sslSessionTimeout));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg4NTg3NQ==", "bodyText": "These changes are no longer needed right?", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384885875", "createdAt": "2020-02-27T02:46:06Z", "author": {"login": "FreCap"}, "path": "r2-netty/src/main/java/com/linkedin/r2/netty/handler/common/SessionResumptionSslHandler.java", "diffHunk": "@@ -46,14 +50,19 @@\n public class SessionResumptionSslHandler extends ChannelOutboundHandlerAdapter\n {\n   public static final String PIPELINE_SESSION_RESUMPTION_HANDLER = \"SessionResumptionSslHandler\";\n+  public static final AttributeKey<SessionResumptionSslHandler> CHANNEL_SESSION_RESUMPTION_HANDLER =\n+      AttributeKey.valueOf(\"sslSessionResumptionHandler\");\n \n   private final SslHandlerGenerator _hostPortToSslHandler;\n+  private Future<Channel> _handshakeFuture;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg4NjU3OA==", "bodyText": "Can be deprecated", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384886578", "createdAt": "2020-02-27T02:48:52Z", "author": {"login": "FreCap"}, "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -156,6 +157,22 @@ public AsyncPoolImpl(String name,\n         maxWaiters, strategy, minSize, rateLimiter, SystemClock.instance(), new LongTracking());\n   }\n \n+  public AsyncPoolImpl(String name,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg4NjgzOA==", "bodyText": "target -> deadline", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384886838", "createdAt": "2020-02-27T02:49:50Z", "author": {"login": "FreCap"}, "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -697,6 +751,23 @@ private void timeoutObjects()\n     return toReap;\n   }\n \n+  private <U> Collection<TimeTrackingCallback<U>> reapWaiters(Queue<TimeTrackingCallback<U>> queue, long timeout)\n+  {\n+    List<TimeTrackingCallback<U>> toReap = new ArrayList<>();\n+    long now = _clock.currentTimeMillis();\n+    long target = now - timeout;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 163}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg4NzAyMA==", "bodyText": "getExpiredWaiters since they are not killed here", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384887020", "createdAt": "2020-02-27T02:50:37Z", "author": {"login": "FreCap"}, "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -697,6 +751,23 @@ private void timeoutObjects()\n     return toReap;\n   }\n \n+  private <U> Collection<TimeTrackingCallback<U>> reapWaiters(Queue<TimeTrackingCallback<U>> queue, long timeout)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 159}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg4OTIxNg==", "bodyText": "waittimeout can be very low, let's add a min of 20-50 ms", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384889216", "createdAt": "2020-02-27T03:00:02Z", "author": {"login": "FreCap"}, "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -255,13 +275,15 @@ public void start()\n         throw new IllegalStateException(_poolName + \" is \" + _state);\n       }\n       _state = State.RUNNING;\n-      if (_idleTimeout > 0)\n+      long timeOut = Math.min(_idleTimeout, _waitTimeout);\n+      if (timeOut > 0)\n       {\n-        long freq = Math.min(_idleTimeout / 10, 1000);\n+        long freq = Math.min(timeOut / 10, 1000);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5NTg2OQ==", "bodyText": "The correctness of this line is not immediately clear and we might want to clarify that it is tightly tied to the shouldCreate methd", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384895869", "createdAt": "2020-02-27T03:29:48Z", "author": {"login": "FreCap"}, "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -601,6 +623,25 @@ private void create()\n       @Override\n       public void run(final SimpleCallback callback)\n       {\n+        boolean shouldIgnore;\n+        synchronized (_lock) {\n+          // Ignore the object creation if no one is waiting for the object and the pool already has _minSize objects\n+          int totalObjects = _checkedOut + _idle.size();\n+          shouldIgnore = _waiters.size() == 0 && totalObjects >= _minSize;\n+          if (shouldIgnore) {\n+            _statsTracker.incrementIgnoredCreation();\n+            if (_poolSize >= 1)\n+            {\n+              _poolSize--;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5NjEyMw==", "bodyText": "also I'm not super clear why this would go below 1, at first sight it seem that it would be kind of a bug if ti went below.\nI'd be curious if it ever happens", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384896123", "createdAt": "2020-02-27T03:31:07Z", "author": {"login": "FreCap"}, "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -601,6 +623,25 @@ private void create()\n       @Override\n       public void run(final SimpleCallback callback)\n       {\n+        boolean shouldIgnore;\n+        synchronized (_lock) {\n+          // Ignore the object creation if no one is waiting for the object and the pool already has _minSize objects\n+          int totalObjects = _checkedOut + _idle.size();\n+          shouldIgnore = _waiters.size() == 0 && totalObjects >= _minSize;\n+          if (shouldIgnore) {\n+            _statsTracker.incrementIgnoredCreation();\n+            if (_poolSize >= 1)\n+            {\n+              _poolSize--;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5NTg2OQ=="}, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5NjM4Nw==", "bodyText": "We can move the increment on line 731.\n        obj.onError(new WaiterTimeoutException(\"Waiter timeout after \" + _waitTimeout + \"ms\"));", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384896387", "createdAt": "2020-02-27T03:32:33Z", "author": {"login": "FreCap"}, "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -697,6 +751,23 @@ private void timeoutObjects()\n     return toReap;\n   }\n \n+  private <U> Collection<TimeTrackingCallback<U>> reapWaiters(Queue<TimeTrackingCallback<U>> queue, long timeout)\n+  {\n+    List<TimeTrackingCallback<U>> toReap = new ArrayList<>();\n+    long now = _clock.currentTimeMillis();\n+    long target = now - timeout;\n+\n+    synchronized (_lock)\n+    {\n+      for (TimeTrackingCallback<U> p; (p = queue.peek()) != null && p.getTime() < target;)\n+      {\n+        toReap.add(queue.poll());\n+        _statsTracker.incrementWaiterTimedOut();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 170}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5NjU1Nw==", "bodyText": "Is this method unused?", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384896557", "createdAt": "2020-02-27T03:33:22Z", "author": {"login": "FreCap"}, "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -797,14 +868,24 @@ public void onError(Throwable e)\n     @Override\n     public void onSuccess(T result)\n     {\n-      long waitTime = System.currentTimeMillis() - _startTime;\n+      long waitTime = _clock.currentTimeMillis() - _startTime;\n       synchronized (_lock)\n       {\n         _statsTracker.trackWaitTime(waitTime);\n         _statsTracker.sampleMaxWaitTime(waitTime);\n       }\n       _callback.onSuccess(result);\n     }\n+\n+    public Callback<T> get()\n+    {\n+      return _callback;\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 230}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5Njc0Nw==", "bodyText": "totalCreationsIgnored\nor to be even more explicit\ntotalCreationsCancelledNoWaiter", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384896747", "createdAt": "2020-02-27T03:34:21Z", "author": {"login": "FreCap"}, "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolStats.java", "diffHunk": "@@ -64,6 +66,8 @@ public AsyncPoolStats(\n       int totalDestroyErrors,\n       int totalBadDestroyed,\n       int totalTimedOut,\n+      int totalWaiterTimedOut,\n+      int totalCreationIgnored,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5NzY2Ng==", "bodyText": "There is not explicit need for having this other than testing. Our usual stance is to add methods to interfaces only if really needed. Adding it in the interface means extra support in the future for any ratelimiter.\nI'd rather remove this and make the method @VisibleForTesting", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384897666", "createdAt": "2020-02-27T03:38:38Z", "author": {"login": "FreCap"}, "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/RateLimiter.java", "diffHunk": "@@ -57,6 +57,11 @@\n    */\n   Collection<Task> cancelPendingTasks();\n \n+  default int numberOfPendingTasks()\n+  {\n+    return -1;\n+  }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5ODE0Mg==", "bodyText": "Is this change actually part of your RB?", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384898142", "createdAt": "2020-02-27T03:41:01Z", "author": {"login": "FreCap"}, "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/ExponentialBackOffRateLimiter.java", "diffHunk": "@@ -173,24 +173,10 @@ public void incrementPeriod()\n   @Override\n   public void submit(Task t)\n   {\n-    boolean runNow = false;\n     synchronized (this)\n     {\n-      if (_period == 0 && _pending.isEmpty() && _runningTasks < _maxRunningTasks)\n-      {\n-        _runningTasks ++;\n-        runNow = true;\n-      }\n-      else\n-      {\n-        _pending.add(t);\n-        schedule();\n-      }\n-    }\n-\n-    if (runNow)\n-    {\n-      t.run(_doneCallback);\n+      _pending.add(t);\n+      schedule();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5ODI2NA==", "bodyText": "@VisibleForTesting", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384898264", "createdAt": "2020-02-27T03:41:34Z", "author": {"login": "FreCap"}, "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/ExponentialBackOffRateLimiter.java", "diffHunk": "@@ -208,6 +194,12 @@ public void submit(Task t)\n     }\n   }\n \n+  @Override\n+  public int numberOfPendingTasks()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5ODczMw==", "bodyText": "This comment is not updated anymore", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384898733", "createdAt": "2020-02-27T03:44:01Z", "author": {"login": "FreCap"}, "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -534,7 +544,7 @@ public void testGetStatsWithErrors() throws Exception\n     Assert.assertEquals(stats.getCheckedOut(), GET - PUT_BAD - DISPOSE);\n     // When the each create fails, it will retry and cancel the waiter,\n     // resulting in a second create error.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5ODgxNw==", "bodyText": "just formatting, no need of space before ! or :", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384898817", "createdAt": "2020-02-27T03:44:30Z", "author": {"login": "FreCap"}, "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -570,6 +580,389 @@ public void testWaitTimeStats() throws Exception\n     Assert.assertEquals(stats.getWaitTimeAvg(), DELAY, DELTA * DELAY);\n   }\n \n+  /***\n+   * This test case verifies that if more request object creation requests are submitted to the rate limiter, it only\n+   * creates the absolute required maximum (see below example)\n+   *\n+   *  Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *  A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the\n+   *      rate limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *  B = In Phase B, N number of object checkout request again sent to the channel pool when the pool has already\n+   *      checkout N number of objects, In this phase, the object creation inside the pool is blocked and the\n+   *      rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *  C = Ih Phase C, N number of objects are returned to the pool which are created in Phase A, this will make\n+   *      the number of idle objects in the pool as N.\n+   *  D = In Phase D, All the object creation blocked in Phase B will get un blocked and create number of new objects\n+   *      that are equal to the rate limiter concurrency. When rate limiter executes the queued creation requests - it\n+   *      should ignore the creation requests as there are no object waiters in the pool and thus effectively only\n+   *      creating the absolute minimum required count (N+Concurrency)\n+   *\n+   * @param numberOfCheckouts the N number of checkout operations that will be performed in phase A & B\n+   * @param poolSize the maximum Object Pool Size\n+   * @param concurrency the maximum allowed concurrent object creation\n+   */\n+  @Test(dataProvider = \"dataProvider\")\n+  public void testObjectsAreNotCreatedWhenThereAreNoWaiters(int numberOfCheckouts, int poolSize, int concurrency)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckouts, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        _executor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckout' times !", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 101}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5OTAwMg==", "bodyText": "Could we add in what way it is unexpected?", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384899002", "createdAt": "2020-02-27T03:45:31Z", "author": {"login": "FreCap"}, "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -570,6 +580,389 @@ public void testWaitTimeStats() throws Exception\n     Assert.assertEquals(stats.getWaitTimeAvg(), DELAY, DELTA * DELAY);\n   }\n \n+  /***\n+   * This test case verifies that if more request object creation requests are submitted to the rate limiter, it only\n+   * creates the absolute required maximum (see below example)\n+   *\n+   *  Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *  A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the\n+   *      rate limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *  B = In Phase B, N number of object checkout request again sent to the channel pool when the pool has already\n+   *      checkout N number of objects, In this phase, the object creation inside the pool is blocked and the\n+   *      rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *  C = Ih Phase C, N number of objects are returned to the pool which are created in Phase A, this will make\n+   *      the number of idle objects in the pool as N.\n+   *  D = In Phase D, All the object creation blocked in Phase B will get un blocked and create number of new objects\n+   *      that are equal to the rate limiter concurrency. When rate limiter executes the queued creation requests - it\n+   *      should ignore the creation requests as there are no object waiters in the pool and thus effectively only\n+   *      creating the absolute minimum required count (N+Concurrency)\n+   *\n+   * @param numberOfCheckouts the N number of checkout operations that will be performed in phase A & B\n+   * @param poolSize the maximum Object Pool Size\n+   * @param concurrency the maximum allowed concurrent object creation\n+   */\n+  @Test(dataProvider = \"dataProvider\")\n+  public void testObjectsAreNotCreatedWhenThereAreNoWaiters(int numberOfCheckouts, int poolSize, int concurrency)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckouts, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        _executor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckout' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckouts, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckout' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckouts, numberOfCheckouts, pool);\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (Object checkedOutObject : checkedOutObjects)\n+    {\n+      pool.put(checkedOutObject);\n+    }\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      // Wait for all object creation to be unblocked\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)\n+    {\n+      Assert.fail(\"Unexpected interruption\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5OTE0Mw==", "bodyText": "Here no need of catching all exceptions, we can just specify the ones that Thread.sleep returns", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384899143", "createdAt": "2020-02-27T03:46:04Z", "author": {"login": "FreCap"}, "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -570,6 +580,389 @@ public void testWaitTimeStats() throws Exception\n     Assert.assertEquals(stats.getWaitTimeAvg(), DELAY, DELTA * DELAY);\n   }\n \n+  /***\n+   * This test case verifies that if more request object creation requests are submitted to the rate limiter, it only\n+   * creates the absolute required maximum (see below example)\n+   *\n+   *  Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *  A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the\n+   *      rate limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *  B = In Phase B, N number of object checkout request again sent to the channel pool when the pool has already\n+   *      checkout N number of objects, In this phase, the object creation inside the pool is blocked and the\n+   *      rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *  C = Ih Phase C, N number of objects are returned to the pool which are created in Phase A, this will make\n+   *      the number of idle objects in the pool as N.\n+   *  D = In Phase D, All the object creation blocked in Phase B will get un blocked and create number of new objects\n+   *      that are equal to the rate limiter concurrency. When rate limiter executes the queued creation requests - it\n+   *      should ignore the creation requests as there are no object waiters in the pool and thus effectively only\n+   *      creating the absolute minimum required count (N+Concurrency)\n+   *\n+   * @param numberOfCheckouts the N number of checkout operations that will be performed in phase A & B\n+   * @param poolSize the maximum Object Pool Size\n+   * @param concurrency the maximum allowed concurrent object creation\n+   */\n+  @Test(dataProvider = \"dataProvider\")\n+  public void testObjectsAreNotCreatedWhenThereAreNoWaiters(int numberOfCheckouts, int poolSize, int concurrency)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckouts, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        _executor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckout' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckouts, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckout' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckouts, numberOfCheckouts, pool);\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (Object checkedOutObject : checkedOutObjects)\n+    {\n+      pool.put(checkedOutObject);\n+    }\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      // Wait for all object creation to be unblocked\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)\n+    {\n+      Assert.fail(\"Unexpected interruption\", e);\n+    }\n+\n+    // Making sure the rate limiter pending tasks are submitted to the executor\n+    while (rateLimiter.numberOfPendingTasks() > 0)\n+    {\n+      try\n+      {\n+        Thread.sleep(1);\n+      }\n+      catch (Exception e)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5OTg1OQ==", "bodyText": "ClockedExecutor should extend Clock, so no need to have two", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384899859", "createdAt": "2020-02-27T03:49:34Z", "author": {"login": "FreCap"}, "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -570,6 +580,389 @@ public void testWaitTimeStats() throws Exception\n     Assert.assertEquals(stats.getWaitTimeAvg(), DELAY, DELTA * DELAY);\n   }\n \n+  /***\n+   * This test case verifies that if more request object creation requests are submitted to the rate limiter, it only\n+   * creates the absolute required maximum (see below example)\n+   *\n+   *  Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *  A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the\n+   *      rate limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *  B = In Phase B, N number of object checkout request again sent to the channel pool when the pool has already\n+   *      checkout N number of objects, In this phase, the object creation inside the pool is blocked and the\n+   *      rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *  C = Ih Phase C, N number of objects are returned to the pool which are created in Phase A, this will make\n+   *      the number of idle objects in the pool as N.\n+   *  D = In Phase D, All the object creation blocked in Phase B will get un blocked and create number of new objects\n+   *      that are equal to the rate limiter concurrency. When rate limiter executes the queued creation requests - it\n+   *      should ignore the creation requests as there are no object waiters in the pool and thus effectively only\n+   *      creating the absolute minimum required count (N+Concurrency)\n+   *\n+   * @param numberOfCheckouts the N number of checkout operations that will be performed in phase A & B\n+   * @param poolSize the maximum Object Pool Size\n+   * @param concurrency the maximum allowed concurrent object creation\n+   */\n+  @Test(dataProvider = \"dataProvider\")\n+  public void testObjectsAreNotCreatedWhenThereAreNoWaiters(int numberOfCheckouts, int poolSize, int concurrency)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckouts, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        _executor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckout' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckouts, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckout' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckouts, numberOfCheckouts, pool);\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (Object checkedOutObject : checkedOutObjects)\n+    {\n+      pool.put(checkedOutObject);\n+    }\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      // Wait for all object creation to be unblocked\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)\n+    {\n+      Assert.fail(\"Unexpected interruption\", e);\n+    }\n+\n+    // Making sure the rate limiter pending tasks are submitted to the executor\n+    while (rateLimiter.numberOfPendingTasks() > 0)\n+    {\n+      try\n+      {\n+        Thread.sleep(1);\n+      }\n+      catch (Exception e)\n+      {\n+        Assert.fail(\"Unexpected interruption\", e);\n+      }\n+    }\n+\n+    // Wait for all the tasks in the rate limiter executor to finish\n+    executor.shutdown();\n+    try\n+    {\n+      if (!executor.awaitTermination(10, TimeUnit.SECONDS))\n+      {\n+        Assert.fail(\"Too long to finish\");\n+      }\n+    }\n+    catch (Exception ex)\n+    {\n+      Assert.fail(\"Unexpected interruption\", ex);\n+    }\n+\n+    // Verify all the expectations\n+    PoolStats stats = pool.getStats();\n+    Assert.assertEquals(stats.getTotalCreationIgnored(), numberOfCheckouts-concurrency);\n+    Assert.assertEquals(stats.getCheckedOut(), numberOfCheckouts);\n+    Assert.assertEquals(stats.getIdleCount(), concurrency);\n+    Assert.assertEquals(stats.getTotalCreated(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getPoolSize(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getTotalDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalBadDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalTimedOut(), 0);\n+  }\n+\n+  /***\n+   * This test case verifies that the correct number of waiters are timed out while waiting for object from the pool\n+   *\n+   *     Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *   A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the rate\n+   *       limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *   B = In Phase B, O number of object checkout request again sent to the channel pool when the pool has already\n+   *       checkout N number of objects, In this phase, the object creation inside the pool is blocked\n+   *       and the rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *   C = Ih Phase C, P number of objects are returned to the pool which are created in Phase A, this will make\n+   *       the number of waiter queue size to be O-P\n+   *   D = In Phase D, A delay will be introduced to timeout the waiters and all the O-P waiters should be timed out.\n+   *       After the delay the object creation will be unblocked and it should create aleast the concurrency number of\n+   *       objects even though the waiters are timedout.\n+   *\n+   * @param numberOfCheckoutsInPhaseA the N number of checkout operations that will be performed in phase A\n+   * @param numberOfCheckoutsInPhaseB the O number of checkout operations that will be performed in Phase B\n+   * @param numbOfObjectsToBeReturnedInPhaseC the numeber of objects returned in Phase C\n+   * @param poolSize size of the pool,\n+   * @param concurrency concurrency of the rate limiter\n+   */\n+  @Test(dataProvider = \"waiterTimeoutDataProvider\")\n+  public void testWaiterTimeout(int numberOfCheckoutsInPhaseA, int numberOfCheckoutsInPhaseB,\n+      int numbOfObjectsToBeReturnedInPhaseC,\n+      int poolSize, int concurrency, int waiterTimeout)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckoutsInPhaseB, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    ClockedExecutor clockedExecutor = new ClockedExecutor();\n+    SettableClock settableClock = new SettableClock();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 201}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5OTk3NA==", "bodyText": "Expand exceptions everywhere :)", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384899974", "createdAt": "2020-02-27T03:50:11Z", "author": {"login": "FreCap"}, "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -570,6 +580,389 @@ public void testWaitTimeStats() throws Exception\n     Assert.assertEquals(stats.getWaitTimeAvg(), DELAY, DELTA * DELAY);\n   }\n \n+  /***\n+   * This test case verifies that if more request object creation requests are submitted to the rate limiter, it only\n+   * creates the absolute required maximum (see below example)\n+   *\n+   *  Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *  A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the\n+   *      rate limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *  B = In Phase B, N number of object checkout request again sent to the channel pool when the pool has already\n+   *      checkout N number of objects, In this phase, the object creation inside the pool is blocked and the\n+   *      rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *  C = Ih Phase C, N number of objects are returned to the pool which are created in Phase A, this will make\n+   *      the number of idle objects in the pool as N.\n+   *  D = In Phase D, All the object creation blocked in Phase B will get un blocked and create number of new objects\n+   *      that are equal to the rate limiter concurrency. When rate limiter executes the queued creation requests - it\n+   *      should ignore the creation requests as there are no object waiters in the pool and thus effectively only\n+   *      creating the absolute minimum required count (N+Concurrency)\n+   *\n+   * @param numberOfCheckouts the N number of checkout operations that will be performed in phase A & B\n+   * @param poolSize the maximum Object Pool Size\n+   * @param concurrency the maximum allowed concurrent object creation\n+   */\n+  @Test(dataProvider = \"dataProvider\")\n+  public void testObjectsAreNotCreatedWhenThereAreNoWaiters(int numberOfCheckouts, int poolSize, int concurrency)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckouts, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        _executor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckout' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckouts, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckout' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckouts, numberOfCheckouts, pool);\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (Object checkedOutObject : checkedOutObjects)\n+    {\n+      pool.put(checkedOutObject);\n+    }\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      // Wait for all object creation to be unblocked\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)\n+    {\n+      Assert.fail(\"Unexpected interruption\", e);\n+    }\n+\n+    // Making sure the rate limiter pending tasks are submitted to the executor\n+    while (rateLimiter.numberOfPendingTasks() > 0)\n+    {\n+      try\n+      {\n+        Thread.sleep(1);\n+      }\n+      catch (Exception e)\n+      {\n+        Assert.fail(\"Unexpected interruption\", e);\n+      }\n+    }\n+\n+    // Wait for all the tasks in the rate limiter executor to finish\n+    executor.shutdown();\n+    try\n+    {\n+      if (!executor.awaitTermination(10, TimeUnit.SECONDS))\n+      {\n+        Assert.fail(\"Too long to finish\");\n+      }\n+    }\n+    catch (Exception ex)\n+    {\n+      Assert.fail(\"Unexpected interruption\", ex);\n+    }\n+\n+    // Verify all the expectations\n+    PoolStats stats = pool.getStats();\n+    Assert.assertEquals(stats.getTotalCreationIgnored(), numberOfCheckouts-concurrency);\n+    Assert.assertEquals(stats.getCheckedOut(), numberOfCheckouts);\n+    Assert.assertEquals(stats.getIdleCount(), concurrency);\n+    Assert.assertEquals(stats.getTotalCreated(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getPoolSize(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getTotalDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalBadDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalTimedOut(), 0);\n+  }\n+\n+  /***\n+   * This test case verifies that the correct number of waiters are timed out while waiting for object from the pool\n+   *\n+   *     Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *   A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the rate\n+   *       limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *   B = In Phase B, O number of object checkout request again sent to the channel pool when the pool has already\n+   *       checkout N number of objects, In this phase, the object creation inside the pool is blocked\n+   *       and the rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *   C = Ih Phase C, P number of objects are returned to the pool which are created in Phase A, this will make\n+   *       the number of waiter queue size to be O-P\n+   *   D = In Phase D, A delay will be introduced to timeout the waiters and all the O-P waiters should be timed out.\n+   *       After the delay the object creation will be unblocked and it should create aleast the concurrency number of\n+   *       objects even though the waiters are timedout.\n+   *\n+   * @param numberOfCheckoutsInPhaseA the N number of checkout operations that will be performed in phase A\n+   * @param numberOfCheckoutsInPhaseB the O number of checkout operations that will be performed in Phase B\n+   * @param numbOfObjectsToBeReturnedInPhaseC the numeber of objects returned in Phase C\n+   * @param poolSize size of the pool,\n+   * @param concurrency concurrency of the rate limiter\n+   */\n+  @Test(dataProvider = \"waiterTimeoutDataProvider\")\n+  public void testWaiterTimeout(int numberOfCheckoutsInPhaseA, int numberOfCheckoutsInPhaseB,\n+      int numbOfObjectsToBeReturnedInPhaseC,\n+      int poolSize, int concurrency, int waiterTimeout)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckoutsInPhaseB, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    ClockedExecutor clockedExecutor = new ClockedExecutor();\n+    SettableClock settableClock = new SettableClock();\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        waiterTimeout,\n+        clockedExecutor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter, settableClock, new LongTracking()\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckoutsInPhaseA' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckoutsInPhaseA, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckoutsInPhaseB' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckoutsInPhaseB,\n+        0, pool);\n+\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (int i = 0; i < numbOfObjectsToBeReturnedInPhaseC; i++)\n+    {\n+      pool.put(checkedOutObjects.remove(0));\n+    }\n+\n+    settableClock.addDuration(waiterTimeout+1);\n+    clockedExecutor.runFor(waiterTimeout+2);\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 241}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkwMDIxMw==", "bodyText": "use AssertWithTimeout instead to avoid locking situations, here and in the other places with sleep", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384900213", "createdAt": "2020-02-27T03:51:28Z", "author": {"login": "FreCap"}, "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -570,6 +580,389 @@ public void testWaitTimeStats() throws Exception\n     Assert.assertEquals(stats.getWaitTimeAvg(), DELAY, DELTA * DELAY);\n   }\n \n+  /***\n+   * This test case verifies that if more request object creation requests are submitted to the rate limiter, it only\n+   * creates the absolute required maximum (see below example)\n+   *\n+   *  Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *  A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the\n+   *      rate limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *  B = In Phase B, N number of object checkout request again sent to the channel pool when the pool has already\n+   *      checkout N number of objects, In this phase, the object creation inside the pool is blocked and the\n+   *      rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *  C = Ih Phase C, N number of objects are returned to the pool which are created in Phase A, this will make\n+   *      the number of idle objects in the pool as N.\n+   *  D = In Phase D, All the object creation blocked in Phase B will get un blocked and create number of new objects\n+   *      that are equal to the rate limiter concurrency. When rate limiter executes the queued creation requests - it\n+   *      should ignore the creation requests as there are no object waiters in the pool and thus effectively only\n+   *      creating the absolute minimum required count (N+Concurrency)\n+   *\n+   * @param numberOfCheckouts the N number of checkout operations that will be performed in phase A & B\n+   * @param poolSize the maximum Object Pool Size\n+   * @param concurrency the maximum allowed concurrent object creation\n+   */\n+  @Test(dataProvider = \"dataProvider\")\n+  public void testObjectsAreNotCreatedWhenThereAreNoWaiters(int numberOfCheckouts, int poolSize, int concurrency)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckouts, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        _executor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckout' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckouts, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckout' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckouts, numberOfCheckouts, pool);\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (Object checkedOutObject : checkedOutObjects)\n+    {\n+      pool.put(checkedOutObject);\n+    }\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      // Wait for all object creation to be unblocked\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)\n+    {\n+      Assert.fail(\"Unexpected interruption\", e);\n+    }\n+\n+    // Making sure the rate limiter pending tasks are submitted to the executor\n+    while (rateLimiter.numberOfPendingTasks() > 0)\n+    {\n+      try\n+      {\n+        Thread.sleep(1);\n+      }\n+      catch (Exception e)\n+      {\n+        Assert.fail(\"Unexpected interruption\", e);\n+      }\n+    }\n+\n+    // Wait for all the tasks in the rate limiter executor to finish\n+    executor.shutdown();\n+    try\n+    {\n+      if (!executor.awaitTermination(10, TimeUnit.SECONDS))\n+      {\n+        Assert.fail(\"Too long to finish\");\n+      }\n+    }\n+    catch (Exception ex)\n+    {\n+      Assert.fail(\"Unexpected interruption\", ex);\n+    }\n+\n+    // Verify all the expectations\n+    PoolStats stats = pool.getStats();\n+    Assert.assertEquals(stats.getTotalCreationIgnored(), numberOfCheckouts-concurrency);\n+    Assert.assertEquals(stats.getCheckedOut(), numberOfCheckouts);\n+    Assert.assertEquals(stats.getIdleCount(), concurrency);\n+    Assert.assertEquals(stats.getTotalCreated(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getPoolSize(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getTotalDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalBadDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalTimedOut(), 0);\n+  }\n+\n+  /***\n+   * This test case verifies that the correct number of waiters are timed out while waiting for object from the pool\n+   *\n+   *     Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *   A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the rate\n+   *       limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *   B = In Phase B, O number of object checkout request again sent to the channel pool when the pool has already\n+   *       checkout N number of objects, In this phase, the object creation inside the pool is blocked\n+   *       and the rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *   C = Ih Phase C, P number of objects are returned to the pool which are created in Phase A, this will make\n+   *       the number of waiter queue size to be O-P\n+   *   D = In Phase D, A delay will be introduced to timeout the waiters and all the O-P waiters should be timed out.\n+   *       After the delay the object creation will be unblocked and it should create aleast the concurrency number of\n+   *       objects even though the waiters are timedout.\n+   *\n+   * @param numberOfCheckoutsInPhaseA the N number of checkout operations that will be performed in phase A\n+   * @param numberOfCheckoutsInPhaseB the O number of checkout operations that will be performed in Phase B\n+   * @param numbOfObjectsToBeReturnedInPhaseC the numeber of objects returned in Phase C\n+   * @param poolSize size of the pool,\n+   * @param concurrency concurrency of the rate limiter\n+   */\n+  @Test(dataProvider = \"waiterTimeoutDataProvider\")\n+  public void testWaiterTimeout(int numberOfCheckoutsInPhaseA, int numberOfCheckoutsInPhaseB,\n+      int numbOfObjectsToBeReturnedInPhaseC,\n+      int poolSize, int concurrency, int waiterTimeout)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckoutsInPhaseB, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    ClockedExecutor clockedExecutor = new ClockedExecutor();\n+    SettableClock settableClock = new SettableClock();\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        waiterTimeout,\n+        clockedExecutor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter, settableClock, new LongTracking()\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckoutsInPhaseA' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckoutsInPhaseA, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckoutsInPhaseB' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckoutsInPhaseB,\n+        0, pool);\n+\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (int i = 0; i < numbOfObjectsToBeReturnedInPhaseC; i++)\n+    {\n+      pool.put(checkedOutObjects.remove(0));\n+    }\n+\n+    settableClock.addDuration(waiterTimeout+1);\n+    clockedExecutor.runFor(waiterTimeout+2);\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)\n+    {\n+      Assert.fail(\"Unexpected interruption\", e);\n+    }\n+\n+    // Making sure the rate limiter pending tasks are submitted to the executor\n+    while (rateLimiter.numberOfPendingTasks() > 0)\n+    {\n+      try\n+      {\n+        Thread.sleep(1);\n+      }\n+      catch (Exception e)\n+      {\n+        Assert.fail(\"Unexpected interruption\", e);\n+      }\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 257}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkwMDM3NQ==", "bodyText": "You can specify the name of the dataProvider including what kind of data it'll return", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384900375", "createdAt": "2020-02-27T03:52:05Z", "author": {"login": "FreCap"}, "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -570,6 +580,389 @@ public void testWaitTimeStats() throws Exception\n     Assert.assertEquals(stats.getWaitTimeAvg(), DELAY, DELTA * DELAY);\n   }\n \n+  /***\n+   * This test case verifies that if more request object creation requests are submitted to the rate limiter, it only\n+   * creates the absolute required maximum (see below example)\n+   *\n+   *  Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *  A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the\n+   *      rate limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *  B = In Phase B, N number of object checkout request again sent to the channel pool when the pool has already\n+   *      checkout N number of objects, In this phase, the object creation inside the pool is blocked and the\n+   *      rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *  C = Ih Phase C, N number of objects are returned to the pool which are created in Phase A, this will make\n+   *      the number of idle objects in the pool as N.\n+   *  D = In Phase D, All the object creation blocked in Phase B will get un blocked and create number of new objects\n+   *      that are equal to the rate limiter concurrency. When rate limiter executes the queued creation requests - it\n+   *      should ignore the creation requests as there are no object waiters in the pool and thus effectively only\n+   *      creating the absolute minimum required count (N+Concurrency)\n+   *\n+   * @param numberOfCheckouts the N number of checkout operations that will be performed in phase A & B\n+   * @param poolSize the maximum Object Pool Size\n+   * @param concurrency the maximum allowed concurrent object creation\n+   */\n+  @Test(dataProvider = \"dataProvider\")\n+  public void testObjectsAreNotCreatedWhenThereAreNoWaiters(int numberOfCheckouts, int poolSize, int concurrency)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckouts, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        _executor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckout' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckouts, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckout' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckouts, numberOfCheckouts, pool);\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (Object checkedOutObject : checkedOutObjects)\n+    {\n+      pool.put(checkedOutObject);\n+    }\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      // Wait for all object creation to be unblocked\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)\n+    {\n+      Assert.fail(\"Unexpected interruption\", e);\n+    }\n+\n+    // Making sure the rate limiter pending tasks are submitted to the executor\n+    while (rateLimiter.numberOfPendingTasks() > 0)\n+    {\n+      try\n+      {\n+        Thread.sleep(1);\n+      }\n+      catch (Exception e)\n+      {\n+        Assert.fail(\"Unexpected interruption\", e);\n+      }\n+    }\n+\n+    // Wait for all the tasks in the rate limiter executor to finish\n+    executor.shutdown();\n+    try\n+    {\n+      if (!executor.awaitTermination(10, TimeUnit.SECONDS))\n+      {\n+        Assert.fail(\"Too long to finish\");\n+      }\n+    }\n+    catch (Exception ex)\n+    {\n+      Assert.fail(\"Unexpected interruption\", ex);\n+    }\n+\n+    // Verify all the expectations\n+    PoolStats stats = pool.getStats();\n+    Assert.assertEquals(stats.getTotalCreationIgnored(), numberOfCheckouts-concurrency);\n+    Assert.assertEquals(stats.getCheckedOut(), numberOfCheckouts);\n+    Assert.assertEquals(stats.getIdleCount(), concurrency);\n+    Assert.assertEquals(stats.getTotalCreated(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getPoolSize(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getTotalDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalBadDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalTimedOut(), 0);\n+  }\n+\n+  /***\n+   * This test case verifies that the correct number of waiters are timed out while waiting for object from the pool\n+   *\n+   *     Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *   A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the rate\n+   *       limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *   B = In Phase B, O number of object checkout request again sent to the channel pool when the pool has already\n+   *       checkout N number of objects, In this phase, the object creation inside the pool is blocked\n+   *       and the rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *   C = Ih Phase C, P number of objects are returned to the pool which are created in Phase A, this will make\n+   *       the number of waiter queue size to be O-P\n+   *   D = In Phase D, A delay will be introduced to timeout the waiters and all the O-P waiters should be timed out.\n+   *       After the delay the object creation will be unblocked and it should create aleast the concurrency number of\n+   *       objects even though the waiters are timedout.\n+   *\n+   * @param numberOfCheckoutsInPhaseA the N number of checkout operations that will be performed in phase A\n+   * @param numberOfCheckoutsInPhaseB the O number of checkout operations that will be performed in Phase B\n+   * @param numbOfObjectsToBeReturnedInPhaseC the numeber of objects returned in Phase C\n+   * @param poolSize size of the pool,\n+   * @param concurrency concurrency of the rate limiter\n+   */\n+  @Test(dataProvider = \"waiterTimeoutDataProvider\")\n+  public void testWaiterTimeout(int numberOfCheckoutsInPhaseA, int numberOfCheckoutsInPhaseB,\n+      int numbOfObjectsToBeReturnedInPhaseC,\n+      int poolSize, int concurrency, int waiterTimeout)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckoutsInPhaseB, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    ClockedExecutor clockedExecutor = new ClockedExecutor();\n+    SettableClock settableClock = new SettableClock();\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        waiterTimeout,\n+        clockedExecutor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter, settableClock, new LongTracking()\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckoutsInPhaseA' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckoutsInPhaseA, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckoutsInPhaseB' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckoutsInPhaseB,\n+        0, pool);\n+\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (int i = 0; i < numbOfObjectsToBeReturnedInPhaseC; i++)\n+    {\n+      pool.put(checkedOutObjects.remove(0));\n+    }\n+\n+    settableClock.addDuration(waiterTimeout+1);\n+    clockedExecutor.runFor(waiterTimeout+2);\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)\n+    {\n+      Assert.fail(\"Unexpected interruption\", e);\n+    }\n+\n+    // Making sure the rate limiter pending tasks are submitted to the executor\n+    while (rateLimiter.numberOfPendingTasks() > 0)\n+    {\n+      try\n+      {\n+        Thread.sleep(1);\n+      }\n+      catch (Exception e)\n+      {\n+        Assert.fail(\"Unexpected interruption\", e);\n+      }\n+    }\n+\n+    executor.shutdown();\n+\n+    try\n+    {\n+      if (!executor.awaitTermination(10, TimeUnit.SECONDS))\n+      {\n+        Assert.fail(\"Too long to finish\");\n+      }\n+    }\n+    catch (Exception ex)\n+    {\n+      Assert.fail(\"Unexpected interruption\", ex);\n+    }\n+\n+    PoolStats stats = pool.getStats();\n+    Assert.assertEquals(stats.getTotalCreationIgnored(), numberOfCheckoutsInPhaseB - concurrency);\n+    Assert.assertEquals(stats.getCheckedOut(), numberOfCheckoutsInPhaseA);\n+    Assert.assertEquals(stats.getIdleCount(), concurrency);\n+    Assert.assertEquals(stats.getTotalCreated(), numberOfCheckoutsInPhaseA + concurrency);\n+    Assert.assertEquals(stats.getPoolSize(), numberOfCheckoutsInPhaseA + concurrency);\n+    Assert.assertEquals(stats.getTotalWaiterTimedOut(), numberOfCheckoutsInPhaseB - numbOfObjectsToBeReturnedInPhaseC);\n+  }\n+\n+  @DataProvider\n+  public Object[][] dataProvider()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 283}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkwMDQ0OA==", "bodyText": "ThreadLocalRandom.current()", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384900448", "createdAt": "2020-02-27T03:52:31Z", "author": {"login": "FreCap"}, "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -570,6 +580,389 @@ public void testWaitTimeStats() throws Exception\n     Assert.assertEquals(stats.getWaitTimeAvg(), DELAY, DELTA * DELAY);\n   }\n \n+  /***\n+   * This test case verifies that if more request object creation requests are submitted to the rate limiter, it only\n+   * creates the absolute required maximum (see below example)\n+   *\n+   *  Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *  A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the\n+   *      rate limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *  B = In Phase B, N number of object checkout request again sent to the channel pool when the pool has already\n+   *      checkout N number of objects, In this phase, the object creation inside the pool is blocked and the\n+   *      rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *  C = Ih Phase C, N number of objects are returned to the pool which are created in Phase A, this will make\n+   *      the number of idle objects in the pool as N.\n+   *  D = In Phase D, All the object creation blocked in Phase B will get un blocked and create number of new objects\n+   *      that are equal to the rate limiter concurrency. When rate limiter executes the queued creation requests - it\n+   *      should ignore the creation requests as there are no object waiters in the pool and thus effectively only\n+   *      creating the absolute minimum required count (N+Concurrency)\n+   *\n+   * @param numberOfCheckouts the N number of checkout operations that will be performed in phase A & B\n+   * @param poolSize the maximum Object Pool Size\n+   * @param concurrency the maximum allowed concurrent object creation\n+   */\n+  @Test(dataProvider = \"dataProvider\")\n+  public void testObjectsAreNotCreatedWhenThereAreNoWaiters(int numberOfCheckouts, int poolSize, int concurrency)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckouts, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        _executor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckout' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckouts, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckout' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckouts, numberOfCheckouts, pool);\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (Object checkedOutObject : checkedOutObjects)\n+    {\n+      pool.put(checkedOutObject);\n+    }\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      // Wait for all object creation to be unblocked\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)\n+    {\n+      Assert.fail(\"Unexpected interruption\", e);\n+    }\n+\n+    // Making sure the rate limiter pending tasks are submitted to the executor\n+    while (rateLimiter.numberOfPendingTasks() > 0)\n+    {\n+      try\n+      {\n+        Thread.sleep(1);\n+      }\n+      catch (Exception e)\n+      {\n+        Assert.fail(\"Unexpected interruption\", e);\n+      }\n+    }\n+\n+    // Wait for all the tasks in the rate limiter executor to finish\n+    executor.shutdown();\n+    try\n+    {\n+      if (!executor.awaitTermination(10, TimeUnit.SECONDS))\n+      {\n+        Assert.fail(\"Too long to finish\");\n+      }\n+    }\n+    catch (Exception ex)\n+    {\n+      Assert.fail(\"Unexpected interruption\", ex);\n+    }\n+\n+    // Verify all the expectations\n+    PoolStats stats = pool.getStats();\n+    Assert.assertEquals(stats.getTotalCreationIgnored(), numberOfCheckouts-concurrency);\n+    Assert.assertEquals(stats.getCheckedOut(), numberOfCheckouts);\n+    Assert.assertEquals(stats.getIdleCount(), concurrency);\n+    Assert.assertEquals(stats.getTotalCreated(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getPoolSize(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getTotalDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalBadDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalTimedOut(), 0);\n+  }\n+\n+  /***\n+   * This test case verifies that the correct number of waiters are timed out while waiting for object from the pool\n+   *\n+   *     Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *   A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the rate\n+   *       limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *   B = In Phase B, O number of object checkout request again sent to the channel pool when the pool has already\n+   *       checkout N number of objects, In this phase, the object creation inside the pool is blocked\n+   *       and the rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *   C = Ih Phase C, P number of objects are returned to the pool which are created in Phase A, this will make\n+   *       the number of waiter queue size to be O-P\n+   *   D = In Phase D, A delay will be introduced to timeout the waiters and all the O-P waiters should be timed out.\n+   *       After the delay the object creation will be unblocked and it should create aleast the concurrency number of\n+   *       objects even though the waiters are timedout.\n+   *\n+   * @param numberOfCheckoutsInPhaseA the N number of checkout operations that will be performed in phase A\n+   * @param numberOfCheckoutsInPhaseB the O number of checkout operations that will be performed in Phase B\n+   * @param numbOfObjectsToBeReturnedInPhaseC the numeber of objects returned in Phase C\n+   * @param poolSize size of the pool,\n+   * @param concurrency concurrency of the rate limiter\n+   */\n+  @Test(dataProvider = \"waiterTimeoutDataProvider\")\n+  public void testWaiterTimeout(int numberOfCheckoutsInPhaseA, int numberOfCheckoutsInPhaseB,\n+      int numbOfObjectsToBeReturnedInPhaseC,\n+      int poolSize, int concurrency, int waiterTimeout)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckoutsInPhaseB, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    ClockedExecutor clockedExecutor = new ClockedExecutor();\n+    SettableClock settableClock = new SettableClock();\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        waiterTimeout,\n+        clockedExecutor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter, settableClock, new LongTracking()\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckoutsInPhaseA' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckoutsInPhaseA, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckoutsInPhaseB' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckoutsInPhaseB,\n+        0, pool);\n+\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (int i = 0; i < numbOfObjectsToBeReturnedInPhaseC; i++)\n+    {\n+      pool.put(checkedOutObjects.remove(0));\n+    }\n+\n+    settableClock.addDuration(waiterTimeout+1);\n+    clockedExecutor.runFor(waiterTimeout+2);\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)\n+    {\n+      Assert.fail(\"Unexpected interruption\", e);\n+    }\n+\n+    // Making sure the rate limiter pending tasks are submitted to the executor\n+    while (rateLimiter.numberOfPendingTasks() > 0)\n+    {\n+      try\n+      {\n+        Thread.sleep(1);\n+      }\n+      catch (Exception e)\n+      {\n+        Assert.fail(\"Unexpected interruption\", e);\n+      }\n+    }\n+\n+    executor.shutdown();\n+\n+    try\n+    {\n+      if (!executor.awaitTermination(10, TimeUnit.SECONDS))\n+      {\n+        Assert.fail(\"Too long to finish\");\n+      }\n+    }\n+    catch (Exception ex)\n+    {\n+      Assert.fail(\"Unexpected interruption\", ex);\n+    }\n+\n+    PoolStats stats = pool.getStats();\n+    Assert.assertEquals(stats.getTotalCreationIgnored(), numberOfCheckoutsInPhaseB - concurrency);\n+    Assert.assertEquals(stats.getCheckedOut(), numberOfCheckoutsInPhaseA);\n+    Assert.assertEquals(stats.getIdleCount(), concurrency);\n+    Assert.assertEquals(stats.getTotalCreated(), numberOfCheckoutsInPhaseA + concurrency);\n+    Assert.assertEquals(stats.getPoolSize(), numberOfCheckoutsInPhaseA + concurrency);\n+    Assert.assertEquals(stats.getTotalWaiterTimedOut(), numberOfCheckoutsInPhaseB - numbOfObjectsToBeReturnedInPhaseC);\n+  }\n+\n+  @DataProvider\n+  public Object[][] dataProvider()\n+  {\n+    // 500 represent a good sample for the randomized data.\n+    // This has been verified against 100K test cases in local\n+    int numberOfTestCases = 500;\n+    Random randomNumberGenerator = new Random();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 288}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkwMDc0NQ==", "bodyText": "extra lines", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384900745", "createdAt": "2020-02-27T03:54:06Z", "author": {"login": "FreCap"}, "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -570,6 +580,389 @@ public void testWaitTimeStats() throws Exception\n     Assert.assertEquals(stats.getWaitTimeAvg(), DELAY, DELTA * DELAY);\n   }\n \n+  /***\n+   * This test case verifies that if more request object creation requests are submitted to the rate limiter, it only\n+   * creates the absolute required maximum (see below example)\n+   *\n+   *  Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *  A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the\n+   *      rate limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *  B = In Phase B, N number of object checkout request again sent to the channel pool when the pool has already\n+   *      checkout N number of objects, In this phase, the object creation inside the pool is blocked and the\n+   *      rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *  C = Ih Phase C, N number of objects are returned to the pool which are created in Phase A, this will make\n+   *      the number of idle objects in the pool as N.\n+   *  D = In Phase D, All the object creation blocked in Phase B will get un blocked and create number of new objects\n+   *      that are equal to the rate limiter concurrency. When rate limiter executes the queued creation requests - it\n+   *      should ignore the creation requests as there are no object waiters in the pool and thus effectively only\n+   *      creating the absolute minimum required count (N+Concurrency)\n+   *\n+   * @param numberOfCheckouts the N number of checkout operations that will be performed in phase A & B\n+   * @param poolSize the maximum Object Pool Size\n+   * @param concurrency the maximum allowed concurrent object creation\n+   */\n+  @Test(dataProvider = \"dataProvider\")\n+  public void testObjectsAreNotCreatedWhenThereAreNoWaiters(int numberOfCheckouts, int poolSize, int concurrency)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckouts, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        _executor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckout' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckouts, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckout' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckouts, numberOfCheckouts, pool);\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (Object checkedOutObject : checkedOutObjects)\n+    {\n+      pool.put(checkedOutObject);\n+    }\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      // Wait for all object creation to be unblocked\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)\n+    {\n+      Assert.fail(\"Unexpected interruption\", e);\n+    }\n+\n+    // Making sure the rate limiter pending tasks are submitted to the executor\n+    while (rateLimiter.numberOfPendingTasks() > 0)\n+    {\n+      try\n+      {\n+        Thread.sleep(1);\n+      }\n+      catch (Exception e)\n+      {\n+        Assert.fail(\"Unexpected interruption\", e);\n+      }\n+    }\n+\n+    // Wait for all the tasks in the rate limiter executor to finish\n+    executor.shutdown();\n+    try\n+    {\n+      if (!executor.awaitTermination(10, TimeUnit.SECONDS))\n+      {\n+        Assert.fail(\"Too long to finish\");\n+      }\n+    }\n+    catch (Exception ex)\n+    {\n+      Assert.fail(\"Unexpected interruption\", ex);\n+    }\n+\n+    // Verify all the expectations\n+    PoolStats stats = pool.getStats();\n+    Assert.assertEquals(stats.getTotalCreationIgnored(), numberOfCheckouts-concurrency);\n+    Assert.assertEquals(stats.getCheckedOut(), numberOfCheckouts);\n+    Assert.assertEquals(stats.getIdleCount(), concurrency);\n+    Assert.assertEquals(stats.getTotalCreated(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getPoolSize(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getTotalDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalBadDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalTimedOut(), 0);\n+  }\n+\n+  /***\n+   * This test case verifies that the correct number of waiters are timed out while waiting for object from the pool\n+   *\n+   *     Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *   A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the rate\n+   *       limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *   B = In Phase B, O number of object checkout request again sent to the channel pool when the pool has already\n+   *       checkout N number of objects, In this phase, the object creation inside the pool is blocked\n+   *       and the rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *   C = Ih Phase C, P number of objects are returned to the pool which are created in Phase A, this will make\n+   *       the number of waiter queue size to be O-P\n+   *   D = In Phase D, A delay will be introduced to timeout the waiters and all the O-P waiters should be timed out.\n+   *       After the delay the object creation will be unblocked and it should create aleast the concurrency number of\n+   *       objects even though the waiters are timedout.\n+   *\n+   * @param numberOfCheckoutsInPhaseA the N number of checkout operations that will be performed in phase A\n+   * @param numberOfCheckoutsInPhaseB the O number of checkout operations that will be performed in Phase B\n+   * @param numbOfObjectsToBeReturnedInPhaseC the numeber of objects returned in Phase C\n+   * @param poolSize size of the pool,\n+   * @param concurrency concurrency of the rate limiter\n+   */\n+  @Test(dataProvider = \"waiterTimeoutDataProvider\")\n+  public void testWaiterTimeout(int numberOfCheckoutsInPhaseA, int numberOfCheckoutsInPhaseB,\n+      int numbOfObjectsToBeReturnedInPhaseC,\n+      int poolSize, int concurrency, int waiterTimeout)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckoutsInPhaseB, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    ClockedExecutor clockedExecutor = new ClockedExecutor();\n+    SettableClock settableClock = new SettableClock();\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        waiterTimeout,\n+        clockedExecutor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter, settableClock, new LongTracking()\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckoutsInPhaseA' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckoutsInPhaseA, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckoutsInPhaseB' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckoutsInPhaseB,\n+        0, pool);\n+\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (int i = 0; i < numbOfObjectsToBeReturnedInPhaseC; i++)\n+    {\n+      pool.put(checkedOutObjects.remove(0));\n+    }\n+\n+    settableClock.addDuration(waiterTimeout+1);\n+    clockedExecutor.runFor(waiterTimeout+2);\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)\n+    {\n+      Assert.fail(\"Unexpected interruption\", e);\n+    }\n+\n+    // Making sure the rate limiter pending tasks are submitted to the executor\n+    while (rateLimiter.numberOfPendingTasks() > 0)\n+    {\n+      try\n+      {\n+        Thread.sleep(1);\n+      }\n+      catch (Exception e)\n+      {\n+        Assert.fail(\"Unexpected interruption\", e);\n+      }\n+    }\n+\n+    executor.shutdown();\n+\n+    try\n+    {\n+      if (!executor.awaitTermination(10, TimeUnit.SECONDS))\n+      {\n+        Assert.fail(\"Too long to finish\");\n+      }\n+    }\n+    catch (Exception ex)\n+    {\n+      Assert.fail(\"Unexpected interruption\", ex);\n+    }\n+\n+    PoolStats stats = pool.getStats();\n+    Assert.assertEquals(stats.getTotalCreationIgnored(), numberOfCheckoutsInPhaseB - concurrency);\n+    Assert.assertEquals(stats.getCheckedOut(), numberOfCheckoutsInPhaseA);\n+    Assert.assertEquals(stats.getIdleCount(), concurrency);\n+    Assert.assertEquals(stats.getTotalCreated(), numberOfCheckoutsInPhaseA + concurrency);\n+    Assert.assertEquals(stats.getPoolSize(), numberOfCheckoutsInPhaseA + concurrency);\n+    Assert.assertEquals(stats.getTotalWaiterTimedOut(), numberOfCheckoutsInPhaseB - numbOfObjectsToBeReturnedInPhaseC);\n+  }\n+\n+  @DataProvider\n+  public Object[][] dataProvider()\n+  {\n+    // 500 represent a good sample for the randomized data.\n+    // This has been verified against 100K test cases in local\n+    int numberOfTestCases = 500;\n+    Random randomNumberGenerator = new Random();\n+\n+    Object[][] data = new Object[numberOfTestCases][3];\n+    for (int i = 0; i < numberOfTestCases; i++)\n+    {\n+      int checkout = randomNumberGenerator.nextInt(200)+1;\n+      int poolSize = randomNumberGenerator.nextInt(checkout)+checkout*2;\n+      int concurrency = randomNumberGenerator.nextInt(Math.min(checkout,499))+1;\n+      data[i][0] = checkout;\n+      data[i][1] = poolSize;\n+      data[i][2] = concurrency;\n+    }\n+\n+    return data;\n+  }\n+\n+  @DataProvider\n+  public Object[][] waiterTimeoutDataProvider()\n+  {\n+    // 500 represent a good sample for the randomized data.\n+    // This has been verified against 100K test cases in local\n+    int numberOfTestCases = 500;\n+    Random randomNumberGenerator = new Random();\n+\n+    Object[][] data = new Object[numberOfTestCases][6];\n+    for (int i = 0; i < numberOfTestCases; i++)\n+    {\n+      int numberOfCheckoutsInPhaseA = randomNumberGenerator.nextInt(100)+1;\n+      int numberOfCheckoutsInPhaseB = randomNumberGenerator.nextInt(numberOfCheckoutsInPhaseA)+1;\n+      numberOfCheckoutsInPhaseB = Math.min(numberOfCheckoutsInPhaseA, numberOfCheckoutsInPhaseB);\n+      int numbOfObjectsToBeReturnedInPhaseC = randomNumberGenerator.nextInt(numberOfCheckoutsInPhaseB);\n+      int poolSize = randomNumberGenerator.nextInt(numberOfCheckoutsInPhaseA)+numberOfCheckoutsInPhaseA*2;\n+      int concurrency = randomNumberGenerator.nextInt(Math.min(numberOfCheckoutsInPhaseB,499))+1;\n+      concurrency = Math.min(concurrency, numberOfCheckoutsInPhaseB);\n+\n+      data[i][0] = numberOfCheckoutsInPhaseA;\n+      data[i][1] = numberOfCheckoutsInPhaseB;\n+      data[i][2] = numbOfObjectsToBeReturnedInPhaseC;\n+      data[i][3] = poolSize;\n+      data[i][4] = concurrency;\n+      data[i][5] = randomNumberGenerator.nextInt(500)+100;\n+    }\n+\n+    return data;\n+  }\n+\n+  private List<Object> performCheckout(int numberOfCheckouts, AsyncPool<Object> pool)\n+  {\n+    List<Object> checkedOutObjects = new ArrayList<>(numberOfCheckouts);\n+\n+    ScheduledExecutorService checkoutExecutor = Executors.newScheduledThreadPool(50);\n+    CountDownLatch checkoutLatch = new CountDownLatch(numberOfCheckouts);\n+    Runnable checkoutTask = getCheckoutTask(pool, checkedOutObjects, new Object(), checkoutLatch, new CountDownLatch(numberOfCheckouts));\n+\n+    for (int i = 0; i < numberOfCheckouts; i++)\n+    {\n+      checkoutExecutor.execute(checkoutTask);\n+    }\n+\n+    try\n+    {\n+      checkoutLatch.await(5, TimeUnit.SECONDS);\n+      checkoutExecutor.shutdownNow();\n+    }\n+    catch (Exception ex)\n+    {\n+      Assert.fail(\"Too long to perform checkout operation\");\n+    }\n+\n+    return checkedOutObjects;\n+  }\n+\n+  private Future<None> performUnblockingCheckout(int numberOfCheckoutRequests, int numberOfCheckouts, AsyncPool<Object> pool)\n+  {\n+    ScheduledExecutorService checkoutExecutor = Executors.newScheduledThreadPool(500);\n+\n+    CountDownLatch checkoutLatch = new CountDownLatch(numberOfCheckouts);\n+    CountDownLatch requestLatch = new CountDownLatch(numberOfCheckoutRequests);\n+    Runnable checkoutTask = getCheckoutTask(pool, new LinkedList<>(), new Object(), checkoutLatch,\n+        requestLatch);\n+\n+    for (int i = 0; i < numberOfCheckoutRequests; i++)\n+    {\n+      checkoutExecutor.execute(checkoutTask);\n+    }\n+\n+    try\n+    {\n+      requestLatch.await(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception ex)\n+    {\n+      Assert.fail(\"Too long to perform checkout operation\");\n+    }\n+\n+    return new DelayedFutureCallback<>(checkoutLatch, checkoutExecutor);\n+  }\n+\n+  private class DelayedFutureCallback<T> extends FutureCallback<T>\n+  {\n+    private CountDownLatch _checkoutLatch;\n+    private ScheduledExecutorService _checkoutExecutor;\n+\n+    public DelayedFutureCallback(CountDownLatch checkoutLatch, ScheduledExecutorService checkoutExecutor)\n+    {\n+      _checkoutLatch = checkoutLatch;\n+      _checkoutExecutor = checkoutExecutor;\n+    }\n+\n+    @Override\n+    public T get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException {\n+      _checkoutLatch.await(timeout, unit);\n+      _checkoutExecutor.shutdownNow();\n+      return null;\n+    }\n+\n+    @Override\n+    public T get() throws InterruptedException, ExecutionException {\n+      throw new ExecutionException(new Exception(\"Not Implemented\"));\n+    }\n+  }\n+\n+  private Runnable getCheckoutTask(AsyncPool<Object> pool, List<Object> checkedOutObjects, Object sync, CountDownLatch latch,\n+      CountDownLatch requestLatch)\n+  {\n+    return new Runnable()\n+    {\n+      @Override\n+      public void run()\n+      {\n+        FutureCallback<Object> cb = new FutureCallback<>();\n+        pool.get(cb);\n+        requestLatch.countDown();\n+        try\n+        {\n+          Object checkedOutObject = cb.get();\n+          synchronized (sync)\n+          {\n+            checkedOutObjects.add(checkedOutObject);\n+          }\n+\n+          latch.countDown();\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 430}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkwMDkwMA==", "bodyText": "missing exception. either log, rethrow runtime or rename exception ignored.\nExpand Exception", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384900900", "createdAt": "2020-02-27T03:55:01Z", "author": {"login": "FreCap"}, "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -622,6 +1015,60 @@ public int getLive()\n     }\n   }\n \n+  public static class CreationBlockableSynchronousLifecycle extends SynchronousLifecycle\n+  {\n+    private CountDownLatch _blockersDoneLatch;\n+    private int _totalBlockers;\n+\n+    public CreationBlockableSynchronousLifecycle(int checkout, int concurrency) {\n+      _blockersDoneLatch = new CountDownLatch(checkout);\n+      _totalBlockers = concurrency;\n+    }\n+\n+    private CountDownLatch _doneLatch = new CountDownLatch(0);\n+\n+    public void unblockCreation()\n+    {\n+      _doneLatch.countDown();\n+    }\n+\n+    public void blockCreation()\n+    {\n+      _doneLatch = new CountDownLatch(1);\n+      _blockersDoneLatch = new CountDownLatch(_totalBlockers);\n+    }\n+\n+    public void waitUntilAllBlocked()\n+    {\n+      try\n+      {\n+        _blockersDoneLatch.await();\n+      }\n+      catch (Exception ex)\n+      {\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 478}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkwMTMxNg==", "bodyText": "This tightly coupled condition is very dangerous being so distant from the origin of the update", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384901316", "createdAt": "2020-02-27T03:56:46Z", "author": {"login": "FreCap"}, "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -601,6 +623,25 @@ private void create()\n       @Override\n       public void run(final SimpleCallback callback)\n       {\n+        boolean shouldIgnore;\n+        synchronized (_lock) {\n+          // Ignore the object creation if no one is waiting for the object and the pool already has _minSize objects\n+          int totalObjects = _checkedOut + _idle.size();\n+          shouldIgnore = _waiters.size() == 0 && totalObjects >= _minSize;\n+          if (shouldIgnore) {\n+            _statsTracker.incrementIgnoredCreation();\n+            if (_poolSize >= 1)\n+            {\n+              _poolSize--;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5NTg2OQ=="}, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 117}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1ODk0Njcx", "url": "https://github.com/linkedin/rest.li/pull/185#pullrequestreview-365894671", "createdAt": "2020-02-27T18:25:52Z", "commit": {"oid": "d4b4f8912510dde6c7baf4b7e4c6aea1a383d386"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxODoyNTo1MlrOFvcP8g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxODoyOToxOFrOFvcXUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTI5MDIyNg==", "bodyText": "What I meant here was to set an upper and lower bound like in   Math.max(50,Math.min(timeOut / 10, 1000));", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385290226", "createdAt": "2020-02-27T18:25:52Z", "author": {"login": "FreCap"}, "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -278,7 +279,7 @@ public void start()\n       long timeOut = Math.min(_idleTimeout, _waitTimeout);\n       if (timeOut > 0)\n       {\n-        long freq = Math.min(timeOut / 10, 1000);\n+        long freq = Math.min(timeOut / 10, 50);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4b4f8912510dde6c7baf4b7e4c6aea1a383d386"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTI5MTkyNg==", "bodyText": "AssertionMethods.assertWithTimeout(5000, () ->       Assert.assertEquals(rateLimiter.numberOfPendingTasks(),0,\"Number of tasks has to drop to 0\")", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385291926", "createdAt": "2020-02-27T18:29:00Z", "author": {"login": "FreCap"}, "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -647,34 +648,35 @@ public void testObjectsAreNotCreatedWhenThereAreNoWaiters(int numberOfCheckouts,\n     }\n     catch (Exception e)\n     {\n-      Assert.fail(\"Unexpected interruption\", e);\n+      Assert.fail(\"Did not complete unblocked object creations on time, Unexpected interruption\", e);\n     }\n \n     // Making sure the rate limiter pending tasks are submitted to the executor\n-    while (rateLimiter.numberOfPendingTasks() > 0)\n-    {\n-      try\n-      {\n-        Thread.sleep(1);\n-      }\n-      catch (Exception e)\n+    AssertionMethods.assertWithTimeout(5000, () -> {\n+      while (rateLimiter.numberOfPendingTasks() > 0)\n       {\n-        Assert.fail(\"Unexpected interruption\", e);\n-      }\n-    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4b4f8912510dde6c7baf4b7e4c6aea1a383d386"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTI5MjExNQ==", "bodyText": "Same for others", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385292115", "createdAt": "2020-02-27T18:29:18Z", "author": {"login": "FreCap"}, "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -647,34 +648,35 @@ public void testObjectsAreNotCreatedWhenThereAreNoWaiters(int numberOfCheckouts,\n     }\n     catch (Exception e)\n     {\n-      Assert.fail(\"Unexpected interruption\", e);\n+      Assert.fail(\"Did not complete unblocked object creations on time, Unexpected interruption\", e);\n     }\n \n     // Making sure the rate limiter pending tasks are submitted to the executor\n-    while (rateLimiter.numberOfPendingTasks() > 0)\n-    {\n-      try\n-      {\n-        Thread.sleep(1);\n-      }\n-      catch (Exception e)\n+    AssertionMethods.assertWithTimeout(5000, () -> {\n+      while (rateLimiter.numberOfPendingTasks() > 0)\n       {\n-        Assert.fail(\"Unexpected interruption\", e);\n-      }\n-    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTI5MTkyNg=="}, "originalCommit": {"oid": "d4b4f8912510dde6c7baf4b7e4c6aea1a383d386"}, "originalPosition": 89}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2MDIzNjI5", "url": "https://github.com/linkedin/rest.li/pull/185#pullrequestreview-366023629", "createdAt": "2020-02-27T21:48:54Z", "commit": {"oid": "ed72ed47198758e9bd2d284c1e54c16d71e2d9ea"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QyMTo0ODo1NFrOFviZwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QyMTo0ODo1NFrOFviZwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTM5MTA0Mg==", "bodyText": "Please name the parameter and class variable consistently. _waitTimeout vs. waiterTimeout.", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385391042", "createdAt": "2020-02-27T21:48:54Z", "author": {"login": "ssheng"}, "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -209,11 +231,13 @@ public AsyncPoolImpl(String name,\n     _lifecycle = lifecycle;\n     _maxSize = maxSize;\n     _idleTimeout = idleTimeout;\n+    _waitTimeout = waiterTimeout;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed72ed47198758e9bd2d284c1e54c16d71e2d9ea"}, "originalPosition": 74}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2MDM5OTY0", "url": "https://github.com/linkedin/rest.li/pull/185#pullrequestreview-366039964", "createdAt": "2020-02-27T22:18:06Z", "commit": {"oid": "ed72ed47198758e9bd2d284c1e54c16d71e2d9ea"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QyMjoxODowN1rOFvjM5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QyMjoxODowN1rOFvjM5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQwNDEzNQ==", "bodyText": "reformat", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385404135", "createdAt": "2020-02-27T22:18:07Z", "author": {"login": "FreCap"}, "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -647,34 +648,25 @@ public void testObjectsAreNotCreatedWhenThereAreNoWaiters(int numberOfCheckouts,\n     }\n     catch (Exception e)\n     {\n-      Assert.fail(\"Unexpected interruption\", e);\n+      Assert.fail(\"Did not complete unblocked object creations on time, Unexpected interruption\", e);\n     }\n \n     // Making sure the rate limiter pending tasks are submitted to the executor\n-    while (rateLimiter.numberOfPendingTasks() > 0)\n-    {\n-      try\n-      {\n-        Thread.sleep(1);\n-      }\n-      catch (Exception e)\n-      {\n-        Assert.fail(\"Unexpected interruption\", e);\n-      }\n-    }\n+    AssertionMethods.assertWithTimeout(5000, () ->\n+            Assert.assertEquals(rateLimiter.numberOfPendingTasks(),0,\"Number of tasks has to drop to 0\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed72ed47198758e9bd2d284c1e54c16d71e2d9ea"}, "originalPosition": 89}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2MDQwOTM1", "url": "https://github.com/linkedin/rest.li/pull/185#pullrequestreview-366040935", "createdAt": "2020-02-27T22:19:56Z", "commit": {"oid": "ed72ed47198758e9bd2d284c1e54c16d71e2d9ea"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QyMjoxOTo1NlrOFvjP1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QyMjoxOTo1NlrOFvjP1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQwNDg4NA==", "bodyText": "I'd be ok also with copy pasting the formula ;)  Math.max(MIN_WAITER_TIMEOUT, Math.min(timeOut / 10, MAX_WAITER_TIMEOUT));", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385404884", "createdAt": "2020-02-27T22:19:56Z", "author": {"login": "FreCap"}, "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -755,8 +746,7 @@ public void testWaiterTimeout(int numberOfCheckoutsInPhaseA, int numberOfCheckou\n       pool.put(checkedOutObjects.remove(0));\n     }\n \n-    settableClock.addDuration(waiterTimeout+1);\n-    clockedExecutor.runFor(waiterTimeout+2);\n+    clockedExecutor.runFor(waiterTimeout + AsyncPoolImpl.MAX_WAITER_TIMEOUT);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed72ed47198758e9bd2d284c1e54c16d71e2d9ea"}, "originalPosition": 142}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2MDQyMjM4", "url": "https://github.com/linkedin/rest.li/pull/185#pullrequestreview-366042238", "createdAt": "2020-02-27T22:22:26Z", "commit": {"oid": "ed72ed47198758e9bd2d284c1e54c16d71e2d9ea"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2MDU2NjIw", "url": "https://github.com/linkedin/rest.li/pull/185#pullrequestreview-366056620", "createdAt": "2020-02-27T22:51:42Z", "commit": {"oid": "ed72ed47198758e9bd2d284c1e54c16d71e2d9ea"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QyMjo1MTo0M1rOFvkA5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QyMjo1MTo0M1rOFvkA5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQxNzQ0Nw==", "bodyText": "The waiters queue is already a class variable and doesn't need to be passed around as a parameter.", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385417447", "createdAt": "2020-02-27T22:51:43Z", "author": {"login": "ssheng"}, "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -697,6 +757,23 @@ private void timeoutObjects()\n     return toReap;\n   }\n \n+  private <U> Collection<TimeTrackingCallback<U>> getExpiredWaiters(Queue<TimeTrackingCallback<U>> queue, long timeout)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed72ed47198758e9bd2d284c1e54c16d71e2d9ea"}, "originalPosition": 170}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2MDgxNzU2", "url": "https://github.com/linkedin/rest.li/pull/185#pullrequestreview-366081756", "createdAt": "2020-02-27T23:56:40Z", "commit": {"oid": "ed72ed47198758e9bd2d284c1e54c16d71e2d9ea"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QyMzo1Njo0MFrOFvlS9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QyMzo1Njo0MFrOFvlS9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQzODQ1NA==", "bodyText": "_waiterTimeout to be consistent with the parameter.", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385438454", "createdAt": "2020-02-27T23:56:40Z", "author": {"login": "ssheng"}, "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -209,11 +231,13 @@ public AsyncPoolImpl(String name,\n     _lifecycle = lifecycle;\n     _maxSize = maxSize;\n     _idleTimeout = idleTimeout;\n+    _waitTimeout = waiterTimeout;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed72ed47198758e9bd2d284c1e54c16d71e2d9ea"}, "originalPosition": 74}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ed72ed47198758e9bd2d284c1e54c16d71e2d9ea", "author": {"user": {"login": "nizarm", "name": "Nizar Mankulangara"}}, "url": "https://github.com/linkedin/rest.li/commit/ed72ed47198758e9bd2d284c1e54c16d71e2d9ea", "committedDate": "2020-02-27T21:05:20Z", "message": "Iterate with review comments"}, "afterCommit": {"oid": "a3512d71d040dcda2ea5d67e6c00783454819773", "author": {"user": {"login": "nizarm", "name": "Nizar Mankulangara"}}, "url": "https://github.com/linkedin/rest.li/commit/a3512d71d040dcda2ea5d67e6c00783454819773", "committedDate": "2020-02-28T01:15:17Z", "message": "AsyncPool Improvements and Fixes:\n1. Do not submit the object creation request in the rate limiter When there is no waiters for the object and when the pool is above the minimum size. This fix will make sure that only the absolute minimum required objects are created in the pool even when the object creation request rate is higher than the actual object creation rate itself.\n\n2. Currenltly in the chhanel pool, the concurrency control how many parallel channel creation requests are in progress. The netty channel creation returns the channel as soon as the channel is created and before the SSL handshake is completed. This behaviour makes the concurrency settings less efffective.\nFix: Fix the channel pool to return the channl after the ssl handshake (for ssl channels) and make the ssl handshake part of the concurrency\n\n3. When a downstream server is healthy - it will not take so much time for the pool to provide a channel to the waiter. If the waiter is too long in the waiters queue, somethign unhealthy in the downstream and it is always better to fail fast the request.\nFix: A new channel pool level configuration introduced. WaiterTimeout - to fail fast the waiter. These waiters will be re-tried in different downstream due to RetriableException\n\n4. Currently during channel creation - there is no easy way to fine tune the \"connectionTimeout\" and \"sslHandShakeTimeout\". It always use the default values.\nFix: Provide a configuration option to fine tune these to fail fast"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2MTEwNjYx", "url": "https://github.com/linkedin/rest.li/pull/185#pullrequestreview-366110661", "createdAt": "2020-02-28T01:27:21Z", "commit": {"oid": "a3512d71d040dcda2ea5d67e6c00783454819773"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2NjQ4MzYy", "url": "https://github.com/linkedin/rest.li/pull/185#pullrequestreview-366648362", "createdAt": "2020-02-28T19:55:11Z", "commit": {"oid": "05ea3ba9753c42ca4969fe0bd38a7a6ac1759a70"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQxOTo1NToxMVrOFwBEow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQxOTo1ODo0NVrOFwBK-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTg5MzUzOQ==", "bodyText": "Thinking more about this, instead of modifying the min timeout (which could have an impact on servers with thousand of AsyncPools when set to a low value), we could run the expire logic per request.\nThis would guarantee us that we are doing the checking work only when actually needed and not keep checking every 100-300ms x 5000 Async Pools which can be a lot of load on the servers if we don't actually have any new connection.", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385893539", "createdAt": "2020-02-28T19:55:11Z", "author": {"login": "FreCap"}, "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -255,13 +278,15 @@ public void start()\n         throw new IllegalStateException(_poolName + \" is \" + _state);\n       }\n       _state = State.RUNNING;\n-      if (_idleTimeout > 0)\n+      long timeOut = Math.min(_idleTimeout, _waiterTimeout);\n+      if (timeOut > 0)\n       {\n-        long freq = Math.min(_idleTimeout / 10, 1000);\n+        long freq = Math.max(MIN_WAITER_TIMEOUT, Math.min(timeOut / 10, MAX_WAITER_TIMEOUT));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "05ea3ba9753c42ca4969fe0bd38a7a6ac1759a70"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTg5NTE2MA==", "bodyText": "I don't see the exception expanded to TimeoutException here", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385895160", "createdAt": "2020-02-28T19:58:45Z", "author": {"login": "FreCap"}, "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -570,6 +580,389 @@ public void testWaitTimeStats() throws Exception\n     Assert.assertEquals(stats.getWaitTimeAvg(), DELAY, DELTA * DELAY);\n   }\n \n+  /***\n+   * This test case verifies that if more request object creation requests are submitted to the rate limiter, it only\n+   * creates the absolute required maximum (see below example)\n+   *\n+   *  Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *  A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the\n+   *      rate limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *  B = In Phase B, N number of object checkout request again sent to the channel pool when the pool has already\n+   *      checkout N number of objects, In this phase, the object creation inside the pool is blocked and the\n+   *      rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *  C = Ih Phase C, N number of objects are returned to the pool which are created in Phase A, this will make\n+   *      the number of idle objects in the pool as N.\n+   *  D = In Phase D, All the object creation blocked in Phase B will get un blocked and create number of new objects\n+   *      that are equal to the rate limiter concurrency. When rate limiter executes the queued creation requests - it\n+   *      should ignore the creation requests as there are no object waiters in the pool and thus effectively only\n+   *      creating the absolute minimum required count (N+Concurrency)\n+   *\n+   * @param numberOfCheckouts the N number of checkout operations that will be performed in phase A & B\n+   * @param poolSize the maximum Object Pool Size\n+   * @param concurrency the maximum allowed concurrent object creation\n+   */\n+  @Test(dataProvider = \"dataProvider\")\n+  public void testObjectsAreNotCreatedWhenThereAreNoWaiters(int numberOfCheckouts, int poolSize, int concurrency)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckouts, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        _executor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckout' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckouts, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckout' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckouts, numberOfCheckouts, pool);\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (Object checkedOutObject : checkedOutObjects)\n+    {\n+      pool.put(checkedOutObject);\n+    }\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      // Wait for all object creation to be unblocked\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)\n+    {\n+      Assert.fail(\"Unexpected interruption\", e);\n+    }\n+\n+    // Making sure the rate limiter pending tasks are submitted to the executor\n+    while (rateLimiter.numberOfPendingTasks() > 0)\n+    {\n+      try\n+      {\n+        Thread.sleep(1);\n+      }\n+      catch (Exception e)\n+      {\n+        Assert.fail(\"Unexpected interruption\", e);\n+      }\n+    }\n+\n+    // Wait for all the tasks in the rate limiter executor to finish\n+    executor.shutdown();\n+    try\n+    {\n+      if (!executor.awaitTermination(10, TimeUnit.SECONDS))\n+      {\n+        Assert.fail(\"Too long to finish\");\n+      }\n+    }\n+    catch (Exception ex)\n+    {\n+      Assert.fail(\"Unexpected interruption\", ex);\n+    }\n+\n+    // Verify all the expectations\n+    PoolStats stats = pool.getStats();\n+    Assert.assertEquals(stats.getTotalCreationIgnored(), numberOfCheckouts-concurrency);\n+    Assert.assertEquals(stats.getCheckedOut(), numberOfCheckouts);\n+    Assert.assertEquals(stats.getIdleCount(), concurrency);\n+    Assert.assertEquals(stats.getTotalCreated(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getPoolSize(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getTotalDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalBadDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalTimedOut(), 0);\n+  }\n+\n+  /***\n+   * This test case verifies that the correct number of waiters are timed out while waiting for object from the pool\n+   *\n+   *     Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *   A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the rate\n+   *       limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *   B = In Phase B, O number of object checkout request again sent to the channel pool when the pool has already\n+   *       checkout N number of objects, In this phase, the object creation inside the pool is blocked\n+   *       and the rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *   C = Ih Phase C, P number of objects are returned to the pool which are created in Phase A, this will make\n+   *       the number of waiter queue size to be O-P\n+   *   D = In Phase D, A delay will be introduced to timeout the waiters and all the O-P waiters should be timed out.\n+   *       After the delay the object creation will be unblocked and it should create aleast the concurrency number of\n+   *       objects even though the waiters are timedout.\n+   *\n+   * @param numberOfCheckoutsInPhaseA the N number of checkout operations that will be performed in phase A\n+   * @param numberOfCheckoutsInPhaseB the O number of checkout operations that will be performed in Phase B\n+   * @param numbOfObjectsToBeReturnedInPhaseC the numeber of objects returned in Phase C\n+   * @param poolSize size of the pool,\n+   * @param concurrency concurrency of the rate limiter\n+   */\n+  @Test(dataProvider = \"waiterTimeoutDataProvider\")\n+  public void testWaiterTimeout(int numberOfCheckoutsInPhaseA, int numberOfCheckoutsInPhaseB,\n+      int numbOfObjectsToBeReturnedInPhaseC,\n+      int poolSize, int concurrency, int waiterTimeout)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckoutsInPhaseB, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    ClockedExecutor clockedExecutor = new ClockedExecutor();\n+    SettableClock settableClock = new SettableClock();\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        waiterTimeout,\n+        clockedExecutor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter, settableClock, new LongTracking()\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckoutsInPhaseA' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckoutsInPhaseA, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckoutsInPhaseB' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckoutsInPhaseB,\n+        0, pool);\n+\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (int i = 0; i < numbOfObjectsToBeReturnedInPhaseC; i++)\n+    {\n+      pool.put(checkedOutObjects.remove(0));\n+    }\n+\n+    settableClock.addDuration(waiterTimeout+1);\n+    clockedExecutor.runFor(waiterTimeout+2);\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5OTk3NA=="}, "originalCommit": {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd"}, "originalPosition": 241}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a639a72a31dd128821d11fa6ed3417ea478ea96b", "author": {"user": {"login": "nizarm", "name": "Nizar Mankulangara"}}, "url": "https://github.com/linkedin/rest.li/commit/a639a72a31dd128821d11fa6ed3417ea478ea96b", "committedDate": "2020-02-29T00:49:20Z", "message": "AsyncPool Improvements and Fixes:\n1. Do not submit the object creation request in the rate limiter When there is no waiters for the object and when the pool is above the minimum size. This fix will make sure that only the absolute minimum required objects are created in the pool even when the object creation request rate is higher than the actual object creation rate itself.\n\n2. Currenltly in the chhanel pool, the concurrency control how many parallel channel creation requests are in progress. The netty channel creation returns the channel as soon as the channel is created and before the SSL handshake is completed. This behaviour makes the concurrency settings less efffective.\nFix: Fix the channel pool to return the channl after the ssl handshake (for ssl channels) and make the ssl handshake part of the concurrency\n\n3. When a downstream server is healthy - it will not take so much time for the pool to provide a channel to the waiter. If the waiter is too long in the waiters queue, somethign unhealthy in the downstream and it is always better to fail fast the request.\nFix: A new channel pool level configuration introduced. WaiterTimeout - to fail fast the waiter. These waiters will be re-tried in different downstream due to RetriableException\n\n4. Currently during channel creation - there is no easy way to fine tune the \"connectionTimeout\" and \"sslHandShakeTimeout\". It always use the default values.\nFix: Provide a configuration option to fine tune these to fail fast"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "05ea3ba9753c42ca4969fe0bd38a7a6ac1759a70", "author": {"user": {"login": "nizarm", "name": "Nizar Mankulangara"}}, "url": "https://github.com/linkedin/rest.li/commit/05ea3ba9753c42ca4969fe0bd38a7a6ac1759a70", "committedDate": "2020-02-28T05:17:47Z", "message": "Merge branch 'master' into bugfix/asyncpool"}, "afterCommit": {"oid": "a639a72a31dd128821d11fa6ed3417ea478ea96b", "author": {"user": {"login": "nizarm", "name": "Nizar Mankulangara"}}, "url": "https://github.com/linkedin/rest.li/commit/a639a72a31dd128821d11fa6ed3417ea478ea96b", "committedDate": "2020-02-29T00:49:20Z", "message": "AsyncPool Improvements and Fixes:\n1. Do not submit the object creation request in the rate limiter When there is no waiters for the object and when the pool is above the minimum size. This fix will make sure that only the absolute minimum required objects are created in the pool even when the object creation request rate is higher than the actual object creation rate itself.\n\n2. Currenltly in the chhanel pool, the concurrency control how many parallel channel creation requests are in progress. The netty channel creation returns the channel as soon as the channel is created and before the SSL handshake is completed. This behaviour makes the concurrency settings less efffective.\nFix: Fix the channel pool to return the channl after the ssl handshake (for ssl channels) and make the ssl handshake part of the concurrency\n\n3. When a downstream server is healthy - it will not take so much time for the pool to provide a channel to the waiter. If the waiter is too long in the waiters queue, somethign unhealthy in the downstream and it is always better to fail fast the request.\nFix: A new channel pool level configuration introduced. WaiterTimeout - to fail fast the waiter. These waiters will be re-tried in different downstream due to RetriableException\n\n4. Currently during channel creation - there is no easy way to fine tune the \"connectionTimeout\" and \"sslHandShakeTimeout\". It always use the default values.\nFix: Provide a configuration option to fine tune these to fail fast"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2NzYwOTAx", "url": "https://github.com/linkedin/rest.li/pull/185#pullrequestreview-366760901", "createdAt": "2020-02-29T00:56:04Z", "commit": {"oid": "a639a72a31dd128821d11fa6ed3417ea478ea96b"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOVQwMDo1NjowNFrOFwGmZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOVQwMDo1Nzo1MlrOFwGnUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTk4NDEwMg==", "bodyText": "Unused", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385984102", "createdAt": "2020-02-29T00:56:04Z", "author": {"login": "FreCap"}, "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -64,11 +63,15 @@\n   private final int _maxSize;\n   private final int _maxWaiters;\n   private final long _idleTimeout;\n+  private final long _waiterTimeout;\n   private final ScheduledExecutorService _timeoutExecutor;\n   private final int _minSize;\n   private volatile ScheduledFuture<?> _objectTimeoutFuture;\n   private final RateLimiter _rateLimiter;\n \n+  public static final int MIN_WAITER_TIMEOUT = 300;\n+  public static final int MAX_WAITER_TIMEOUT = 3000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a639a72a31dd128821d11fa6ed3417ea478ea96b"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTk4NDMzOA==", "bodyText": "getIdleTimeoutExpiredObjects", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385984338", "createdAt": "2020-02-29T00:57:52Z", "author": {"login": "FreCap"}, "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -668,33 +713,33 @@ public void onError(final Throwable e)\n \n   private void timeoutObjects()\n   {\n-    Collection<T> idle = reap(_idle, _idleTimeout);\n-    if (idle.size() > 0)\n+    Collection<T> expiredObjects = getExpiredObjects();\n+    if (expiredObjects.size() > 0)\n     {\n-      LOG.debug(\"{}: disposing {} objects due to idle timeout\", _poolName, idle.size());\n-      for (T obj : idle)\n+      LOG.debug(\"{}: disposing {} objects due to idle timeout\", _poolName, expiredObjects.size());\n+      for (T obj : expiredObjects)\n       {\n         destroy(obj, false);\n       }\n     }\n   }\n \n-  private <U> Collection<U> reap(Queue<TimedObject<U>> queue, long timeout)\n+  private Collection<T> getExpiredObjects()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a639a72a31dd128821d11fa6ed3417ea478ea96b"}, "originalPosition": 164}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2NzYyMDg3", "url": "https://github.com/linkedin/rest.li/pull/185#pullrequestreview-366762087", "createdAt": "2020-02-29T01:03:52Z", "commit": {"oid": "a639a72a31dd128821d11fa6ed3417ea478ea96b"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "036d31ba0085e5eaaabddd2d9c65408c381da1cd", "author": {"user": {"login": "nizarm", "name": "Nizar Mankulangara"}}, "url": "https://github.com/linkedin/rest.li/commit/036d31ba0085e5eaaabddd2d9c65408c381da1cd", "committedDate": "2020-02-29T01:09:08Z", "message": "Merge branch 'master' into bugfix/asyncpool"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4944, "cost": 1, "resetAt": "2021-11-01T16:37:27Z"}}}