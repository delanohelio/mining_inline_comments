{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTEwNzU4NTgz", "number": 957, "reviewThreads": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNTozMjoxM1rOEy3tXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNjowMToxOVrOEy4nKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxNzc2OTg5OnYy", "diffSide": "RIGHT", "path": "docs/modules/ROOT/partials/getting-started/con-registry-serdes-concepts.adoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNTozMjoxM1rOHpwF1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNTozMjoxM1rOHpwF1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzU0MTU5MQ==", "bodyText": "Suggest \"...can be located\" (use \"may\" only for permissions)", "url": "https://github.com/Apicurio/apicurio-registry/pull/957#discussion_r513541591", "createdAt": "2020-10-28T15:32:13Z", "author": {"login": "smccarthy-ie"}, "path": "docs/modules/ROOT/partials/getting-started/con-registry-serdes-concepts.adoc", "diffHunk": "@@ -41,8 +50,12 @@ To enable a consumer to use {registry} for deserialization:\n ** {registry} deserializer to use with the messages\n ** Input data stream for deserialization\n \n-The schema is then retrieved by the deserializer using a global ID written into the message being consumed.\n-The message received must, therefore, include a global ID as well as the message data.\n+The schema is then retrieved by the deserializer using a global ID written into the message being consumed.  The schema\n+global ID may be located in the message headers or in the message payload itself, depending on the configuration of", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bff8b4dcfcc628697676892336f6eec0e4d061f0"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxNzc4NTA2OnYy", "diffSide": "LEFT", "path": "docs/modules/ROOT/partials/getting-started/con-registry-serdes-strategy.adoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNTozNToxNVrOHpwPcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNTozNToxNVrOHpwPcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzU0NDA0OA==", "bodyText": "Suggest adding block heading to help break up the text, for example: \".Artifact ID strategy\"", "url": "https://github.com/Apicurio/apicurio-registry/pull/957#discussion_r513544048", "createdAt": "2020-10-28T15:35:15Z", "author": {"login": "smccarthy-ie"}, "path": "docs/modules/ROOT/partials/getting-started/con-registry-serdes-strategy.adoc", "diffHunk": "@@ -4,18 +4,30 @@\n [id='registry-serdes-concepts-strategy-{context}']\n = Strategies to lookup a schema\n \n-The Kafka client serializer/deserializer uses a lookup _strategy_ to determine the artifact ID or global ID under which the message schema is registered in {registry}.\n+The Kafka client serializer uses two lookup _strategies_ to determine the artifact ID and global ID under which the message schema is registered in {registry}.\n \n-For a given topic and message, you can use implementations of the following Java classes:\n+For a given topic and message, you can use implementations of the following Java interfaces:\n \n * `ArtifactIdStrategy` to return an artifact ID\n * `GlobalIdStrategy` to return a global ID\n \n-The artifact ID returned depends on whether the _key_ or _value_ in the message is being serialized.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bff8b4dcfcc628697676892336f6eec0e4d061f0"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxNzc4NzMwOnYy", "diffSide": "RIGHT", "path": "docs/modules/ROOT/partials/getting-started/con-registry-serdes-strategy.adoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNTozNTo0MFrOHpwQ3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNTozNTo0MFrOHpwQ3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzU0NDQxMw==", "bodyText": "Suggest adding block heading to help break up the text, for example: \".Global ID strategy\"", "url": "https://github.com/Apicurio/apicurio-registry/pull/957#discussion_r513544413", "createdAt": "2020-10-28T15:35:40Z", "author": {"login": "smccarthy-ie"}, "path": "docs/modules/ROOT/partials/getting-started/con-registry-serdes-strategy.adoc", "diffHunk": "@@ -4,18 +4,30 @@\n [id='registry-serdes-concepts-strategy-{context}']\n = Strategies to lookup a schema\n \n-The Kafka client serializer/deserializer uses a lookup _strategy_ to determine the artifact ID or global ID under which the message schema is registered in {registry}.\n+The Kafka client serializer uses two lookup _strategies_ to determine the artifact ID and global ID under which the message schema is registered in {registry}.\n \n-For a given topic and message, you can use implementations of the following Java classes:\n+For a given topic and message, you can use implementations of the following Java interfaces:\n \n * `ArtifactIdStrategy` to return an artifact ID\n * `GlobalIdStrategy` to return a global ID\n \n-The artifact ID returned depends on whether the _key_ or _value_ in the message is being serialized.\n+The artifact ID strategy provides a way to map the Kafka topic and message information to the ID of an artifact in\n+{registry}.  The common convention for the mapping is to combine the Kafka topic name with either `key` or `value`\n+(depending on whether the serializer is being used for the Kafka message key or value).  However, alternative\n+conventions can be used for the mapping, either by using an alternative strategy provided by {registry} or by\n+creating a custom Java class that implements `io.apicurio.registry.utils.serde.strategy.ArtifactIdStrategy`.\n+\n+The global ID strategy is responsible for locating and identifying the specific *version* of the schema registered", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bff8b4dcfcc628697676892336f6eec0e4d061f0"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxNzgxOTMzOnYy", "diffSide": "RIGHT", "path": "docs/modules/ROOT/partials/getting-started/con-registry-serdes-types.adoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNTo0MjowNFrOHpwlQA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNTo0MjowNFrOHpwlQA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzU0OTYzMg==", "bodyText": "Suggest uppercase \"...Kafka settings\"", "url": "https://github.com/Apicurio/apicurio-registry/pull/957#discussion_r513549632", "createdAt": "2020-10-28T15:42:04Z", "author": {"login": "smccarthy-ie"}, "path": "docs/modules/ROOT/partials/getting-started/con-registry-serdes-types.adoc", "diffHunk": "@@ -0,0 +1,224 @@\n+// Module included in the following assemblies:\n+//  assembly-using-kafka-client-serdes\n+\n+[id='registry-serdes-types-serde-{context}']\n+= Configuring different SerDe types\n+\n+When using a schema technology in your Kafka applications, you must choose which specific schema type to use.  Common\n+options include:\n+\n+* Apache Avro\n+* JSON Schema\n+* Google Protobuf\n+\n+Which schema technology you choose is dependent on use-case and preference.  Of course Kafka allows you to implement\n+your own custom serializer and deserializer classes, so you are always free to write your own classes, including\n+leveraging {registry} functionality by utilizing the REST Client (see the \"Using the {registry} Java client\" section).\n+\n+For your convenience, {registry} provides out of the box SerDe classes for all three of the above schema technologies.\n+This section of the documentation explains how to configure Kafka applications to use each type.\n+\n+Using one of the serializer or deserializer classes provided by {registry} in your Kafka application is as simple\n+as setting the proper configuration properties.  Here are some simple examples of configuring producer and\n+consumer Kafka applications.\n+\n+.Configuring a Producer\n+\n+[source,java,subs=\"+quotes,attributes\"]\n+----\n+public Producer<Object,Object> createKafkaProducer(String kafkaBootstrapServers, String topicName) {\n+    Properties props = new Properties();\n+\n+    // Configure standard kafka settings\n+    props.putIfAbsent(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaBootstrapServers);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bff8b4dcfcc628697676892336f6eec0e4d061f0"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxNzgyMjMyOnYy", "diffSide": "RIGHT", "path": "docs/modules/ROOT/partials/getting-started/con-registry-serdes-types.adoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNTo0Mjo0M1rOHpwnOA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNTo0Mjo0M1rOHpwnOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzU1MDEzNg==", "bodyText": "Suggest lowercase \"...schema from the registry\"", "url": "https://github.com/Apicurio/apicurio-registry/pull/957#discussion_r513550136", "createdAt": "2020-10-28T15:42:43Z", "author": {"login": "smccarthy-ie"}, "path": "docs/modules/ROOT/partials/getting-started/con-registry-serdes-types.adoc", "diffHunk": "@@ -0,0 +1,224 @@\n+// Module included in the following assemblies:\n+//  assembly-using-kafka-client-serdes\n+\n+[id='registry-serdes-types-serde-{context}']\n+= Configuring different SerDe types\n+\n+When using a schema technology in your Kafka applications, you must choose which specific schema type to use.  Common\n+options include:\n+\n+* Apache Avro\n+* JSON Schema\n+* Google Protobuf\n+\n+Which schema technology you choose is dependent on use-case and preference.  Of course Kafka allows you to implement\n+your own custom serializer and deserializer classes, so you are always free to write your own classes, including\n+leveraging {registry} functionality by utilizing the REST Client (see the \"Using the {registry} Java client\" section).\n+\n+For your convenience, {registry} provides out of the box SerDe classes for all three of the above schema technologies.\n+This section of the documentation explains how to configure Kafka applications to use each type.\n+\n+Using one of the serializer or deserializer classes provided by {registry} in your Kafka application is as simple\n+as setting the proper configuration properties.  Here are some simple examples of configuring producer and\n+consumer Kafka applications.\n+\n+.Configuring a Producer\n+\n+[source,java,subs=\"+quotes,attributes\"]\n+----\n+public Producer<Object,Object> createKafkaProducer(String kafkaBootstrapServers, String topicName) {\n+    Properties props = new Properties();\n+\n+    // Configure standard kafka settings\n+    props.putIfAbsent(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaBootstrapServers);\n+    props.putIfAbsent(ProducerConfig.CLIENT_ID_CONFIG, \"Producer-\" + topicName);\n+    props.putIfAbsent(ProducerConfig.ACKS_CONFIG, \"all\");\n+\n+    // Use a {registry} provided Kafka Serializer\n+    props.putIfAbsent(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,\n+        io.apicurio.registry.utils.serde.AvroKafkaSerializer.class.getName());\n+    props.putIfAbsent(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,\n+        io.apicurio.registry.utils.serde.AvroKafkaSerializer.class.getName());\n+\n+    // Configure {registry} location\n+    props.putIfAbsent(AbstractKafkaSerDe.REGISTRY_URL_CONFIG_PARAM, REGISTRY_URL);\n+    // Map the topic name (plus -key/value) to the artifactId in the registry\n+    props.putIfAbsent(AbstractKafkaSerializer.REGISTRY_ARTIFACT_ID_STRATEGY_CONFIG_PARAM,\n+        io.apicurio.registry.utils.serde.strategy.TopicIdStrategy.class.getName());\n+    // Get an existing schema or auto-register if not found\n+    props.putIfAbsent(AbstractKafkaSerializer.REGISTRY_GLOBAL_ID_STRATEGY_CONFIG_PARAM,\n+        io.apicurio.registry.utils.serde.strategy.GetOrCreateIdStrategy.class.getName());\n+\n+    // Create the Kafka producer\n+    Producer<Object, Object> producer = new KafkaProducer<>(props);\n+    return producer;\n+}\n+----\n+\n+.Configuring a Consumer\n+\n+[source,java,subs=\"+quotes,attributes\"]\n+----\n+public Consumer<Object,Object> createKafkaConsumer(String kafkaBootstrapServers, String topicName) {\n+    Properties props = new Properties();\n+\n+    // Configure standard Kafka settings\n+    props.putIfAbsent(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaBootstrapServers);\n+    props.putIfAbsent(ConsumerConfig.GROUP_ID_CONFIG, \"Consumer-\" + topicName);\n+    props.putIfAbsent(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \"true\");\n+    props.putIfAbsent(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, \"1000\");\n+    props.putIfAbsent(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n+\n+    // Use a {registry} provided Kafka Deserializer\n+    props.putIfAbsent(ProducerConfig.KEY_DESERIALIZER_CLASS_CONFIG,\n+        io.apicurio.registry.utils.serde.AvroKafkaDeserializer.class.getName());\n+    props.putIfAbsent(ProducerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,\n+        io.apicurio.registry.utils.serde.AvroKafkaDeserializer.class.getName());\n+\n+    // Configure {registry} location\n+    props.putIfAbsent(AbstractKafkaSerDe.REGISTRY_URL_CONFIG_PARAM, REGISTRY_URL);\n+    // No other configuration needed for the deserializer, because the globalId of the schema\n+    // the deserializer should use is sent as part of the message.  So the deserializer simply\n+    // extracts that globalId and uses it to look up the Schema from the registry.\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bff8b4dcfcc628697676892336f6eec0e4d061f0"}, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxNzg0MjgwOnYy", "diffSide": "RIGHT", "path": "docs/modules/ROOT/partials/getting-started/con-registry-serdes-types.adoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNTo0Njo1MFrOHpw0NA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNTo0Njo1MFrOHpw0NA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzU1MzQ2MA==", "bodyText": "Suggest \"You can configure the Avro serializer...\" for active voice", "url": "https://github.com/Apicurio/apicurio-registry/pull/957#discussion_r513553460", "createdAt": "2020-10-28T15:46:50Z", "author": {"login": "smccarthy-ie"}, "path": "docs/modules/ROOT/partials/getting-started/con-registry-serdes-types.adoc", "diffHunk": "@@ -0,0 +1,224 @@\n+// Module included in the following assemblies:\n+//  assembly-using-kafka-client-serdes\n+\n+[id='registry-serdes-types-serde-{context}']\n+= Configuring different SerDe types\n+\n+When using a schema technology in your Kafka applications, you must choose which specific schema type to use.  Common\n+options include:\n+\n+* Apache Avro\n+* JSON Schema\n+* Google Protobuf\n+\n+Which schema technology you choose is dependent on use-case and preference.  Of course Kafka allows you to implement\n+your own custom serializer and deserializer classes, so you are always free to write your own classes, including\n+leveraging {registry} functionality by utilizing the REST Client (see the \"Using the {registry} Java client\" section).\n+\n+For your convenience, {registry} provides out of the box SerDe classes for all three of the above schema technologies.\n+This section of the documentation explains how to configure Kafka applications to use each type.\n+\n+Using one of the serializer or deserializer classes provided by {registry} in your Kafka application is as simple\n+as setting the proper configuration properties.  Here are some simple examples of configuring producer and\n+consumer Kafka applications.\n+\n+.Configuring a Producer\n+\n+[source,java,subs=\"+quotes,attributes\"]\n+----\n+public Producer<Object,Object> createKafkaProducer(String kafkaBootstrapServers, String topicName) {\n+    Properties props = new Properties();\n+\n+    // Configure standard kafka settings\n+    props.putIfAbsent(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaBootstrapServers);\n+    props.putIfAbsent(ProducerConfig.CLIENT_ID_CONFIG, \"Producer-\" + topicName);\n+    props.putIfAbsent(ProducerConfig.ACKS_CONFIG, \"all\");\n+\n+    // Use a {registry} provided Kafka Serializer\n+    props.putIfAbsent(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,\n+        io.apicurio.registry.utils.serde.AvroKafkaSerializer.class.getName());\n+    props.putIfAbsent(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,\n+        io.apicurio.registry.utils.serde.AvroKafkaSerializer.class.getName());\n+\n+    // Configure {registry} location\n+    props.putIfAbsent(AbstractKafkaSerDe.REGISTRY_URL_CONFIG_PARAM, REGISTRY_URL);\n+    // Map the topic name (plus -key/value) to the artifactId in the registry\n+    props.putIfAbsent(AbstractKafkaSerializer.REGISTRY_ARTIFACT_ID_STRATEGY_CONFIG_PARAM,\n+        io.apicurio.registry.utils.serde.strategy.TopicIdStrategy.class.getName());\n+    // Get an existing schema or auto-register if not found\n+    props.putIfAbsent(AbstractKafkaSerializer.REGISTRY_GLOBAL_ID_STRATEGY_CONFIG_PARAM,\n+        io.apicurio.registry.utils.serde.strategy.GetOrCreateIdStrategy.class.getName());\n+\n+    // Create the Kafka producer\n+    Producer<Object, Object> producer = new KafkaProducer<>(props);\n+    return producer;\n+}\n+----\n+\n+.Configuring a Consumer\n+\n+[source,java,subs=\"+quotes,attributes\"]\n+----\n+public Consumer<Object,Object> createKafkaConsumer(String kafkaBootstrapServers, String topicName) {\n+    Properties props = new Properties();\n+\n+    // Configure standard Kafka settings\n+    props.putIfAbsent(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaBootstrapServers);\n+    props.putIfAbsent(ConsumerConfig.GROUP_ID_CONFIG, \"Consumer-\" + topicName);\n+    props.putIfAbsent(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \"true\");\n+    props.putIfAbsent(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, \"1000\");\n+    props.putIfAbsent(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n+\n+    // Use a {registry} provided Kafka Deserializer\n+    props.putIfAbsent(ProducerConfig.KEY_DESERIALIZER_CLASS_CONFIG,\n+        io.apicurio.registry.utils.serde.AvroKafkaDeserializer.class.getName());\n+    props.putIfAbsent(ProducerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,\n+        io.apicurio.registry.utils.serde.AvroKafkaDeserializer.class.getName());\n+\n+    // Configure {registry} location\n+    props.putIfAbsent(AbstractKafkaSerDe.REGISTRY_URL_CONFIG_PARAM, REGISTRY_URL);\n+    // No other configuration needed for the deserializer, because the globalId of the schema\n+    // the deserializer should use is sent as part of the message.  So the deserializer simply\n+    // extracts that globalId and uses it to look up the Schema from the registry.\n+\n+    // Create the Kafka Consumer\n+    KafkaConsumer<Long, GenericRecord> consumer = new KafkaConsumer<>(props);\n+    return consumer;\n+}\n+----\n+\n+\n+== Using Avro SerDe with {registry}\n+\n+{registry} provides serializer and deserializer classes for Apache Avro out of the box, to make using Avro as\n+easy as possible.  These classes are:\n+\n+* `io.apicurio.registry.utils.serde.AvroKafkaSerializer`\n+* `io.apicurio.registry.utils.serde.AvroKafkaDeserializer`\n+\n+=== Configuring the Avro serializer\n+\n+The Avro serializer class can be configured in the following ways:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bff8b4dcfcc628697676892336f6eec0e4d061f0"}, "originalPosition": 101}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxNzg2OTgzOnYy", "diffSide": "RIGHT", "path": "docs/modules/ROOT/partials/getting-started/con-registry-serdes-types.adoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNTo1MjoyMVrOHpxFyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNTo1MjoyMVrOHpxFyg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzU1Nzk2Mg==", "bodyText": "Suggest \"you can customize precisely...\" for active voice", "url": "https://github.com/Apicurio/apicurio-registry/pull/957#discussion_r513557962", "createdAt": "2020-10-28T15:52:21Z", "author": {"login": "smccarthy-ie"}, "path": "docs/modules/ROOT/partials/getting-started/con-registry-serdes-types.adoc", "diffHunk": "@@ -0,0 +1,224 @@\n+// Module included in the following assemblies:\n+//  assembly-using-kafka-client-serdes\n+\n+[id='registry-serdes-types-serde-{context}']\n+= Configuring different SerDe types\n+\n+When using a schema technology in your Kafka applications, you must choose which specific schema type to use.  Common\n+options include:\n+\n+* Apache Avro\n+* JSON Schema\n+* Google Protobuf\n+\n+Which schema technology you choose is dependent on use-case and preference.  Of course Kafka allows you to implement\n+your own custom serializer and deserializer classes, so you are always free to write your own classes, including\n+leveraging {registry} functionality by utilizing the REST Client (see the \"Using the {registry} Java client\" section).\n+\n+For your convenience, {registry} provides out of the box SerDe classes for all three of the above schema technologies.\n+This section of the documentation explains how to configure Kafka applications to use each type.\n+\n+Using one of the serializer or deserializer classes provided by {registry} in your Kafka application is as simple\n+as setting the proper configuration properties.  Here are some simple examples of configuring producer and\n+consumer Kafka applications.\n+\n+.Configuring a Producer\n+\n+[source,java,subs=\"+quotes,attributes\"]\n+----\n+public Producer<Object,Object> createKafkaProducer(String kafkaBootstrapServers, String topicName) {\n+    Properties props = new Properties();\n+\n+    // Configure standard kafka settings\n+    props.putIfAbsent(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaBootstrapServers);\n+    props.putIfAbsent(ProducerConfig.CLIENT_ID_CONFIG, \"Producer-\" + topicName);\n+    props.putIfAbsent(ProducerConfig.ACKS_CONFIG, \"all\");\n+\n+    // Use a {registry} provided Kafka Serializer\n+    props.putIfAbsent(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,\n+        io.apicurio.registry.utils.serde.AvroKafkaSerializer.class.getName());\n+    props.putIfAbsent(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,\n+        io.apicurio.registry.utils.serde.AvroKafkaSerializer.class.getName());\n+\n+    // Configure {registry} location\n+    props.putIfAbsent(AbstractKafkaSerDe.REGISTRY_URL_CONFIG_PARAM, REGISTRY_URL);\n+    // Map the topic name (plus -key/value) to the artifactId in the registry\n+    props.putIfAbsent(AbstractKafkaSerializer.REGISTRY_ARTIFACT_ID_STRATEGY_CONFIG_PARAM,\n+        io.apicurio.registry.utils.serde.strategy.TopicIdStrategy.class.getName());\n+    // Get an existing schema or auto-register if not found\n+    props.putIfAbsent(AbstractKafkaSerializer.REGISTRY_GLOBAL_ID_STRATEGY_CONFIG_PARAM,\n+        io.apicurio.registry.utils.serde.strategy.GetOrCreateIdStrategy.class.getName());\n+\n+    // Create the Kafka producer\n+    Producer<Object, Object> producer = new KafkaProducer<>(props);\n+    return producer;\n+}\n+----\n+\n+.Configuring a Consumer\n+\n+[source,java,subs=\"+quotes,attributes\"]\n+----\n+public Consumer<Object,Object> createKafkaConsumer(String kafkaBootstrapServers, String topicName) {\n+    Properties props = new Properties();\n+\n+    // Configure standard Kafka settings\n+    props.putIfAbsent(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaBootstrapServers);\n+    props.putIfAbsent(ConsumerConfig.GROUP_ID_CONFIG, \"Consumer-\" + topicName);\n+    props.putIfAbsent(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \"true\");\n+    props.putIfAbsent(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, \"1000\");\n+    props.putIfAbsent(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n+\n+    // Use a {registry} provided Kafka Deserializer\n+    props.putIfAbsent(ProducerConfig.KEY_DESERIALIZER_CLASS_CONFIG,\n+        io.apicurio.registry.utils.serde.AvroKafkaDeserializer.class.getName());\n+    props.putIfAbsent(ProducerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,\n+        io.apicurio.registry.utils.serde.AvroKafkaDeserializer.class.getName());\n+\n+    // Configure {registry} location\n+    props.putIfAbsent(AbstractKafkaSerDe.REGISTRY_URL_CONFIG_PARAM, REGISTRY_URL);\n+    // No other configuration needed for the deserializer, because the globalId of the schema\n+    // the deserializer should use is sent as part of the message.  So the deserializer simply\n+    // extracts that globalId and uses it to look up the Schema from the registry.\n+\n+    // Create the Kafka Consumer\n+    KafkaConsumer<Long, GenericRecord> consumer = new KafkaConsumer<>(props);\n+    return consumer;\n+}\n+----\n+\n+\n+== Using Avro SerDe with {registry}\n+\n+{registry} provides serializer and deserializer classes for Apache Avro out of the box, to make using Avro as\n+easy as possible.  These classes are:\n+\n+* `io.apicurio.registry.utils.serde.AvroKafkaSerializer`\n+* `io.apicurio.registry.utils.serde.AvroKafkaDeserializer`\n+\n+=== Configuring the Avro serializer\n+\n+The Avro serializer class can be configured in the following ways:\n+\n+* {registry} location as a URL\n+* Artifact ID strategy (see the \"Strategies to lookup a schema\" section)\n+* Global ID strategy (see the \"Strategies to lookup a schema\" section)\n+* Global ID location\n+* Global ID handler\n+* Avro datum provider\n+* Avro encoding\n+\n+==== *Global ID location*\n+\n+The serializer is responsible for passing the unique global ID of the schema as part of the Kafka message so that\n+consumers can use the right schema for deserialization.  The location of that global ID can be in the payload of\n+the message or in the message headers.  The default approach is to pass the global ID in the message payload.  If\n+you want the ID sent in the message headers instead, you can set the following configuration property:\n+\n+`props.putIfAbsent(AbstractKafkaSerDe.USE_HEADERS, \"true\")`\n+\n+The property name is `apicurio.registry.use.headers`.\n+\n+\n+==== *Global ID handler*\n+\n+When passing the global ID in the message payload, it is possible to customize precisely how that is done.  Set\n+the configuration property `apicurio.registry.id-handler` to be a class that implements the", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bff8b4dcfcc628697676892336f6eec0e4d061f0"}, "originalPosition": 126}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxNzg4NDU1OnYy", "diffSide": "RIGHT", "path": "docs/modules/ROOT/partials/getting-started/con-registry-serdes-types.adoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNTo1NToxNVrOHpxO5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNTo1NToxNVrOHpxO5g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzU2MDI5NA==", "bodyText": "Suggest \"use cases\", hyphen not needed", "url": "https://github.com/Apicurio/apicurio-registry/pull/957#discussion_r513560294", "createdAt": "2020-10-28T15:55:15Z", "author": {"login": "smccarthy-ie"}, "path": "docs/modules/ROOT/partials/getting-started/con-registry-serdes-types.adoc", "diffHunk": "@@ -0,0 +1,224 @@\n+// Module included in the following assemblies:\n+//  assembly-using-kafka-client-serdes\n+\n+[id='registry-serdes-types-serde-{context}']\n+= Configuring different SerDe types\n+\n+When using a schema technology in your Kafka applications, you must choose which specific schema type to use.  Common\n+options include:\n+\n+* Apache Avro\n+* JSON Schema\n+* Google Protobuf\n+\n+Which schema technology you choose is dependent on use-case and preference.  Of course Kafka allows you to implement\n+your own custom serializer and deserializer classes, so you are always free to write your own classes, including\n+leveraging {registry} functionality by utilizing the REST Client (see the \"Using the {registry} Java client\" section).\n+\n+For your convenience, {registry} provides out of the box SerDe classes for all three of the above schema technologies.\n+This section of the documentation explains how to configure Kafka applications to use each type.\n+\n+Using one of the serializer or deserializer classes provided by {registry} in your Kafka application is as simple\n+as setting the proper configuration properties.  Here are some simple examples of configuring producer and\n+consumer Kafka applications.\n+\n+.Configuring a Producer\n+\n+[source,java,subs=\"+quotes,attributes\"]\n+----\n+public Producer<Object,Object> createKafkaProducer(String kafkaBootstrapServers, String topicName) {\n+    Properties props = new Properties();\n+\n+    // Configure standard kafka settings\n+    props.putIfAbsent(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaBootstrapServers);\n+    props.putIfAbsent(ProducerConfig.CLIENT_ID_CONFIG, \"Producer-\" + topicName);\n+    props.putIfAbsent(ProducerConfig.ACKS_CONFIG, \"all\");\n+\n+    // Use a {registry} provided Kafka Serializer\n+    props.putIfAbsent(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,\n+        io.apicurio.registry.utils.serde.AvroKafkaSerializer.class.getName());\n+    props.putIfAbsent(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,\n+        io.apicurio.registry.utils.serde.AvroKafkaSerializer.class.getName());\n+\n+    // Configure {registry} location\n+    props.putIfAbsent(AbstractKafkaSerDe.REGISTRY_URL_CONFIG_PARAM, REGISTRY_URL);\n+    // Map the topic name (plus -key/value) to the artifactId in the registry\n+    props.putIfAbsent(AbstractKafkaSerializer.REGISTRY_ARTIFACT_ID_STRATEGY_CONFIG_PARAM,\n+        io.apicurio.registry.utils.serde.strategy.TopicIdStrategy.class.getName());\n+    // Get an existing schema or auto-register if not found\n+    props.putIfAbsent(AbstractKafkaSerializer.REGISTRY_GLOBAL_ID_STRATEGY_CONFIG_PARAM,\n+        io.apicurio.registry.utils.serde.strategy.GetOrCreateIdStrategy.class.getName());\n+\n+    // Create the Kafka producer\n+    Producer<Object, Object> producer = new KafkaProducer<>(props);\n+    return producer;\n+}\n+----\n+\n+.Configuring a Consumer\n+\n+[source,java,subs=\"+quotes,attributes\"]\n+----\n+public Consumer<Object,Object> createKafkaConsumer(String kafkaBootstrapServers, String topicName) {\n+    Properties props = new Properties();\n+\n+    // Configure standard Kafka settings\n+    props.putIfAbsent(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaBootstrapServers);\n+    props.putIfAbsent(ConsumerConfig.GROUP_ID_CONFIG, \"Consumer-\" + topicName);\n+    props.putIfAbsent(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \"true\");\n+    props.putIfAbsent(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, \"1000\");\n+    props.putIfAbsent(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n+\n+    // Use a {registry} provided Kafka Deserializer\n+    props.putIfAbsent(ProducerConfig.KEY_DESERIALIZER_CLASS_CONFIG,\n+        io.apicurio.registry.utils.serde.AvroKafkaDeserializer.class.getName());\n+    props.putIfAbsent(ProducerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,\n+        io.apicurio.registry.utils.serde.AvroKafkaDeserializer.class.getName());\n+\n+    // Configure {registry} location\n+    props.putIfAbsent(AbstractKafkaSerDe.REGISTRY_URL_CONFIG_PARAM, REGISTRY_URL);\n+    // No other configuration needed for the deserializer, because the globalId of the schema\n+    // the deserializer should use is sent as part of the message.  So the deserializer simply\n+    // extracts that globalId and uses it to look up the Schema from the registry.\n+\n+    // Create the Kafka Consumer\n+    KafkaConsumer<Long, GenericRecord> consumer = new KafkaConsumer<>(props);\n+    return consumer;\n+}\n+----\n+\n+\n+== Using Avro SerDe with {registry}\n+\n+{registry} provides serializer and deserializer classes for Apache Avro out of the box, to make using Avro as\n+easy as possible.  These classes are:\n+\n+* `io.apicurio.registry.utils.serde.AvroKafkaSerializer`\n+* `io.apicurio.registry.utils.serde.AvroKafkaDeserializer`\n+\n+=== Configuring the Avro serializer\n+\n+The Avro serializer class can be configured in the following ways:\n+\n+* {registry} location as a URL\n+* Artifact ID strategy (see the \"Strategies to lookup a schema\" section)\n+* Global ID strategy (see the \"Strategies to lookup a schema\" section)\n+* Global ID location\n+* Global ID handler\n+* Avro datum provider\n+* Avro encoding\n+\n+==== *Global ID location*\n+\n+The serializer is responsible for passing the unique global ID of the schema as part of the Kafka message so that\n+consumers can use the right schema for deserialization.  The location of that global ID can be in the payload of\n+the message or in the message headers.  The default approach is to pass the global ID in the message payload.  If\n+you want the ID sent in the message headers instead, you can set the following configuration property:\n+\n+`props.putIfAbsent(AbstractKafkaSerDe.USE_HEADERS, \"true\")`\n+\n+The property name is `apicurio.registry.use.headers`.\n+\n+\n+==== *Global ID handler*\n+\n+When passing the global ID in the message payload, it is possible to customize precisely how that is done.  Set\n+the configuration property `apicurio.registry.id-handler` to be a class that implements the\n+`io.apicurio.registry.utils.serde.strategy.IdHandler` interface.  {registry} provides two implementations of\n+that interface:\n+\n+* `io.apicurio.registry.utils.serde.strategy.DefaultIdHandler` - stores the ID as an 8 byte long\n+* `io.apicurio.registry.utils.serde.strategy.Legacy4ByteIdHandler` - stores the ID as an 4 byte int\n+\n+{registry} represents the global ID of an artifact as a long, but for legacy reasons (or for compatibility with\n+other registries or serde classes) you may want to use 4 bytes when sending the ID.\n+\n+==== *Avro datum provider*\n+TBD\n+\n+==== *Avro encoding*\n+\n+When using Apache Avro to serializer data, it is common to use the Avro binary encoding format.  This is so that\n+the data is encoded in as efficient a format as possible.  However, Avro also supports encoding the data as JSON.\n+Encoding as JSON is useful because it is much easier to inspect the payload of each message, often for logging,\n+debugging, or other similar use-cases.  The {registry} Avro serializer can be configured to change the encoding\n+to JSON from the default (binary).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bff8b4dcfcc628697676892336f6eec0e4d061f0"}, "originalPosition": 145}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxNzg4NjEyOnYy", "diffSide": "RIGHT", "path": "docs/modules/ROOT/partials/getting-started/con-registry-serdes-types.adoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNTo1NTozMFrOHpxPwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNTo1NTozMFrOHpxPwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzU2MDUxMw==", "bodyText": "Suggest \"use case\", hyphen not needed", "url": "https://github.com/Apicurio/apicurio-registry/pull/957#discussion_r513560513", "createdAt": "2020-10-28T15:55:30Z", "author": {"login": "smccarthy-ie"}, "path": "docs/modules/ROOT/partials/getting-started/con-registry-serdes-types.adoc", "diffHunk": "@@ -0,0 +1,224 @@\n+// Module included in the following assemblies:\n+//  assembly-using-kafka-client-serdes\n+\n+[id='registry-serdes-types-serde-{context}']\n+= Configuring different SerDe types\n+\n+When using a schema technology in your Kafka applications, you must choose which specific schema type to use.  Common\n+options include:\n+\n+* Apache Avro\n+* JSON Schema\n+* Google Protobuf\n+\n+Which schema technology you choose is dependent on use-case and preference.  Of course Kafka allows you to implement", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bff8b4dcfcc628697676892336f6eec0e4d061f0"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxNzg5MjU5OnYy", "diffSide": "RIGHT", "path": "docs/modules/ROOT/partials/getting-started/con-registry-serdes-types.adoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNTo1Njo0N1rOHpxTtw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNTo1Njo0N1rOHpxTtw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzU2MTUyNw==", "bodyText": "Suggest sentence case heading \"Configuring a consumer\"", "url": "https://github.com/Apicurio/apicurio-registry/pull/957#discussion_r513561527", "createdAt": "2020-10-28T15:56:47Z", "author": {"login": "smccarthy-ie"}, "path": "docs/modules/ROOT/partials/getting-started/con-registry-serdes-types.adoc", "diffHunk": "@@ -0,0 +1,224 @@\n+// Module included in the following assemblies:\n+//  assembly-using-kafka-client-serdes\n+\n+[id='registry-serdes-types-serde-{context}']\n+= Configuring different SerDe types\n+\n+When using a schema technology in your Kafka applications, you must choose which specific schema type to use.  Common\n+options include:\n+\n+* Apache Avro\n+* JSON Schema\n+* Google Protobuf\n+\n+Which schema technology you choose is dependent on use-case and preference.  Of course Kafka allows you to implement\n+your own custom serializer and deserializer classes, so you are always free to write your own classes, including\n+leveraging {registry} functionality by utilizing the REST Client (see the \"Using the {registry} Java client\" section).\n+\n+For your convenience, {registry} provides out of the box SerDe classes for all three of the above schema technologies.\n+This section of the documentation explains how to configure Kafka applications to use each type.\n+\n+Using one of the serializer or deserializer classes provided by {registry} in your Kafka application is as simple\n+as setting the proper configuration properties.  Here are some simple examples of configuring producer and\n+consumer Kafka applications.\n+\n+.Configuring a Producer\n+\n+[source,java,subs=\"+quotes,attributes\"]\n+----\n+public Producer<Object,Object> createKafkaProducer(String kafkaBootstrapServers, String topicName) {\n+    Properties props = new Properties();\n+\n+    // Configure standard kafka settings\n+    props.putIfAbsent(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaBootstrapServers);\n+    props.putIfAbsent(ProducerConfig.CLIENT_ID_CONFIG, \"Producer-\" + topicName);\n+    props.putIfAbsent(ProducerConfig.ACKS_CONFIG, \"all\");\n+\n+    // Use a {registry} provided Kafka Serializer\n+    props.putIfAbsent(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,\n+        io.apicurio.registry.utils.serde.AvroKafkaSerializer.class.getName());\n+    props.putIfAbsent(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,\n+        io.apicurio.registry.utils.serde.AvroKafkaSerializer.class.getName());\n+\n+    // Configure {registry} location\n+    props.putIfAbsent(AbstractKafkaSerDe.REGISTRY_URL_CONFIG_PARAM, REGISTRY_URL);\n+    // Map the topic name (plus -key/value) to the artifactId in the registry\n+    props.putIfAbsent(AbstractKafkaSerializer.REGISTRY_ARTIFACT_ID_STRATEGY_CONFIG_PARAM,\n+        io.apicurio.registry.utils.serde.strategy.TopicIdStrategy.class.getName());\n+    // Get an existing schema or auto-register if not found\n+    props.putIfAbsent(AbstractKafkaSerializer.REGISTRY_GLOBAL_ID_STRATEGY_CONFIG_PARAM,\n+        io.apicurio.registry.utils.serde.strategy.GetOrCreateIdStrategy.class.getName());\n+\n+    // Create the Kafka producer\n+    Producer<Object, Object> producer = new KafkaProducer<>(props);\n+    return producer;\n+}\n+----\n+\n+.Configuring a Consumer", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bff8b4dcfcc628697676892336f6eec0e4d061f0"}, "originalPosition": 58}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxNzkxNzg2OnYy", "diffSide": "RIGHT", "path": "docs/modules/ROOT/partials/getting-started/con-registry-serdes-types.adoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNjowMToyMFrOHpxjVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNjowMToyMFrOHpxjVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzU2NTUyNQ==", "bodyText": "Suggest \"You must configure the Avro deserializer class to match the settings of the serializer. As a result, you can configure the deserializer in the following ways:\" (for active voice)", "url": "https://github.com/Apicurio/apicurio-registry/pull/957#discussion_r513565525", "createdAt": "2020-10-28T16:01:20Z", "author": {"login": "smccarthy-ie"}, "path": "docs/modules/ROOT/partials/getting-started/con-registry-serdes-types.adoc", "diffHunk": "@@ -0,0 +1,224 @@\n+// Module included in the following assemblies:\n+//  assembly-using-kafka-client-serdes\n+\n+[id='registry-serdes-types-serde-{context}']\n+= Configuring different SerDe types\n+\n+When using a schema technology in your Kafka applications, you must choose which specific schema type to use.  Common\n+options include:\n+\n+* Apache Avro\n+* JSON Schema\n+* Google Protobuf\n+\n+Which schema technology you choose is dependent on use-case and preference.  Of course Kafka allows you to implement\n+your own custom serializer and deserializer classes, so you are always free to write your own classes, including\n+leveraging {registry} functionality by utilizing the REST Client (see the \"Using the {registry} Java client\" section).\n+\n+For your convenience, {registry} provides out of the box SerDe classes for all three of the above schema technologies.\n+This section of the documentation explains how to configure Kafka applications to use each type.\n+\n+Using one of the serializer or deserializer classes provided by {registry} in your Kafka application is as simple\n+as setting the proper configuration properties.  Here are some simple examples of configuring producer and\n+consumer Kafka applications.\n+\n+.Configuring a Producer\n+\n+[source,java,subs=\"+quotes,attributes\"]\n+----\n+public Producer<Object,Object> createKafkaProducer(String kafkaBootstrapServers, String topicName) {\n+    Properties props = new Properties();\n+\n+    // Configure standard kafka settings\n+    props.putIfAbsent(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaBootstrapServers);\n+    props.putIfAbsent(ProducerConfig.CLIENT_ID_CONFIG, \"Producer-\" + topicName);\n+    props.putIfAbsent(ProducerConfig.ACKS_CONFIG, \"all\");\n+\n+    // Use a {registry} provided Kafka Serializer\n+    props.putIfAbsent(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,\n+        io.apicurio.registry.utils.serde.AvroKafkaSerializer.class.getName());\n+    props.putIfAbsent(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,\n+        io.apicurio.registry.utils.serde.AvroKafkaSerializer.class.getName());\n+\n+    // Configure {registry} location\n+    props.putIfAbsent(AbstractKafkaSerDe.REGISTRY_URL_CONFIG_PARAM, REGISTRY_URL);\n+    // Map the topic name (plus -key/value) to the artifactId in the registry\n+    props.putIfAbsent(AbstractKafkaSerializer.REGISTRY_ARTIFACT_ID_STRATEGY_CONFIG_PARAM,\n+        io.apicurio.registry.utils.serde.strategy.TopicIdStrategy.class.getName());\n+    // Get an existing schema or auto-register if not found\n+    props.putIfAbsent(AbstractKafkaSerializer.REGISTRY_GLOBAL_ID_STRATEGY_CONFIG_PARAM,\n+        io.apicurio.registry.utils.serde.strategy.GetOrCreateIdStrategy.class.getName());\n+\n+    // Create the Kafka producer\n+    Producer<Object, Object> producer = new KafkaProducer<>(props);\n+    return producer;\n+}\n+----\n+\n+.Configuring a Consumer\n+\n+[source,java,subs=\"+quotes,attributes\"]\n+----\n+public Consumer<Object,Object> createKafkaConsumer(String kafkaBootstrapServers, String topicName) {\n+    Properties props = new Properties();\n+\n+    // Configure standard Kafka settings\n+    props.putIfAbsent(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaBootstrapServers);\n+    props.putIfAbsent(ConsumerConfig.GROUP_ID_CONFIG, \"Consumer-\" + topicName);\n+    props.putIfAbsent(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \"true\");\n+    props.putIfAbsent(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, \"1000\");\n+    props.putIfAbsent(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n+\n+    // Use a {registry} provided Kafka Deserializer\n+    props.putIfAbsent(ProducerConfig.KEY_DESERIALIZER_CLASS_CONFIG,\n+        io.apicurio.registry.utils.serde.AvroKafkaDeserializer.class.getName());\n+    props.putIfAbsent(ProducerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,\n+        io.apicurio.registry.utils.serde.AvroKafkaDeserializer.class.getName());\n+\n+    // Configure {registry} location\n+    props.putIfAbsent(AbstractKafkaSerDe.REGISTRY_URL_CONFIG_PARAM, REGISTRY_URL);\n+    // No other configuration needed for the deserializer, because the globalId of the schema\n+    // the deserializer should use is sent as part of the message.  So the deserializer simply\n+    // extracts that globalId and uses it to look up the Schema from the registry.\n+\n+    // Create the Kafka Consumer\n+    KafkaConsumer<Long, GenericRecord> consumer = new KafkaConsumer<>(props);\n+    return consumer;\n+}\n+----\n+\n+\n+== Using Avro SerDe with {registry}\n+\n+{registry} provides serializer and deserializer classes for Apache Avro out of the box, to make using Avro as\n+easy as possible.  These classes are:\n+\n+* `io.apicurio.registry.utils.serde.AvroKafkaSerializer`\n+* `io.apicurio.registry.utils.serde.AvroKafkaDeserializer`\n+\n+=== Configuring the Avro serializer\n+\n+The Avro serializer class can be configured in the following ways:\n+\n+* {registry} location as a URL\n+* Artifact ID strategy (see the \"Strategies to lookup a schema\" section)\n+* Global ID strategy (see the \"Strategies to lookup a schema\" section)\n+* Global ID location\n+* Global ID handler\n+* Avro datum provider\n+* Avro encoding\n+\n+==== *Global ID location*\n+\n+The serializer is responsible for passing the unique global ID of the schema as part of the Kafka message so that\n+consumers can use the right schema for deserialization.  The location of that global ID can be in the payload of\n+the message or in the message headers.  The default approach is to pass the global ID in the message payload.  If\n+you want the ID sent in the message headers instead, you can set the following configuration property:\n+\n+`props.putIfAbsent(AbstractKafkaSerDe.USE_HEADERS, \"true\")`\n+\n+The property name is `apicurio.registry.use.headers`.\n+\n+\n+==== *Global ID handler*\n+\n+When passing the global ID in the message payload, it is possible to customize precisely how that is done.  Set\n+the configuration property `apicurio.registry.id-handler` to be a class that implements the\n+`io.apicurio.registry.utils.serde.strategy.IdHandler` interface.  {registry} provides two implementations of\n+that interface:\n+\n+* `io.apicurio.registry.utils.serde.strategy.DefaultIdHandler` - stores the ID as an 8 byte long\n+* `io.apicurio.registry.utils.serde.strategy.Legacy4ByteIdHandler` - stores the ID as an 4 byte int\n+\n+{registry} represents the global ID of an artifact as a long, but for legacy reasons (or for compatibility with\n+other registries or serde classes) you may want to use 4 bytes when sending the ID.\n+\n+==== *Avro datum provider*\n+TBD\n+\n+==== *Avro encoding*\n+\n+When using Apache Avro to serializer data, it is common to use the Avro binary encoding format.  This is so that\n+the data is encoded in as efficient a format as possible.  However, Avro also supports encoding the data as JSON.\n+Encoding as JSON is useful because it is much easier to inspect the payload of each message, often for logging,\n+debugging, or other similar use-cases.  The {registry} Avro serializer can be configured to change the encoding\n+to JSON from the default (binary).\n+\n+Set the Avro encoding to use by configuring the `apicurio.avro.encoding` property. The value must be either\n+`JSON` or `BINARY`.\n+\n+\n+=== Configuring the Avro deserializer\n+\n+The Avro deserializer class must be configured to match the settings of the serializer.  As a result, the\n+deserializer can be configured in the following ways:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bff8b4dcfcc628697676892336f6eec0e4d061f0"}, "originalPosition": 154}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3461, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}