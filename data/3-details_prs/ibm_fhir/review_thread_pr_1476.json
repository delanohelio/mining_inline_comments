{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDc5NjgyMzg5", "number": 1476, "reviewThreads": {"totalCount": 21, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNToyOTowOFrOEgbanA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNjowOTo0M1rOEgceIA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNDM5MDY4OnYy", "diffSide": "RIGHT", "path": "fhir-bucket/README.md", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNToyOTowOFrOHNSJFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNzowMzozMlrOHNVvSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzY5MDc3Mw==", "bodyText": "no closing of the code element ```", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483690773", "createdAt": "2020-09-04T15:29:08Z", "author": {"login": "prb112"}, "path": "fhir-bucket/README.md", "diffHunk": "@@ -0,0 +1,308 @@\n+## Synthetic Data Loader\n+Scans cloud object storage buckets and uploads data using the FHIR REST API\n+\n+### Background\n+\n+Synthea is a project for generating \"synthetic\" patient/population data for healthcare applications.\n+It generates realistic data based on census statistics and a lot of configuration.\n+It supports generating data in FHIR R4 \n+\n+This \"fhir-bucket\" project will help you upload Synthea-generated data to a FHIR R4 server.\n+\n+To facilitate high-volume load scenarios, multiple instances of the application can be run and their work coordinated so that each file is loaded exactly once.\n+\n+The loader records the identities of the created resources. These identities can be used in other test and load generator applications to access the data.\n+\n+### Steps\n+\n+1. Follow the steps at https://github.com/synthetichealth/synthea to clone and install Synthea\n+2. Configure Synthea to generate FHIR R4 resources\n+3. Generate a bunch of patients\n+4. Clone this repo and set it up with Maven/Eclipse\n+5. Configure the truststore with root certs required to trust connections to your FHIR server, cloud object store and tracking database\n+5. Tweak fhir.properties to point at your target FHIR server\n+6. Tweak cos.properties to point at your COS bucket\n+7. Tweak db.properties to point at your tracking database\n+8. Execute Main.class as described in the Running section below\n+\n+\n+### Configuration\n+\n+#### The cos.properties file\n+\n+```\n+# the IBM COS API key or S3 access key.\n+cos.api.key=\n+\n+# the IBM COS service instance id or S3 secret key.\n+cos.srvinstid=\n+\n+# the IBM COS or S3 End point URL.\n+cos.endpoint.url=\n+\n+# the IBM COS or S3 location.\n+cos.location=\n+\n+# the IBM COS or S3 bucket name to import from.\n+cos.bucket.name=\n+\n+# if use IBM credential(Y/N), default(Y).\n+cos.credential.ibm=Y\n+\n+# COS network timeouts\n+cos.request.timeout=60000\n+cos.socket.timeout=60000\n+\n+# The number of COS keys (items) to fetch per read\n+cos.max.keys=1000\n+```\n+\n+#### The db2.properties file\n+\n+```\n+db.host=<DB2-HOST-NAME>\n+db.port=<DB2-PORT>\n+db.database=<DB2-DATABASE>\n+user=<DB2-USER>\n+password=<DB2-PASSWORD>\n+sslConnection=true\n+sslTrustStoreLocation=/path/to/dbTruststore.p12\n+sslTrustStorePassword=<TRUSTSTORE-PASSWORD>\n+currentSchema=FHIRBUCKET\n+```\n+\n+#### The derby.properties file\n+\n+Db2 is the preferred database for hosting the fhir-bucket schema. Derby can, however, be used for development. The derby.properties file must be configured as follows:\n+\n+```\n+db.database=derby/bucketDB\n+db.create=Y\n+```\n+\n+\n+#### The postgres.properties file\n+\n+\n+\n+The name of the Derby database can be anything (without spaces) but must be contained within a folder called \"derby\".\n+\n+### Schema Deployment\n+\n+As a one-time activity, create the schema objects using the following command:\n+\n+```\n+#!/bin/bash\n+\n+JAR=\"~/git/FHIR/fhir-bucket/target/fhir-bucket-4.4.0-SNAPSHOT-cli.jar\"\n+\n+java -jar \"${JAR}\"               \\\n+  --db-type db2                  \\\n+  --db-properties db2.properties \\\n+  --create-schema\n+```\n+\n+If using a local Derby instance:\n+\n+```\n+#!/bin/bash\n+\n+JAR=\"~/git/FHIR/fhir-bucket/target/fhir-bucket-4.4.0-SNAPSHOT-cli.jar\"\n+\n+java -jar \"${JAR}\"                 \\\n+  --db-type derby                  \\\n+  --db-properties derby.properties \\\n+  --create-schema\n+```\n+\n+If using a local PostgreSQL instance:\n+\n+```\n+#!/bin/bash\n+\n+JAR=\"~/git/FHIR/fhir-bucket/target/fhir-bucket-4.4.0-SNAPSHOT-cli.jar\"\n+\n+java -jar \"${JAR}\"                    \\\n+  --db-type postgresql                \\\n+  --db-properties postgres.properties \\\n+  --create-schema\n+```\n+\n+This tracking database can be shared with the instance used by FHIR, but for proper performance testing it should be on a separate host. The standard schema for the tables is FHIRBUCKET.\n+\n+\n+### Running\n+\n+The following script can be used to run the bucket loader from a local build:\n+\n+```\n+#!/bin/bash\n+\n+JAR=\"~/git/FHIR/fhir-bucket/target/fhir-bucket-4.4.0-SNAPSHOT-cli.jar\"\n+\n+java -jar \"${JAR}\"                  \\\n+  --db-type db2                     \\\n+  --db-properties db2.properties    \\\n+  --cos-properties cos.properties   \\\n+  --fhir-properties fhir.properties \\\n+  --bucket example-bucket           \\\n+  --tenant-name example-tenant      \\\n+  --file-type NDJSON                \\\n+  --max-concurrent-fhir-requests 40 \\\n+  --max-concurrent-json-files 10    \\\n+  --max-concurrent-ndjson-files 1   \\\n+  --connection-pool-size 20         \\\n+  --incremental\n+```\n+\n+To run using Derby, change the relevant arguments to:\n+\n+```\n+...\n+  --db-type derby                   \\\n+  --db-properties derby.properties  \\\n+...\n+```\n+\n+To run using PostgreSQL, change the relevant arguments to:\n+\n+```\n+...\n+  --db-type postgresql                 \\\n+  --db-properties postgres.properties  \\\n+...\n+```\n+\n+| command-line options |\n+| ------- |\n+| `--incremental` </br> If the loader is stopped or fails before a bundle completes, the bundle will be reclaimed by another loader instance after the heartbeat timeout expires (60s). If the `--incremental` option is specified, the loader skips lines already processed in the NDJSON file. This is reasonably quick but is approximate, and may end up skipping rows due to threaded processing when the loader terminated. |\n+| `--incremental-exact` </br> the FHIRBUCKET tracking database is checked for every line in the NDJSON to see if any resources have been recorded for it, and if so, processing will be skipped. |\n+| `--db-type type` </br> where `type` is one of: db2, derby, postgresql. Specifies the type of database to use for the FHIRBUCKET tracking data. |\n+| `--db-properties properties-file` </br>  Connection properties file for the database |\n+| `--cos-properties properties-file` </br>  Connection properties file for COS | \n+| `--fhir-properties properties-file` </br> Connection properties file for the FHIR server |\n+| `--bucket cos-bucket-name` </br> The bucket name in COS |\n+| `--tenant-name fhir-tenant-name` </br> The IBM FHIR Server tenant name|\n+| `--file-type file-type` </br> One of: JSON, NDJSON. Used to limit the discovery scan to a particular type of file/entry |       \n+| `--max-concurrent-ndjson-files pool-size` </br> The maximum number of NDJSON files to read in parallel. Typically a small number, like the default which is 1. |\n+| `--max-concurrent-json-files pool-size` </br> The maximum number of JSON files to read in parallel. Each JSON file translates to a single FHIR request, which may be a single resource, or a bundle with many resources. |\n+| `--max-concurrent-fhir-requests pool-size` </br> The maximum number concurrent FHIR requests. For example, an NDJSON file may contain millions of records. Although a single NDJSON file is read sequentially, each resource (row) can be processed in parallel, up to this limit |\n+| `--connection-pool-size pool-size` </br> The maximum size of the database connection pool. Threads will block and wait if the current number of active connections exceeds this value |\n+| `--recycle-seconds seconds` </br> Artificially force discovered entries to be reloaded some time after they have been loaded successfully. This permits the loader to be set up in a continuous mode of operation, where the resource bundles are loaded over and over again, generating new resources to fill the target system with lots of data. The processing times for each load is tracked, so this can be used to look for regression.\n+| `--cos-scan-interval-ms millis` </br> The number of milliseconds to wait before scanning the COS bucket again to discover new entries |\n+| `--path-prefix prefix` </br> Limit the discovery scan to keys with the given prefix. |\n+| `--pool-shutdown-timeout-seconds seconds` </br> How many seconds to wait for the resource pool to shutdown when the loader has been asked to terminate. This value should be slightly longer than the Liberty transaction timeout.\n+| `--create-schema` </br> Creates a new or updates an existing database schema. The program will exit after the schema operations have completed.|\n+\n+\n+\n+\n+### Internals\n+\n+The purpose of fhir-bucket is to exercise the ingestion capability of the IBM FHIR Server (or any FHIR Server, for that matter). It scans IBM Cloud Object Store using the S3 connector and registers each matching entry in a tracking database.\n+\n+This tracking database is used to allocate these discovered entries (resource bundles) to loaders with free capacity. Several loader instances (JVMs) can be run in parallel and will coordinate their work using the common tracking database.\n+\n+When an instance of the fhir-bucket loader starts, it registers itself by creating a new entry in the loader_instances table. It periodically updates the heartbeat_tstamp of this record to publicize its liveness. Periodically, loader instances will perform a liveness check, looking for any other instances with an old heartbeat_tstamp. If the timestamp is considered too old, then the respective loader instance is considered to have failed. Any jobs it was running or had been assigned are cleared so that they can be picked up by another loader instance and hopefully completed successfully (see ClearStaleAllocations class).\n+\n+The COS scanner periodically scans COS to look for new items. It also checks each current item to see if the signature (size, modified time or etag hash) has changed. If a change is detected, the version number is incremented and any current allocation is cleared (recinded).\n+\n+The job allocation is performed by a thread in the `CosReader` class. This thread loops, asking the database to assign it new work when the loader has free capacity (see the AllocateJobs class). If the database assigns fewer jobs than the available capacity, this indicates we've run out of work to do so the loop will sleep for a short while before asking again so as not to overload the database.\n+\n+Each time a bundle is allocated to a loader for processing, a new record in RESOURCE_BUNDLE_LOADS is created. Any logical ids or errors generated during the processing of the bundle are recorded against the specific RESOURCE_BUNDLE_LOADS record. This permits tracking of multiple loads of the same bundle over time. The same bundle may be loaded multiple times if previous loads did not complete, or if recycling is enabled.\n+\n+Processing of files/entries from COS is performed with two thread pools. The first thread pool is used to parallelize the processing of individual files. This is useful when there are large numbers of files, e.g. one per patient.\n+\n+The second thread pool is used to process resources read from a file/entry. This is useful when the entries are NDJSON files which may contain millions of entries. The reader reads and validates each resource then submits the resource to the thread pool to parallelize the calls to FHIR.\n+\n+Limits are placed on the number of files/entries which can be allocated to a particular instance, as well as the number of resources which are currently inflight waiting to be processed. This is important to avoid unbounded memory growth. The goal is to keep the thread pool as busy as possible without consuming too much memory by reading and queueing too many resources (the assumption is that the fhir-bucket loader can read and validate resources more quickly than the FHIR server can process them).\n+\n+If the resource is a Bundle, then FHIR returns a bundle containing the newly assigned logical ids of every resource created from that bundle. Each of these logical ids is recorded in the LOGICAL_RESOURCES table in the tracking database.\n+\n+If the resource file/entry is not a Bundle, then FHIR returns the newly assigned logical id in the Location header. This value is also stored in the LOGICAL_RESOURCES table in the tracking database.\n+\n+\n+### Metrics\n+\n+The FHIRBUCKET schema tracks some useful statistics captured during the load runs which can be used to analyze performance.\n+\n+#### Schema\n+\n+| Table Name | Description |\n+| ---------- | ----------- |\n+| loader_instances | Each time a loader starts up it is allocated a unique loader_instances record |\n+| bucket_paths | The bucket name and item path up to the last / to avoid repeating the long path string for every item |\n+| resource_bundles | Represents a JSON or NDJSON file found in COS |\n+| resource_bundle_loads | Records each attempt to load a particular bundle |\n+| resource_bundle_errors | records errors by line. Includes HTTP response if available |\n+| resource_types | The FHIR model resource names |\n+| logical_resources | Holds the logical id for every resource created by the FHIR server |\n+\n+See the com.ibm.fhir.bucket.persistence.FhirBucketSchema class for details (columns and relationships) on the above tables.\n+\n+The `resource_bundle_loads` table contains timestamp fields marking the start and end of processing. The end time is only updated if the bundle is completed before the loader is stopped. \n+\n+Each `logical_resources` record contains a `created_tstamp` column which marks the time when the record was created in the FHIRBUCKET database.\n+\n+\n+\n+#### Db2 Analytic Queries\n+\n+To compute an approximate resources-per-second rate for each NDJSON bundle:\n+```\n+SET CURRENT SCHEMA FHIRBUCKET;\n+\n+SELECT loader_instance_id, substr(object_name, 1, 24) object_name, resource_type, resource_count, resource_count / run_seconds AS resources_per_second,\n+       timestampdiff(2, bundle_end - bundle_start) bundle_duration\n+  FROM (\n+       SELECT lr.loader_instance_id, resource_type_id, rb.object_name, count(*) AS resource_count,\n+              timestampdiff(2, max(lr.created_tstamp) - min(lr.created_tstamp)) run_seconds,\n+              min(rb.load_started) bundle_start,\n+              max(rb.load_completed) bundle_end\n+         FROM logical_resources lr,\n+              resource_bundles rb\n+        WHERE lr.loader_instance_id IS NOT NULL\n+          AND rb.resource_bundle_id = lr.resource_bundle_id\n+          AND rb.load_completed IS NOT NULL\n+     GROUP BY lr.loader_instance_id, resource_type_id, rb.object_name\n+     ) lr,\n+       resource_types rt\n+ WHERE rt.resource_type_id = lr.resource_type_id\n+   AND lr.run_seconds > 0\n+;\n+```\n+\n+The resource rate is calculated using the first and last creation timestamps from the logical_resources table.\n+\n+#### PostgreSQL Analytic Queries\n+\n+PostgreSQL uses a different mechanism for calculating the gap between two timestamps:\n+\n+```\n+SELECT abs(EXTRACT(EPOCH FROM end - start)) AS gap_in_seconds\n+  FROM ...\n+```\n+\n+The resource rate approximation query therefore becomes:\n+\n+```\n+SET search_path=FHIRBUCKET,PUBLIC;\n+\n+SELECT loader_instance_id, substr(object_name, 1, 24) object_name, resource_type, resource_count, resource_count / run_seconds AS resources_per_second,\n+       EXTRACT(EPOCH FROM bundle_end - bundle_start) AS bundle_duration\n+  FROM (\n+       SELECT lr.loader_instance_id, resource_type_id, rb.object_name, count(*) AS resource_count,\n+              EXTRACT(EPOCH FROM max(lr.created_tstamp) - min(lr.created_tstamp)) AS run_seconds,\n+              min(rb.load_started) bundle_start,\n+              max(rb.load_completed) bundle_end\n+         FROM logical_resources lr,\n+              resource_bundles rb\n+        WHERE lr.loader_instance_id IS NOT NULL\n+          AND rb.resource_bundle_id = lr.resource_bundle_id\n+          AND rb.load_completed IS NOT NULL\n+     GROUP BY lr.loader_instance_id, resource_type_id, rb.object_name\n+     ) lr,\n+       resource_types rt\n+ WHERE rt.resource_type_id = lr.resource_type_id\n+   AND lr.run_seconds > 0\n+;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 308}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc0MzE4NQ==", "bodyText": "fixed", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483743185", "createdAt": "2020-09-04T16:49:03Z", "author": {"login": "punktilious"}, "path": "fhir-bucket/README.md", "diffHunk": "@@ -0,0 +1,308 @@\n+## Synthetic Data Loader\n+Scans cloud object storage buckets and uploads data using the FHIR REST API\n+\n+### Background\n+\n+Synthea is a project for generating \"synthetic\" patient/population data for healthcare applications.\n+It generates realistic data based on census statistics and a lot of configuration.\n+It supports generating data in FHIR R4 \n+\n+This \"fhir-bucket\" project will help you upload Synthea-generated data to a FHIR R4 server.\n+\n+To facilitate high-volume load scenarios, multiple instances of the application can be run and their work coordinated so that each file is loaded exactly once.\n+\n+The loader records the identities of the created resources. These identities can be used in other test and load generator applications to access the data.\n+\n+### Steps\n+\n+1. Follow the steps at https://github.com/synthetichealth/synthea to clone and install Synthea\n+2. Configure Synthea to generate FHIR R4 resources\n+3. Generate a bunch of patients\n+4. Clone this repo and set it up with Maven/Eclipse\n+5. Configure the truststore with root certs required to trust connections to your FHIR server, cloud object store and tracking database\n+5. Tweak fhir.properties to point at your target FHIR server\n+6. Tweak cos.properties to point at your COS bucket\n+7. Tweak db.properties to point at your tracking database\n+8. Execute Main.class as described in the Running section below\n+\n+\n+### Configuration\n+\n+#### The cos.properties file\n+\n+```\n+# the IBM COS API key or S3 access key.\n+cos.api.key=\n+\n+# the IBM COS service instance id or S3 secret key.\n+cos.srvinstid=\n+\n+# the IBM COS or S3 End point URL.\n+cos.endpoint.url=\n+\n+# the IBM COS or S3 location.\n+cos.location=\n+\n+# the IBM COS or S3 bucket name to import from.\n+cos.bucket.name=\n+\n+# if use IBM credential(Y/N), default(Y).\n+cos.credential.ibm=Y\n+\n+# COS network timeouts\n+cos.request.timeout=60000\n+cos.socket.timeout=60000\n+\n+# The number of COS keys (items) to fetch per read\n+cos.max.keys=1000\n+```\n+\n+#### The db2.properties file\n+\n+```\n+db.host=<DB2-HOST-NAME>\n+db.port=<DB2-PORT>\n+db.database=<DB2-DATABASE>\n+user=<DB2-USER>\n+password=<DB2-PASSWORD>\n+sslConnection=true\n+sslTrustStoreLocation=/path/to/dbTruststore.p12\n+sslTrustStorePassword=<TRUSTSTORE-PASSWORD>\n+currentSchema=FHIRBUCKET\n+```\n+\n+#### The derby.properties file\n+\n+Db2 is the preferred database for hosting the fhir-bucket schema. Derby can, however, be used for development. The derby.properties file must be configured as follows:\n+\n+```\n+db.database=derby/bucketDB\n+db.create=Y\n+```\n+\n+\n+#### The postgres.properties file\n+\n+\n+\n+The name of the Derby database can be anything (without spaces) but must be contained within a folder called \"derby\".\n+\n+### Schema Deployment\n+\n+As a one-time activity, create the schema objects using the following command:\n+\n+```\n+#!/bin/bash\n+\n+JAR=\"~/git/FHIR/fhir-bucket/target/fhir-bucket-4.4.0-SNAPSHOT-cli.jar\"\n+\n+java -jar \"${JAR}\"               \\\n+  --db-type db2                  \\\n+  --db-properties db2.properties \\\n+  --create-schema\n+```\n+\n+If using a local Derby instance:\n+\n+```\n+#!/bin/bash\n+\n+JAR=\"~/git/FHIR/fhir-bucket/target/fhir-bucket-4.4.0-SNAPSHOT-cli.jar\"\n+\n+java -jar \"${JAR}\"                 \\\n+  --db-type derby                  \\\n+  --db-properties derby.properties \\\n+  --create-schema\n+```\n+\n+If using a local PostgreSQL instance:\n+\n+```\n+#!/bin/bash\n+\n+JAR=\"~/git/FHIR/fhir-bucket/target/fhir-bucket-4.4.0-SNAPSHOT-cli.jar\"\n+\n+java -jar \"${JAR}\"                    \\\n+  --db-type postgresql                \\\n+  --db-properties postgres.properties \\\n+  --create-schema\n+```\n+\n+This tracking database can be shared with the instance used by FHIR, but for proper performance testing it should be on a separate host. The standard schema for the tables is FHIRBUCKET.\n+\n+\n+### Running\n+\n+The following script can be used to run the bucket loader from a local build:\n+\n+```\n+#!/bin/bash\n+\n+JAR=\"~/git/FHIR/fhir-bucket/target/fhir-bucket-4.4.0-SNAPSHOT-cli.jar\"\n+\n+java -jar \"${JAR}\"                  \\\n+  --db-type db2                     \\\n+  --db-properties db2.properties    \\\n+  --cos-properties cos.properties   \\\n+  --fhir-properties fhir.properties \\\n+  --bucket example-bucket           \\\n+  --tenant-name example-tenant      \\\n+  --file-type NDJSON                \\\n+  --max-concurrent-fhir-requests 40 \\\n+  --max-concurrent-json-files 10    \\\n+  --max-concurrent-ndjson-files 1   \\\n+  --connection-pool-size 20         \\\n+  --incremental\n+```\n+\n+To run using Derby, change the relevant arguments to:\n+\n+```\n+...\n+  --db-type derby                   \\\n+  --db-properties derby.properties  \\\n+...\n+```\n+\n+To run using PostgreSQL, change the relevant arguments to:\n+\n+```\n+...\n+  --db-type postgresql                 \\\n+  --db-properties postgres.properties  \\\n+...\n+```\n+\n+| command-line options |\n+| ------- |\n+| `--incremental` </br> If the loader is stopped or fails before a bundle completes, the bundle will be reclaimed by another loader instance after the heartbeat timeout expires (60s). If the `--incremental` option is specified, the loader skips lines already processed in the NDJSON file. This is reasonably quick but is approximate, and may end up skipping rows due to threaded processing when the loader terminated. |\n+| `--incremental-exact` </br> the FHIRBUCKET tracking database is checked for every line in the NDJSON to see if any resources have been recorded for it, and if so, processing will be skipped. |\n+| `--db-type type` </br> where `type` is one of: db2, derby, postgresql. Specifies the type of database to use for the FHIRBUCKET tracking data. |\n+| `--db-properties properties-file` </br>  Connection properties file for the database |\n+| `--cos-properties properties-file` </br>  Connection properties file for COS | \n+| `--fhir-properties properties-file` </br> Connection properties file for the FHIR server |\n+| `--bucket cos-bucket-name` </br> The bucket name in COS |\n+| `--tenant-name fhir-tenant-name` </br> The IBM FHIR Server tenant name|\n+| `--file-type file-type` </br> One of: JSON, NDJSON. Used to limit the discovery scan to a particular type of file/entry |       \n+| `--max-concurrent-ndjson-files pool-size` </br> The maximum number of NDJSON files to read in parallel. Typically a small number, like the default which is 1. |\n+| `--max-concurrent-json-files pool-size` </br> The maximum number of JSON files to read in parallel. Each JSON file translates to a single FHIR request, which may be a single resource, or a bundle with many resources. |\n+| `--max-concurrent-fhir-requests pool-size` </br> The maximum number concurrent FHIR requests. For example, an NDJSON file may contain millions of records. Although a single NDJSON file is read sequentially, each resource (row) can be processed in parallel, up to this limit |\n+| `--connection-pool-size pool-size` </br> The maximum size of the database connection pool. Threads will block and wait if the current number of active connections exceeds this value |\n+| `--recycle-seconds seconds` </br> Artificially force discovered entries to be reloaded some time after they have been loaded successfully. This permits the loader to be set up in a continuous mode of operation, where the resource bundles are loaded over and over again, generating new resources to fill the target system with lots of data. The processing times for each load is tracked, so this can be used to look for regression.\n+| `--cos-scan-interval-ms millis` </br> The number of milliseconds to wait before scanning the COS bucket again to discover new entries |\n+| `--path-prefix prefix` </br> Limit the discovery scan to keys with the given prefix. |\n+| `--pool-shutdown-timeout-seconds seconds` </br> How many seconds to wait for the resource pool to shutdown when the loader has been asked to terminate. This value should be slightly longer than the Liberty transaction timeout.\n+| `--create-schema` </br> Creates a new or updates an existing database schema. The program will exit after the schema operations have completed.|\n+\n+\n+\n+\n+### Internals\n+\n+The purpose of fhir-bucket is to exercise the ingestion capability of the IBM FHIR Server (or any FHIR Server, for that matter). It scans IBM Cloud Object Store using the S3 connector and registers each matching entry in a tracking database.\n+\n+This tracking database is used to allocate these discovered entries (resource bundles) to loaders with free capacity. Several loader instances (JVMs) can be run in parallel and will coordinate their work using the common tracking database.\n+\n+When an instance of the fhir-bucket loader starts, it registers itself by creating a new entry in the loader_instances table. It periodically updates the heartbeat_tstamp of this record to publicize its liveness. Periodically, loader instances will perform a liveness check, looking for any other instances with an old heartbeat_tstamp. If the timestamp is considered too old, then the respective loader instance is considered to have failed. Any jobs it was running or had been assigned are cleared so that they can be picked up by another loader instance and hopefully completed successfully (see ClearStaleAllocations class).\n+\n+The COS scanner periodically scans COS to look for new items. It also checks each current item to see if the signature (size, modified time or etag hash) has changed. If a change is detected, the version number is incremented and any current allocation is cleared (recinded).\n+\n+The job allocation is performed by a thread in the `CosReader` class. This thread loops, asking the database to assign it new work when the loader has free capacity (see the AllocateJobs class). If the database assigns fewer jobs than the available capacity, this indicates we've run out of work to do so the loop will sleep for a short while before asking again so as not to overload the database.\n+\n+Each time a bundle is allocated to a loader for processing, a new record in RESOURCE_BUNDLE_LOADS is created. Any logical ids or errors generated during the processing of the bundle are recorded against the specific RESOURCE_BUNDLE_LOADS record. This permits tracking of multiple loads of the same bundle over time. The same bundle may be loaded multiple times if previous loads did not complete, or if recycling is enabled.\n+\n+Processing of files/entries from COS is performed with two thread pools. The first thread pool is used to parallelize the processing of individual files. This is useful when there are large numbers of files, e.g. one per patient.\n+\n+The second thread pool is used to process resources read from a file/entry. This is useful when the entries are NDJSON files which may contain millions of entries. The reader reads and validates each resource then submits the resource to the thread pool to parallelize the calls to FHIR.\n+\n+Limits are placed on the number of files/entries which can be allocated to a particular instance, as well as the number of resources which are currently inflight waiting to be processed. This is important to avoid unbounded memory growth. The goal is to keep the thread pool as busy as possible without consuming too much memory by reading and queueing too many resources (the assumption is that the fhir-bucket loader can read and validate resources more quickly than the FHIR server can process them).\n+\n+If the resource is a Bundle, then FHIR returns a bundle containing the newly assigned logical ids of every resource created from that bundle. Each of these logical ids is recorded in the LOGICAL_RESOURCES table in the tracking database.\n+\n+If the resource file/entry is not a Bundle, then FHIR returns the newly assigned logical id in the Location header. This value is also stored in the LOGICAL_RESOURCES table in the tracking database.\n+\n+\n+### Metrics\n+\n+The FHIRBUCKET schema tracks some useful statistics captured during the load runs which can be used to analyze performance.\n+\n+#### Schema\n+\n+| Table Name | Description |\n+| ---------- | ----------- |\n+| loader_instances | Each time a loader starts up it is allocated a unique loader_instances record |\n+| bucket_paths | The bucket name and item path up to the last / to avoid repeating the long path string for every item |\n+| resource_bundles | Represents a JSON or NDJSON file found in COS |\n+| resource_bundle_loads | Records each attempt to load a particular bundle |\n+| resource_bundle_errors | records errors by line. Includes HTTP response if available |\n+| resource_types | The FHIR model resource names |\n+| logical_resources | Holds the logical id for every resource created by the FHIR server |\n+\n+See the com.ibm.fhir.bucket.persistence.FhirBucketSchema class for details (columns and relationships) on the above tables.\n+\n+The `resource_bundle_loads` table contains timestamp fields marking the start and end of processing. The end time is only updated if the bundle is completed before the loader is stopped. \n+\n+Each `logical_resources` record contains a `created_tstamp` column which marks the time when the record was created in the FHIRBUCKET database.\n+\n+\n+\n+#### Db2 Analytic Queries\n+\n+To compute an approximate resources-per-second rate for each NDJSON bundle:\n+```\n+SET CURRENT SCHEMA FHIRBUCKET;\n+\n+SELECT loader_instance_id, substr(object_name, 1, 24) object_name, resource_type, resource_count, resource_count / run_seconds AS resources_per_second,\n+       timestampdiff(2, bundle_end - bundle_start) bundle_duration\n+  FROM (\n+       SELECT lr.loader_instance_id, resource_type_id, rb.object_name, count(*) AS resource_count,\n+              timestampdiff(2, max(lr.created_tstamp) - min(lr.created_tstamp)) run_seconds,\n+              min(rb.load_started) bundle_start,\n+              max(rb.load_completed) bundle_end\n+         FROM logical_resources lr,\n+              resource_bundles rb\n+        WHERE lr.loader_instance_id IS NOT NULL\n+          AND rb.resource_bundle_id = lr.resource_bundle_id\n+          AND rb.load_completed IS NOT NULL\n+     GROUP BY lr.loader_instance_id, resource_type_id, rb.object_name\n+     ) lr,\n+       resource_types rt\n+ WHERE rt.resource_type_id = lr.resource_type_id\n+   AND lr.run_seconds > 0\n+;\n+```\n+\n+The resource rate is calculated using the first and last creation timestamps from the logical_resources table.\n+\n+#### PostgreSQL Analytic Queries\n+\n+PostgreSQL uses a different mechanism for calculating the gap between two timestamps:\n+\n+```\n+SELECT abs(EXTRACT(EPOCH FROM end - start)) AS gap_in_seconds\n+  FROM ...\n+```\n+\n+The resource rate approximation query therefore becomes:\n+\n+```\n+SET search_path=FHIRBUCKET,PUBLIC;\n+\n+SELECT loader_instance_id, substr(object_name, 1, 24) object_name, resource_type, resource_count, resource_count / run_seconds AS resources_per_second,\n+       EXTRACT(EPOCH FROM bundle_end - bundle_start) AS bundle_duration\n+  FROM (\n+       SELECT lr.loader_instance_id, resource_type_id, rb.object_name, count(*) AS resource_count,\n+              EXTRACT(EPOCH FROM max(lr.created_tstamp) - min(lr.created_tstamp)) AS run_seconds,\n+              min(rb.load_started) bundle_start,\n+              max(rb.load_completed) bundle_end\n+         FROM logical_resources lr,\n+              resource_bundles rb\n+        WHERE lr.loader_instance_id IS NOT NULL\n+          AND rb.resource_bundle_id = lr.resource_bundle_id\n+          AND rb.load_completed IS NOT NULL\n+     GROUP BY lr.loader_instance_id, resource_type_id, rb.object_name\n+     ) lr,\n+       resource_types rt\n+ WHERE rt.resource_type_id = lr.resource_type_id\n+   AND lr.run_seconds > 0\n+;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzY5MDc3Mw=="}, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 308}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc0OTcwNg==", "bodyText": "fixed", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483749706", "createdAt": "2020-09-04T17:03:32Z", "author": {"login": "punktilious"}, "path": "fhir-bucket/README.md", "diffHunk": "@@ -0,0 +1,308 @@\n+## Synthetic Data Loader\n+Scans cloud object storage buckets and uploads data using the FHIR REST API\n+\n+### Background\n+\n+Synthea is a project for generating \"synthetic\" patient/population data for healthcare applications.\n+It generates realistic data based on census statistics and a lot of configuration.\n+It supports generating data in FHIR R4 \n+\n+This \"fhir-bucket\" project will help you upload Synthea-generated data to a FHIR R4 server.\n+\n+To facilitate high-volume load scenarios, multiple instances of the application can be run and their work coordinated so that each file is loaded exactly once.\n+\n+The loader records the identities of the created resources. These identities can be used in other test and load generator applications to access the data.\n+\n+### Steps\n+\n+1. Follow the steps at https://github.com/synthetichealth/synthea to clone and install Synthea\n+2. Configure Synthea to generate FHIR R4 resources\n+3. Generate a bunch of patients\n+4. Clone this repo and set it up with Maven/Eclipse\n+5. Configure the truststore with root certs required to trust connections to your FHIR server, cloud object store and tracking database\n+5. Tweak fhir.properties to point at your target FHIR server\n+6. Tweak cos.properties to point at your COS bucket\n+7. Tweak db.properties to point at your tracking database\n+8. Execute Main.class as described in the Running section below\n+\n+\n+### Configuration\n+\n+#### The cos.properties file\n+\n+```\n+# the IBM COS API key or S3 access key.\n+cos.api.key=\n+\n+# the IBM COS service instance id or S3 secret key.\n+cos.srvinstid=\n+\n+# the IBM COS or S3 End point URL.\n+cos.endpoint.url=\n+\n+# the IBM COS or S3 location.\n+cos.location=\n+\n+# the IBM COS or S3 bucket name to import from.\n+cos.bucket.name=\n+\n+# if use IBM credential(Y/N), default(Y).\n+cos.credential.ibm=Y\n+\n+# COS network timeouts\n+cos.request.timeout=60000\n+cos.socket.timeout=60000\n+\n+# The number of COS keys (items) to fetch per read\n+cos.max.keys=1000\n+```\n+\n+#### The db2.properties file\n+\n+```\n+db.host=<DB2-HOST-NAME>\n+db.port=<DB2-PORT>\n+db.database=<DB2-DATABASE>\n+user=<DB2-USER>\n+password=<DB2-PASSWORD>\n+sslConnection=true\n+sslTrustStoreLocation=/path/to/dbTruststore.p12\n+sslTrustStorePassword=<TRUSTSTORE-PASSWORD>\n+currentSchema=FHIRBUCKET\n+```\n+\n+#### The derby.properties file\n+\n+Db2 is the preferred database for hosting the fhir-bucket schema. Derby can, however, be used for development. The derby.properties file must be configured as follows:\n+\n+```\n+db.database=derby/bucketDB\n+db.create=Y\n+```\n+\n+\n+#### The postgres.properties file\n+\n+\n+\n+The name of the Derby database can be anything (without spaces) but must be contained within a folder called \"derby\".\n+\n+### Schema Deployment\n+\n+As a one-time activity, create the schema objects using the following command:\n+\n+```\n+#!/bin/bash\n+\n+JAR=\"~/git/FHIR/fhir-bucket/target/fhir-bucket-4.4.0-SNAPSHOT-cli.jar\"\n+\n+java -jar \"${JAR}\"               \\\n+  --db-type db2                  \\\n+  --db-properties db2.properties \\\n+  --create-schema\n+```\n+\n+If using a local Derby instance:\n+\n+```\n+#!/bin/bash\n+\n+JAR=\"~/git/FHIR/fhir-bucket/target/fhir-bucket-4.4.0-SNAPSHOT-cli.jar\"\n+\n+java -jar \"${JAR}\"                 \\\n+  --db-type derby                  \\\n+  --db-properties derby.properties \\\n+  --create-schema\n+```\n+\n+If using a local PostgreSQL instance:\n+\n+```\n+#!/bin/bash\n+\n+JAR=\"~/git/FHIR/fhir-bucket/target/fhir-bucket-4.4.0-SNAPSHOT-cli.jar\"\n+\n+java -jar \"${JAR}\"                    \\\n+  --db-type postgresql                \\\n+  --db-properties postgres.properties \\\n+  --create-schema\n+```\n+\n+This tracking database can be shared with the instance used by FHIR, but for proper performance testing it should be on a separate host. The standard schema for the tables is FHIRBUCKET.\n+\n+\n+### Running\n+\n+The following script can be used to run the bucket loader from a local build:\n+\n+```\n+#!/bin/bash\n+\n+JAR=\"~/git/FHIR/fhir-bucket/target/fhir-bucket-4.4.0-SNAPSHOT-cli.jar\"\n+\n+java -jar \"${JAR}\"                  \\\n+  --db-type db2                     \\\n+  --db-properties db2.properties    \\\n+  --cos-properties cos.properties   \\\n+  --fhir-properties fhir.properties \\\n+  --bucket example-bucket           \\\n+  --tenant-name example-tenant      \\\n+  --file-type NDJSON                \\\n+  --max-concurrent-fhir-requests 40 \\\n+  --max-concurrent-json-files 10    \\\n+  --max-concurrent-ndjson-files 1   \\\n+  --connection-pool-size 20         \\\n+  --incremental\n+```\n+\n+To run using Derby, change the relevant arguments to:\n+\n+```\n+...\n+  --db-type derby                   \\\n+  --db-properties derby.properties  \\\n+...\n+```\n+\n+To run using PostgreSQL, change the relevant arguments to:\n+\n+```\n+...\n+  --db-type postgresql                 \\\n+  --db-properties postgres.properties  \\\n+...\n+```\n+\n+| command-line options |\n+| ------- |\n+| `--incremental` </br> If the loader is stopped or fails before a bundle completes, the bundle will be reclaimed by another loader instance after the heartbeat timeout expires (60s). If the `--incremental` option is specified, the loader skips lines already processed in the NDJSON file. This is reasonably quick but is approximate, and may end up skipping rows due to threaded processing when the loader terminated. |\n+| `--incremental-exact` </br> the FHIRBUCKET tracking database is checked for every line in the NDJSON to see if any resources have been recorded for it, and if so, processing will be skipped. |\n+| `--db-type type` </br> where `type` is one of: db2, derby, postgresql. Specifies the type of database to use for the FHIRBUCKET tracking data. |\n+| `--db-properties properties-file` </br>  Connection properties file for the database |\n+| `--cos-properties properties-file` </br>  Connection properties file for COS | \n+| `--fhir-properties properties-file` </br> Connection properties file for the FHIR server |\n+| `--bucket cos-bucket-name` </br> The bucket name in COS |\n+| `--tenant-name fhir-tenant-name` </br> The IBM FHIR Server tenant name|\n+| `--file-type file-type` </br> One of: JSON, NDJSON. Used to limit the discovery scan to a particular type of file/entry |       \n+| `--max-concurrent-ndjson-files pool-size` </br> The maximum number of NDJSON files to read in parallel. Typically a small number, like the default which is 1. |\n+| `--max-concurrent-json-files pool-size` </br> The maximum number of JSON files to read in parallel. Each JSON file translates to a single FHIR request, which may be a single resource, or a bundle with many resources. |\n+| `--max-concurrent-fhir-requests pool-size` </br> The maximum number concurrent FHIR requests. For example, an NDJSON file may contain millions of records. Although a single NDJSON file is read sequentially, each resource (row) can be processed in parallel, up to this limit |\n+| `--connection-pool-size pool-size` </br> The maximum size of the database connection pool. Threads will block and wait if the current number of active connections exceeds this value |\n+| `--recycle-seconds seconds` </br> Artificially force discovered entries to be reloaded some time after they have been loaded successfully. This permits the loader to be set up in a continuous mode of operation, where the resource bundles are loaded over and over again, generating new resources to fill the target system with lots of data. The processing times for each load is tracked, so this can be used to look for regression.\n+| `--cos-scan-interval-ms millis` </br> The number of milliseconds to wait before scanning the COS bucket again to discover new entries |\n+| `--path-prefix prefix` </br> Limit the discovery scan to keys with the given prefix. |\n+| `--pool-shutdown-timeout-seconds seconds` </br> How many seconds to wait for the resource pool to shutdown when the loader has been asked to terminate. This value should be slightly longer than the Liberty transaction timeout.\n+| `--create-schema` </br> Creates a new or updates an existing database schema. The program will exit after the schema operations have completed.|\n+\n+\n+\n+\n+### Internals\n+\n+The purpose of fhir-bucket is to exercise the ingestion capability of the IBM FHIR Server (or any FHIR Server, for that matter). It scans IBM Cloud Object Store using the S3 connector and registers each matching entry in a tracking database.\n+\n+This tracking database is used to allocate these discovered entries (resource bundles) to loaders with free capacity. Several loader instances (JVMs) can be run in parallel and will coordinate their work using the common tracking database.\n+\n+When an instance of the fhir-bucket loader starts, it registers itself by creating a new entry in the loader_instances table. It periodically updates the heartbeat_tstamp of this record to publicize its liveness. Periodically, loader instances will perform a liveness check, looking for any other instances with an old heartbeat_tstamp. If the timestamp is considered too old, then the respective loader instance is considered to have failed. Any jobs it was running or had been assigned are cleared so that they can be picked up by another loader instance and hopefully completed successfully (see ClearStaleAllocations class).\n+\n+The COS scanner periodically scans COS to look for new items. It also checks each current item to see if the signature (size, modified time or etag hash) has changed. If a change is detected, the version number is incremented and any current allocation is cleared (recinded).\n+\n+The job allocation is performed by a thread in the `CosReader` class. This thread loops, asking the database to assign it new work when the loader has free capacity (see the AllocateJobs class). If the database assigns fewer jobs than the available capacity, this indicates we've run out of work to do so the loop will sleep for a short while before asking again so as not to overload the database.\n+\n+Each time a bundle is allocated to a loader for processing, a new record in RESOURCE_BUNDLE_LOADS is created. Any logical ids or errors generated during the processing of the bundle are recorded against the specific RESOURCE_BUNDLE_LOADS record. This permits tracking of multiple loads of the same bundle over time. The same bundle may be loaded multiple times if previous loads did not complete, or if recycling is enabled.\n+\n+Processing of files/entries from COS is performed with two thread pools. The first thread pool is used to parallelize the processing of individual files. This is useful when there are large numbers of files, e.g. one per patient.\n+\n+The second thread pool is used to process resources read from a file/entry. This is useful when the entries are NDJSON files which may contain millions of entries. The reader reads and validates each resource then submits the resource to the thread pool to parallelize the calls to FHIR.\n+\n+Limits are placed on the number of files/entries which can be allocated to a particular instance, as well as the number of resources which are currently inflight waiting to be processed. This is important to avoid unbounded memory growth. The goal is to keep the thread pool as busy as possible without consuming too much memory by reading and queueing too many resources (the assumption is that the fhir-bucket loader can read and validate resources more quickly than the FHIR server can process them).\n+\n+If the resource is a Bundle, then FHIR returns a bundle containing the newly assigned logical ids of every resource created from that bundle. Each of these logical ids is recorded in the LOGICAL_RESOURCES table in the tracking database.\n+\n+If the resource file/entry is not a Bundle, then FHIR returns the newly assigned logical id in the Location header. This value is also stored in the LOGICAL_RESOURCES table in the tracking database.\n+\n+\n+### Metrics\n+\n+The FHIRBUCKET schema tracks some useful statistics captured during the load runs which can be used to analyze performance.\n+\n+#### Schema\n+\n+| Table Name | Description |\n+| ---------- | ----------- |\n+| loader_instances | Each time a loader starts up it is allocated a unique loader_instances record |\n+| bucket_paths | The bucket name and item path up to the last / to avoid repeating the long path string for every item |\n+| resource_bundles | Represents a JSON or NDJSON file found in COS |\n+| resource_bundle_loads | Records each attempt to load a particular bundle |\n+| resource_bundle_errors | records errors by line. Includes HTTP response if available |\n+| resource_types | The FHIR model resource names |\n+| logical_resources | Holds the logical id for every resource created by the FHIR server |\n+\n+See the com.ibm.fhir.bucket.persistence.FhirBucketSchema class for details (columns and relationships) on the above tables.\n+\n+The `resource_bundle_loads` table contains timestamp fields marking the start and end of processing. The end time is only updated if the bundle is completed before the loader is stopped. \n+\n+Each `logical_resources` record contains a `created_tstamp` column which marks the time when the record was created in the FHIRBUCKET database.\n+\n+\n+\n+#### Db2 Analytic Queries\n+\n+To compute an approximate resources-per-second rate for each NDJSON bundle:\n+```\n+SET CURRENT SCHEMA FHIRBUCKET;\n+\n+SELECT loader_instance_id, substr(object_name, 1, 24) object_name, resource_type, resource_count, resource_count / run_seconds AS resources_per_second,\n+       timestampdiff(2, bundle_end - bundle_start) bundle_duration\n+  FROM (\n+       SELECT lr.loader_instance_id, resource_type_id, rb.object_name, count(*) AS resource_count,\n+              timestampdiff(2, max(lr.created_tstamp) - min(lr.created_tstamp)) run_seconds,\n+              min(rb.load_started) bundle_start,\n+              max(rb.load_completed) bundle_end\n+         FROM logical_resources lr,\n+              resource_bundles rb\n+        WHERE lr.loader_instance_id IS NOT NULL\n+          AND rb.resource_bundle_id = lr.resource_bundle_id\n+          AND rb.load_completed IS NOT NULL\n+     GROUP BY lr.loader_instance_id, resource_type_id, rb.object_name\n+     ) lr,\n+       resource_types rt\n+ WHERE rt.resource_type_id = lr.resource_type_id\n+   AND lr.run_seconds > 0\n+;\n+```\n+\n+The resource rate is calculated using the first and last creation timestamps from the logical_resources table.\n+\n+#### PostgreSQL Analytic Queries\n+\n+PostgreSQL uses a different mechanism for calculating the gap between two timestamps:\n+\n+```\n+SELECT abs(EXTRACT(EPOCH FROM end - start)) AS gap_in_seconds\n+  FROM ...\n+```\n+\n+The resource rate approximation query therefore becomes:\n+\n+```\n+SET search_path=FHIRBUCKET,PUBLIC;\n+\n+SELECT loader_instance_id, substr(object_name, 1, 24) object_name, resource_type, resource_count, resource_count / run_seconds AS resources_per_second,\n+       EXTRACT(EPOCH FROM bundle_end - bundle_start) AS bundle_duration\n+  FROM (\n+       SELECT lr.loader_instance_id, resource_type_id, rb.object_name, count(*) AS resource_count,\n+              EXTRACT(EPOCH FROM max(lr.created_tstamp) - min(lr.created_tstamp)) AS run_seconds,\n+              min(rb.load_started) bundle_start,\n+              max(rb.load_completed) bundle_end\n+         FROM logical_resources lr,\n+              resource_bundles rb\n+        WHERE lr.loader_instance_id IS NOT NULL\n+          AND rb.resource_bundle_id = lr.resource_bundle_id\n+          AND rb.load_completed IS NOT NULL\n+     GROUP BY lr.loader_instance_id, resource_type_id, rb.object_name\n+     ) lr,\n+       resource_types rt\n+ WHERE rt.resource_type_id = lr.resource_type_id\n+   AND lr.run_seconds > 0\n+;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzY5MDc3Mw=="}, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 308}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNDQwNzQ0OnYy", "diffSide": "RIGHT", "path": "fhir-bucket/Dockerfile", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNTozMTo1NlrOHNSS1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNzowMzowNFrOHNVumw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzY5MzI2OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            FROM xxxxx\n          \n          \n            \n            # ----------------------------------------------------------------------------\n          \n          \n            \n            # (C) Copyright IBM Corp. 2020\n          \n          \n            \n            #\n          \n          \n            \n            # SPDX-License-Identifier: Apache-2.0\n          \n          \n            \n            # ----------------------------------------------------------------------------\n          \n          \n            \n            FROM xxxxx", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483693268", "createdAt": "2020-09-04T15:31:56Z", "author": {"login": "prb112"}, "path": "fhir-bucket/Dockerfile", "diffHunk": "@@ -0,0 +1,13 @@\n+FROM xxxxx", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzY5MzQ3OQ==", "bodyText": "any special meaning for xxxxx", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483693479", "createdAt": "2020-09-04T15:32:10Z", "author": {"login": "prb112"}, "path": "fhir-bucket/Dockerfile", "diffHunk": "@@ -0,0 +1,13 @@\n+FROM xxxxx", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzY5MzI2OA=="}, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc0OTUzMQ==", "bodyText": "removed the file", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483749531", "createdAt": "2020-09-04T17:03:04Z", "author": {"login": "punktilious"}, "path": "fhir-bucket/Dockerfile", "diffHunk": "@@ -0,0 +1,13 @@\n+FROM xxxxx", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzY5MzI2OA=="}, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNDQyMTU1OnYy", "diffSide": "RIGHT", "path": "fhir-bucket/README.md", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNTozNDoyNVrOHNSbjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNzowNToyOFrOHNVyjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzY5NTUwMA==", "bodyText": "small recommendation for future\n#!/usr/bin/env bash\nthis ensures the environment finds bash, it's not a guarantee on all systems that it is under /bin/bash (for example upcoming releases of macos)", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483695500", "createdAt": "2020-09-04T15:34:25Z", "author": {"login": "prb112"}, "path": "fhir-bucket/README.md", "diffHunk": "@@ -0,0 +1,308 @@\n+## Synthetic Data Loader\n+Scans cloud object storage buckets and uploads data using the FHIR REST API\n+\n+### Background\n+\n+Synthea is a project for generating \"synthetic\" patient/population data for healthcare applications.\n+It generates realistic data based on census statistics and a lot of configuration.\n+It supports generating data in FHIR R4 \n+\n+This \"fhir-bucket\" project will help you upload Synthea-generated data to a FHIR R4 server.\n+\n+To facilitate high-volume load scenarios, multiple instances of the application can be run and their work coordinated so that each file is loaded exactly once.\n+\n+The loader records the identities of the created resources. These identities can be used in other test and load generator applications to access the data.\n+\n+### Steps\n+\n+1. Follow the steps at https://github.com/synthetichealth/synthea to clone and install Synthea\n+2. Configure Synthea to generate FHIR R4 resources\n+3. Generate a bunch of patients\n+4. Clone this repo and set it up with Maven/Eclipse\n+5. Configure the truststore with root certs required to trust connections to your FHIR server, cloud object store and tracking database\n+5. Tweak fhir.properties to point at your target FHIR server\n+6. Tweak cos.properties to point at your COS bucket\n+7. Tweak db.properties to point at your tracking database\n+8. Execute Main.class as described in the Running section below\n+\n+\n+### Configuration\n+\n+#### The cos.properties file\n+\n+```\n+# the IBM COS API key or S3 access key.\n+cos.api.key=\n+\n+# the IBM COS service instance id or S3 secret key.\n+cos.srvinstid=\n+\n+# the IBM COS or S3 End point URL.\n+cos.endpoint.url=\n+\n+# the IBM COS or S3 location.\n+cos.location=\n+\n+# the IBM COS or S3 bucket name to import from.\n+cos.bucket.name=\n+\n+# if use IBM credential(Y/N), default(Y).\n+cos.credential.ibm=Y\n+\n+# COS network timeouts\n+cos.request.timeout=60000\n+cos.socket.timeout=60000\n+\n+# The number of COS keys (items) to fetch per read\n+cos.max.keys=1000\n+```\n+\n+#### The db2.properties file\n+\n+```\n+db.host=<DB2-HOST-NAME>\n+db.port=<DB2-PORT>\n+db.database=<DB2-DATABASE>\n+user=<DB2-USER>\n+password=<DB2-PASSWORD>\n+sslConnection=true\n+sslTrustStoreLocation=/path/to/dbTruststore.p12\n+sslTrustStorePassword=<TRUSTSTORE-PASSWORD>\n+currentSchema=FHIRBUCKET\n+```\n+\n+#### The derby.properties file\n+\n+Db2 is the preferred database for hosting the fhir-bucket schema. Derby can, however, be used for development. The derby.properties file must be configured as follows:\n+\n+```\n+db.database=derby/bucketDB\n+db.create=Y\n+```\n+\n+\n+#### The postgres.properties file\n+\n+\n+\n+The name of the Derby database can be anything (without spaces) but must be contained within a folder called \"derby\".\n+\n+### Schema Deployment\n+\n+As a one-time activity, create the schema objects using the following command:\n+\n+```\n+#!/bin/bash", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc0MjM4Nw==", "bodyText": "Indeed. Old habits.", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483742387", "createdAt": "2020-09-04T16:47:04Z", "author": {"login": "punktilious"}, "path": "fhir-bucket/README.md", "diffHunk": "@@ -0,0 +1,308 @@\n+## Synthetic Data Loader\n+Scans cloud object storage buckets and uploads data using the FHIR REST API\n+\n+### Background\n+\n+Synthea is a project for generating \"synthetic\" patient/population data for healthcare applications.\n+It generates realistic data based on census statistics and a lot of configuration.\n+It supports generating data in FHIR R4 \n+\n+This \"fhir-bucket\" project will help you upload Synthea-generated data to a FHIR R4 server.\n+\n+To facilitate high-volume load scenarios, multiple instances of the application can be run and their work coordinated so that each file is loaded exactly once.\n+\n+The loader records the identities of the created resources. These identities can be used in other test and load generator applications to access the data.\n+\n+### Steps\n+\n+1. Follow the steps at https://github.com/synthetichealth/synthea to clone and install Synthea\n+2. Configure Synthea to generate FHIR R4 resources\n+3. Generate a bunch of patients\n+4. Clone this repo and set it up with Maven/Eclipse\n+5. Configure the truststore with root certs required to trust connections to your FHIR server, cloud object store and tracking database\n+5. Tweak fhir.properties to point at your target FHIR server\n+6. Tweak cos.properties to point at your COS bucket\n+7. Tweak db.properties to point at your tracking database\n+8. Execute Main.class as described in the Running section below\n+\n+\n+### Configuration\n+\n+#### The cos.properties file\n+\n+```\n+# the IBM COS API key or S3 access key.\n+cos.api.key=\n+\n+# the IBM COS service instance id or S3 secret key.\n+cos.srvinstid=\n+\n+# the IBM COS or S3 End point URL.\n+cos.endpoint.url=\n+\n+# the IBM COS or S3 location.\n+cos.location=\n+\n+# the IBM COS or S3 bucket name to import from.\n+cos.bucket.name=\n+\n+# if use IBM credential(Y/N), default(Y).\n+cos.credential.ibm=Y\n+\n+# COS network timeouts\n+cos.request.timeout=60000\n+cos.socket.timeout=60000\n+\n+# The number of COS keys (items) to fetch per read\n+cos.max.keys=1000\n+```\n+\n+#### The db2.properties file\n+\n+```\n+db.host=<DB2-HOST-NAME>\n+db.port=<DB2-PORT>\n+db.database=<DB2-DATABASE>\n+user=<DB2-USER>\n+password=<DB2-PASSWORD>\n+sslConnection=true\n+sslTrustStoreLocation=/path/to/dbTruststore.p12\n+sslTrustStorePassword=<TRUSTSTORE-PASSWORD>\n+currentSchema=FHIRBUCKET\n+```\n+\n+#### The derby.properties file\n+\n+Db2 is the preferred database for hosting the fhir-bucket schema. Derby can, however, be used for development. The derby.properties file must be configured as follows:\n+\n+```\n+db.database=derby/bucketDB\n+db.create=Y\n+```\n+\n+\n+#### The postgres.properties file\n+\n+\n+\n+The name of the Derby database can be anything (without spaces) but must be contained within a folder called \"derby\".\n+\n+### Schema Deployment\n+\n+As a one-time activity, create the schema objects using the following command:\n+\n+```\n+#!/bin/bash", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzY5NTUwMA=="}, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc1MDU0Mw==", "bodyText": "fixed", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483750543", "createdAt": "2020-09-04T17:05:28Z", "author": {"login": "punktilious"}, "path": "fhir-bucket/README.md", "diffHunk": "@@ -0,0 +1,308 @@\n+## Synthetic Data Loader\n+Scans cloud object storage buckets and uploads data using the FHIR REST API\n+\n+### Background\n+\n+Synthea is a project for generating \"synthetic\" patient/population data for healthcare applications.\n+It generates realistic data based on census statistics and a lot of configuration.\n+It supports generating data in FHIR R4 \n+\n+This \"fhir-bucket\" project will help you upload Synthea-generated data to a FHIR R4 server.\n+\n+To facilitate high-volume load scenarios, multiple instances of the application can be run and their work coordinated so that each file is loaded exactly once.\n+\n+The loader records the identities of the created resources. These identities can be used in other test and load generator applications to access the data.\n+\n+### Steps\n+\n+1. Follow the steps at https://github.com/synthetichealth/synthea to clone and install Synthea\n+2. Configure Synthea to generate FHIR R4 resources\n+3. Generate a bunch of patients\n+4. Clone this repo and set it up with Maven/Eclipse\n+5. Configure the truststore with root certs required to trust connections to your FHIR server, cloud object store and tracking database\n+5. Tweak fhir.properties to point at your target FHIR server\n+6. Tweak cos.properties to point at your COS bucket\n+7. Tweak db.properties to point at your tracking database\n+8. Execute Main.class as described in the Running section below\n+\n+\n+### Configuration\n+\n+#### The cos.properties file\n+\n+```\n+# the IBM COS API key or S3 access key.\n+cos.api.key=\n+\n+# the IBM COS service instance id or S3 secret key.\n+cos.srvinstid=\n+\n+# the IBM COS or S3 End point URL.\n+cos.endpoint.url=\n+\n+# the IBM COS or S3 location.\n+cos.location=\n+\n+# the IBM COS or S3 bucket name to import from.\n+cos.bucket.name=\n+\n+# if use IBM credential(Y/N), default(Y).\n+cos.credential.ibm=Y\n+\n+# COS network timeouts\n+cos.request.timeout=60000\n+cos.socket.timeout=60000\n+\n+# The number of COS keys (items) to fetch per read\n+cos.max.keys=1000\n+```\n+\n+#### The db2.properties file\n+\n+```\n+db.host=<DB2-HOST-NAME>\n+db.port=<DB2-PORT>\n+db.database=<DB2-DATABASE>\n+user=<DB2-USER>\n+password=<DB2-PASSWORD>\n+sslConnection=true\n+sslTrustStoreLocation=/path/to/dbTruststore.p12\n+sslTrustStorePassword=<TRUSTSTORE-PASSWORD>\n+currentSchema=FHIRBUCKET\n+```\n+\n+#### The derby.properties file\n+\n+Db2 is the preferred database for hosting the fhir-bucket schema. Derby can, however, be used for development. The derby.properties file must be configured as follows:\n+\n+```\n+db.database=derby/bucketDB\n+db.create=Y\n+```\n+\n+\n+#### The postgres.properties file\n+\n+\n+\n+The name of the Derby database can be anything (without spaces) but must be contained within a folder called \"derby\".\n+\n+### Schema Deployment\n+\n+As a one-time activity, create the schema objects using the following command:\n+\n+```\n+#!/bin/bash", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzY5NTUwMA=="}, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 95}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNDQ0ODUxOnYy", "diffSide": "RIGHT", "path": "fhir-bucket/pom.xml", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNTozOToxNFrOHNSs8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNjo1MzoyNlrOHNVdlA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzY5OTk1Mg==", "bodyText": "build/security/asoc.sh\nplease update this file with -not -iname 'fhir-bucket-*-cli.jar'", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483699952", "createdAt": "2020-09-04T15:39:14Z", "author": {"login": "prb112"}, "path": "fhir-bucket/pom.xml", "diffHunk": "@@ -0,0 +1,109 @@\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+\n+    <artifactId>fhir-bucket</artifactId>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc0NTE3Mg==", "bodyText": "done", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483745172", "createdAt": "2020-09-04T16:53:26Z", "author": {"login": "punktilious"}, "path": "fhir-bucket/pom.xml", "diffHunk": "@@ -0,0 +1,109 @@\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+\n+    <artifactId>fhir-bucket</artifactId>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzY5OTk1Mg=="}, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNDQ1NjI1OnYy", "diffSide": "RIGHT", "path": "fhir-bucket/Dockerfile", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNTo0MDozN1rOHNSx2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNjo0NTo0MlrOHNVQXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcwMTIwOQ==", "bodyText": "I suggest changing to fhir not fhir_dstu2", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483701209", "createdAt": "2020-09-04T15:40:37Z", "author": {"login": "prb112"}, "path": "fhir-bucket/Dockerfile", "diffHunk": "@@ -0,0 +1,13 @@\n+FROM xxxxx\n+\n+COPY synthea-2.4.0-shaded.jar .\n+COPY target/synthea-uploader-0.0.1-SNAPSHOT-shaded.jar .\n+COPY cloudflare.truststore .\n+\n+RUN echo \"x.x.x.x   fhir-service\" >> /etc/hosts\n+\n+ENV LANG en_US.UTF-8\n+\n+RUN sed -i 's/override_install_langs=en_US.utf8/#override_install_langs=en_US.utf8/g' /etc/yum.conf\n+\n+CMD java -jar synthea-2.4.0-shaded.jar -p 1000 -o false && java -Djavax.net.ssl.trustStore=clientTruststore.jks -jar synthea-uploader-0.0.1-SNAPSHOT-shaded.jar output/fhir_dstu2/", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc0MTc5MQ==", "bodyText": "actually the Dockerfile here isn't required at all. I'll remove it.", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483741791", "createdAt": "2020-09-04T16:45:42Z", "author": {"login": "punktilious"}, "path": "fhir-bucket/Dockerfile", "diffHunk": "@@ -0,0 +1,13 @@\n+FROM xxxxx\n+\n+COPY synthea-2.4.0-shaded.jar .\n+COPY target/synthea-uploader-0.0.1-SNAPSHOT-shaded.jar .\n+COPY cloudflare.truststore .\n+\n+RUN echo \"x.x.x.x   fhir-service\" >> /etc/hosts\n+\n+ENV LANG en_US.UTF-8\n+\n+RUN sed -i 's/override_install_langs=en_US.utf8/#override_install_langs=en_US.utf8/g' /etc/yum.conf\n+\n+CMD java -jar synthea-2.4.0-shaded.jar -p 1000 -o false && java -Djavax.net.ssl.trustStore=clientTruststore.jks -jar synthea-uploader-0.0.1-SNAPSHOT-shaded.jar output/fhir_dstu2/", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcwMTIwOQ=="}, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNDQ1ODU3OnYy", "diffSide": "RIGHT", "path": "fhir-bucket/src/main/java/com/ibm/fhir/bucket/api/Constants.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNTo0MDo1OVrOHNSzSA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNjo1NToyM1rOHNVhMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcwMTU3Ng==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             * Constants for BulkExportImport.\n          \n          \n            \n             * Constants for FHIR Bucket.", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483701576", "createdAt": "2020-09-04T15:40:59Z", "author": {"login": "prb112"}, "path": "fhir-bucket/src/main/java/com/ibm/fhir/bucket/api/Constants.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * (C) Copyright IBM Corp. 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+package com.ibm.fhir.bucket.api;\n+\n+/**\n+ * Constants for BulkExportImport.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc0NjA5Ng==", "bodyText": "fixed", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483746096", "createdAt": "2020-09-04T16:55:23Z", "author": {"login": "punktilious"}, "path": "fhir-bucket/src/main/java/com/ibm/fhir/bucket/api/Constants.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * (C) Copyright IBM Corp. 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+package com.ibm.fhir.bucket.api;\n+\n+/**\n+ * Constants for BulkExportImport.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcwMTU3Ng=="}, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNDQ2MDI1OnYy", "diffSide": "RIGHT", "path": "fhir-bucket/src/main/java/com/ibm/fhir/bucket/api/Constants.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNTo0MToxNVrOHNS0Kw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNjo1NTo1NFrOHNViKQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcwMTgwMw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public static final String DEFAULT_COS_BUCKETNAME = \"fhir-bulkImExport-Connectathon\";\n          \n          \n            \n                public static final String DEFAULT_COS_BUCKETNAME = \"fhir-bulkImExport-Connectathon\";\n          \n      \n    \n    \n  \n\nmaybe we drop this?", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483701803", "createdAt": "2020-09-04T15:41:15Z", "author": {"login": "prb112"}, "path": "fhir-bucket/src/main/java/com/ibm/fhir/bucket/api/Constants.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * (C) Copyright IBM Corp. 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+package com.ibm.fhir.bucket.api;\n+\n+/**\n+ * Constants for BulkExportImport.\n+ *\n+ */\n+public class Constants {\n+\n+    public static final String DEFAULT_FHIR_TENANT = \"default\";\n+    public static final String DEFAULT_COS_BUCKETNAME = \"fhir-bulkImExport-Connectathon\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc0NjM0NQ==", "bodyText": "definitely", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483746345", "createdAt": "2020-09-04T16:55:54Z", "author": {"login": "punktilious"}, "path": "fhir-bucket/src/main/java/com/ibm/fhir/bucket/api/Constants.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * (C) Copyright IBM Corp. 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+package com.ibm.fhir.bucket.api;\n+\n+/**\n+ * Constants for BulkExportImport.\n+ *\n+ */\n+public class Constants {\n+\n+    public static final String DEFAULT_FHIR_TENANT = \"default\";\n+    public static final String DEFAULT_COS_BUCKETNAME = \"fhir-bulkImExport-Connectathon\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcwMTgwMw=="}, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNDQ2OTU2OnYy", "diffSide": "RIGHT", "path": "fhir-bucket/src/main/java/com/ibm/fhir/bucket/client/FhirClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNTo0Mjo1NlrOHNS5yQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNTo0Mjo1NlrOHNS5yQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcwMzI0MQ==", "bodyText": "smart addition", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483703241", "createdAt": "2020-09-04T15:42:56Z", "author": {"login": "prb112"}, "path": "fhir-bucket/src/main/java/com/ibm/fhir/bucket/client/FhirClient.java", "diffHunk": "@@ -0,0 +1,504 @@\n+/*\n+ * (C) Copyright IBM Corp. 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+package com.ibm.fhir.bucket.client;\n+\n+import java.io.BufferedReader;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.InputStreamReader;\n+import java.io.Reader;\n+import java.io.UnsupportedEncodingException;\n+import java.nio.charset.StandardCharsets;\n+import java.security.KeyManagementException;\n+import java.security.KeyStoreException;\n+import java.security.NoSuchAlgorithmException;\n+import java.security.cert.CertificateException;\n+import java.util.Base64;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Function;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+\n+import javax.net.ssl.HostnameVerifier;\n+import javax.net.ssl.SSLContext;\n+\n+import org.apache.http.Header;\n+import org.apache.http.HttpEntity;\n+import org.apache.http.HttpResponse;\n+import org.apache.http.HttpStatus;\n+import org.apache.http.NoHttpResponseException;\n+import org.apache.http.client.ClientProtocolException;\n+import org.apache.http.client.UserTokenHandler;\n+import org.apache.http.client.methods.HttpGet;\n+import org.apache.http.client.methods.HttpPost;\n+import org.apache.http.client.methods.HttpPut;\n+import org.apache.http.client.methods.HttpRequestBase;\n+import org.apache.http.config.Registry;\n+import org.apache.http.config.RegistryBuilder;\n+import org.apache.http.config.SocketConfig;\n+import org.apache.http.conn.ConnectionKeepAliveStrategy;\n+import org.apache.http.conn.socket.ConnectionSocketFactory;\n+import org.apache.http.conn.socket.PlainConnectionSocketFactory;\n+import org.apache.http.conn.ssl.NoopHostnameVerifier;\n+import org.apache.http.conn.ssl.SSLConnectionSocketFactory;\n+import org.apache.http.entity.ContentType;\n+import org.apache.http.entity.StringEntity;\n+import org.apache.http.impl.DefaultConnectionReuseStrategy;\n+import org.apache.http.impl.client.CloseableHttpClient;\n+import org.apache.http.impl.client.DefaultHttpRequestRetryHandler;\n+import org.apache.http.impl.client.HttpClients;\n+import org.apache.http.impl.conn.PoolingHttpClientConnectionManager;\n+import org.apache.http.pool.PoolStats;\n+import org.apache.http.protocol.HttpContext;\n+import org.apache.http.ssl.SSLContextBuilder;\n+import org.apache.http.util.EntityUtils;\n+\n+import com.ibm.fhir.database.utils.api.DataAccessException;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.parser.FHIRParser;\n+import com.ibm.fhir.model.parser.exception.FHIRParserException;\n+import com.ibm.fhir.model.resource.Resource;\n+\n+/**\n+ * Handles pooled HTTP/S connections to a FHIR server. Derived from the\n+ * former High Volume Ingestion Tool (HVIT) which is known to scale to\n+ * a large number of client connections.\n+ */\n+public class FhirClient {\n+\n+    private static final Logger logger = Logger.getLogger(FhirClient.class.getName());\n+    private static final String USER_AGENT = \"FHIR_BUCKET_LOADER\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 75}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNDQ3OTIzOnYy", "diffSide": "RIGHT", "path": "fhir-bucket/src/main/java/com/ibm/fhir/bucket/client/FhirClient.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNTo0NDo0N1rOHNTARg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNzowODozNVrOHNV3pQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcwNDkwMg==", "bodyText": "I think we have a setting that we can flip between FHIR and the RFC lastmodified.  In case you hit an issue with the format.", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483704902", "createdAt": "2020-09-04T15:44:47Z", "author": {"login": "prb112"}, "path": "fhir-bucket/src/main/java/com/ibm/fhir/bucket/client/FhirClient.java", "diffHunk": "@@ -0,0 +1,504 @@\n+/*\n+ * (C) Copyright IBM Corp. 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+package com.ibm.fhir.bucket.client;\n+\n+import java.io.BufferedReader;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.InputStreamReader;\n+import java.io.Reader;\n+import java.io.UnsupportedEncodingException;\n+import java.nio.charset.StandardCharsets;\n+import java.security.KeyManagementException;\n+import java.security.KeyStoreException;\n+import java.security.NoSuchAlgorithmException;\n+import java.security.cert.CertificateException;\n+import java.util.Base64;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Function;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+\n+import javax.net.ssl.HostnameVerifier;\n+import javax.net.ssl.SSLContext;\n+\n+import org.apache.http.Header;\n+import org.apache.http.HttpEntity;\n+import org.apache.http.HttpResponse;\n+import org.apache.http.HttpStatus;\n+import org.apache.http.NoHttpResponseException;\n+import org.apache.http.client.ClientProtocolException;\n+import org.apache.http.client.UserTokenHandler;\n+import org.apache.http.client.methods.HttpGet;\n+import org.apache.http.client.methods.HttpPost;\n+import org.apache.http.client.methods.HttpPut;\n+import org.apache.http.client.methods.HttpRequestBase;\n+import org.apache.http.config.Registry;\n+import org.apache.http.config.RegistryBuilder;\n+import org.apache.http.config.SocketConfig;\n+import org.apache.http.conn.ConnectionKeepAliveStrategy;\n+import org.apache.http.conn.socket.ConnectionSocketFactory;\n+import org.apache.http.conn.socket.PlainConnectionSocketFactory;\n+import org.apache.http.conn.ssl.NoopHostnameVerifier;\n+import org.apache.http.conn.ssl.SSLConnectionSocketFactory;\n+import org.apache.http.entity.ContentType;\n+import org.apache.http.entity.StringEntity;\n+import org.apache.http.impl.DefaultConnectionReuseStrategy;\n+import org.apache.http.impl.client.CloseableHttpClient;\n+import org.apache.http.impl.client.DefaultHttpRequestRetryHandler;\n+import org.apache.http.impl.client.HttpClients;\n+import org.apache.http.impl.conn.PoolingHttpClientConnectionManager;\n+import org.apache.http.pool.PoolStats;\n+import org.apache.http.protocol.HttpContext;\n+import org.apache.http.ssl.SSLContextBuilder;\n+import org.apache.http.util.EntityUtils;\n+\n+import com.ibm.fhir.database.utils.api.DataAccessException;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.parser.FHIRParser;\n+import com.ibm.fhir.model.parser.exception.FHIRParserException;\n+import com.ibm.fhir.model.resource.Resource;\n+\n+/**\n+ * Handles pooled HTTP/S connections to a FHIR server. Derived from the\n+ * former High Volume Ingestion Tool (HVIT) which is known to scale to\n+ * a large number of client connections.\n+ */\n+public class FhirClient {\n+\n+    private static final Logger logger = Logger.getLogger(FhirClient.class.getName());\n+    private static final String USER_AGENT = \"FHIR_BUCKET_LOADER\";\n+\n+    // Connection pool managing FHIR server HTTPS connections\n+    private PoolingHttpClientConnectionManager connManager;\n+    \n+    // HTTP client used to POST/PUT/GET FHIR server requests\n+    private CloseableHttpClient client;\n+    private String[] enabledCiphers;\n+\n+    // connection properties encapsulated in an adapter for easy access\n+    private final ClientPropertyAdapter propertyAdapter;\n+\n+    // The common headers we use which are shared across all threads\n+    private final Map<String,String> headers = new ConcurrentHashMap<String, String>();\n+    \n+    /**\n+     * Public constructor\n+     * @param cpa\n+     */\n+    public FhirClient(ClientPropertyAdapter cpa) {\n+        this.propertyAdapter = cpa;\n+    }\n+\n+    /**\n+     * Add the given key/value as a header\n+     * @param key\n+     * @param value\n+     */\n+    public void addHeader(String key, String value) {\n+        this.headers.put(key, value);\n+    }\n+    \n+    /**\n+     * Initialize the SSL connection pool after all the required field values have been injected\n+     */\n+    public void init(String tenantName) {\n+        if (connManager != null) {\n+            throw new IllegalStateException(\"Already initialied\");\n+        }\n+\n+        \n+        String enabledCiphersValue = propertyAdapter.getEnabledCiphers();\n+        if (enabledCiphersValue != null && !enabledCiphersValue.isEmpty()) {\n+            enabledCiphers = enabledCiphersValue.split(\",\");\n+        }\n+\n+        ConnectionKeepAliveStrategy connKeepAliveStrategy = new ConnectionKeepAliveStrategy() {\n+\n+            @Override\n+            public long getKeepAliveDuration(HttpResponse response, HttpContext context) {\n+                return 60000*60;\n+            }\n+        };\n+        \n+        try {\n+            // SSLContext sslContext = SSLContexts.custom().build();\n+            \n+            SSLContextBuilder sslContextBuilder = SSLContextBuilder.create();\n+            // sslContextBuilder.loadKeyMaterial(new File(keystoreFilename), keystorePass.toCharArray(), keyPass.toCharArray());\n+            sslContextBuilder.loadTrustMaterial(new File(propertyAdapter.getTruststore()), propertyAdapter.getTruststorePass().toCharArray());\n+            SSLContext sslContext = sslContextBuilder.build();\n+\n+            // For dev/test setups, allow connections to a FHIR server using a hostname\n+            // other than localhost\n+            HostnameVerifier hnv;\n+            if (propertyAdapter.isDisableHostnameVerification()) {\n+                hnv = new NoopHostnameVerifier();\n+            } else {\n+                hnv = SSLConnectionSocketFactory.getDefaultHostnameVerifier();\n+            }\n+            SSLConnectionSocketFactory factory = new SSLConnectionSocketFactory(sslContext, new String[]{\"TLSv1.2\"}, enabledCiphers, hnv);\n+\n+            Registry<ConnectionSocketFactory> registry = RegistryBuilder.<ConnectionSocketFactory>create()\n+                    .register(\"http\", PlainConnectionSocketFactory.getSocketFactory())\n+                    .register(\"https\",factory).build();\n+\n+            connManager = new PoolingHttpClientConnectionManager(registry);\n+            connManager.setMaxTotal(propertyAdapter.getPoolConnectionsMax());\n+            connManager.setDefaultMaxPerRoute(propertyAdapter.getPoolConnectionsMax());\n+            connManager.setValidateAfterInactivity(60000);\n+            connManager.setDefaultSocketConfig(SocketConfig.custom().build());\n+            \n+            client = obtainCloseableHttpClient(connKeepAliveStrategy);\n+        } \n+        catch (KeyManagementException e) {\n+            throw new IllegalStateException(\"Failed to initialize connection manager\", e);\n+        } \n+        catch (NoSuchAlgorithmException e) {\n+            throw new IllegalStateException(\"Failed to initialize connection manager\", e);\n+        }        \n+        catch (IOException x) {\n+            throw new IllegalStateException(\"Failed to initialize connection manager\", x);\n+        }\n+        catch (CertificateException x) {\n+            throw new IllegalStateException(\"Failed to initialize connection manager\", x);\n+        }\n+        catch (KeyStoreException x) {\n+            throw new IllegalStateException(\"Failed to initialize connection manager\", x);\n+        }\n+\n+        if (tenantName != null) {\n+            this.headers.put(Headers.TENANT_HEADER, tenantName);\n+        }\n+\n+        // For now, we only talk JSON with the FHIR server\n+        this.headers.put(Headers.ACCEPT_HEADER, ContentType.APPLICATION_JSON.getMimeType());\n+        this.headers.put(Headers.CONTENT_TYPE_HEADER, ContentType.APPLICATION_JSON.getMimeType());\n+        this.headers.put(\"Prefer\", \"return=representation\");\n+\n+        String user = propertyAdapter.getFhirServerUser();\n+        String pass = propertyAdapter.getFhirServerPass();\n+        if (user != null && pass != null) {\n+            // Set up basic auth\n+            String b64 = Base64.getEncoder().encodeToString(user.concat(\":\").concat(pass).getBytes());\n+            headers.put(Headers.AUTH_HEADER, \"Basic \".concat(b64));\n+        }\n+    }\n+    \n+    /**\n+     * Add our headers to the request\n+     * @param request\n+     */\n+    private void addHeadersTo(final HttpRequestBase request) {\n+        // inject each header into the request\n+        headers.entrySet().stream().forEach(e -> request.addHeader(e.getKey(), e.getValue())); \n+    }\n+    \n+    private String buildTargetPath(String resourceName) {\n+        StringBuilder result = new StringBuilder();\n+\n+        result.append(\"https://\");\n+        result.append(propertyAdapter.fhirServerHost());\n+        result.append(\":\");\n+        result.append(propertyAdapter.fhirServerPort());\n+        result.append(propertyAdapter.fhirServerEndpoint());\n+        \n+        if (resourceName != null) {\n+            result.append(resourceName);\n+        }\n+        \n+        return result.toString();\n+    }\n+    \n+    public FhirServerResponse get(String url, Function<Reader, Resource> fn) {\n+        \n+        String target = buildTargetPath(url);\n+        if (logger.isLoggable(Level.FINE)){\n+            logger.fine(\"REQUEST GET \"+ target);\n+        }\n+\n+        HttpGet getRequest = new HttpGet(target);\n+        addHeadersTo(getRequest);\n+        \n+        for (int i = 1; ; i++) {\n+            try {\n+                long startTime = System.nanoTime();\n+                HttpResponse response = client.execute(getRequest);\n+                if(logger.isLoggable(Level.FINE)){\n+                    Header responseHeaders[] = response.getAllHeaders();\n+                    \n+                    StringBuilder msg = new StringBuilder();\n+                    msg.append(\"Response HTTP Headers: \");\n+                    for (Header responseHeader : responseHeaders) {\n+                        msg.append(System.lineSeparator());\n+                        msg.append(\"\\t\" + responseHeader.getName() + \": \" + responseHeader.getValue());\n+                    }\n+                    logger.fine(msg.toString());\n+                }\n+                return buildResponse(response, startTime, true);\n+            } catch (NoHttpResponseException e) {\n+                logger.warning(\"Encountered an org.apache.http.NoHttpResponseException during GET request. \" + e);\n+                logger.warning(\"GET URL: \"+target);\n+                logger.warning(\"Will retry this request for the Nth time. N = \" + i);\n+            } catch (IOException e) {\n+                logger.severe(\"Error while executing the GET request. \" + e);\n+                logger.warning(\"GET URL: \"+target);\n+                logger.warning(\"Skipping this request.\");\n+                return null;\n+            }\n+        }        \n+    }\n+    \n+    /**\n+     * Issue a POST request at the given url\n+     * @param sUrl\n+     * @param body\n+     * @return\n+     */\n+    public FhirServerResponse post(String url, String body) {\n+        String target = buildTargetPath(url);\n+        if(logger.isLoggable(Level.FINE)) {\n+            logger.fine(\"REQUEST POST \"+ target);\n+        }\n+        \n+        try {\n+            HttpPost postRequest = new HttpPost(target);\n+            postRequest.setEntity(new StringEntity(body));\n+            addHeadersTo(postRequest);\n+            \n+            if(logger.isLoggable(Level.FINE)) {\n+                logger.fine(\"REQUEST POST BODY - \" + body);\n+            }\n+            \n+            long startTime = System.currentTimeMillis();\n+            HttpResponse response = client.execute(postRequest);\n+            \n+            // Log details of the response if required\n+            if(logger.isLoggable(Level.FINE)) {\n+                Header responseHeaders[] = response.getAllHeaders();\n+                \n+                StringBuilder msg = new StringBuilder();\n+                msg.append(\"Response HTTP Headers: \");\n+                for (Header responseHeader : responseHeaders) {\n+                    msg.append(System.lineSeparator());\n+                    msg.append(\"\\t\" + responseHeader.getName() + \": \" + responseHeader.getValue());\n+                }\n+                logger.fine(msg.toString());\n+            }\n+\n+            // If we are posting a bundle, then we need to parse the response entity\n+            boolean isBundle = url.isEmpty();\n+            return buildResponse(response, startTime, isBundle);\n+            \n+        } catch (UnsupportedEncodingException e) {\n+            logger.severe(\"Can't encode json string into entity. \"+e);\n+            logger.warning(\"POST URL: \"+target+\"\\nRequest Body: \"+body);\n+            throw new IllegalStateException(\"FHIR client configuration error\");\n+        } catch (ClientProtocolException e) {\n+            logger.severe(\"Error while executing the POST request. \"+e);\n+            logger.warning(\"POST URL: \"+target+\"\\nRequest Body: \"+body);\n+            throw new DataAccessException(\"FHIR server connection failed\");\n+        } catch (IOException e) {\n+            logger.severe(\"Error while executing the POST request. \"+e);\n+            logger.warning(\"POST URL: \"+target+\"\\nRequest Body: \"+body);\n+            throw new DataAccessException(\"FHIR server connection failed\");\n+        }\n+    }\n+    \n+    public FhirServerResponse put(String url, Map<String, String> headers, String body) {\n+        String target = buildTargetPath(url);\n+\n+        if (logger.isLoggable(Level.FINE)) {\n+            logger.fine(\"REQUEST PUT \"+target);\n+        }\n+        \n+        try {\n+            HttpPut putRequest = new HttpPut(target);\n+            putRequest.setEntity(new StringEntity(body));\n+            addHeadersTo(putRequest);\n+            \n+            if (logger.isLoggable(Level.FINE)) {\n+                logger.fine(\"REQUEST PUT BODY - \" + body);\n+            }\n+            \n+            long startTime = System.currentTimeMillis();\n+            HttpResponse response = client.execute(putRequest);\n+            if (logger.isLoggable(Level.FINE)) {\n+                Header responseHeaders[] = response.getAllHeaders();\n+                logger.fine(\"Response HTTP Headers: \");\n+                for (Header responseHeader : responseHeaders) {\n+                    logger.fine(\"\\t\" + responseHeader.getName() + \": \" + responseHeader.getValue());\n+                }\n+            }\n+            return buildResponse(response, startTime, false);\n+            \n+        } catch (UnsupportedEncodingException e) {\n+            logger.severe(\"Can't encode json string into entity. \"+e);\n+            logger.warning(\"PUT URL: \"+target+\"\\nRequest Body: \"+body);\n+        } catch (ClientProtocolException e) {\n+            logger.severe(\"Error while executing the PUT request. \"+e);\n+            logger.warning(\"PUT URL: \"+target+\"\\nRequest Body: \"+body);\n+        } catch (IOException e) {\n+            logger.severe(\"Error while executing the PUT request. \"+e);\n+            logger.warning(\"PUT URL: \"+target+\"\\nRequest Body: \"+body);\n+        }\n+        \n+        return null;\n+    }\n+    \n+    public void shutdown() {\n+        if (client != null) {\n+            try {\n+                connManager.shutdown();\n+                client.close();\n+            } catch (IOException e) {\n+                throw new IllegalStateException(\"Unable to shutdown HTTP clients and Connection Manager successfully. \", e);\n+            }\n+        }\n+        \n+    }\n+\n+    /**\n+     * Get statistics from the internal HTTP connection manager\n+     * @return\n+     */\n+    public PoolStats getPoolInformation() {\n+        if (connManager != null) {\n+            return connManager.getTotalStats();\n+        } \n+        \n+        return null;\n+    }\n+\n+    /**\n+     * Construct a FhirServerResponse from the FHIR server {@link HttpResponse}\n+     * @param response\n+     * @param startTime\n+     * @return\n+     */\n+    private FhirServerResponse buildResponse(HttpResponse response, long startTime, boolean processResponseEntity) {\n+        FhirServerResponse sr = new FhirServerResponse();\n+        \n+        int status = response.getStatusLine().getStatusCode();\n+        sr.setStatusCode(status);\n+        sr.setStatusMessage(response.getStatusLine().getReasonPhrase());\n+\n+        HttpEntity entity = response.getEntity();\n+        try {\n+            if (status == HttpStatus.SC_OK || status == HttpStatus.SC_CREATED) {\n+                if (processResponseEntity) {\n+                    processEntity(sr, entity);\n+                } else if (response.getFirstHeader(\"Location\") != null) {\n+                    // Single resource case, no response body, just the URL returned in the Location header\n+                    sr.setLocationHeader(response.getFirstHeader(\"Location\").getValue());\n+                } else {\n+                    logger.warning(\"No body or Location header in response\");\n+                }\n+            } else if (status == HttpStatus.SC_BAD_REQUEST) {\n+                processOperationalOutcome(sr, entity);\n+            } else {\n+                logger.warning(\"Unexpected server response: \" + status + \" \" + response.getStatusLine().getReasonPhrase());\n+            }\n+        } finally {\n+            consume(entity);\n+            long endTime = System.nanoTime();\n+            sr.setResponseTime((int)(endTime-startTime));\n+        }\n+        \n+            // Last-Modified: 2018-11-26T05:07:00.954Z\n+            // TODO\n+//            Header lastModifiedHeader = response.getFirstHeader(\"Last-Modified\");\n+//            if (lastModifiedHeader != null) {\n+//                sr.setLastModified(TimeUtil.getFhirTime(lastModifiedHeader.getValue()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 417}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc1MTg0NQ==", "bodyText": "I'm not using this at the moment, but noted for when I add this. Hopefully we have some utility code which already handles this, if not I create something.", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483751845", "createdAt": "2020-09-04T17:08:35Z", "author": {"login": "punktilious"}, "path": "fhir-bucket/src/main/java/com/ibm/fhir/bucket/client/FhirClient.java", "diffHunk": "@@ -0,0 +1,504 @@\n+/*\n+ * (C) Copyright IBM Corp. 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+package com.ibm.fhir.bucket.client;\n+\n+import java.io.BufferedReader;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.InputStreamReader;\n+import java.io.Reader;\n+import java.io.UnsupportedEncodingException;\n+import java.nio.charset.StandardCharsets;\n+import java.security.KeyManagementException;\n+import java.security.KeyStoreException;\n+import java.security.NoSuchAlgorithmException;\n+import java.security.cert.CertificateException;\n+import java.util.Base64;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Function;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+\n+import javax.net.ssl.HostnameVerifier;\n+import javax.net.ssl.SSLContext;\n+\n+import org.apache.http.Header;\n+import org.apache.http.HttpEntity;\n+import org.apache.http.HttpResponse;\n+import org.apache.http.HttpStatus;\n+import org.apache.http.NoHttpResponseException;\n+import org.apache.http.client.ClientProtocolException;\n+import org.apache.http.client.UserTokenHandler;\n+import org.apache.http.client.methods.HttpGet;\n+import org.apache.http.client.methods.HttpPost;\n+import org.apache.http.client.methods.HttpPut;\n+import org.apache.http.client.methods.HttpRequestBase;\n+import org.apache.http.config.Registry;\n+import org.apache.http.config.RegistryBuilder;\n+import org.apache.http.config.SocketConfig;\n+import org.apache.http.conn.ConnectionKeepAliveStrategy;\n+import org.apache.http.conn.socket.ConnectionSocketFactory;\n+import org.apache.http.conn.socket.PlainConnectionSocketFactory;\n+import org.apache.http.conn.ssl.NoopHostnameVerifier;\n+import org.apache.http.conn.ssl.SSLConnectionSocketFactory;\n+import org.apache.http.entity.ContentType;\n+import org.apache.http.entity.StringEntity;\n+import org.apache.http.impl.DefaultConnectionReuseStrategy;\n+import org.apache.http.impl.client.CloseableHttpClient;\n+import org.apache.http.impl.client.DefaultHttpRequestRetryHandler;\n+import org.apache.http.impl.client.HttpClients;\n+import org.apache.http.impl.conn.PoolingHttpClientConnectionManager;\n+import org.apache.http.pool.PoolStats;\n+import org.apache.http.protocol.HttpContext;\n+import org.apache.http.ssl.SSLContextBuilder;\n+import org.apache.http.util.EntityUtils;\n+\n+import com.ibm.fhir.database.utils.api.DataAccessException;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.parser.FHIRParser;\n+import com.ibm.fhir.model.parser.exception.FHIRParserException;\n+import com.ibm.fhir.model.resource.Resource;\n+\n+/**\n+ * Handles pooled HTTP/S connections to a FHIR server. Derived from the\n+ * former High Volume Ingestion Tool (HVIT) which is known to scale to\n+ * a large number of client connections.\n+ */\n+public class FhirClient {\n+\n+    private static final Logger logger = Logger.getLogger(FhirClient.class.getName());\n+    private static final String USER_AGENT = \"FHIR_BUCKET_LOADER\";\n+\n+    // Connection pool managing FHIR server HTTPS connections\n+    private PoolingHttpClientConnectionManager connManager;\n+    \n+    // HTTP client used to POST/PUT/GET FHIR server requests\n+    private CloseableHttpClient client;\n+    private String[] enabledCiphers;\n+\n+    // connection properties encapsulated in an adapter for easy access\n+    private final ClientPropertyAdapter propertyAdapter;\n+\n+    // The common headers we use which are shared across all threads\n+    private final Map<String,String> headers = new ConcurrentHashMap<String, String>();\n+    \n+    /**\n+     * Public constructor\n+     * @param cpa\n+     */\n+    public FhirClient(ClientPropertyAdapter cpa) {\n+        this.propertyAdapter = cpa;\n+    }\n+\n+    /**\n+     * Add the given key/value as a header\n+     * @param key\n+     * @param value\n+     */\n+    public void addHeader(String key, String value) {\n+        this.headers.put(key, value);\n+    }\n+    \n+    /**\n+     * Initialize the SSL connection pool after all the required field values have been injected\n+     */\n+    public void init(String tenantName) {\n+        if (connManager != null) {\n+            throw new IllegalStateException(\"Already initialied\");\n+        }\n+\n+        \n+        String enabledCiphersValue = propertyAdapter.getEnabledCiphers();\n+        if (enabledCiphersValue != null && !enabledCiphersValue.isEmpty()) {\n+            enabledCiphers = enabledCiphersValue.split(\",\");\n+        }\n+\n+        ConnectionKeepAliveStrategy connKeepAliveStrategy = new ConnectionKeepAliveStrategy() {\n+\n+            @Override\n+            public long getKeepAliveDuration(HttpResponse response, HttpContext context) {\n+                return 60000*60;\n+            }\n+        };\n+        \n+        try {\n+            // SSLContext sslContext = SSLContexts.custom().build();\n+            \n+            SSLContextBuilder sslContextBuilder = SSLContextBuilder.create();\n+            // sslContextBuilder.loadKeyMaterial(new File(keystoreFilename), keystorePass.toCharArray(), keyPass.toCharArray());\n+            sslContextBuilder.loadTrustMaterial(new File(propertyAdapter.getTruststore()), propertyAdapter.getTruststorePass().toCharArray());\n+            SSLContext sslContext = sslContextBuilder.build();\n+\n+            // For dev/test setups, allow connections to a FHIR server using a hostname\n+            // other than localhost\n+            HostnameVerifier hnv;\n+            if (propertyAdapter.isDisableHostnameVerification()) {\n+                hnv = new NoopHostnameVerifier();\n+            } else {\n+                hnv = SSLConnectionSocketFactory.getDefaultHostnameVerifier();\n+            }\n+            SSLConnectionSocketFactory factory = new SSLConnectionSocketFactory(sslContext, new String[]{\"TLSv1.2\"}, enabledCiphers, hnv);\n+\n+            Registry<ConnectionSocketFactory> registry = RegistryBuilder.<ConnectionSocketFactory>create()\n+                    .register(\"http\", PlainConnectionSocketFactory.getSocketFactory())\n+                    .register(\"https\",factory).build();\n+\n+            connManager = new PoolingHttpClientConnectionManager(registry);\n+            connManager.setMaxTotal(propertyAdapter.getPoolConnectionsMax());\n+            connManager.setDefaultMaxPerRoute(propertyAdapter.getPoolConnectionsMax());\n+            connManager.setValidateAfterInactivity(60000);\n+            connManager.setDefaultSocketConfig(SocketConfig.custom().build());\n+            \n+            client = obtainCloseableHttpClient(connKeepAliveStrategy);\n+        } \n+        catch (KeyManagementException e) {\n+            throw new IllegalStateException(\"Failed to initialize connection manager\", e);\n+        } \n+        catch (NoSuchAlgorithmException e) {\n+            throw new IllegalStateException(\"Failed to initialize connection manager\", e);\n+        }        \n+        catch (IOException x) {\n+            throw new IllegalStateException(\"Failed to initialize connection manager\", x);\n+        }\n+        catch (CertificateException x) {\n+            throw new IllegalStateException(\"Failed to initialize connection manager\", x);\n+        }\n+        catch (KeyStoreException x) {\n+            throw new IllegalStateException(\"Failed to initialize connection manager\", x);\n+        }\n+\n+        if (tenantName != null) {\n+            this.headers.put(Headers.TENANT_HEADER, tenantName);\n+        }\n+\n+        // For now, we only talk JSON with the FHIR server\n+        this.headers.put(Headers.ACCEPT_HEADER, ContentType.APPLICATION_JSON.getMimeType());\n+        this.headers.put(Headers.CONTENT_TYPE_HEADER, ContentType.APPLICATION_JSON.getMimeType());\n+        this.headers.put(\"Prefer\", \"return=representation\");\n+\n+        String user = propertyAdapter.getFhirServerUser();\n+        String pass = propertyAdapter.getFhirServerPass();\n+        if (user != null && pass != null) {\n+            // Set up basic auth\n+            String b64 = Base64.getEncoder().encodeToString(user.concat(\":\").concat(pass).getBytes());\n+            headers.put(Headers.AUTH_HEADER, \"Basic \".concat(b64));\n+        }\n+    }\n+    \n+    /**\n+     * Add our headers to the request\n+     * @param request\n+     */\n+    private void addHeadersTo(final HttpRequestBase request) {\n+        // inject each header into the request\n+        headers.entrySet().stream().forEach(e -> request.addHeader(e.getKey(), e.getValue())); \n+    }\n+    \n+    private String buildTargetPath(String resourceName) {\n+        StringBuilder result = new StringBuilder();\n+\n+        result.append(\"https://\");\n+        result.append(propertyAdapter.fhirServerHost());\n+        result.append(\":\");\n+        result.append(propertyAdapter.fhirServerPort());\n+        result.append(propertyAdapter.fhirServerEndpoint());\n+        \n+        if (resourceName != null) {\n+            result.append(resourceName);\n+        }\n+        \n+        return result.toString();\n+    }\n+    \n+    public FhirServerResponse get(String url, Function<Reader, Resource> fn) {\n+        \n+        String target = buildTargetPath(url);\n+        if (logger.isLoggable(Level.FINE)){\n+            logger.fine(\"REQUEST GET \"+ target);\n+        }\n+\n+        HttpGet getRequest = new HttpGet(target);\n+        addHeadersTo(getRequest);\n+        \n+        for (int i = 1; ; i++) {\n+            try {\n+                long startTime = System.nanoTime();\n+                HttpResponse response = client.execute(getRequest);\n+                if(logger.isLoggable(Level.FINE)){\n+                    Header responseHeaders[] = response.getAllHeaders();\n+                    \n+                    StringBuilder msg = new StringBuilder();\n+                    msg.append(\"Response HTTP Headers: \");\n+                    for (Header responseHeader : responseHeaders) {\n+                        msg.append(System.lineSeparator());\n+                        msg.append(\"\\t\" + responseHeader.getName() + \": \" + responseHeader.getValue());\n+                    }\n+                    logger.fine(msg.toString());\n+                }\n+                return buildResponse(response, startTime, true);\n+            } catch (NoHttpResponseException e) {\n+                logger.warning(\"Encountered an org.apache.http.NoHttpResponseException during GET request. \" + e);\n+                logger.warning(\"GET URL: \"+target);\n+                logger.warning(\"Will retry this request for the Nth time. N = \" + i);\n+            } catch (IOException e) {\n+                logger.severe(\"Error while executing the GET request. \" + e);\n+                logger.warning(\"GET URL: \"+target);\n+                logger.warning(\"Skipping this request.\");\n+                return null;\n+            }\n+        }        \n+    }\n+    \n+    /**\n+     * Issue a POST request at the given url\n+     * @param sUrl\n+     * @param body\n+     * @return\n+     */\n+    public FhirServerResponse post(String url, String body) {\n+        String target = buildTargetPath(url);\n+        if(logger.isLoggable(Level.FINE)) {\n+            logger.fine(\"REQUEST POST \"+ target);\n+        }\n+        \n+        try {\n+            HttpPost postRequest = new HttpPost(target);\n+            postRequest.setEntity(new StringEntity(body));\n+            addHeadersTo(postRequest);\n+            \n+            if(logger.isLoggable(Level.FINE)) {\n+                logger.fine(\"REQUEST POST BODY - \" + body);\n+            }\n+            \n+            long startTime = System.currentTimeMillis();\n+            HttpResponse response = client.execute(postRequest);\n+            \n+            // Log details of the response if required\n+            if(logger.isLoggable(Level.FINE)) {\n+                Header responseHeaders[] = response.getAllHeaders();\n+                \n+                StringBuilder msg = new StringBuilder();\n+                msg.append(\"Response HTTP Headers: \");\n+                for (Header responseHeader : responseHeaders) {\n+                    msg.append(System.lineSeparator());\n+                    msg.append(\"\\t\" + responseHeader.getName() + \": \" + responseHeader.getValue());\n+                }\n+                logger.fine(msg.toString());\n+            }\n+\n+            // If we are posting a bundle, then we need to parse the response entity\n+            boolean isBundle = url.isEmpty();\n+            return buildResponse(response, startTime, isBundle);\n+            \n+        } catch (UnsupportedEncodingException e) {\n+            logger.severe(\"Can't encode json string into entity. \"+e);\n+            logger.warning(\"POST URL: \"+target+\"\\nRequest Body: \"+body);\n+            throw new IllegalStateException(\"FHIR client configuration error\");\n+        } catch (ClientProtocolException e) {\n+            logger.severe(\"Error while executing the POST request. \"+e);\n+            logger.warning(\"POST URL: \"+target+\"\\nRequest Body: \"+body);\n+            throw new DataAccessException(\"FHIR server connection failed\");\n+        } catch (IOException e) {\n+            logger.severe(\"Error while executing the POST request. \"+e);\n+            logger.warning(\"POST URL: \"+target+\"\\nRequest Body: \"+body);\n+            throw new DataAccessException(\"FHIR server connection failed\");\n+        }\n+    }\n+    \n+    public FhirServerResponse put(String url, Map<String, String> headers, String body) {\n+        String target = buildTargetPath(url);\n+\n+        if (logger.isLoggable(Level.FINE)) {\n+            logger.fine(\"REQUEST PUT \"+target);\n+        }\n+        \n+        try {\n+            HttpPut putRequest = new HttpPut(target);\n+            putRequest.setEntity(new StringEntity(body));\n+            addHeadersTo(putRequest);\n+            \n+            if (logger.isLoggable(Level.FINE)) {\n+                logger.fine(\"REQUEST PUT BODY - \" + body);\n+            }\n+            \n+            long startTime = System.currentTimeMillis();\n+            HttpResponse response = client.execute(putRequest);\n+            if (logger.isLoggable(Level.FINE)) {\n+                Header responseHeaders[] = response.getAllHeaders();\n+                logger.fine(\"Response HTTP Headers: \");\n+                for (Header responseHeader : responseHeaders) {\n+                    logger.fine(\"\\t\" + responseHeader.getName() + \": \" + responseHeader.getValue());\n+                }\n+            }\n+            return buildResponse(response, startTime, false);\n+            \n+        } catch (UnsupportedEncodingException e) {\n+            logger.severe(\"Can't encode json string into entity. \"+e);\n+            logger.warning(\"PUT URL: \"+target+\"\\nRequest Body: \"+body);\n+        } catch (ClientProtocolException e) {\n+            logger.severe(\"Error while executing the PUT request. \"+e);\n+            logger.warning(\"PUT URL: \"+target+\"\\nRequest Body: \"+body);\n+        } catch (IOException e) {\n+            logger.severe(\"Error while executing the PUT request. \"+e);\n+            logger.warning(\"PUT URL: \"+target+\"\\nRequest Body: \"+body);\n+        }\n+        \n+        return null;\n+    }\n+    \n+    public void shutdown() {\n+        if (client != null) {\n+            try {\n+                connManager.shutdown();\n+                client.close();\n+            } catch (IOException e) {\n+                throw new IllegalStateException(\"Unable to shutdown HTTP clients and Connection Manager successfully. \", e);\n+            }\n+        }\n+        \n+    }\n+\n+    /**\n+     * Get statistics from the internal HTTP connection manager\n+     * @return\n+     */\n+    public PoolStats getPoolInformation() {\n+        if (connManager != null) {\n+            return connManager.getTotalStats();\n+        } \n+        \n+        return null;\n+    }\n+\n+    /**\n+     * Construct a FhirServerResponse from the FHIR server {@link HttpResponse}\n+     * @param response\n+     * @param startTime\n+     * @return\n+     */\n+    private FhirServerResponse buildResponse(HttpResponse response, long startTime, boolean processResponseEntity) {\n+        FhirServerResponse sr = new FhirServerResponse();\n+        \n+        int status = response.getStatusLine().getStatusCode();\n+        sr.setStatusCode(status);\n+        sr.setStatusMessage(response.getStatusLine().getReasonPhrase());\n+\n+        HttpEntity entity = response.getEntity();\n+        try {\n+            if (status == HttpStatus.SC_OK || status == HttpStatus.SC_CREATED) {\n+                if (processResponseEntity) {\n+                    processEntity(sr, entity);\n+                } else if (response.getFirstHeader(\"Location\") != null) {\n+                    // Single resource case, no response body, just the URL returned in the Location header\n+                    sr.setLocationHeader(response.getFirstHeader(\"Location\").getValue());\n+                } else {\n+                    logger.warning(\"No body or Location header in response\");\n+                }\n+            } else if (status == HttpStatus.SC_BAD_REQUEST) {\n+                processOperationalOutcome(sr, entity);\n+            } else {\n+                logger.warning(\"Unexpected server response: \" + status + \" \" + response.getStatusLine().getReasonPhrase());\n+            }\n+        } finally {\n+            consume(entity);\n+            long endTime = System.nanoTime();\n+            sr.setResponseTime((int)(endTime-startTime));\n+        }\n+        \n+            // Last-Modified: 2018-11-26T05:07:00.954Z\n+            // TODO\n+//            Header lastModifiedHeader = response.getFirstHeader(\"Last-Modified\");\n+//            if (lastModifiedHeader != null) {\n+//                sr.setLastModified(TimeUtil.getFhirTime(lastModifiedHeader.getValue()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcwNDkwMg=="}, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 417}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNDUwNTM3OnYy", "diffSide": "RIGHT", "path": "fhir-bucket/src/main/java/com/ibm/fhir/bucket/scanner/DirectoryScanner.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNTo1MTo1NlrOHNTPxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNzoxMDo1OFrOHNV7pQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcwODg3MQ==", "bodyText": "I think I missed the intent of this class.  To be implemented?", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483708871", "createdAt": "2020-09-04T15:51:56Z", "author": {"login": "prb112"}, "path": "fhir-bucket/src/main/java/com/ibm/fhir/bucket/scanner/DirectoryScanner.java", "diffHunk": "@@ -0,0 +1,10 @@\n+/*\n+ * (C) Copyright IBM Corp. 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+package com.ibm.fhir.bucket.scanner;\n+\n+public class DirectoryScanner {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc1Mjg2OQ==", "bodyText": "An artifact of my brain as I was thinking how best to scan through the COS tree (wondering if we might need to parallelize scanning of different branches of the tree). Not needed, so I'll remove.", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483752869", "createdAt": "2020-09-04T17:10:58Z", "author": {"login": "punktilious"}, "path": "fhir-bucket/src/main/java/com/ibm/fhir/bucket/scanner/DirectoryScanner.java", "diffHunk": "@@ -0,0 +1,10 @@\n+/*\n+ * (C) Copyright IBM Corp. 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+package com.ibm.fhir.bucket.scanner;\n+\n+public class DirectoryScanner {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcwODg3MQ=="}, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNDUwOTYwOnYy", "diffSide": "RIGHT", "path": "fhir-bucket/src/main/java/com/ibm/fhir/bucket/scanner/ResourceHandler.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNTo1MzowMVrOHNTSVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNzoxNToyMlrOHNWDHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcwOTUyNA==", "bodyText": "useful or extraneous now?", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483709524", "createdAt": "2020-09-04T15:53:01Z", "author": {"login": "prb112"}, "path": "fhir-bucket/src/main/java/com/ibm/fhir/bucket/scanner/ResourceHandler.java", "diffHunk": "@@ -0,0 +1,379 @@\n+/*\n+ * (C) Copyright IBM Corp. 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bucket.scanner;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+\n+import org.apache.http.HttpStatus;\n+\n+import com.ibm.fhir.bucket.api.ResourceBundleError;\n+import com.ibm.fhir.bucket.api.ResourceEntry;\n+import com.ibm.fhir.bucket.api.ResourceIdValue;\n+import com.ibm.fhir.bucket.client.FhirClient;\n+import com.ibm.fhir.bucket.client.FhirServerResponse;\n+import com.ibm.fhir.bucket.client.PostResource;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Bundle;\n+import com.ibm.fhir.model.resource.Bundle.Entry.Response;\n+import com.ibm.fhir.model.resource.Resource;\n+\n+/**\n+ * Calls the FHIR REST API to create resources, supported by a thread pool\n+ */\n+public class ResourceHandler {\n+    private static final Logger logger = Logger.getLogger(ResourceHandler.class.getName());\n+    private static final int BATCH_SIZE = 200;\n+    \n+    // Nanos in a millisecond\n+    private static final long NANOS_MS = 1000000;\n+\n+    // The number of concurrent FHIR requests we allow\n+    private final int maxConcurrentFhirRequests;\n+    \n+    // The thread pool\n+    private final ExecutorService pool;\n+\n+    // Client for making FHIR server requests\n+    private final FhirClient fhirClient;\n+    \n+    // flow control so we don't overload the thread pool queue\n+    private final Lock lock = new ReentrantLock();\n+    private final Condition capacityCondition = lock.newCondition();\n+    \n+    // how many resources are currently queued or being processed\n+    private int inflight;\n+    \n+    // flag used to handle shutdown\n+    private volatile boolean running = true;\n+\n+    // Access to the FHIR bucket persistence layer to record logical ids\n+    private final DataAccess dataAccess;\n+    \n+    /**\n+     * Public constructor\n+     * @param poolSize\n+     */\n+    public ResourceHandler(ExecutorService commonPool, int maxConcurrentFhirRequests, FhirClient fc, DataAccess dataAccess) {\n+        this.maxConcurrentFhirRequests = maxConcurrentFhirRequests;\n+        this.fhirClient = fc;\n+        this.pool = commonPool;\n+        this.dataAccess = dataAccess;\n+    }\n+\n+    /**\n+     * Tell the ResourceHandler to shut down processing\n+     */\n+    public void signalStop() {\n+        if (running) {\n+            logger.info(\"Shutting down resource handler\");\n+            this.running = false;\n+        }\n+        \n+        // Wake up anything which may be blocked\n+        lock.lock();\n+        try {\n+            capacityCondition.signalAll();\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+    \n+    /**\n+     * Shut down all resource processing\n+     */\n+    public void waitForStop() {\n+        signalStop();\n+        \n+        // We don't own the pool, so we don't wait for it to shut down\n+    }\n+\n+    /**\n+     * Add the resource entry to the thread-pool for processing, subject to the\n+     * rate limiting we have to make sure memory consumption is kept in check\n+     * @param entry\n+     * @return\n+     */\n+    public boolean process(ResourceEntry entry) {\n+        boolean result = false;\n+\n+        lock.lock();\n+        try {\n+            while (running && inflight >= maxConcurrentFhirRequests) {\n+                capacityCondition.await();\n+            }\n+            \n+            if (running) {\n+                inflight += entry.getCost(); // Grab the capacity while we're locked\n+                entry.getJob().addEntry(); // Add to row count so we can track when the job completes\n+                result = true;\n+            }\n+        } catch (InterruptedException x) {\n+            logger.info(\"Interrupted while waiting for capacity\");\n+        }\n+        finally {\n+            lock.unlock();\n+        }\n+\n+        // only submit to the pool if we have permission\n+        if (running && result) {\n+            pool.submit(() -> {\n+                try {\n+                    processThr(entry);\n+                } catch (Exception x) {\n+                    // don't let exceptions propagate to the thread-pool\n+                    logger.log(Level.SEVERE, entry.toString(), x);\n+                } finally {\n+                    lock.lock();\n+                    try {\n+                        // Free up the capacity consumed by this entry\n+                        inflight -= entry.getCost();\n+                        capacityCondition.signalAll();\n+                    } finally {\n+                        lock.unlock();\n+                    }\n+                }\n+            });\n+        }\n+        \n+        return result;\n+    }\n+    \n+    /**\n+     * Process the resource in the thread pool\n+     * @param resource\n+     */\n+    public void processThr(ResourceEntry re) {\n+        \n+        boolean success = false;\n+        try {\n+            Resource resource = re.getResource();\n+            final String resourceType = resource.getClass().getSimpleName();\n+            if (logger.isLoggable(Level.FINE)) {\n+                logger.fine(\"Processing resource: \" + resourceType);\n+            }\n+            \n+            // Build a post request for the resource and send to FHIR\n+            long start = System.nanoTime();\n+            PostResource post = new PostResource(resource);\n+            FhirServerResponse response = post.run(fhirClient);\n+            long end = System.nanoTime();\n+            switch (response.getStatusCode()) {\n+            case HttpStatus.SC_OK:\n+            case HttpStatus.SC_CREATED:\n+                String locn = response.getLocationHeader();\n+                if (response.getResource() != null) {\n+                    // Process the response bundle\n+                    success = processResponseResource(re, response.getResource());\n+                } else if (locn != null) {\n+                    if (locn.startsWith(\"https://\")) {\n+                        // the response was empty, so in this case we need to extract the id from\n+                        // the location header\n+                        int responseTimeMs = (int)((end - start) / NANOS_MS);\n+                        success = processLocation(re, locn, responseTimeMs);\n+                    } else {\n+                        logger.warning(\"FHIR bad location format [\" + re.toString() + \"]: \" + \n+                                locn);\n+                    }\n+                    \n+                } else {\n+                    logger.warning(\"FHIR request id not found [\" + re.toString() + \"]: \" + \n+                            response.getStatusCode() + \" \" + response.getStatusMessage());\n+                }\n+                break;\n+            default:\n+                logger.warning(\"FHIR request failed [\" + re.toString() + \"]: \" + \n+                        response.getStatusCode() + \" \" + response.getStatusMessage());\n+                processBadRequest(re, response);\n+                break;\n+            }\n+        } catch (Throwable x) {\n+            // don't let any exceptions propagate into the thread pool\n+            logger.log(Level.SEVERE, re.toString(), x);\n+        } finally {\n+            // Signal the processing is complete for this entry\n+            re.getJob().operationComplete(success);\n+        }\n+    }\n+\n+    /**\n+     * Process the bundle we received in the FHIR POST response to extract all the ids\n+     * Synthetic example:\n+        {           \n+            \"entry\": [\n+                {\n+                    \"response\": {\n+                        \"etag\": \"W/\\\"1\\\"\",\n+                        \"id\": \"1740ce473c9-aecca6ca-6824-44a0-a8d8-4cfd230e0309\",\n+                        \"lastModified\": \"2020-08-20T17:22:12.554128Z\",\n+                        \"location\": \"Patient/1740ce473c9-aecca6ca-6824-44a0-a8d8-4cfd230e0309/_history/1\",\n+                        \"status\": \"201\"\n+                    }\n+                },\n+                {\n+                    \"response\": {\n+                        \"etag\": \"W/\\\"1\\\"\",\n+                        \"id\": \"1740ce47574-fb9b6b7e-15a4-4abc-bc33-f6b4fdb3d1e3\",\n+                        \"lastModified\": \"2020-08-20T17:22:12.980788Z\",\n+                        \"location\": \"Organization/1740ce47574-fb9b6b7e-15a4-4abc-bc33-f6b4fdb3d1e3/_history/1\",\n+                        \"status\": \"201\"\n+                    }\n+                },\n+                ...\n+            ],  \n+            \"resourceType\": \"Bundle\",\n+            \"type\": \"transaction-response\"\n+        }\n+     * \n+     * @param bundle\n+     * @return\n+     */\n+    private boolean processResponseResource(ResourceEntry re, Resource resource) {\n+        boolean result;\n+        \n+        if (Bundle.class.isAssignableFrom(resource.getClass())) {\n+            Bundle bundle = resource.as(Bundle.class);\n+            result = processResponseBundle(re, bundle);\n+        } else {\n+            logger.severe(\"Resource is not a bundle. Skipping: \" + resource.getClass().getSimpleName());\n+            result = false;\n+        }\n+        \n+        \n+        return result;\n+    }\n+    \n+    private boolean processResponseBundle(ResourceEntry re, Bundle bundle) {\n+        \n+        // Extract the location from every entry in the bundle. Collect them\n+        // together so that we can make a single batch insert into the database\n+        // which is going to be a lot more efficient than individual inserts\n+        List<ResourceIdValue> idValues = new ArrayList<>();\n+        for (Bundle.Entry entry: bundle.getEntry()) {\n+            Response response = entry.getResponse();\n+            if (response != null) {\n+                if (response.getLocation() != null && response.getLocation().getValue() != null) {\n+                    String locn = response.getLocation().getValue();\n+                    logger.info(\"New resource: \" + locn);\n+                    ResourceIdValue rid = getResourceIdValue(locn);\n+                    if (rid != null) {\n+                        idValues.add(rid);\n+                    }\n+                }\n+            }\n+        }\n+\n+        processResourceIdValues(re, idValues);\n+        return idValues.size() > 0;\n+    }\n+\n+    /**\n+     * Process the list of resource ids as a batch\n+     * @param re\n+     * @param idValues\n+     * @return\n+     */\n+    private void processResourceIdValues(ResourceEntry re, List<ResourceIdValue> idValues) {\n+        dataAccess.recordLogicalIds(re.getJob().getResourceBundleLoadId(), re.getLineNumber(), idValues, BATCH_SIZE);\n+    }\n+    /**\n+     * Parse the location to create a {@link ResourceIdValue} DTO object.\n+     * The location can take one of two forms:\n+     *   \"Patient/1740ce473c9-aecca6ca-6824-44a0-a8d8-4cfd230e0309/_history/1\"\n+     *   \"https://localhost:9443/fhir-server/api/v4/DiagnosticReport/173eed87a99-605de23b-266d-4b4d-b64f-31e769fda112/_history/1\"\n+     * @param location\n+     * @return\n+     */\n+    private ResourceIdValue getResourceIdValue(String location) {\n+        ResourceIdValue result;\n+    \n+        String[] parts = location.split(\"/\");\n+        if (parts.length == 10) {\n+            String resourceType = parts[6];\n+            String id = parts[7];\n+            result = new ResourceIdValue(resourceType, id);\n+        } else if (parts.length == 4) {\n+            String resourceType = parts[0];\n+            String id = parts[1];\n+            result = new ResourceIdValue(resourceType, id);\n+        } else {\n+            result = null;\n+        }\n+        \n+        return result;\n+    }\n+    \n+    private boolean processLocation(ResourceEntry re, String location, int responseTimeMs) {\n+        boolean result = false;\n+        // the response was empty, so in this case we need to extract the id from\n+        // the location header, which means cracking the string into parts:\n+        // https://localhost:9443/fhir-server/api/v4/DiagnosticReport/173eed87a99-605de23b-266d-4b4d-b64f-31e769fda112/_history/1\n+        String[] parts = location.split(\"/\");\n+        if (parts.length == 10) {\n+            String resourceType = parts[6];\n+            String id = parts[7];\n+            logger.info(\"[\" +re.toString() + \"] new \" + resourceType + \"/\" + id + \" [took \" + responseTimeMs + \" ms]\");\n+            dataAccess.recordLogicalId(resourceType, id, re.getJob().getResourceBundleLoadId(), re.getLineNumber(), responseTimeMs);\n+            result = true;\n+        }\n+        \n+        return result;\n+    }\n+\n+    /**\n+     * Record the error in the database\n+     * @param re\n+     * @param response\n+     */\n+    protected void processBadRequest(ResourceEntry re, FhirServerResponse response) {\n+        \n+        if (logger.isLoggable(Level.FINE)) {\n+            // dump the resource and full operational outcome to the log\n+            logger.fine(re.getJob().getObjectKey() + \"[\" + re.getLineNumber() + \"]: \"\n+                + resourceToString(re.getResource()));\n+            logger.fine(re.getJob().getObjectKey() + \"[\" + re.getLineNumber() + \"]: \"\n+                + response.getOperationalOutcomeText());\n+        }\n+        \n+        List<ResourceBundleError> errors = new ArrayList<>();\n+        errors.add(new ResourceBundleError(re.getLineNumber(), response.getOperationalOutcomeText(), \n+            response.getResponseTime(), response.getStatusCode(), response.getStatusMessage()));\n+        \n+        dataAccess.recordErrors(re.getJob().getResourceBundleLoadId(), re.getLineNumber(), errors);\n+    }\n+\n+    /**\n+     * Render the resource as a string (for logging)\n+     * @param resource\n+     * @return\n+     */\n+    private String resourceToString(Resource resource) {\n+        ByteArrayOutputStream os = new ByteArrayOutputStream(4096);\n+        try {\n+            FHIRGenerator.generator(Format.JSON, false).generate(resource, os);\n+            return new String(os.toByteArray(), StandardCharsets.UTF_8);\n+        } catch (FHIRGeneratorException e) {\n+            throw new IllegalStateException(e);\n+        }\n+    }\n+\n+    /**\n+     * \n+     */\n+    public void init() {\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 378}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc1NDc4MQ==", "bodyText": "My style. I tend to have init() methods on major classes to support initialization after dependencies have been injected. But in this case, everything gets set up in the constructor, so we're not really injecting anything. I'll leave for now, but may remove if it's really not useful next time I'm refactoring.", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483754781", "createdAt": "2020-09-04T17:15:22Z", "author": {"login": "punktilious"}, "path": "fhir-bucket/src/main/java/com/ibm/fhir/bucket/scanner/ResourceHandler.java", "diffHunk": "@@ -0,0 +1,379 @@\n+/*\n+ * (C) Copyright IBM Corp. 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bucket.scanner;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+\n+import org.apache.http.HttpStatus;\n+\n+import com.ibm.fhir.bucket.api.ResourceBundleError;\n+import com.ibm.fhir.bucket.api.ResourceEntry;\n+import com.ibm.fhir.bucket.api.ResourceIdValue;\n+import com.ibm.fhir.bucket.client.FhirClient;\n+import com.ibm.fhir.bucket.client.FhirServerResponse;\n+import com.ibm.fhir.bucket.client.PostResource;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Bundle;\n+import com.ibm.fhir.model.resource.Bundle.Entry.Response;\n+import com.ibm.fhir.model.resource.Resource;\n+\n+/**\n+ * Calls the FHIR REST API to create resources, supported by a thread pool\n+ */\n+public class ResourceHandler {\n+    private static final Logger logger = Logger.getLogger(ResourceHandler.class.getName());\n+    private static final int BATCH_SIZE = 200;\n+    \n+    // Nanos in a millisecond\n+    private static final long NANOS_MS = 1000000;\n+\n+    // The number of concurrent FHIR requests we allow\n+    private final int maxConcurrentFhirRequests;\n+    \n+    // The thread pool\n+    private final ExecutorService pool;\n+\n+    // Client for making FHIR server requests\n+    private final FhirClient fhirClient;\n+    \n+    // flow control so we don't overload the thread pool queue\n+    private final Lock lock = new ReentrantLock();\n+    private final Condition capacityCondition = lock.newCondition();\n+    \n+    // how many resources are currently queued or being processed\n+    private int inflight;\n+    \n+    // flag used to handle shutdown\n+    private volatile boolean running = true;\n+\n+    // Access to the FHIR bucket persistence layer to record logical ids\n+    private final DataAccess dataAccess;\n+    \n+    /**\n+     * Public constructor\n+     * @param poolSize\n+     */\n+    public ResourceHandler(ExecutorService commonPool, int maxConcurrentFhirRequests, FhirClient fc, DataAccess dataAccess) {\n+        this.maxConcurrentFhirRequests = maxConcurrentFhirRequests;\n+        this.fhirClient = fc;\n+        this.pool = commonPool;\n+        this.dataAccess = dataAccess;\n+    }\n+\n+    /**\n+     * Tell the ResourceHandler to shut down processing\n+     */\n+    public void signalStop() {\n+        if (running) {\n+            logger.info(\"Shutting down resource handler\");\n+            this.running = false;\n+        }\n+        \n+        // Wake up anything which may be blocked\n+        lock.lock();\n+        try {\n+            capacityCondition.signalAll();\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+    \n+    /**\n+     * Shut down all resource processing\n+     */\n+    public void waitForStop() {\n+        signalStop();\n+        \n+        // We don't own the pool, so we don't wait for it to shut down\n+    }\n+\n+    /**\n+     * Add the resource entry to the thread-pool for processing, subject to the\n+     * rate limiting we have to make sure memory consumption is kept in check\n+     * @param entry\n+     * @return\n+     */\n+    public boolean process(ResourceEntry entry) {\n+        boolean result = false;\n+\n+        lock.lock();\n+        try {\n+            while (running && inflight >= maxConcurrentFhirRequests) {\n+                capacityCondition.await();\n+            }\n+            \n+            if (running) {\n+                inflight += entry.getCost(); // Grab the capacity while we're locked\n+                entry.getJob().addEntry(); // Add to row count so we can track when the job completes\n+                result = true;\n+            }\n+        } catch (InterruptedException x) {\n+            logger.info(\"Interrupted while waiting for capacity\");\n+        }\n+        finally {\n+            lock.unlock();\n+        }\n+\n+        // only submit to the pool if we have permission\n+        if (running && result) {\n+            pool.submit(() -> {\n+                try {\n+                    processThr(entry);\n+                } catch (Exception x) {\n+                    // don't let exceptions propagate to the thread-pool\n+                    logger.log(Level.SEVERE, entry.toString(), x);\n+                } finally {\n+                    lock.lock();\n+                    try {\n+                        // Free up the capacity consumed by this entry\n+                        inflight -= entry.getCost();\n+                        capacityCondition.signalAll();\n+                    } finally {\n+                        lock.unlock();\n+                    }\n+                }\n+            });\n+        }\n+        \n+        return result;\n+    }\n+    \n+    /**\n+     * Process the resource in the thread pool\n+     * @param resource\n+     */\n+    public void processThr(ResourceEntry re) {\n+        \n+        boolean success = false;\n+        try {\n+            Resource resource = re.getResource();\n+            final String resourceType = resource.getClass().getSimpleName();\n+            if (logger.isLoggable(Level.FINE)) {\n+                logger.fine(\"Processing resource: \" + resourceType);\n+            }\n+            \n+            // Build a post request for the resource and send to FHIR\n+            long start = System.nanoTime();\n+            PostResource post = new PostResource(resource);\n+            FhirServerResponse response = post.run(fhirClient);\n+            long end = System.nanoTime();\n+            switch (response.getStatusCode()) {\n+            case HttpStatus.SC_OK:\n+            case HttpStatus.SC_CREATED:\n+                String locn = response.getLocationHeader();\n+                if (response.getResource() != null) {\n+                    // Process the response bundle\n+                    success = processResponseResource(re, response.getResource());\n+                } else if (locn != null) {\n+                    if (locn.startsWith(\"https://\")) {\n+                        // the response was empty, so in this case we need to extract the id from\n+                        // the location header\n+                        int responseTimeMs = (int)((end - start) / NANOS_MS);\n+                        success = processLocation(re, locn, responseTimeMs);\n+                    } else {\n+                        logger.warning(\"FHIR bad location format [\" + re.toString() + \"]: \" + \n+                                locn);\n+                    }\n+                    \n+                } else {\n+                    logger.warning(\"FHIR request id not found [\" + re.toString() + \"]: \" + \n+                            response.getStatusCode() + \" \" + response.getStatusMessage());\n+                }\n+                break;\n+            default:\n+                logger.warning(\"FHIR request failed [\" + re.toString() + \"]: \" + \n+                        response.getStatusCode() + \" \" + response.getStatusMessage());\n+                processBadRequest(re, response);\n+                break;\n+            }\n+        } catch (Throwable x) {\n+            // don't let any exceptions propagate into the thread pool\n+            logger.log(Level.SEVERE, re.toString(), x);\n+        } finally {\n+            // Signal the processing is complete for this entry\n+            re.getJob().operationComplete(success);\n+        }\n+    }\n+\n+    /**\n+     * Process the bundle we received in the FHIR POST response to extract all the ids\n+     * Synthetic example:\n+        {           \n+            \"entry\": [\n+                {\n+                    \"response\": {\n+                        \"etag\": \"W/\\\"1\\\"\",\n+                        \"id\": \"1740ce473c9-aecca6ca-6824-44a0-a8d8-4cfd230e0309\",\n+                        \"lastModified\": \"2020-08-20T17:22:12.554128Z\",\n+                        \"location\": \"Patient/1740ce473c9-aecca6ca-6824-44a0-a8d8-4cfd230e0309/_history/1\",\n+                        \"status\": \"201\"\n+                    }\n+                },\n+                {\n+                    \"response\": {\n+                        \"etag\": \"W/\\\"1\\\"\",\n+                        \"id\": \"1740ce47574-fb9b6b7e-15a4-4abc-bc33-f6b4fdb3d1e3\",\n+                        \"lastModified\": \"2020-08-20T17:22:12.980788Z\",\n+                        \"location\": \"Organization/1740ce47574-fb9b6b7e-15a4-4abc-bc33-f6b4fdb3d1e3/_history/1\",\n+                        \"status\": \"201\"\n+                    }\n+                },\n+                ...\n+            ],  \n+            \"resourceType\": \"Bundle\",\n+            \"type\": \"transaction-response\"\n+        }\n+     * \n+     * @param bundle\n+     * @return\n+     */\n+    private boolean processResponseResource(ResourceEntry re, Resource resource) {\n+        boolean result;\n+        \n+        if (Bundle.class.isAssignableFrom(resource.getClass())) {\n+            Bundle bundle = resource.as(Bundle.class);\n+            result = processResponseBundle(re, bundle);\n+        } else {\n+            logger.severe(\"Resource is not a bundle. Skipping: \" + resource.getClass().getSimpleName());\n+            result = false;\n+        }\n+        \n+        \n+        return result;\n+    }\n+    \n+    private boolean processResponseBundle(ResourceEntry re, Bundle bundle) {\n+        \n+        // Extract the location from every entry in the bundle. Collect them\n+        // together so that we can make a single batch insert into the database\n+        // which is going to be a lot more efficient than individual inserts\n+        List<ResourceIdValue> idValues = new ArrayList<>();\n+        for (Bundle.Entry entry: bundle.getEntry()) {\n+            Response response = entry.getResponse();\n+            if (response != null) {\n+                if (response.getLocation() != null && response.getLocation().getValue() != null) {\n+                    String locn = response.getLocation().getValue();\n+                    logger.info(\"New resource: \" + locn);\n+                    ResourceIdValue rid = getResourceIdValue(locn);\n+                    if (rid != null) {\n+                        idValues.add(rid);\n+                    }\n+                }\n+            }\n+        }\n+\n+        processResourceIdValues(re, idValues);\n+        return idValues.size() > 0;\n+    }\n+\n+    /**\n+     * Process the list of resource ids as a batch\n+     * @param re\n+     * @param idValues\n+     * @return\n+     */\n+    private void processResourceIdValues(ResourceEntry re, List<ResourceIdValue> idValues) {\n+        dataAccess.recordLogicalIds(re.getJob().getResourceBundleLoadId(), re.getLineNumber(), idValues, BATCH_SIZE);\n+    }\n+    /**\n+     * Parse the location to create a {@link ResourceIdValue} DTO object.\n+     * The location can take one of two forms:\n+     *   \"Patient/1740ce473c9-aecca6ca-6824-44a0-a8d8-4cfd230e0309/_history/1\"\n+     *   \"https://localhost:9443/fhir-server/api/v4/DiagnosticReport/173eed87a99-605de23b-266d-4b4d-b64f-31e769fda112/_history/1\"\n+     * @param location\n+     * @return\n+     */\n+    private ResourceIdValue getResourceIdValue(String location) {\n+        ResourceIdValue result;\n+    \n+        String[] parts = location.split(\"/\");\n+        if (parts.length == 10) {\n+            String resourceType = parts[6];\n+            String id = parts[7];\n+            result = new ResourceIdValue(resourceType, id);\n+        } else if (parts.length == 4) {\n+            String resourceType = parts[0];\n+            String id = parts[1];\n+            result = new ResourceIdValue(resourceType, id);\n+        } else {\n+            result = null;\n+        }\n+        \n+        return result;\n+    }\n+    \n+    private boolean processLocation(ResourceEntry re, String location, int responseTimeMs) {\n+        boolean result = false;\n+        // the response was empty, so in this case we need to extract the id from\n+        // the location header, which means cracking the string into parts:\n+        // https://localhost:9443/fhir-server/api/v4/DiagnosticReport/173eed87a99-605de23b-266d-4b4d-b64f-31e769fda112/_history/1\n+        String[] parts = location.split(\"/\");\n+        if (parts.length == 10) {\n+            String resourceType = parts[6];\n+            String id = parts[7];\n+            logger.info(\"[\" +re.toString() + \"] new \" + resourceType + \"/\" + id + \" [took \" + responseTimeMs + \" ms]\");\n+            dataAccess.recordLogicalId(resourceType, id, re.getJob().getResourceBundleLoadId(), re.getLineNumber(), responseTimeMs);\n+            result = true;\n+        }\n+        \n+        return result;\n+    }\n+\n+    /**\n+     * Record the error in the database\n+     * @param re\n+     * @param response\n+     */\n+    protected void processBadRequest(ResourceEntry re, FhirServerResponse response) {\n+        \n+        if (logger.isLoggable(Level.FINE)) {\n+            // dump the resource and full operational outcome to the log\n+            logger.fine(re.getJob().getObjectKey() + \"[\" + re.getLineNumber() + \"]: \"\n+                + resourceToString(re.getResource()));\n+            logger.fine(re.getJob().getObjectKey() + \"[\" + re.getLineNumber() + \"]: \"\n+                + response.getOperationalOutcomeText());\n+        }\n+        \n+        List<ResourceBundleError> errors = new ArrayList<>();\n+        errors.add(new ResourceBundleError(re.getLineNumber(), response.getOperationalOutcomeText(), \n+            response.getResponseTime(), response.getStatusCode(), response.getStatusMessage()));\n+        \n+        dataAccess.recordErrors(re.getJob().getResourceBundleLoadId(), re.getLineNumber(), errors);\n+    }\n+\n+    /**\n+     * Render the resource as a string (for logging)\n+     * @param resource\n+     * @return\n+     */\n+    private String resourceToString(Resource resource) {\n+        ByteArrayOutputStream os = new ByteArrayOutputStream(4096);\n+        try {\n+            FHIRGenerator.generator(Format.JSON, false).generate(resource, os);\n+            return new String(os.toByteArray(), StandardCharsets.UTF_8);\n+        } catch (FHIRGeneratorException e) {\n+            throw new IllegalStateException(e);\n+        }\n+    }\n+\n+    /**\n+     * \n+     */\n+    public void init() {\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcwOTUyNA=="}, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 378}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNDUxMzE5OnYy", "diffSide": "RIGHT", "path": "fhir-bucket/src/main/resources/stats/bundle_rate.sql", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNTo1NDowNlrOHNTUjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNzoxNzoyNlrOHNWGgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcxMDA5Mg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            SET CURRENT SCHEMA FHIRBUCKET;\n          \n          \n            \n            -------------------------------------------------------------------------------\n          \n          \n            \n            -- (C) Copyright IBM Corp. 2020\n          \n          \n            \n            --\n          \n          \n            \n            -- SPDX-License-Identifier: Apache-2.0\n          \n          \n            \n            -------------------------------------------------------------------------------\n          \n          \n            \n             SET CURRENT SCHEMA FHIRBUCKET;", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483710092", "createdAt": "2020-09-04T15:54:06Z", "author": {"login": "prb112"}, "path": "fhir-bucket/src/main/resources/stats/bundle_rate.sql", "diffHunk": "@@ -0,0 +1,20 @@\n+SET CURRENT SCHEMA FHIRBUCKET;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc1NTY0OQ==", "bodyText": "fixed", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483755649", "createdAt": "2020-09-04T17:17:26Z", "author": {"login": "punktilious"}, "path": "fhir-bucket/src/main/resources/stats/bundle_rate.sql", "diffHunk": "@@ -0,0 +1,20 @@\n+SET CURRENT SCHEMA FHIRBUCKET;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcxMDA5Mg=="}, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNDUxNTY0OnYy", "diffSide": "RIGHT", "path": "fhir-bucket/src/main/resources/stats/get_errors.sql", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNTo1NDo0NVrOHNTWBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNzoyMTo0NVrOHNWNoQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcxMDQ3MA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            select e.line_number, e.http_status_code, e.http_status_text\n          \n          \n            \n            -------------------------------------------------------------------------------\n          \n          \n            \n            -- (C) Copyright IBM Corp. 2020\n          \n          \n            \n            --\n          \n          \n            \n            -- SPDX-License-Identifier: Apache-2.0\n          \n          \n            \n            -------------------------------------------------------------------------------\n          \n          \n            \n            select e.line_number, e.http_status_code, e.http_status_text", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483710470", "createdAt": "2020-09-04T15:54:45Z", "author": {"login": "prb112"}, "path": "fhir-bucket/src/main/resources/stats/get_errors.sql", "diffHunk": "@@ -0,0 +1,8 @@\n+select e.line_number, e.http_status_code, e.http_status_text", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc1NzQ3Mw==", "bodyText": "fixed", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483757473", "createdAt": "2020-09-04T17:21:45Z", "author": {"login": "punktilious"}, "path": "fhir-bucket/src/main/resources/stats/get_errors.sql", "diffHunk": "@@ -0,0 +1,8 @@\n+select e.line_number, e.http_status_code, e.http_status_text", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcxMDQ3MA=="}, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNDUxNjE5OnYy", "diffSide": "RIGHT", "path": "fhir-bucket/src/main/resources/stats/stats.sql", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNTo1NDo1N1rOHNTWXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNzoxNzozNVrOHNWGqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcxMDU1Ng==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            SET CURRENT SCHEMA FHIRBUCKET;\n          \n          \n            \n            -------------------------------------------------------------------------------\n          \n          \n            \n            -- (C) Copyright IBM Corp. 2020\n          \n          \n            \n            --\n          \n          \n            \n            -- SPDX-License-Identifier: Apache-2.0\n          \n          \n            \n            -------------------------------------------------------------------------------\n          \n          \n            \n            SET CURRENT SCHEMA FHIRBUCKET;", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483710556", "createdAt": "2020-09-04T15:54:57Z", "author": {"login": "prb112"}, "path": "fhir-bucket/src/main/resources/stats/stats.sql", "diffHunk": "@@ -0,0 +1,14 @@\n+SET CURRENT SCHEMA FHIRBUCKET;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc1NTY5MA==", "bodyText": "fixed", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483755690", "createdAt": "2020-09-04T17:17:35Z", "author": {"login": "punktilious"}, "path": "fhir-bucket/src/main/resources/stats/stats.sql", "diffHunk": "@@ -0,0 +1,14 @@\n+SET CURRENT SCHEMA FHIRBUCKET;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcxMDU1Ng=="}, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNDUzMjU5OnYy", "diffSide": "RIGHT", "path": "fhir-persistence-scout/src/main/java/com/ibm/fhir/persistence/scout/FHIRPersistenceScoutFactory.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNTo1OTo0NVrOHNTgaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNzowMjowM1rOHNVtCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcxMzEyOQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                /* (non-Javadoc)\n          \n          \n            \n                 * @see com.ibm.watson.health.fhir.persistence.FHIRPersistenceFactory#getInstance()\n          \n          \n            \n                 */", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483713129", "createdAt": "2020-09-04T15:59:45Z", "author": {"login": "prb112"}, "path": "fhir-persistence-scout/src/main/java/com/ibm/fhir/persistence/scout/FHIRPersistenceScoutFactory.java", "diffHunk": "@@ -0,0 +1,43 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.persistence.scout;\n+\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.FHIRPersistenceFactory;\n+import com.ibm.fhir.persistence.exception.FHIRPersistenceException;\n+import com.ibm.fhir.persistence.exception.FHIRPersistenceNotSupportedException;\n+\n+/**\n+ * Factory for creating FHIRPersistence instances using Cloudant as the underlying\n+ * datastore.\n+ * @author rarnold\n+ *\n+ */\n+public class FHIRPersistenceScoutFactory implements FHIRPersistenceFactory {\n+    private static final Logger logger = Logger.getLogger(FHIRPersistenceScoutFactory.class.getName());\n+    \n+    /* (non-Javadoc)\n+     * @see com.ibm.watson.health.fhir.persistence.FHIRPersistenceFactory#getInstance()\n+     */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc0OTEyOQ==", "bodyText": "fixed", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483749129", "createdAt": "2020-09-04T17:02:03Z", "author": {"login": "punktilious"}, "path": "fhir-persistence-scout/src/main/java/com/ibm/fhir/persistence/scout/FHIRPersistenceScoutFactory.java", "diffHunk": "@@ -0,0 +1,43 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.persistence.scout;\n+\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.FHIRPersistenceFactory;\n+import com.ibm.fhir.persistence.exception.FHIRPersistenceException;\n+import com.ibm.fhir.persistence.exception.FHIRPersistenceNotSupportedException;\n+\n+/**\n+ * Factory for creating FHIRPersistence instances using Cloudant as the underlying\n+ * datastore.\n+ * @author rarnold\n+ *\n+ */\n+public class FHIRPersistenceScoutFactory implements FHIRPersistenceFactory {\n+    private static final Logger logger = Logger.getLogger(FHIRPersistenceScoutFactory.class.getName());\n+    \n+    /* (non-Javadoc)\n+     * @see com.ibm.watson.health.fhir.persistence.FHIRPersistenceFactory#getInstance()\n+     */", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcxMzEyOQ=="}, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNDUzMzAzOnYy", "diffSide": "RIGHT", "path": "fhir-persistence-scout/src/main/java/com/ibm/fhir/persistence/scout/FHIRPersistenceScoutFactory.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNTo1OTo1M1rOHNTgqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNzowMDoyMVrOHNVqDQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcxMzE5NA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             * @author rarnold", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483713194", "createdAt": "2020-09-04T15:59:53Z", "author": {"login": "prb112"}, "path": "fhir-persistence-scout/src/main/java/com/ibm/fhir/persistence/scout/FHIRPersistenceScoutFactory.java", "diffHunk": "@@ -0,0 +1,43 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.persistence.scout;\n+\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.FHIRPersistenceFactory;\n+import com.ibm.fhir.persistence.exception.FHIRPersistenceException;\n+import com.ibm.fhir.persistence.exception.FHIRPersistenceNotSupportedException;\n+\n+/**\n+ * Factory for creating FHIRPersistence instances using Cloudant as the underlying\n+ * datastore.\n+ * @author rarnold", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc0ODM2NQ==", "bodyText": "fixed", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483748365", "createdAt": "2020-09-04T17:00:21Z", "author": {"login": "punktilious"}, "path": "fhir-persistence-scout/src/main/java/com/ibm/fhir/persistence/scout/FHIRPersistenceScoutFactory.java", "diffHunk": "@@ -0,0 +1,43 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.persistence.scout;\n+\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.FHIRPersistenceFactory;\n+import com.ibm.fhir.persistence.exception.FHIRPersistenceException;\n+import com.ibm.fhir.persistence.exception.FHIRPersistenceNotSupportedException;\n+\n+/**\n+ * Factory for creating FHIRPersistence instances using Cloudant as the underlying\n+ * datastore.\n+ * @author rarnold", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcxMzE5NA=="}, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNDUzNDAxOnYy", "diffSide": "RIGHT", "path": "fhir-persistence-scout/src/main/java/com/ibm/fhir/persistence/scout/FHIRPersistenceScoutImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNjowMDoxMVrOHNThUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNzoxNzo0NlrOHNWG-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcxMzM2MA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             * @author Robin Arnold", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483713360", "createdAt": "2020-09-04T16:00:11Z", "author": {"login": "prb112"}, "path": "fhir-persistence-scout/src/main/java/com/ibm/fhir/persistence/scout/FHIRPersistenceScoutImpl.java", "diffHunk": "@@ -0,0 +1,471 @@\n+/**\n+ * (C) Copyright IBM Corp. 2017,2018,2019\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.persistence.scout;\n+\n+import static com.ibm.fhir.config.FHIRConfiguration.PROPERTY_UPDATE_CREATE_ENABLED;\n+import static com.ibm.fhir.model.type.String.string;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.IOException;\n+import java.net.InetSocketAddress;\n+import java.net.URL;\n+import java.sql.Connection;\n+import java.sql.SQLException;\n+import java.sql.Timestamp;\n+import java.text.MessageFormat;\n+import java.time.ZoneOffset;\n+import java.time.temporal.TemporalAccessor;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Base64;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.UUID;\n+import java.util.Map.Entry;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+import java.util.zip.GZIPOutputStream;\n+\n+import javax.transaction.TransactionSynchronizationRegistry;\n+\n+import com.datastax.oss.driver.api.core.CqlSession;\n+import com.datastax.oss.driver.api.core.CqlSessionBuilder;\n+import com.google.gson.Gson;\n+import com.google.gson.GsonBuilder;\n+import com.ibm.fhir.config.FHIRConfigHelper;\n+import com.ibm.fhir.config.FHIRConfiguration;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.config.PropertyGroup;\n+import com.ibm.fhir.core.FHIRUtilities;\n+import com.ibm.fhir.database.utils.common.GetSequenceNextValueDAO;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.resource.OperationOutcome;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.resource.SearchParameter;\n+import com.ibm.fhir.model.resource.OperationOutcome.Issue;\n+import com.ibm.fhir.model.resource.SearchParameter.Component;\n+import com.ibm.fhir.model.type.CodeableConcept;\n+import com.ibm.fhir.model.type.Element;\n+import com.ibm.fhir.model.type.Id;\n+import com.ibm.fhir.model.type.Instant;\n+import com.ibm.fhir.model.type.Meta;\n+import com.ibm.fhir.model.type.code.IssueSeverity;\n+import com.ibm.fhir.model.type.code.IssueType;\n+import com.ibm.fhir.model.type.code.SearchParamType;\n+import com.ibm.fhir.model.util.FHIRUtil;\n+import com.ibm.fhir.model.visitor.Visitable;\n+import com.ibm.fhir.path.FHIRPathNode;\n+import com.ibm.fhir.path.FHIRPathSystemValue;\n+import com.ibm.fhir.path.evaluator.FHIRPathEvaluator;\n+import com.ibm.fhir.path.evaluator.FHIRPathEvaluator.EvaluationContext;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.FHIRPersistenceTransaction;\n+import com.ibm.fhir.persistence.MultiResourceResult;\n+import com.ibm.fhir.persistence.SingleResourceResult;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.exception.FHIRPersistenceException;\n+import com.ibm.fhir.persistence.exception.FHIRPersistenceResourceDeletedException;\n+import com.ibm.fhir.persistence.scout.SearchParameters;\n+import com.ibm.fhir.persistence.scout.SearchParameters.ParameterBlock;\n+import com.ibm.fhir.persistence.scout.SearchParameters.StrValue;\n+import com.ibm.fhir.persistence.scout.SearchParameters.StrValueList;\n+import com.ibm.fhir.persistence.scout.SearchParameters.TokenValue;\n+import com.ibm.fhir.persistence.scout.SearchParameters.TokenValueList;\n+import com.ibm.fhir.persistence.scout.cql.DatasourceSessions;\n+import com.ibm.fhir.search.SearchConstants.Type;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.date.DateTimeHandler;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Scalable persistence layer, storing resources in Cassandra and the corresponding\n+ * indexes in Redis.\n+ * @author Robin Arnold", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc1NTc3MA==", "bodyText": "fixed", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483755770", "createdAt": "2020-09-04T17:17:46Z", "author": {"login": "punktilious"}, "path": "fhir-persistence-scout/src/main/java/com/ibm/fhir/persistence/scout/FHIRPersistenceScoutImpl.java", "diffHunk": "@@ -0,0 +1,471 @@\n+/**\n+ * (C) Copyright IBM Corp. 2017,2018,2019\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.persistence.scout;\n+\n+import static com.ibm.fhir.config.FHIRConfiguration.PROPERTY_UPDATE_CREATE_ENABLED;\n+import static com.ibm.fhir.model.type.String.string;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.IOException;\n+import java.net.InetSocketAddress;\n+import java.net.URL;\n+import java.sql.Connection;\n+import java.sql.SQLException;\n+import java.sql.Timestamp;\n+import java.text.MessageFormat;\n+import java.time.ZoneOffset;\n+import java.time.temporal.TemporalAccessor;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Base64;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.UUID;\n+import java.util.Map.Entry;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+import java.util.zip.GZIPOutputStream;\n+\n+import javax.transaction.TransactionSynchronizationRegistry;\n+\n+import com.datastax.oss.driver.api.core.CqlSession;\n+import com.datastax.oss.driver.api.core.CqlSessionBuilder;\n+import com.google.gson.Gson;\n+import com.google.gson.GsonBuilder;\n+import com.ibm.fhir.config.FHIRConfigHelper;\n+import com.ibm.fhir.config.FHIRConfiguration;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.config.PropertyGroup;\n+import com.ibm.fhir.core.FHIRUtilities;\n+import com.ibm.fhir.database.utils.common.GetSequenceNextValueDAO;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.resource.OperationOutcome;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.resource.SearchParameter;\n+import com.ibm.fhir.model.resource.OperationOutcome.Issue;\n+import com.ibm.fhir.model.resource.SearchParameter.Component;\n+import com.ibm.fhir.model.type.CodeableConcept;\n+import com.ibm.fhir.model.type.Element;\n+import com.ibm.fhir.model.type.Id;\n+import com.ibm.fhir.model.type.Instant;\n+import com.ibm.fhir.model.type.Meta;\n+import com.ibm.fhir.model.type.code.IssueSeverity;\n+import com.ibm.fhir.model.type.code.IssueType;\n+import com.ibm.fhir.model.type.code.SearchParamType;\n+import com.ibm.fhir.model.util.FHIRUtil;\n+import com.ibm.fhir.model.visitor.Visitable;\n+import com.ibm.fhir.path.FHIRPathNode;\n+import com.ibm.fhir.path.FHIRPathSystemValue;\n+import com.ibm.fhir.path.evaluator.FHIRPathEvaluator;\n+import com.ibm.fhir.path.evaluator.FHIRPathEvaluator.EvaluationContext;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.FHIRPersistenceTransaction;\n+import com.ibm.fhir.persistence.MultiResourceResult;\n+import com.ibm.fhir.persistence.SingleResourceResult;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.exception.FHIRPersistenceException;\n+import com.ibm.fhir.persistence.exception.FHIRPersistenceResourceDeletedException;\n+import com.ibm.fhir.persistence.scout.SearchParameters;\n+import com.ibm.fhir.persistence.scout.SearchParameters.ParameterBlock;\n+import com.ibm.fhir.persistence.scout.SearchParameters.StrValue;\n+import com.ibm.fhir.persistence.scout.SearchParameters.StrValueList;\n+import com.ibm.fhir.persistence.scout.SearchParameters.TokenValue;\n+import com.ibm.fhir.persistence.scout.SearchParameters.TokenValueList;\n+import com.ibm.fhir.persistence.scout.cql.DatasourceSessions;\n+import com.ibm.fhir.search.SearchConstants.Type;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.date.DateTimeHandler;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Scalable persistence layer, storing resources in Cassandra and the corresponding\n+ * indexes in Redis.\n+ * @author Robin Arnold", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcxMzM2MA=="}, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 91}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNDUzNDU2OnYy", "diffSide": "RIGHT", "path": "fhir-persistence-scout/src/main/java/com/ibm/fhir/persistence/scout/FHIRPersistenceScoutImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNjowMDoyM1rOHNThuA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNzoxNzo1NVrOHNWHSA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcxMzQ2NA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                /* (non-Javadoc)\n          \n          \n            \n                 * @see com.ibm.fhir.persistence.FHIRPersistence#isDeleteSupported()\n          \n          \n            \n                 */", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483713464", "createdAt": "2020-09-04T16:00:23Z", "author": {"login": "prb112"}, "path": "fhir-persistence-scout/src/main/java/com/ibm/fhir/persistence/scout/FHIRPersistenceScoutImpl.java", "diffHunk": "@@ -0,0 +1,471 @@\n+/**\n+ * (C) Copyright IBM Corp. 2017,2018,2019\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.persistence.scout;\n+\n+import static com.ibm.fhir.config.FHIRConfiguration.PROPERTY_UPDATE_CREATE_ENABLED;\n+import static com.ibm.fhir.model.type.String.string;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.IOException;\n+import java.net.InetSocketAddress;\n+import java.net.URL;\n+import java.sql.Connection;\n+import java.sql.SQLException;\n+import java.sql.Timestamp;\n+import java.text.MessageFormat;\n+import java.time.ZoneOffset;\n+import java.time.temporal.TemporalAccessor;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Base64;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.UUID;\n+import java.util.Map.Entry;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+import java.util.zip.GZIPOutputStream;\n+\n+import javax.transaction.TransactionSynchronizationRegistry;\n+\n+import com.datastax.oss.driver.api.core.CqlSession;\n+import com.datastax.oss.driver.api.core.CqlSessionBuilder;\n+import com.google.gson.Gson;\n+import com.google.gson.GsonBuilder;\n+import com.ibm.fhir.config.FHIRConfigHelper;\n+import com.ibm.fhir.config.FHIRConfiguration;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.config.PropertyGroup;\n+import com.ibm.fhir.core.FHIRUtilities;\n+import com.ibm.fhir.database.utils.common.GetSequenceNextValueDAO;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.resource.OperationOutcome;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.resource.SearchParameter;\n+import com.ibm.fhir.model.resource.OperationOutcome.Issue;\n+import com.ibm.fhir.model.resource.SearchParameter.Component;\n+import com.ibm.fhir.model.type.CodeableConcept;\n+import com.ibm.fhir.model.type.Element;\n+import com.ibm.fhir.model.type.Id;\n+import com.ibm.fhir.model.type.Instant;\n+import com.ibm.fhir.model.type.Meta;\n+import com.ibm.fhir.model.type.code.IssueSeverity;\n+import com.ibm.fhir.model.type.code.IssueType;\n+import com.ibm.fhir.model.type.code.SearchParamType;\n+import com.ibm.fhir.model.util.FHIRUtil;\n+import com.ibm.fhir.model.visitor.Visitable;\n+import com.ibm.fhir.path.FHIRPathNode;\n+import com.ibm.fhir.path.FHIRPathSystemValue;\n+import com.ibm.fhir.path.evaluator.FHIRPathEvaluator;\n+import com.ibm.fhir.path.evaluator.FHIRPathEvaluator.EvaluationContext;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.FHIRPersistenceTransaction;\n+import com.ibm.fhir.persistence.MultiResourceResult;\n+import com.ibm.fhir.persistence.SingleResourceResult;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.exception.FHIRPersistenceException;\n+import com.ibm.fhir.persistence.exception.FHIRPersistenceResourceDeletedException;\n+import com.ibm.fhir.persistence.scout.SearchParameters;\n+import com.ibm.fhir.persistence.scout.SearchParameters.ParameterBlock;\n+import com.ibm.fhir.persistence.scout.SearchParameters.StrValue;\n+import com.ibm.fhir.persistence.scout.SearchParameters.StrValueList;\n+import com.ibm.fhir.persistence.scout.SearchParameters.TokenValue;\n+import com.ibm.fhir.persistence.scout.SearchParameters.TokenValueList;\n+import com.ibm.fhir.persistence.scout.cql.DatasourceSessions;\n+import com.ibm.fhir.search.SearchConstants.Type;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.date.DateTimeHandler;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Scalable persistence layer, storing resources in Cassandra and the corresponding\n+ * indexes in Redis.\n+ * @author Robin Arnold\n+ */\n+public class FHIRPersistenceScoutImpl implements FHIRPersistence {\n+    private static final Logger logger = Logger.getLogger(FHIRPersistenceScoutImpl.class.getName());\n+    private static final String CLASSNAME = FHIRPersistenceScoutImpl.class.getName();\n+    private static final Logger log = Logger.getLogger(CLASSNAME);\n+        \n+    public static final String TRX_SYNCH_REG_JNDI_NAME = \"java:comp/TransactionSynchronizationRegistry\";\n+    \n+    // TODO. Shouldn't be necessary\n+    private static final int MAX_NUM_OF_COMPOSITE_COMPONENTS = 3;\n+    \n+    private TransactionSynchronizationRegistry trxSynchRegistry;\n+    \n+    private boolean updateCreateEnabled;\n+    \n+    private List<OperationOutcome.Issue> supplementalIssues = new ArrayList<>();\n+    \n+\n+    /**\n+     * Constructor for use when running as web application in WLP. \n+     * @throws Exception \n+     */\n+    public FHIRPersistenceScoutImpl() throws Exception {\n+        super();\n+        final String METHODNAME = \"FHIRPersistenceCloudantImpl()\";\n+        log.entering(CLASSNAME, METHODNAME);\n+        \n+        PropertyGroup fhirConfig = FHIRConfiguration.getInstance().loadConfiguration();\n+        this.updateCreateEnabled = fhirConfig.getBooleanProperty(PROPERTY_UPDATE_CREATE_ENABLED, Boolean.TRUE);\n+        log.exiting(CLASSNAME, METHODNAME);\n+    }\n+    \n+    /**\n+     * Constructor for use when running standalone, outside of any web container.\n+     * @throws Exception \n+     */\n+    @SuppressWarnings(\"rawtypes\")\n+    public FHIRPersistenceScoutImpl(Properties configProps) throws Exception {\n+        final String METHODNAME = \"FHIRPersistenceCloudantImpl(Properties)\";\n+        log.entering(CLASSNAME, METHODNAME);\n+        \n+        this.updateCreateEnabled = Boolean.parseBoolean(configProps.getProperty(\"updateCreateEnabled\"));\n+        \n+        log.exiting(CLASSNAME, METHODNAME);\n+    }\n+\n+    /* (non-Javadoc)\n+     * @see com.ibm.fhir.persistence.FHIRPersistence#isDeleteSupported()\n+     */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc1NTg0OA==", "bodyText": "fixed", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483755848", "createdAt": "2020-09-04T17:17:55Z", "author": {"login": "punktilious"}, "path": "fhir-persistence-scout/src/main/java/com/ibm/fhir/persistence/scout/FHIRPersistenceScoutImpl.java", "diffHunk": "@@ -0,0 +1,471 @@\n+/**\n+ * (C) Copyright IBM Corp. 2017,2018,2019\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.persistence.scout;\n+\n+import static com.ibm.fhir.config.FHIRConfiguration.PROPERTY_UPDATE_CREATE_ENABLED;\n+import static com.ibm.fhir.model.type.String.string;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.IOException;\n+import java.net.InetSocketAddress;\n+import java.net.URL;\n+import java.sql.Connection;\n+import java.sql.SQLException;\n+import java.sql.Timestamp;\n+import java.text.MessageFormat;\n+import java.time.ZoneOffset;\n+import java.time.temporal.TemporalAccessor;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Base64;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.UUID;\n+import java.util.Map.Entry;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+import java.util.zip.GZIPOutputStream;\n+\n+import javax.transaction.TransactionSynchronizationRegistry;\n+\n+import com.datastax.oss.driver.api.core.CqlSession;\n+import com.datastax.oss.driver.api.core.CqlSessionBuilder;\n+import com.google.gson.Gson;\n+import com.google.gson.GsonBuilder;\n+import com.ibm.fhir.config.FHIRConfigHelper;\n+import com.ibm.fhir.config.FHIRConfiguration;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.config.PropertyGroup;\n+import com.ibm.fhir.core.FHIRUtilities;\n+import com.ibm.fhir.database.utils.common.GetSequenceNextValueDAO;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.resource.OperationOutcome;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.resource.SearchParameter;\n+import com.ibm.fhir.model.resource.OperationOutcome.Issue;\n+import com.ibm.fhir.model.resource.SearchParameter.Component;\n+import com.ibm.fhir.model.type.CodeableConcept;\n+import com.ibm.fhir.model.type.Element;\n+import com.ibm.fhir.model.type.Id;\n+import com.ibm.fhir.model.type.Instant;\n+import com.ibm.fhir.model.type.Meta;\n+import com.ibm.fhir.model.type.code.IssueSeverity;\n+import com.ibm.fhir.model.type.code.IssueType;\n+import com.ibm.fhir.model.type.code.SearchParamType;\n+import com.ibm.fhir.model.util.FHIRUtil;\n+import com.ibm.fhir.model.visitor.Visitable;\n+import com.ibm.fhir.path.FHIRPathNode;\n+import com.ibm.fhir.path.FHIRPathSystemValue;\n+import com.ibm.fhir.path.evaluator.FHIRPathEvaluator;\n+import com.ibm.fhir.path.evaluator.FHIRPathEvaluator.EvaluationContext;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.FHIRPersistenceTransaction;\n+import com.ibm.fhir.persistence.MultiResourceResult;\n+import com.ibm.fhir.persistence.SingleResourceResult;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.exception.FHIRPersistenceException;\n+import com.ibm.fhir.persistence.exception.FHIRPersistenceResourceDeletedException;\n+import com.ibm.fhir.persistence.scout.SearchParameters;\n+import com.ibm.fhir.persistence.scout.SearchParameters.ParameterBlock;\n+import com.ibm.fhir.persistence.scout.SearchParameters.StrValue;\n+import com.ibm.fhir.persistence.scout.SearchParameters.StrValueList;\n+import com.ibm.fhir.persistence.scout.SearchParameters.TokenValue;\n+import com.ibm.fhir.persistence.scout.SearchParameters.TokenValueList;\n+import com.ibm.fhir.persistence.scout.cql.DatasourceSessions;\n+import com.ibm.fhir.search.SearchConstants.Type;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.date.DateTimeHandler;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Scalable persistence layer, storing resources in Cassandra and the corresponding\n+ * indexes in Redis.\n+ * @author Robin Arnold\n+ */\n+public class FHIRPersistenceScoutImpl implements FHIRPersistence {\n+    private static final Logger logger = Logger.getLogger(FHIRPersistenceScoutImpl.class.getName());\n+    private static final String CLASSNAME = FHIRPersistenceScoutImpl.class.getName();\n+    private static final Logger log = Logger.getLogger(CLASSNAME);\n+        \n+    public static final String TRX_SYNCH_REG_JNDI_NAME = \"java:comp/TransactionSynchronizationRegistry\";\n+    \n+    // TODO. Shouldn't be necessary\n+    private static final int MAX_NUM_OF_COMPOSITE_COMPONENTS = 3;\n+    \n+    private TransactionSynchronizationRegistry trxSynchRegistry;\n+    \n+    private boolean updateCreateEnabled;\n+    \n+    private List<OperationOutcome.Issue> supplementalIssues = new ArrayList<>();\n+    \n+\n+    /**\n+     * Constructor for use when running as web application in WLP. \n+     * @throws Exception \n+     */\n+    public FHIRPersistenceScoutImpl() throws Exception {\n+        super();\n+        final String METHODNAME = \"FHIRPersistenceCloudantImpl()\";\n+        log.entering(CLASSNAME, METHODNAME);\n+        \n+        PropertyGroup fhirConfig = FHIRConfiguration.getInstance().loadConfiguration();\n+        this.updateCreateEnabled = fhirConfig.getBooleanProperty(PROPERTY_UPDATE_CREATE_ENABLED, Boolean.TRUE);\n+        log.exiting(CLASSNAME, METHODNAME);\n+    }\n+    \n+    /**\n+     * Constructor for use when running standalone, outside of any web container.\n+     * @throws Exception \n+     */\n+    @SuppressWarnings(\"rawtypes\")\n+    public FHIRPersistenceScoutImpl(Properties configProps) throws Exception {\n+        final String METHODNAME = \"FHIRPersistenceCloudantImpl(Properties)\";\n+        log.entering(CLASSNAME, METHODNAME);\n+        \n+        this.updateCreateEnabled = Boolean.parseBoolean(configProps.getProperty(\"updateCreateEnabled\"));\n+        \n+        log.exiting(CLASSNAME, METHODNAME);\n+    }\n+\n+    /* (non-Javadoc)\n+     * @see com.ibm.fhir.persistence.FHIRPersistence#isDeleteSupported()\n+     */", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcxMzQ2NA=="}, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 140}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNDU1NjcyOnYy", "diffSide": "RIGHT", "path": "fhir-persistence-scout/src/main/java/com/ibm/fhir/persistence/scout/cql/InsertParameterBlock.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNjowNzoyM1rOHNTvlw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNzoxODo0MFrOHNWIhA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcxNzAxNQ==", "bodyText": "Update in the code for the future? marking just to confirm", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483717015", "createdAt": "2020-09-04T16:07:23Z", "author": {"login": "prb112"}, "path": "fhir-persistence-scout/src/main/java/com/ibm/fhir/persistence/scout/cql/InsertParameterBlock.java", "diffHunk": "@@ -0,0 +1,32 @@\n+/*\n+ * (C) Copyright IBM Corp. 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.persistence.scout.cql;\n+\n+import com.datastax.oss.driver.api.core.CqlSession;\n+import com.ibm.fhir.persistence.scout.SearchParameters.ParameterBlock;\n+\n+/**\n+ * CQL command to insert the parameter block using the resource logical id as the key\n+ */\n+public class InsertParameterBlock {\n+    \n+    private final ParameterBlock parameterBlock;\n+    private final byte[] payload;\n+    \n+    public InsertParameterBlock(ParameterBlock pb, byte[] payload) {\n+        this.parameterBlock = pb;\n+        this.payload = payload;\n+    }\n+\n+    /**\n+     * Run the command against the given session\n+     * @param s\n+     */\n+    public void run(CqlSession s) {\n+        ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc1NjE2NA==", "bodyText": "Yes, this is a work in progress, but sharing to give others visibility.", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483756164", "createdAt": "2020-09-04T17:18:40Z", "author": {"login": "punktilious"}, "path": "fhir-persistence-scout/src/main/java/com/ibm/fhir/persistence/scout/cql/InsertParameterBlock.java", "diffHunk": "@@ -0,0 +1,32 @@\n+/*\n+ * (C) Copyright IBM Corp. 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.persistence.scout.cql;\n+\n+import com.datastax.oss.driver.api.core.CqlSession;\n+import com.ibm.fhir.persistence.scout.SearchParameters.ParameterBlock;\n+\n+/**\n+ * CQL command to insert the parameter block using the resource logical id as the key\n+ */\n+public class InsertParameterBlock {\n+    \n+    private final ParameterBlock parameterBlock;\n+    private final byte[] payload;\n+    \n+    public InsertParameterBlock(ParameterBlock pb, byte[] payload) {\n+        this.parameterBlock = pb;\n+        this.payload = payload;\n+    }\n+\n+    /**\n+     * Run the command against the given session\n+     * @param s\n+     */\n+    public void run(CqlSession s) {\n+        ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcxNzAxNQ=="}, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNDU2MjYwOnYy", "diffSide": "RIGHT", "path": "fhir-persistence-scout/src/main/protobuf/SearchParameters.proto", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNjowOToyNlrOHNTzVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNzoxOTo1MlrOHNWKlA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcxNzk3Mw==", "bodyText": "should we add a copyright here?", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483717973", "createdAt": "2020-09-04T16:09:26Z", "author": {"login": "prb112"}, "path": "fhir-persistence-scout/src/main/protobuf/SearchParameters.proto", "diffHunk": "@@ -0,0 +1,91 @@\n+syntax = \"proto3\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc1NjY5Mg==", "bodyText": "fixed", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483756692", "createdAt": "2020-09-04T17:19:52Z", "author": {"login": "punktilious"}, "path": "fhir-persistence-scout/src/main/protobuf/SearchParameters.proto", "diffHunk": "@@ -0,0 +1,91 @@\n+syntax = \"proto3\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcxNzk3Mw=="}, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNDU2MzUyOnYy", "diffSide": "RIGHT", "path": "fhir-persistence-scout/src/test/java/com/ibm/fhir/persistence/scale/test/ConfigTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNjowOTo0M1rOHNTz6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxNzoxOToyNFrOHNWJrw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcxODEyMQ==", "bodyText": "no op?", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483718121", "createdAt": "2020-09-04T16:09:43Z", "author": {"login": "prb112"}, "path": "fhir-persistence-scout/src/test/java/com/ibm/fhir/persistence/scale/test/ConfigTest.java", "diffHunk": "@@ -0,0 +1,21 @@\n+/*\n+ * (C) Copyright IBM Corp. 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.persistence.scale.test;\n+\n+import org.testng.annotations.Test;\n+\n+/**\n+ *\n+ */\n+public class ConfigTest {\n+\n+    @Test\n+    public void test1() {\n+        ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc1NjQ2Mw==", "bodyText": "work in progress", "url": "https://github.com/IBM/FHIR/pull/1476#discussion_r483756463", "createdAt": "2020-09-04T17:19:24Z", "author": {"login": "punktilious"}, "path": "fhir-persistence-scout/src/test/java/com/ibm/fhir/persistence/scale/test/ConfigTest.java", "diffHunk": "@@ -0,0 +1,21 @@\n+/*\n+ * (C) Copyright IBM Corp. 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.persistence.scale.test;\n+\n+import org.testng.annotations.Test;\n+\n+/**\n+ *\n+ */\n+public class ConfigTest {\n+\n+    @Test\n+    public void test1() {\n+        ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzcxODEyMQ=="}, "originalCommit": {"oid": "d049d1228b4a41e37360ff28da2a2168f3df0e0f"}, "originalPosition": 18}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4824, "cost": 1, "resetAt": "2021-11-13T12:10:21Z"}}}