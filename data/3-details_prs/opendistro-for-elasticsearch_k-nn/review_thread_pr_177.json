{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU2NDk1MTk1", "number": 177, "reviewThreads": {"totalCount": 24, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQyMTozNTowOVrOER-O1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMToyMDowOVrOES_0OQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3MjgwODUzOnYy", "diffSide": "RIGHT", "path": "PerformanceTuning.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQyMTozNTowOVrOG2-YgA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNVQwNTozMTozNVrOG3Cotw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDI5ODM2OA==", "bodyText": "replace \"In this section\" with \"In this document,\"\nAlso, replace \"On a high level\" with \"From a high level,\"\nAlso, add a \":\" after principles.", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r460298368", "createdAt": "2020-07-24T21:35:09Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM2ODA1NQ==", "bodyText": "Done", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r460368055", "createdAt": "2020-07-25T05:31:35Z", "author": {"login": "vamshin"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDI5ODM2OA=="}, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3MjgxMTM4OnYy", "diffSide": "RIGHT", "path": "PerformanceTuning.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQyMTozNjo0MFrOG2-aSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNVQwNTozMTo0MlrOG3Coww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDI5ODgyNg==", "bodyText": "Remove the period at the end if it is a list item", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r460298826", "createdAt": "2020-07-24T21:36:40Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM2ODA2Nw==", "bodyText": "Done", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r460368067", "createdAt": "2020-07-25T05:31:42Z", "author": {"login": "vamshin"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDI5ODgyNg=="}, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3MjgxNDY2OnYy", "diffSide": "RIGHT", "path": "PerformanceTuning.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQyMTozODoxNFrOG2-cTQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNVQwNTozMTo1MVrOG3Co1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDI5OTM0MQ==", "bodyText": "Same as above\nAlso instead of adding single quotes around k, just Italicize it like *k*. Do the same with size.", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r460299341", "createdAt": "2020-07-24T21:38:14Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM2ODA4Nw==", "bodyText": "Good point. Done", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r460368087", "createdAt": "2020-07-25T05:31:51Z", "author": {"login": "vamshin"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDI5OTM0MQ=="}, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3Mjg3OTM5OnYy", "diffSide": "RIGHT", "path": "PerformanceTuning.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQyMjoxMDoyNFrOG2_Cpw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNVQwNTozMjozMVrOG3Co9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMwOTE1OQ==", "bodyText": "Start sentence with \"The\".", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r460309159", "createdAt": "2020-07-24T22:10:24Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.\n+\n+##Indexing Performance Tuning\n+\n+Following steps could help improve indexing performance especially when you plan to index large number of vectors at once. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM2ODExOQ==", "bodyText": "Done", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r460368119", "createdAt": "2020-07-25T05:32:31Z", "author": {"login": "vamshin"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.\n+\n+##Indexing Performance Tuning\n+\n+Following steps could help improve indexing performance especially when you plan to index large number of vectors at once. ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMwOTE1OQ=="}, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3Mjg4MDY4OnYy", "diffSide": "RIGHT", "path": "PerformanceTuning.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQyMjoxMToxNFrOG2_DZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNVQwNTo1MzoyNlrOG3CvNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMwOTM1MA==", "bodyText": "Could you add a sentence description here?", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r460309350", "createdAt": "2020-07-24T22:11:14Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.\n+\n+##Indexing Performance Tuning\n+\n+Following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+* Disable flush", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM2OTcxNw==", "bodyText": "I changed my mind to not include this step. Default settings for translog is 512MB which seems to be safe setting. 10GB would be too much for smaller instance types with low disk space .", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r460369717", "createdAt": "2020-07-25T05:53:26Z", "author": {"login": "vamshin"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.\n+\n+##Indexing Performance Tuning\n+\n+Following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+* Disable flush", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMwOTM1MA=="}, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3Mjg4MTg1OnYy", "diffSide": "RIGHT", "path": "PerformanceTuning.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQyMjoxMTo0M1rOG2_ECA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQyMjoxMTo0M1rOG2_ECA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMwOTUxMg==", "bodyText": "Change this to \"Enable Replicas after indexing\"", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r460309512", "createdAt": "2020-07-24T22:11:43Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.\n+\n+##Indexing Performance Tuning\n+\n+Following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+* Disable flush\n+ ```\n+    Increase the \"index.translog.flush_threshold_size\" to some bigger value lets say \"10gb\", default is 512MB\n+ ```\n+* No Replicas (No Elasticsearch replica shard)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3Mjg4Mzc2OnYy", "diffSide": "RIGHT", "path": "PerformanceTuning.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQyMjoxMjoyOFrOG2_FAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QyMjozNzoxN1rOG32BAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMwOTc2MQ==", "bodyText": "Is there any risk associated with not having replicas during indexing?", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r460309761", "createdAt": "2020-07-24T22:12:28Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.\n+\n+##Indexing Performance Tuning\n+\n+Following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+* Disable flush\n+ ```\n+    Increase the \"index.translog.flush_threshold_size\" to some bigger value lets say \"10gb\", default is 512MB\n+ ```\n+* No Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIwOTg1OA==", "bodyText": "Yes. I pointed the doc to read more about this section. It is covered there. To avoid confusion adding a note in the paragraph.", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461209858", "createdAt": "2020-07-27T22:37:17Z", "author": {"login": "vamshin"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.\n+\n+##Indexing Performance Tuning\n+\n+Following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+* Disable flush\n+ ```\n+    Increase the \"index.translog.flush_threshold_size\" to some bigger value lets say \"10gb\", default is 512MB\n+ ```\n+* No Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMwOTc2MQ=="}, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3Mjk0MDk5OnYy", "diffSide": "RIGHT", "path": "PerformanceTuning.md", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQyMjo0Mzo0NVrOG2_mbA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxOTowMDoyOVrOG4aTKQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMxODMxNg==", "bodyText": "I think I gave wrong information on this. I believe Lucene's IndexSearcher uses a threadpool to search over different segments concurrently, right?", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r460318316", "createdAt": "2020-07-24T22:43:45Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.\n+\n+##Indexing Performance Tuning\n+\n+Following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+* Disable flush\n+ ```\n+    Increase the \"index.translog.flush_threshold_size\" to some bigger value lets say \"10gb\", default is 512MB\n+ ```\n+* No Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied.\n+ ```\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose have multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)\n+\n+* Forcemerge \n+  \n+ Forcemerge is a costly operation and could take a while depending on number of segments and size of the segments.\n+ To ensure force merge is completed, we could keep calling forcemerge with 5 minute interval till you get 200 response.\n+    \n+    curl -X POST \"localhost:9200/myindex/_forcemerge?max_num_segments=1&pretty\"\n+    \n+* Call refresh \n+\n+ Might not needed but to ensure the buffer is cleared and all segments are up. \n+ ```\n+  POST /twitter/_refresh\n+```\n+* Add replicas (replica shards)\n+\n+* We can now enable replicas to copy the serialized graphs\n+\n+*  Enable refresh interval\n+ ```\n+      PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"1m\"\n+            }\n+        }\n+ ```\n+\n+Please refer following doc (https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html) for more details on improving indexing performance in general.\n+\n+##Search Performance Tuning\n+\n+### Warm up\n+\n+The graphs are constructed during indexing, but they are loaded into memory during the first search. The way search works in Lucene is that each segment is searched sequentially (so, for k-NN, each segment returns up to k nearest neighbors of the query point) and the results are aggregated together and ranked based on the score of each result (higher score --> better result). ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIxMDQxNA==", "bodyText": "Elasticsearch uses single thread for IndexSearcher and hence segments are searched sequentially. Parallelism in shard is not achieved with current Elasticsearch code.", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461210414", "createdAt": "2020-07-27T22:38:55Z", "author": {"login": "vamshin"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.\n+\n+##Indexing Performance Tuning\n+\n+Following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+* Disable flush\n+ ```\n+    Increase the \"index.translog.flush_threshold_size\" to some bigger value lets say \"10gb\", default is 512MB\n+ ```\n+* No Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied.\n+ ```\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose have multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)\n+\n+* Forcemerge \n+  \n+ Forcemerge is a costly operation and could take a while depending on number of segments and size of the segments.\n+ To ensure force merge is completed, we could keep calling forcemerge with 5 minute interval till you get 200 response.\n+    \n+    curl -X POST \"localhost:9200/myindex/_forcemerge?max_num_segments=1&pretty\"\n+    \n+* Call refresh \n+\n+ Might not needed but to ensure the buffer is cleared and all segments are up. \n+ ```\n+  POST /twitter/_refresh\n+```\n+* Add replicas (replica shards)\n+\n+* We can now enable replicas to copy the serialized graphs\n+\n+*  Enable refresh interval\n+ ```\n+      PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"1m\"\n+            }\n+        }\n+ ```\n+\n+Please refer following doc (https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html) for more details on improving indexing performance in general.\n+\n+##Search Performance Tuning\n+\n+### Warm up\n+\n+The graphs are constructed during indexing, but they are loaded into memory during the first search. The way search works in Lucene is that each segment is searched sequentially (so, for k-NN, each segment returns up to k nearest neighbors of the query point) and the results are aggregated together and ranked based on the score of each result (higher score --> better result). ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMxODMxNg=="}, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIzNDU1MA==", "bodyText": "Is there documentation for this?", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461234550", "createdAt": "2020-07-27T23:49:57Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.\n+\n+##Indexing Performance Tuning\n+\n+Following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+* Disable flush\n+ ```\n+    Increase the \"index.translog.flush_threshold_size\" to some bigger value lets say \"10gb\", default is 512MB\n+ ```\n+* No Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied.\n+ ```\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose have multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)\n+\n+* Forcemerge \n+  \n+ Forcemerge is a costly operation and could take a while depending on number of segments and size of the segments.\n+ To ensure force merge is completed, we could keep calling forcemerge with 5 minute interval till you get 200 response.\n+    \n+    curl -X POST \"localhost:9200/myindex/_forcemerge?max_num_segments=1&pretty\"\n+    \n+* Call refresh \n+\n+ Might not needed but to ensure the buffer is cleared and all segments are up. \n+ ```\n+  POST /twitter/_refresh\n+```\n+* Add replicas (replica shards)\n+\n+* We can now enable replicas to copy the serialized graphs\n+\n+*  Enable refresh interval\n+ ```\n+      PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"1m\"\n+            }\n+        }\n+ ```\n+\n+Please refer following doc (https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html) for more details on improving indexing performance in general.\n+\n+##Search Performance Tuning\n+\n+### Warm up\n+\n+The graphs are constructed during indexing, but they are loaded into memory during the first search. The way search works in Lucene is that each segment is searched sequentially (so, for k-NN, each segment returns up to k nearest neighbors of the query point) and the results are aggregated together and ranked based on the score of each result (higher score --> better result). ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMxODMxNg=="}, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTMyNTQ3Nw==", "bodyText": "I could not find a documentation but here is the code pointers. IndexSearcher class has couple of constructors and one of the constructor accepts Executor class which runs the segments parallely by batching them as per the size. Elasticsearch uses other constructor which does not have Executor and segments are searched sequentially", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461325477", "createdAt": "2020-07-28T05:23:30Z", "author": {"login": "vamshin"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.\n+\n+##Indexing Performance Tuning\n+\n+Following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+* Disable flush\n+ ```\n+    Increase the \"index.translog.flush_threshold_size\" to some bigger value lets say \"10gb\", default is 512MB\n+ ```\n+* No Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied.\n+ ```\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose have multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)\n+\n+* Forcemerge \n+  \n+ Forcemerge is a costly operation and could take a while depending on number of segments and size of the segments.\n+ To ensure force merge is completed, we could keep calling forcemerge with 5 minute interval till you get 200 response.\n+    \n+    curl -X POST \"localhost:9200/myindex/_forcemerge?max_num_segments=1&pretty\"\n+    \n+* Call refresh \n+\n+ Might not needed but to ensure the buffer is cleared and all segments are up. \n+ ```\n+  POST /twitter/_refresh\n+```\n+* Add replicas (replica shards)\n+\n+* We can now enable replicas to copy the serialized graphs\n+\n+*  Enable refresh interval\n+ ```\n+      PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"1m\"\n+            }\n+        }\n+ ```\n+\n+Please refer following doc (https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html) for more details on improving indexing performance in general.\n+\n+##Search Performance Tuning\n+\n+### Warm up\n+\n+The graphs are constructed during indexing, but they are loaded into memory during the first search. The way search works in Lucene is that each segment is searched sequentially (so, for k-NN, each segment returns up to k nearest neighbors of the query point) and the results are aggregated together and ranked based on the score of each result (higher score --> better result). ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMxODMxNg=="}, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTgwNDMyOQ==", "bodyText": "Interesting, makes sense thanks", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461804329", "createdAt": "2020-07-28T19:00:29Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.\n+\n+##Indexing Performance Tuning\n+\n+Following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+* Disable flush\n+ ```\n+    Increase the \"index.translog.flush_threshold_size\" to some bigger value lets say \"10gb\", default is 512MB\n+ ```\n+* No Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied.\n+ ```\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose have multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)\n+\n+* Forcemerge \n+  \n+ Forcemerge is a costly operation and could take a while depending on number of segments and size of the segments.\n+ To ensure force merge is completed, we could keep calling forcemerge with 5 minute interval till you get 200 response.\n+    \n+    curl -X POST \"localhost:9200/myindex/_forcemerge?max_num_segments=1&pretty\"\n+    \n+* Call refresh \n+\n+ Might not needed but to ensure the buffer is cleared and all segments are up. \n+ ```\n+  POST /twitter/_refresh\n+```\n+* Add replicas (replica shards)\n+\n+* We can now enable replicas to copy the serialized graphs\n+\n+*  Enable refresh interval\n+ ```\n+      PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"1m\"\n+            }\n+        }\n+ ```\n+\n+Please refer following doc (https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html) for more details on improving indexing performance in general.\n+\n+##Search Performance Tuning\n+\n+### Warm up\n+\n+The graphs are constructed during indexing, but they are loaded into memory during the first search. The way search works in Lucene is that each segment is searched sequentially (so, for k-NN, each segment returns up to k nearest neighbors of the query point) and the results are aggregated together and ranked based on the score of each result (higher score --> better result). ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMxODMxNg=="}, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 84}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3Mjk2MTY1OnYy", "diffSide": "RIGHT", "path": "PerformanceTuning.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQyMjo1NjoxM1rOG2_yhw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QyMzowNTo1NVrOG32pdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMyMTQxNQ==", "bodyText": "So, say we have a somewhat sizeable shard, but within the Elasticsearch recommendation. Say 20 GB. In this case, it probably wouldn't make sense to have a single segment right? Would it be better to discuss the tradeoff instead of just saying 1 segment?\n\"Lucene's IndexSearcher will search over all of the segments in a shard to find the size best results. Searching over a large amount of smaller graphs and then selecting the top size results may result in higher recall than just searching over a smaller number of larger graphs. But, because the complexity of search for the HNSW algorithm is logarithmic with respect to the number of vectors, searching over 5 graphs with a 100 vectors each and then taking the top size results from 5*k results will take longer than searching over 1 graph with 500 vectors and then taking the top size results from k results (ignoring concurrency for the sake of example). That being said, it is important to understand your system's requirements for latency and accuracy, and then to choose the number of segments you want your index to have based on experimentation.", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r460321415", "createdAt": "2020-07-24T22:56:13Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyMDIxMw==", "bodyText": "Good point to call the trade offs. Added information in the respective sections.", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461220213", "createdAt": "2020-07-27T23:05:55Z", "author": {"login": "vamshin"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMyMTQxNQ=="}, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3Mjk2MjczOnYy", "diffSide": "RIGHT", "path": "PerformanceTuning.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQyMjo1Njo1MFrOG2_zKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNVQwNTozMzoxOFrOG3CpIA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMyMTU3Nw==", "bodyText": "has instead of have.", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r460321577", "createdAt": "2020-07-24T22:56:50Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.\n+\n+##Indexing Performance Tuning\n+\n+Following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+* Disable flush\n+ ```\n+    Increase the \"index.translog.flush_threshold_size\" to some bigger value lets say \"10gb\", default is 512MB\n+ ```\n+* No Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied.\n+ ```\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose have multiple cores, we could allow multiple threads ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM2ODE2MA==", "bodyText": "done", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r460368160", "createdAt": "2020-07-25T05:33:18Z", "author": {"login": "vamshin"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.\n+\n+##Indexing Performance Tuning\n+\n+Following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+* Disable flush\n+ ```\n+    Increase the \"index.translog.flush_threshold_size\" to some bigger value lets say \"10gb\", default is 512MB\n+ ```\n+* No Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied.\n+ ```\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose have multiple cores, we could allow multiple threads ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMyMTU3Nw=="}, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3Mjk2MzMyOnYy", "diffSide": "RIGHT", "path": "PerformanceTuning.md", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQyMjo1NzoxM1rOG2_zfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQwNTowMDo1NlrOG38rhg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMyMTY2MQ==", "bodyText": "Add comment here describing in more depth", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r460321661", "createdAt": "2020-07-24T22:57:13Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.\n+\n+##Indexing Performance Tuning\n+\n+Following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+* Disable flush\n+ ```\n+    Increase the \"index.translog.flush_threshold_size\" to some bigger value lets say \"10gb\", default is 512MB\n+ ```\n+* No Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied.\n+ ```\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose have multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM2ODE5NQ==", "bodyText": "I think its self explanatory.", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r460368195", "createdAt": "2020-07-25T05:33:55Z", "author": {"login": "vamshin"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.\n+\n+##Indexing Performance Tuning\n+\n+Following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+* Disable flush\n+ ```\n+    Increase the \"index.translog.flush_threshold_size\" to some bigger value lets say \"10gb\", default is 512MB\n+ ```\n+* No Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied.\n+ ```\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose have multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMyMTY2MQ=="}, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIzNDEwMQ==", "bodyText": "Ah so I think whats confusing on this point is that it references \"the following steps\", but they are bullet points. So, its more about the workflow that should be followed as opposed to independent tips.", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461234101", "createdAt": "2020-07-27T23:48:28Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.\n+\n+##Indexing Performance Tuning\n+\n+Following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+* Disable flush\n+ ```\n+    Increase the \"index.translog.flush_threshold_size\" to some bigger value lets say \"10gb\", default is 512MB\n+ ```\n+* No Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied.\n+ ```\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose have multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMyMTY2MQ=="}, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTMxOTA0Ng==", "bodyText": "Correct this is more like a workflow of steps. Changed to numbers instead of bullet points.", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461319046", "createdAt": "2020-07-28T05:00:56Z", "author": {"login": "vamshin"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.\n+\n+##Indexing Performance Tuning\n+\n+Following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+* Disable flush\n+ ```\n+    Increase the \"index.translog.flush_threshold_size\" to some bigger value lets say \"10gb\", default is 512MB\n+ ```\n+* No Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied.\n+ ```\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose have multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMyMTY2MQ=="}, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3Mjk2NDIwOnYy", "diffSide": "RIGHT", "path": "PerformanceTuning.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQyMjo1Nzo1M1rOG2_0DA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNVQwNTozNDo1MVrOG3CpiA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMyMTgwNA==", "bodyText": "I dont think you will need to do this. If forcemerge times out, it will continue to run.", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r460321804", "createdAt": "2020-07-24T22:57:53Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.\n+\n+##Indexing Performance Tuning\n+\n+Following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+* Disable flush\n+ ```\n+    Increase the \"index.translog.flush_threshold_size\" to some bigger value lets say \"10gb\", default is 512MB\n+ ```\n+* No Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied.\n+ ```\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose have multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)\n+\n+* Forcemerge ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM2ODI2NA==", "bodyText": "Correct it will continue to run but to figure out when forcemerge is completed, we need to kind of poll it.\nWe could either keep calling it or poll the tasks api.", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r460368264", "createdAt": "2020-07-25T05:34:51Z", "author": {"login": "vamshin"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.\n+\n+##Indexing Performance Tuning\n+\n+Following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+* Disable flush\n+ ```\n+    Increase the \"index.translog.flush_threshold_size\" to some bigger value lets say \"10gb\", default is 512MB\n+ ```\n+* No Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied.\n+ ```\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose have multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)\n+\n+* Forcemerge ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMyMTgwNA=="}, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3Mjk2NDk4OnYy", "diffSide": "RIGHT", "path": "PerformanceTuning.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQyMjo1ODoyMVrOG2_0ew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNVQwNTozNzoxNFrOG3CqSA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMyMTkxNQ==", "bodyText": "Please add description for how this helps", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r460321915", "createdAt": "2020-07-24T22:58:21Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.\n+\n+##Indexing Performance Tuning\n+\n+Following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+* Disable flush\n+ ```\n+    Increase the \"index.translog.flush_threshold_size\" to some bigger value lets say \"10gb\", default is 512MB\n+ ```\n+* No Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied.\n+ ```\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose have multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)\n+\n+* Forcemerge \n+  \n+ Forcemerge is a costly operation and could take a while depending on number of segments and size of the segments.\n+ To ensure force merge is completed, we could keep calling forcemerge with 5 minute interval till you get 200 response.\n+    \n+    curl -X POST \"localhost:9200/myindex/_forcemerge?max_num_segments=1&pretty\"\n+    \n+* Call refresh \n+\n+ Might not needed but to ensure the buffer is cleared and all segments are up. \n+ ```\n+  POST /twitter/_refresh\n+```\n+* Add replicas (replica shards)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM2ODQ1Ng==", "bodyText": "Done", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r460368456", "createdAt": "2020-07-25T05:37:14Z", "author": {"login": "vamshin"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.\n+\n+##Indexing Performance Tuning\n+\n+Following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+* Disable flush\n+ ```\n+    Increase the \"index.translog.flush_threshold_size\" to some bigger value lets say \"10gb\", default is 512MB\n+ ```\n+* No Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied.\n+ ```\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose have multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)\n+\n+* Forcemerge \n+  \n+ Forcemerge is a costly operation and could take a while depending on number of segments and size of the segments.\n+ To ensure force merge is completed, we could keep calling forcemerge with 5 minute interval till you get 200 response.\n+    \n+    curl -X POST \"localhost:9200/myindex/_forcemerge?max_num_segments=1&pretty\"\n+    \n+* Call refresh \n+\n+ Might not needed but to ensure the buffer is cleared and all segments are up. \n+ ```\n+  POST /twitter/_refresh\n+```\n+* Add replicas (replica shards)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMyMTkxNQ=="}, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3Mjk2NTUwOnYy", "diffSide": "RIGHT", "path": "PerformanceTuning.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQyMjo1ODozM1rOG2_0vA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNVQwNTozODowM1rOG3Cqnw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMyMTk4MA==", "bodyText": "Could you add description here?", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r460321980", "createdAt": "2020-07-24T22:58:33Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.\n+\n+##Indexing Performance Tuning\n+\n+Following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+* Disable flush\n+ ```\n+    Increase the \"index.translog.flush_threshold_size\" to some bigger value lets say \"10gb\", default is 512MB\n+ ```\n+* No Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied.\n+ ```\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose have multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)\n+\n+* Forcemerge \n+  \n+ Forcemerge is a costly operation and could take a while depending on number of segments and size of the segments.\n+ To ensure force merge is completed, we could keep calling forcemerge with 5 minute interval till you get 200 response.\n+    \n+    curl -X POST \"localhost:9200/myindex/_forcemerge?max_num_segments=1&pretty\"\n+    \n+* Call refresh ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM2ODU0Mw==", "bodyText": "Done", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r460368543", "createdAt": "2020-07-25T05:38:03Z", "author": {"login": "vamshin"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,147 @@\n+#KNN Performance Tuning\n+\n+\n+In this section we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  On a high level k-NN works on following principles\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query). \n+* Each graph in the segment returns \u2018k\u2019 neighbors and the size results with the highest score is returned by the coordinating node. Note that size can be greater or smaller than k.\n+\n+To improve performance it is necessary to keep the number of segments under control. Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We can achieve more parallelism by having more shards per index. We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval, increasing the flush threshold OR force-merging to 1 segment after all the indexing finishes and before searches.\n+\n+##Indexing Performance Tuning\n+\n+Following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+* Disable flush\n+ ```\n+    Increase the \"index.translog.flush_threshold_size\" to some bigger value lets say \"10gb\", default is 512MB\n+ ```\n+* No Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied.\n+ ```\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose have multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)\n+\n+* Forcemerge \n+  \n+ Forcemerge is a costly operation and could take a while depending on number of segments and size of the segments.\n+ To ensure force merge is completed, we could keep calling forcemerge with 5 minute interval till you get 200 response.\n+    \n+    curl -X POST \"localhost:9200/myindex/_forcemerge?max_num_segments=1&pretty\"\n+    \n+* Call refresh ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMyMTk4MA=="}, "originalCommit": {"oid": "46330950b1d4197cd8ad88f53f8d3111f44c7980"}, "originalPosition": 58}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4Mjk0Nzc0OnYy", "diffSide": "RIGHT", "path": "PerformanceTuning.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxODo0MDowMFrOG4ZmHA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxOTozNjowN1rOG4bhsw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTc5Mjc5Ng==", "bodyText": "Add space between # and KNN", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461792796", "createdAt": "2020-07-28T18:40:00Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,157 @@\n+#KNN Performance Tuning", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "330076a7c161280ab679c26226c2f44ec1e19d5a"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTgyNDQzNQ==", "bodyText": "Done", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461824435", "createdAt": "2020-07-28T19:36:07Z", "author": {"login": "vamshin"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,157 @@\n+#KNN Performance Tuning", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTc5Mjc5Ng=="}, "originalCommit": {"oid": "330076a7c161280ab679c26226c2f44ec1e19d5a"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4Mjk0ODQwOnYy", "diffSide": "RIGHT", "path": "PerformanceTuning.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxODo0MDoxMlrOG4Zmhg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxOTozNjoxNFrOG4bh6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTc5MjkwMg==", "bodyText": "Add Space", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461792902", "createdAt": "2020-07-28T18:40:12Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,157 @@\n+#KNN Performance Tuning\n+\n+\n+In this document we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  From a high level k-NN works on following principles:\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query) \n+* Each graph in the segment returns *<=k* neighbors. \n+* Coordinator node picks up final *size* number of neighbors from the neighbors returned by each shard\n+\n+##Indexing Performance Tuning", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "330076a7c161280ab679c26226c2f44ec1e19d5a"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTgyNDQ5MQ==", "bodyText": "Done", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461824491", "createdAt": "2020-07-28T19:36:14Z", "author": {"login": "vamshin"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,157 @@\n+#KNN Performance Tuning\n+\n+\n+In this document we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  From a high level k-NN works on following principles:\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query) \n+* Each graph in the segment returns *<=k* neighbors. \n+* Coordinator node picks up final *size* number of neighbors from the neighbors returned by each shard\n+\n+##Indexing Performance Tuning", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTc5MjkwMg=="}, "originalCommit": {"oid": "330076a7c161280ab679c26226c2f44ec1e19d5a"}, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4Mjk1NTIxOnYy", "diffSide": "RIGHT", "path": "PerformanceTuning.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxODo0MjoxMlrOG4Zqpw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxOTozODowOVrOG4bnDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTc5Mzk1OQ==", "bodyText": "If we already called force merge, we dont need to call refresh, correct?", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461793959", "createdAt": "2020-07-28T18:42:12Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,157 @@\n+#KNN Performance Tuning\n+\n+\n+In this document we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  From a high level k-NN works on following principles:\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query) \n+* Each graph in the segment returns *<=k* neighbors. \n+* Coordinator node picks up final *size* number of neighbors from the neighbors returned by each shard\n+\n+##Indexing Performance Tuning\n+\n+The following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+\n+* Disable Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied. Having no replicas means that losing \n+    a node(s) may incur data loss, so it is important that the data lives elsewhere \n+    so that this initial load can be retried in case of an issue.\n+ ```\n+More details [here](https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html#_disable_replicas_for_initial_loads)\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose has multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)\n+\n+* Forcemerge \n+  \n+ Forcemerge is a costly operation and could take a while depending on number of segments and size of the segments.\n+ To ensure force merge is completed, we could keep calling forcemerge with 5 minute interval till you get 200 response.\n+    \n+    curl -X POST \"localhost:9200/myindex/_forcemerge?max_num_segments=1&pretty\"\n+    \n+* Call refresh ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "330076a7c161280ab679c26226c2f44ec1e19d5a"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTgyNTgwNA==", "bodyText": "Correct. This step is just to ensure all documents are available for search. More like a safety check", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461825804", "createdAt": "2020-07-28T19:38:09Z", "author": {"login": "vamshin"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,157 @@\n+#KNN Performance Tuning\n+\n+\n+In this document we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  From a high level k-NN works on following principles:\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query) \n+* Each graph in the segment returns *<=k* neighbors. \n+* Coordinator node picks up final *size* number of neighbors from the neighbors returned by each shard\n+\n+##Indexing Performance Tuning\n+\n+The following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+\n+* Disable Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied. Having no replicas means that losing \n+    a node(s) may incur data loss, so it is important that the data lives elsewhere \n+    so that this initial load can be retried in case of an issue.\n+ ```\n+More details [here](https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html#_disable_replicas_for_initial_loads)\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose has multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)\n+\n+* Forcemerge \n+  \n+ Forcemerge is a costly operation and could take a while depending on number of segments and size of the segments.\n+ To ensure force merge is completed, we could keep calling forcemerge with 5 minute interval till you get 200 response.\n+    \n+    curl -X POST \"localhost:9200/myindex/_forcemerge?max_num_segments=1&pretty\"\n+    \n+* Call refresh ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTc5Mzk1OQ=="}, "originalCommit": {"oid": "330076a7c161280ab679c26226c2f44ec1e19d5a"}, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4Mjk2NTM3OnYy", "diffSide": "RIGHT", "path": "PerformanceTuning.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxODo0NTowOFrOG4Zw6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxOTozOToyM1rOG4brpQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTc5NTU2MQ==", "bodyText": "Add space", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461795561", "createdAt": "2020-07-28T18:45:08Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,157 @@\n+#KNN Performance Tuning\n+\n+\n+In this document we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  From a high level k-NN works on following principles:\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query) \n+* Each graph in the segment returns *<=k* neighbors. \n+* Coordinator node picks up final *size* number of neighbors from the neighbors returned by each shard\n+\n+##Indexing Performance Tuning\n+\n+The following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+\n+* Disable Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied. Having no replicas means that losing \n+    a node(s) may incur data loss, so it is important that the data lives elsewhere \n+    so that this initial load can be retried in case of an issue.\n+ ```\n+More details [here](https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html#_disable_replicas_for_initial_loads)\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose has multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)\n+\n+* Forcemerge \n+  \n+ Forcemerge is a costly operation and could take a while depending on number of segments and size of the segments.\n+ To ensure force merge is completed, we could keep calling forcemerge with 5 minute interval till you get 200 response.\n+    \n+    curl -X POST \"localhost:9200/myindex/_forcemerge?max_num_segments=1&pretty\"\n+    \n+* Call refresh \n+\n+ Calling refresh ensure the buffer is cleared and all segments are created so that documents are available for search. \n+ ```\n+  POST /twitter/_refresh\n+```\n+* Add replicas (replica shards)\n+ \n+ This will make replica shards come up with the already serialized graphs created on the primary shards during indexing. This way \n+ we avoid duplicate graph construction.\n+\n+* We can now enable replicas to copy the serialized graphs\n+\n+*  Enable refresh interval\n+ ```\n+      PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"1m\"\n+            }\n+        }\n+ ```\n+\n+Please refer following doc (https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html) for more details on improving indexing performance in general.\n+\n+##Search Performance Tuning\n+\n+To improve Search performance it is necessary to keep the number of segments under control. Lucene's IndexSearcher will search over all of the segments in a shard to find the 'size' best results. But, because the complexity of search for the HNSW algorithm is logarithmic with respect to the number of vectors, searching over 5 graphs with a 100 vectors each and then taking the top size results from ```5*k``` results will take longer than searching over 1 graph with 500 vectors and then taking the top size results from k results. \n+Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We could configure index to have multiple shards to aviod having giant shards and achieve more parallelism.\n+\n+We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval.\n+\n+### Warm up\n+\n+The graphs are constructed during indexing, but they are loaded into memory during the first search. The way search works in Lucene is that each segment is searched sequentially (so, for k-NN, each segment returns up to k nearest neighbors of the query point) and the results are aggregated together and ranked based on the score of each result (higher score --> better result). \n+\n+Once a graph is loaded(graphs are loaded outside Elasticsearch JVM), we cache the graphs in memory. So the initial queries would be expensive in the order of few seconds and subsequent queries should be faster in the order of milliseconds(assuming knn circuit breaker is not hit).\n+\n+In order to avoid this latency penalty during your first queries, a user should use the warmup API on the indices they want to search. The API looks like this:\n+\n+GET /_opendistro/_knn/warmup/index1,index2,index3?pretty\n+{\n+  \"_shards\" : {\n+    \"total\" : 6,\n+    \"successful\" : 6,\n+    \"failed\" : 0\n+  }\n+}\n+\n+The API loads all of the graphs for all of the shards (primaries and replicas) for the specified indices into the cache. Thus, there will be no penalty to load graphs during initial searches. *Note \u2014 * this API only loads the segments of the indices it sees into the cache. If a merge or refresh operation finishes after this API is ran or if new documents are added, this API will need to be re-ran to load those graphs into memory.\n+\n+### Avoid reading stored fields\n+\n+If the use case is to just read the nearest neighbors Ids and scores, then we could disable reading stored fields which could save some time retrieving the vectors from stored fields. \n+To understand more about stored fields, \n+please refer this [page.](https://discuss.elastic.co/t/what-does-it-mean-to-store-a-field/5893/5)\n+```\n+{\n+ \"size\": 5,\n+ \"stored_fields\": \"_none_\",\n+ \"docvalue_fields\": [\"_id\"],\n+ \"query\": {\n+   \"knn\": {\n+    \"v\": {\n+      \"vector\": [-0.16490704,-0.047262248,-0.078923926],\n+      \"k\": 50\n+     }       \n+   }\n+ }\n+}\n+```\n+##Improving Recall ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "330076a7c161280ab679c26226c2f44ec1e19d5a"}, "originalPosition": 128}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTgyNjk4MQ==", "bodyText": "Done", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461826981", "createdAt": "2020-07-28T19:39:23Z", "author": {"login": "vamshin"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,157 @@\n+#KNN Performance Tuning\n+\n+\n+In this document we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  From a high level k-NN works on following principles:\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query) \n+* Each graph in the segment returns *<=k* neighbors. \n+* Coordinator node picks up final *size* number of neighbors from the neighbors returned by each shard\n+\n+##Indexing Performance Tuning\n+\n+The following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+\n+* Disable Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied. Having no replicas means that losing \n+    a node(s) may incur data loss, so it is important that the data lives elsewhere \n+    so that this initial load can be retried in case of an issue.\n+ ```\n+More details [here](https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html#_disable_replicas_for_initial_loads)\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose has multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)\n+\n+* Forcemerge \n+  \n+ Forcemerge is a costly operation and could take a while depending on number of segments and size of the segments.\n+ To ensure force merge is completed, we could keep calling forcemerge with 5 minute interval till you get 200 response.\n+    \n+    curl -X POST \"localhost:9200/myindex/_forcemerge?max_num_segments=1&pretty\"\n+    \n+* Call refresh \n+\n+ Calling refresh ensure the buffer is cleared and all segments are created so that documents are available for search. \n+ ```\n+  POST /twitter/_refresh\n+```\n+* Add replicas (replica shards)\n+ \n+ This will make replica shards come up with the already serialized graphs created on the primary shards during indexing. This way \n+ we avoid duplicate graph construction.\n+\n+* We can now enable replicas to copy the serialized graphs\n+\n+*  Enable refresh interval\n+ ```\n+      PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"1m\"\n+            }\n+        }\n+ ```\n+\n+Please refer following doc (https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html) for more details on improving indexing performance in general.\n+\n+##Search Performance Tuning\n+\n+To improve Search performance it is necessary to keep the number of segments under control. Lucene's IndexSearcher will search over all of the segments in a shard to find the 'size' best results. But, because the complexity of search for the HNSW algorithm is logarithmic with respect to the number of vectors, searching over 5 graphs with a 100 vectors each and then taking the top size results from ```5*k``` results will take longer than searching over 1 graph with 500 vectors and then taking the top size results from k results. \n+Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We could configure index to have multiple shards to aviod having giant shards and achieve more parallelism.\n+\n+We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval.\n+\n+### Warm up\n+\n+The graphs are constructed during indexing, but they are loaded into memory during the first search. The way search works in Lucene is that each segment is searched sequentially (so, for k-NN, each segment returns up to k nearest neighbors of the query point) and the results are aggregated together and ranked based on the score of each result (higher score --> better result). \n+\n+Once a graph is loaded(graphs are loaded outside Elasticsearch JVM), we cache the graphs in memory. So the initial queries would be expensive in the order of few seconds and subsequent queries should be faster in the order of milliseconds(assuming knn circuit breaker is not hit).\n+\n+In order to avoid this latency penalty during your first queries, a user should use the warmup API on the indices they want to search. The API looks like this:\n+\n+GET /_opendistro/_knn/warmup/index1,index2,index3?pretty\n+{\n+  \"_shards\" : {\n+    \"total\" : 6,\n+    \"successful\" : 6,\n+    \"failed\" : 0\n+  }\n+}\n+\n+The API loads all of the graphs for all of the shards (primaries and replicas) for the specified indices into the cache. Thus, there will be no penalty to load graphs during initial searches. *Note \u2014 * this API only loads the segments of the indices it sees into the cache. If a merge or refresh operation finishes after this API is ran or if new documents are added, this API will need to be re-ran to load those graphs into memory.\n+\n+### Avoid reading stored fields\n+\n+If the use case is to just read the nearest neighbors Ids and scores, then we could disable reading stored fields which could save some time retrieving the vectors from stored fields. \n+To understand more about stored fields, \n+please refer this [page.](https://discuss.elastic.co/t/what-does-it-mean-to-store-a-field/5893/5)\n+```\n+{\n+ \"size\": 5,\n+ \"stored_fields\": \"_none_\",\n+ \"docvalue_fields\": [\"_id\"],\n+ \"query\": {\n+   \"knn\": {\n+    \"v\": {\n+      \"vector\": [-0.16490704,-0.047262248,-0.078923926],\n+      \"k\": 50\n+     }       \n+   }\n+ }\n+}\n+```\n+##Improving Recall ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTc5NTU2MQ=="}, "originalCommit": {"oid": "330076a7c161280ab679c26226c2f44ec1e19d5a"}, "originalPosition": 128}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4Mjk2NTg0OnYy", "diffSide": "RIGHT", "path": "PerformanceTuning.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxODo0NToxN1rOG4ZxNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxOTo1OTo1N1rOG4ckgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTc5NTYzOQ==", "bodyText": "Add space", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461795639", "createdAt": "2020-07-28T18:45:17Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,157 @@\n+#KNN Performance Tuning\n+\n+\n+In this document we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  From a high level k-NN works on following principles:\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query) \n+* Each graph in the segment returns *<=k* neighbors. \n+* Coordinator node picks up final *size* number of neighbors from the neighbors returned by each shard\n+\n+##Indexing Performance Tuning\n+\n+The following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+\n+* Disable Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied. Having no replicas means that losing \n+    a node(s) may incur data loss, so it is important that the data lives elsewhere \n+    so that this initial load can be retried in case of an issue.\n+ ```\n+More details [here](https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html#_disable_replicas_for_initial_loads)\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose has multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)\n+\n+* Forcemerge \n+  \n+ Forcemerge is a costly operation and could take a while depending on number of segments and size of the segments.\n+ To ensure force merge is completed, we could keep calling forcemerge with 5 minute interval till you get 200 response.\n+    \n+    curl -X POST \"localhost:9200/myindex/_forcemerge?max_num_segments=1&pretty\"\n+    \n+* Call refresh \n+\n+ Calling refresh ensure the buffer is cleared and all segments are created so that documents are available for search. \n+ ```\n+  POST /twitter/_refresh\n+```\n+* Add replicas (replica shards)\n+ \n+ This will make replica shards come up with the already serialized graphs created on the primary shards during indexing. This way \n+ we avoid duplicate graph construction.\n+\n+* We can now enable replicas to copy the serialized graphs\n+\n+*  Enable refresh interval\n+ ```\n+      PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"1m\"\n+            }\n+        }\n+ ```\n+\n+Please refer following doc (https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html) for more details on improving indexing performance in general.\n+\n+##Search Performance Tuning\n+\n+To improve Search performance it is necessary to keep the number of segments under control. Lucene's IndexSearcher will search over all of the segments in a shard to find the 'size' best results. But, because the complexity of search for the HNSW algorithm is logarithmic with respect to the number of vectors, searching over 5 graphs with a 100 vectors each and then taking the top size results from ```5*k``` results will take longer than searching over 1 graph with 500 vectors and then taking the top size results from k results. \n+Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We could configure index to have multiple shards to aviod having giant shards and achieve more parallelism.\n+\n+We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval.\n+\n+### Warm up\n+\n+The graphs are constructed during indexing, but they are loaded into memory during the first search. The way search works in Lucene is that each segment is searched sequentially (so, for k-NN, each segment returns up to k nearest neighbors of the query point) and the results are aggregated together and ranked based on the score of each result (higher score --> better result). \n+\n+Once a graph is loaded(graphs are loaded outside Elasticsearch JVM), we cache the graphs in memory. So the initial queries would be expensive in the order of few seconds and subsequent queries should be faster in the order of milliseconds(assuming knn circuit breaker is not hit).\n+\n+In order to avoid this latency penalty during your first queries, a user should use the warmup API on the indices they want to search. The API looks like this:\n+\n+GET /_opendistro/_knn/warmup/index1,index2,index3?pretty\n+{\n+  \"_shards\" : {\n+    \"total\" : 6,\n+    \"successful\" : 6,\n+    \"failed\" : 0\n+  }\n+}\n+\n+The API loads all of the graphs for all of the shards (primaries and replicas) for the specified indices into the cache. Thus, there will be no penalty to load graphs during initial searches. *Note \u2014 * this API only loads the segments of the indices it sees into the cache. If a merge or refresh operation finishes after this API is ran or if new documents are added, this API will need to be re-ran to load those graphs into memory.\n+\n+### Avoid reading stored fields\n+\n+If the use case is to just read the nearest neighbors Ids and scores, then we could disable reading stored fields which could save some time retrieving the vectors from stored fields. \n+To understand more about stored fields, \n+please refer this [page.](https://discuss.elastic.co/t/what-does-it-mean-to-store-a-field/5893/5)\n+```\n+{\n+ \"size\": 5,\n+ \"stored_fields\": \"_none_\",\n+ \"docvalue_fields\": [\"_id\"],\n+ \"query\": {\n+   \"knn\": {\n+    \"v\": {\n+      \"vector\": [-0.16490704,-0.047262248,-0.078923926],\n+      \"k\": 50\n+     }       \n+   }\n+ }\n+}\n+```\n+##Improving Recall \n+\n+Recall could depend on multiple factors like number of vectors, number of dimensions, segments etc. Searching over large number of small segments and aggregating the results leads better recall than searching over small number of large segments and aggregating results. The larger the graph the more chances of losing recall if sticking to smaller algorithm parameters. \n+Choosing larger values for algorithm params should help solve this issue but at the cost of search latency and indexing time. That being said, it is important to understand your system's requirements for latency and accuracy, and then to choose the number of segments you want your index to have based on experimentation.\n+\n+Recall can be configured by adjusting the algorithm parameters of hnsw algorithm exposed through index settings. Algorithm params that control the recall are *m, ef_construction, ef_search*. For more details on influence of algorithm parameters on the indexing, search recall, please refer this  doc (https://github.com/nmslib/hnswlib/blob/master/ALGO_PARAMS.md).  Increasing these values could help recall(better search results) but at the cost of higher memory utilization and increased indexing time. Our default values work on a broader set of use cases from our experiments but we encourage users to run their own experiments on their data sets and choose the appropriate values. You could refer to these settings in this section (https://github.com/opendistro-for-elasticsearch/k-NN#index-level-settings). We will add details on our experiments shortly here.\n+\n+##Memory Estimation", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "330076a7c161280ab679c26226c2f44ec1e19d5a"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg0MTUzNw==", "bodyText": "Done", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461841537", "createdAt": "2020-07-28T19:59:57Z", "author": {"login": "vamshin"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,157 @@\n+#KNN Performance Tuning\n+\n+\n+In this document we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  From a high level k-NN works on following principles:\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query) \n+* Each graph in the segment returns *<=k* neighbors. \n+* Coordinator node picks up final *size* number of neighbors from the neighbors returned by each shard\n+\n+##Indexing Performance Tuning\n+\n+The following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+\n+* Disable Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied. Having no replicas means that losing \n+    a node(s) may incur data loss, so it is important that the data lives elsewhere \n+    so that this initial load can be retried in case of an issue.\n+ ```\n+More details [here](https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html#_disable_replicas_for_initial_loads)\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose has multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)\n+\n+* Forcemerge \n+  \n+ Forcemerge is a costly operation and could take a while depending on number of segments and size of the segments.\n+ To ensure force merge is completed, we could keep calling forcemerge with 5 minute interval till you get 200 response.\n+    \n+    curl -X POST \"localhost:9200/myindex/_forcemerge?max_num_segments=1&pretty\"\n+    \n+* Call refresh \n+\n+ Calling refresh ensure the buffer is cleared and all segments are created so that documents are available for search. \n+ ```\n+  POST /twitter/_refresh\n+```\n+* Add replicas (replica shards)\n+ \n+ This will make replica shards come up with the already serialized graphs created on the primary shards during indexing. This way \n+ we avoid duplicate graph construction.\n+\n+* We can now enable replicas to copy the serialized graphs\n+\n+*  Enable refresh interval\n+ ```\n+      PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"1m\"\n+            }\n+        }\n+ ```\n+\n+Please refer following doc (https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html) for more details on improving indexing performance in general.\n+\n+##Search Performance Tuning\n+\n+To improve Search performance it is necessary to keep the number of segments under control. Lucene's IndexSearcher will search over all of the segments in a shard to find the 'size' best results. But, because the complexity of search for the HNSW algorithm is logarithmic with respect to the number of vectors, searching over 5 graphs with a 100 vectors each and then taking the top size results from ```5*k``` results will take longer than searching over 1 graph with 500 vectors and then taking the top size results from k results. \n+Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We could configure index to have multiple shards to aviod having giant shards and achieve more parallelism.\n+\n+We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval.\n+\n+### Warm up\n+\n+The graphs are constructed during indexing, but they are loaded into memory during the first search. The way search works in Lucene is that each segment is searched sequentially (so, for k-NN, each segment returns up to k nearest neighbors of the query point) and the results are aggregated together and ranked based on the score of each result (higher score --> better result). \n+\n+Once a graph is loaded(graphs are loaded outside Elasticsearch JVM), we cache the graphs in memory. So the initial queries would be expensive in the order of few seconds and subsequent queries should be faster in the order of milliseconds(assuming knn circuit breaker is not hit).\n+\n+In order to avoid this latency penalty during your first queries, a user should use the warmup API on the indices they want to search. The API looks like this:\n+\n+GET /_opendistro/_knn/warmup/index1,index2,index3?pretty\n+{\n+  \"_shards\" : {\n+    \"total\" : 6,\n+    \"successful\" : 6,\n+    \"failed\" : 0\n+  }\n+}\n+\n+The API loads all of the graphs for all of the shards (primaries and replicas) for the specified indices into the cache. Thus, there will be no penalty to load graphs during initial searches. *Note \u2014 * this API only loads the segments of the indices it sees into the cache. If a merge or refresh operation finishes after this API is ran or if new documents are added, this API will need to be re-ran to load those graphs into memory.\n+\n+### Avoid reading stored fields\n+\n+If the use case is to just read the nearest neighbors Ids and scores, then we could disable reading stored fields which could save some time retrieving the vectors from stored fields. \n+To understand more about stored fields, \n+please refer this [page.](https://discuss.elastic.co/t/what-does-it-mean-to-store-a-field/5893/5)\n+```\n+{\n+ \"size\": 5,\n+ \"stored_fields\": \"_none_\",\n+ \"docvalue_fields\": [\"_id\"],\n+ \"query\": {\n+   \"knn\": {\n+    \"v\": {\n+      \"vector\": [-0.16490704,-0.047262248,-0.078923926],\n+      \"k\": 50\n+     }       \n+   }\n+ }\n+}\n+```\n+##Improving Recall \n+\n+Recall could depend on multiple factors like number of vectors, number of dimensions, segments etc. Searching over large number of small segments and aggregating the results leads better recall than searching over small number of large segments and aggregating results. The larger the graph the more chances of losing recall if sticking to smaller algorithm parameters. \n+Choosing larger values for algorithm params should help solve this issue but at the cost of search latency and indexing time. That being said, it is important to understand your system's requirements for latency and accuracy, and then to choose the number of segments you want your index to have based on experimentation.\n+\n+Recall can be configured by adjusting the algorithm parameters of hnsw algorithm exposed through index settings. Algorithm params that control the recall are *m, ef_construction, ef_search*. For more details on influence of algorithm parameters on the indexing, search recall, please refer this  doc (https://github.com/nmslib/hnswlib/blob/master/ALGO_PARAMS.md).  Increasing these values could help recall(better search results) but at the cost of higher memory utilization and increased indexing time. Our default values work on a broader set of use cases from our experiments but we encourage users to run their own experiments on their data sets and choose the appropriate values. You could refer to these settings in this section (https://github.com/opendistro-for-elasticsearch/k-NN#index-level-settings). We will add details on our experiments shortly here.\n+\n+##Memory Estimation", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTc5NTYzOQ=="}, "originalCommit": {"oid": "330076a7c161280ab679c26226c2f44ec1e19d5a"}, "originalPosition": 135}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4Mjk2NjMxOnYy", "diffSide": "RIGHT", "path": "PerformanceTuning.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxODo0NToyNVrOG4ZxgA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMDowMDowMlrOG4ckyw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTc5NTcxMg==", "bodyText": "Add space", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461795712", "createdAt": "2020-07-28T18:45:25Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,157 @@\n+#KNN Performance Tuning\n+\n+\n+In this document we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  From a high level k-NN works on following principles:\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query) \n+* Each graph in the segment returns *<=k* neighbors. \n+* Coordinator node picks up final *size* number of neighbors from the neighbors returned by each shard\n+\n+##Indexing Performance Tuning\n+\n+The following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+\n+* Disable Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied. Having no replicas means that losing \n+    a node(s) may incur data loss, so it is important that the data lives elsewhere \n+    so that this initial load can be retried in case of an issue.\n+ ```\n+More details [here](https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html#_disable_replicas_for_initial_loads)\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose has multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)\n+\n+* Forcemerge \n+  \n+ Forcemerge is a costly operation and could take a while depending on number of segments and size of the segments.\n+ To ensure force merge is completed, we could keep calling forcemerge with 5 minute interval till you get 200 response.\n+    \n+    curl -X POST \"localhost:9200/myindex/_forcemerge?max_num_segments=1&pretty\"\n+    \n+* Call refresh \n+\n+ Calling refresh ensure the buffer is cleared and all segments are created so that documents are available for search. \n+ ```\n+  POST /twitter/_refresh\n+```\n+* Add replicas (replica shards)\n+ \n+ This will make replica shards come up with the already serialized graphs created on the primary shards during indexing. This way \n+ we avoid duplicate graph construction.\n+\n+* We can now enable replicas to copy the serialized graphs\n+\n+*  Enable refresh interval\n+ ```\n+      PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"1m\"\n+            }\n+        }\n+ ```\n+\n+Please refer following doc (https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html) for more details on improving indexing performance in general.\n+\n+##Search Performance Tuning\n+\n+To improve Search performance it is necessary to keep the number of segments under control. Lucene's IndexSearcher will search over all of the segments in a shard to find the 'size' best results. But, because the complexity of search for the HNSW algorithm is logarithmic with respect to the number of vectors, searching over 5 graphs with a 100 vectors each and then taking the top size results from ```5*k``` results will take longer than searching over 1 graph with 500 vectors and then taking the top size results from k results. \n+Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We could configure index to have multiple shards to aviod having giant shards and achieve more parallelism.\n+\n+We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval.\n+\n+### Warm up\n+\n+The graphs are constructed during indexing, but they are loaded into memory during the first search. The way search works in Lucene is that each segment is searched sequentially (so, for k-NN, each segment returns up to k nearest neighbors of the query point) and the results are aggregated together and ranked based on the score of each result (higher score --> better result). \n+\n+Once a graph is loaded(graphs are loaded outside Elasticsearch JVM), we cache the graphs in memory. So the initial queries would be expensive in the order of few seconds and subsequent queries should be faster in the order of milliseconds(assuming knn circuit breaker is not hit).\n+\n+In order to avoid this latency penalty during your first queries, a user should use the warmup API on the indices they want to search. The API looks like this:\n+\n+GET /_opendistro/_knn/warmup/index1,index2,index3?pretty\n+{\n+  \"_shards\" : {\n+    \"total\" : 6,\n+    \"successful\" : 6,\n+    \"failed\" : 0\n+  }\n+}\n+\n+The API loads all of the graphs for all of the shards (primaries and replicas) for the specified indices into the cache. Thus, there will be no penalty to load graphs during initial searches. *Note \u2014 * this API only loads the segments of the indices it sees into the cache. If a merge or refresh operation finishes after this API is ran or if new documents are added, this API will need to be re-ran to load those graphs into memory.\n+\n+### Avoid reading stored fields\n+\n+If the use case is to just read the nearest neighbors Ids and scores, then we could disable reading stored fields which could save some time retrieving the vectors from stored fields. \n+To understand more about stored fields, \n+please refer this [page.](https://discuss.elastic.co/t/what-does-it-mean-to-store-a-field/5893/5)\n+```\n+{\n+ \"size\": 5,\n+ \"stored_fields\": \"_none_\",\n+ \"docvalue_fields\": [\"_id\"],\n+ \"query\": {\n+   \"knn\": {\n+    \"v\": {\n+      \"vector\": [-0.16490704,-0.047262248,-0.078923926],\n+      \"k\": 50\n+     }       \n+   }\n+ }\n+}\n+```\n+##Improving Recall \n+\n+Recall could depend on multiple factors like number of vectors, number of dimensions, segments etc. Searching over large number of small segments and aggregating the results leads better recall than searching over small number of large segments and aggregating results. The larger the graph the more chances of losing recall if sticking to smaller algorithm parameters. \n+Choosing larger values for algorithm params should help solve this issue but at the cost of search latency and indexing time. That being said, it is important to understand your system's requirements for latency and accuracy, and then to choose the number of segments you want your index to have based on experimentation.\n+\n+Recall can be configured by adjusting the algorithm parameters of hnsw algorithm exposed through index settings. Algorithm params that control the recall are *m, ef_construction, ef_search*. For more details on influence of algorithm parameters on the indexing, search recall, please refer this  doc (https://github.com/nmslib/hnswlib/blob/master/ALGO_PARAMS.md).  Increasing these values could help recall(better search results) but at the cost of higher memory utilization and increased indexing time. Our default values work on a broader set of use cases from our experiments but we encourage users to run their own experiments on their data sets and choose the appropriate values. You could refer to these settings in this section (https://github.com/opendistro-for-elasticsearch/k-NN#index-level-settings). We will add details on our experiments shortly here.\n+\n+##Memory Estimation\n+\n+AWS Elasticsearch Service clusters allocate 50% of available RAM in the Instance capped around 32GB (because of JVM GC performance limit). Graphs part of k-NN are loaded outside the Elasticsearch process JVM. We have circuit breakers to limit graph usage to 50% of the left over RAM space for the graphs.\n+\n+* Memory required for graphs =   1.1 *((4* dimensions) + (8 * M)) *Bytes/vector*\n+    * (4 bytes/float * dimension float/vector)\n+    * (8 * M) = 4 bytes/edge * 2 levels/node *  M edge/level\n+        * Note \u2014 as an estimation, each node will have membership in roughly 2 layers, and, on each layer, it will have M edges\n+    * 1.1 = an extra 10% buffer for other meta data in the data structure\n+* Example:- Let us assume\n+    * 1 Million vectors \n+    * 256 Dimensions (2^8)\n+    * M = 16 (default setting of HNSW)\n+        * Memory required for !M vectors = 1.1*(4*256 + 8*16) *1M Bytes =~ 1.26GB \n+\n+##Monitoring ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "330076a7c161280ab679c26226c2f44ec1e19d5a"}, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg0MTYxMQ==", "bodyText": "Done", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461841611", "createdAt": "2020-07-28T20:00:02Z", "author": {"login": "vamshin"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,157 @@\n+#KNN Performance Tuning\n+\n+\n+In this document we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  From a high level k-NN works on following principles:\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query) \n+* Each graph in the segment returns *<=k* neighbors. \n+* Coordinator node picks up final *size* number of neighbors from the neighbors returned by each shard\n+\n+##Indexing Performance Tuning\n+\n+The following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+\n+* Disable Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied. Having no replicas means that losing \n+    a node(s) may incur data loss, so it is important that the data lives elsewhere \n+    so that this initial load can be retried in case of an issue.\n+ ```\n+More details [here](https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html#_disable_replicas_for_initial_loads)\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose has multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)\n+\n+* Forcemerge \n+  \n+ Forcemerge is a costly operation and could take a while depending on number of segments and size of the segments.\n+ To ensure force merge is completed, we could keep calling forcemerge with 5 minute interval till you get 200 response.\n+    \n+    curl -X POST \"localhost:9200/myindex/_forcemerge?max_num_segments=1&pretty\"\n+    \n+* Call refresh \n+\n+ Calling refresh ensure the buffer is cleared and all segments are created so that documents are available for search. \n+ ```\n+  POST /twitter/_refresh\n+```\n+* Add replicas (replica shards)\n+ \n+ This will make replica shards come up with the already serialized graphs created on the primary shards during indexing. This way \n+ we avoid duplicate graph construction.\n+\n+* We can now enable replicas to copy the serialized graphs\n+\n+*  Enable refresh interval\n+ ```\n+      PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"1m\"\n+            }\n+        }\n+ ```\n+\n+Please refer following doc (https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html) for more details on improving indexing performance in general.\n+\n+##Search Performance Tuning\n+\n+To improve Search performance it is necessary to keep the number of segments under control. Lucene's IndexSearcher will search over all of the segments in a shard to find the 'size' best results. But, because the complexity of search for the HNSW algorithm is logarithmic with respect to the number of vectors, searching over 5 graphs with a 100 vectors each and then taking the top size results from ```5*k``` results will take longer than searching over 1 graph with 500 vectors and then taking the top size results from k results. \n+Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We could configure index to have multiple shards to aviod having giant shards and achieve more parallelism.\n+\n+We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval.\n+\n+### Warm up\n+\n+The graphs are constructed during indexing, but they are loaded into memory during the first search. The way search works in Lucene is that each segment is searched sequentially (so, for k-NN, each segment returns up to k nearest neighbors of the query point) and the results are aggregated together and ranked based on the score of each result (higher score --> better result). \n+\n+Once a graph is loaded(graphs are loaded outside Elasticsearch JVM), we cache the graphs in memory. So the initial queries would be expensive in the order of few seconds and subsequent queries should be faster in the order of milliseconds(assuming knn circuit breaker is not hit).\n+\n+In order to avoid this latency penalty during your first queries, a user should use the warmup API on the indices they want to search. The API looks like this:\n+\n+GET /_opendistro/_knn/warmup/index1,index2,index3?pretty\n+{\n+  \"_shards\" : {\n+    \"total\" : 6,\n+    \"successful\" : 6,\n+    \"failed\" : 0\n+  }\n+}\n+\n+The API loads all of the graphs for all of the shards (primaries and replicas) for the specified indices into the cache. Thus, there will be no penalty to load graphs during initial searches. *Note \u2014 * this API only loads the segments of the indices it sees into the cache. If a merge or refresh operation finishes after this API is ran or if new documents are added, this API will need to be re-ran to load those graphs into memory.\n+\n+### Avoid reading stored fields\n+\n+If the use case is to just read the nearest neighbors Ids and scores, then we could disable reading stored fields which could save some time retrieving the vectors from stored fields. \n+To understand more about stored fields, \n+please refer this [page.](https://discuss.elastic.co/t/what-does-it-mean-to-store-a-field/5893/5)\n+```\n+{\n+ \"size\": 5,\n+ \"stored_fields\": \"_none_\",\n+ \"docvalue_fields\": [\"_id\"],\n+ \"query\": {\n+   \"knn\": {\n+    \"v\": {\n+      \"vector\": [-0.16490704,-0.047262248,-0.078923926],\n+      \"k\": 50\n+     }       \n+   }\n+ }\n+}\n+```\n+##Improving Recall \n+\n+Recall could depend on multiple factors like number of vectors, number of dimensions, segments etc. Searching over large number of small segments and aggregating the results leads better recall than searching over small number of large segments and aggregating results. The larger the graph the more chances of losing recall if sticking to smaller algorithm parameters. \n+Choosing larger values for algorithm params should help solve this issue but at the cost of search latency and indexing time. That being said, it is important to understand your system's requirements for latency and accuracy, and then to choose the number of segments you want your index to have based on experimentation.\n+\n+Recall can be configured by adjusting the algorithm parameters of hnsw algorithm exposed through index settings. Algorithm params that control the recall are *m, ef_construction, ef_search*. For more details on influence of algorithm parameters on the indexing, search recall, please refer this  doc (https://github.com/nmslib/hnswlib/blob/master/ALGO_PARAMS.md).  Increasing these values could help recall(better search results) but at the cost of higher memory utilization and increased indexing time. Our default values work on a broader set of use cases from our experiments but we encourage users to run their own experiments on their data sets and choose the appropriate values. You could refer to these settings in this section (https://github.com/opendistro-for-elasticsearch/k-NN#index-level-settings). We will add details on our experiments shortly here.\n+\n+##Memory Estimation\n+\n+AWS Elasticsearch Service clusters allocate 50% of available RAM in the Instance capped around 32GB (because of JVM GC performance limit). Graphs part of k-NN are loaded outside the Elasticsearch process JVM. We have circuit breakers to limit graph usage to 50% of the left over RAM space for the graphs.\n+\n+* Memory required for graphs =   1.1 *((4* dimensions) + (8 * M)) *Bytes/vector*\n+    * (4 bytes/float * dimension float/vector)\n+    * (8 * M) = 4 bytes/edge * 2 levels/node *  M edge/level\n+        * Note \u2014 as an estimation, each node will have membership in roughly 2 layers, and, on each layer, it will have M edges\n+    * 1.1 = an extra 10% buffer for other meta data in the data structure\n+* Example:- Let us assume\n+    * 1 Million vectors \n+    * 256 Dimensions (2^8)\n+    * M = 16 (default setting of HNSW)\n+        * Memory required for !M vectors = 1.1*(4*256 + 8*16) *1M Bytes =~ 1.26GB \n+\n+##Monitoring ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTc5NTcxMg=="}, "originalCommit": {"oid": "330076a7c161280ab679c26226c2f44ec1e19d5a"}, "originalPosition": 150}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4MzAyMDMxOnYy", "diffSide": "RIGHT", "path": "PerformanceTuning.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxOTowMDo0MFrOG4aTlg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxOTozODoxNlrOG4bnhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTgwNDQzOA==", "bodyText": "Add space", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461804438", "createdAt": "2020-07-28T19:00:40Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,157 @@\n+#KNN Performance Tuning\n+\n+\n+In this document we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  From a high level k-NN works on following principles:\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query) \n+* Each graph in the segment returns *<=k* neighbors. \n+* Coordinator node picks up final *size* number of neighbors from the neighbors returned by each shard\n+\n+##Indexing Performance Tuning\n+\n+The following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+\n+* Disable Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied. Having no replicas means that losing \n+    a node(s) may incur data loss, so it is important that the data lives elsewhere \n+    so that this initial load can be retried in case of an issue.\n+ ```\n+More details [here](https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html#_disable_replicas_for_initial_loads)\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose has multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)\n+\n+* Forcemerge \n+  \n+ Forcemerge is a costly operation and could take a while depending on number of segments and size of the segments.\n+ To ensure force merge is completed, we could keep calling forcemerge with 5 minute interval till you get 200 response.\n+    \n+    curl -X POST \"localhost:9200/myindex/_forcemerge?max_num_segments=1&pretty\"\n+    \n+* Call refresh \n+\n+ Calling refresh ensure the buffer is cleared and all segments are created so that documents are available for search. \n+ ```\n+  POST /twitter/_refresh\n+```\n+* Add replicas (replica shards)\n+ \n+ This will make replica shards come up with the already serialized graphs created on the primary shards during indexing. This way \n+ we avoid duplicate graph construction.\n+\n+* We can now enable replicas to copy the serialized graphs\n+\n+*  Enable refresh interval\n+ ```\n+      PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"1m\"\n+            }\n+        }\n+ ```\n+\n+Please refer following doc (https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html) for more details on improving indexing performance in general.\n+\n+##Search Performance Tuning", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "330076a7c161280ab679c26226c2f44ec1e19d5a"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTgyNTkyNQ==", "bodyText": "Done.", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461825925", "createdAt": "2020-07-28T19:38:16Z", "author": {"login": "vamshin"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,157 @@\n+#KNN Performance Tuning\n+\n+\n+In this document we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  From a high level k-NN works on following principles:\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query) \n+* Each graph in the segment returns *<=k* neighbors. \n+* Coordinator node picks up final *size* number of neighbors from the neighbors returned by each shard\n+\n+##Indexing Performance Tuning\n+\n+The following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+\n+* Disable Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied. Having no replicas means that losing \n+    a node(s) may incur data loss, so it is important that the data lives elsewhere \n+    so that this initial load can be retried in case of an issue.\n+ ```\n+More details [here](https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html#_disable_replicas_for_initial_loads)\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose has multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)\n+\n+* Forcemerge \n+  \n+ Forcemerge is a costly operation and could take a while depending on number of segments and size of the segments.\n+ To ensure force merge is completed, we could keep calling forcemerge with 5 minute interval till you get 200 response.\n+    \n+    curl -X POST \"localhost:9200/myindex/_forcemerge?max_num_segments=1&pretty\"\n+    \n+* Call refresh \n+\n+ Calling refresh ensure the buffer is cleared and all segments are created so that documents are available for search. \n+ ```\n+  POST /twitter/_refresh\n+```\n+* Add replicas (replica shards)\n+ \n+ This will make replica shards come up with the already serialized graphs created on the primary shards during indexing. This way \n+ we avoid duplicate graph construction.\n+\n+* We can now enable replicas to copy the serialized graphs\n+\n+*  Enable refresh interval\n+ ```\n+      PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"1m\"\n+            }\n+        }\n+ ```\n+\n+Please refer following doc (https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html) for more details on improving indexing performance in general.\n+\n+##Search Performance Tuning", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTgwNDQzOA=="}, "originalCommit": {"oid": "330076a7c161280ab679c26226c2f44ec1e19d5a"}, "originalPosition": 82}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4MzAyODAzOnYy", "diffSide": "RIGHT", "path": "PerformanceTuning.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxOTowMjo0NlrOG4aYXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMDowMDo1NlrOG4cm-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTgwNTY2Mg==", "bodyText": "This needs a header like the other sections. Also, good explanation. I think adding a link to this newly created section from the force merge section would be helpful.", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461805662", "createdAt": "2020-07-28T19:02:46Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,157 @@\n+#KNN Performance Tuning\n+\n+\n+In this document we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  From a high level k-NN works on following principles:\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query) \n+* Each graph in the segment returns *<=k* neighbors. \n+* Coordinator node picks up final *size* number of neighbors from the neighbors returned by each shard\n+\n+##Indexing Performance Tuning\n+\n+The following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+\n+* Disable Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied. Having no replicas means that losing \n+    a node(s) may incur data loss, so it is important that the data lives elsewhere \n+    so that this initial load can be retried in case of an issue.\n+ ```\n+More details [here](https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html#_disable_replicas_for_initial_loads)\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose has multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)\n+\n+* Forcemerge \n+  \n+ Forcemerge is a costly operation and could take a while depending on number of segments and size of the segments.\n+ To ensure force merge is completed, we could keep calling forcemerge with 5 minute interval till you get 200 response.\n+    \n+    curl -X POST \"localhost:9200/myindex/_forcemerge?max_num_segments=1&pretty\"\n+    \n+* Call refresh \n+\n+ Calling refresh ensure the buffer is cleared and all segments are created so that documents are available for search. \n+ ```\n+  POST /twitter/_refresh\n+```\n+* Add replicas (replica shards)\n+ \n+ This will make replica shards come up with the already serialized graphs created on the primary shards during indexing. This way \n+ we avoid duplicate graph construction.\n+\n+* We can now enable replicas to copy the serialized graphs\n+\n+*  Enable refresh interval\n+ ```\n+      PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"1m\"\n+            }\n+        }\n+ ```\n+\n+Please refer following doc (https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html) for more details on improving indexing performance in general.\n+\n+##Search Performance Tuning\n+\n+To improve Search performance it is necessary to keep the number of segments under control. Lucene's IndexSearcher will search over all of the segments in a shard to find the 'size' best results. But, because the complexity of search for the HNSW algorithm is logarithmic with respect to the number of vectors, searching over 5 graphs with a 100 vectors each and then taking the top size results from ```5*k``` results will take longer than searching over 1 graph with 500 vectors and then taking the top size results from k results. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "330076a7c161280ab679c26226c2f44ec1e19d5a"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg0MjE2OQ==", "bodyText": "makes sense", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461842169", "createdAt": "2020-07-28T20:00:56Z", "author": {"login": "vamshin"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,157 @@\n+#KNN Performance Tuning\n+\n+\n+In this document we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  From a high level k-NN works on following principles:\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query) \n+* Each graph in the segment returns *<=k* neighbors. \n+* Coordinator node picks up final *size* number of neighbors from the neighbors returned by each shard\n+\n+##Indexing Performance Tuning\n+\n+The following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+* Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+\n+* Disable Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied. Having no replicas means that losing \n+    a node(s) may incur data loss, so it is important that the data lives elsewhere \n+    so that this initial load can be retried in case of an issue.\n+ ```\n+More details [here](https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html#_disable_replicas_for_initial_loads)\n+    \n+* Increase number of indexing threads\n+  ```\n+    If the hardware we choose has multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+* Index all docs (Perform bulk indexing)\n+\n+* Forcemerge \n+  \n+ Forcemerge is a costly operation and could take a while depending on number of segments and size of the segments.\n+ To ensure force merge is completed, we could keep calling forcemerge with 5 minute interval till you get 200 response.\n+    \n+    curl -X POST \"localhost:9200/myindex/_forcemerge?max_num_segments=1&pretty\"\n+    \n+* Call refresh \n+\n+ Calling refresh ensure the buffer is cleared and all segments are created so that documents are available for search. \n+ ```\n+  POST /twitter/_refresh\n+```\n+* Add replicas (replica shards)\n+ \n+ This will make replica shards come up with the already serialized graphs created on the primary shards during indexing. This way \n+ we avoid duplicate graph construction.\n+\n+* We can now enable replicas to copy the serialized graphs\n+\n+*  Enable refresh interval\n+ ```\n+      PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"1m\"\n+            }\n+        }\n+ ```\n+\n+Please refer following doc (https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html) for more details on improving indexing performance in general.\n+\n+##Search Performance Tuning\n+\n+To improve Search performance it is necessary to keep the number of segments under control. Lucene's IndexSearcher will search over all of the segments in a shard to find the 'size' best results. But, because the complexity of search for the HNSW algorithm is logarithmic with respect to the number of vectors, searching over 5 graphs with a 100 vectors each and then taking the top size results from ```5*k``` results will take longer than searching over 1 graph with 500 vectors and then taking the top size results from k results. ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTgwNTY2Mg=="}, "originalCommit": {"oid": "330076a7c161280ab679c26226c2f44ec1e19d5a"}, "originalPosition": 84}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4MzU1MjA4OnYy", "diffSide": "RIGHT", "path": "PerformanceTuning.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMToxOTozMlrOG4fSkA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMToyOToyMVrOG4flYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg4NjA5Ng==", "bodyText": "Minor: wrap in code block", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461886096", "createdAt": "2020-07-28T21:19:32Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,154 @@\n+# KNN Performance Tuning\n+\n+In this document we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  From a high level k-NN works on following principles:\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query) \n+* Each graph in the segment returns *<=k* neighbors. \n+* Coordinator node picks up final *size* number of neighbors from the neighbors returned by each shard\n+\n+## Indexing Performance Tuning\n+\n+The following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+1 Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+2 Disable Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied. Having no replicas means that losing \n+    a node(s) may incur data loss, so it is important that the data lives elsewhere \n+    so that this initial load can be retried in case of an issue.\n+ ```\n+More details [here](https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html#_disable_replicas_for_initial_loads)\n+    \n+3 Increase number of indexing threads\n+  ```\n+    If the hardware we choose has multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+4 Index all docs (Perform bulk indexing)\n+\n+5 Forcemerge \n+  \n+ Forcemerge is a costly operation and could take a while depending on number of segments and size of the segments.\n+ To ensure force merge is completed, we could keep calling forcemerge with 5 minute interval till you get 200 response.\n+    \n+    curl -X POST \"localhost:9200/myindex/_forcemerge?max_num_segments=1&pretty\"\n+    \n+6 Call refresh \n+\n+ Calling refresh ensure the buffer is cleared and all segments are created so that documents are available for search. \n+ ```\n+  POST /twitter/_refresh\n+```\n+7 Enable replicas \n+ \n+ This will make replica shards come up with the already serialized graphs created on the primary shards during indexing. This way \n+ we avoid duplicate graph construction.\n+\n+8  Enable refresh interval\n+ ```\n+      PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"1m\"\n+            }\n+        }\n+ ```\n+\n+Please refer following doc (https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html) for more details on improving indexing performance in general.\n+\n+## Search Performance Tuning\n+\n+### Fewer Segments\n+To improve Search performance it is necessary to keep the number of segments under control. Lucene's IndexSearcher will search over all of the segments in a shard to find the 'size' best results. But, because the complexity of search for the HNSW algorithm is logarithmic with respect to the number of vectors, searching over 5 graphs with a 100 vectors each and then taking the top size results from ```5*k``` results will take longer than searching over 1 graph with 500 vectors and then taking the top size results from k results. \n+Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We could configure index to have multiple shards to aviod having giant shards and achieve more parallelism.\n+\n+We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval.\n+\n+### Warm up\n+\n+The graphs are constructed during indexing, but they are loaded into memory during the first search. The way search works in Lucene is that each segment is searched sequentially (so, for k-NN, each segment returns up to k nearest neighbors of the query point) and the top ```size``` number of results based on the score would be returned from all of the results returned by segements at a shard level(higher score --> better result). \n+\n+Once a graph is loaded(graphs are loaded outside Elasticsearch JVM), we cache the graphs in memory. So the initial queries would be expensive in the order of few seconds and subsequent queries should be faster in the order of milliseconds(assuming knn circuit breaker is not hit).\n+\n+In order to avoid this latency penalty during your first queries, a user should use the warmup API on the indices they want to search. The API looks like this:\n+\n+GET /_opendistro/_knn/warmup/index1,index2,index3?pretty", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0e889c7428d6c059236bacdaa0ffeb6055301c1"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg5MDkxMw==", "bodyText": "Done", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461890913", "createdAt": "2020-07-28T21:29:21Z", "author": {"login": "vamshin"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,154 @@\n+# KNN Performance Tuning\n+\n+In this document we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  From a high level k-NN works on following principles:\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query) \n+* Each graph in the segment returns *<=k* neighbors. \n+* Coordinator node picks up final *size* number of neighbors from the neighbors returned by each shard\n+\n+## Indexing Performance Tuning\n+\n+The following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+1 Disable refresh interval  (Default = 1 sec)\n+ \n+ Disable refresh interval or set a long duration for refresh interval to avoid creating multiple smaller segments\n+  ```  \n+    PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"-1\"\n+            }\n+        }\n+  ```\n+2 Disable Replicas (No Elasticsearch replica shard)\n+ ```\n+    Having replication set to 0, will avoid duplicate construction of graphs in \n+    both primary and replicas. When we enable replicas after the indexing, the \n+    serialized graphs are directly copied. Having no replicas means that losing \n+    a node(s) may incur data loss, so it is important that the data lives elsewhere \n+    so that this initial load can be retried in case of an issue.\n+ ```\n+More details [here](https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html#_disable_replicas_for_initial_loads)\n+    \n+3 Increase number of indexing threads\n+  ```\n+    If the hardware we choose has multiple cores, we could allow multiple threads \n+    in graph construction and there by speed up the indexing process. You could determine\n+    the number of threads to be alloted by using the following setting   \n+    https://github.com/opendistro-for-elasticsearch/k-NN#knnalgo_paramindex_thread_qty.\n+     \n+    Please keep an eye on CPU utilization and choose right number of threads. Since graph\n+    construction is costly, having multiple threads can put additional load on CPU. \n+  ```\n+    \n+4 Index all docs (Perform bulk indexing)\n+\n+5 Forcemerge \n+  \n+ Forcemerge is a costly operation and could take a while depending on number of segments and size of the segments.\n+ To ensure force merge is completed, we could keep calling forcemerge with 5 minute interval till you get 200 response.\n+    \n+    curl -X POST \"localhost:9200/myindex/_forcemerge?max_num_segments=1&pretty\"\n+    \n+6 Call refresh \n+\n+ Calling refresh ensure the buffer is cleared and all segments are created so that documents are available for search. \n+ ```\n+  POST /twitter/_refresh\n+```\n+7 Enable replicas \n+ \n+ This will make replica shards come up with the already serialized graphs created on the primary shards during indexing. This way \n+ we avoid duplicate graph construction.\n+\n+8  Enable refresh interval\n+ ```\n+      PUT /<index_name>/_settings\n+        {\n+            \"index\" : {\n+                \"refresh_interval\" : \"1m\"\n+            }\n+        }\n+ ```\n+\n+Please refer following doc (https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html) for more details on improving indexing performance in general.\n+\n+## Search Performance Tuning\n+\n+### Fewer Segments\n+To improve Search performance it is necessary to keep the number of segments under control. Lucene's IndexSearcher will search over all of the segments in a shard to find the 'size' best results. But, because the complexity of search for the HNSW algorithm is logarithmic with respect to the number of vectors, searching over 5 graphs with a 100 vectors each and then taking the top size results from ```5*k``` results will take longer than searching over 1 graph with 500 vectors and then taking the top size results from k results. \n+Ideally having 1 segment per shard will give the optimal performance with respect to search latency. We could configure index to have multiple shards to aviod having giant shards and achieve more parallelism.\n+\n+We can control the number of segments either during indexing by asking Elasticsearch to slow down the segment creation by disabling the refresh interval or choosing larger refresh interval.\n+\n+### Warm up\n+\n+The graphs are constructed during indexing, but they are loaded into memory during the first search. The way search works in Lucene is that each segment is searched sequentially (so, for k-NN, each segment returns up to k nearest neighbors of the query point) and the top ```size``` number of results based on the score would be returned from all of the results returned by segements at a shard level(higher score --> better result). \n+\n+Once a graph is loaded(graphs are loaded outside Elasticsearch JVM), we cache the graphs in memory. So the initial queries would be expensive in the order of few seconds and subsequent queries should be faster in the order of milliseconds(assuming knn circuit breaker is not hit).\n+\n+In order to avoid this latency penalty during your first queries, a user should use the warmup API on the indices they want to search. The API looks like this:\n+\n+GET /_opendistro/_knn/warmup/index1,index2,index3?pretty", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg4NjA5Ng=="}, "originalCommit": {"oid": "d0e889c7428d6c059236bacdaa0ffeb6055301c1"}, "originalPosition": 94}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4MzU1Mzg1OnYy", "diffSide": "RIGHT", "path": "PerformanceTuning.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMToyMDowOVrOG4fTsg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMToyOTo0NFrOG4fmDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg4NjM4Ng==", "bodyText": "Minor: add \".\" after numbering", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461886386", "createdAt": "2020-07-28T21:20:09Z", "author": {"login": "jmazanec15"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,154 @@\n+# KNN Performance Tuning\n+\n+In this document we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  From a high level k-NN works on following principles:\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query) \n+* Each graph in the segment returns *<=k* neighbors. \n+* Coordinator node picks up final *size* number of neighbors from the neighbors returned by each shard\n+\n+## Indexing Performance Tuning\n+\n+The following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+1 Disable refresh interval  (Default = 1 sec)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0e889c7428d6c059236bacdaa0ffeb6055301c1"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg5MTA4Ng==", "bodyText": "Done", "url": "https://github.com/opendistro-for-elasticsearch/k-NN/pull/177#discussion_r461891086", "createdAt": "2020-07-28T21:29:44Z", "author": {"login": "vamshin"}, "path": "PerformanceTuning.md", "diffHunk": "@@ -0,0 +1,154 @@\n+# KNN Performance Tuning\n+\n+In this document we provide recommendations for performance tuning to improve indexing/search performance with the k-NN plugin.  From a high level k-NN works on following principles:\n+\n+* Graphs are created per (Lucene) segment\n+* Queries execute on segments sequentially inside the shard (same as any other Elasticsearch query) \n+* Each graph in the segment returns *<=k* neighbors. \n+* Coordinator node picks up final *size* number of neighbors from the neighbors returned by each shard\n+\n+## Indexing Performance Tuning\n+\n+The following steps could help improve indexing performance especially when you plan to index large number of vectors at once. \n+\n+1 Disable refresh interval  (Default = 1 sec)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg4NjM4Ng=="}, "originalCommit": {"oid": "d0e889c7428d6c059236bacdaa0ffeb6055301c1"}, "originalPosition": 14}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2653, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}